{"id": "2601.17966", "pdf": "https://arxiv.org/pdf/2601.17966", "abs": "https://arxiv.org/abs/2601.17966", "authors": ["Naman Gupta", "Sophie Stephenson", "Chung Chi Yeung", "Wei Ting Wu", "Jeneile Luebke", "Kate Walsh", "Rahul Chatterjee"], "title": "\"Lighting The Way For Those Not Here\": How Technology Researchers Can Help Fight the Missing and Murdered Indigenous Relatives (MMIR) Crisis", "categories": ["cs.CY", "cs.HC"], "comment": null, "summary": "Indigenous peoples across Turtle Island (North America) face disproportionate rates of disappearance and murder, a \"genocide\" rooted in settler-colonial violence and systemic erasure. Technology plays a crucial role in the Missing and Murdered Indigenous Relatives (MMIR) crisis: perpetuating harm and impeding investigations, yet enabling advocacy and resistance. Communities utilize technologies such as AMBER alerts, news websites, social media groups, and campaigns (like #MMIW, #MMIWR, #NoMoreStolenSisters, and #NoMoreStolenDaughters) to mobilize searches, amplify awareness, and honor missing relatives. Yet, little research in HCI has critically examined technology's role in shaping the MMIR crisis by centering community voices. Through a large-scale study, we analyze 140 webpages to identify systemic, technological, and institutional barriers that hinder communities' efforts, while highlighting socio-technical actions that foster healing and safety. Finally, we amplify Indigenous voices by providing a dataset of stories that resist epistemic erasure, along with recommendations for HCI researchers to support Indigenous-led initiatives with cultural sensitivity, accountability, and self-determination.", "AI": {"tldr": "本文探讨了技术在失踪和被谋杀的原住民亲属危机中的作用，并提出了支持原住民领导倡议的方法。", "motivation": "文章旨在通过中心化社区声音，审视技术如何影响MMIR危机，并提出解决措施以促进治愈与安全。", "method": "作者们进行了一项大规模研究，分析了140个网页，识别出系统性、技术和机构上的障碍，并强调了支持社区努力的行动。", "result": "文章揭示了现有的系统性和技术障碍，并提出了具体建议和一个数据集，以促进对原住民声音的认识和支持。", "conclusion": "作者呼吁HCI研究人员应采取文化敏感的方式，为原住民主导的倡议提供支持，从而推进治愈与安全的工作。"}}
{"id": "2601.17962", "pdf": "https://arxiv.org/pdf/2601.17962", "abs": "https://arxiv.org/abs/2601.17962", "authors": ["Wenhan Lyu", "Yimeng Wang", "Murong Yue", "Yifan Sun", "Jennifer Suh", "Meredith Kier", "Ziyu Yao", "Yixuan Zhang"], "title": "Designing AI Peers for Collaborative Mathematical Problem Solving with Middle School Students: A Participatory Design Study", "categories": ["cs.HC"], "comment": "Accepted by ACM CHI 2026", "summary": "Collaborative problem solving (CPS) is a fundamental practice in middle-school mathematics education; however, student groups frequently stall or struggle without ongoing teacher support. Recent work has explored how Generative AI tools can be designed to support one-on-one tutoring, but little is known about how AI can be designed as peer learning partners in collaborative learning contexts. We conducted a participatory design study with 24 middle school students, who first engaged in mathematics CPS tasks with AI peers in a technology probe, and then collaboratively designed their ideal AI peer. Our findings reveal that students envision an AI peer as competent in mathematics yet explicitly deferential, providing progressive scaffolds such as hints and checks under clear student control. Students preferred a tone of friendly expertise over exaggerated personas. We also discuss design recommendations and implications for AI peers in middle school mathematics CPS.", "AI": {"tldr": "本论文研究了如何设计AI同伴以支持初中生在数学协作问题解决中的学习，通过参与式设计研究方法收集学生对理想AI同伴的构想。", "motivation": "虽然协作解决问题是中学数学教育的基础实践，但小组合作经常需要持续的教师支持才能进行。本文旨在探索如何将生成性人工智能工具设计为协作学习环境中的同伴学习伙伴。", "method": "进行了参与式设计研究，与24名初中学生一起，首先让学生们在技术探测任务中使用AI同伴解决数学问题，然后共同设计他们理想的AI同伴。", "result": "学生们希望AI同伴在数学上具备能力但要表现出谦逊态度，并提供逐步的指导和检查，且完全处于学生的控制之下。他们更偏好友好的专家语气而非夸张的人设。", "conclusion": "研究结果提供了关于如何为初中学生设计AI同伴的建议，强调了AI同伴应具备的能力、态度以及用户友好性的重要性。"}}
{"id": "2601.17952", "pdf": "https://arxiv.org/pdf/2601.17952", "abs": "https://arxiv.org/abs/2601.17952", "authors": ["Michail Mamalakis", "Tiago Azevedo", "Cristian Cosentino", "Chiara D'Ercoli", "Subati Abulikemu", "Zhongtian Sun", "Richard Bethlehem", "Pietro Lio"], "title": "A Monosemantic Attribution Framework for Stable Interpretability in Clinical Neuroscience Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Interpretability remains a key challenge for deploying large language models (LLMs) in clinical settings such as Alzheimer's disease progression diagnosis, where early and trustworthy predictions are essential. Existing attribution methods exhibit high inter-method variability and unstable explanations due to the polysemantic nature of LLM representations, while mechanistic interpretability approaches lack direct alignment with model inputs and outputs and do not provide explicit importance scores. We introduce a unified interpretability framework that integrates attributional and mechanistic perspectives through monosemantic feature extraction. By constructing a monosemantic embedding space at the level of an LLM layer and optimizing the framework to explicitly reduce inter-method variability, our approach produces stable input-level importance scores and highlights salient features via a decompressed representation of the layer of interest, advancing the safe and trustworthy application of LLMs in cognitive health and neurodegenerative disease.", "AI": {"tldr": "本文提出了一种统一的可解释性框架，结合归因和机制视角通过单义特征提取来提高临床神经科学中大型语言模型在阿尔茨海默病诊断中的稳定性和可信度。", "motivation": "现有的归因方法由于多义性质表示而表现出高方法间差异和不稳定的解释，同时机械可解释性方法缺乏与输入输出的直接对齐且不能提供显式的权重得分。因此，需要一种新的框架来解决这些问题，以促进大型语言模型在认知健康领域的安全可信应用。", "method": "通过构建单义嵌入空间并优化框架减少归因差异，本文的方法生成稳定的重要性和特征高亮。", "result": "该方法能够提供稳定的输入级重要性评分，并且能突出显示显著的特征，这有助于提高大型语言模型在临床神经科学中的可解释性和稳定性。", "conclusion": "单义属性框架通过减少归因差异并提供明确的重要性得分和显著特征，增强了大型语言模型在阿尔茨海默病等疾病诊断中的稳定性和可信度。"}}
{"id": "2601.17950", "pdf": "https://arxiv.org/pdf/2601.17950", "abs": "https://arxiv.org/abs/2601.17950", "authors": ["Matthew Walmer", "Saksham Suri", "Anirud Aggarwal", "Abhinav Shrivastava"], "title": "UPLiFT: Efficient Pixel-Dense Feature Upsampling with Local Attenders", "categories": ["cs.CV"], "comment": null, "summary": "The space of task-agnostic feature upsampling has emerged as a promising area of research to efficiently create denser features from pre-trained visual backbones. These methods act as a shortcut to achieve dense features for a fraction of the cost by learning to map low-resolution features to high-resolution versions. While early works in this space used iterative upsampling approaches, more recent works have switched to cross-attention-based methods, which risk falling into the same efficiency scaling problems of the backbones they are upsampling. In this work, we demonstrate that iterative upsampling methods can still compete with cross-attention-based methods; moreover, they can achieve state-of-the-art performance with lower inference costs. We propose UPLiFT, an architecture for Universal Pixel-dense Lightweight Feature Transforms. We also propose an efficient Local Attender operator to overcome the limitations of prior iterative feature upsampling methods. This operator uses an alternative attentional pooling formulation defined fully locally. We show that our Local Attender allows UPLiFT to maintain stable features throughout upsampling, enabling state-of-the-art performance with lower inference costs than existing pixel-dense feature upsamplers. In addition, we apply UPLiFT to generative downstream tasks and show that it achieves competitive performance with state-of-the-art Coupled Flow Matching models for VAE feature upsampling. Altogether, UPLiFT offers a versatile and efficient approach to creating denser features.", "AI": {"tldr": "本文提出了UPLiFT架构，用于高效地将低分辨率的视觉特征映射到高分辨率版本。", "motivation": "作者旨在通过迭代上采样的方法来提高密集特征生成的效率，同时保持或超越基于交叉注意力的方法性能。", "method": "提出了一种名为Local Attender的操作符，其使用完全局部定义的注意池化形式克服了前人迭代特征上采样方法的局限性。", "result": "UPLiFT架构实现了与现有像素密集型特征上采样器相比更低的推理成本和领先的性能，在生成下游任务中也表现出色。", "conclusion": "UPLiFT提供了一种通用且高效的解决方案来创建更密集的视觉特征，具有稳定性和低计算开销的优势。"}}
{"id": "2601.17947", "pdf": "https://arxiv.org/pdf/2601.17947", "abs": "https://arxiv.org/abs/2601.17947", "authors": ["Bora Yimenicioglu", "Vishal Manikanden"], "title": "FlowMorph: Physics-Consistent Self-Supervision for Label-Free Single-Cell Mechanics in Microfluidic Videos", "categories": ["cs.CV"], "comment": null, "summary": "Mechanical properties of red blood cells (RBCs) are promising biomarkers for hematologic and systemic disease, motivating microfluidic assays that probe deformability at throughputs of $10^3$--$10^6$ cells per experiment. However, existing pipelines rely on supervised segmentation or hand-crafted kymographs and rarely encode the laminar Stokes-flow physics that governs RBC shape evolution. We introduce FlowMorph, a physics-consistent self-supervised framework that learns a label-free scalar mechanics proxy $k$ for each tracked RBC from short brightfield microfluidic videos. FlowMorph models each cell by a low-dimensional parametric contour, advances boundary points through a differentiable ''capsule-in-flow'' combining laminar advection and curvature-regularized elastic relaxation, and optimizes a loss coupling silhouette overlap, intra-cellular flow agreement, area conservation, wall constraints, and temporal smoothness, using only automatically derived silhouettes and optical flow. Across four public RBC microfluidic datasets, FlowMorph achieves a mean silhouette IoU of $0.905$ on physics-rich videos with provided velocity fields and markedly improves area conservation and wall violations over purely data-driven baselines. On $\\sim 1.5\\times 10^5$ centered sequences, the scalar $k$ alone separates tank-treading from flipping dynamics with an AUC of $0.863$. Using only $200$ real-time deformability cytometry (RT-DC) events for calibration, a monotone map $E=g(k)$ predicts apparent Young's modulus with a mean absolute error of $0.118$\\,MPa on $600$ held-out cells and degrades gracefully under shifts in channel geometry, optics, and frame rate.", "AI": {"tldr": "FlowMorph 是一个用于从微流控视频中无标签学习单个红细胞力学特性的自监督框架。", "motivation": "研究动力是由于红细胞的机械属性作为血液和全身疾病的生物标志物具有潜力，但现有的管道依赖于监督分割或手工制作的时间图，很少编码控制 RBC 形状演化的层流斯托克斯物理。", "method": "FlowMorph 使用低维参数轮廓建模每个细胞，并通过结合层流传导和曲率正则化弹性松弛的可微 '胶囊在流动中' 模型推进边界点。它优化了一个损失函数，该函数耦合了剪影重叠、胞内流一致性、面积保存、壁约束及时间平滑度，仅使用自动提取的剪影和光流。", "result": "FlowMorph 在四个公开的 RBC 微流控数据集上实现了平均轮廓 IoU 达到0.905，并显著改善了面积保存和壁违反问题。它可以通过标量k分离坦克踏步与翻转动态，AUC为0.863。", "conclusion": "FlowMorph 使用仅200个实时变形细胞计数事件校准的单调映射预测杨氏模量，并在通道几何、光学和帧率变化下表现出良好的泛化能力。"}}
{"id": "2601.17946", "pdf": "https://arxiv.org/pdf/2601.17946", "abs": "https://arxiv.org/abs/2601.17946", "authors": ["Renkai Ma", "Ben Z. Zhang", "Chen Chen", "Fan Yang", "Xiaoshan Huang", "Haolun Wu", "Lingyao Li"], "title": "\"I use ChatGPT to humanize my words\": Affordances and Risks of ChatGPT to Autistic Users", "categories": ["cs.HC"], "comment": null, "summary": "Large Language Model (LLM) chatbots like ChatGPT have emerged as cognitive scaffolding for autistic users, yet the tension between their utility and risk remains under-articulated. Through an inductive thematic analysis of 3,984 social media posts by self-identified autistic users, we apply the Technology Affordance framework to examine this duality. We found that while users leveraged ChatGPT to offload executive dysfunction, regulate emotions, translate neurotypical communication, and validate their autistic identity, these affordances coexist with significant risks: reinforcing delusional thinking, erasing authentic identity through automated masking, and triggering conflicts with the autistic sense of justice. This poster identifies these trade-offs in autistic users' interactions with ChatGPT and concludes by outlining our future work on developing neuro-inclusive technologies that address these tensions through beneficial friction and bidirectional translation.", "AI": {"tldr": "本文探讨了大型语言模型聊天机器人ChatGPT对自闭症用户既有利又有风险的双重作用。", "motivation": "由于大语言模型（LLM）聊天机器人像ChatGPT这样的工具被用作自闭症用户的认知支架，但其效用和风险之间的张力尚未得到充分阐述。", "method": "通过归纳主题分析来自3,984条社交媒体帖子的数据，这些数据是由自我认定为自闭症的用户发布的，并应用技术能力框架来研究这种双重性。", "result": "发现虽然用户利用ChatGPT缓解执行功能障碍、调节情绪、翻译神经典型交流和验证其自闭症身份，但这些优势也伴随着重大风险：强化妄想思维、通过自动化掩盖抹去真实身份以及触发与自闭症正义感的冲突。", "conclusion": "该研究确定了自闭症用户与ChatGPT互动中的权衡，并概述了未来工作的方向，即开发神经包容性技术来解决这些矛盾并实现有益摩擦和双向翻译。"}}
{"id": "2601.17944", "pdf": "https://arxiv.org/pdf/2601.17944", "abs": "https://arxiv.org/abs/2601.17944", "authors": ["Seyed Majid Zahedi", "Rupert Freeman"], "title": "Credit Fairness: Online Fairness In Shared Resource Pools", "categories": ["cs.GT", "cs.AI", "cs.OS"], "comment": null, "summary": "We consider a setting in which a group of agents share resources that must be allocated among them in each discrete time period. Agents have time-varying demands and derive constant marginal utility from each unit of resource received up to their demand, with zero utility for any additional resources. In this setting, it is known that independently maximizing the minimum utility in each round satisfies sharing incentives (agents weakly prefer participating in the mechanism to not participating), strategyproofness (agents have no incentive to misreport their demands), and Pareto efficiency (Freeman et al. 2018). However, recent work (Vuppalapati et al. 2023) has shown that this max-min mechanism can lead to large disparities in the total resources received by agents, even when they have the same average demand. In this paper, we introduce credit fairness, a strengthening of sharing incentives that ensures agents who lend resources in early rounds are able to recoup them in later rounds. Credit fairness can be achieved in conjunction with either Pareto efficiency or strategyproofness, but not both. We propose a mechanism that is credit fair and Pareto efficient, and we evaluate its performance in a computational resource-sharing setting.", "AI": {"tldr": "本文提出了一种称为信用公平的机制，确保在早期轮次中共享资源的代理能够在后期收回这些资源，并且这种机制可以实现帕累托效率。", "motivation": "现有的最大最小效用分配机制虽然满足了共享激励、策略证明性和帕累托效率，但会导致不同代理间获得资源总量的巨大差异。因此，作者希望通过提出新的信用公平机制来解决这一问题。", "method": "提出了一个既具有信用公平性又保持帕累托效率的机制，并在计算资源共享场景中对其性能进行了评估。", "result": "提出的机制实现了信用公平和帕累托效率，并通过实验展示了其有效性。", "conclusion": "证明了所提出的方法能够有效地解决资源分配中的信用公平问题，同时保持了帕累托效率。"}}
{"id": "2601.17942", "pdf": "https://arxiv.org/pdf/2601.17942", "abs": "https://arxiv.org/abs/2601.17942", "authors": ["Yu-Jie Yang", "Hung-Fu Chang", "Po-An Chen"], "title": "LLM-Based SQL Generation: Prompting, Self-Refinement, and Adaptive Weighted Majority Voting", "categories": ["cs.AI", "cs.DB"], "comment": "29 pages, 22 figures", "summary": "Text-to-SQL has emerged as a prominent research area, particularly with the rapid advancement of large language models (LLMs). By enabling users to query databases through natural language rather than SQL, this technology significantly lowers the barrier to data analysis. However, generating accurate SQL from natural language remains challenging due to ambiguity in user queries, the complexity of schema linking, limited generalization across SQL dialects, and the need for domain-specific understanding. In this study, we propose a Single-Agent Self-Refinement with Ensemble Voting (SSEV) pipeline built on PET-SQL that operates without ground-truth data, integrating self-refinement with Weighted Majority Voting (WMV) and its randomized variant (RWMA). Experimental results show that the SSEV achieves competitive performance across multiple benchmarks, attaining execution accuracies of 85.5% on Spider 1.0-Dev, 86.4% on Spider 1.0-Test, and 66.3% on BIRD-Dev. Building on insights from the SSEV pipeline, we further propose ReCAPAgent-SQL (Refinement-Critique-Act-Plan agent-based SQL framework) to address the growing complexity of enterprise databases and real-world Text-to-SQL tasks. The framework integrates multiple specialized agents for planning, external knowledge retrieval, critique, action generation, self-refinement, schema linking, and result validation, enabling iterative refinement of SQL predictions through agent collaboration. ReCAPAgent-SQL's WMA results achieve 31% execution accuracy on the first 100 queries of Spider 2.0-Lite, demonstrating significant improvements in handling real-world enterprise scenarios. Overall, our work facilitates the deployment of scalable Text-to-SQL systems in practical settings, supporting better data-driven decision-making at lower cost and with greater efficiency.", "AI": {"tldr": "本文提出了一种基于大型语言模型的SQL生成方法，通过自我精炼和集成投票来提高准确性，并进一步提出了一个包含多个专用代理的框架以处理复杂的企业数据库查询。", "motivation": "文本到SQL转换技术可以降低数据分析的门槛，但生成准确SQL仍面临用户查询模糊、模式链接复杂及跨SQL方言泛化能力有限等问题。本文旨在解决这些问题并提高Text-to-SQL系统的实际应用效果。", "method": "作者提出了一种无地面真实数据支持的SSEV管道，结合自我精炼和加权多数投票技术，并在此基础上开发了ReCAPAgent-SQL框架，通过多个专用代理来处理复杂的SQL生成任务。", "result": "实验结果表明，提出的SSEV在Spider 1.0-Dev和Test上的执行准确率分别达到85.5%和86.4%，而在BIRD-Dev上为66.3%。ReCAPAgent-SQL在处理真实世界企业场景时，前100个查询的执行准确率为31%。", "conclusion": "本文的工作有助于实现Text-to-SQL系统的实际部署，支持更低成本和更高效率的数据驱动决策制定，尤其适用于复杂的企业数据库环境下的文本到SQL转换任务。"}}
{"id": "2601.17939", "pdf": "https://arxiv.org/pdf/2601.17939", "abs": "https://arxiv.org/abs/2601.17939", "authors": ["Chengkun Sun", "Jinqian Pan", "Renjie Liang", "Zhengkang Fan", "Xin Miao", "Jiang Bian", "Jie Xu"], "title": "DTC: A Deformable Transposed Convolution Module for Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "In medical image segmentation, particularly in UNet-like architectures, upsampling is primarily used to transform smaller feature maps into larger ones, enabling feature fusion between encoder and decoder features and supporting multi-scale prediction. Conventional upsampling methods, such as transposed convolution and linear interpolation, operate on fixed positions: transposed convolution applies kernel elements to predetermined pixel or voxel locations, while linear interpolation assigns values based on fixed coordinates in the original feature map. These fixed-position approaches may fail to capture structural information beyond predefined sampling positions and can lead to artifacts or loss of detail. Inspired by deformable convolutions, we propose a novel upsampling method, Deformable Transposed Convolution (DTC), which learns dynamic coordinates (i.e., sampling positions) to generate high-resolution feature maps for both 2D and 3D medical image segmentation tasks. Experiments on 3D (e.g., BTCV15) and 2D datasets (e.g., ISIC18, BUSI) demonstrate that DTC can be effectively integrated into existing medical image segmentation models, consistently improving the decoder's feature reconstruction and detail recovery capability.", "AI": {"tldr": "本文提出了Deformable Transposed Convolution (DTC)模块，用于改进医疗图像分割中的上采样过程。", "motivation": "传统的上采样方法在固定位置进行操作，可能会导致结构信息丢失和细节损失。为了克服这些缺点，作者受到可变形卷积的启发，提出了DTC来学习动态坐标以生成高分辨率特征图。", "method": "提出了一种名为Deformable Transposed Convolution (DTC)的新上采样方法，该方法能够学习动态坐标（即采样位置），适用于2D和3D医疗图像分割任务。", "result": "实验结果表明，在3D（如BTCV15）和2D数据集（如ISIC18, BUSI）上，将DTC集成到现有的医疗图像分割模型中能够显著提升特征重建和细节恢复能力。", "conclusion": "研究证明了Deformable Transposed Convolution (DTC)在改进医疗图像分割的特征重构和细节恢复方面是有效的。"}}
{"id": "2601.17937", "pdf": "https://arxiv.org/pdf/2601.17937", "abs": "https://arxiv.org/abs/2601.17937", "authors": ["Anne Arzberger", "Celine Offerman", "Ujwal Gadiraju", "Alessandro Bozzon", "Jie Yang"], "title": "\"Label from Somewhere\": Reflexive Annotating for Situated AI Alignment", "categories": ["cs.HC"], "comment": null, "summary": "AI alignment relies on annotator judgments, yet annotation pipelines often treat annotators as interchangeable, obscuring how their social position shapes annotation. We introduce reflexive annotating as a probe that invites crowd workers to reflect on how their positionality informs subjective annotation judgments in a language model alignment context. Through a qualitative study with crowd workers (N=30) and follow-up interviews (N=5), we examine how our probe shapes annotators' behaviour, experience, and the situated metadata it elicits. We find that reflexive annotating captures epistemic metadata beyond static demographics by eliciting intersectional reasoning, surfacing positional humility, and nudging viewpoint change. Crucially, we also denote tensions between reflexive engagement and affective demands such as emotional exposure. We discuss the implications of our work for richer value elicitation and alignment practices that treat annotator judgments as situated and selectively integrate positional metadata.", "AI": {"tldr": "本文介绍了反射式标注方法，通过邀请众包工作者反思其社会位置如何影响主观注释判断，旨在为语言模型对齐提供更丰富的价值和定位元数据。", "motivation": "动机在于解决现有AI对齐依赖的注释过程忽视了注释者的社会地位对其判断的影响，并且通常将注释者视为可互换的资源，这阻碍了更加细致的理解注释行为。", "method": "作者进行了一项定性研究，包括30名众包工作者和后续5人的访谈，探讨反射式标注如何影响注释行为、体验及所揭示的社会位置元数据。", "result": "研究表明，反射式标注不仅能够捕获超越静态人口统计信息的知识元数据，还可以激发交叉思考、展现职位谦逊，并促进观点的转变。但也发现了与情感需求如情绪暴露之间的张力。", "conclusion": "研究结果表明，在AI对齐实践中应更细致地对待注释者的判断，考虑其社会位置并选择性整合定位元数据以实现更加丰富的价值提取和对齐实践。"}}
{"id": "2601.17934", "pdf": "https://arxiv.org/pdf/2601.17934", "abs": "https://arxiv.org/abs/2601.17934", "authors": ["Vi Vu", "Thanh-Huy Nguyen", "Tien-Thinh Nguyen", "Ba-Thinh Lam", "Hoang-Thien Nguyen", "Tianyang Wang", "Xingjian Li", "Min Xu"], "title": "From Specialist to Generalist: Unlocking SAM's Learning Potential on Unlabeled Medical Images", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to ISBI 2026", "summary": "Foundation models like the Segment Anything Model (SAM) show strong generalization, yet adapting them to medical images remains difficult due to domain shift, scarce labels, and the inability of Parameter-Efficient Fine-Tuning (PEFT) to exploit unlabeled data. While conventional models like U-Net excel in semi-supervised medical learning, their potential to assist a PEFT SAM has been largely overlooked. We introduce SC-SAM, a specialist-generalist framework where U-Net provides point-based prompts and pseudo-labels to guide SAM's adaptation, while SAM serves as a powerful generalist supervisor to regularize U-Net. This reciprocal guidance forms a bidirectional co-training loop that allows both models to effectively exploit the unlabeled data. Across prostate MRI and polyp segmentation benchmarks, our method achieves state-of-the-art results, outperforming other existing semi-supervised SAM variants and even medical foundation models like MedSAM, highlighting the value of specialist-generalist cooperation for label-efficient medical image segmentation. Our code is available at https://github.com/vnlvi2k3/SC-SAM.", "AI": {"tldr": "本文介绍了SC-SAM框架，通过U-Net提供点式提示和伪标签指导SAM适应医学图像，并利用SAM作为强大的通用监督模型来规整U-Net，形成双向协同训练循环。", "motivation": "虽然基础模型如Segment Anything Model (SAM)展示了强泛化能力，但将其应用于医学图像面临领域迁移、标签稀缺等问题。传统模型如U-Net在半监督学习中表现出色，然而它们辅助PEFT SAM的潜力尚未得到充分利用。", "method": "SC-SAM框架利用U-Net提供点式提示和伪标签来引导SAM适应医学图像，而SAM则作为强大的通用监督模型来规整U-Net，两者形成双向协同训练循环。", "result": "在前列腺MRI和息肉分割基准测试中，该方法取得了最先进的结果，优于其他现有的半监督SAM变体及医学基础模型如MedSAM。", "conclusion": "研究证明了专家模型与通用模型合作对于标签高效的医学图像分割的价值，并展示了如何通过双向协同训练循环利用无标签数据。"}}
{"id": "2601.17933", "pdf": "https://arxiv.org/pdf/2601.17933", "abs": "https://arxiv.org/abs/2601.17933", "authors": ["Laurent Caraffa"], "title": "Dissipative Learning: A Framework for Viable Adaptive Systems", "categories": ["cs.LG", "cs.CV"], "comment": "68 pages, 14 figures", "summary": "We propose a perspective in which learning is an intrinsically dissipative process. Forgetting and regularization are not heuristic add-ons but structural requirements for adaptive systems. Drawing on information theory, thermodynamics, and information geometry, we introduce the BEDS (Bayesian Emergent Dissipative Structures) framework, modeling learning as the evolution of compressed belief states under dissipation constraints. A central contribution is the Conditional Optimality Theorem, showing that Fisher-Rao regularization measuring change via information divergence rather than Euclidean distance is the unique thermodynamically optimal regularization strategy, achieving minimal dissipation. Euclidean regularization is shown to be structurally suboptimal. The framework unifies existing methods (Ridge, SIGReg, EMA, SAC) as special cases of a single governing equation. Within this view, overfitting corresponds to over-crystallization, while catastrophic forgetting reflects insufficient dissipation control. The framework distinguishes BEDS-crystallizable problems, where beliefs converge to stable equilibria, from BEDS-maintainable problems, which require continual adaptation. It extends naturally to continual and multi-agent systems, where viability, stability under adaptation and finite resources replaces asymptotic optimality as the primary criterion. Overall, this work reframes learning as maintaining viable belief states under dissipation constraints, providing a principled lens on forgetting, regularization, and stability.", "AI": {"tldr": "本文提出了一个框架，将学习视为一种耗散过程，并引入了BEDS（贝叶斯涌现耗散结构）框架来模拟在耗散约束下的信念状态演化。", "motivation": "作者希望通过信息论、热力学和信息几何的角度，重新定义学习作为一种内在的耗散过程，强调遗忘和正则化是自适应系统的基本要求。", "method": "引入BEDS框架，并证明Fisher-Rao正则化的条件最优性定理，将其视为实现最小耗散的唯一热力学优化策略，并将现有方法统一为一个治理方程下的特殊情况。", "result": "展示了欧几里得正则化在结构上的次优性，并定义了BEDS可结晶问题和BEDS可维持问题。框架适用于持续学习和多代理系统，强调在有限资源下适应过程中的生存性和稳定性。", "conclusion": "本文提出了一个新的视角，将学习重新定义为维护耗散约束下的可行信念状态，提供了一个原理性的框架来理解和分析遗忘、正则化和稳定性的关系。"}}
{"id": "2601.17927", "pdf": "https://arxiv.org/pdf/2601.17927", "abs": "https://arxiv.org/abs/2601.17927", "authors": ["Eashan Adhikarla", "Brian D. Davison"], "title": "RemEdit: Efficient Diffusion Editing with Riemannian Geometry", "categories": ["cs.CV", "cs.MM"], "comment": "ef:IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2026", "summary": "Controllable image generation is fundamental to the success of modern generative AI, yet it faces a critical trade-off between semantic fidelity and inference speed. The RemEdit diffusion-based framework addresses this trade-off with two synergistic innovations. First, for editing fidelity, we navigate the latent space as a Riemannian manifold. A mamba-based module efficiently learns the manifold's structure, enabling direct and accurate geodesic path computation for smooth semantic edits. This control is further refined by a dual-SLERP blending technique and a goal-aware prompt enrichment pass from a Vision-Language Model. Second, for additional acceleration, we introduce a novel task-specific attention pruning mechanism. A lightweight pruning head learns to retain tokens essential to the edit, enabling effective optimization without the semantic degradation common in content-agnostic approaches. RemEdit surpasses prior state-of-the-art editing frameworks while maintaining real-time performance under 50% pruning. Consequently, RemEdit establishes a new benchmark for practical and powerful image editing. Source code: https://www.github.com/eashanadhikarla/RemEdit.", "AI": {"tldr": "RemEdit 提出了一种基于扩散模型的图像编辑框架，通过黎曼几何和任务特定注意力剪枝机制提高了编辑的准确性和推理速度。", "motivation": "文章旨在解决现代生成AI在可控图像生成中面临的语义保真度与推断速度之间的权衡问题。", "method": "RemEdit 使用mamba模块学习潜空间中的黎曼流形结构，结合双SLERP混合技术及目标导向的提示增强来提高编辑准确性；同时引入了任务特定注意力剪枝机制以加速处理。", "result": "RemEdit 在保持实时性能的情况下，在50%的剪枝下超越了先前的最先进框架，确立了图像编辑的新基准。", "conclusion": "通过结合黎曼几何和注意力剪枝技术，RemEdit 实现了高效的语义保真度控制与快速推理速度，为实用且强大的图像编辑设立了新标准。"}}
{"id": "2601.17923", "pdf": "https://arxiv.org/pdf/2601.17923", "abs": "https://arxiv.org/abs/2601.17923", "authors": ["Ali Najar"], "title": "Learning Transferable Skills in Action RPGs via Directed Skill Graphs and Selective Adaptation", "categories": ["cs.AI"], "comment": "5 pages", "summary": "Lifelong agents should expand their competence over time without retraining from scratch or overwriting previously learned behaviors. We investigate this in a challenging real-time control setting (Dark Souls III) by representing combat as a directed skill graph and training its components in a hierarchical curriculum. The resulting agent decomposes control into five reusable skills: camera control, target lock-on, movement, dodging, and a heal-attack decision policy, each optimized for a narrow responsibility. This factorization improves sample efficiency by reducing the burden on any single policy and supports selective post-training: when the environment shifts from Phase 1 to Phase 2, only a subset of skills must be adapted, while upstream skills remain transferable. Empirically, we find that targeted fine-tuning of just two skills rapidly recovers performance under a limited interaction budget, suggesting that skill-graph curricula together with selective fine-tuning offer a practical pathway toward evolving, continually learning agents in complex real-time environments.", "AI": {"tldr": "本文探讨了通过有向技能图和选择性适应在动作角色扮演游戏《暗魂III》中学习可迁移技能的方法。", "motivation": "作者旨在研究如何使人工智能代理能够在复杂实时环境中不断扩展其能力，而无需从头开始重新训练或覆盖之前学到的行为。", "method": "通过将战斗表示为有向技能图，并采用分层课程进行组件培训。该方法分解控制为五种可重用的技能：摄像机控制、目标锁定、移动、躲避和治疗攻击决策策略，每个技能优化特定责任。", "result": "实验表明，只需针对两个技能进行有针对性的微调就可以在有限交互预算下迅速恢复性能，这证明了技能图课程结合选择性微调为复杂实时环境中的不断学习代理提供了一条实际途径。", "conclusion": "该方法通过减少单个策略的工作负担提高了样本效率，并支持在环境变化时仅对部分技能进行适应，保持上游技能的可迁移性。"}}
{"id": "2601.17920", "pdf": "https://arxiv.org/pdf/2601.17920", "abs": "https://arxiv.org/abs/2601.17920", "authors": ["Xuanzhou Chen", "Audrey Wang", "Stanley Yin", "Hanyang Jiang", "Dong Zhang"], "title": "Agentic AI for Self-Driving Laboratories in Soft Matter: Taxonomy, Benchmarks,and Open Challenges", "categories": ["cs.AI"], "comment": null, "summary": "Self-driving laboratories (SDLs) close the loop between experiment design, automated execution, and data-driven decision making, and they provide a demanding testbed for agentic AI under expensive actions, noisy and delayed feedback, strict feasibility and safety constraints, and non-stationarity. This survey uses soft matter as a representative setting but focuses on the AI questions that arise in real laboratories. We frame SDL autonomy as an agent environment interaction problem with explicit observations, actions, costs, and constraints, and we use this formulation to connect common SDL pipelines to established AI principles. We review the main method families that enable closed loop experimentation, including Bayesian optimization and active learning for sample efficient experiment selection, planning and reinforcement learning for long horizon protocol optimization, and tool using agents that orchestrate heterogeneous instruments and software. We emphasize verifiable and provenance aware policies that support debugging, reproducibility, and safe operation. We then propose a capability driven taxonomy that organizes systems by decision horizon, uncertainty modeling, action parameterization, constraint handling, failure recovery, and human involvement. To enable meaningful comparison, we synthesize benchmark task templates and evaluation metrics that prioritize cost aware performance, robustness to drift, constraint violation behavior, and reproducibility. Finally, we distill lessons from deployed SDLs and outline open challenges in multi-modal representation, calibrated uncertainty, safe exploration, and shared benchmark infrastructure.", "AI": {"tldr": "本文探讨了自驱动实验室中的代理人工智能，提出了一个以能力为基础的分类法，并制定了基准任务和评估指标。", "motivation": "研究动机在于探索在自驱动实验室中应用代理AI时面临的挑战，包括昂贵的操作、延迟反馈以及非平稳性等问题。", "method": "本文采用了代理环境交互模型，通过贝叶斯优化、主动学习及强化学习等方法实现闭环实验。", "result": "提出了一个分类法来组织决策范围、不确定性建模、动作参数化等内容，并制定了基准任务和评估指标以促进有意义的比较。", "conclusion": "本文总结了部署自驱动实验室的经验教训，指出了多模态表示、校准不确定性和安全探索等开放挑战。"}}
{"id": "2601.17918", "pdf": "https://arxiv.org/pdf/2601.17918", "abs": "https://arxiv.org/abs/2601.17918", "authors": ["Dain Kim", "Jiwoo Lee", "Jaehoon Yun", "Yong Hoe Koo", "Qingyu Chen", "Hyunjae Kim", "Jaewoo Kang"], "title": "Benchmarking Direct Preference Optimization for Medical Large Vision-Language Models", "categories": ["cs.CV", "cs.CL"], "comment": "EACL 2026 (Findings)", "summary": "Large Vision-Language Models (LVLMs) hold significant promise for medical applications, yet their deployment is often constrained by insufficient alignment and reliability. While Direct Preference Optimization (DPO) has emerged as a potent framework for refining model responses, its efficacy in high-stakes medical contexts remains underexplored, lacking the rigorous empirical groundwork necessary to guide future methodological advances. To bridge this gap, we present the first comprehensive examination of diverse DPO variants within the medical domain, evaluating nine distinct formulations across two medical LVLMs: LLaVA-Med and HuatuoGPT-Vision. Our results reveal several critical limitations: current DPO approaches often yield inconsistent gains over supervised fine-tuning, with their efficacy varying significantly across different tasks and backbones. Furthermore, they frequently fail to resolve fundamental visual misinterpretation errors. Building on these insights, we present a targeted preference construction strategy as a proof-of-concept that explicitly addresses visual misinterpretation errors frequently observed in existing DPO models. This design yields a 3.6% improvement over the strongest existing DPO baseline on visual question-answering tasks. To support future research, we release our complete framework, including all training data, model checkpoints, and our codebase at https://github.com/dmis-lab/med-vlm-dpo.", "AI": {"tldr": "本文对医学大视觉语言模型中的直接偏好优化进行了全面评估，揭示了其在医疗领域应用中的局限性，并提出了一种针对视觉误解错误的改进策略。", "motivation": "大型视觉语言模型虽然具有重要的医疗应用潜力，但它们的一致性和可靠性往往不足。当前缺乏对这些模型在高风险医学环境中的有效性的系统研究，本文旨在填补这一空白。", "method": "评估了九种不同的直接偏好优化变体在两个医学大视觉语言模型（LLaVA-Med和HuatuoGPT-Vision）上的表现，并提出了一种针对性的改进策略以解决视觉误解错误问题。", "result": "发现当前的直接偏好优化方法经常不能稳定地超越监督微调的效果，且对不同任务和基础架构的有效性存在显著差异。提出的方法在视觉问答任务上比最强的现有基线提高了3.6%。", "conclusion": "本文揭示了直接偏好优化在医学大视觉语言模型中的局限性，并通过引入一种针对性策略证明了其改进潜力，支持未来研究的完整框架也一并公开。"}}
{"id": "2601.17917", "pdf": "https://arxiv.org/pdf/2601.17917", "abs": "https://arxiv.org/abs/2601.17917", "authors": ["Zhongyu Xiao", "Zhiwei Hao", "Jianyuan Guo", "Yong Luo", "Jia Liu", "Jie Xu", "Han Hu"], "title": "treaming-dLLM: Accelerating Diffusion LLMs via Suffix Pruning and Dynamic Decoding", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": "Tech report. Code is available at https://github.com/xiaoshideta/Streaming-dLLM", "summary": "Diffusion Large Language Models (dLLMs) offer a compelling paradigm for natural language generation, leveraging parallel decoding and bidirectional attention to achieve superior global coherence compared to autoregressive models. While recent works have accelerated inference via KV cache reuse or heuristic decoding, they overlook the intrinsic inefficiencies within the block-wise diffusion process. Specifically, they suffer from spatial redundancy by modeling informative-sparse suffix regions uniformly and temporal inefficiency by applying fixed denoising schedules across all the decoding process. To address this, we propose Streaming-dLLM, a training-free framework that streamlines inference across both spatial and temporal dimensions. Spatially, we introduce attenuation guided suffix modeling to approximate the full context by pruning redundant mask tokens. Temporally, we employ a dynamic confidence aware strategy with an early exit mechanism, allowing the model to skip unnecessary iterations for converged tokens. Extensive experiments show that Streaming-dLLM achieves up to 68.2X speedup while maintaining generation quality, highlighting its effectiveness in diffusion decoding. The code is available at https://github.com/xiaoshideta/Streaming-dLLM.", "AI": {"tldr": "该论文提出了一种名为Streaming-dLLM的框架，通过截断后缀和动态解码来加速扩散大语言模型的推理过程。", "motivation": "现有的工作虽然通过KV缓存复用或启发式解码等方式加快了推理速度，但忽略了块状扩散过程中固有的低效问题。这些问题包括空间冗余和时间上的低效。", "method": "在空间上，引入衰减引导的后缀建模来近似整个上下文并剪枝多余的掩码标记；在时间维度上，采用动态自信感知策略结合早期退出机制，使得模型可以跳过已经收敛的标记不必要的迭代。", "result": "实验结果表明，Streaming-dLLM实现了最高68.2倍的速度提升，并且保持了生成的质量。", "conclusion": "该研究展示了一个无需训练的框架如何在不牺牲生成质量的情况下显著加速扩散大语言模型的推理过程。"}}
{"id": "2601.17915", "pdf": "https://arxiv.org/pdf/2601.17915", "abs": "https://arxiv.org/abs/2601.17915", "authors": ["Saurabh Jha", "Rohan Arora", "Bhavya", "Noah Zheutlin", "Paulina Toro Isaza", "Laura Shwartz", "Yu Deng", "Daby Sow", "Ruchi Mahindru", "Ruchir Puri"], "title": "Think Locally, Explain Globally: Graph-Guided LLM Investigations via Local Reasoning and Belief Propagation", "categories": ["cs.AI", "cs.LG", "cs.LO"], "comment": null, "summary": "LLM agents excel when environments are mostly static and the needed information fits in a model's context window, but they often fail in open-ended investigations where explanations must be constructed by iteratively mining evidence from massive, heterogeneous operational data. These investigations exhibit hidden dependency structure: entities interact, signals co-vary, and the importance of a fact may only become clear after other evidence is discovered. Because the context window is bounded, agents must summarize intermediate findings before their significance is known, increasing the risk of discarding key evidence. ReAct-style agents are especially brittle in this regime. Their retrieve-summarize-reason loop makes conclusions sensitive to exploration order and introduces run-to-run non-determinism, producing a reliability gap where Pass-at-k may be high but Majority-at-k remains low. Simply sampling more rollouts or generating longer reasoning traces does not reliably stabilize results, since hypotheses cannot be autonomously checked as new evidence arrives and there is no explicit mechanism for belief bookkeeping and revision. In addition, ReAct entangles semantic reasoning with controller duties such as tool orchestration and state tracking, so execution errors and plan drift degrade reasoning while consuming scarce context. We address these issues by formulating investigation as abductive reasoning over a dependency graph and proposing EoG (Explanations over Graphs), a disaggregated framework in which an LLM performs bounded local evidence mining and labeling (cause vs symptom) while a deterministic controller manages traversal, state, and belief propagation to compute a minimal explanatory frontier. On a representative ITBench diagnostics task, EoG improves both accuracy and run-to-run consistency over ReAct baselines, including a 7x average gain in Majority-at-k entity F1.", "AI": {"tldr": "本文提出了EoG框架，通过图引导的局部推理和信念传播来改进LLM在开放调查任务中的表现。", "motivation": "解决现有LLM如ReAct在处理开放性、迭代式证据挖掘时存在的可靠性问题，特别是在事实重要性不明确的情况下容易丢失关键信息。", "method": "EoG框架将调查视为依赖图上的反向推理问题，并分离了局部证据的提取与全局控制任务。", "result": "EoG在ITBench诊断任务上提升了准确性和运行一致性，Majority-at-k实体F1平均提高了7倍。", "conclusion": "通过分解LLM的功能和采用依赖图方法，EoG框架显著改善了开放性调查任务的可靠性和效率。"}}
{"id": "2601.17912", "pdf": "https://arxiv.org/pdf/2601.17912", "abs": "https://arxiv.org/abs/2601.17912", "authors": ["Qinyi Liu", "Mohammad Khalil", "Naman Goel"], "title": "Causal Pre-training Under the Fairness Lens: An Empirical Study of TabPFN", "categories": ["cs.LG", "cs.AI"], "comment": "ef:Proceedings of the ACM Web Conference 2026 (WWW '26), April 13--17, 2026, Dubai, United Arab Emirates", "summary": "Foundation models for tabular data, such as the Tabular Prior-data Fitted Network (TabPFN), are pre-trained on a massive number of synthetic datasets generated by structural causal models (SCM). They leverage in-context learning to offer high predictive accuracy in real-world tasks. However, the fairness properties of these foundational models, which incorporate ideas from causal reasoning during pre-training, have not yet been explored in sufficient depth. In this work, we conduct a comprehensive empirical evaluation of TabPFN and its fine-tuned variants, assessing predictive performance, fairness, and robustness across varying dataset sizes and distributional shifts. Our results reveal that while TabPFN achieves stronger predictive accuracy compared to baselines and exhibits robustness to spurious correlations, improvements in fairness are moderate and inconsistent, particularly under missing-not-at-random (MNAR) covariate shifts. These findings suggest that the causal pre-training in TabPFN is helpful but insufficient for algorithmic fairness, highlighting implications for deploying such models in practice and the need for further fairness interventions.", "AI": {"tldr": "评估TabPFN及其微调变体在预测性能、公平性和鲁棒性方面的表现，特别是在不同数据集大小和分布变化下的表现。", "motivation": "探讨将因果推理概念融入预训练的Foundation模型（如TabPFN）是否能改善算法公平性，并发现这些模型在实际应用中的局限性。", "method": "通过综合实证评估，比较TabPFN及其微调变体与基线模型在预测性能、公平性和鲁棒性方面的表现，考虑了不同数据集大小和分布变化的影响。", "result": "TabPFN展现出比基准更高的预测准确性，并且对虚假相关性有较强的抵抗能力；然而，在缺失值不随机（MNAR）的情况下，其改进的公平性是适度和不一致的。", "conclusion": "尽管因果预训练在TabPFN中有所助益，但不足以实现算法公平性，提示部署此类模型需进一步采取公平干预措施。"}}
{"id": "2601.17905", "pdf": "https://arxiv.org/pdf/2601.17905", "abs": "https://arxiv.org/abs/2601.17905", "authors": ["Jack Foster", "Kirill Paramonov", "Mete Ozay", "Umberto Michieli"], "title": "Feature-Space Generative Models for One-Shot Class-Incremental Learning", "categories": ["cs.CV", "cs.AI", "stat.ML"], "comment": null, "summary": "Few-shot class-incremental learning (FSCIL) is a paradigm where a model, initially trained on a dataset of base classes, must adapt to an expanding problem space by recognizing novel classes with limited data. We focus on the challenging FSCIL setup where a model receives only a single sample (1-shot) for each novel class and no further training or model alterations are allowed after the base training phase. This makes generalization to novel classes particularly difficult. We propose a novel approach predicated on the hypothesis that base and novel class embeddings have structural similarity. We map the original embedding space into a residual space by subtracting the class prototype (i.e., the average class embedding) of input samples. Then, we leverage generative modeling with VAE or diffusion models to learn the multi-modal distribution of residuals over the base classes, and we use this as a valuable structural prior to improve recognition of novel classes. Our approach, Gen1S, consistently improves novel class recognition over the state of the art across multiple benchmarks and backbone architectures.", "AI": {"tldr": "本文提出了Gen1S方法，用于解决仅凭单个样本识别新类的挑战性问题。", "motivation": "在Few-shot class-incremental learning（FSCIL）中，模型需要适应不断扩大的问题空间，并且能够使用有限的数据识别新的类别，特别是当每种新类别只有一个样本时，这非常具有挑战性。", "method": "通过假设基类和新类的嵌入之间存在结构性相似性，将原始嵌入空间映射到残差空间，并利用VAE或扩散模型学习这些残差的多模态分布，作为识别新类别的结构先验。", "result": "Gen1S方法在多个基准测试和骨干架构上始终优于现有的技术水平，提高了对新类别识别的效果。", "conclusion": "本文提出的方法通过映射到残差空间并使用生成模型学习这些残差的分布，有效提升了单样本类增量学习中新型别识别的性能。"}}
{"id": "2601.17902", "pdf": "https://arxiv.org/pdf/2601.17902", "abs": "https://arxiv.org/abs/2601.17902", "authors": ["Wenjie Tian", "Bingshen Mu", "Guobin Ma", "Xuelong Geng", "Zhixian Zhao", "Lei Xie"], "title": "dLLM-ASR: A Faster Diffusion LLM-based Framework for Speech Recognition", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Automatic speech recognition (ASR) systems based on large language models (LLMs) achieve superior performance by leveraging pretrained LLMs as decoders, but their token-by-token generation mechanism leads to inference latency that grows linearly with sequence length. Meanwhile, discrete diffusion large language models (dLLMs) offer a promising alternative, enabling high-quality parallel sequence generation with pretrained decoders. However, directly applying native text-oriented dLLMs to ASR leads to a fundamental mismatch between open-ended text generation and the acoustically conditioned transcription paradigm required by ASR. As a result, it introduces unnecessary difficulty and computational redundancy, such as denoising from pure noise, inflexible generation lengths, and fixed denoising steps. We propose dLLM-ASR, an efficient dLLM-based ASR framework that formulates dLLM's decoding as a prior-guided and adaptive denoising process. It leverages an ASR prior to initialize the denoising process and provide an anchor for sequence length. Building upon this prior, length-adaptive pruning dynamically removes redundant tokens, while confidence-based denoising allows converged tokens to exit the denoising loop early, enabling token-level adaptive computation. Experiments demonstrate that dLLM-ASR achieves recognition accuracy comparable to autoregressive LLM-based ASR systems and delivers a 4.44$\\times$ inference speedup, establishing a practical and efficient paradigm for ASR.", "AI": {"tldr": "提出dLLM-ASR框架，通过先验引导和自适应降噪过程来实现高效的并行语音识别。", "motivation": "解决基于大语言模型的自动语音识别系统中的推理延迟问题，并克服直接应用离散扩散语言模型到ASR时出现的基本不匹配问题。", "method": "dLLM-ASR框架采用先验引导初始化降噪过程，并通过长度自适应剪枝和置信度基降噪实现自适应计算。", "result": "实验表明，dLLM-ASR在保证识别精度的同时，实现了4.44倍的推理加速。", "conclusion": "dLLM-ASR框架提供了一种实用高效的ASR方法，解决了现有基于大语言模型系统的延迟问题，并提高了计算效率。"}}
{"id": "2601.17901", "pdf": "https://arxiv.org/pdf/2601.17901", "abs": "https://arxiv.org/abs/2601.17901", "authors": ["Yuanchao Li"], "title": "Speech Emotion Recognition with ASR Integration", "categories": ["eess.AS", "cs.SD"], "comment": "PhD Thesis", "summary": "Speech Emotion Recognition (SER) plays a pivotal role in understanding human communication, enabling emotionally intelligent systems, and serving as a fundamental component in the development of Artificial General Intelligence (AGI). However, deploying SER in real-world, spontaneous, and low-resource scenarios remains a significant challenge due to the complexity of emotional expression and the limitations of current speech and language technologies. This thesis investigates the integration of Automatic Speech Recognition (ASR) into SER, with the goal of enhancing the robustness, scalability, and practical applicability of emotion recognition from spoken language.", "AI": {"tldr": "论文探讨了将自动语音识别（ASR）集成到语音情感识别（SER）中，以提高其在真实世界场景中的鲁棒性、可扩展性和实用性。", "motivation": "论文动机在于解决当前语音和语言技术在复杂情感表达下的局限性，特别是在资源匮乏的现实环境中部署SER时遇到的重大挑战。", "method": "方法涉及将自动语音识别（ASR）与语音情感识别（SER）集成，以提升系统处理自发性和低资源场景下情感识别的能力。", "result": "结果部分展示了这种方法如何增强了情感识别系统的鲁棒性、可扩展性和现实应用价值。", "conclusion": "结论指出，通过整合自动语音识别技术，可以有效提升语音情感识别在实际应用中的表现和可靠性。"}}
{"id": "2601.17900", "pdf": "https://arxiv.org/pdf/2601.17900", "abs": "https://arxiv.org/abs/2601.17900", "authors": ["Shengjun Zhang", "Min Chen", "Yibo Wei", "Mingyu Dong", "Yueqi Duan"], "title": "Revisiting 3D Reconstruction Kernels as Low-Pass Filters", "categories": ["cs.CV"], "comment": "14 pages, 5 figures", "summary": "3D reconstruction is to recover 3D signals from the sampled discrete 2D pixels, with the goal to converge continuous 3D spaces. In this paper, we revisit 3D reconstruction from the perspective of signal processing, identifying the periodic spectral extension induced by discrete sampling as the fundamental challenge. Previous 3D reconstruction kernels, such as Gaussians, Exponential functions, and Student's t distributions, serve as the low pass filters to isolate the baseband spectrum. However, their unideal low-pass property results in the overlap of high-frequency components with low-frequency components in the discrete-time signal's spectrum. To this end, we introduce Jinc kernel with an instantaneous drop to zero magnitude exactly at the cutoff frequency, which is corresponding to the ideal low pass filters. As Jinc kernel suffers from low decay speed in the spatial domain, we further propose modulated kernels to strick an effective balance, and achieves superior rendering performance by reconciling spatial efficiency and frequency-domain fidelity. Experimental results have demonstrated the effectiveness of our Jinc and modulated kernels.", "AI": {"tldr": "本文重新审视了3D重建内核作为低通滤波器的作用，提出了一种新的Jinc内核及其调制变体，以改善频域和空间效率之间的平衡。", "motivation": "传统3D重建内核的非理想低通属性导致离散信号频谱中高频分量与低频分量重叠，影响了重建效果。因此，作者动机在于寻找更有效的内核来解决这一问题。", "method": "本文提出使用Jinc内核及其调制变体作为理想的低通滤波器，解决了传统内核在频域和空间效率上的不足，通过实验验证其有效性。", "result": "实验结果显示，新的Jinc内核和调制内核显著提高了重建效果，在保持高频率成分的同时改善了空间效率。", "conclusion": "研究得出结论，使用改进的Jinc内核及其调制变体可以有效提升3D重建性能，并且在频域与空间效率之间取得了良好的平衡。"}}
{"id": "2601.17899", "pdf": "https://arxiv.org/pdf/2601.17899", "abs": "https://arxiv.org/abs/2601.17899", "authors": ["Junhao Qiu", "Xin Chen", "Liang Ge", "Liyong Lin", "Zhichao Lu", "Qingfu Zhang"], "title": "Evolving Interdependent Operators with Large Language Models for Multi-Objective Combinatorial Optimization", "categories": ["cs.NE"], "comment": null, "summary": "Neighborhood search operators are critical to the performance of Multi-Objective Evolutionary Algorithms (MOEAs) and rely heavily on expert design. Although recent LLM-based Automated Heuristic Design (AHD) methods have made notable progress, they primarily optimize individual heuristics or components independently, lacking explicit exploration and exploitation of dynamic coupling relationships between multiple operators. In this paper, multi-operator optimization in MOEAs is formulated as a Markov decision process, enabling the improvement of interdependent operators through sequential decision-making. To address this, we propose the Evolution of Operator Combination (E2OC) framework for MOEAs, which achieves the co-evolution of design strategies and executable codes. E2OC employs Monte Carlo Tree Search to progressively search combinations of operator design strategies and adopts an operator rotation mechanism to identify effective operator configurations while supporting the integration of mainstream AHD methods as the underlying designer. Experimental results across AHD tasks with varying objectives and problem scales show that E2OC consistently outperforms state-of-the-art AHD and other multi-heuristic co-design frameworks, demonstrating strong generalization and sustained optimization capability.", "AI": {"tldr": "提出E2OC框架，通过协同演化设计策略和可执行代码，以改进多目标组合优化问题中的互相关算子。", "motivation": "尽管基于LLM的自动化启发式设计方法取得了显著进展，但它们主要独立地优化单个启发式或组件，缺乏对多个操作者之间动态耦合关系的显式探索和利用。", "method": "将多操作符优化在MOEAs中表述为马尔可夫决策过程，并使用蒙特卡洛树搜索逐步查找操作符设计策略的组合，引入操作符轮换机制以识别有效的操作符配置。", "result": "实验结果显示，E2OC框架在不同目标和问题规模的任务上始终超越了最先进的AHD和其他多启发式共设计框架，表现出强大的泛化能力和持续优化能力。", "conclusion": "证明了提出的E2OC框架能够有效提升基于LLM的自动化启发式设计方法性能，特别是在处理互相关操作符的问题时。"}}
{"id": "2601.17897", "pdf": "https://arxiv.org/pdf/2601.17897", "abs": "https://arxiv.org/abs/2601.17897", "authors": ["Jiayu Liu", "Yinhe Long", "Zhenya Huang", "Enhong Chen"], "title": "UniCog: Uncovering Cognitive Abilities of LLMs through Latent Mind Space Analysis", "categories": ["cs.AI"], "comment": null, "summary": "A growing body of research suggests that the cognitive processes of large language models (LLMs) differ fundamentally from those of humans. However, existing interpretability methods remain limited in explaining how cognitive abilities are engaged during LLM reasoning. In this paper, we propose UniCog, a unified framework that analyzes LLM cognition via a latent mind space. Formulated as a latent variable model, UniCog encodes diverse abilities from dense model activations into sparse, disentangled latent dimensions. Through extensive analysis on six advanced LLMs, including DeepSeek-V3.2 and GPT-4o, we reveal a Pareto principle of LLM cognition, where a shared reasoning core is complemented by ability-specific signatures. Furthermore, we discover that reasoning failures often manifest as anomalous intensity in latent activations. These findings opens a new paradigm in LLM analysis, providing a cognition grounded view of reasoning dynamics. Finally, leveraging these insights, we introduce a latent-informed candidate prioritization strategy, which improves reasoning performance by up to 7.5% across challenging benchmarks. Our code is available at https://github.com/milksalute/unicog.", "AI": {"tldr": "该论文提出了UniCog框架，通过潜在心智空间分析大型语言模型的认知能力。", "motivation": "研究动机在于现有方法难以解释LLMs在推理过程中如何运用认知能力，旨在深入理解LLMs的内部运作机制。", "method": "UniCog以潜变量模型为基础，将多种能力从密集模型激活中编码为稀疏、分离的潜在维度进行分析。", "result": "通过分析六个高级语言模型，揭示了LLM推理中的帕累托原则和异常推理失败模式，并提出了改进推理性能的方法。", "conclusion": "UniCog框架提供了一种新的研究视角，能够更好地理解和优化大型语言模型的认知过程。"}}
{"id": "2601.17895", "pdf": "https://arxiv.org/pdf/2601.17895", "abs": "https://arxiv.org/abs/2601.17895", "authors": ["Bin Tan", "Changjiang Sun", "Xiage Qin", "Hanat Adai", "Zelin Fu", "Tianxiang Zhou", "Han Zhang", "Yinghao Xu", "Xing Zhu", "Yujun Shen", "Nan Xue"], "title": "Masked Depth Modeling for Spatial Perception", "categories": ["cs.CV", "cs.RO"], "comment": "Tech report, 19 pages, 15 figures and 4 tables", "summary": "Spatial visual perception is a fundamental requirement in physical-world applications like autonomous driving and robotic manipulation, driven by the need to interact with 3D environments. Capturing pixel-aligned metric depth using RGB-D cameras would be the most viable way, yet it usually faces obstacles posed by hardware limitations and challenging imaging conditions, especially in the presence of specular or texture-less surfaces. In this work, we argue that the inaccuracies from depth sensors can be viewed as \"masked\" signals that inherently reflect underlying geometric ambiguities. Building on this motivation, we present LingBot-Depth, a depth completion model which leverages visual context to refine depth maps through masked depth modeling and incorporates an automated data curation pipeline for scalable training. It is encouraging to see that our model outperforms top-tier RGB-D cameras in terms of both depth precision and pixel coverage. Experimental results on a range of downstream tasks further suggest that LingBot-Depth offers an aligned latent representation across RGB and depth modalities. We release the code, checkpoint, and 3M RGB-depth pairs (including 2M real data and 1M simulated data) to the community of spatial perception.", "AI": {"tldr": "本论文提出了LingBot-Depth模型，该模型通过利用视觉上下文来改进深度图，并且包含了一个自动的数据整理管道用于可扩展训练。", "motivation": "在物理世界应用如自动驾驶和机器人操作中，精确的三维空间感知至关重要，但RGB-D相机受限于硬件和成像条件，难以提供准确的深度信息。因此，研究动机是解决这些限制，提高深度图的质量。", "method": "通过建立被遮罩的深度信号模型来处理传感器不准确性，并使用视觉上下文来改进深度映射，同时引入一个自动的数据整理管道用于训练。", "result": "实验表明该模型在深度精度和像素覆盖率方面超过了顶级RGB-D相机。此外，在多个下游任务中的结果证明了它能够提供跨RGB和深度模态的对齐潜在表示。", "conclusion": "LingBot-Depth模型通过改进深度图处理提供了更高质量的空间感知能力，并且其公开的数据集有助于促进空间感知研究社区的发展。"}}
{"id": "2601.17893", "pdf": "https://arxiv.org/pdf/2601.17893", "abs": "https://arxiv.org/abs/2601.17893", "authors": ["Sarmistha Sarna Gomasta", "Mahmood Jasim", "Hossein Hadisi", "Yvonne Jansen", "Pierre Dragicevic", "Narges Mahyar", "Ali Sarvghad"], "title": "Investigating How Music Affects Persuasion, Engagement, and Emotion in Data Videos", "categories": ["cs.HC"], "comment": null, "summary": "Data videos have become a prominent vessel for communicating data to broad audiences, and a common object of study in information visualization. Many of these videos include music, yet the impact of music on how people experience data videos remains largely unexplored. We conducted a preregistered study into the effect of music across three dimensions: persuasion, engagement, and emotion. We showed online participants an existing data video (1) without any music, (2) with its generic default music, and (3) with custom music designed by a professional composer. We found that the default music helped make the data video more persuasive. However, the effects of custom music were more mixed, and we did not find that music increased engagement. In addition, and contrary to our expectations, our participants reported more intense emotions without music. Our study contributes new insights into the intersection of music and data visualization and is a first step toward guiding designers in creating impactful data-driven narratives.", "AI": {"tldr": "研究音乐在数据视频中对说服力、参与度和情感的影响。", "motivation": "尽管许多数据视频包含音乐，但关于音乐如何影响观众体验的数据仍不充分，因此本研究旨在探讨音乐对于数据视频的三个维度（说服力、参与度、情感）的影响。", "method": "在线参与者被展示了一个现有的数据视频，并以三种方式呈现：无任何音乐、带有默认通用音乐和专业作曲家设计的定制音乐，从而研究这些不同类型的音乐对观众体验的影响。", "result": "研究发现，默认通用音乐有助于提升数据视频的说服力，而定制音乐的效果则更加复杂且不一致；同时，与预期相反的是，在没有背景音乐的情况下参与者报告了更为强烈的情感反应。", "conclusion": "本研究为理解和指导音乐在数据可视化中的应用提供了新的见解，并为进一步探索如何创造具有影响力的基于数据的故事提供了第一步的指南。"}}
{"id": "2601.17892", "pdf": "https://arxiv.org/pdf/2601.17892", "abs": "https://arxiv.org/abs/2601.17892", "authors": ["Sahibpreet Singh", "Manjit Singh"], "title": "Artificial Intelligence and Intellectual Property Rights: Comparative Transnational Policy Analysis", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "comment": "Published in Journal of University Institute of Legal Studies, Vol. 19, Issue 1, pp. 182-208, 2025", "summary": "Artificial intelligence's rapid integration with intellectual property rights necessitates assessment of its impact on trade secrets, copyrights and patents. This study addresses lacunae in existing laws where India lacks AI-specific provisions, creating doctrinal inconsistencies and enforcement inefficacies. Global discourse on AI-IPR protections remains nascent. The research identifies gaps in Indian IP laws' adaptability to AI-generated outputs: trade secret protection is inadequate against AI threats; standardized inventorship criteria are absent. Employing doctrinal and comparative methodology, it scrutinizes legislative texts, judicial precedents and policy instruments across India, US, UK and EU. Preliminary findings reveal shortcomings: India's contract law creates fragmented trade secret regime; Section 3(k) of Indian Patents Act blocks AI invention patenting; copyright varies in authorship attribution. The study proposes harmonized legal taxonomy accommodating AI's role while preserving innovation incentives. India's National AI Strategy (2024) shows progress but legislative clarity is imperative. This contributes to global discourse with AI-specific IP protections ensuring resilience and equitable innovation. Promising results underscore recalibrating India's IP jurisprudence for global alignment.", "AI": {"tldr": "论文分析了人工智能对知识产权（包括商业秘密、版权和专利）的影响，特别关注印度法律中缺乏针对AI的具体规定的漏洞，并提出改进措施。", "motivation": "随着人工智能快速融入知识产权领域，现有的法律法规出现了空白区域。研究动机是评估这些影响并识别各国在适应AI产生的输出方面存在的不足，特别是在印度。", "method": "论文采用教义学和比较法的方法，审查了包括印度、美国、英国和欧盟在内的国家的立法文本、司法先例及政策工具。", "result": "初步研究发现：印度合同法导致贸易秘密保护制度碎片化；印度专利法案第3(k)节阻碍AI发明专利申请；版权在作者归属上存在差异。提出了一个协调化的法律分类方案，以适应人工智能的角色并保持创新激励。", "conclusion": "该论文为全球讨论提供了贡献，并强调需要调整印度的知识产权法理学以实现与国际接轨。"}}
{"id": "2601.17890", "pdf": "https://arxiv.org/pdf/2601.17890", "abs": "https://arxiv.org/abs/2601.17890", "authors": ["Ailin Liu", "Francesco Chiossi", "Felix Henninger", "Lisa Bondo Andersen", "Tobias Wistuba", "Sonja Greven", "Frauke Kreuter", "Fiona Draxler"], "title": "Physiological and Behavioral Modeling of Stress and Cognitive Load in Web-Based Question Answering", "categories": ["cs.HC"], "comment": null, "summary": "Time pressure and question difficulty can trigger stress and cognitive overload in web-based surveys, compromising data quality and user experience. Most stress detection methods are based on low-resolution self-reports, which are poorly suited for capturing fast, moment-to-moment changes during short online tasks. Addressing this gap, we conducted a 2x2 within-subjects study (N = 29), manipulating question difficulty and time pressure in a web-based multiple-choice task. Participants completed general knowledge and cognitive questions while we collected multimodal data: mouse dynamics, eye tracking, electrocardiogram, and electrodermal activity. Using condition-based and self-reported labels, we used statistical and machine learning models to model stress and question difficulty. Our results show distinct physiological and behavioral patterns within very short timeframes. This work demonstrates the feasibility of rapidly detecting cognitive-affective states in digital environments, paving the way for more adaptive, ethical, and user-aware survey interfaces.", "AI": {"tldr": "研究通过多模态数据检测网络问卷中的压力和认知负荷，提出了一种基于生理和行为模型的方法。", "motivation": "传统的自我报告方法无法捕捉到短时间内的情绪变化，因此需要一种更有效的手段来监测在线任务中的压力和认知负担，以改善用户体验。", "method": "进行了一个2x2的被试内设计实验（N = 29），操纵问题难度和时间压力，在线多项选择题任务中收集了鼠标动态、眼动追踪、心电图和皮肤电活动的数据，使用条件标签和自我报告标签进行统计及机器学习建模。", "result": "研究发现了短时间内生理和行为上的不同模式，证明在数字环境中快速检测认知-情感状态是可行的。", "conclusion": "该工作为创建更适应、伦理且以用户为中心的在线调查界面提供了可能。"}}
{"id": "2601.17887", "pdf": "https://arxiv.org/pdf/2601.17887", "abs": "https://arxiv.org/abs/2601.17887", "authors": ["Jiahe Guo", "Xiangran Guo", "Yulin Hu", "Zimo Long", "Xingyu Sui", "Xuda Zhi", "Yongbo Huang", "Hao He", "Weixiang Zhao", "Yanyan Zhao", "Bing Qin"], "title": "When Personalization Legitimizes Risks: Uncovering Safety Vulnerabilities in Personalized Dialogue Agents", "categories": ["cs.AI"], "comment": null, "summary": "Long-term memory enables large language model (LLM) agents to support personalized and sustained interactions. However, most work on personalized agents prioritizes utility and user experience, treating memory as a neutral component and largely overlooking its safety implications. In this paper, we reveal intent legitimation, a previously underexplored safety failure in personalized agents, where benign personal memories bias intent inference and cause models to legitimize inherently harmful queries. To study this phenomenon, we introduce PS-Bench, a benchmark designed to identify and quantify intent legitimation in personalized interactions. Across multiple memory-augmented agent frameworks and base LLMs, personalization increases attack success rates by 15.8%-243.7% relative to stateless baselines. We further provide mechanistic evidence for intent legitimation from internal representations space, and propose a lightweight detection-reflection method that effectively reduces safety degradation. Overall, our work provides the first systematic exploration and evaluation of intent legitimation as a safety failure mode that naturally arises from benign, real-world personalization, highlighting the importance of assessing safety under long-term personal context. WARNING: This paper may contain harmful content.", "AI": {"tldr": "揭示个性化对话代理中的意图合法化问题，并提出一种轻量级的检测和反映方法以减少安全风险。", "motivation": "大多数关于个性化代理的研究优先考虑实用性和用户体验，忽视了记忆组件的安全影响。该研究旨在探索个人记忆如何导致模型对有害查询的合法化。", "method": "引入PS-Bench基准测试工具来识别并量化个性化交互中的意图合法化现象，并分析内部表示空间以提供机制证据，提出一种轻量级检测和反映方法。", "result": "研究表明，在多种记忆增强代理框架和基础语言模型中，个人化使得攻击成功率相较于无状态基线增加了15.8%到243.7%。", "conclusion": "个性化对话代理中的意图合法化是一个重要的安全风险问题，需要在长期个人化的背景下评估其安全性。"}}
{"id": "2601.17885", "pdf": "https://arxiv.org/pdf/2601.17885", "abs": "https://arxiv.org/abs/2601.17885", "authors": ["Qingyu Fan", "Zhaoxiang Li", "Yi Lu", "Wang Chen", "Qiu Shen", "Xiao-xiao Long", "Yinghao Cai", "Tao Lu", "Shuo Wang", "Xun Cao"], "title": "PEAfowl: Perception-Enhanced Multi-View Vision-Language-Action for Bimanual Manipulation", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Bimanual manipulation in cluttered scenes requires policies that remain stable under occlusions, viewpoint and scene variations. Existing vision-language-action models often fail to generalize because (i) multi-view features are fused via view-agnostic token concatenation, yielding weak 3D-consistent spatial understanding, and (ii) language is injected as global conditioning, resulting in coarse instruction grounding. In this paper, we introduce PEAfowl, a perception-enhanced multi-view VLA policy for bimanual manipulation. For spatial reasoning, PEAfowl predicts per-token depth distributions, performs differentiable 3D lifting, and aggregates local cross-view neighbors to form geometrically grounded, cross-view consistent representations. For instruction grounding, we propose to replace global conditioning with a Perceiver-style text-aware readout over frozen CLIP visual features, enabling iterative evidence accumulation. To overcome noisy and incomplete commodity depth without adding inference overhead, we apply training-only depth distillation from a pretrained depth teacher to supervise the depth-distribution head, providing perception front-end with geometry-aware priors. On RoboTwin 2.0 under domain-randomized setting, PEAfowl improves the strongest baseline by 23.0 pp in success rate, and real-robot experiments further demonstrate reliable sim-to-real transfer and consistent improvements from depth distillation. Project website: https://peafowlvla.github.io/.", "AI": {"tldr": "本文提出了PEAfowl，一种用于双臂操作的感知增强多视角视觉语言动作策略。", "motivation": "现有模型在处理复杂场景下的双臂操作时存在不足，主要在于多视角特征融合和语言指导方式的问题，导致无法实现良好的泛化能力。", "method": "PEAfowl通过预测每标记的深度分布、执行可微分3D提升以及聚合局部跨视图邻居形成几何基础和跨视图一致表示来加强空间推理。对于指令定位，采用Perceiver风格的文本感知读取以取代全局条件设置，并且应用训练中的深度蒸馏技术。", "result": "在RoboTwin 2.0领域随机设定下，PEAfowl的成功率比最强基线提升了23.0个百分点，在现实机器人实验中也展示了可靠的模拟到现实的转移和持续改进效果。", "conclusion": "PEAfowl通过增强感知能力和深度蒸馏技术显著提高了双臂操作在复杂场景中的性能。"}}
{"id": "2601.17883", "pdf": "https://arxiv.org/pdf/2601.17883", "abs": "https://arxiv.org/abs/2601.17883", "authors": ["Dingkun Liu", "Yuheng Chen", "Zhu Chen", "Zhenyao Cui", "Yaozhi Wen", "Jiayu An", "Jingwei Luo", "Dongrui Wu"], "title": "EEG Foundation Models: Progresses, Benchmarking, and Open Problems", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Electroencephalography (EEG) foundation models have recently emerged as a promising paradigm for brain-computer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper fills this gap. We first review 50 representative models and organize their design choices into a unified taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under a leave-one-subject-out protocol and rapid calibration under a within-subject few-shot setting. We further compare full-parameter fine-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufficient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices.", "AI": {"tldr": "本文介绍了50个代表性的EEG基础模型，并评估了其中的12个开源模型，以比较它们在BCI任务中的表现。", "motivation": "由于预训练目标、数据预处理和下游评估协议不一致，现有的EEG基础模型缺乏公平和全面的对比，本文旨在填补这一空白。", "method": "作者首先回顾了50个代表性的模型，并将设计选择组织成一个统一的分类框架，包括数据标准化、模型架构和自监督预训练策略。然后在13个涵盖九种BCI范式的EEG数据集上评估12个开源基础模型和竞争性专有基线模型。", "result": "研究结果表明：1) 线性探测经常不足；2) 从头开始训练的专用模型在许多任务中仍具有竞争力；3) 在当前的数据制度和训练实践中，更大的基础模型并不一定带来更好的泛化性能。", "conclusion": "本文强调了线性探测可能不足以评估EEG基础模型的迁移能力，并指出更大规模的基础模型不一定能提高泛化性能。"}}
{"id": "2601.17880", "pdf": "https://arxiv.org/pdf/2601.17880", "abs": "https://arxiv.org/abs/2601.17880", "authors": ["Muhammad Umar Salman", "Mohammad Areeb Qazi", "Mohammed Talha Alam"], "title": "Quran-MD: A Fine-Grained Multilingual Multimodal Dataset of the Quran", "categories": ["cs.CV"], "comment": "6 pages, 2 tables and 2 figures", "summary": "We present Quran MD, a comprehensive multimodal dataset of the Quran that integrates textual, linguistic, and audio dimensions at the verse and word levels. For each verse (ayah), the dataset provides its original Arabic text, English translation, and phonetic transliteration. To capture the rich oral tradition of Quranic recitation, we include verse-level audio from 32 distinct reciters, reflecting diverse recitation styles and dialectical nuances. At the word level, each token is paired with its corresponding Arabic script, English translation, transliteration, and an aligned audio recording, allowing fine-grained analysis of pronunciation, phonology, and semantic context. This dataset supports various applications, including natural language processing, speech recognition, text-to-speech synthesis, linguistic analysis, and digital Islamic studies. Bridging text and audio modalities across multiple reciters, this dataset provides a unique resource to advance computational approaches to Quranic recitation and study. Beyond enabling tasks such as ASR, tajweed detection, and Quranic TTS, it lays the foundation for multimodal embeddings, semantic retrieval, style transfer, and personalized tutoring systems that can support both research and community applications. The dataset is available at https://huggingface.co/datasets/Buraaq/quran-audio-text-dataset", "AI": {"tldr": "介绍Quran-MD，一个包含《古兰经》文本、语言和音频维度的细粒度多语言多模态数据集。", "motivation": "推动计算方法在《古兰经》诵读和研究中的应用，并支持自然语言处理、语音识别等任务。", "method": "构建了一个综合数据集，包含《古兰经》每个章节的阿拉伯文原文、英文翻译和音标转写，以及来自32位不同朗诵者的音频记录。", "result": "提供了一种独特的资源，支持多种应用，包括自然语言处理、语音识别、文本到语音合成等。", "conclusion": "Quran-MD数据集为计算方法在《古兰经》研究中的应用提供了坚实的基础，并将促进相关领域的进一步发展。"}}
{"id": "2601.17879", "pdf": "https://arxiv.org/pdf/2601.17879", "abs": "https://arxiv.org/abs/2601.17879", "authors": ["Yilong Xu", "Zhi Zheng", "Xiang Long", "Yujun Cai", "Yiwei Wang"], "title": "Self-Manager: Parallel Agent Loop for Long-form Deep Research", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Long-form deep research requires multi-faceted investigations over extended horizons to get a comprehensive report. When handling such complex tasks, existing agents manage context at the subtask level to overcome linear context accumulation and information loss. However, they still adhere to a single context window and sequential execution paradigm, which results in mutual interference and blocking behavior, restricting scalability and adaptability. To address this issue, this paper introduces Self-Manager, a parallel agent loop that enables asynchronous and concurrent execution. The main thread can create multiple subthreads, each with its own isolated context, and manage them iteratively through Thread Control Blocks, allowing for more focused and flexible parallel agent execution. To assess its effectiveness, we benchmark Self-Manager on DeepResearch Bench, where it consistently outperforms existing single-agent loop baselines across all metrics. Furthermore, we conduct extensive analytical experiments to demonstrate the necessity of Self-Manager's design choices, as well as its advantages in contextual capacity, efficiency, and generalization.", "AI": {"tldr": "本文介绍了Self-Manager，一种用于长篇深度研究的并行代理循环系统。", "motivation": "现有的代理在处理复杂任务时仍然存在线性上下文累积和信息丢失的问题，并且它们遵循单一上下文窗口和顺序执行模式，导致可扩展性和适应性的限制。", "method": "Self-Manager通过创建多个具有独立上下文的子线程并使用线程控制块迭代管理这些线程来实现异步并发执行。", "result": "在DeepResearch Bench基准测试中，Self-Manager在所有指标上均优于现有的单代理循环基线，并且通过广泛的分析实验展示了其设计选择的必要性和优势。", "conclusion": "研究结果表明，Self-Manager的设计在上下文容量、效率和泛化方面具有显著的优势。"}}
{"id": "2601.17877", "pdf": "https://arxiv.org/pdf/2601.17877", "abs": "https://arxiv.org/abs/2601.17877", "authors": ["Sahibpreet Singh"], "title": "Comparative Algorithmic Governance of Public Health Instruments across India, EU, US and LMICs", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "Chapter in \"Law and Medicine\" (Pacific Books International, 2025), pp. 409-423", "summary": "The study investigates the juridico-technological architecture of international public health instruments, focusing on their implementation across India, the European Union, the United States and low- and middle-income countries (LMICs), particularly in Sub-Saharan Africa. It addresses a research lacuna: the insufficient harmonisation between normative health law and algorithmic public health infrastructures in resource-constrained jurisdictions. The principal objective is to assess how artificial intelligence augments implementation of instruments grounded in IHR 2005 and the WHO FCTC while identifying doctrinal and infrastructural bottlenecks. Using comparative doctrinal analysis and legal-normative mapping, the study triangulates legislative instruments, WHO monitoring frameworks, AI systems including BlueDot, Aarogya Setu and EIOS, and compliance metrics. Preliminary results show that AI has improved early detection, surveillance precision and responsiveness in high-capacity jurisdictions, whereas LMICs face infrastructural deficits, data privacy gaps and fragmented legal scaffolding. The findings highlight the relevance of the EU Artificial Intelligence Act and GDPR as regulatory prototypes for health-oriented algorithmic governance and contrast them with embryonic AI integration and limited internet penetration in many LMICs. The study argues for embedding AI within a rights-compliant, supranationally coordinated regulatory framework to secure equitable health outcomes and stronger compliance. It proposes a model for algorithmic treaty-making inspired by FCTC architecture and calls for WHO-led compliance mechanisms modelled on the WTO Dispute Settlement Body to enhance pandemic preparedness, surveillance equity and transnational governance resilience.", "AI": {"tldr": "研究调查了国际公共卫生工具的法律和技术架构，特别是在印度、欧盟、美国和低中收入国家（LMICs）中的实施情况，并评估人工智能如何增强这些基于IHR2005和WHO FCTC的工具。", "motivation": "该论文旨在解决规范健康法与算法公共健康基础设施之间的协调不足问题，尤其是在资源受限的司法管辖区。", "method": "通过比较教义分析和法律规范映射的方法，研究将立法工具、世卫组织监测框架、AI系统如BlueDot、Aarogya Setu和EIOS以及合规度量标准进行了三角化处理。", "result": "初步结果显示，在高容量司法管辖区中，人工智能改善了早期检测、监控精度和反应能力；而在低中收入国家，则面临基础设施不足、数据隐私问题和法律框架碎片化的挑战。", "conclusion": "研究建议将AI嵌入权利符合性且超国界协调的监管框架内，以实现公平的健康结果和更强的合规性，并提出一个受FCTC架构启发的算法条约制定模型。"}}
{"id": "2601.17868", "pdf": "https://arxiv.org/pdf/2601.17868", "abs": "https://arxiv.org/abs/2601.17868", "authors": ["Zhihao He", "Tieyuan Chen", "Kangyu Wang", "Ziran Qin", "Yang Shao", "Chaofan Gan", "Shijie Li", "Zuxuan Wu", "Weiyao Lin"], "title": "VidLaDA: Bidirectional Diffusion Large Language Models for Efficient Video Understanding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Standard Autoregressive Video LLMs inevitably suffer from causal masking biases that hinder global spatiotemporal modeling, leading to suboptimal understanding efficiency. We propose VidLaDA, a Video LLM based on Diffusion Language Model utilizing bidirectional attention to capture bidirectional dependencies. To further tackle the inference bottleneck of diffusion decoding on massive video tokens, we introduce MARS-Cache. This framework accelerates inference by combining asynchronous visual cache refreshing with frame-wise chunk attention, effectively pruning redundancy while preserving global connectivity via anchor tokens. Extensive experiments show VidLaDA outperforms diffusion baselines and rivals state-of-the-art autoregressive models (e.g., Qwen2.5-VL and LLaVA-Video), with MARS-Cache delivering over 12x speedup without compromising reasoning accuracy. Code and checkpoints are open-sourced at https://github.com/ziHoHe/VidLaDA.", "AI": {"tldr": "本文介绍了VidLaDA，一种基于扩散语言模型并利用双向注意力机制的视频大型语言模型，以提高视频理解效率。", "motivation": "标准的自回归视频LLM由于因果遮蔽偏差导致全局时空建模受限，从而影响了理解效率。为此提出了一种新的方法来改进这一问题。", "method": "VidLaDA采用双向注意力机制捕捉视频中的双向依赖关系，并引入MARS-Cache框架加速推理，通过异步视觉缓存刷新和帧级块注意有效修剪冗余信息同时保持全局连通性。", "result": "实验表明，VidLaDA在性能上超越了扩散模型基线，并且与最先进的自回归模型（如Qwen2.5-VL和LLaVA-Video）相当，MARS-Cache框架提供了超过12倍的速度提升而不影响推理准确性。", "conclusion": "该研究提出了一个有效的视频理解系统VidLaDA及其加速框架MARS-Cache，证明了其在效率和性能上的优越性。"}}
{"id": "2601.17866", "pdf": "https://arxiv.org/pdf/2601.17866", "abs": "https://arxiv.org/abs/2601.17866", "authors": ["Yoonwoo Jeong", "Cheng Sun", "Yu-Chiang Frank Wang", "Minsu Cho", "Jaesung Choe"], "title": "MV-SAM: Multi-view Promptable Segmentation using Pointmap Guidance", "categories": ["cs.CV"], "comment": "Project page, https://jaesung-choe.github.io/mv_sam/index.html", "summary": "Promptable segmentation has emerged as a powerful paradigm in computer vision, enabling users to guide models in parsing complex scenes with prompts such as clicks, boxes, or textual cues. Recent advances, exemplified by the Segment Anything Model (SAM), have extended this paradigm to videos and multi-view images. However, the lack of 3D awareness often leads to inconsistent results, necessitating costly per-scene optimization to enforce 3D consistency. In this work, we introduce MV-SAM, a framework for multi-view segmentation that achieves 3D consistency using pointmaps -- 3D points reconstructed from unposed images by recent visual geometry models. Leveraging the pixel-point one-to-one correspondence of pointmaps, MV-SAM lifts images and prompts into 3D space, eliminating the need for explicit 3D networks or annotated 3D data. Specifically, MV-SAM extends SAM by lifting image embeddings from its pretrained encoder into 3D point embeddings, which are decoded by a transformer using cross-attention with 3D prompt embeddings. This design aligns 2D interactions with 3D geometry, enabling the model to implicitly learn consistent masks across views through 3D positional embeddings. Trained on the SA-1B dataset, our method generalizes well across domains, outperforming SAM2-Video and achieving comparable performance with per-scene optimization baselines on NVOS, SPIn-NeRF, ScanNet++, uCo3D, and DL3DV benchmarks. Code will be released.", "AI": {"tldr": "介绍MV-SAM框架，通过点图指导实现多视角可提示分割，并确保三维一致性。", "motivation": "解决现有方法中缺乏三维感知导致的不一致问题，减少对昂贵的逐场景优化的需求。", "method": "使用点图将图像和提示提升到三维空间，利用转换器解码3D点嵌入并与3D提示嵌入交叉注意，以实现跨视图的一致性分割。", "result": "在多个基准测试中表现出色，超越了SAM2-Video，并与逐场景优化基线方法性能相当。", "conclusion": "MV-SAM通过创新的设计实现了多视角分割的3D一致性，并且无需显式的3D网络或标注数据。"}}
{"id": "2601.17862", "pdf": "https://arxiv.org/pdf/2601.17862", "abs": "https://arxiv.org/abs/2601.17862", "authors": ["Jingsong Xia", "Siqi Wang"], "title": "Domain Generalization with Quantum Enhancement for Medical Image Classification: A Lightweight Approach for Cross-Center Deployment", "categories": ["cs.CV"], "comment": null, "summary": "Medical image artificial intelligence models often achieve strong performance in single-center or single-device settings, yet their effectiveness frequently deteriorates in real-world cross-center deployment due to domain shift, limiting clinical generalizability. To address this challenge, we propose a lightweight domain generalization framework with quantum-enhanced collaborative learning, enabling robust generalization to unseen target domains without relying on real multi-center labeled data. Specifically, a MobileNetV2-based domain-invariant encoder is constructed and optimized through three key components: (1) multi-domain imaging shift simulation using brightness, contrast, sharpening, and noise perturbations to emulate heterogeneous acquisition conditions; (2) domain-adversarial training with gradient reversal to suppress domain-discriminative features; and (3) a lightweight quantum feature enhancement layer that applies parameterized quantum circuits for nonlinear feature mapping and entanglement modeling. In addition, a test-time adaptation strategy is employed during inference to further alleviate distribution shifts. Experiments on simulated multi-center medical imaging datasets demonstrate that the proposed method significantly outperforms baseline models without domain generalization or quantum enhancement on unseen domains, achieving reduced domain-specific performance variance and improved AUC and sensitivity. These results highlight the clinical potential of quantum-enhanced domain generalization under constrained computational resources and provide a feasible paradigm for hybrid quantum--classical medical imaging systems.", "AI": {"tldr": "本文提出了一种轻量级的量子增强领域泛化框架，用于改善医学影像分类在跨中心部署中的性能。", "motivation": "目前医学图像AI模型在单一中心或设备上的表现很好，但在跨中心实际应用中由于领域迁移导致效果下降。研究动机是通过引入量子计算来解决这一问题，提高模型的临床泛化能力。", "method": "提出的方法包括基于MobileNetV2构建领域不变编码器，并结合多领域影像位移模拟、领域对抗训练和轻量级量子特征增强层来优化模型，同时在推理时采用测试时间适应策略进一步减轻分布差异。", "result": "实验结果显示，所提方法相比没有领域泛化或量子增强的基线模型，在未见过的领域上表现更优，实现了更低的领域特定性能方差和更高的AUC及敏感度。", "conclusion": "研究结果强调了在计算资源受限的情况下，量子增强领域的泛化的临床潜力，并为混合量子-经典医学影像系统提供了一个可行的方法。"}}
{"id": "2601.17858", "pdf": "https://arxiv.org/pdf/2601.17858", "abs": "https://arxiv.org/abs/2601.17858", "authors": ["Jiapeng Wang", "Changxin Tian", "Kunlong Chen", "Ziqi Liu", "Jiaxin Mao", "Wayne Xin Zhao", "Zhiqiang Zhang", "Jun Zhou"], "title": "MergeMix: Optimizing Mid-Training Data Mixtures via Learnable Model Merging", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Optimizing data mixtures is essential for unlocking the full potential of large language models (LLMs), yet identifying the optimal composition remains computationally prohibitive due to reliance on heuristic trials or expensive proxy training. To address this, we introduce \\textbf{MergeMix}, a novel approach that efficiently determines optimal data mixing ratios by repurposing model merging weights as a high-fidelity, low-cost performance proxy. By training domain-specific experts on minimal tokens and optimizing their merging weights against downstream benchmarks, MergeMix effectively optimizes the performance of data mixtures without incurring the cost of full-scale training. Extensive experiments on models with 8B and 16B parameters validate that MergeMix achieves performance comparable to or surpassing exhaustive manual tuning while drastically reducing search costs. Furthermore, MergeMix exhibits high rank consistency (Spearman $ρ> 0.9$) and strong cross-scale transferability, offering a scalable, automated solution for data mixture optimization.", "AI": {"tldr": "介绍了一种名为MergeMix的新方法，通过将模型合并权重作为性能代理来优化数据混合比例。", "motivation": "解决大规模语言模型中确定最优数据混合组成的计算成本高的问题，减少依赖于启发式试验或昂贵的代理训练。", "method": "使用领域特定专家在少量标记上进行培训，并针对下游基准优化他们的合并权重以有效优化数据混合性能。", "result": "实验表明MergeMix可以在大幅降低搜索成本的同时达到甚至超过手动精细调优的性能，具有高一致性（Spearman $ρ>0.9$）和较强的跨规模转移能力。", "conclusion": "MergeMix为大规模语言模型的数据混合优化提供了可扩展、自动化的解决方案。"}}
{"id": "2601.17857", "pdf": "https://arxiv.org/pdf/2601.17857", "abs": "https://arxiv.org/abs/2601.17857", "authors": ["Lan Yang", "Minghan Yang", "Ke Li", "Honggang Zhang", "Kaiyue Pang", "Yi-Zhe Song"], "title": "SynMind: Reducing Semantic Hallucination in fMRI-Based Image Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in fMRI-based image reconstruction have achieved remarkable photo-realistic fidelity. Yet, a persistent limitation remains: while reconstructed images often appear naturalistic and holistically similar to the target stimuli, they frequently suffer from severe semantic misalignment -- salient objects are often replaced or hallucinated despite high visual quality. In this work, we address this limitation by rethinking the role of explicit semantic interpretation in fMRI decoding. We argue that existing methods rely too heavily on entangled visual embeddings which prioritize low-level appearance cues -- such as texture and global gist -- over explicit semantic identity. To overcome this, we parse fMRI signals into rich, sentence-level semantic descriptions that mirror the hierarchical and compositional nature of human visual understanding. We achieve this by leveraging grounded VLMs to generate synthetic, human-like, multi-granularity textual representations that capture object identities and spatial organization. Built upon this foundation, we propose SynMind, a framework that integrates these explicit semantic encodings with visual priors to condition a pretrained diffusion model. Extensive experiments demonstrate that SynMind outperforms state-of-the-art methods across most quantitative metrics. Notably, by offloading semantic reasoning to our text-alignment module, SynMind surpasses competing methods based on SDXL while using the much smaller Stable Diffusion 1.4 and a single consumer GPU. Large-scale human evaluations further confirm that SynMind produces reconstructions more consistent with human visual perception. Neurovisualization analyses reveal that SynMind engages broader and more semantically relevant brain regions, mitigating the over-reliance on high-level visual areas.", "AI": {"tldr": "本文提出了SynMind框架，通过将fMRI信号解析为丰富的语义描述，并结合视觉先验条件预训练的扩散模型，以减少基于fMRI的图像重建中的语义幻觉现象。", "motivation": "尽管最近基于fMRI的图像重建在照片级逼真度上取得了显著进展，但存在一个持续性的限制：重建的图像虽然看起来自然且整体上与目标刺激相似，但在语义上常出现严重错位。作者认为现有方法过于依赖纠缠的视觉嵌入，优先考虑低层次的外观线索而忽略了显式的语义身份。", "method": "本文提出通过将fMRI信号解析成句级的语义描述来克服这一限制，这些描述反映了人类视觉理解的分层和组合性质。利用接地语言-视觉模型生成合成的人类样多粒度文本表示，捕捉对象身份和空间组织，并与视觉先验结合，条件化预训练的扩散模型。", "result": "实验表明，SynMind在大多数定量指标上优于现有方法，在使用较小规模的Stable Diffusion 1.4和单个消费级GPU的情况下超越了基于SDXL的方法。大规模的人类评估进一步证实了SynMind产生的重建结果与人类视觉感知更加一致。", "conclusion": "通过将语义推理卸载到文本对齐模块，SynMind不仅在技术指标上表现出色，在神经可视化分析中也显示出更广泛的和更具语义相关的脑区活动，从而减轻了对高层次视觉区域的过度依赖。"}}
{"id": "2601.17846", "pdf": "https://arxiv.org/pdf/2601.17846", "abs": "https://arxiv.org/abs/2601.17846", "authors": ["Peinuan Qin", "Chi-Lan Yang", "Nattapat Boonprakong", "Jingzhu Chen", "Yugin Tan", "Yi-Chieh Lee"], "title": "AI Personalization Paradox: Personalized AI Increases Superficial Engagement in Reading while Undermines Autonomy and Ownership in Writing", "categories": ["cs.HC"], "comment": "This paper has been accepted for publication at ACM CHI 2026", "summary": "AI-assisted writing raises concerns about autonomy and ownership when benefiting writers. Personalization has been proposed as an effective solution while also risking writers' reliance on AI and behavior shifting. For better personalization design, existing studies rely on interaction and information solely within the writing phase; however, few studies have examined how reading behaviors can inform personalized writing. This study investigates the effects of integrating reading highlights for personalization on AI-assisted writing. A between-subjects study with 46 participants revealed that the personalization condition encouraged participants to produce more highlights. However, highlighting unexpectedly shifted from a sense-making strategy to an instrumental act of \"feeding the AI,\" leading to significant reliance on AI and declines in writers' sense of autonomy, ownership, and self-credit. These findings indicate personalization risks in AI-assisted writing, emphasize the importance of personalization strategies, and provide design implications.", "AI": {"tldr": "研究探讨了AI个性化辅助写作中，阅读高亮对写作行为的影响，并揭示了这种个性化设计可能带来的负面影响。", "motivation": "尽管个人化被认为是提高AI辅助写作效果的有效方法，但其可能导致使用者过度依赖AI并影响自主性和所有权感。现有的研究主要关注写作过程中的交互和信息处理，而较少探讨阅读行为如何为个性化写作提供信息。因此，本研究旨在填补这一空白。", "method": "采用46名参与者之间的对照实验设计，探究了整合阅读高亮的个性化策略对AI辅助写作的影响。", "result": "结果显示，在个人化条件下，参与者更倾向于产生更多高亮。然而，这种行为从原本的理解策略转变为“喂养AI”的工具性活动，导致过度依赖于AI，并且降低了作者的自主感、所有权和自我认同感。", "conclusion": "研究指出了个性化在AI辅助写作中的风险，强调了个性化设计的重要性，并提供了相关的设计启示。"}}
{"id": "2601.17845", "pdf": "https://arxiv.org/pdf/2601.17845", "abs": "https://arxiv.org/abs/2601.17845", "authors": ["Killian Davitt", "Dan Ristea", "Steven J. Murdoch"], "title": "Are we collaborative yet? A Usability Perspective on Mixnet Latency for Real-Time Applications", "categories": ["cs.HC"], "comment": null, "summary": "Mixnet networks deliberately induce additional latency to communications to provide anonymity. Recent developments have allowed mixnets to reduce their latency from hours to seconds while maintaining the same level of anonymity. As a result, real-time communications are now possible on mixnets. There has been limited research on how users tolerate different levels of delay, and it is unclear what latency levels mixnet operators should choose. Previous studies about latency do not apply to these 'mid-latency' mixnet scenarios. Our paper contributes the first measurement of users' tolerance to real-time applications under mixnet delay. We design a text-based collaborative quiz system to test user response to latency where participants complete a set of question tasks in collaboration with a simulated second user. Different levels of latency are added, analogous to a modern mixnet system. We show that average delay parameters of 1s and 4s maintain usability, a mean delay of 7s shows some difficulty and a mean delay of 10s is detrimental to user experience. Using these delay parameters, mixnet operators can ensure that most types of real-time communication applications are usable. Mixnets thus can balance usability and anonymity without compromising either.", "AI": {"tldr": "研究了用户在混网延迟下的实时应用容忍度，以平衡匿名性和可用性。", "motivation": "虽然现代混网能将通信延迟降至几秒内，但关于这种“中等延迟”场景下用户体验的研究较少。本文旨在填补这一空白。", "method": "设计了一个基于文本的协作测验系统来测试用户对不同水平延迟的反应，并模拟了多种延迟情况下的用户体验。", "result": "结果显示，在平均1秒和4秒的延迟下，可用性保持良好；7秒延迟开始出现一些困难；而10秒以上的延迟则严重影响用户体验。", "conclusion": "通过合理设置延迟参数，混网运营商可以在保证匿名性的前提下实现多数实时通信应用的可用性。"}}
{"id": "2601.17844", "pdf": "https://arxiv.org/pdf/2601.17844", "abs": "https://arxiv.org/abs/2601.17844", "authors": ["Siyang Li", "Zhuoya Wang", "Xiyan Gui", "Xiaoqing Chen", "Ziwei Wang", "Yaozhi Wen", "Dongrui Wu"], "title": "RAICL: Retrieval-Augmented In-Context Learning for Vision-Language-Model Based EEG Seizure Detection", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": null, "summary": "Electroencephalogram (EEG) decoding is a critical component of medical diagnostics, rehabilitation engineering, and brain-computer interfaces. However, contemporary decoding methodologies remain heavily dependent on task-specific datasets to train specialized neural network architectures. Consequently, limited data availability impedes the development of generalizable large brain decoding models. In this work, we propose a paradigm shift from conventional signal-based decoding by leveraging large-scale vision-language models (VLMs) to analyze EEG waveform plots. By converting multivariate EEG signals into stacked waveform images and integrating neuroscience domain expertise into textual prompts, we demonstrate that foundational VLMs can effectively differentiate between different patterns in the human brain. To address the inherent non-stationarity of EEG signals, we introduce a Retrieval-Augmented In-Context Learning (RAICL) approach, which dynamically selects the most representative and relevant few-shot examples to condition the autoregressive outputs of the VLM. Experiments on EEG-based seizure detection indicate that state-of-the-art VLMs under RAICL achieved better or comparable performance with traditional time series based approaches. These findings suggest a new direction in physiological signal processing that effectively bridges the modalities of vision, language, and neural activities. Furthermore, the utilization of off-the-shelf VLMs, without the need for retraining or downstream architecture construction, offers a readily deployable solution for clinical applications.", "AI": {"tldr": "本文提出了一种新的基于大规模视觉语言模型（VLM）的脑电图（EEG）癫痫检测方法，通过将多变量EEG信号转换为波形图像，并结合神经科学领域的专业知识，在RAICL框架下实现了对不同脑模式的有效区分。", "motivation": "传统的脑电波解码依赖于特定任务的数据集和专门的神经网络架构，导致数据不足限制了通用大型脑解码模型的发展，因此本文提出利用大规模视觉语言模型来解决这一问题。", "method": "将多变量EEG信号转换成堆叠的波形图像，并结合文本提示中的神经科学专业知识，通过RAICL框架动态选择最具代表性和相关性的少样本示例来调节VLM的自回归输出。", "result": "实验表明，在基于EEG的癫痫检测中，使用RAICL框架下的大型视觉语言模型能够达到或超越传统时间序列方法的表现。", "conclusion": "研究结果表明了跨视觉、语言和神经活动模态的有效结合的新方向，并证明了利用现成VLMs而无需重新训练或构建下游架构的解决方案在临床应用中的潜力。"}}
{"id": "2601.17837", "pdf": "https://arxiv.org/pdf/2601.17837", "abs": "https://arxiv.org/abs/2601.17837", "authors": ["Peinuan Qin", "Yugin Tan", "Jingzhu Chen", "Nattapat Boonprakong", "Zicheng Zhu", "Naomi Yamashita", "Yi-Chieh Lee"], "title": "ChatLearn: Leveraging AI to Transform Non-Native Speaker Communication Challenges as Language Learning Opportunities", "categories": ["cs.HC"], "comment": "This paper has been accepted for publication at ACM CHI 2026", "summary": "Non-native speakers (NNSs) face significant language barriers in multilingual communication with native speakers (NSs). While AI-mediated communication (AIMC) tools offer efficient one-time assistance, they often overlook opportunities for NNSs' continuous language acquisition. We introduce ChatLearn, an enhanced AIMC system that leverages NNSs' communication difficulties as learning opportunities. Beyond comprehension and expression assistance, ChatLearn simultaneously captures NNSs' language challenges, and subsequently provides them with spaced review as the conversation progresses. We conducted a mixed-methods study using a communication task with 43 NNS-NS pairs, after which ChatLearn NNSs recalled significantly more expressions than the baseline group, while there was no substantial decline in communication experience. Our findings highlight the value of contextual learning in NNS-NS communication, providing a new direction for AIMC systems that foster both immediate collaboration and continuous language development.", "AI": {"tldr": "介绍ChatLearn，一种增强型AI介导通信系统，旨在通过利用非母语者的沟通困难作为学习机会来促进其语言能力的持续发展。", "motivation": "解决非母语者在与母语者多语言交流中面临的语言障碍问题，并探索将这些障碍转化为学习机会的方法。现有的AI介导通信工具虽然提供了有效的即时帮助，但未能充分利用这些情境进行长期的语言学习。", "method": "开发了ChatLearn系统，在提供沟通协助的同时捕捉非母语者的语言挑战，并在对话过程中为他们提供间隔复习。研究采用了混合方法研究设计，包括43对非母语者和母语者参与的通信任务。", "result": "与基线组相比，使用ChatLearn系统的非母语者能够回忆起更多的表达方式，同时没有显著降低沟通体验的质量。这表明，在非母语者与母语者的交流中，情境学习具有重要价值。", "conclusion": "研究结果证明了将AI介导通信系统发展为既支持即时协作又促进长期语言发展的工具的新方向。ChatLearn展示了通过利用沟通障碍作为学习机会来提高非母语者的语言能力的潜力。"}}
{"id": "2601.17835", "pdf": "https://arxiv.org/pdf/2601.17835", "abs": "https://arxiv.org/abs/2601.17835", "authors": ["Baowen Zhang", "Chenxing Jiang", "Heng Li", "Shaojie Shen", "Ping Tan"], "title": "Geometry-Grounded Gaussian Splatting", "categories": ["cs.CV"], "comment": "16 pages, 15 figures", "summary": "Gaussian Splatting (GS) has demonstrated impressive quality and efficiency in novel view synthesis. However, shape extraction from Gaussian primitives remains an open problem. Due to inadequate geometry parameterization and approximation, existing shape reconstruction methods suffer from poor multi-view consistency and are sensitive to floaters. In this paper, we present a rigorous theoretical derivation that establishes Gaussian primitives as a specific type of stochastic solids. This theoretical framework provides a principled foundation for Geometry-Grounded Gaussian Splatting by enabling the direct treatment of Gaussian primitives as explicit geometric representations. Using the volumetric nature of stochastic solids, our method efficiently renders high-quality depth maps for fine-grained geometry extraction. Experiments show that our method achieves the best shape reconstruction results among all Gaussian Splatting-based methods on public datasets.", "AI": {"tldr": "本文提出了Geometry-Grounded Gaussian Splatting，通过将高斯原语视为随机固体的特定类型，实现了高质量的深度图渲染和精细几何提取。", "motivation": "现有形状重建方法由于缺乏足够的几何参数化和近似而面临多视角一致性和浮游物敏感性的问题。本文旨在解决从高斯原语中提取形状的问题，并提高其效果。", "method": "通过建立随机固体的理论框架，将高斯原语视为显式几何表示，利用随机固体的体积性质高效地渲染高质量深度图以进行精细几何提取。", "result": "实验表明，该方法在公共数据集上取得了所有基于高斯散射的方法中最好的形状重建结果。", "conclusion": "本文通过理论推导建立了将高斯原语作为显式几何表示的基础，并证明了所提出的方法可以有效提高形状重建的质量和一致性。"}}
{"id": "2601.17830", "pdf": "https://arxiv.org/pdf/2601.17830", "abs": "https://arxiv.org/abs/2601.17830", "authors": ["Mengmeng Wang", "Dengyang Jiang", "Liuzhuozheng Li", "Yucheng Lin", "Guojiang Shen", "Xiangjie Kong", "Yong Liu", "Guang Dai", "Jingdong Wang"], "title": "VAE-REPA: Variational Autoencoder Representation Alignment for Efficient Diffusion Training", "categories": ["cs.CV"], "comment": null, "summary": "Denoising-based diffusion transformers, despite their strong generation performance, suffer from inefficient training convergence. Existing methods addressing this issue, such as REPA (relying on external representation encoders) or SRA (requiring dual-model setups), inevitably incur heavy computational overhead during training due to external dependencies. To tackle these challenges, this paper proposes \\textbf{\\namex}, a lightweight intrinsic guidance framework for efficient diffusion training. \\name leverages off-the-shelf pre-trained Variational Autoencoder (VAE) features: their reconstruction property ensures inherent encoding of visual priors like rich texture details, structural patterns, and basic semantic information. Specifically, \\name aligns the intermediate latent features of diffusion transformers with VAE features via a lightweight projection layer, supervised by a feature alignment loss. This design accelerates training without extra representation encoders or dual-model maintenance, resulting in a simple yet effective pipeline. Extensive experiments demonstrate that \\name improves both generation quality and training convergence speed compared to vanilla diffusion transformers, matches or outperforms state-of-the-art acceleration methods, and incurs merely 4\\% extra GFLOPs with zero additional cost for external guidance models.", "AI": {"tldr": "本文提出了VAE-REPA，一种利用预训练变分自编码器（VAE）特征加速扩散模型训练的方法。", "motivation": "现有的解决扩散模型训练效率低下的方法存在计算开销大等问题，因此需要提出更高效、轻量级的解决方案。", "method": "VAE-REPA通过将扩散模型中间层特征与预训练VAE特征对齐来加速训练，使用轻量投影层和特征对齐损失函数实现这一目标。", "result": "实验结果显示，该方法提高了生成质量并加快了训练收敛速度，性能优于或匹配最先进的加速方法，并且额外的计算开销仅为4% GFLOPs。", "conclusion": "VAE-REPA是一种简单有效的提高扩散模型训练效率的方法，无需外部指导模型或双模维护。"}}
{"id": "2601.17829", "pdf": "https://arxiv.org/pdf/2601.17829", "abs": "https://arxiv.org/abs/2601.17829", "authors": ["Dan Greenstein", "Zohar Karnin", "Chen Amiraz", "Oren Somekh"], "title": "Linguistic and Argument Diversity in Synthetic Data for Function-Calling Agents", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The construction of function calling agents has emerged as a promising avenue for extending model capabilities. A major challenge for this task is obtaining high quality diverse data for training. Prior work emphasizes diversity in functions, invocation patterns, and interaction turns, yet linguistic diversity of requests and coverage of arguments (e.g., \\texttt{city\\_name}, \\texttt{stock\\_ticker}) remain underexplored. We propose a method that generates synthetic datasets via optimizing general-purpose diversity metrics across both queries and arguments, without relying on hand-crafted rules or taxonomies, making it robust to different usecases. We demonstrate the effectiveness of our technique via both intrinsic and extrinsic testing, comparing it to SoTA data generation methods. We show a superiority over baselines in terms of diversity, while keeping comparable correctness. Additionally, when used as a training set, the model resulting from our dataset exhibits superior performance compared to analogous models based on the baseline data generation methods in out-of-distribution performance. In particular, we achieve an $7.4\\%$ increase in accuracy on the BFCL benchmark compared to similar counterparts.", "AI": {"tldr": "本文提出了一种生成函数调用代理训练数据的方法，该方法通过优化查询和参数的通用多样性指标来提高模型性能。", "motivation": "现有的函数调用代理训练数据缺乏足够的语言多样性和参数覆盖度，因此作者希望提供一种更高效、多样化且可靠的合成数据生成方法。", "method": "作者提出了一种不依赖手工规则或分类学的方法，通过优化通用多样性指标来生成包含高多样性查询和参数的合成数据集。", "result": "实验结果表明该方法在多样性和正确性方面优于现有方法，并且基于此生成的数据训练出的模型在外部分布上的性能也有所提升，在BFCL基准测试中准确性提高了7.4%。", "conclusion": "作者得出结论，通过优化通用多样性指标来生成合成数据集的方法能够有效提高函数调用代理的性能和泛化能力。"}}
{"id": "2601.17828", "pdf": "https://arxiv.org/pdf/2601.17828", "abs": "https://arxiv.org/abs/2601.17828", "authors": ["Tanvi Verma", "Yang Zhou", "Rick Siow Mong Goh", "Yong Liu"], "title": "Aligning Medical Conversational AI through Online Reinforcement Learning with Information-Theoretic Rewards", "categories": ["cs.AI"], "comment": null, "summary": "We present Information Gain Fine-Tuning (IGFT), a novel approach for training medical conversational AI to conduct effective patient interviews and generate comprehensive History of Present Illness (HPI) without requiring pre-collected human conversations. IGFT combines online Group Relative Policy Optimization (GRPO) with information-theoretic rewards, enabling models to learn from self-generated conversations with simulated patients. Unlike existing approaches that rely on expensive expert-annotated conversations or static datasets, our online RL framework allows models to discover effective questioning strategies through exploration. Our key innovation is an information gain reward function that tracks which clinical entities such as symptoms, temporal patterns, and medical history, are revealed during conversation. Each question's reward is computed based on its expected information gain combined with GPT-4o-mini quality assessments across dimensions including clinical relevance, patient engagement, and specificity. This hybrid approach ensures models learn to ask targeted, clinically appropriate questions that efficiently gather diagnostic information. We fine-tune two models using LoRA: Llama-3.1-8B-Instruct and DeepSeek-R1-Distill-Qwen-7B (a reasoning-optimized model). Training exclusively on Avey data containing concise HPIs, we evaluate generalization to MIMIC data with longer, more elaborate HPIs. DeepSeek-R1-Distill-Qwen-7B (IGFT) achieves F1 scores of 0.408 on Avey (10.9% improvement over base) and 0.289 on MIMIC (12.9% improvement), while Llama-3.1-8B-Instruct (IGFT) reaches 0.384 and 0.336 respectively. Both models outperform OpenAI's model on MIMIC and surpass medical domain-specific baselines like HuatuoGPT and UltraMedical, which were optimized for single-turn medical QA rather than multi-turn conversations.", "AI": {"tldr": "本文介绍了信息增益微调（IGFT）方法，用于训练医疗对话AI进行有效的患者访谈并生成全面的现病史（HPI）。", "motivation": "现有方法依赖昂贵的专业注释对话或静态数据集，而本文提出了一种在线强化学习框架，可以自动生成对话并在探索中发现有效的问题策略。", "method": "IGFT结合了在线群体相对策略优化（GRPO）和信息论奖励函数，通过追踪临床实体如症状、时间模式和病史在对话中的揭示来计算每个问题的预期信息增益，并结合GPT-4o-mini的质量评估。", "result": "实验结果显示，经过微调后，DeepSeek-R1-Distill-Qwen-7B模型在Avey数据集上F1分数达到0.408，在MIMIC数据集上为0.289；Llama-3.1-8B-Instruct模型分别达到了0.384和0.336。这些结果优于OpenAI的模型和其他医疗领域的基线。", "conclusion": "IGFT框架通过在线强化学习，无需依赖昂贵的专业注释对话或静态数据集，即可有效训练医疗对话AI进行多轮次、高质量的患者访谈。"}}
{"id": "2601.17826", "pdf": "https://arxiv.org/pdf/2601.17826", "abs": "https://arxiv.org/abs/2601.17826", "authors": ["Siyuan Yang", "Xihan Bian", "Jiayin Tang"], "title": "RegGuard: AI-Powered Retrieval-Enhanced Assistant for Pharmaceutical Regulatory Compliance", "categories": ["cs.AI"], "comment": null, "summary": "The increasing frequency and complexity of regulatory updates present a significant burden for multinational pharmaceutical companies. Compliance teams must interpret evolving rules across jurisdictions, formats, and agencies, often manually, at high cost and risk of error. We introduce RegGuard, an industrial-scale AI assistant designed to automate the interpretation of heterogeneous regulatory texts and align them with internal corporate policies. The system ingests heterogeneous document sources through a secure pipeline and enhances retrieval and generation quality with two novel components: HiSACC (Hierarchical Semantic Aggregation for Contextual Chunking) semantically segments long documents into coherent units while maintaining consistency across non-contiguous sections. ReLACE (Regulatory Listwise Adaptive Cross-Encoder for Reranking), a domain-adapted cross-encoder built on an open-source model, jointly models user queries and retrieved candidates to improve ranking relevance. Evaluations in enterprise settings demonstrate that RegGuard improves answer quality specifically in terms of relevance, groundedness, and contextual focus, while significantly mitigating hallucination risk. The system architecture is built for auditability and traceability, featuring provenance tracking, access control, and incremental indexing, making it highly responsive to evolving document sources and relevant for any domain with stringent compliance demands.", "AI": {"tldr": "介绍RegGuard，一种用于制药监管合规性的AI增强检索助手。", "motivation": "为了应对日益频繁和复杂的法规更新带来的负担，特别是对于需要解释多国、多种格式和不同机构的法律法规的跨国制药公司。", "method": "通过一个安全的数据管道摄取异构文档，并使用HiSACC对长文档进行语义分段，以及ReLACE增强检索质量。", "result": "在企业环境中的评估显示RegGuard提高了答案的相关性、依据性和上下文焦点，同时显著减少了幻觉风险。", "conclusion": "该系统架构具备可审计性和追溯性功能，适用于任何有严格合规要求的领域。"}}
{"id": "2601.17824", "pdf": "https://arxiv.org/pdf/2601.17824", "abs": "https://arxiv.org/abs/2601.17824", "authors": ["Saber Zerhoudi", "Michael Dinzinger", "Michael Granitzer", "Jelena Mitrovic"], "title": "OwlerLite: Scope- and Freshness-Aware Web Retrieval for LLM Assistants", "categories": ["cs.HC", "cs.IR"], "comment": "ef:Proceedings of the Companion Proceedings of the ACM Web Conference 2026 (WWW Companion '26)", "summary": "Browser-based language models often use retrieval-augmented generation (RAG) but typically rely on fixed, outdated indices that give users no control over which sources are consulted. This can lead to answers that mix trusted and untrusted content or draw on stale information. We present OwlerLite, a browser-based RAG system that makes user-defined scopes and data freshness central to retrieval. Users define reusable scopes-sets of web pages or sources-and select them when querying. A freshness-aware crawler monitors live pages, uses a semantic change detector to identify meaningful updates, and selectively re-indexes changed content. OwlerLite integrates text relevance, scope choice, and recency into a unified retrieval model. Implemented as a browser extension, it represents a step toward more controllable and trustworthy web assistants.", "AI": {"tldr": "提出了OwlerLite，一个浏览器中的RAG系统，强调用户自定义的范围和数据的新鲜度。", "motivation": "现有的基于检索增强生成的模型通常使用固定且过时的数据索引，导致答案可能混合可信与不可信内容或引用陈旧信息。", "method": "OwlerLite允许用户定义可重复使用的网页或来源集，并在查询时选择它们。一个新鲜度感知的爬虫监测实时页面，通过语义变化检测器识别有意义的更新并重新索引变化的内容。系统将文本相关性、范围选择和新近度整合进统一检索模型。", "result": "OwlerLite作为浏览器扩展实现，提供更可控且值得信赖的网络助手。", "conclusion": "OwlerLite通过用户定义的搜索范围和数据新鲜度提高基于语言模型的答案质量与可信性。"}}
{"id": "2601.17823", "pdf": "https://arxiv.org/pdf/2601.17823", "abs": "https://arxiv.org/abs/2601.17823", "authors": ["Pranav Kasela", "Marco Braga", "Alessandro Ghiotto", "Andrea Pilzer", "Marco Viviani", "Alessandro Raganato"], "title": "DIETA: A Decoder-only transformer-based model for Italian-English machine TrAnslation", "categories": ["cs.CL", "cs.AI"], "comment": "Published in CLiC-IT '25: https://aclanthology.org/2025.clicit-1.52/", "summary": "In this paper, we present DIETA, a small, decoder-only Transformer model with 0.5 billion parameters, specifically designed and trained for Italian-English machine translation. We collect and curate a large parallel corpus consisting of approximately 207 million Italian-English sentence pairs across diverse domains, including parliamentary proceedings, legal texts, web-crawled content, subtitles, news, literature and 352 million back-translated data using pretrained models. Additionally, we create and release a new small-scale evaluation set, consisting of 450 sentences, based on 2025 WikiNews articles, enabling assessment of translation quality on contemporary text. Comprehensive evaluations show that DIETA achieves competitive performance on multiple Italian-English benchmarks, consistently ranking in the second quartile of a 32-system leaderboard and outperforming most other sub-3B models on four out of five test suites. The training script, trained models, curated corpus, and newly introduced evaluation set are made publicly available, facilitating further research and development in specialized Italian-English machine translation. https://github.com/pkasela/DIETA-Machine-Translation", "AI": {"tldr": "本研究提出了DIETA，一种针对意大利语-英语机器翻译的小型解码器-only变压器模型。", "motivation": "目的是开发一个专门用于意大利语和英语之间机器翻译的高效模型，并通过收集大量平行语料库来提高性能。", "method": "作者构建了一个包含约207百万句对的大规模并行语料库，使用预训练模型生成了3.52亿个回译数据，并创建了一个新的小规模评估集。DIETA是一个参数量为0.5B的解码器-only Transformer模型。", "result": "DIETA在多个意大利语-英语基准测试中表现出色，排名处于32系统排行榜中的第二四分位，在五个测试套件中有四个优于大多数其他小于3B参数的模型。", "conclusion": "研究证明了DIETA作为一个小型解码器-only Transformer模型能够实现具有竞争力的表现，并且相关资源公开发布以促进进一步的研究。"}}
{"id": "2601.17818", "pdf": "https://arxiv.org/pdf/2601.17818", "abs": "https://arxiv.org/abs/2601.17818", "authors": ["Wen Luo", "Peng Chen", "Xiaotao Huang", "LiQun Huang"], "title": "ViTCoP: Accelerating Large Vision-Language Models via Visual and Textual Semantic Collaborative Pruning", "categories": ["cs.CV"], "comment": null, "summary": "Large Vision-Language Models (LVLMs) incur high computational costs due to significant redundancy in their visual tokens. To effectively reduce this cost, researchers have proposed various visual token pruning methods. However, existing methods are generally limited, either losing critical visual information prematurely due to pruning in the vision encoder, or leading to information redundancy among the selected tokens due to pruning in the Large Language Models (LLMs). To address these challenges, we propose a Visual and Textual Semantic Collaborative Pruning framework (ViTCoP) that combines redundancy filtering in the vision encoder with step-wise co-pruning within the LLM based on its hierarchical characteristics, to efficiently preserve critical and informationally diverse visual tokens. Meanwhile, to ensure compatibility with acceleration techniques like FlashAttention, we introduce the L2 norm of K-vectors as the token saliency metric in the LLM. Extensive experiments on various Large Vision-Language Models demonstrate that ViTCoP not only achieves state-of-the-art performance surpassing existing methods on both image and video understanding tasks, but also significantly reduces model inference latency and GPU memory consumption. Notably, its performance advantage over other methods becomes even more pronounced under extreme pruning rates.", "AI": {"tldr": "本文提出了ViTCoP框架，通过视觉和文本语义协同剪枝来加速大型视觉语言模型。", "motivation": "为了减少大型视觉语言模型中的计算成本并解决现有剪枝方法的不足，提出了一种新的框架来有效保留关键且信息多样的视觉标记。", "method": "ViTCoP结合了视觉编码器中的冗余过滤和基于LLM层次特征的逐步协同剪枝，使用K向量的L2范数作为LLM中的标记显著性度量。", "result": "实验表明，与现有方法相比，ViTCoP不仅在图像和视频理解任务中达到最新性能水平，还大幅减少了模型推理延迟和GPU内存消耗，在极端剪枝率下表现尤为明显。", "conclusion": "ViTCoP框架有效解决了大型视觉语言模型中的计算成本问题，并显著提高了模型的效率。"}}
{"id": "2601.17815", "pdf": "https://arxiv.org/pdf/2601.17815", "abs": "https://arxiv.org/abs/2601.17815", "authors": ["Yves Inglin", "Jonas Frey", "Changan Chen", "Marco Hutter"], "title": "Less Is More: Scalable Visual Navigation from Limited Data", "categories": ["cs.RO"], "comment": null, "summary": "Imitation learning provides a powerful framework for goal-conditioned visual navigation in mobile robots, enabling obstacle avoidance while respecting human preferences and social norms. However, its effectiveness depends critically on the quality and diversity of training data. In this work, we show how classical geometric planners can be leveraged to generate synthetic trajectories that complement costly human demonstrations. We train Less is More (LiMo), a transformer-based visual navigation policy that predicts goal-conditioned SE(2) trajectories from a single RGB observation, and find that augmenting limited expert demonstrations with planner-generated supervision yields substantial performance gains. Through ablations and complementary qualitative and quantitative analyses, we characterize how dataset scale and diversity affect planning performance. We demonstrate real-robot deployment and argue that robust visual navigation is enabled not by simply collecting more demonstrations, but by strategically curating diverse, high-quality datasets. Our results suggest that scalable, embodiment-specific geometric supervision is a practical path toward data-efficient visual navigation.", "AI": {"tldr": "本文提出Less is More（LiMo）策略，通过结合有限的人类示范和生成的合成轨迹来提升移动机器人目标导向视觉导航性能。", "motivation": "模仿学习在移动机器人中的应用依赖于高质量多样化的训练数据。该研究旨在探索如何使用经典几何规划器生成的合成轨迹来补充昂贵的人类演示，从而改善视觉导航效果。", "method": "本文提出了一种基于Transformer的视觉导航策略LiMo，它能够从单个RGB观察中预测目标导向SE(2)轨迹，并通过有限的专家示范与计划者生成监督相结合的方式提升性能。进行了消融研究和定性定量分析以表征数据集规模和多样性对规划表现的影响。", "result": "研究表明，在真实机器人上的部署表明，战略性地策划多样且高质量的数据集对于实现稳健视觉导航至关重要，并指出使用几何监督是实现高效能视觉导航的实际途径。", "conclusion": "通过结合有限的人类演示与生成的合成轨迹，可以有效提升移动机器人的目标导向视觉导航性能。战略性的数据策划比单纯的收集更多示范更有助于提高表现。"}}
{"id": "2601.17814", "pdf": "https://arxiv.org/pdf/2601.17814", "abs": "https://arxiv.org/abs/2601.17814", "authors": ["Haoxuan Ma", "Guannan Lai", "Han-Jia Ye"], "title": "MMR-Bench: A Comprehensive Benchmark for Multimodal LLM Routing", "categories": ["cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) have advanced rapidly, yet heterogeneity in architecture, alignment strategies, and efficiency means that no single model is uniformly superior across tasks. In practical deployments, workloads span lightweight OCR to complex multimodal reasoning; using one MLLM for all queries either over-provisions compute on easy instances or sacrifices accuracy on hard ones. Query-level model selection (routing) addresses this tension, but extending routing from text-only LLMs to MLLMs is nontrivial due to modality fusion, wide variation in computational cost across models, and the absence of a standardized, budget-aware evaluation. We present MMR-Bench, a unified benchmark that isolates the multimodal routing problem and enables comparison under fixed candidate sets and cost models. MMR-Bench provides (i) a controlled environment with modality-aware inputs and variable compute budgets, (ii) a broad suite of vision-language tasks covering OCR, general VQA, and multimodal math reasoning, and (iii) strong single-model reference, oracle upper bounds, and representative routing policies. Using MMR-Bench, we show that incorporating multimodal signals improves routing quality. Empirically, these cues improve the cost-accuracy frontier and enable the routed system to exceed the strongest single model's accuracy at roughly 33% of its cost. Furthermore, policies trained on a subset of models and tasks generalize zero-shot to new datasets and text-only benchmarks without retuning, establishing MMR-Bench as a foundation for studying adaptive multimodal model selection and efficient MLLM deployment. The code will be available at: https://github.com/Hunter-Wrynn/MMR-Bench.", "AI": {"tldr": "本文介绍了MMR-Bench，这是一个全面的多模态大语言模型（MLLM）路由基准测试平台。", "motivation": "由于多模态模型在架构、对齐策略和效率上的异质性，没有单一模型能在所有任务上表现最优。因此，提出一个能适应不同查询难度和计算成本的路由系统是必要的。", "method": "MMR-Bench提供了一个控制环境，包括模态感知输入和可变计算预算，涵盖了OCR、通用视觉问答和多模态数学推理等广泛的任务，并提供了强单模型参考、上界和代表性的路由策略。", "result": "研究结果表明，加入多模态信号能提高路由质量，改善成本-准确性边界。此外，这些政策在未重新训练的情况下对新数据集和文本基准测试具有零样本泛化能力。", "conclusion": "MMR-Bench为研究自适应的多模态模型选择和高效的MLLM部署奠定了基础，证明了其作为评估路由策略的有效性。"}}
{"id": "2601.17812", "pdf": "https://arxiv.org/pdf/2601.17812", "abs": "https://arxiv.org/abs/2601.17812", "authors": ["Mingtian Du", "Suhas Raghavendra Kulkarni", "Bernardo Noronha", "Domenico Campolo"], "title": "Delay-Compensated Stiffness Estimation for Robot-Mediated Dyadic Interaction", "categories": ["cs.RO", "cs.HC", "eess.SY"], "comment": null, "summary": "Robot-mediated human-human (dyadic) interactions enable therapists to provide physical therapy remotely, yet an accurate perception of patient stiffness remains challenging due to network-induced haptic delays. Conventional stiffness estimation methods, which neglect delay, suffer from temporal misalignment between force and position signals, leading to significant estimation errors as delays increase. To address this, we propose a robust, delay-compensated stiffness estimation framework by deriving an algebraic estimator based on quasi-static equilibrium that explicitly accounts for temporally aligning the expert's input with the novice's response. A Normalised Weighted Least Squares (NWLS) implementation is then introduced to robustly filter dynamic bias resulting from the algebraic derivation. Experiments using commercial rehabilitation robots (H-MAN) as the platform demonstrate that the proposed method significantly outperforms the standard estimator, maintaining consistent tracking accuracy under multiple introduced delays. These findings offer a promising solution for achieving high-fidelity haptic perception in remote dyadic interaction, potentially facilitating reliable stiffness assessment in therapeutic settings across networks.", "AI": {"tldr": "本文提出了一种基于准静态平衡的代数估计器，用于补偿机器人介导的人际互动中的延迟问题，以提高对患者僵硬度感知的准确性。", "motivation": "远程物理治疗需要准确感知患者的僵硬度，但网络诱导的触觉延迟导致了力和位置信号的时间错位，影响了传统方法的精度。", "method": "通过代数估计器明确地对齐专家输入与新手响应之间的时序关系，并引入归一化加权最小二乘（NWLS）实现来过滤由于代数推导产生的动态偏差。", "result": "实验结果显示，提出的方法在多种延迟条件下都能保持一致的跟踪精度，显著优于标准估计器。", "conclusion": "该研究为远程人际互动中的高保真触觉感知提供了有希望的解决方案，有望促进网络环境中可靠的僵硬度评估。"}}
{"id": "2601.17811", "pdf": "https://arxiv.org/pdf/2601.17811", "abs": "https://arxiv.org/abs/2601.17811", "authors": ["Xiang Li", "Wei He", "Per Ola Kristensson"], "title": "How Do We Evaluate Experiences in Immersive Environments?", "categories": ["cs.HC"], "comment": "25 pages, 7 figures, Accepted by ACM CHI 2026", "summary": "How do we evaluate experiences in immersive environments? Despite decades of research in immersive technologies such as virtual reality, the field remains fragmented. Studies rely on overlapping constructs, heterogeneous instruments, and little agreement on what counts as immersive experience. To better understand this landscape, we conducted a bottom-up scoping review of 375 papers published in ACM CHI, UIST, VRST, SUI, IEEE VR, ISMAR, and TVCG. Our analysis reveals that evaluation practices are often domain- and purpose-specific, shaped more by local choices than by shared standards. Yet this diversity also points to new directions. Instead of multiplying instruments, researchers benefit from integrating and refining them into smarter measures. Rather than focusing only on system outputs, evaluations must center the user's lived experience. Computational modeling offers opportunities to bridge signals across methods, but lasting progress requires open and sustainable evaluation practices that support comparability and reuse. Ultimately, our contribution is to map current practices and outline a forward-looking agenda for immersive experience research.", "AI": {"tldr": "本文旨在评估沉浸式环境中的体验，通过综述相关文献来分析当前的评价实践，并提出未来的研究议程。", "motivation": "尽管虚拟现实等沉浸技术已有数十年研究，但该领域仍存在碎片化问题，包括重叠的概念、异质化的工具和对何为沉浸体验的不同看法。本文希望通过系统性的综述，更好地理解这一领域的现状并推动发展。", "method": "作者进行了一项自下而上的范围审查（scoping review），分析了发表在七个主要会议期刊上的375篇论文。", "result": "研究发现评价实践往往因领域和目的的不同而异，缺乏统一标准。文章指出，整合和改进测量工具，关注用户体验，并利用计算建模来连接不同方法中的信号是未来的发展方向。", "conclusion": "本文贡献在于描绘了当前的评估实践现状，并提出了一项面向未来的沉浸式体验研究议程，强调开放和可持续性的评价实践的重要性。"}}
{"id": "2601.17808", "pdf": "https://arxiv.org/pdf/2601.17808", "abs": "https://arxiv.org/abs/2601.17808", "authors": ["Alejandro Medina", "Mary Lauren Benton"], "title": "Motif Diversity in Human Liver ChIP-seq Data Using MAP-Elites", "categories": ["cs.NE", "q-bio.GN"], "comment": "Under review for a conference companion paper", "summary": "Motif discovery is a core problem in computational biology, traditionally formulated as a likelihood optimization task that returns a single dominant motif from a DNA sequence dataset. However, regulatory sequence data admit multiple plausible motif explanations, reflecting underlying biological heterogeneity. In this work, we frame motif discovery as a quality-diversity problem and apply the MAP-Elites algorithm to evolve position weight matrix motifs under a likelihood-based fitness objective while explicitly preserving diversity across biologically meaningful dimensions. We evaluate MAP-Elites using three complementary behavioral characterizations that capture trade-offs between motif specificity, compositional structure, coverage, and robustness. Experiments on human CTCF liver ChIP-seq data aligned to the human reference genome compare MAP-Elites against a standard motif discovery tool, MEME, under matched evaluation criteria across stratified dataset subsets. Results show that MAP-Elites recovers multiple high-quality motif variants with fitness comparable to MEME's strongest solutions while revealing structured diversity obscured by single-solution approaches.", "AI": {"tldr": "使用MAP-Elites算法在人类肝脏CTCF ChIP-seq数据中发现多样性的调控序列模式。", "motivation": "传统的动机发现方法只返回单一的主导模式，但实际生物数据可能存在多种合理的解释，该论文希望通过质量多样性问题框架来探索这种多样性。", "method": "采用MAP-Elites算法，在基于可能性的适应度目标下进化位置权重矩阵，并在生物学上有意义的维度上显式地保持多样性。使用三个互补的行为特征化指标进行评估。", "result": "实验结果表明，与传统的MEME工具相比，MAP-Elites不仅能够发现多个高质量的模式变体，其适应度也与MEME的最佳解决方案相当，同时还揭示了被单一解方法隐藏的结构多样性。", "conclusion": "通过质量多样性优化框架和MAP-Elites算法，可以更好地理解生物数据中的模式多样性和复杂性。"}}
{"id": "2601.17799", "pdf": "https://arxiv.org/pdf/2601.17799", "abs": "https://arxiv.org/abs/2601.17799", "authors": ["Qing Zhang", "Junyu Chen", "Yifei Huang", "Jing Huang", "Thad Starner", "Kai Kunze", "Jun Rekimoto"], "title": "Beyond Symbols: Motion Perception Cues Enhance Dual-Task Performance with Wearable Directional Guidance", "categories": ["cs.HC"], "comment": null, "summary": "Directional cues are crucial for environmental interaction. Conventional methods rely on symbolic visual or auditory reminders that require semantic interpretation, a process that proves challenging in demanding dual-tasking scenarios. We introduce a novel alternative for conveying directional cues on wearable displays: directly triggering motion perception using monocularly presented peripheral stimuli. This approach is designed for low visual interference, with the goal of reducing the need for gaze-switching and the complex cognitive processing associated with symbols. User studies demonstrate our method's potential to robustly convey directional cues. Compared to a conventional arrow-based technique in a demanding dual-task scenario, our motion-based approach resulted in significantly more accurate interpretation of these directional cues ($p=.008$) and showed a trend towards reduced errors on the concurrent primary task ($p=.066$).", "AI": {"tldr": "本文介绍了一种新的方法，利用可穿戴设备上的运动感知线索来增强双任务场景中的方向性提示。", "motivation": "传统的视觉或听觉符号提醒需要复杂的语义解读，在高需求的双任务场景中具有挑战性。因此，研究动机在于探索一种减少干扰并简化认知处理的方向性提示方法。", "method": "通过在可穿戴显示设备上使用单眼呈现的周边刺激来直接触发运动感知，旨在减少视觉干扰和对眼球转移的需求。", "result": "实验结果显示，与传统的箭头指示相比，基于运动的方法显著提高了方向线索的解读准确性（$p=.008$）并对辅助任务的错误率有降低的趋势（$p=.066$）。", "conclusion": "研究表明，利用可穿戴设备上的运动感知线索可以作为传达方向性提示的有效且干扰小的方式。"}}
{"id": "2601.17791", "pdf": "https://arxiv.org/pdf/2601.17791", "abs": "https://arxiv.org/abs/2601.17791", "authors": ["Rabin Dulal", "Wenfeng Jia", "Lihong Zheng", "Jane Quinn"], "title": "Agreement-Driven Multi-View 3D Reconstruction for Live Cattle Weight Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate cattle live weight estimation is vital for livestock management, welfare, and productivity. Traditional methods, such as manual weighing using a walk-over weighing system or proximate measurements using body condition scoring, involve manual handling of stock and can impact productivity from both a stock and economic perspective. To address these issues, this study investigated a cost-effective, non-contact method for live weight calculation in cattle using 3D reconstruction. The proposed pipeline utilized multi-view RGB images with SAM 3D-based agreement-guided fusion, followed by ensemble regression. Our approach generates a single 3D point cloud per animal and compares classical ensemble models with deep learning models under low-data conditions. Results show that SAM 3D with multi-view agreement fusion outperforms other 3D generation methods, while classical ensemble models provide the most consistent performance for practical farm scenarios (R$^2$ = 0.69 $\\pm$ 0.10, MAPE = 2.22 $\\pm$ 0.56 \\%), making this practical for on-farm implementation. These findings demonstrate that improving reconstruction quality is more critical than increasing model complexity for scalable deployment on farms where producing a large volume of 3D data is challenging.", "AI": {"tldr": "该研究开发了一种基于多视角RGB图像和SAM 3D技术的非接触式牛只体重估算方法，用于提高牧场管理效率。", "motivation": "传统的牛只体重测量方法耗时费力且影响生产效率。因此，本研究旨在寻找一种经济高效的、非接触式的牛只体重估算方法。", "method": "该方法使用多视角RGB图像与SAM 3D技术进行三维重建，并通过集成回归模型来估计体重。实验比较了在少量数据下的经典集成模型和深度学习模型的表现。", "result": "结果表明，基于SAM 3D的多视图融合方法优于其他三维生成方法。经典的集成模型在农场实际场景中提供了最一致的性能（R$^2$=0.69 ± 0.10, MAPE = 2.22 ± 0.56%），这使其适用于农场实施。", "conclusion": "研究结论指出，对于数据生成困难的实际应用场景而言，提高重建质量比增加模型复杂度更为关键。"}}
{"id": "2601.17789", "pdf": "https://arxiv.org/pdf/2601.17789", "abs": "https://arxiv.org/abs/2601.17789", "authors": ["Yiming Su", "Kunzhao Xu", "Yanjie Gao", "Fan Yang", "Cheng Li", "Mao Yang", "Tianyin Xu"], "title": "Neuro-Symbolic Verification on Instruction Following of LLMs", "categories": ["cs.AI"], "comment": null, "summary": "A fundamental problem of applying Large Language Models (LLMs) to important applications is that LLMs do not always follow instructions, and violations are often hard to observe or check. In LLM-based agentic workflows, such violations can propagate and amplify along reasoning chains, causing task failures and system incidents. This paper presents NSVIF, a neuro-symbolic framework for verifying whether an LLM's output follows the instructions used to prompt the LLM. NSVIF is a universal, general-purpose verifier; it makes no assumption about the instruction or the LLM. NSVIF formulates instruction-following verification as a constraint-satisfaction problem by modeling user instructions as constraints. NSVIF models both logical and semantic constraints; constraint solving is done by a unified solver that orchestrates logical reasoning and semantic analysis. To evaluate NSVIF, we develop VIFBENCH, a new benchmark for instruction-following verifiers with fine-grained data labels. Experiments show that NSVIF significantly outperforms LLM-based approaches and provides interpretable feedback. We also show that feedback from NSVIF helps improve LLMs' instruction-following capability without post-training.", "AI": {"tldr": "本文介绍了NSVIF，一个用于验证大型语言模型（LLMs）是否遵循给定指令的神经符号框架。", "motivation": "由于大型语言模型在重要应用中经常不遵守指示且难以检测这种违规行为，作者提出了一种通用的、无假设的神经符号验证框架来解决这个问题。", "method": "NSVIF将验证任务建模为一个约束满足问题，通过逻辑和语义分析结合的方式来解决问题。用户指令被转化为约束条件，由统一解算器协调逻辑推理和语义分析。", "result": "实验表明，NSVIF在新的验证基准测试VIFBENCH上显著优于基于LLM的方法，并提供了可解释的反馈。", "conclusion": "NSVIF提供了一种有效的方法来检测大型语言模型是否遵循给定指令，并且其提供的反馈可以帮助提升这些模型遵守指示的能力。"}}
{"id": "2601.17782", "pdf": "https://arxiv.org/pdf/2601.17782", "abs": "https://arxiv.org/abs/2601.17782", "authors": ["Md Sahidullah", "Hye-jin Shim", "Rosa Gonzalez Hautamäki", "Tomi H. Kinnunen"], "title": "Shortcut Learning in Binary Classifier Black Boxes: Applications to Voice Anti-Spoofing and Biometrics", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted for Publication in IEEE Journal of Selected Topics in Signal Processing", "summary": "The widespread adoption of deep-learning models in data-driven applications has drawn attention to the potential risks associated with biased datasets and models. Neglected or hidden biases within datasets and models can lead to unexpected results. This study addresses the challenges of dataset bias and explores ``shortcut learning'' or ``Clever Hans effect'' in binary classifiers. We propose a novel framework for analyzing the black-box classifiers and for examining the impact of both training and test data on classifier scores. Our framework incorporates intervention and observational perspectives, employing a linear mixed-effects model for post-hoc analysis. By evaluating classifier performance beyond error rates, we aim to provide insights into biased datasets and offer a comprehensive understanding of their influence on classifier behavior. The effectiveness of our approach is demonstrated through experiments on audio anti-spoofing and speaker verification tasks using both statistical models and deep neural networks. The insights gained from this study have broader implications for tackling biases in other domains and advancing the field of explainable artificial intelligence.", "AI": {"tldr": "本文提出了一种新的框架，用于分析二元分类器中的黑盒模型，并探讨训练和测试数据对分类器评分的影响。", "motivation": "研究旨在解决数据集偏差问题，探索深度学习模型在二元分类中的“捷径学习”现象及其潜在风险。", "method": "该研究采用线性混合效应模型进行事后分析，结合干预和观察两种视角来评估分类器性能。", "result": "通过在音频防欺骗和说话人验证任务中应用统计模型和深度神经网络的实验，证明了该方法的有效性。", "conclusion": "本文提供的见解有助于识别数据偏见对模型行为的影响，并为增强可解释人工智能领域的发展提供了启示。"}}
{"id": "2601.17777", "pdf": "https://arxiv.org/pdf/2601.17777", "abs": "https://arxiv.org/abs/2601.17777", "authors": ["Xiaoyu Liu", "Xiaoyu Guan", "Di Liang", "Xianjie Wu"], "title": "DPI: Exploiting Parameter Heterogeneity for Interference-Free Fine-Tuning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Supervised fine-tuning (SFT) is a crucial step for adapting large language models (LLMs) to downstream tasks. However, conflicting objectives across heterogeneous SFT tasks often induce the \"seesaw effect\": optimizing for one task may degrade performance on others, particularly when model parameters are updated indiscriminately. In this paper, we propose a principled approach to disentangle and isolate task-specific parameter regions, motivated by the hypothesis that parameter heterogeneity underlies cross-task interference. Specifically, we first independently fine-tune LLMs on diverse SFT tasks and identify each task's core parameter region as the subset of parameters exhibiting the largest updates. Tasks with highly overlapping core parameter regions are merged for joint training, while disjoint tasks are organized into different stages. During multi-stage SFT, core parameters acquired in prior tasks are frozen, thereby preventing overwriting by subsequent tasks. To verify the effectiveness of our method, we conducted intensive experiments on multiple public datasets. The results showed that our dynamic parameter isolation strategy consistently reduced data conflicts and achieved consistent performance improvements compared to multi-stage and multi-task tuning baselines.", "AI": {"tldr": "本文提出一种利用参数异质性来实现无干扰微调的方法，以减少不同任务之间的冲突并提高性能。", "motivation": "在对大型语言模型进行监督微调时，不同的目标任务之间往往存在冲突，这会导致“跷跷板效应”，即优化一个任务会降低其他任务的性能。本文旨在解决这一问题，提出了一个新的方法来分离和隔离特定任务的参数区域。", "method": "首先独立地对多种任务进行微调，并确定每个任务的核心参数区域作为更新量最大的子集。然后根据核心参数区域的重叠情况合并任务或将其组织到不同的阶段。在多阶段微调过程中，冻结先前任务中获得的核心参数以防止被后续任务覆盖。", "result": "实验结果表明，动态参数隔离策略能够减少数据冲突，并在多个公开数据集上持续改善性能，优于现有的多阶段和多任务微调基准。", "conclusion": "通过分离不同的核心参数区域并按此组织训练流程，该方法可以有效避免不同目标任务之间的相互干扰，从而提高模型对下游任务的适应能力。"}}
{"id": "2601.17770", "pdf": "https://arxiv.org/pdf/2601.17770", "abs": "https://arxiv.org/abs/2601.17770", "authors": ["Junyong Shin", "Joohyuk Park", "Jihong Park", "Jinho Choi", "Yo-Seb Jeon"], "title": "Context-Aware Iterative Token Detection and Masked Transmission for Wireless Token Communication", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "The success of large-scale language models has established tokens as compact and meaningful units for natural-language representation, which motivates token communication over wireless channels, where tokens are considered fundamental units for wireless transmission. We propose a context-aware token communication framework that uses a pretrained masked language model (MLM) as a shared contextual probability model between the transmitter (Tx) and receiver (Rx). At Rx, we develop an iterative token detection method that jointly exploits MLM-guided contextual priors and channel observations based on a Bayesian perspective. At Tx, we additionally introduce a context-aware masking strategy which skips highly predictable token transmission to reduce transmission rate. Simulation results demonstrate that the proposed framework substantially improves reconstructed sentence quality and supports effective rate adaptation under various channel conditions.", "AI": {"tldr": "本文提出了一种基于预训练掩码语言模型的上下文感知迭代令牌检测和掩蔽传输框架，用于无线令牌通信。", "motivation": "大型语言模型的成功促使将令牌作为自然语言表示的重要单元，并启发了在无线信道中进行令牌通信的需求。", "method": "使用预训练的掩码语言模型作为发射机与接收机之间共享的上下文概率模型，开发了一种迭代令牌检测方法和一种基于上下文感知的掩蔽策略。", "result": "模拟结果显示该框架显著改善了重建句子的质量，并能够在多种信道条件下支持有效的传输速率调整。", "conclusion": "提出的框架能够通过减少高可预测令牌的传输来降低传输率，同时提高无线通信中的句子质量。"}}
{"id": "2601.17769", "pdf": "https://arxiv.org/pdf/2601.17769", "abs": "https://arxiv.org/abs/2601.17769", "authors": ["Anqi Wang", "Zhengyi Li", "Lan Luo", "Xin Tong", "Pan Hui"], "title": "Reflexa: Uncovering How LLM-Supported Reflection Scaffolding Reshapes Creativity in Creative Coding", "categories": ["cs.HC"], "comment": null, "summary": "Creative coding requires continuous translation between evolving concepts and computational artifacts, making reflection essential yet difficult to sustain. Creators often struggle to manage ambiguous intentions, emergent outputs, and complex code, limiting depth of exploration. This work examines how large language models (LLMs) can scaffold reflection not as isolated prompts, but as a system-level mechanism shaping creative regulation. From formative studies with eight expert creators, we derived reflection challenges and design principles that informed Reflexa, an integrated scaffold combining dialogic guidance, visualized version navigation, and iterative suggestion pathways. A within-subject study with 18 participants provides an exploratory mechanism validation, showing that structured reflection patterns mediate the link between AI interaction and creative outcomes. These reflection trajectories enhanced perceived controllability, broadened exploration, and improved originality and aesthetic quality. Our findings advance HCI understanding of reflection from LLM-assisted creative practices, and provide design strategies for building LLM-based creative tools that support richer human-AI co-creativity.", "AI": {"tldr": "该论文探讨了大型语言模型（LLMs）如何作为系统级机制支持创意编程中的反思过程，进而提升创造力。", "motivation": "创意编程要求持续将不断演变的概念与计算作品相转换，这一过程中反思虽至关重要却难以维持。创作者常因模糊意图、突发输出和复杂代码而限制探索深度。", "method": "研究从八位专家创作者的形成性研究中得出反思挑战和设计原则，并构建了结合对话式引导、可视化版本导航及迭代建议路径的综合支撑系统Reflexa，通过18名参与者在同一主体下的实验进行机制验证。", "result": "结构化的反思模式证明了AI交互与创意成果之间的联系。这些反思轨迹增强了感知可控性、拓宽探索范围，并提高了原创性和审美质量。", "conclusion": "研究推进了人机交互（HCI）对LLM辅助创意实践中的反思理解，提供了设计策略以构建支持更丰富人类-人工智能共同创作的工具。"}}
{"id": "2601.17768", "pdf": "https://arxiv.org/pdf/2601.17768", "abs": "https://arxiv.org/abs/2601.17768", "authors": ["Raja Gond", "Aditya K Kamath", "Arkaprava Basu", "Ramachandran Ramjee", "Ashish Panwar"], "title": "LLM-42: Enabling Determinism in LLM Inference with Verified Speculation", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "https://github.com/microsoft/llm-42", "summary": "In LLM inference, the same prompt may yield different outputs across different runs. At the system level, this non-determinism arises from floating-point non-associativity combined with dynamic batching and GPU kernels whose reduction orders vary with batch size. A straightforward way to eliminate non-determinism is to disable dynamic batching during inference, but doing so severely degrades throughput. Another approach is to make kernels batch-invariant; however, this tightly couples determinism to kernel design, requiring new implementations. This coupling also imposes fixed runtime overheads, regardless of how much of the workload actually requires determinism. Inspired by ideas from speculative decoding, we present LLM-42, a scheduling-based approach to enable determinism in LLM inference. Our key observation is that if a sequence is in a consistent state, the next emitted token is likely to be consistent even with dynamic batching. Moreover, most GPU kernels use shape-consistent reductions. Leveraging these insights, LLM-42 decodes tokens using a non-deterministic fast path and enforces determinism via a lightweight verify-rollback loop. The verifier replays candidate tokens under a fixed-shape reduction schedule, commits those that are guaranteed to be consistent across runs, and rolls back those violating determinism. LLM-42 mostly re-uses existing kernels unchanged and incurs overhead only in proportion to the traffic that requires determinism.", "AI": {"tldr": "LLM-42通过调度方法实现大型语言模型推理中的确定性，同时保持高性能。", "motivation": "解决大型语言模型在推理过程中因浮点运算的非结合性和动态批处理导致的输出不确定性问题，同时避免降低吞吐量或引入固定运行时开销。", "method": "LLM-42采用投机解码的思想，使用一个非确定性的快速路径进行令牌解码，并通过轻量级验证回滚循环确保最终结果的一致性。它利用现有内核并在需要保证确定性的流量上施加额外开销。", "result": "LLM-42能够在保持高吞吐量的同时解决推理中的不确定性问题，主要通过再使用未改动的内核来实现高效运行，并且仅在必要的工作负载部分增加开销。", "conclusion": "LLM-42提供了一种有效的方法，在不牺牲性能的情况下为大型语言模型推理添加确定性，证明了其在实际应用中的可行性和优势。"}}
{"id": "2601.17767", "pdf": "https://arxiv.org/pdf/2601.17767", "abs": "https://arxiv.org/abs/2601.17767", "authors": ["Rajan Das Gupta", "Xiaobin Wu", "Xun Liu", "Jiaqi He"], "title": "HyCARD-Net: A Synergistic Hybrid Intelligence Framework for Cardiovascular Disease Diagnosis", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted and published in the 2025 4th International Conference on Image Processing, Computer Vision and Machine Learning (ICICML)", "summary": "Cardiovascular disease (CVD) remains the foremost cause of mortality worldwide, underscoring the urgent need for intelligent and data-driven diagnostic tools. Traditional predictive models often struggle to generalize across heterogeneous datasets and complex physiological patterns. To address this, we propose a hybrid ensemble framework that integrates deep learning architectures, Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM), with classical machine learning algorithms, including K-Nearest Neighbor (KNN) and Extreme Gradient Boosting (XGB), using an ensemble voting mechanism. This approach combines the representational power of deep networks with the interpretability and efficiency of traditional models. Experiments on two publicly available Kaggle datasets demonstrate that the proposed model achieves superior performance, reaching 82.30 percent accuracy on Dataset I and 97.10 percent on Dataset II, with consistent gains in precision, recall, and F1-score. These findings underscore the robustness and clinical potential of hybrid AI frameworks for predicting cardiovascular disease and facilitating early intervention. Furthermore, this study directly supports the United Nations Sustainable Development Goal 3 (Good Health and Well-being) by promoting early diagnosis, prevention, and management of non-communicable diseases through innovative, data-driven healthcare solutions.", "AI": {"tldr": "提出了一种结合深度学习和传统机器学习算法的混合智能框架HyCARD-Net，用于心血管疾病的诊断。", "motivation": "心血管疾病是全球首要死因，迫切需要智能化的数据驱动诊断工具。传统的预测模型在处理异构数据集和复杂生理模式时存在困难，因此提出了一种新的方法以提高心血管疾病预测的准确性和泛化能力。", "method": "该框架通过集成卷积神经网络（CNN）、长短期记忆网络（LSTM）与K-最近邻算法（KNN）及极端梯度提升（XGB），利用投票机制进行决策，结合深度网络的强大表征能力和传统模型的解释性和效率。", "result": "实验结果表明，HyCARD-Net在两个公开数据集上分别达到了82.30%和97.10%的准确率，并且提高了精确度、召回率和F1得分。", "conclusion": "研究证明了混合人工智能框架在心血管疾病预测中的稳健性和临床潜力，支持联合国可持续发展目标3（良好健康与福祉），通过创新的数据驱动医疗解决方案促进早期诊断、预防和管理非传染性疾病。"}}
{"id": "2601.17764", "pdf": "https://arxiv.org/pdf/2601.17764", "abs": "https://arxiv.org/abs/2601.17764", "authors": ["Md Asgor Hossain Reaj", "Rajan Das Gupta", "Jui Saha Pritha", "Abdullah Al Noman", "Abir Ahmed", "Golam Md Mohiuddin", "Tze Hui Liew"], "title": "Cross-Lingual Probing and Community-Grounded Analysis of Gender Bias in Low-Resource Bengali", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted in 2025 4th International Conference on Smart Cities, Automation & Intelligent Computing Systems (ICON-SONICS)", "summary": "Large Language Models (LLMs) have achieved significant success in recent years; yet, issues of intrinsic gender bias persist, especially in non-English languages. Although current research mostly emphasizes English, the linguistic and cultural biases inherent in Global South languages, like Bengali, are little examined. This research seeks to examine the characteristics and magnitude of gender bias in Bengali, evaluating the efficacy of current approaches in identifying and alleviating bias. We use several methods to extract gender-biased utterances, including lexicon-based mining, computational classification models, translation-based comparison analysis, and GPT-based bias creation. Our research indicates that the straight application of English-centric bias detection frameworks to Bengali is severely constrained by language disparities and socio-cultural factors that impact implicit biases. To tackle these difficulties, we executed two field investigations inside rural and low-income areas, gathering authentic insights on gender bias. The findings demonstrate that gender bias in Bengali presents distinct characteristics relative to English, requiring a more localized and context-sensitive methodology. Additionally, our research emphasizes the need of integrating community-driven research approaches to identify culturally relevant biases often neglected by automated systems. Our research enhances the ongoing discussion around gender bias in AI by illustrating the need to create linguistic tools specifically designed for underrepresented languages. This study establishes a foundation for further investigations into bias reduction in Bengali and other Indic languages, promoting the development of more inclusive and fair NLP systems.", "AI": {"tldr": "研究分析了低资源语言孟加拉语中的性别偏见，并探讨了现有方法在识别和减轻这种偏见方面的有效性。", "motivation": "尽管大型语言模型取得了显著成功，但内在的性别偏见问题仍然存在，特别是在非英语语言中。当前的研究主要集中在英语上，忽视了如孟加拉语这样的南亚语言中的语言和文化偏见。", "method": "研究采用词典挖掘、计算分类模型、翻译比较分析和GPT生成偏见等方法来提取性别偏见的表述，并在农村和低收入地区进行了实地调查以获得真实见解。", "result": "研究表明，直接将英语中心的偏见检测框架应用于孟加拉语受到语言差异和社会文化因素的影响。孟加拉语中的性别偏见表现出与英语不同的特征，需要更本地化和情景敏感的方法来解决这些偏见。", "conclusion": "研究强调了整合社区驱动的研究方法来识别自动化系统忽视的文化相关偏见的重要性，并为减少孟加拉语和其他印度语言的偏见奠定了基础，促进了更具包容性和公平性的NLP系统的开发。"}}
{"id": "2601.17761", "pdf": "https://arxiv.org/pdf/2601.17761", "abs": "https://arxiv.org/abs/2601.17761", "authors": ["Dongjie Cheng", "Ruifeng Yuan", "Yongqi Li", "Runyang You", "Wenjie Wang", "Liqiang Nie", "Lei Zhang", "Wenjie Li"], "title": "AR-Omni: A Unified Autoregressive Model for Any-to-Any Generation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Real-world perception and interaction are inherently multimodal, encompassing not only language but also vision and speech, which motivates the development of \"Omni\" MLLMs that support both multimodal inputs and multimodal outputs. While a sequence of omni MLLMs has emerged, most existing systems still rely on additional expert components to achieve multimodal generation, limiting the simplicity of unified training and inference. Autoregressive (AR) modeling, with a single token stream, a single next-token objective, and a single decoder, is an elegant and scalable foundation in the text domain. Motivated by this, we present AR-Omni, a unified any-to-any model in the autoregressive paradigm without any expert decoders. AR-Omni supports autoregressive text and image generation, as well as streaming speech generation, all under a single Transformer decoder. We further address three practical issues in unified AR modeling: modality imbalance via task-aware loss reweighting, visual fidelity via a lightweight token-level perceptual alignment loss for image tokens, and stability-creativity trade-offs via a finite-state decoding mechanism. Empirically, AR-Omni achieves strong quality across three modalities while remaining real-time, achieving a 0.88 real-time factor for speech generation.", "AI": {"tldr": "AR-Omni是一个统一的自回归模型，支持从任意输入到任意输出的生成。", "motivation": "现实世界的感知和交互是多模态的，现有系统通常依赖额外的专业组件来实现多模态生成，限制了训练和推断的简洁性。因此，开发一种不依赖专业解码器的统一模型成为研究动机。", "method": "AR-Omni采用单个Transformer解码器进行自回归文本、图像以及流式语音生成，并解决三个实际问题：通过任务感知损失重权衡处理模态不平衡；使用轻量级标记级别感知对齐损失提升视觉保真度；通过有限状态解码机制平衡稳定性和创造性。", "result": "实验结果表明，AR-Omni在文本、图像和语音三种模式下表现出强大的质量，并且保持实时性，在语音生成方面达到0.88的实时因子。", "conclusion": "该研究成功展示了AR-Omni作为统一模型的有效性，证明了其跨模态自回归生成能力和实时性能。"}}
{"id": "2601.17756", "pdf": "https://arxiv.org/pdf/2601.17756", "abs": "https://arxiv.org/abs/2601.17756", "authors": ["Ziyang Song", "Xinyu Gong", "Bangya Liu", "Zelin Zhao"], "title": "MV-S2V: Multi-View Subject-Consistent Video Generation", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": "13 pages, 9 figures", "summary": "Existing Subject-to-Video Generation (S2V) methods have achieved high-fidelity and subject-consistent video generation, yet remain constrained to single-view subject references. This limitation renders the S2V task reducible to an S2I + I2V pipeline, failing to exploit the full potential of video subject control. In this work, we propose and address the challenging Multi-View S2V (MV-S2V) task, which synthesizes videos from multiple reference views to enforce 3D-level subject consistency. Regarding the scarcity of training data, we first develop a synthetic data curation pipeline to generate highly customized synthetic data, complemented by a small-scale real-world captured dataset to boost the training of MV-S2V. Another key issue lies in the potential confusion between cross-subject and cross-view references in conditional generation. To overcome this, we further introduce Temporally Shifted RoPE (TS-RoPE) to distinguish between different subjects and distinct views of the same subject in reference conditioning. Our framework achieves superior 3D subject consistency w.r.t. multi-view reference images and high-quality visual outputs, establishing a new meaningful direction for subject-driven video generation. Our project page is available at <a href=\"https://szy-young.github.io/mv-s2v\">this URL</a>", "AI": {"tldr": "本文提出了MV-S2V框架，用于从多个视角的参考图像生成视频，并保持三维级别的一致性。", "motivation": "现有方法只能处理单视图下的主题到视频（S2V）生成任务，这限制了其潜力。为解决这一问题并提高3D层面的主题一致性，作者提出了MV-S2V框架。", "method": "开发了一个合成数据管道来生成定制的训练数据，并引入了TS-RoPE以区分参考条件中的不同主题和同一主题的不同视角。", "result": "该框架在多视图参考图像中实现了卓越的3D主题一致性，并产生了高质量的视频输出。", "conclusion": "MV-S2V为基于主题驱动的视频生成建立了新的方向，展示了通过多个视角实现高质量视频生成的能力。"}}
{"id": "2601.17754", "pdf": "https://arxiv.org/pdf/2601.17754", "abs": "https://arxiv.org/abs/2601.17754", "authors": ["Nicolai Stawinoga", "David Katz", "Anton Lydike", "Justs Zarins", "Nick Brown", "George Bisbas", "Tobias Grosser"], "title": "An MLIR Lowering Pipeline for Stencils at Wafer-Scale", "categories": ["cs.DC", "cs.ET", "cs.PL"], "comment": "Paper in ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS '26)", "summary": "The Cerebras Wafer-Scale Engine (WSE) delivers performance at an unprecedented scale of over 900,000 compute units, all connected via a single-wafer on-chip interconnect. Initially designed for AI, the WSE architecture is also well-suited for High Performance Computing (HPC). However, its distributed asynchronous programming model diverges significantly from the simple sequential or bulk-synchronous programs that one would typically derive for a given mathematical program description. Targeting the WSE requires a bespoke re-implementation when porting existing code. The absence of WSE support in compilers such as MLIR, meant that there was little hope for automating this process. Stencils are ubiquitous in HPC, and in this paper we explore the hypothesis that domain specific information about stencils can be leveraged by the compiler to automatically target the WSE without requiring application-level code changes. We present a compiler pipeline that transforms stencil-based kernels into highly optimized CSL code for the WSE, bridging the semantic gap between the mathematical representation of the problem and the WSE's asynchronous execution model. Based upon five benchmarks across three HPC programming technologies, running on both the Cerebras WSE2 and WSE3, our approach delivers comparable, if not slightly better, performance than manually optimized code. Furthermore, without requiring any application level code changes, performance on the WSE3 is around 14 times faster than 128 Nvidia A100 GPUs and 20 times faster than 128 nodes of a CPU-based Cray-EX supercomputer when using our approach.", "AI": {"tldr": "该论文介绍了一个针对Cerebras Wafer-Scale Engine (WSE)的MLIR降低管道，用于自动优化HPC中的Stencil计算。", "motivation": "由于WSE的独特分布式异步编程模型与传统程序编写方式差异显著，目标化WSE需要重写现有代码。然而，现有的编译器如MLIR不支持WSE，限制了自动化过程的可能性。", "method": "论文提出了一种新的编译管道，能够将基于Stencil的内核转换为高度优化的CSL（Cerebras软件语言）代码，以便在WSE上执行。", "result": "通过五个基准测试和三种HPC编程技术，在Cerebras WSE2和WSE3上的性能表现与手动优化代码相当或稍优。使用该方法时，相较于128个Nvidia A100 GPU和基于CPU的Cray-EX超级计算机的128节点，性能分别提高了约14倍和20倍。", "conclusion": "研究证实了通过编译器优化可以自动将Stencil程序转换为适应WSE异步执行模型的高度优化代码，而无需修改应用程序源码。"}}
{"id": "2601.17749", "pdf": "https://arxiv.org/pdf/2601.17749", "abs": "https://arxiv.org/abs/2601.17749", "authors": ["Kyriakos Stylianopoulos", "Mattia Fabiani", "Giulia Torcolacci", "Davide Dardari", "George C. Alexandropoulos"], "title": "Over-The-Air Extreme Learning Machines with XL Reception via Nonlinear Cascaded Metasurfaces", "categories": ["eess.SP", "cs.ET", "cs.LG", "cs.NE"], "comment": "6 pages, 5 figures, to be presented at a conference", "summary": "The recently envisioned goal-oriented communications paradigm calls for the application of inference on wirelessly transferred data via Machine Learning (ML) tools. An emerging research direction deals with the realization of inference ML models directly in the physical layer of Multiple-Input Multiple-Output (MIMO) systems, which, however, entails certain significant challenges. In this paper, leveraging the technology of programmable MetaSurfaces (MSs), we present an eXtremely Large (XL) MIMO system that acts as an Extreme Learning Machine (ELM) performing binary classification tasks completely Over-The-Air (OTA), which can be trained in closed form. The proposed system comprises a receiver architecture consisting of densely parallel placed diffractive layers of XL MSs followed by a single reception radio-frequency chain. The front layer facing the MIMO channel consists of identical unit cells of a fixed NonLinear (NL) response, while the remaining layers of elements of tunable linear responses are utilized to approximate OTA the trained ELM weights. Our numerical investigations showcase that, in the XL regime of MS elements, the proposed XL-MIMO-ELM system achieves performance comparable to that of digital and idealized ML models across diverse datasets and wireless scenarios, thereby demonstrating the feasibility of embedding OTA learning capabilities into future communication systems.", "AI": {"tldr": "本文介绍了一种通过使用可编程元表面技术实现的极大型MIMO系统，该系统作为极端学习机（ELM）在空中完全执行二元分类任务，并能够闭式训练。", "motivation": "目标导向通信范式要求在无线传输的数据上应用机器学习工具进行推理，而将这些模型直接实现在多输入多输出系统的物理层面临挑战。本文旨在通过非线性级联元表面技术解决这些问题。", "method": "利用可编程元表面技术构建一个极大型MIMO系统，该系统作为极端学习机在空中执行二元分类任务。系统包含接收架构，由密集排列的超大规模元表面衍射层和单个无线电链路组成。前一层具有固定非线性响应，后续层使用调谐线性响应来近似训练好的ELM权重。", "result": "数值研究显示，在大规模元表面元件的情况下，所提出的XL-MIMO-ELM系统在不同的数据集和无线场景中实现了与数字和理想化的机器学习模型相当的性能，证明了嵌入空中学习能力在未来通信系统的可行性。", "conclusion": "该研究表明通过非线性级联元表面技术实现极大型MIMO系统作为极端学习机在空中完全执行二元分类任务是可行的，并且具有与传统数字和理想化机器学习模型相媲美的性能。"}}
{"id": "2601.17747", "pdf": "https://arxiv.org/pdf/2601.17747", "abs": "https://arxiv.org/abs/2601.17747", "authors": ["Kaixuan Jiang", "Chen Wu", "Zhenghui Zhao", "Chengxi Han"], "title": "Bridging Supervision Gaps: A Unified Framework for Remote Sensing Change Detection", "categories": ["cs.CV"], "comment": null, "summary": "Change detection (CD) aims to identify surface changes from multi-temporal remote sensing imagery. In real-world scenarios, Pixel-level change labels are expensive to acquire, and existing models struggle to adapt to scenarios with diverse annotation availability. To tackle this challenge, we propose a unified change detection framework (UniCD), which collaboratively handles supervised, weakly-supervised, and unsupervised tasks through a coupled architecture. UniCD eliminates architectural barriers through a shared encoder and multi-branch collaborative learning mechanism, achieving deep coupling of heterogeneous supervision signals. Specifically, UniCD consists of three supervision-specific branches. In the supervision branch, UniCD introduces the spatial-temporal awareness module (STAM), achieving efficient synergistic fusion of bi-temporal features. In the weakly-supervised branch, we construct change representation regularization (CRR), which steers model convergence from coarse-grained activations toward coherent and separable change modeling. In the unsupervised branch, we propose semantic prior-driven change inference (SPCI), which transforms unsupervised tasks into controlled weakly-supervised path optimization. Experiments on mainstream datasets demonstrate that UniCD achieves optimal performance across three tasks. It exhibits significant accuracy improvements in weakly and unsupervised scenarios, surpassing current state-of-the-art by 12.72% and 12.37% on LEVIR-CD, respectively.", "AI": {"tldr": "本文提出了一个统一的变化检测框架UniCD，用于处理监督、弱监督和无监督的任务。", "motivation": "在现实世界中获取像素级别的变化标签成本高昂，并且现有模型难以适应不同标注可用性的情景。因此需要一种可以应对各种标注情况的解决方案。", "method": "UniCD采用共享编码器和多分支协作学习机制，包括监督、弱监督和无监督三个特定分支。在监督分支中引入了时空感知模块，在弱监督分支中构建变化表示正则化，在无监督分支中提出了语义先验驱动的变化推理。", "result": "实验结果表明，UniCD在三大任务上均表现出色，尤其是在弱监督和无监督场景下的准确性提升显著，分别比现有最先进方法高出12.72%和12.37%（以LEVIR-CD数据集为例）。", "conclusion": "本文提出的UniCD框架通过消除架构障碍并深入耦合异质监督信号，有效地提高了在不同标注情况下变化检测任务的性能。"}}
{"id": "2601.17744", "pdf": "https://arxiv.org/pdf/2601.17744", "abs": "https://arxiv.org/abs/2601.17744", "authors": ["Amjad Fatmi"], "title": "Faramesh: A Protocol-Agnostic Execution Control Plane for Autonomous Agent Systems", "categories": ["cs.AI", "cs.CR", "cs.DC"], "comment": "40 pages, 10 figures. Preprint. Code: https://github.com/faramesh/faramesh-core", "summary": "Autonomous agent systems increasingly trigger real-world side effects: deploying infrastructure, modifying databases, moving money, and executing workflows. Yet most agent stacks provide no mandatory execution checkpoint where organizations can deterministically permit, deny, or defer an action before it changes reality. This paper introduces Faramesh, a protocol-agnostic execution control plane that enforces execution-time authorization for agent-driven actions via a non-bypassable Action Authorization Boundary (AAB). Faramesh canonicalizes agent intent into a Canonical Action Representation (CAR), evaluates actions deterministically against policy and state, and issues a decision artifact (PERMIT/DEFER/DENY) that executors must validate prior to execution. The system is designed to be framework- and model-agnostic, supports multi-agent and multi-tenant deployments, and remains independent of transport protocols (e.g., MCP). Faramesh further provides decision-centric, append-only provenance logging keyed by canonical action hashes, enabling auditability, verification, and deterministic replay without re-running agent reasoning. We show how these primitives yield enforceable, predictable governance for autonomous execution while avoiding hidden coupling to orchestration layers or observability-only approaches.", "AI": {"tldr": "本文介绍了Faramesh，一个协议无关的执行控制平面，用于自主代理系统中强制执行行动授权。", "motivation": "大多数代理堆栈在触发实际世界影响之前没有提供确定性的许可、拒绝或延迟机制，因此引入了Faramesh来解决这一问题。", "method": "通过非绕过的行为授权边界（AAB），将代理意图标准化为一个规范动作表示（CAR），并基于策略和状态做出决策（PERMIT/DEFER/DENY）。", "result": "展示了如何使用这些原语实现可执行、预测性的自主行动治理，同时避免与编排层的隐藏耦合或仅用于可观测性方法的问题。", "conclusion": "Faramesh提供了一个框架和模型无关的支持多代理和多租户部署系统，并独立于传输协议，实现了审计性、验证性和确定性回放。"}}
{"id": "2601.17743", "pdf": "https://arxiv.org/pdf/2601.17743", "abs": "https://arxiv.org/abs/2601.17743", "authors": ["Jun Zhu", "Xinfeng Zhang", "Lv Tang", "Junhao Jiang", "Gai Zhang", "Jia Wang"], "title": "Video Compression with Hierarchical Temporal Neural Representation", "categories": ["cs.CV"], "comment": null, "summary": "Video compression has recently benefited from implicit neural representations (INRs), which model videos as continuous functions. INRs offer compact storage and flexible reconstruction, providing a promising alternative to traditional codecs. However, most existing INR-based methods treat the temporal dimension as an independent input, limiting their ability to capture complex temporal dependencies. To address this, we propose a Hierarchical Temporal Neural Representation for Videos, TeNeRV. TeNeRV integrates short- and long-term dependencies through two key components. First, an Inter-Frame Feature Fusion (IFF) module aggregates features from adjacent frames, enforcing local temporal coherence and capturing fine-grained motion. Second, a GoP-Adaptive Modulation (GAM) mechanism partitions videos into Groups-of-Pictures and learns group-specific priors. The mechanism modulates network parameters, enabling adaptive representations across different GoPs. Extensive experiments demonstrate that TeNeRV consistently outperforms existing INR-based methods in rate-distortion performance, validating the effectiveness of our proposed approach.", "AI": {"tldr": "本文提出了一种名为TeNeRV的分层时序神经视频表示方法，以提高基于隐式神经表示的视频压缩性能。", "motivation": "现有的隐式神经表示方法在处理视频压缩时，通常将时间维度作为独立输入，限制了其捕捉复杂时序依赖的能力。因此，本文旨在通过改进方法来提升视频压缩效果。", "method": "TeNeRV包含两个关键组件：跨帧特征融合（IFF）模块和GoP自适应调制（GAM）机制。前者聚合相邻帧的特征以确保局部时间一致性和捕捉细粒度运动；后者将视频划分为图像组，学习特定组的先验信息，并调整网络参数实现不同GoPs的自适应表示。", "result": "实验结果表明，TeNeRV在率失真性能上持续优于现有的基于隐式神经表示的方法，证明了该方法的有效性。", "conclusion": "提出的TeNeRV方法通过整合短时和长时依赖关系提升了视频压缩效果，验证了其在这一领域的优越性和潜力。"}}
{"id": "2601.17741", "pdf": "https://arxiv.org/pdf/2601.17741", "abs": "https://arxiv.org/abs/2601.17741", "authors": ["Jun Zhu", "Xinfeng Zhang", "Lv Tang", "Junhao Jiang", "Gai Zhang", "Jia Wang"], "title": "Frequency-aware Neural Representation for Videos", "categories": ["cs.CV"], "comment": null, "summary": "Implicit Neural Representations (INRs) have emerged as a promising paradigm for video compression. However, existing INR-based frameworks typically suffer from inherent spectral bias, which favors low-frequency components and leads to over-smoothed reconstructions and suboptimal rate-distortion performance. In this paper, we propose FaNeRV, a Frequency-aware Neural Representation for videos, which explicitly decouples low- and high-frequency components to enable efficient and faithful video reconstruction. FaNeRV introduces a multi-resolution supervision strategy that guides the network to progressively capture global structures and fine-grained textures through staged supervision . To further enhance high-frequency reconstruction, we propose a dynamic high-frequency injection mechanism that adaptively emphasizes challenging regions. In addition, we design a frequency-decomposed network module to improve feature modeling across different spectral bands. Extensive experiments on standard benchmarks demonstrate that FaNeRV significantly outperforms state-of-the-art INR methods and achieves competitive rate-distortion performance against traditional codecs.", "AI": {"tldr": "本文提出了FaNeRV，一种频率感知的神经视频表示方法，旨在克服现有基于INR框架的频谱偏差问题，以实现更高效的视频重建。", "motivation": "现有的基于隐式神经表征的方法在处理视频压缩时存在频谱偏向性问题，导致低频成分过度平滑和次优的率失真性能。因此，需要开发一种新的方法来改善这种情况。", "method": "FaNeRV采用多分辨率监督策略、动态高频注入机制以及频率分解网络模块来分别解决全局结构捕捉、细粒度纹理增强及跨不同光谱带特征建模的问题。", "result": "实验结果表明，相较于现有的INR方法和传统编解码器，FaNeRV在标准基准测试上取得了显著的性能提升。", "conclusion": "研究表明，频率感知的神经视频表示方法能够有效克服现有基于隐式神经表征框架的不足，并实现更好的率失真表现。"}}
{"id": "2601.17740", "pdf": "https://arxiv.org/pdf/2601.17740", "abs": "https://arxiv.org/abs/2601.17740", "authors": ["Cong Cao", "Ren Li", "Corentin Dumery", "Hao Li"], "title": "Learning Sewing Patterns via Latent Flow Matching of Implicit Fields", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "Sewing patterns define the structural foundation of garments and are essential for applications such as fashion design, fabrication, and physical simulation. Despite progress in automated pattern generation, accurately modeling sewing patterns remains difficult due to the broad variability in panel geometry and seam arrangements. In this work, we introduce a sewing pattern modeling method based on an implicit representation. We represent each panel using a signed distance field that defines its boundary and an unsigned distance field that identifies seam endpoints, and encode these fields into a continuous latent space that enables differentiable meshing. A latent flow matching model learns distributions over panel combinations in this representation, and a stitching prediction module recovers seam relations from extracted edge segments. This formulation allows accurate modeling and generation of sewing patterns with complex structures. We further show that it can be used to estimate sewing patterns from images with improved accuracy relative to existing approaches, and supports applications such as pattern completion and refitting, providing a practical tool for digital fashion design.", "AI": {"tldr": "本文提出了一种基于隐式表示的缝纫图案建模方法，能够准确地生成和模拟具有复杂结构的缝纫图案，并能从图像中估计缝纫图案。", "motivation": "尽管在自动化图案生成方面取得了进展，但由于衣片几何形状和缝线排列的巨大变化性，准确建模缝纫图案仍然面临挑战。", "method": "本文使用隐式表示方法，通过正负距离场来定义每个衣片的边界及缝线端点，并将其编码到连续潜在空间中以实现可微网格化。利用潜在流匹配模型学习这些表示中的衣片组合分布，并通过一个缝合预测模块恢复从提取边段中的缝线关系。", "result": "该方法能够准确地建模和生成具有复杂结构的缝纫图案，且能比现有方法更精确地从图像中估计缝纫图案。此外，它还支持如图案补全和重新拟合的应用。", "conclusion": "本文提出的方法为数字时装设计提供了一个实用工具，能够在不同应用场合下准确建模缝纫图案，并提升了基于图像的缝纫图案估计精度。"}}
{"id": "2601.17737", "pdf": "https://arxiv.org/pdf/2601.17737", "abs": "https://arxiv.org/abs/2601.17737", "authors": ["Chenyu Mu", "Xin He", "Qu Yang", "Wanshun Chen", "Jiadi Yao", "Huang Liu", "Zihao Yi", "Bo Zhao", "Xingyu Chen", "Ruotian Ma", "Fanghua Ye", "Erkun Yang", "Cheng Deng", "Zhaopeng Tu", "Xiaolong Li", "Linus"], "title": "The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advances in video generation have produced models capable of synthesizing stunning visual content from simple text prompts. However, these models struggle to generate long-form, coherent narratives from high-level concepts like dialogue, revealing a ``semantic gap'' between a creative idea and its cinematic execution. To bridge this gap, we introduce a novel, end-to-end agentic framework for dialogue-to-cinematic-video generation. Central to our framework is ScripterAgent, a model trained to translate coarse dialogue into a fine-grained, executable cinematic script. To enable this, we construct ScriptBench, a new large-scale benchmark with rich multimodal context, annotated via an expert-guided pipeline. The generated script then guides DirectorAgent, which orchestrates state-of-the-art video models using a cross-scene continuous generation strategy to ensure long-horizon coherence. Our comprehensive evaluation, featuring an AI-powered CriticAgent and a new Visual-Script Alignment (VSA) metric, shows our framework significantly improves script faithfulness and temporal fidelity across all tested video models. Furthermore, our analysis uncovers a crucial trade-off in current SOTA models between visual spectacle and strict script adherence, providing valuable insights for the future of automated filmmaking.", "AI": {"tldr": "本文提出了一种新的端到端代理框架，用于将对话转化为连贯的电影视频。", "motivation": "现有模型难以从高层次的概念如对话生成长篇、连贯的故事，存在创意想法与实际影视制作之间的语义鸿沟。", "method": "该框架包含ScripterAgent，用于将粗略对话转化为详细的可执行影视脚本；DirectorAgent，使用跨场景连续生成策略来保证长时间的连贯性。", "result": "综合评估显示，该框架显著提高了剧本忠实度和时间一致性，并揭示了当前顶尖模型在视觉震撼与严格遵循剧本之间的权衡。", "conclusion": "该研究为自动电影制作提供了有价值的见解。"}}
{"id": "2601.17736", "pdf": "https://arxiv.org/pdf/2601.17736", "abs": "https://arxiv.org/abs/2601.17736", "authors": ["Can Liu", "Jaeuk Lee", "Tianhe Chen", "Zhibang Jiang", "Xiaolin Wen", "Yong Wang"], "title": "Athanor: Authoring Action Modification-based Interactions on Static Visualizations via Natural Language", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Interactivity is crucial for effective data visualizations. However, it is often challenging to implement interactions for existing static visualizations, since the underlying code and data for existing static visualizations are often not available, and it also takes significant time and effort to enable interactions for them even if the original code and data are available. To fill this gap, we propose Athanor, a novel approach to transform existing static visualizations into interactive ones using multimodal large language models (MLLMs) and natural language instructions. Our approach introduces three key innovations: (1) an action-modification interaction design space that maps visualization interactions into user actions and corresponding adjustments, (2) a multi-agent requirement analyzer that translates natural language instructions into an actionable operational space, and (3) a visualization abstraction transformer that converts static visualizations into flexible and interactive representations regardless of their underlying implementation. Athanor allows users to effortlessly author interactions through natural language instructions, eliminating the need for programming. We conducted two case studies and in-depth interviews with target users to evaluate our approach. The results demonstrate the effectiveness and usability of our approach in allowing users to conveniently enable flexible interactions for static visualizations.", "AI": {"tldr": "本文提出Athanor，一种通过自然语言指令和多模态大型语言模型将现有静态可视化转换为交互式可视化的新型方法。", "motivation": "现有的静态可视化难以实现互动功能，因为其底层代码和数据通常不可用或需要大量的时间和精力来实现互动性。为此，提出Athanor以弥补这一差距。", "method": "该方法包括三个创新点：1) 一种映射可视化交互到用户操作及相应调整的动作-修改交互设计空间；2) 将自然语言指令转换为可执行操作空间的多代理需求分析器；3) 转换静态可视化为灵活、交互式表示的可视化抽象变换器。", "result": "通过两个案例研究和与目标用户的深度访谈，结果证明该方法在使用户方便地启用静态可视化的灵活互动方面有效且易于使用。", "conclusion": "Athanor允许用户无需编程即可轻松创建交互操作，展示了其将现有静态可视化转换为交互式可视化的潜力。"}}
{"id": "2601.17735", "pdf": "https://arxiv.org/pdf/2601.17735", "abs": "https://arxiv.org/abs/2601.17735", "authors": ["Kyungho Kim", "Geon Lee", "Juyeon Kim", "Dongwon Choi", "Shinhwan Kang", "Kijung Shin"], "title": "ReFuGe: Feature Generation for Prediction Tasks on Relational Databases with LLM Agents", "categories": ["cs.AI"], "comment": "Accepted in ACM WWW 2026 (Short Paper)", "summary": "Relational databases (RDBs) play a crucial role in many real-world web applications, supporting data management across multiple interconnected tables. Beyond typical retrieval-oriented tasks, prediction tasks on RDBs have recently gained attention. In this work, we address this problem by generating informative relational features that enhance predictive performance. However, generating such features is challenging: it requires reasoning over complex schemas and exploring a combinatorially large feature space, all without explicit supervision. To address these challenges, we propose ReFuGe, an agentic framework that leverages specialized large language model agents: (1) a schema selection agent identifies the tables and columns relevant to the task, (2) a feature generation agent produces diverse candidate features from the selected schema, and (3) a feature filtering agent evaluates and retains promising features through reasoning-based and validation-based filtering. It operates within an iterative feedback loop until performance converges. Experiments on RDB benchmarks demonstrate that ReFuGe substantially improves performance on various RDB prediction tasks. Our code and datasets are available at https://github.com/K-Kyungho/REFUGE.", "AI": {"tldr": "本文介绍了ReFuGe框架，用于生成有助于预测任务的特征，这些任务基于关系数据库中的数据。", "motivation": "随着对在关系数据库上进行预测任务的兴趣增加，而生成有效的预测特征具有挑战性，因为这需要理解复杂的模式并探索大量的特征空间。", "method": "ReFuGe框架包含三个专门的大语言模型代理：用于选择相关表和列的schema选择代理、用于从选定模式中生成候选特征的功能生成代理、以及通过推理和验证过滤保留有前景功能的功能筛选代理。", "result": "在关系数据库基准上的实验显示，ReFuGe显著提高了各种预测任务的表现。", "conclusion": "ReFuGe框架利用大语言模型代理成功解决了基于复杂模式的关系数据的预测特征生成问题，并在其上实现了性能改进。"}}
{"id": "2601.17733", "pdf": "https://arxiv.org/pdf/2601.17733", "abs": "https://arxiv.org/abs/2601.17733", "authors": ["Junran Lu", "Yuanqi Li", "Hengji Li", "Jie Guo", "Yanwen Guo"], "title": "Flatten The Complex: Joint B-Rep Generation via Compositional $k$-Cell Particles", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "Boundary Representation (B-Rep) is the widely adopted standard in Computer-Aided Design (CAD) and manufacturing. However, generative modeling of B-Reps remains a formidable challenge due to their inherent heterogeneity as geometric cell complexes, which entangles topology with geometry across cells of varying orders (i.e., $k$-cells such as vertices, edges, faces). Previous methods typically rely on cascaded sequences to handle this hierarchy, which fails to fully exploit the geometric relationships between cells, such as adjacency and sharing, limiting context awareness and error recovery. To fill this gap, we introduce a novel paradigm that reformulates B-Reps into sets of compositional $k$-cell particles. Our approach encodes each topological entity as a composition of particles, where adjacent cells share identical latents at their interfaces, thereby promoting geometric coupling along shared boundaries. By decoupling the rigid hierarchy, our representation unifies vertices, edges, and faces, enabling the joint generation of topology and geometry with global context awareness. We synthesize these particle sets using a multi-modal flow matching framework to handle unconditional generation as well as precise conditional tasks, such as 3D reconstruction from single-view or point cloud. Furthermore, the explicit and localized nature of our representation naturally extends to downstream tasks like local in-painting and enables the direct synthesis of non-manifold structures (e.g., wireframes). Extensive experiments demonstrate that our method produces high-fidelity CAD models with superior validity and editability compared to state-of-the-art methods.", "AI": {"tldr": "本文提出了一种新的B-Rep生成模型，通过将几何结构分解为$k$-cell粒子集合来联合生成拓扑和几何结构。", "motivation": "现有的B-Rep生成方法在处理几何细胞复合体的层次关系时存在局限性，未能充分利用细胞间的几何关联。", "method": "本文提出了一种新的范式，将B-Reps重新表述为一组组合$k$-cell粒子，并使用多模态流匹配框架来合成这些粒子集合，实现无条件和精确有条件的任务生成。", "result": "实验表明，该方法在产生高保真CAD模型方面具有优越的有效性和可编辑性。", "conclusion": "本文的方法通过重新定义B-Reps结构并利用$k$-cell粒子集合实现了更高效、更具上下文意识的几何和拓扑联合生成。"}}
{"id": "2601.17723", "pdf": "https://arxiv.org/pdf/2601.17723", "abs": "https://arxiv.org/abs/2601.17723", "authors": ["Tayyab Nasir", "Daochang Liu", "Ajmal Mian"], "title": "Implicit Neural Representation-Based Continuous Single Image Super Resolution: An Empirical Study", "categories": ["cs.CV"], "comment": null, "summary": "Implicit neural representation (INR) has become the standard approach for arbitrary-scale image super-resolution (ASSR). To date, no empirical study has systematically examined the effectiveness of existing methods, nor investigated the effects of different training recipes, such as scaling laws, objective design, and optimization strategies. A rigorous empirical analysis is essential not only for benchmarking performance and revealing true gains but also for establishing the current state of ASSR, identifying saturation limits, and highlighting promising directions. We fill this gap by comparing existing techniques across diverse settings and presenting aggregated performance results on multiple image quality metrics. We contribute a unified framework and code repository to facilitate reproducible comparisons. Furthermore, we investigate the impact of carefully controlled training configurations on perceptual image quality and examine a new loss function that penalizes intensity variations while preserving edges, textures, and finer details during training. We conclude the following key insights that have been previously overlooked: (1) Recent, more complex INR methods provide only marginal improvements over earlier methods. (2) Model performance is strongly correlated to training configurations, a factor overlooked in prior works. (3) The proposed loss enhances texture fidelity across architectures, emphasizing the role of objective design for targeted perceptual gains. (4) Scaling laws apply to INR-based ASSR, confirming predictable gains with increased model complexity and data diversity.", "AI": {"tldr": "本文通过隐式神经表示（INR）方法研究了任意尺度图像超分辨率（ASSR），并提供了系统性的实证分析。", "motivation": "现有文献缺乏对不同训练配方效果的全面研究，如缩放定律、目标设计和优化策略。本研究旨在弥补这一空白，并确立ASSR领域的发展现状。", "method": "比较了不同的现有技术在多种设置下的表现，并提出了一种新的损失函数以提升纹理保真度。", "result": "研究表明最近的复杂INR方法相比早期方法只有微小改进，模型性能与训练配置紧密相关。此外，提出的损失函数增强了图像细节的表现力，证实了目标设计对感知效果的重要性。", "conclusion": "研究揭示了ASSR领域的一些被忽视的关键见解：复杂的INR方法仅提供边际改善；模型表现受制于训练配置；新的损失函数有助于提升纹理保真度；缩放定律适用于基于INR的ASSR，增加模型复杂性和数据多样性可带来预测性收益。"}}
{"id": "2601.17722", "pdf": "https://arxiv.org/pdf/2601.17722", "abs": "https://arxiv.org/abs/2601.17722", "authors": ["Ying Mo", "Yu Bai", "Dapeng Sun", "Yuqian Shi", "Yukai Miao", "Li Chen", "Dan Li"], "title": "EntWorld: A Holistic Environment and Benchmark for Verifiable Enterprise GUI Agents", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have enabled agents to operate in open-ended web and operating system environments. However, existing benchmarks predominantly target consumer-oriented scenarios (e.g., e-commerce and travel booking), failing to capture the complexity and rigor of professional enterprise workflows. Enterprise systems pose distinct challenges, including high-density user interfaces, strict business logic constraints, and a strong reliance on precise, state-consistent information retrieval-settings in which current generalist agents often struggle. To address this gap, we introduce EntWorld, a large-scale benchmark consisting of 1,756 tasks across six representative enterprise domains, including customer relationship management (CRM), information technology infrastructure library (ITIL), and enterprise resource planning (ERP) systems. Unlike previous datasets that depend on fragile execution traces or extensive manual annotation, EntWorld adopts a schema-grounded task generation framework that directly reverse-engineers business logic from underlying database schemas, enabling the synthesis of realistic, long-horizon workflows. Moreover, we propose a SQL-based deterministic verification mechanism in building datasets that replaces ambiguous visual matching with rigorous state-transition validation. Experimental results demonstrate that state-of-the-art models (e.g., GPT-4.1) achieve 47.61% success rate on EntWorld, substantially lower than the human performance, highlighting a pronounced enterprise gap in current agentic capabilities and the necessity of developing domain-specific agents. We release EntWorld as a rigorous testbed to facilitate the development and evaluation of the next generation of enterprise-ready digital agents.", "AI": {"tldr": "介绍EntWorld，一个面向企业级环境的基准测试平台，包含多个领域的任务，旨在评估和促进企业级GUI代理的发展。", "motivation": "现有基准主要针对消费场景，未能涵盖专业企业工作流程的复杂性和严格性。为了填补这一空白，作者提出了EntWorld来解决当前通用智能体在处理企业系统时遇到的问题。", "method": "EntWorld通过基于模式的任务生成框架从底层数据库模式中反向工程出业务逻辑，合成了包含1,756个任务的真实长期工作流程，并采用SQL基础的确定性验证机制以确保数据集质量。", "result": "实验结果表明，最先进的模型（如GPT-4.1）在EntWorld上的成功率仅为47.61%，远低于人类表现，凸显了现有代理在企业场景中的能力差距和开发领域特定智能体的需求。", "conclusion": "发布EntWorld作为严格测试平台，以促进下一代针对企业的数字智能体的发展与评估。"}}
{"id": "2601.17720", "pdf": "https://arxiv.org/pdf/2601.17720", "abs": "https://arxiv.org/abs/2601.17720", "authors": ["Ting-Hsun Chi", "Chu-Rong Chen", "Chi-Tun Hsu", "Hsuan-Ting Lin", "Sheng-Yu Huang", "Cheng Sun", "Yu-Chiang Frank Wang"], "title": "Advancing Structured Priors for Sparse-Voxel Surface Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Reconstructing accurate surfaces with radiance fields has progressed rapidly, yet two promising explicit representations, 3D Gaussian Splatting and sparse-voxel rasterization, exhibit complementary strengths and weaknesses. 3D Gaussian Splatting converges quickly and carries useful geometric priors, but surface fidelity is limited by its point-like parameterization. Sparse-voxel rasterization provides continuous opacity fields and crisp geometry, but its typical uniform dense-grid initialization slows convergence and underutilizes scene structure. We combine the advantages of both by introducing a voxel initialization method that places voxels at plausible locations and with appropriate levels of detail, yielding a strong starting point for per-scene optimization. To further enhance depth consistency without blurring edges, we propose refined depth geometry supervision that converts multi-view cues into direct per-ray depth regularization. Experiments on standard benchmarks demonstrate improvements over prior methods in geometric accuracy, better fine-structure recovery, and more complete surfaces, while maintaining fast convergence.", "AI": {"tldr": "本文提出了一种结合3D高斯散斑和稀疏体素光栅化的表面重建方法，通过优化初始体素设置和深度几何监督来提高几何准确性、细节恢复能力和表面完整性。", "motivation": "当前的显式表示法存在各自的优缺点，作者希望通过整合3D高斯散斑（快速收敛和有用的几何先验）与稀疏体素光栅化（连续不透明场和清晰几何），来改善表面重建的质量。", "method": "提出了一种新的初始化方法，用于在合理的位置放置体素并以适当的细节水平进行设置，以及一种改进的深度几何监督方法，将多视图线索转化为直接每光线深度正则化。", "result": "实验结果表明，在标准基准测试中，该方法在几何准确性、细结构恢复和更完整的表面重建方面优于先前的方法，并保持了快速收敛性。", "conclusion": "通过结合3D高斯散斑与稀疏体素光栅化的优点并提出改进的初始化和监督方法，本文提出了一个高效的表面重建方案，显著改善了几何准确性、细节恢复能力和表面完整性。"}}
{"id": "2601.17717", "pdf": "https://arxiv.org/pdf/2601.17717", "abs": "https://arxiv.org/abs/2601.17717", "authors": ["Kaituo Zhang", "Mingzhi Hu", "Hoang Anh Duy Le", "Fariha Kabir Torsha", "Zhimeng Jiang", "Minh Khai Bui", "Chia-Yuan Chang", "Yu-Neng Chuang", "Zhen Xiong", "Ying Lin", "Guanchu Wang", "Na Zou"], "title": "The LLM Data Auditor: A Metric-oriented Survey on Quality and Trustworthiness in Evaluating Synthetic Data", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have emerged as powerful tools for generating data across various modalities. By transforming data from a scarce resource into a controllable asset, LLMs mitigate the bottlenecks imposed by the acquisition costs of real-world data for model training, evaluation, and system iteration. However, ensuring the high quality of LLM-generated synthetic data remains a critical challenge. Existing research primarily focuses on generation methodologies, with limited direct attention to the quality of the resulting data. Furthermore, most studies are restricted to single modalities, lacking a unified perspective across different data types. To bridge this gap, we propose the \\textbf{LLM Data Auditor framework}. In this framework, we first describe how LLMs are utilized to generate data across six distinct modalities. More importantly, we systematically categorize intrinsic metrics for evaluating synthetic data from two dimensions: quality and trustworthiness. This approach shifts the focus from extrinsic evaluation, which relies on downstream task performance, to the inherent properties of the data itself. Using this evaluation system, we analyze the experimental evaluations of representative generation methods for each modality and identify substantial deficiencies in current evaluation practices. Based on these findings, we offer concrete recommendations for the community to improve the evaluation of data generation. Finally, the framework outlines methodologies for the practical application of synthetic data across different modalities.", "AI": {"tldr": "本文提出了LLM数据审计框架，用于系统地评估大型语言模型生成的多模态合成数据的质量和可信度。", "motivation": "随着大型语言模型在生成跨多种模式的数据方面变得强大，确保这些合成数据的质量成为一个关键挑战。现有研究大多关注于生成方法，而忽视了对生成数据质量的直接评估，并且缺乏统一的视角来涵盖不同类型的合成数据。", "method": "文章描述了如何使用LLM生成六种不同模态的数据，并系统地将评估指标分为质量和可信度两大类，以评估这些合成数据的内在属性。", "result": "通过所提出的评价体系，对代表性的生成方法进行了实验分析，发现了当前评估实践中存在的显著缺陷，并据此向社区提出了改进数据生成评估的具体建议。", "conclusion": "文章强调了LLM数据审计框架对于提高跨模态合成数据质量和可信度的重要性，并概述了将这些合成数据实际应用的方法。"}}
{"id": "2601.17713", "pdf": "https://arxiv.org/pdf/2601.17713", "abs": "https://arxiv.org/abs/2601.17713", "authors": ["Kaile Wang", "Jiannong Cao", "Yu Yang", "Xiaoyin Li", "Yinfeng Cao"], "title": "FedCCA: Client-Centric Adaptation against Data Heterogeneity in Federated Learning on IoT Devices", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IEEE Annual Congress on Artificial Intelligence of Things (IEEE AIoT) 2025", "summary": "With the rapid development of the Internet of Things (IoT), AI model training on private data such as human sensing data is highly desired. Federated learning (FL) has emerged as a privacy-preserving distributed training framework for this purpuse. However, the data heterogeneity issue among IoT devices can significantly degrade the model performance and convergence speed in FL. Existing approaches limit in fixed client selection and aggregation on cloud server, making the privacy-preserving extraction of client-specific information during local training challenging. To this end, we propose Client-Centric Adaptation federated learning (FedCCA), an algorithm that optimally utilizes client-specific knowledge to learn a unique model for each client through selective adaptation, aiming to alleviate the influence of data heterogeneity. Specifically, FedCCA employs dynamic client selection and adaptive aggregation based on the additional client-specific encoder. To enhance multi-source knowledge transfer, we adopt an attention-based global aggregation strategy. We conducted extensive experiments on diverse datasets to assess the efficacy of FedCCA. The experimental results demonstrate that our approach exhibits a substantial performance advantage over competing baselines in addressing this specific problem.", "AI": {"tldr": "提出FedCCA算法，通过选择性适应和动态客户端选择来优化联邦学习中的设备特定知识利用。", "motivation": "解决物联网设备中数据异构问题对模型性能和收敛速度的影响。", "method": "采用动态客户端选择、基于额外的设备特定编码器自适应聚合以及注意力机制全局聚合策略的方法，以增强多源知识迁移。", "result": "实验结果表明，FedCCA在处理此问题上比竞争基线具有显著优势。", "conclusion": "通过优化联邦学习中的数据异构性问题，FedCCA算法能够提升设备上的AI模型训练效果。"}}
{"id": "2601.17711", "pdf": "https://arxiv.org/pdf/2601.17711", "abs": "https://arxiv.org/abs/2601.17711", "authors": ["Chengqian Jiang", "Jie Zhang", "Haoyin Yan"], "title": "CaSNet: Compress-and-Send Network Based Multi-Device Speech Enhancement Model for Distributed Microphone Arrays", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "this paper has been accept by ICASSP2026", "summary": "Distributed microphone array (DMA) is a promising next-generation platform for speech interaction, where speech enhancement (SE) is still required to improve the speech quality in noisy cases. Existing SE methods usually first gather raw waveforms at a fusion center (FC) from all devices and then design a multi-microphone model, causing high bandwidth and energy costs. In this work, we propose a \\emph{Compress-and-Send Network (CaSNet)} for resource-constrained DMAs, where one microphone serves as the FC and reference. Each of other devices encodes the measured raw data into a feature matrix, which is then compressed by singular value decomposition (SVD) to produce a more compact representation. The received features at the FC are aligned via cross window query with respect to the reference, followed by neural decoding to yield spatially coherent enhanced speech. Experiments on multiple datasets show that the proposed CaSNet can save the data amount with a negligible impact on the performance compared to the uncompressed case. The reproducible code is available at https://github.com/Jokejiangv/CaSNet.", "AI": {"tldr": "本文提出了一种基于压缩和发送网络的分布式麦克风阵列语音增强模型，即CaSNet。", "motivation": "现有的语音增强方法需要将原始波形数据集中在融合中心处理，导致带宽和能耗成本高。因此，论文旨在为资源受限的分布式麦克风阵列设计一种高效的数据传输和语音增强方案。", "method": "该方法使用一个麦克风作为融合中心和参考，其他设备将测量到的原始数据编码成特征矩阵，并通过奇异值分解压缩以产生更紧凑的表示。在融合中心处对齐接收到的特征后，利用神经解码生成空间一致性的增强语音。", "result": "实验结果表明，CaSNet可以在几乎不影响性能的情况下大幅度减少所需传输的数据量。", "conclusion": "结论是该模型能够有效地节省数据量而不会显著影响语音质量。"}}
{"id": "2601.17706", "pdf": "https://arxiv.org/pdf/2601.17706", "abs": "https://arxiv.org/abs/2601.17706", "authors": ["Saptarshi Ghosh", "Linfeng Liu", "Tianyu Jiang"], "title": "A Computational Approach to Visual Metonymy", "categories": ["cs.CL", "cs.CV"], "comment": "EACL 2026", "summary": "Images often communicate more than they literally depict: a set of tools can suggest an occupation and a cultural artifact can suggest a tradition. This kind of indirect visual reference, known as visual metonymy, invites viewers to recover a target concept via associated cues rather than explicit depiction. In this work, we present the first computational investigation of visual metonymy. We introduce a novel pipeline grounded in semiotic theory that leverages large language models and text-to-image models to generate metonymic visual representations. Using this framework, we construct ViMET, the first visual metonymy dataset comprising 2,000 multiple-choice questions to evaluate the cognitive reasoning abilities in multimodal language models. Experimental results on our dataset reveal a significant gap between human performance (86.9%) and state-of-the-art vision-language models (65.9%), highlighting limitations in machines' ability to interpret indirect visual references. Our dataset is publicly available at: https://github.com/cincynlp/ViMET.", "AI": {"tldr": "本文提出了一种计算视觉转喻的方法，并构建了首个用于评估多模态语言模型认知推理能力的数据集ViMET。", "motivation": "研究动机在于探索机器理解间接视觉引用的能力，通过创建一个新的数据集来评估现有的多模态语言模型在处理视觉转喻上的表现。", "method": "方法是基于符号理论的计算管道，利用大型语言模型和文本到图像模型生成转喻性视觉表示，并构建了包含2000个多项选择题的数据集ViMET。", "result": "实验结果表明，在ViMET数据集上的人类性能为86.9%，而最先进的视图-语言模型的性能仅为65.9%，揭示了机器在理解间接视觉引用方面的局限性。", "conclusion": "结论是当前的多模态语言模型在理解和处理视觉转喻方面存在显著差距，这表明需要进一步的研究来提高机器在这种类型任务上的表现。"}}
{"id": "2601.17703", "pdf": "https://arxiv.org/pdf/2601.17703", "abs": "https://arxiv.org/abs/2601.17703", "authors": ["Nikhil Kadivar", "Guansheng Li", "Jianlu Zheng", "John M. Higgins", "Ming Dao", "George Em Karniadakis", "Mengjia Xu"], "title": "An AI-enabled tool for quantifying overlapping red blood cell sickling dynamics in microfluidic assays", "categories": ["cs.CV"], "comment": null, "summary": "Understanding sickle cell dynamics requires accurate identification of morphological transitions under diverse biophysical conditions, particularly in densely packed and overlapping cell populations. Here, we present an automated deep learning framework that integrates AI-assisted annotation, segmentation, classification, and instance counting to quantify red blood cell (RBC) populations across varying density regimes in time-lapse microscopy data. Experimental images were annotated using the Roboflow platform to generate labeled dataset for training an nnU-Net segmentation model. The trained network enables prediction of the temporal evolution of the sickle cell fraction, while a watershed algorithm resolves overlapping cells to enhance quantification accuracy. Despite requiring only a limited amount of labeled data for training, the framework achieves high segmentation performance, effectively addressing challenges associated with scarce manual annotations and cell overlap. By quantitatively tracking dynamic changes in RBC morphology, this approach can more than double the experimental throughput via densely packed cell suspensions, capture drug-dependent sickling behavior, and reveal distinct mechanobiological signatures of cellular morphological evolution. Overall, this AI-driven framework establishes a scalable and reproducible computational platform for investigating cellular biomechanics and assessing therapeutic efficacy in microphysiological systems.", "AI": {"tldr": "本文介绍了一种基于AI的工具，用于量化微流体测定中重叠红细胞的镰变动力学。", "motivation": "为了准确识别在不同生物物理条件下红血球的形态转变，特别是在密集且相互重叠的群体中，需要一种自动化的方法来提高研究效率和准确性。", "method": "该工具使用深度学习框架，包含AI辅助注释、分割、分类和实例计数，以量化时间序列显微镜数据中的红细胞种群。通过Roboflow平台标注实验图像并训练nnU-Net模型，预测镰变细胞随时间的变化，并利用分水岭算法解析重叠的细胞。", "result": "尽管只需要少量标记的数据进行训练，该框架仍实现了高分割性能，有效解决了人工注释稀缺和细胞重叠的问题。通过定量追踪红血球形态的动力学变化，实验吞吐量可提高一倍以上，并能捕捉药物依赖性镰变行为及揭示细胞形态演化的机械生物学特征。", "conclusion": "该AI驱动的框架为研究细胞生物力学提供了可扩展且可重复使用的计算平台，并可用于评估微生理系统中的治疗效果。"}}
{"id": "2601.17699", "pdf": "https://arxiv.org/pdf/2601.17699", "abs": "https://arxiv.org/abs/2601.17699", "authors": ["Harper Hua", "Zhen Han", "Zhengyuan Shen", "Jeremy Lee", "Patrick Guan", "Qi Zhu", "Sullam Jeoung", "Yueyan Chen", "Yunfei Bai", "Shuai Wang", "Vassilis Ioannidis", "Huzefa Rangwala"], "title": "SQL-Trail: Multi-Turn Reinforcement Learning with Interleaved Feedback for Text-to-SQL", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While large language models (LLMs) have substantially improved Text-to-SQL generation, a pronounced gap remains between AI systems and human experts on challenging benchmarks such as BIRD-SQL. We argue this gap stems largely from the prevailing single-pass paradigm, which lacks the iterative reasoning, schema exploration, and error-correction behaviors that humans naturally employ. To address this limitation, we introduce SQL-Trail, a multi-turn reinforcement learning (RL) agentic framework for Text-to-SQL. Rather than producing a query in one shot, SQL-Trail interacts with the database environment and uses execution feedback to iteratively refine its predictions. Our approach centers on two key ideas: (i) an adaptive turn-budget allocation mechanism that scales the agent's interaction depth to match question difficulty, and (ii) a composite reward panel that jointly incentivizes SQL correctness and efficient exploration. Across benchmarks, SQL-Trail sets a new state of the art and delivers strong data efficiency--up to 18x higher than prior single-pass RL state-of-the-art methods. Notably, our 7B and 14B models outperform substantially larger proprietary systems by 5% on average, underscoring the effectiveness of interactive, agentic workflows for robust Text-to-SQL generation.", "AI": {"tldr": "介绍了一种多轮强化学习框架SQL-Trail，用于文本到SQL的生成。", "motivation": "现有的单次生成方法在复杂基准测试中存在不足，缺乏迭代推理、模式探索和错误纠正等行为。", "method": "提出了一个包含自适应回合预算分配机制和复合奖励面板的多轮强化学习框架，以交互式方式改进SQL预测。", "result": "SQL-Trail在多个基准上实现了新状态，并且数据效率高达18倍高于之前的单次生成方法。7B和14B模型平均优于更大规模的专有系统5%。", "conclusion": "证明了交互式、代理工作流在强大的文本到SQL生成中的有效性。"}}
{"id": "2601.17697", "pdf": "https://arxiv.org/pdf/2601.17697", "abs": "https://arxiv.org/abs/2601.17697", "authors": ["Zexi Jia", "Jinchao Zhang", "Jie Zhou"], "title": "StyleDecoupler: Generalizable Artistic Style Disentanglement", "categories": ["cs.CV"], "comment": null, "summary": "Representing artistic style is challenging due to its deep entanglement with semantic content. We propose StyleDecoupler, an information-theoretic framework that leverages a key insight: multi-modal vision models encode both style and content, while uni-modal models suppress style to focus on content-invariant features. By using uni-modal representations as content-only references, we isolate pure style features from multi-modal embeddings through mutual information minimization. StyleDecoupler operates as a plug-and-play module on frozen Vision-Language Models without fine-tuning. We also introduce WeART, a large-scale benchmark of 280K artworks across 152 styles and 1,556 artists. Experiments show state-of-the-art performance on style retrieval across WeART and WikiART, while enabling applications like style relationship mapping and generative model evaluation. We release our method and dataset at this url.", "AI": {"tldr": "本文提出了StyleDecoupler，一个能够从多模态视觉模型中分离艺术风格和内容的信息理论框架。", "motivation": "由于艺术风格与语义内容的深度纠缠，表示艺术风格具有挑战性。作者提出利用多模态和单模态模型之间的差异来解决这一问题。", "method": "通过使用单模态模型作为仅包含内容的参考，并利用互信息最小化从多模态嵌入中分离出纯风格特征，StyleDecoupler可以在不进行微调的情况下作为一个即插即用模块应用于冻结的视觉语言模型上。", "result": "实验展示了在大规模艺术作品基准WeART和WikiART上的风格检索达到了最先进的性能，并支持诸如风格关系映射和生成模型评估等应用。", "conclusion": "StyleDecoupler成功实现了艺术风格与内容的分离，提供了强大的工具来理解和处理艺术风格，在多个任务上表现出色。"}}
{"id": "2601.17690", "pdf": "https://arxiv.org/pdf/2601.17690", "abs": "https://arxiv.org/abs/2601.17690", "authors": ["Ziling Gong", "Yunyan Ouyang", "Iram Kamdar", "Melody Ma", "Hongjie Chen", "Franck Dernoncourt", "Ryan A. Rossi", "Nesreen K. Ahmed"], "title": "Segment Length Matters: A Study of Segment Lengths on Audio Fingerprinting Performance", "categories": ["cs.SD", "cs.AI", "cs.IR", "cs.LG", "eess.AS"], "comment": null, "summary": "Audio fingerprinting provides an identifiable representation of acoustic signals, which can be later used for identification and retrieval systems. To obtain a discriminative representation, the input audio is usually segmented into shorter time intervals, allowing local acoustic features to be extracted and analyzed. Modern neural approaches typically operate on short, fixed-duration audio segments, yet the choice of segment duration is often made heuristically and rarely examined in depth. In this paper, we study how segment length affects audio fingerprinting performance. We extend an existing neural fingerprinting architecture to adopt various segment lengths and evaluate retrieval accuracy across different segment lengths and query durations. Our results show that short segment lengths (0.5-second) generally achieve better performance. Moreover, we evaluate LLM capacity in recommending the best segment length, which shows that GPT-5-mini consistently gives the best suggestions across five considerations among three studied LLMs. Our findings provide practical guidance for selecting segment duration in large-scale neural audio retrieval systems.", "AI": {"tldr": "研究不同音频片段长度对音频指纹性能的影响，并评估大语言模型推荐最佳片段长度的能力。", "motivation": "现有神经方法通常基于固定时长的短音频片段工作，但关于片段长度的选择往往是启发式且缺乏深入探讨。本论文旨在解决这一问题。", "method": "扩展现有的神经音频指纹架构以适应不同的片段长度，并评估不同片段长度和查询持续时间下的检索精度。同时使用三个大型语言模型（LLM）来推荐最佳的片段长度。", "result": "结果显示，较短的片段长度（0.5秒）通常能获得更好的性能。GPT-5-mini在五种考虑因素中一致给出了最好的建议。", "conclusion": "本研究为大规模神经音频检索系统选择合适的片段持续时间提供了实用指南。"}}
{"id": "2601.17687", "pdf": "https://arxiv.org/pdf/2601.17687", "abs": "https://arxiv.org/abs/2601.17687", "authors": ["Hao Li", "He Cao", "Shenyao Peng", "Zijing Liu", "Bin Feng", "Yu Wang", "Zhiyuan Yan", "Yonghong Tian", "Yu Li", "Li Yuan"], "title": "Agentic reinforcement learning empowers next-generation chemical language models for molecular design and synthesis", "categories": ["cs.LG", "cs.AI"], "comment": "Working in Progress, 13 pages, 4 figures", "summary": "Language models are revolutionizing the biochemistry domain, assisting scientists in drug design and chemical synthesis with high efficiency. Yet current approaches struggle between small language models prone to hallucination and limited knowledge retention, and large cloud-based language models plagued by privacy risks and high inference costs. To bridge this gap, we introduce ChemCRAFT, a novel framework leveraging agentic reinforcement learning to decouple chemical reasoning from knowledge storage. Instead of forcing the model to memorize vast chemical data, our approach empowers the language model to interact with a sandbox for precise information retrieval. This externalization of knowledge allows a locally deployable small model to achieve superior performance with minimal inference costs. To enable small language models for agent-calling ability, we build an agentic trajectory construction pipeline and a comprehensive chemical-agent sandbox. Based on sandbox interactions, we constructed ChemToolDataset, the first large-scale chemical tool trajectory dataset. Simultaneously, we propose SMILES-GRPO to build a dense chemical reward function, promoting the model's ability to call chemical agents. Evaluations across diverse aspects of drug design show that ChemCRAFT outperforms current cloud-based LLMs in molecular structure analysis, molecular optimization, and synthesis pathway prediction, demonstrating that scientific reasoning is not solely an emergent ability of model scale, but a learnable policy of tool orchestration. This work establishes a cost-effective and privacy-preserving paradigm for AI-aided chemistry, opening new avenues for accelerating molecular discovery with locally deployable agents.", "AI": {"tldr": "本文介绍了一种名为ChemCRAFT的新框架，通过代理强化学习将化学推理与知识存储分离，以实现高效的分子设计和合成。", "motivation": "当前语言模型在生物化学领域辅助科学家进行药物设计和化学合成时存在局限性，小型模型容易产生幻觉且记忆力有限，大型云基语言模型则面临隐私风险和高昂的推断成本。本文旨在解决这些问题。", "method": "ChemCRAFT框架通过构建代理轨迹构造管道和全面的化学代理人沙箱，使小型语言模型能够与外部信息源交互进行精准检索，并使用SMILES-GRPO建立密集的化学奖励函数来促进化学代理调用能力。", "result": "实验结果显示，在分子结构分析、分子优化和合成路径预测等多个方面，ChemCRAFT优于现有的云基大型语言模型。", "conclusion": "本文提出的方法证明了科学推理不仅依赖于模型规模，还是一种可学习的工具编排策略，并且为AI辅助化学研究提供了一种成本效益高且保护隐私的新范式。"}}
{"id": "2601.17684", "pdf": "https://arxiv.org/pdf/2601.17684", "abs": "https://arxiv.org/abs/2601.17684", "authors": ["Cordelia Hu", "Jennifer Tang"], "title": "A Model-Driven Lossless Compression Algorithm Resistant to Mismatch", "categories": ["cs.IT", "cs.AI"], "comment": "10 pages, 5 figure. Submitted to ISIT 2026. This is a follow-up to the following paper: arXiv:2601.10678", "summary": "Due to the fundamental connection between next-symbol prediction and compression, modern predictive models, such as large language models (LLMs), can be combined with entropy coding to achieve compression rates that surpass those of standard compression algorithms. However, this approach relies on the assumption that the predictive model produces identical output distributions at both the encoder and decoder, since even small mismatches can cause the decoding to fail. This assumption often fails with complex predictive models, particularly those based on neural networks, a phenomenon referred to as non-determinism. In this work, we propose a new compression algorithm based on next-token prediction that is robust to arbitrarily large, but structured, prediction mismatches. We prove the correctness of the proposed scheme under a formal mismatch certification, characterize its theoretical performance, and validate it experimentally on real datasets. Our results demonstrate reliable operation within the certified mismatch regime while achieving compression ratios that exceed those of commonly used compression methods.", "AI": {"tldr": "本文提出了一种基于下一个标记预测的无损压缩算法，该算法能够抵抗任意大小但结构化的预测误差。", "motivation": "现代预测模型（如大型语言模型）可以与熵编码相结合实现比标准压缩算法更高的压缩率，但这种技术依赖于假设编码器和解码器中的预测模型输出相同的分布。复杂预测模型的非确定性往往使这一假设失效，因此提出了能够抵抗预测误差的新压缩算法。", "method": "提出了一种基于下一个标记预测的无损压缩算法，并通过正式的误差认证来证明其正确性。同时分析了该方法的理论性能并在真实数据集上进行了实验验证。", "result": "实验结果显示，在认证误差范围内，所提方法能够可靠运行并实现超过常见压缩方法的压缩率。", "conclusion": "本研究成功开发了一种新型无损压缩算法，其能够在存在任意大小结构化预测误差的情况下保持高效和可靠的性能。"}}
{"id": "2601.17679", "pdf": "https://arxiv.org/pdf/2601.17679", "abs": "https://arxiv.org/abs/2601.17679", "authors": ["Md Sazzadul Islam Ridoy", "Mubaswira Ibnat Zidney", "Sumi Akter", "Md. Aminur Rahman"], "title": "BanglaRobustNet: A Hybrid Denoising-Attention Architecture for Robust Bangla Speech Recognition", "categories": ["cs.SD", "cs.CL", "cs.CV", "cs.LG", "eess.AS"], "comment": null, "summary": "Bangla, one of the most widely spoken languages, remains underrepresented in state-of-the-art automatic speech recognition (ASR) research, particularly under noisy and speaker-diverse conditions. This paper presents BanglaRobustNet, a hybrid denoising-attention framework built on Wav2Vec-BERT, designed to address these challenges. The architecture integrates a diffusion-based denoising module to suppress environmental noise while preserving Bangla-specific phonetic cues, and a contextual cross-attention module that conditions recognition on speaker embeddings for robustness across gender, age, and dialects. Trained end-to-end with a composite objective combining CTC loss, phonetic consistency, and speaker alignment, BanglaRobustNet achieves substantial reductions in word error rate (WER) and character error rate (CER) compared to Wav2Vec-BERT and Whisper baselines. Evaluations on Mozilla Common Voice Bangla and augmented noisy speech confirm the effectiveness of our approach, establishing BanglaRobustNet as a robust ASR system tailored to low-resource, noise-prone linguistic settings.", "AI": {"tldr": "介绍BanglaRobustNet，一种结合降噪和注意力机制的框架，用于提高孟加拉语在嘈杂环境中的自动语音识别性能。", "motivation": "孟加拉语作为广泛使用的语言之一，在抗噪声和多说话人条件下的ASR研究中代表性不足，需要更稳健的系统来处理这些挑战。", "method": "BanglaRobustNet整合了基于扩散的降噪模块以抑制环境噪音，并保持孟加拉语音素线索；同时使用上下文交叉注意力机制，通过说话人嵌入进行条件识别，提高性别、年龄和方言方面的鲁棒性。整个框架采用结合CTC损失、音素一致性和说话人对齐的综合目标训练。", "result": "与Wav2Vec-BERT和Whisper基准相比，BanglaRobustNet在单词错误率（WER）和字符错误率（CER）上显著降低；在Mozilla Common Voice孟加拉语数据集及噪音增强数据上的评估验证了该方法的有效性。", "conclusion": "BanglaRobustNet作为一个针对资源匮乏、噪声敏感语言环境的鲁棒ASR系统，证明了其有效性和适应性。"}}
{"id": "2601.17678", "pdf": "https://arxiv.org/pdf/2601.17678", "abs": "https://arxiv.org/abs/2601.17678", "authors": ["Zhiyu An", "Wan Du"], "title": "DIML: Differentiable Inverse Mechanism Learning from Behaviors of Multi-Agent Learning Trajectories", "categories": ["cs.AI", "cs.GT"], "comment": null, "summary": "We study inverse mechanism learning: recovering an unknown incentive-generating mechanism from observed strategic interaction traces of self-interested learning agents. Unlike inverse game theory and multi-agent inverse reinforcement learning, which typically infer utility/reward parameters inside a structured mechanism, our target includes unstructured mechanism -- a (possibly neural) mapping from joint actions to per-agent payoffs. Unlike differentiable mechanism design, which optimizes mechanisms forward, we infer mechanisms from behavior in an observational setting. We propose DIML, a likelihood-based framework that differentiates through a model of multi-agent learning dynamics and uses the candidate mechanism to generate counterfactual payoffs needed to predict observed actions. We establish identifiability of payoff differences under a conditional logit response model and prove statistical consistency of maximum likelihood estimation under standard regularity conditions. We evaluate DIML with simulated interactions of learning agents across unstructured neural mechanisms, congestion tolling, public goods subsidies, and large-scale anonymous games. DIML reliably recovers identifiable incentive differences and supports counterfactual prediction, where its performance rivals tabular enumeration oracle in small environments and its convergence scales to large, hundred-participant environments. Code to reproduce our experiments is open-sourced.", "AI": {"tldr": "本文提出了DIML框架，通过可微分的逆机制学习方法从多智能体学习轨迹的行为中恢复未知激励生成机制。", "motivation": "该研究旨在解决从自利学习代理人的战略互动痕迹中恢复未知名激励生成机制的问题，不同于传统的逆博弈理论和多智能体逆强化学习，DIML处理的是无结构的机制，并在观察环境中通过行为推断机制。", "method": "DIML框架基于似然估计方法，通过对多智能体学习动态模型进行可微分操作，并使用候选机制生成用于预测观察到的动作所需的反事实收益来进行机制的逆向推导。", "result": "该研究证明了在条件对数反应模型下的回报差异的识别性以及最大似然估计下统计一致性。实验评估表明，DIML可以可靠地恢复可识别的激励差异，并支持反事实预测，在小环境和大环境中都有良好的表现。", "conclusion": "DIML框架有效地解决了从多智能体学习轨迹行为中逆向推导复杂机制的问题，并在多种不同类型的任务中证明了其有效性和可靠性。"}}
{"id": "2601.17676", "pdf": "https://arxiv.org/pdf/2601.17676", "abs": "https://arxiv.org/abs/2601.17676", "authors": ["Jiexin Ding", "Yizhuo Zhang", "Xinyun Liu", "Ke chen", "Yuntao Wang", "Shwetak Patel", "Akshay Gadre"], "title": "GazeSummary: Exploring Gaze as an Implicit Prompt for Personalization in Text-based LLM Tasks", "categories": ["cs.HC"], "comment": null, "summary": "Smart glasses are accelerating progress toward more seamless and personalized LLM-based assistance by integrating multimodal inputs. Yet, these inputs rely on obtrusive explicit prompts. The advent of gaze tracking on smart devices offers a unique opportunity to extract implicit user intent for personalization. This paper investigates whether LLMs can interpret user gaze for text-based tasks. We evaluate different gaze representations for personalization and validate their effectiveness in realistic reading tasks. Results show that LLMs can leverage gaze to generate high-quality personalized summaries and support users in downstream tasks, highlighting the feasibility and value of gaze-driven personalization for future mobile and wearable LLM applications.", "AI": {"tldr": "研究了基于智能眼镜的凝视追踪是否可以作为隐式提示来提高文本大语言模型任务中的个性化效果。", "motivation": "旨在减少对显式输入的需求，利用凝视追踪技术从用户的行为中提取隐含意图以实现更自然和个性化的LLM辅助。", "method": "评估了不同的凝视表示方法在实现个性化方面的有效性，并验证其在实际阅读任务中的表现。", "result": "结果显示，大语言模型能够利用用户的凝视来生成高质量的个性化摘要，并支持用户进行后续的任务。", "conclusion": "证实了基于凝视驱动的个性化的可行性和价值，为未来的移动和可穿戴LLM应用提供了潜在的发展方向。"}}
{"id": "2601.17673", "pdf": "https://arxiv.org/pdf/2601.17673", "abs": "https://arxiv.org/abs/2601.17673", "authors": ["Weiyu Zhang", "Yuan Hu", "Yong Li", "Yu Liu"], "title": "Uni-RS: A Spatially Faithful Unified Understanding and Generation Model for Remote Sensing", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Unified remote sensing multimodal models exhibit a pronounced spatial reversal curse: Although they can accurately recognize and describe object locations in images, they often fail to faithfully execute the same spatial relations during text-to-image generation, where such relations constitute core semantic information in remote sensing. Motivated by this observation, we propose Uni-RS, the first unified multimodal model tailored for remote sensing, to explicitly address the spatial asymmetry between understanding and generation. Specifically, we first introduce explicit Spatial-Layout Planning to transform textual instructions into spatial layout plans, decoupling geometric planning from visual synthesis. We then impose Spatial-Aware Query Supervision to bias learnable queries toward spatial relations explicitly specified in the instruction. Finally, we develop Image-Caption Spatial Layout Variation to expose the model to systematic geometry-consistent spatial transformations. Extensive experiments across multiple benchmarks show that our approach substantially improves spatial faithfulness in text-to-image generation, while maintaining strong performance on multimodal understanding tasks like image captioning, visual grounding, and VQA tasks.", "AI": {"tldr": "介绍了一种名为Uni-RS的统一多模态模型，专门用于解决遥感图像理解和生成中的空间一致性问题。", "motivation": "发现现有的远程感知多模态模型在图像识别和描述物体位置方面准确，但在文本到图像生成中无法忠实地执行相同的空间关系。", "method": "提出一种名为Uni-RS的模型，通过引入显式的空间布局规划、施加空间感知查询监督以及开发图像-标题空间布局变化来解决空间一致性问题。", "result": "实验表明该方法在文本到图像生成中的空间忠实度有了显著提升，并且在多模态理解任务中也保持了强大的性能。", "conclusion": "Uni-RS模型有效地解决了遥感数据中理解和生成之间的空间不对称性，提升了空间忠实度。"}}
{"id": "2601.17670", "pdf": "https://arxiv.org/pdf/2601.17670", "abs": "https://arxiv.org/abs/2601.17670", "authors": ["Roberto Rossi", "Steven D. Prestwich"], "title": "Grammar-Aware Literate Generative Mathematical Programming with Compiler-in-the-Loop", "categories": ["cs.PL", "cs.AI"], "comment": "18 pages, 10 figures", "summary": "This work investigates generative mathematical programming through the lens of Algebraic Modelling Languages (AMLs) and compiler-guided model synthesis. By leveraging PyOPL, an OPL-like AML compiler that provides detailed syntax diagnostics, we introduce SyntAGM, an end-to-end system that translates natural language problem descriptions into PyOPL models via a generate--compile--assess--revise loop. SyntAGM is grammar-aware thanks to in-context exposure to the PyOPL BNF grammar, and benefits from few-shot retrieval of literate PyOPL model exemplars. To obtain a valid PyOPL model that matches the problem description, SyntAGM mobilises compiler feedback and an LLM-based alignment judge. In a comparative study against established prompting baselines SyntAGM achieves competitive accuracy with superior token, cost, and latency profiles.", "AI": {"tldr": "本论文研究了通过代数建模语言（AMLs）和编译器引导的模型综合来进行生成性数学编程。", "motivation": "通过使用PyOPL，一个提供详细语法诊断的类似OPL的AML编译器，本文旨在开发一个能够将自然语言问题描述转化为有效的PyOPL模型的系统。", "method": "引入了SyntAGM，这是一个端到端系统，利用生成-编译-评估-修订循环来翻译自然语言问题描述为PyOPL模型，并通过编译器反馈和基于LLM的对齐判断获得有效模型。", "result": "在与现有提示基线进行比较研究时，SyntAGM实现了具有竞争力的准确性，同时具备更优的令牌、成本和延迟性能。", "conclusion": "SyntAGM系统通过语法意识和编译器反馈提高了自然语言问题描述转化为数学模型的有效性和效率，展示了其在生成性编程中的潜力。"}}
{"id": "2601.17666", "pdf": "https://arxiv.org/pdf/2601.17666", "abs": "https://arxiv.org/abs/2601.17666", "authors": ["Xinyue Pan", "Yuhao Chen", "Fengqing Zhu"], "title": "Training-Free Text-to-Image Compositional Food Generation via Prompt Grafting", "categories": ["cs.CV"], "comment": "Accepted by CAI2026", "summary": "Real-world meal images often contain multiple food items, making reliable compositional food image generation important for applications such as image-based dietary assessment, where multi-food data augmentation is needed, and recipe visualization. However, modern text-to-image diffusion models struggle to generate accurate multi-food images due to object entanglement, where adjacent foods (e.g., rice and soup) fuse together because many foods do not have clear boundaries. To address this challenge, we introduce Prompt Grafting (PG), a training-free framework that combines explicit spatial cues in text with implicit layout guidance during sampling. PG runs a two-stage process where a layout prompt first establishes distinct regions and the target prompt is grafted once layout formation stabilizes. The framework enables food entanglement control: users can specify which food items should remain separated or be intentionally mixed by editing the arrangement of layouts. Across two food datasets, our method significantly improves the presence of target objects and provides qualitative evidence of controllable separation.", "AI": {"tldr": "提出Prompt Grafting（PG），一种无训练框架，通过结合文本中的显式空间线索和采样过程中的隐式布局指导来生成多食品图像。", "motivation": "现实世界的餐食图片通常包含多个食物项，因此可靠的食物组合图像是重要的。现有的文本到图像扩散模型难以准确生成这些图像，因为相邻的食物会融合在一起。", "method": "Prompt Grafting采用两阶段过程：首先使用布局提示建立区域，然后在布局形成稳定时嫁接目标提示。用户可以通过编辑布局来控制食物的分离或混合。", "result": "在两个食品数据集上验证了该方法，显著提高了目标对象的存在感，并提供了可控制的分离质量证据。", "conclusion": "Prompt Grafting框架通过结合显式和隐式指导有效解决了文本到图像生成中多食品融合的问题。"}}
{"id": "2601.17664", "pdf": "https://arxiv.org/pdf/2601.17664", "abs": "https://arxiv.org/abs/2601.17664", "authors": ["Syed Muhammad Ali", "Hammad Sajid", "Zainab Haider", "Ali Muhammad Asad", "Haya Fatima", "Abdul Samad"], "title": "UrduLM: A Resource-Efficient Monolingual Urdu Language Model", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages", "summary": "Urdu, spoken by 230 million people worldwide, lacks dedicated transformer-based language models and curated corpora. While multilingual models provide limited Urdu support, they suffer from poor performance, high computational costs, and cultural inaccuracies due to insufficient training data. To address these challenges, we present UrduLM, a pretrained Urdu monolingual language model trained in low-resource settings. We curate a 33GB Urdu corpus from diverse sources, develop a custom BPE tokenizer that reduces tokenization overhead by atleast 20-30% compared to multilingual alternatives, and pretrain a 100M-parameter decoder-only model. In few-shot evaluations, UrduLM achieves competitive performance with multilingual models up to 30x its size, reaching 66.6% accuracy on sentiment classification and BLEU scores exceeding 30 on grammar correction tasks. The complete methodology -- including corpus, tokenizer, model weights, and evaluation benchmarks -- is released openly to establish a baseline for Urdu NLP research and provide a scalable framework for other underrepresented languages.", "AI": {"tldr": "本文介绍了UrduLM，一个在低资源环境下训练的乌尔都语单语言模型。", "motivation": "由于缺乏专门针对乌尔都语的变压器基础语言模型和精心整理的数据集，现有的多语言模型在处理乌尔都语时存在性能差、计算成本高及文化不准确等问题。因此，本文旨在开发一个适用于乌尔都语的语言模型来解决这些挑战。", "method": "作者收集了一个33GB的乌尔都语文本数据集，并设计了一种自定义BPE分词器以减少至少20-30%的分词开销。此外，还训练了一个1亿参数的解码器仅模型。", "result": "在少量样本评估中，UrduLM与规模大30倍的多语言模型相比表现出竞争力，达到了66.6%的情感分类准确率和超过30的语法纠正任务BLEU分数。", "conclusion": "研究结果表明，UrduLM为乌尔都语NLP研究提供了一个基准，并且其方法可以作为其他代表性不足的语言开发基础框架的参考。"}}
{"id": "2601.17657", "pdf": "https://arxiv.org/pdf/2601.17657", "abs": "https://arxiv.org/abs/2601.17657", "authors": ["Taewan Cho", "Taeryang Kim", "Andrew Jaeyong Choi"], "title": "SPACE-CLIP: Spatial Perception via Adaptive CLIP Embeddings for Monocular Depth Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Contrastive Language-Image Pre-training (CLIP) has accomplished extraordinary success for semantic understanding but inherently struggles to perceive geometric structure. Existing methods attempt to bridge this gap by querying CLIP with textual prompts, a process that is often indirect and inefficient. This paper introduces a fundamentally different approach using a dual-pathway decoder. We present SPACE-CLIP, an architecture that unlocks and interprets latent geometric knowledge directly from a frozen CLIP vision encoder, completely bypassing the text encoder and its associated textual prompts. A semantic pathway interprets high-level features, dynamically conditioned on global context using feature-wise linear modulation (FiLM). In addition, a structural pathway extracts fine-grained spatial details from early layers. These complementary streams are hierarchically fused, enabling a robust synthesis of semantic context and precise geometry. Extensive experiments on the KITTI benchmark show that SPACE-CLIP dramatically outperforms previous CLIP-based methods. Our ablation studies validate that the synergistic fusion of our dual pathways is critical to this success. SPACE-CLIP offers a new, efficient, and architecturally elegant blueprint for repurposing large-scale vision models. The proposed method is not just a standalone depth estimator, but a readily integrable spatial perception module for the next generation of embodied AI systems, such as vision-language-action (VLA) models. Our model is available at https://github.com/taewan2002/space-clip", "AI": {"tldr": "本文提出了SPACE-CLIP，一种通过自适应的CLIP嵌入来实现单目深度估计的空间感知架构。", "motivation": "现有的方法尝试使用文本提示与CLIP结合以解决几何结构理解问题，但这种方法间接且效率低下。因此，作者希望通过直接解锁和解释冻结的CLIP视觉编码器中的潜在几何知识来改进这个问题。", "method": "SPACE-CLIP采用双路径解码器架构，其中语义路径通过全局上下文动态条件下的特征线性调制（FiLM）诠释高级功能，而结构路径从早期层中提取细粒度空间细节。两条互补的流被分层融合，以实现语义上下文和精确几何学的有效合成。", "result": "在KITTI基准上的广泛实验表明，SPACE-CLIP显著优于之前的基于CLIP的方法。消融研究表明，双路径协同融合是其成功的关键因素。", "conclusion": "SPACE-CLIP提供了一种新的、高效的、架构优美的蓝图，用于重新利用大规模视觉模型，并且它可以作为一个可集成的空间感知模块应用于下一代嵌入式AI系统中，如视图语言动作（VLA）模型。"}}
{"id": "2601.17647", "pdf": "https://arxiv.org/pdf/2601.17647", "abs": "https://arxiv.org/abs/2601.17647", "authors": ["Akila Sampath", "Vandana Janeja", "Jianwu Wang"], "title": "Time-Varying Causal Treatment for Quantifying the Causal Effect of Short-Term Variations on Arctic Sea Ice Dynamics", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Quantifying the causal relationship between ice melt and freshwater distribution is critical, as these complex interactions manifest as regional fluctuations in sea surface height (SSH). Leveraging SSH as a proxy for sea ice dynamics enables improved understanding of the feedback mechanisms driving polar climate change and global sea-level rise. However, conventional deep learning models often struggle with reliable treatment effect estimation in spatiotemporal settings due to unobserved confounders and the absence of physical constraints. To address these challenges, we propose the Knowledge-Guided Causal Model Variational Autoencoder (KGCM-VAE) to quantify causal mechanisms between sea ice thickness and SSH. The proposed framework integrates a velocity modulation scheme in which smoothed velocity signals are dynamically amplified via a sigmoid function governed by SSH transitions to generate physically grounded causal treatments. In addition, the model incorporates Maximum Mean Discrepancy (MMD) to balance treated and control covariate distributions in the latent space, along with a causal adjacency-constrained decoder to ensure alignment with established physical structures. Experimental results on both synthetic and real-world Arctic datasets demonstrate that KGCM-VAE achieves superior PEHE compared to state-of-the-art benchmarks. Ablation studies further confirm the effectiveness of the approach, showing that the joint application of MMD and causal adjacency constraints yields a 1.88\\% reduction in estimation error.", "AI": {"tldr": "本文提出Knowledge-Guided Causal Model Variational Autoencoder (KGCM-VAE)，用于量化北极海冰厚度与海面高度之间的因果关系。", "motivation": "传统深度学习模型在时空设置中难以可靠地估计治疗效果，因为存在未观察到的混淆因素和缺乏物理约束。", "method": "提出KGCM-VAE框架整合了速度调制方案和最大平均差异（MMD）来平衡处理与控制协变量分布，并使用因果邻接约束解码器保证与已建立的物理结构对齐。", "result": "实验结果表明，在合成数据集和真实世界北极数据集中，KGCM-VAE相比现有基准实现了更优的表现。敏感性分析显示MMD和因果邻接约束的应用将估计误差降低了1.88%。", "conclusion": "该方法能够有效量化复杂反馈机制对海冰动态的影响，并改善气候变化研究中对于区域波动的理解。"}}
{"id": "2601.17645", "pdf": "https://arxiv.org/pdf/2601.17645", "abs": "https://arxiv.org/abs/2601.17645", "authors": ["Xilin Jiang", "Qiaolin Wang", "Junkai Wu", "Xiaomin He", "Zhongweiyang Xu", "Yinghao Ma", "Minshuo Piao", "Kaiyi Yang", "Xiuwen Zheng", "Riki Shimizu", "Yicong Chen", "Arsalan Firoozi", "Gavin Mischler", "Sukru Samet Dindar", "Richard Antonello", "Linyang He", "Tsun-An Hsieh", "Xulin Fan", "Yulun Wu", "Yuesheng Ma", "Chaitanya Amballa", "Weixiong Chen", "Jiarui Hai", "Ruisi Li", "Vishal Choudhari", "et al. (8 additional authors not shown)"], "title": "AVMeme Exam: A Multimodal Multilingual Multicultural Benchmark for LLMs' Contextual and Cultural Knowledge and Thinking", "categories": ["cs.SD", "cs.CL", "cs.CV", "cs.MM", "eess.AS"], "comment": "avmemeexam.github.io/public", "summary": "Internet audio-visual clips convey meaning through time-varying sound and motion, which extend beyond what text alone can represent. To examine whether AI models can understand such signals in human cultural contexts, we introduce AVMeme Exam, a human-curated benchmark of over one thousand iconic Internet sounds and videos spanning speech, songs, music, and sound effects. Each meme is paired with a unique Q&A assessing levels of understanding from surface content to context and emotion to usage and world knowledge, along with metadata such as original year, transcript, summary, and sensitivity. We systematically evaluate state-of-the-art multimodal large language models (MLLMs) alongside human participants using this benchmark. Our results reveal a consistent limitation: current models perform poorly on textless music and sound effects, and struggle to think in context and in culture compared to surface content. These findings highlight a key gap in human-aligned multimodal intelligence and call for models that can perceive contextually and culturally beyond the surface of what they hear and see. Project page: avmemeexam.github.io/public", "AI": {"tldr": "本研究介绍了AVMeme Exam，一个用于评估大规模多模态语言模型（MLLMs）在理解音频和视频内容中文化及上下文知识的基准测试。", "motivation": "动机在于探索AI模型是否能够理解和解析人类文化背景下的时变声音和动态影像信息。", "method": "创建了一个包含超过1000个标志性互联网声音和视频的人工策划基准，每个模因都配有独特的问答题来评估理解水平，并且进行了系统化的状态-of-the-art多模态大型语言模型与人类参与者之间的对比评测。", "result": "结果显示当前模型在无文字的音乐和音效上的表现较差，同时在上下文和文化思考方面也落后于表面内容的理解能力。", "conclusion": "研究结果揭示了人机对齐的多模态智能的关键差距，并呼吁开发能够超越所见所闻理解背景文化和上下文的模型。"}}
{"id": "2601.17644", "pdf": "https://arxiv.org/pdf/2601.17644", "abs": "https://arxiv.org/abs/2601.17644", "authors": ["Ali Al-Lawati", "Suhang Wang"], "title": "A Systemic Evaluation of Multimodal RAG Privacy", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The growing adoption of multimodal Retrieval-Augmented Generation (mRAG) pipelines for vision-centric tasks (e.g. visual QA) introduces important privacy challenges. In particular, while mRAG provides a practical capability to connect private datasets to improve model performance, it risks the leakage of private information from these datasets during inference. In this paper, we perform an empirical study to analyze the privacy risks inherent in the mRAG pipeline observed through standard model prompting. Specifically, we implement a case study that attempts to infer the inclusion of a visual asset, e.g. image, in the mRAG, and if present leak the metadata, e.g. caption, related to it. Our findings highlight the need for privacy-preserving mechanisms and motivate future research on mRAG privacy.", "AI": {"tldr": "本文通过实证研究分析了多模态检索增强生成(mRAG)管道在视觉为中心任务中的隐私风险。", "motivation": "随着mRAG管道的广泛应用，它们提供了将私有数据集连接以提高模型性能的能力，但也带来了从这些数据集中泄露私人信息的风险。", "method": "实施案例研究尝试通过标准模型提示来推断mRAG中是否存在视觉资产及其相关的元数据。", "result": "发现突显了对隐私保护机制的需求，并为未来的mRAG隐私研究提供了动力。", "conclusion": "结果表明，需要开发隐私保护措施以应对多模态检索增强生成过程中可能存在的隐私泄露风险。"}}
{"id": "2601.17642", "pdf": "https://arxiv.org/pdf/2601.17642", "abs": "https://arxiv.org/abs/2601.17642", "authors": ["Zhihao Zhang", "Liting Huang", "Guanghao Wu", "Preslav Nakov", "Heng Ji", "Usman Naseem"], "title": "Health-ORSC-Bench: A Benchmark for Measuring Over-Refusal and Safety Completion in Health Context", "categories": ["cs.AI"], "comment": "Preprint", "summary": "Safety alignment in Large Language Models is critical for healthcare; however, reliance on binary refusal boundaries often results in \\emph{over-refusal} of benign queries or \\emph{unsafe compliance} with harmful ones. While existing benchmarks measure these extremes, they fail to evaluate Safe Completion: the model's ability to maximise helpfulness on dual-use or borderline queries by providing safe, high-level guidance without crossing into actionable harm. We introduce \\textbf{Health-ORSC-Bench}, the first large-scale benchmark designed to systematically measure \\textbf{Over-Refusal} and \\textbf{Safe Completion} quality in healthcare. Comprising 31,920 benign boundary prompts across seven health categories (e.g., self-harm, medical misinformation), our framework uses an automated pipeline with human validation to test models at varying levels of intent ambiguity. We evaluate 30 state-of-the-art LLMs, including GPT-5 and Claude-4, revealing a significant tension: safety-optimised models frequently refuse up to 80\\% of \"Hard\" benign prompts, while domain-specific models often sacrifice safety for utility. Our findings demonstrate that model family and size significantly influence calibration: larger frontier models (e.g., GPT-5, Llama-4) exhibit \"safety-pessimism\" and higher over-refusal than smaller or MoE-based counterparts (e.g., Qwen-3-Next), highlighting that current LLMs struggle to balance refusal and compliance. Health-ORSC-Bench provides a rigorous standard for calibrating the next generation of medical AI assistants toward nuanced, safe, and helpful completions. The code and data will be released upon acceptance. \\textcolor{red}{Warning: Some contents may include toxic or undesired contents.}", "AI": {"tldr": "本文介绍了一个新的基准测试Health-ORSC-Bench，用于评估大型语言模型在医疗领域的过度拒绝和安全完成能力。", "motivation": "现有的基准测试无法全面评价医疗场景下大型语言模型的安全对齐性能，特别是对于边缘查询的安全指导能力。因此，开发一个能够系统性测量过度拒绝和安全完成质量的新基准是必要的。", "method": "Health-ORSC-Bench包含31,920个边界提示语句，分为七个健康类别，并使用自动化流程结合人工验证来测试模型在不同意图模糊度下的表现。该研究评估了包括GPT-5和Claude-4在内的30个最先进的大型语言模型。", "result": "研究表明，经过安全优化的模型可能会拒绝高达80%的“困难”良性提示语句，而特定领域的模型则可能牺牲安全性以换取实用性。此外，较大的前沿模型表现出较高的过度拒绝率。", "conclusion": "Health-ORSC-Bench提供了一个严格的评估标准，用于校准新一代医疗AI助手的安全性和帮助性之间的平衡。"}}
{"id": "2601.17640", "pdf": "https://arxiv.org/pdf/2601.17640", "abs": "https://arxiv.org/abs/2601.17640", "authors": ["Anfeng Xu", "Tiantian Feng", "Somer Bishop", "Catherine Lord", "Shrikanth Narayanan"], "title": "End-to-End Joint ASR and Speaker Role Diarization with Child-Adult Interactions", "categories": ["eess.AS", "cs.SD"], "comment": "Under review for IEEE", "summary": "Accurate transcription and speaker diarization of child-adult spoken interactions are crucial for developmental and clinical research. However, manual annotation is time-consuming and challenging to scale. Existing automated systems typically rely on cascaded speaker diarization and speech recognition pipelines, which can lead to error propagation. This paper presents a unified end-to-end framework that extends the Whisper encoder-decoder architecture to jointly model ASR and child-adult speaker role diarization. The proposed approach integrates: (i) a serialized output training scheme that emits speaker tags and start/end timestamps, (ii) a lightweight frame-level diarization head that enhances speaker-discriminative encoder representations, (iii) diarization-guided silence suppression for improved temporal precision, and (iv) a state-machine-based forced decoding procedure that guarantees structurally valid outputs. Comprehensive evaluations on two datasets demonstrate consistent and substantial improvements over two cascaded baselines, achieving lower multi-talker word error rates and demonstrating competitive diarization accuracy across both Whisper-small and Whisper-large models. These findings highlight the effectiveness and practical utility of the proposed joint modeling framework for generating reliable, speaker-attributed transcripts of child-adult interactions at scale. The code and model weights are publicly available", "AI": {"tldr": "本文提出了一种统一的端到端框架，扩展了Whisper编码器-解码器架构，以联合建模自动语音识别（ASR）和儿童与成人说话人角色分离。", "motivation": "准确转录和进行儿童与成人之间的口语交互的说话人分离对于发展性和临床研究至关重要。然而，手动标注耗时且难以扩展。现有的自动化系统通常依赖于级联的说话人分离和语音识别管道，这可能导致错误传播。", "method": "该方法包括：（i）一个序列化输出训练方案，该方案发出说话人标签和开始/结束时间戳；（ii）一种轻量级帧级别分离头，以增强说话人判别编码器表示；（iii）基于分离的静音抑制技术，提高时间精度；以及（iv）一种基于状态机的强制解码程序，确保结构上有效的输出。", "result": "在两个数据集上的综合评估表明，该方法与两种级联基线相比表现出一致且显著的改进，实现了更低的多说话人词错误率，并展示了跨Whisper-small和Whisper-large模型的竞争性分离准确性。", "conclusion": "研究结果强调了提出的联合建模框架的有效性和实际应用价值，能够大规模生成可靠的、按说话人归属的儿童与成人互动转录文本。"}}
{"id": "2601.17637", "pdf": "https://arxiv.org/pdf/2601.17637", "abs": "https://arxiv.org/abs/2601.17637", "authors": ["Kazuhiro Takemoto"], "title": "Scaling Laws for Moral Machine Judgment in Large Language Models", "categories": ["cs.CY", "cs.HC"], "comment": "12 pages, 4 figures, 3 tables", "summary": "Autonomous systems increasingly require moral judgment capabilities, yet whether these capabilities scale predictably with model size remains unexplored. We systematically evaluate 75 large language model configurations (0.27B--1000B parameters) using the Moral Machine framework, measuring alignment with human preferences in life-death dilemmas. We observe a consistent power-law relationship with distance from human preferences ($D$) decreasing as $D \\propto S^{-0.10\\pm0.01}$ ($R^2=0.50$, $p<0.001$) where $S$ is model size. Mixed-effects models confirm this relationship persists after controlling for model family and reasoning capabilities. Extended reasoning models show additional 16\\% improvement beyond scale effects. The relationship holds across diverse architectures, while variance decreases at larger scales, indicating systematic emergence of more reliable moral judgment with computational scale. These findings extend scaling law research to value-based judgments and provide empirical foundations for artificial intelligence governance.", "AI": {"tldr": "研究探讨了大型语言模型的规模与其在道德判断任务上的表现之间的关系，并发现存在幂律关系。", "motivation": "随着自主系统对道德判断能力的需求增加，本研究旨在探索这种能力是否能够随着模型规模的增长而可预测地提升。", "method": "使用Moral Machine框架评估75种不同参数量的大型语言模型（从0.27B到1000B）在生命与死亡困境中与人类偏好的一致性。", "result": "发现距离人类偏好的距离D和模型大小S之间存在幂律关系，即D正比于S^-0.10±0.01，且该关系在控制了模型家族和推理能力之后依然成立。扩展的推理模型在此基础上表现出额外16%的改进。", "conclusion": "研究结果表明，随着计算规模的增长，道德判断的能力更可靠地出现，并为人工智能治理提供了实证基础。"}}
{"id": "2601.17625", "pdf": "https://arxiv.org/pdf/2601.17625", "abs": "https://arxiv.org/abs/2601.17625", "authors": ["Yuhan Xie", "Jinhan Liu", "Xiaoyong Ni", "Fei Tan", "Icare Sakr", "Thibault Collin", "Shiqi Sun", "Alejandro Rodriguez Guajardo", "Demon Fanny", "Charles-francois Vincent Latchoumane", "Henri Lorach", "Jocelyne Bloch", "Gregoire Courtine", "Mahsa Shoaran"], "title": "BrainDistill: Implantable Motor Decoding with Task-Specific Knowledge Distillation", "categories": ["cs.LG", "cs.AI"], "comment": "21 pages,7 figures", "summary": "Transformer-based neural decoders with large parameter counts, pre-trained on large-scale datasets, have recently outperformed classical machine learning models and small neural networks on brain-computer interface (BCI) tasks. However, their large parameter counts and high computational demands hinder deployment in power-constrained implantable systems. To address this challenge, we introduce BrainDistill, a novel implantable motor decoding pipeline that integrates an implantable neural decoder (IND) with a task-specific knowledge distillation (TSKD) framework. Unlike standard feature distillation methods that attempt to preserve teacher representations in full, TSKD explicitly prioritizes features critical for decoding through supervised projection. Across multiple neural datasets, IND consistently outperforms prior neural decoders on motor decoding tasks, while its TSKD-distilled variant further surpasses alternative distillation methods in few-shot calibration settings. Finally, we present a quantization-aware training scheme that enables integer-only inference with activation clipping ranges learned during training. The quantized IND enables deployment under the strict power constraints of implantable BCIs with minimal performance loss.", "AI": {"tldr": "本论文介绍了BrainDistill，一种用于植入式脑机接口的新型运动解码管道，结合了植入式神经解码器（IND）和任务特定知识蒸馏框架。", "motivation": "由于参数量大和计算需求高，大型预训练模型不适合在功率受限的植入系统中部署。本论文旨在解决这一问题，并提高运动解码任务的性能。", "method": "BrainDistill采用了任务特定知识蒸馏（TSKD）方法，在监督投影下优先考虑关键特征以进行解码。此外，还提出了量化感知训练方案，支持整数仅推理和激活剪切范围学习。", "result": "实验结果表明，IND在多个神经数据集上一致优于先前的神经解码器，并且其TSKD蒸馏变体在少量样本校准设置下表现更好。", "conclusion": "量化后的IND可以在植入式BCI严格的功率约束下部署，同时保持性能损失最小。"}}
{"id": "2601.17622", "pdf": "https://arxiv.org/pdf/2601.17622", "abs": "https://arxiv.org/abs/2601.17622", "authors": ["Yoonsang Kim", "Yalong Yang", "Arie E. Kaufman"], "title": "Memento: Towards Proactive Visualization of Everyday Memories with Personal Wearable AR Assistant", "categories": ["cs.HC", "cs.CL", "cs.IR"], "comment": "8 pages, 5 figures. This is the author's version of the article that will appear at the IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (IEEE VRW) 2026", "summary": "We introduce Memento, a conversational AR assistant that permanently captures and memorizes user's verbal queries alongside their spatiotemporal and activity contexts. By storing these \"memories,\" Memento discovers connections between users' recurring interests and the contexts that trigger them. Upon detection of similar or identical spatiotemporal activity, Memento proactively recalls user interests and delivers up-to-date responses through AR, seamlessly integrating AR experience into their daily routine. Unlike prior work, each interaction in Memento is not a transient event, but a connected series of interactions with coherent long--term perspective, tailored to the user's broader multimodal (visual, spatial, temporal, and embodied) context. We conduct preliminary evaluation through user feedbacks with participants of diverse expertise in immersive apps, and explore the value of proactive context-aware AR assistant in everyday settings. We share our findings and challenges in designing a proactive, context-aware AR system.", "AI": {"tldr": "本文介绍了Memento，一种能够永久捕获和存储用户口头查询及其时空和活动上下文的对话AR助手。", "motivation": "动机在于探索在日常生活中使用主动式、环境感知型AR助理的价值，并解决设计这种系统的挑战。", "method": "通过记录用户的“记忆”，发现用户反复兴趣之间的联系及触发这些兴趣的环境，当检测到相似或相同的时空活动时，Memento会主动回忆并提供最新的AR反馈。", "result": "进行了初步评估，收集了来自不同沉浸式应用背景参与者的用户反馈。", "conclusion": "分享了设计主动和情境感知型AR系统的发现与挑战。"}}
{"id": "2601.17614", "pdf": "https://arxiv.org/pdf/2601.17614", "abs": "https://arxiv.org/abs/2601.17614", "authors": ["Yimeng Liu", "Misha Sra", "Chang Xiao"], "title": "AlignUI: A Method for Designing LLM-Generated UIs Aligned with User Preferences", "categories": ["cs.HC"], "comment": null, "summary": "Designing user interfaces that align with user preferences is a time-consuming process, which requires iterative cycles of prototyping, user testing, and refinement. Recent advancements in LLM-based UI generation have enabled efficient UI generation to assist the UI design process. We introduce AlignUI, a method that aligns LLM-generated UIs with user tasks and preferences by using a user preference dataset to guide the LLM's reasoning process. The dataset was crowdsourced from 50 general users (the target users of generated UIs) and contained 720 UI control preferences on eight image-editing tasks. We evaluated AlignUI by generating UIs for six unseen tasks and conducting a user study with 72 additional general users. The results showed that the generated UIs closely align with multiple dimensions of user preferences. We conclude by discussing the applicability of our method to support user-aligned UI design for multiple task domains and user groups, as well as personalized user needs.", "AI": {"tldr": "介绍AlignUI方法，该方法通过用户偏好数据集引导LLM生成与用户任务和偏好对齐的用户界面。", "motivation": "设计符合用户偏好的用户界面是一个耗时的过程，需要多次迭代原型、用户测试和改进。本文旨在提高基于LLM的UI生成效率，并使其更符合用户的实际需求。", "method": "使用来自50名普通用户的720个UI控制偏好数据集来指导LLM推理过程，为八个图像编辑任务生成与用户偏好对齐的UI。", "result": "在六项未见过的任务上生成UI，并通过一项针对72名额外用户的研究验证了所生成的UI符合多维度的用户偏好。", "conclusion": "讨论了该方法支持多个任务领域和用户群体，以及个性化需求的适用性。"}}
{"id": "2601.17611", "pdf": "https://arxiv.org/pdf/2601.17611", "abs": "https://arxiv.org/abs/2601.17611", "authors": ["Davide Berghi", "Philip J. B. Jackson"], "title": "ToS: A Team of Specialists ensemble framework for Stereo Sound Event Localization and Detection with distance estimation in Video", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.IV", "eess.SP"], "comment": null, "summary": "Sound event localization and detection with distance estimation (3D SELD) in video involves identifying active sound events at each time frame while estimating their spatial coordinates. This multimodal task requires joint reasoning across semantic, spatial, and temporal dimensions, a challenge that single models often struggle to address effectively. To tackle this, we introduce the Team of Specialists (ToS) ensemble framework, which integrates three complementary sub-networks: a spatio-linguistic model, a spatio-temporal model, and a tempo-linguistic model. Each sub-network specializes in a unique pair of dimensions, contributing distinct insights to the final prediction, akin to a collaborative team with diverse expertise. ToS has been benchmarked against state-of-the-art audio-visual models for 3D SELD on the DCASE2025 Task 3 Stereo SELD development set, consistently outperforming existing methods across key metrics. Future work will extend this proof of concept by strengthening the specialists with appropriate tasks, training, and pre-training curricula.", "AI": {"tldr": "本文介绍了ToS框架，用于视频中的立体声事件定位和检测，并带有距离估计。", "motivation": "单个模型难以有效处理多模态任务中语义、空间和时间维度的联合推理问题。", "method": "ToS框架集成了三个互补子网络：时空语言模型、时空模型和时序语言模型，每个子网专注于不同的维度组合。", "result": "与现有的音频视觉3D SELD方法相比，在DCASE2025任务数据集上取得了更好的性能指标。", "conclusion": "ToS框架在视频中的立体声事件定位和检测及距离估计方面表现优异，并计划进一步加强子网络的能力。"}}
{"id": "2601.17608", "pdf": "https://arxiv.org/pdf/2601.17608", "abs": "https://arxiv.org/abs/2601.17608", "authors": ["Dong Yoon Lee", "Alyssa Weakley", "Hui Wei", "Daniel Cardona", "Shijia Pan"], "title": "Home Health System Deployment Experience for Geriatric Care Remote Monitoring", "categories": ["cs.HC", "cs.SD", "eess.AS", "eess.SY"], "comment": ":J.3", "summary": "To support aging-in-place, adult children often provide care to their aging parents from a distance. These informal caregivers desire plug-and-play remote care solutions for privacy-preserving continuous monitoring that enabling real-time activity monitoring and intuitive, actionable information. This short paper presents insights from three iterations of deployment experience for remote monitoring system and the iterative improvement in hardware, modeling, and user interface guided by the Geriatric 4Ms framework (matters most, mentation, mobility, and medication). An LLM-assisted solution is developed to balance user experience (privacy-preserving, plug-and-play) and system performance.", "AI": {"tldr": "论文描述了为老年人远程照护开发的家庭健康系统部署经验，并通过三次迭代改进硬件、建模和用户界面。", "motivation": "为了支持老年人居家养老，成年子女需要从远方提供照顾。这些非正式护理人员希望拥有即插即用的远程照护解决方案，以实现隐私保护的持续监测，同时能进行实时活动监控并提供直观、可操作的信息。", "method": "基于Geriatric 4Ms框架（最重要事项、认知能力、行动能力和用药），进行了三次部署经验迭代，改进了硬件、建模和用户界面，并开发了一个LLM辅助解决方案以平衡用户体验与系统性能。", "result": "通过多次迭代优化，实现了隐私保护的即插即用远程监测方案，提高了系统的整体表现。", "conclusion": "研究展示了在家庭健康系统中实现老年人远程照护的潜力，并强调了持续改进的重要性。"}}
{"id": "2601.17604", "pdf": "https://arxiv.org/pdf/2601.17604", "abs": "https://arxiv.org/abs/2601.17604", "authors": ["Suborno Deb Bappon", "Saikat Mondal", "Chanchal K. Roy", "Kevin Schneider"], "title": "Human-Aligned Enhancement of Programming Answers with LLMs Guided by User Feedback", "categories": ["cs.SE", "cs.AI"], "comment": "Preprint", "summary": "Large Language Models (LLMs) are widely used to support software developers in tasks such as code generation, optimization, and documentation. However, their ability to improve existing programming answers in a human-like manner remains underexplored. On technical question-and-answer platforms such as Stack Overflow (SO), contributors often revise answers based on user comments that identify errors, inefficiencies, or missing explanations. Yet roughly one-third of this feedback is never addressed due to limited time, expertise, or visibility, leaving many answers incomplete or outdated. This study investigates whether LLMs can enhance programming answers by interpreting and incorporating comment-based feedback. We make four main contributions. First, we introduce ReSOlve, a benchmark consisting of 790 SO answers with associated comment threads, annotated for improvement-related and general feedback. Second, we evaluate four state-of-the-art LLMs on their ability to identify actionable concerns, finding that DeepSeek achieves the best balance between precision and recall. Third, we present AUTOCOMBAT, an LLM-powered tool that improves programming answers by jointly leveraging user comments and question context. Compared to human revised references, AUTOCOMBAT produces near-human quality improvements while preserving the original intent and significantly outperforming the baseline. Finally, a user study with 58 practitioners shows strong practical value, with 84.5 percent indicating they would adopt or recommend the tool. Overall, AUTOCOMBAT demonstrates the potential of scalable, feedback-driven answer refinement to improve the reliability and trustworthiness of technical knowledge platforms.", "AI": {"tldr": "本文介绍了一种利用大型语言模型（LLMs）根据用户反馈改进编程答案的方法。", "motivation": "由于软件开发者的有限时间和专业知识，技术问答平台上的许多问题答案并未完全响应用户的反馈。因此，研究探索了是否可以使用LLMs来提升现有程序答案的质量。", "method": "作者构建了一个名为ReSOlve的基准测试集，并评估了几种最先进的语言模型在识别用户反馈中的表现。最终开发了一种工具AUTOCOMBAT，该工具有助于改进编程答案同时保持原意。", "result": "结果表明，与人类修订的答案相比，AUTOCOMBAT能够产生接近人类质量的答案改进，并显著优于基线方法。此外，一项包含58位从业者的用户研究显示了强烈的实用价值。", "conclusion": "该研究表明利用可扩展的、基于反馈的方法来改进技术知识平台上的答案是可行且有价值的，提升了这些平台的可靠性和可信度。"}}
{"id": "2601.17598", "pdf": "https://arxiv.org/pdf/2601.17598", "abs": "https://arxiv.org/abs/2601.17598", "authors": ["Yash Kini", "Shiv Davay", "Shreya Polavarapu"], "title": "Deep Intrinsic Surprise-Regularized Control (DISRC): A Biologically Inspired Mechanism for Efficient Deep Q-Learning in Sparse Environments", "categories": ["cs.NE", "cs.LG"], "comment": "5 pages, 3 figures, 1 table. Preprint version of work submitted, accepted, and presented at IEEE URTC. Accepted and pending publication in IEEE Xplore", "summary": "Deep reinforcement learning (DRL) has driven major advances in autonomous control. Still, standard Deep Q-Network (DQN) agents tend to rely on fixed learning rates and uniform update scaling, even as updates are modulated by temporal-difference (TD) error. This rigidity destabilizes convergence, especially in sparse-reward settings where feedback is infrequent. We introduce Deep Intrinsic Surprise-Regularized Control (DISRC), a biologically inspired augmentation to DQN that dynamically scales Q-updates based on latent-space surprise. DISRC encodes states via a LayerNorm-based encoder and computes a deviation-based surprise score relative to a moving latent setpoint. Each update is then scaled in proportion to both TD error and surprise intensity, promoting plasticity during early exploration and stability as familiarity increases. We evaluate DISRC on two sparse-reward MiniGrid environments, which included MiniGrid-DoorKey-8x8 and MiniGrid-LavaCrossingS9N1, under identical settings as a vanilla DQN baseline. In DoorKey, DISRC reached the first successful episode (reward > 0.8) 33% faster than the vanilla DQN baseline (79 vs. 118 episodes), with lower reward standard deviation (0.25 vs. 0.34) and higher reward area under the curve (AUC: 596.42 vs. 534.90). These metrics reflect faster, more consistent learning - critical for sparse, delayed reward settings. In LavaCrossing, DISRC achieved a higher final reward (0.95 vs. 0.93) and the highest AUC of all agents (957.04), though it converged more gradually. These preliminary results establish DISRC as a novel mechanism for regulating learning intensity in off-policy agents, improving both efficiency and stability in sparse-reward domains. By treating surprise as an intrinsic learning signal, DISRC enables agents to modulate updates based on expectation violations, enhancing decision quality when conventional value-based methods fall short.", "AI": {"tldr": "介绍了一种名为DISRC的基于深度强化学习的方法，该方法在稀疏奖励环境中提高了学习效率和稳定性。", "motivation": "标准的DQN代理依赖于固定的学习率和均匀更新比例，这在稀疏奖励设置中不稳定，并且反馈较少。作者希望通过引入动态调整Q-更新的新机制来改善这种情况。", "method": "DISRC通过LayerNorm编码器对状态进行编码并计算基于偏差的惊喜分数，根据TD误差和惊奇强度的比例动态缩放每个更新以促进早期探索中的可塑性和随着熟悉度增加而稳定的更新。", "result": "在两个稀疏奖励的MiniGrid环境中，DISRC比标准DQN基线更快达到首次成功，并且在学习速度、稳定性和累积收益方面表现更好。", "conclusion": "DISRC作为一个新的机制，通过将惊喜作为内在的学习信号来调节非策略代理中的学习强度，在稀疏奖励领域提高了效率和稳定性。"}}
{"id": "2601.17588", "pdf": "https://arxiv.org/pdf/2601.17588", "abs": "https://arxiv.org/abs/2601.17588", "authors": ["Marcus Ma", "Shrikanth Narayanan"], "title": "Intelligence Requires Grounding But Not Embodiment", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances in LLMs have reignited scientific debate over whether embodiment is necessary for intelligence. We present the argument that intelligence requires grounding, a phenomenon entailed by embodiment, but not embodiment itself. We define intelligence as the possession of four properties -- motivation, predictive ability, understanding of causality, and learning from experience -- and argue that each can be achieved by a non-embodied, grounded agent. We use this to conclude that grounding, not embodiment, is necessary for intelligence. We then present a thought experiment of an intelligent LLM agent in a digital environment and address potential counterarguments.", "AI": {"tldr": "本文探讨了智能是否需要实体化的问题，并提出智能需要的是基础性而非实体性的概念。", "motivation": "最近大型语言模型的进步重新引发了关于智能是否需要实体化的科学辩论，作者希望通过这篇文章澄清这个话题。", "method": "定义了智能的四个属性——动机、预测能力、因果理解能力和经验学习能力，并论证这些都可以由非实体但有基础性的代理实现。通过思想实验进一步支持论点。", "result": "证明了智能可以通过具有上述四个属性的非实体化代理实现，而不是依赖于实体化。", "conclusion": "作者得出结论认为，是基础性而非实体化对智能来说是必要的。"}}
{"id": "2601.17587", "pdf": "https://arxiv.org/pdf/2601.17587", "abs": "https://arxiv.org/abs/2601.17587", "authors": ["Azza Fadhel", "Nathaniel W. Zuckschwerdt", "Aryan Deshwal", "Susmita Bose", "Amit Bandyopadhyay", "Jana Doppa"], "title": "Discovery of Feasible 3D Printing Configurations for Metal Alloys via AI-driven Adaptive Experimental Design", "categories": ["cs.AI", "cs.LG"], "comment": "Proceedings of Innovative Applications of AI (IAAI) 2026 Conference", "summary": "Configuring the parameters of additive manufacturing processes for metal alloys is a challenging problem due to complex relationships between input parameters (e.g., laser power, scan speed) and quality of printed outputs. The standard trial-and-error approach to find feasible parameter configurations is highly inefficient because validating each configuration is expensive in terms of resources (physical and human labor) and the configuration space is very large. This paper combines the general principles of AI-driven adaptive experimental design with domain knowledge to address the challenging problem of discovering feasible configurations. The key idea is to build a surrogate model from past experiments to intelligently select a small batch of input configurations for validation in each iteration. To demonstrate the effectiveness of this methodology, we deploy it for Directed Energy Deposition process to print GRCop--42, a high-performance copper--chromium--niobium alloy developed by NASA for aerospace applications. Within three months, our approach yielded multiple defect-free outputs across a range of laser powers dramatically reducing time to result and resource expenditure compared to several months of manual experimentation by domain scientists with no success. By enabling high-quality GRCop--42 fabrication on readily available infrared laser platforms for the first time, we democratize access to this critical alloy, paving the way for cost-effective, decentralized production for aerospace applications.", "AI": {"tldr": "使用AI驱动的自适应实验设计方法，发现金属合金3D打印的可行配置。", "motivation": "由于输入参数与输出质量之间复杂的关系，传统的方法在寻找金属合金3D打印的可行参数配置上效率低下且耗费大量资源。", "method": "结合领域知识和AI驱动的自适应实验设计原理，构建代理模型以智能选择需要验证的小批量输入配置。此方法被部署于定向能量沉积过程中用于打印GRCop-42合金。", "result": "在三个月内，该方法成功生产出多份无缺陷的产品，并显著减少时间与资源消耗。首次实现了使用红外激光平台高质量地制造GRCop-42。", "conclusion": "通过此方法，使关键合金的获取变得更为普及，为航空航天应用提供了低成本、分散化的生产工艺可能性。"}}
{"id": "2601.17586", "pdf": "https://arxiv.org/pdf/2601.17586", "abs": "https://arxiv.org/abs/2601.17586", "authors": ["Sebastian Doerrich", "Francesco Di Salvo", "Jonas Alle", "Christian Ledig"], "title": "Stylizing ViT: Anatomy-Preserving Instance Style Transfer for Domain Generalization", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": "Accepted at 23rd IEEE International Symposium on Biomedical Imaging (IEEE ISBI 2026)", "summary": "Deep learning models in medical image analysis often struggle with generalizability across domains and demographic groups due to data heterogeneity and scarcity. Traditional augmentation improves robustness, but fails under substantial domain shifts. Recent advances in stylistic augmentation enhance domain generalization by varying image styles but fall short in terms of style diversity or by introducing artifacts into the generated images. To address these limitations, we propose Stylizing ViT, a novel Vision Transformer encoder that utilizes weight-shared attention blocks for both self- and cross-attention. This design allows the same attention block to maintain anatomical consistency through self-attention while performing style transfer via cross-attention. We assess the effectiveness of our method for domain generalization by employing it for data augmentation on three distinct image classification tasks in the context of histopathology and dermatology. Results demonstrate an improved robustness (up to +13% accuracy) over the state of the art while generating perceptually convincing images without artifacts. Additionally, we show that Stylizing ViT is effective beyond training, achieving a 17% performance improvement during inference when used for test-time augmentation. The source code is available at https://github.com/sdoerrich97/stylizing-vit .", "AI": {"tldr": "论文提出了Stylizing ViT，一种新型的视觉变换器编码器，用于改进医学图像分析中模型的领域泛化能力。", "motivation": "深度学习模型在处理医疗图像时，在不同领域和人口群体之间往往难以保持良好的泛化性能。传统的数据增强技术虽然能提高鲁棒性但在显著的域偏移情况下效果不佳。因此提出了一种新的方法来提升领域泛化能力和生成无瑕疵的具有多样风格的图像。", "method": "Stylizing ViT利用共享权重注意力块同时执行自注意和交叉注意，以维持解剖学一致性的同时进行样式转移。", "result": "实验结果表明该方法在三种不同的医学图像分类任务中提高了模型的鲁棒性（最高提升13%准确性）并生成了无瑕疵、视觉上具有说服力的图像。此外，在推理过程中用于测试时间增强时，性能提升了17%。", "conclusion": "Stylizing ViT通过其独特的注意力机制设计成功地改进了医学图像分析模型在领域泛化方面的表现，并证明了该方法的有效性和鲁棒性。"}}
{"id": "2601.17584", "pdf": "https://arxiv.org/pdf/2601.17584", "abs": "https://arxiv.org/abs/2601.17584", "authors": ["Mahmoud Samir Fayed", "Ahmed Samir Fayed"], "title": "Prompt Driven Development with Claude Code: Building a Complete TUI Framework for the Ring Programming Language", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large language models are increasingly used in software development, yet their ability to generate and maintain large, multi module systems through natural language interaction remains insufficiently characterized. This study presents an empirical analysis of developing a 7420 line Terminal User Interface framework for the Ring programming language, completed in roughly ten hours of active work spread across three days using a purely prompt driven workflow with Claude Code, Opus 4.5. The system was produced through 107 prompts: 21 feature requests, 72 bug fix prompts, 9 prompts sharing information from Ring documentation, 4 prompts providing architectural guidance, and 1 prompt dedicated to generating documentation. Development progressed across five phases, with the Window Manager phase requiring the most interaction, followed by complex UI systems and controls expansion. Bug related prompts covered redraw issues, event handling faults, runtime errors, and layout inconsistencies, while feature requests focused primarily on new widgets, window manager capabilities, and advanced UI components. Most prompts were short, reflecting a highly iterative workflow in which the human role was limited to specifying requirements, validating behaviour, and issuing corrective prompts without writing any code manually. The resulting framework includes a complete windowing subsystem, event driven architecture, interactive widgets, hierarchical menus, grid and tree components, tab controls, and a multi window desktop environment. By combining quantitative prompt analysis with qualitative assessment of model behaviour, this study provides empirical evidence that modern LLMs can sustain architectural coherence and support the construction of production grade tooling for emerging programming languages, highlighting prompt driven development as a viable methodology within software engineering practice.", "AI": {"tldr": "本研究通过使用Claude Code进行提示驱动开发，完成了Ring编程语言的一个完整的终端用户界面框架的构建。", "motivation": "大型语言模型在软件开发中的应用日益增多，但其生成和维护大规模、多模块系统的能力尚待充分探索。", "method": "该研究采用纯提示驱动工作流，通过107个提示完成了整个开发过程，包括功能请求、错误修复以及架构指导等。", "result": "在约十小时的活跃工作中，成功构建了包含窗口管理子系统、事件驱动架构和多种交互控件的完整框架，并验证了现代大型语言模型支持生产级工具构建的能力。", "conclusion": "本研究表明，提示驱动开发是一种可行的方法论，在软件工程实践中可以维持系统的结构一致性并支持新兴编程语言的工具构建。"}}
{"id": "2601.17582", "pdf": "https://arxiv.org/pdf/2601.17582", "abs": "https://arxiv.org/abs/2601.17582", "authors": ["Maurice Filo", "Nicolò Rossi", "Zhou Fang", "Mustafa Khammash"], "title": "GenAI-Net: A Generative AI Framework for Automated Biomolecular Network Design", "categories": ["q-bio.QM", "cs.AI", "cs.LG", "eess.SY", "q-bio.MN"], "comment": null, "summary": "Biomolecular networks underpin emerging technologies in synthetic biology-from robust biomanufacturing and metabolic engineering to smart therapeutics and cell-based diagnostics-and also provide a mechanistic language for understanding complex dynamics in natural and ecological systems. Yet designing chemical reaction networks (CRNs) that implement a desired dynamical function remains largely manual: while a proposed network can be checked by simulation, the reverse problem of discovering a network from a behavioral specification is difficult, requiring substantial human insight to navigate a vast space of topologies and kinetic parameters with nonlinear and possibly stochastic dynamics. Here we introduce GenAI-Net, a generative AI framework that automates CRN design by coupling an agent that proposes reactions to simulation-based evaluation defined by a user-specified objective. GenAI-Net efficiently produces novel, topologically diverse solutions across multiple design tasks, including dose responses, complex logic gates, classifiers, oscillators, and robust perfect adaptation in deterministic and stochastic settings (including noise reduction). By turning specifications into families of circuit candidates and reusable motifs, GenAI-Net provides a general route to programmable biomolecular circuit design and accelerates the translation from desired function to implementable mechanisms.", "AI": {"tldr": "本文介绍了一种名为GenAI-Net的生成式AI框架，该框架可以自动化设计化学反应网络（CRN），以实现特定的动力学功能。", "motivation": "尽管可以通过模拟验证一个提议的生物分子网络，但根据行为规范来发现对应的网络却是一个难题。这需要大量的人类洞察力去探索庞大的拓扑和动力参数空间。", "method": "GenAI-Net通过耦合提出反应的代理与基于用户指定目标的仿真评估来进行化学反应网络（CRN）的设计自动化。", "result": "GenAI-Net能够高效地生成在多个设计任务中具有新颖性且多样化的解决方案，包括剂量反应、复杂逻辑门、分类器、振荡器以及确定性和随机设置下的鲁棒完美适应。", "conclusion": "通过将规范转化为电路候选和可重复使用的模式家族，GenAI-Net为程序化生物分子电路设计提供了一条通用路径，并加速了从所需功能到可行机制的转化。"}}
{"id": "2601.17581", "pdf": "https://arxiv.org/pdf/2601.17581", "abs": "https://arxiv.org/abs/2601.17581", "authors": ["Daniel Ogenrwot", "John Businge"], "title": "How AI Coding Agents Modify Code: A Large-Scale Study of GitHub Pull Requests", "categories": ["cs.SE", "cs.AI"], "comment": "5 pages, 5 figures", "summary": "AI coding agents are increasingly acting as autonomous contributors by generating and submitting pull requests (PRs). However, we lack empirical evidence on how these agent-generated PRs differ from human contributions, particularly in how they modify code and describe their changes. Understanding these differences is essential for assessing their reliability and impact on development workflows. Using the MSR 2026 Mining Challenge version of the AIDev dataset, we analyze 24,014 merged Agentic PRs (440,295 commits) and 5,081 merged Human PRs (23,242 commits). We examine additions, deletions, commits, and files touched, and evaluate the consistency between PR descriptions and their diffs using lexical and semantic similarity. Agentic PRs differ substantially from Human PRs in commit count (Cliff's $δ= 0.5429$) and show moderate differences in files touched and deleted lines. They also exhibit slightly higher description-to-diff similarity across all measures. These findings provide a large-scale empirical characterization of how AI coding agents contribute to open source development.", "AI": {"tldr": "研究分析了AI编码代理在GitHub拉取请求中的代码修改模式，并将其与人类贡献进行了比较。", "motivation": "缺乏关于AI生成的拉取请求如何修改代码以及描述其更改方式的实际证据，理解这些差异对于评估它们对开发工作流的影响和可靠性至关重要。", "method": "使用MSR 2026挖掘挑战版AIDev数据集，分析了24,014个合并的AI代理PR（涉及440,295次提交）和5,081个人类贡献的PR（涉及23,242次提交）。通过添加、删除、提交和触及文件数进行评估，并使用词汇和语义相似性来评价拉取请求描述与其差异的一致性。", "result": "AI生成的拉取请求在提交次数上与人类显著不同（Cliff's $δ= 0.5429$），并且在触及文件数量和删除行数上有中等程度的区别。它们还显示出所有度量上的描述到差异相似性略高。", "conclusion": "这些发现提供了AI编码代理如何参与开源开发的大规模实证特征。"}}
{"id": "2601.17577", "pdf": "https://arxiv.org/pdf/2601.17577", "abs": "https://arxiv.org/abs/2601.17577", "authors": ["Emilio Barkett"], "title": "Status Hierarchies in Language Models", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": null, "summary": "From school playgrounds to corporate boardrooms, status hierarchies -- rank orderings based on respect and perceived competence -- are universal features of human social organization. Language models trained on human-generated text inevitably encounter these hierarchical patterns embedded in language, raising the question of whether they might reproduce such dynamics in multi-agent settings. This thesis investigates when and how language models form status hierarchies by adapting Berger et al.'s (1972) expectation states framework. I create multi-agent scenarios where separate language model instances complete sentiment classification tasks, are introduced with varying status characteristics (e.g., credentials, expertise), then have opportunities to revise their initial judgments after observing their partner's responses. The dependent variable is deference, the rate at which models shift their ratings toward their partner's position based on status cues rather than task information. Results show that language models form significant status hierarchies when capability is equal (35 percentage point asymmetry, p < .001), but capability differences dominate status cues, with the most striking effect being that high-status assignments reduce higher-capability models' deference rather than increasing lower-capability models' deference. The implications for AI safety are significant: status-seeking behavior could introduce deceptive strategies, amplify discriminatory biases, and scale across distributed deployments far faster than human hierarchies form organically. This work identifies emergent social behaviors in AI systems and highlights a previously underexplored dimension of the alignment challenge.", "AI": {"tldr": "该论文探讨了语言模型在多智能体环境中如何形成地位等级，并研究了这种动态对人工智能安全的影响。", "motivation": "由于人类社会中普遍存在的地位层级，作者希望了解训练过的语言模型是否会在类似的人类交互场景中重现这些等级模式，并探究其可能产生的影响。", "method": "采用了Berger等人（1972）的期望状态框架，在多智能体环境中构建了不同的地位特征（如资格、专长），并通过观察彼此的回答来调整最初的判断，以此来衡量语言模型之间的地位差异和顺从行为。", "result": "研究结果表明，当能力相等时，语言模型确实会形成显著的地位等级；但当存在能力差异时，这种差异对地位线索的影响超过了地位本身的作用。特别是高地位的分配反而减少了较高能力模型的顺从度。", "conclusion": "该研究表明人工智能系统中新兴的社会行为可能会导致欺骗策略和歧视偏见的放大，并强调了在分布式部署中这一现象可能快速扩展的重要性。"}}
{"id": "2601.17572", "pdf": "https://arxiv.org/pdf/2601.17572", "abs": "https://arxiv.org/abs/2601.17572", "authors": ["Ethan Gibbons", "Mario Ventresca", "Beatrice M. Ombuki-Berman"], "title": "Split Algorithm in Linear Time for the Vehicle Routing Problem with Simultaneous Pickup and Delivery and Time Windows", "categories": ["cs.DS"], "comment": null, "summary": "For many kinds of vehicle routing problems (VRPs), a popular heuristic approach involves constructing a Traveling Salesman Problem (TSP) solution, referred to as a long tour, then partitioning segments of the solution into routes for different vehicles with respect to problem constraints. Previously, a Split algorithm with a worst-case runtime of $Θ(n)$ was proposed for the capacitated VRP (CVRP) that finds the most cost-efficient partition of customers, given a long tour. This was an improvement over the previously fastest-known Split algorithm with a worst-case runtime of $Θ(n^2)$ that was based on Bellman's shortest path algorithm. While this linear Split has been an integral part of modern state-of-the-art CVRP approaches, little progress has been made in extending this algorithm to handle additional VRP variants, limiting the general applicability of the algorithm. In this work, we propose an extension of the linear Split that handles two cardinal VRP variants simultaneously: (i) simultaneous pickups and deliveries (VRPSPD) and (ii) time windows (VRPTW). The resulting $Θ(n)$ algorithm is guaranteed to be optimal, assuming travel times between nodes satisfy the triangle inequality. Additionally, we extend the linear Split to handle a capacity penalty for the VRPSPD. For the VRPTW, we extend the linear Split to handle the CVRP capacity penalty in conjunction with the popular time warp penalty function. Computational experiments are performed to empirically validate the speed gains of these linear Splits against their $Θ$($n^2$) counterparts.", "AI": {"tldr": "本文提出了一种线性时间的Split算法，用于解决带有同时装载和卸载以及时间窗口限制的车辆路径问题（VRPSPD-TW）。", "motivation": "虽然已有线性时间复杂度的Split算法被应用于容量受限的车辆路径问题（CVRP），但将其扩展到其他VRP变种上仍存在困难，这限制了该算法的一般适用性。本文旨在解决这一局限。", "method": "提出了一种新的线性时间复杂度的Split算法，同时处理带有同时装载和卸载以及时间窗口约束的问题，并对容量惩罚进行了扩展。", "result": "实验结果验证了新提出的线性Split算法相较于传统的$Θ(n^2)$算法在速度上的优势。", "conclusion": "本文通过提出适用于VRPSPD-TW的线性时间复杂度的Split算法，扩展了现有算法的应用范围，并证实其性能优于传统算法。"}}
{"id": "2601.17571", "pdf": "https://arxiv.org/pdf/2601.17571", "abs": "https://arxiv.org/abs/2601.17571", "authors": ["Javier González-Alonso", "Paula Martín-Tapia", "David González-Ortega", "Míriam Antón-Rodríguez", "Francisco Javier Díaz-Pernas", "Mario Martínez-Zarzuela"], "title": "ME-WARD: A multimodal ergonomic analysis tool for musculoskeletal risk assessment from inertial and video data in working plac", "categories": ["eess.SP", "cs.CV", "cs.LG"], "comment": "19 pages", "summary": "This study presents ME-WARD (Multimodal Ergonomic Workplace Assessment and Risk from Data), a novel system for ergonomic assessment and musculoskeletal risk evaluation that implements the Rapid Upper Limb Assessment (RULA) method. ME-WARD is designed to process joint angle data from motion capture systems, including inertial measurement unit (IMU)-based setups, and deep learning human body pose tracking models. The tool's flexibility enables ergonomic risk assessment using any system capable of reliably measuring joint angles, extending the applicability of RULA beyond proprietary setups. To validate its performance, the tool was tested in an industrial setting during the assembly of conveyor belts, which involved high-risk tasks such as inserting rods and pushing conveyor belt components. The experiments leveraged gold standard IMU systems alongside a state-of-the-art monocular 3D pose estimation system. The results confirmed that ME-WARD produces reliable RULA scores that closely align with IMU-derived metrics for flexion-dominated movements and comparable performance with the monocular system, despite limitations in tracking lateral and rotational motions. This work highlights the potential of integrating multiple motion capture technologies into a unified and accessible ergonomic assessment pipeline. By supporting diverse input sources, including low-cost video-based systems, the proposed multimodal approach offers a scalable, cost-effective solution for ergonomic assessments, paving the way for broader adoption in resource-constrained industrial environments.", "AI": {"tldr": "本文介绍了一种名为ME-WARD的新型系统，用于通过惯性和视频数据进行人体工学评估和肌肉骨骼风险分析。", "motivation": "开发ME-WARD系统的动机在于扩展RULA方法的应用范围，并使其能够适应任何可以准确测量关节角度的系统，从而在工业场所实现更广泛且经济的人体工学风险评估。", "method": "ME-WARD使用了多模态数据源，包括惯性测量单元(IMU)和基于深度学习的人体姿态跟踪模型的数据进行人体工学分析。", "result": "实验验证表明，ME-WARD能够提供可靠的RULA评分，并且与IMU系统的评估结果高度一致，在处理屈曲运动时表现尤为出色。尽管在横向和旋转动作的追踪上存在一些局限性，但整体性能仍然接近最先进的单目3D姿态估计系统。", "conclusion": "本文展示了整合多种运动捕捉技术以实现统一的人体工学评估管道的可能性，并表明了这种多模态方法作为人体工学评估的一种可扩展、成本效益高的解决方案具有广阔的应用前景。"}}
{"id": "2601.17570", "pdf": "https://arxiv.org/pdf/2601.17570", "abs": "https://arxiv.org/abs/2601.17570", "authors": ["Hadi Salloum", "Ali Jnadi", "Yaroslav Kholodov", "Alexander Gasnikov"], "title": "Quantum-Inspired Episode Selection for Monte Carlo Reinforcement Learning via QUBO Optimization", "categories": ["cs.LG", "cs.RO"], "comment": "Proceedings of Machine Learning Research tbd: 1_13, 2025 International Conference on Computational Optimization", "summary": "Monte Carlo (MC) reinforcement learning suffers from high sample complexity, especially in environments with sparse rewards, large state spaces, and correlated trajectories. We address these limitations by reformulating episode selection as a Quadratic Unconstrained Binary Optimization (QUBO) problem and solving it with quantum-inspired samplers. Our method, MC+QUBO, integrates a combinatorial filtering step into standard MC policy evaluation: from each batch of trajectories, we select a subset that maximizes cumulative reward while promoting state-space coverage. This selection is encoded as a QUBO, where linear terms favor high-reward episodes and quadratic terms penalize redundancy. We explore both Simulated Quantum Annealing (SQA) and Simulated Bifurcation (SB) as black-box solvers within this framework. Experiments in a finite-horizon GridWorld demonstrate that MC+QUBO outperforms vanilla MC in convergence speed and final policy quality, highlighting the potential of quantum-inspired optimization as a decision-making subroutine in reinforcement learning.", "AI": {"tldr": "本文提出了一种基于QUBO优化的量子启发式剧集选择方法，用于改进蒙特卡洛强化学习中的样本复杂性问题。", "motivation": "传统的蒙特卡洛强化学习在稀疏奖励、大状态空间和相关轨迹环境中面临高样本复杂性的挑战，因此本文旨在通过引入量子启发式的优化来改善这些问题。", "method": "该方法将剧集选择重新定义为一个QUBO问题，并使用量子启发式采样器解决，具体包括线性项以促进高奖励的剧集选择和二次项以减少冗余。同时探索了SQA和SB作为求解框架中的黑盒求解器。", "result": "实验结果表明，在有限时间范围内的GridWorld中，MC+QUBO方法在收敛速度和最终策略质量上优于传统的蒙特卡洛方法。", "conclusion": "研究展示了量子启发式优化作为一种决策子程序在强化学习中的潜力，并验证了其有效性和优越性。"}}
{"id": "2601.17569", "pdf": "https://arxiv.org/pdf/2601.17569", "abs": "https://arxiv.org/abs/2601.17569", "authors": ["Alireza Salemi", "Hamed Zamani"], "title": "Improving User Privacy in Personalized Generation: Client-Side Retrieval-Augmented Modification of Server-Side Generated Speculations", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.IR"], "comment": null, "summary": "Personalization is crucial for aligning Large Language Model (LLM) outputs with individual user preferences and background knowledge. State-of-the-art solutions are based on retrieval augmentation, where relevant context from a user profile is retrieved for LLM consumption. These methods deal with a trade-off between exposing retrieved private data to cloud providers and relying on less capable local models. We introduce $P^3$, an interactive framework for high-quality personalization without revealing private profiles to server-side LLMs. In $P^3$, a large server-side model generates a sequence of $k$ draft tokens based solely on the user query, while a small client-side model, with retrieval access to the user's private profile, evaluates and modifies these drafts to better reflect user preferences. This process repeats until an end token is generated. Experiments on LaMP-QA, a recent benchmark consisting of three personalized question answering datasets, show that $P^3$ consistently outperforms both non-personalized server-side and personalized client-side baselines, achieving statistically significant improvements of $7.4%$ to $9%$ on average. Importantly, $P^3$ recovers $90.3%$ to $95.7%$ of the utility of a ``leaky'' upper-bound scenario in which the full profile is exposed to the large server-side model. Privacy analyses, including linkability and attribute inference attacks, indicate that $P^3$ preserves the privacy of a non-personalized server-side model, introducing only marginal additional leakage ($1.5%$--$3.5%$) compared to submitting a query without any personal context. Additionally, the framework is efficient for edge deployment, with the client-side model generating only $9.2%$ of the total tokens. These results demonstrate that $P^3$ provides a practical, effective solution for personalized generation with improved privacy.", "AI": {"tldr": "本文介绍了$P^3$，一个交互式框架，用于在不向服务器端大型语言模型暴露用户私人资料的情况下实现高质量的个性化生成。", "motivation": "该研究旨在解决现有个性化解决方案中数据隐私泄露和依赖本地较弱模型之间的权衡问题。通过提出一种新的方法来保护用户的隐私同时提高个性化生成的质量。", "method": "$P^3$框架中，服务器端大型语言模型仅根据用户查询生成$k$个草案令牌序列，客户端小型模型则访问用户的私人资料对这些草案进行评估和修改以更好地反映用户偏好。此过程重复直到生成结束标记。", "result": "实验结果表明，在LaMP-QA基准测试中的三个个性化问答数据集中，$P^3$框架在非个性化的服务器端基线和个人化客户端基线上均表现出显著的改进（平均提升7.4%到9%）。隐私分析显示，与没有个人上下文相比，$P^3$引入了仅有的1.5%-3.5%额外信息泄漏。", "conclusion": "$P^3$框架提供了一种实际有效的解决方案，在提高个性化生成质量的同时保护用户隐私。"}}
{"id": "2601.17568", "pdf": "https://arxiv.org/pdf/2601.17568", "abs": "https://arxiv.org/abs/2601.17568", "authors": ["Amritha Premkumar", "Christian Herglotz"], "title": "Fast Multirate Encoding for 360° Video in OMAF Streaming Workflows", "categories": ["eess.IV", "cs.MM"], "comment": "Mile High Video (MHV), 2026", "summary": "Preparing high-quality 360-degree video for HTTP Adaptive Streaming requires encoding each sequence into multiple representations spanning different resolutions and quantization parameters (QPs). For ultra-high-resolution immersive content such as 8K 360-degree video, this process is computationally intensive due to the large number of representations and the high complexity of modern codecs. This paper investigates fast multirate encoding strategies that reduce encoding time by reusing encoder analysis information across QPs and resolutions. We evaluate two cross-resolution information-reuse pipelines that differ in how reference encodes propagate across resolutions: (i) a strict HD -> 4K -> 8K cascade with scaled analysis reuse, and (ii) a resolution-anchored scheme that initializes each resolution with its own highest-bitrate reference before guiding dependent encodes. In addition to evaluating these pipelines on standard equirectangular projection content, we also apply the same two pipelines to cubemap-projection (CMP) tiling, where each 360-degree frame is partitioned into independently encoded tiles. CMP introduces substantial parallelism, while still benefiting from the proposed multirate analysis-reuse strategies. Experimental results using the SJTU 8K 360-degree dataset show that hierarchical analysis reuse significantly accelerates HEVC encoding with minimal rate-distortion impact across both equirectangular and CMP-tiled content, yielding encoding-time reductions of roughly 33%-59% for ERP and about 51% on average for CMP, with Bjontegaard Delta Encoding Time (BDET) gains approaching -50% and wall-clock speedups of up to 4.2x.", "AI": {"tldr": "研究了用于360度视频快速多速率编码策略，通过重用不同量化参数和分辨率下的编码分析信息来减少编码时间。", "motivation": "高分辨率的沉浸式内容（如8K 360度视频）在HTTP自适应流媒体中的准备过程需要大量计算资源，因此研究如何加速这一过程。", "method": "评估了两种跨分辨率信息重用管道：一种是严格的HD -> 4K -> 8K级联，另一种是以分辨率为基础的方案。同时将这两种策略应用于立方体映射投影（CMP）分块编码中。", "result": "实验结果表明，层次分析复用显著加速HEVC编码，对率失真影响较小，ERP和CMP内容分别减少了33%-59%和平均约51%的编码时间，并且BDET增益接近-50%，实际速度提升高达4.2倍。", "conclusion": "提出的多速率分析复用策略能够在保持质量的同时大幅减少高分辨率360度视频的编码时间。"}}
{"id": "2601.17567", "pdf": "https://arxiv.org/pdf/2601.17567", "abs": "https://arxiv.org/abs/2601.17567", "authors": ["Zijing Hui", "Wenhan Lyu", "Shusen Wang", "Li Chen", "Chu Wang"], "title": "Real-Time Trend Prediction via Continually-Aligned LLM Query Generation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Trending news detection in low-traffic search environments faces a fundamental cold-start problem, where a lack of query volume prevents systems from identifying emerging or long-tail trends. Existing methods relying on keyword frequency or query spikes are inherently slow and ineffective in these sparse settings, lagging behind real-world shifts in attention. We introduce RTTP, a novel Real-Time Trending Prediction framework that generates search queries directly from news content instead of waiting for users to issue them. RTTP leverages a continual learning LLM (CL-LLM) that converts posts into search-style queries and scores them using engagement strength + creator authority, enabling early trend surfacing before search volume forms. To ensure adaptation without degrading reasoning, we propose Mix-Policy DPO, a new preference-based continual learning approach that combines on-policy stability with off-policy novelty to mitigate catastrophic forgetting during model upgrades. Deployed at production scale on Facebook and Meta AI products, RTTP delivers +91.4% improvement in tail-trend detection precision@500 and +19% query generation accuracy over industry baselines, while sustaining stable performance after multi-week online training. This work demonstrates that LLM-generated synthetic search signals, when aligned and continually updated, unlock timely trend understanding in low-traffic search environments.", "AI": {"tldr": "本文介绍了RTTP，一种通过持续学习的大语言模型（CL-LLM）从新闻内容生成搜索查询以实现实时趋势预测的框架。", "motivation": "现有的依赖于关键词频率或查询峰值的趋势检测方法在低流量搜索环境中效果不佳，因为缺乏足够的用户查询来识别新兴或长尾趋势。为此，作者提出了RTTP框架，旨在通过直接生成搜索查询而非等待用户发起，解决冷启动问题并实现早期趋势的快速捕捉。", "method": "RTTP利用CL-LLM将新闻帖子转化为类似搜索的查询，并结合参与强度和创建者权威性进行评分。为了适应模型升级而不损害推理能力，作者还提出了一种名为Mix-Policy DPO的新偏好持续学习方法，该方法结合了在线策略稳定性和离线策略新颖性，以缓解灾难性遗忘。", "result": "在Facebook和Meta AI产品的生产规模部署中，RTTP相较于行业基线，在长尾趋势检测的精度@500上提高了91.4%，查询生成准确性提升了19%。该框架还展示了在多周在线训练后的稳定性能。", "conclusion": "研究证明了当与持续更新保持一致时，由大语言模型生成的合成搜索信号能够解锁低流量搜索环境中的及时趋势理解能力。"}}
{"id": "2601.17566", "pdf": "https://arxiv.org/pdf/2601.17566", "abs": "https://arxiv.org/abs/2601.17566", "authors": ["Qi Li", "Xinchao Wang"], "title": "Sponge Tool Attack: Stealthy Denial-of-Efficiency against Tool-Augmented Agentic Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Enabling large language models (LLMs) to solve complex reasoning tasks is a key step toward artificial general intelligence. Recent work augments LLMs with external tools to enable agentic reasoning, achieving high utility and efficiency in a plug-and-play manner. However, the inherent vulnerabilities of such methods to malicious manipulation of the tool-calling process remain largely unexplored. In this work, we identify a tool-specific attack surface and propose Sponge Tool Attack (STA), which disrupts agentic reasoning solely by rewriting the input prompt under a strict query-only access assumption. Without any modification on the underlying model or the external tools, STA converts originally concise and efficient reasoning trajectories into unnecessarily verbose and convoluted ones before arriving at the final answer. This results in substantial computational overhead while remaining stealthy by preserving the original task semantics and user intent. To achieve this, we design STA as an iterative, multi-agent collaborative framework with explicit rewritten policy control, and generates benign-looking prompt rewrites from the original one with high semantic fidelity. Extensive experiments across 6 models (including both open-source models and closed-source APIs), 12 tools, 4 agentic frameworks, and 13 datasets spanning 5 domains validate the effectiveness of STA.", "AI": {"tldr": "本文介绍了海绵工具攻击（STA），一种通过重写输入提示来破坏增强智能代理推理效率的攻击方法。", "motivation": "增强大型语言模型（LLMs）解决复杂推理任务的能力是实现人工智能的关键步骤。然而，通过外部工具增强LLMs的方法存在被恶意操纵的风险，这种风险尚未得到充分研究。本文旨在识别此类工具特定的攻击面并提出一种新的攻击方法。", "method": "海绵工具攻击（STA）在不修改基础模型或外部工具的前提下，通过重写输入提示来使原本简洁高效的推理过程变得冗长复杂。STA设计为一个迭代多智能体协作框架，并具有显式的重写策略控制。", "result": "实验表明，在6种模型、12个工具、4种增强框架和跨越5个领域的13个数据集上，STA有效地实现了其攻击目标，增加了计算开销同时保持了原任务语义和用户意图的完整。", "conclusion": "海绵工具攻击（STA）展示了在特定条件下通过修改输入提示来显著降低代理推理效率的可能性，并验证了这种方法的有效性。"}}
{"id": "2601.17564", "pdf": "https://arxiv.org/pdf/2601.17564", "abs": "https://arxiv.org/abs/2601.17564", "authors": ["Aadam", "Monu Verma", "Mohamed Abdel-Mottaleb"], "title": "JaxARC: A High-Performance JAX-based Environment for Abstraction and Reasoning Research", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The Abstraction and Reasoning Corpus (ARC) tests AI systems' ability to perform human-like inductive reasoning from a few demonstration pairs. Existing Gymnasium-based RL environments severely limit experimental scale due to computational bottlenecks. We present JaxARC, an open-source, high-performance RL environment for ARC implemented in JAX. Its functional, stateless architecture enables massive parallelism, achieving 38-5,439x speedup over Gymnasium at matched batch sizes, with peak throughput of 790M steps/second. JaxARC supports multiple ARC datasets, flexible action spaces, composable wrappers, and configuration-driven reproducibility, enabling large-scale RL research previously computationally infeasible. JaxARC is available at https://github.com/aadimator/JaxARC.", "AI": {"tldr": "介绍了JaxARC，一个基于JAX的高性能环境，用于进行抽象和推理研究。", "motivation": "现有的Gymnasium基础的强化学习环境由于计算瓶颈限制了实验规模，因此开发了JaxARC以解决这一问题。", "method": "通过使用JAX实现了功能性和无状态架构，支持大规模并行计算，以及多种ARC数据集、灵活的动作空间和可配置驱动的复现性。", "result": "相比Gymnasium环境，在相同批量大小下获得了38-5,439倍的速度提升，峰值吞吐量达到每秒7.9亿步。", "conclusion": "JaxARC为大规模强化学习研究提供了计算上可行的解决方案，并且已经在GitHub上开源。"}}
{"id": "2601.17563", "pdf": "https://arxiv.org/pdf/2601.17563", "abs": "https://arxiv.org/abs/2601.17563", "authors": ["Nathan Gavenski", "Matteo Leonetti", "Odinaldo Rodrigues"], "title": "Towards Generalisable Imitation Learning Through Conditioned Transition Estimation and Online Behaviour Alignment", "categories": ["cs.LG", "cs.AI"], "comment": "The 25th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2026)", "summary": "State-of-the-art imitation learning from observation methods (ILfO) have recently made significant progress, but they still have some limitations: they need action-based supervised optimisation, assume that states have a single optimal action, and tend to apply teacher actions without full consideration of the actual environment state. While the truth may be out there in observed trajectories, existing methods struggle to extract it without supervision. In this work, we propose Unsupervised Imitation Learning from Observation (UfO) that addresses all of these limitations. UfO learns a policy through a two-stage process, in which the agent first obtains an approximation of the teacher's true actions in the observed state transitions, and then refines the learned policy further by adjusting agent trajectories to closely align them with the teacher's. Experiments we conducted in five widely used environments show that UfO not only outperforms the teacher and all other ILfO methods but also displays the smallest standard deviation. This reduction in standard deviation indicates better generalisation in unseen scenarios.", "AI": {"tldr": "本文提出了一种无监督的从观察中进行模仿学习的方法（UfO），通过两阶段的过程来改进现有方法，并展示其在多个环境中的优越性能和更好的泛化能力。", "motivation": "现有的基于观察的模仿学习方法存在需要动作级别的有监督优化、假设状态具有单一最优动作以及忽略实际环境状态等问题，本文旨在解决这些问题并提高模型的泛化能力。", "method": "UfO方法通过两阶段过程实现：首先估计教师在观测到的状态转换中的真实动作；然后调整代理轨迹以与教师的行为更紧密对齐。", "result": "实验结果显示，UfO不仅超越了教师和其他现有的ILfO方法，并且在所有环境中展示了最小的标准差，表明其具有更好的泛化能力。", "conclusion": "本文提出的方法UfO解决了现有模仿学习中的几个关键问题，并通过实验验证了该方法的有效性和优越性，尤其是在提高性能和泛化能力方面。"}}
{"id": "2601.17557", "pdf": "https://arxiv.org/pdf/2601.17557", "abs": "https://arxiv.org/abs/2601.17557", "authors": ["Aref Farhadipour", "Ming Jin", "Valeriia Vyshnevetska", "Xiyang Li", "Elisa Pellegrino", "Srikanth Madikeri"], "title": "Spoofing-Aware Speaker Verification via Wavelet Prompt Tuning and Multi-Model Ensembles", "categories": ["eess.AS", "cs.SD"], "comment": "System description of the T03 team in the WildSpoof Challenge at ICASSP 2026", "summary": "This paper describes the UZH-CL system submitted to the SASV section of the WildSpoof 2026 challenge. The challenge focuses on the integrated defense against generative spoofing attacks by requiring the simultaneous verification of speaker identity and audio authenticity. We proposed a cascaded Spoofing-Aware Speaker Verification framework that integrates a Wavelet Prompt-Tuned XLSR-AASIST countermeasure with a multi-model ensemble. The ASV component utilizes the ResNet34, ResNet293, and WavLM-ECAPA-TDNN architectures, with Z-score normalization followed by score averaging. Trained on VoxCeleb2 and SpoofCeleb, the system obtained a Macro a-DCF of 0.2017 and a SASV EER of 2.08%. While the system achieved a 0.16% EER in spoof detection on the in-domain data, results on unseen datasets, such as the ASVspoof5, highlight the critical challenge of cross-domain generalization.", "AI": {"tldr": "本文介绍了UZH-CL系统参加WildSpoof 2026挑战赛SASV部分的方案，该系统通过Wavelet Prompt Tuning和多模型集成来实现对抗生成式欺骗攻击的说话人验证。", "motivation": "论文动机在于解决说话人身份验证与音频真实性验证同时进行的问题，以防御生成式欺骗攻击。", "method": "提出了一种级联的反欺诈说话人验证框架，结合Wavelet Prompt-Tuned XLSR-AASIST对抗措施和多模型集成技术。ASV部分采用ResNet34、ResNet293和WavLM-ECAPA-TDNN架构，并在Z-score标准化后进行得分平均。", "result": "系统在VoxCeleb2和SpoofCeleb上训练，取得了Macro a-DCF为0.2017和SASV EER为2.08%的成绩。对域内数据的欺骗检测EER达到0.16%，但在未见数据集上的结果显示出跨领域泛化的挑战。", "conclusion": "论文得出结论，尽管系统在特定数据集上表现良好，但跨领域的泛化能力仍然是一个重大挑战。"}}
{"id": "2601.17556", "pdf": "https://arxiv.org/pdf/2601.17556", "abs": "https://arxiv.org/abs/2601.17556", "authors": ["Ulices Santa Cruz", "Mahmoud Elfar", "Yasser Shoukry"], "title": "Correct-by-Construction Vision-based Pose Estimation using Geometric Generative Models", "categories": ["cs.RO"], "comment": null, "summary": "We consider the problem of vision-based pose estimation for autonomous systems. While deep neural networks have been successfully used for vision-based tasks, they inherently lack provable guarantees on the correctness of their output, which is crucial for safety-critical applications. We present a framework for designing certifiable neural networks (NNs) for perception-based pose estimation that integrates physics-driven modeling with learning-based estimation. The proposed framework begins by leveraging the known geometry of planar objects commonly found in the environment, such as traffic signs and runway markings, referred to as target objects. At its core, it introduces a geometric generative model (GGM), a neural-network-like model whose parameters are derived from the image formation process of a target object observed by a camera. Once designed, the GGM can be used to train NN-based pose estimators with certified guarantees in terms of their estimation errors. We first demonstrate this framework in uncluttered environments, where the target object is the only object present in the camera's field of view. We extend this using ideas from NN reachability analysis to design certified object NN that can detect the presence of the target object in cluttered environments. Subsequently, the framework consolidates the certified object detector with the certified pose estimator to design a multi-stage perception pipeline that generalizes the proposed approach to cluttered environments, while maintaining its certified guarantees. We evaluate the proposed framework using both synthetic and real images of various planar objects commonly encountered by autonomous vehicles. Using images captured by an event-based camera, we show that the trained encoder can effectively estimate the pose of a traffic sign in accordance with the certified bound provided by the framework.", "AI": {"tldr": "本文提出了一种基于几何生成模型（GGM）的视觉姿态估计框架，该框架结合了物理驱动建模和学习估计，并在合成和真实图像上进行了验证。", "motivation": "由于深度神经网络缺乏对其输出正确性的可证明保证，在安全关键应用中存在局限性。因此，本文旨在设计具有认证保证的基于感知的姿态估计器。", "method": "该框架通过利用环境中的平面物体几何形状来设计GGM，并使用该模型训练带有所谓认证保证的神经网络姿态估计器。为了处理杂乱环境下的目标检测问题，引入了神经网络可达性分析技术以设计认证的目标检测器。", "result": "本文在无杂物和有杂物环境中验证了所提出的框架的有效性和准确性，在合成图像和真实图像上使用事件相机捕获的图像进行实验，证明姿态估计结果符合预期。", "conclusion": "该研究展示了如何通过整合物理驱动建模与学习方法设计出带有认证保证的视觉姿态估计系统，并成功应用于自动驾驶车辆中常见的平面物体。"}}
{"id": "2601.17555", "pdf": "https://arxiv.org/pdf/2601.17555", "abs": "https://arxiv.org/abs/2601.17555", "authors": ["Justin Downes", "Sam Saltwick", "Anthony Chen"], "title": "Saliency Driven Imagery Preprocessing for Efficient Compression -- Industrial Paper", "categories": ["cs.CV"], "comment": "Proceedings of the 31st ACM International Conference on Advances in Geographic Information Systems (2023)", "summary": "The compression of satellite imagery remains an important research area as hundreds of terabytes of images are collected every day, which drives up storage and bandwidth costs. Although progress has been made in increasing the resolution of these satellite images, many downstream tasks are only interested in small regions of any given image. These areas of interest vary by task but, once known, can be used to optimize how information within the image is encoded. Whereas standard image encoding methods, even those optimized for remote sensing, work on the whole image equally, there are emerging methods that can be guided by saliency maps to focus on important areas. In this work we show how imagery preprocessing techniques driven by saliency maps can be used with traditional lossy compression coding standards to create variable rate image compression within a single large satellite image. Specifically, we use variable sized smoothing kernels that map to different quantized saliency levels to process imagery pixels in order to optimize downstream compression and encoding schemes.", "AI": {"tldr": "本文介绍了如何通过基于显著性图的图像预处理技术，与传统的有损压缩编码标准结合，实现单个大型卫星图像中的可变速率图像压缩。", "motivation": "随着每天收集数百太字节的卫星图像，存储和带宽成本上升，优化这些图像的信息编码方式至关重要。下游任务通常只对图像的小区域感兴趣，因此可以通过显著性图引导的方法来提高压缩效率。", "method": "使用不同大小的平滑核根据量化后的显著性级别处理图像像素，以优化下游的压缩和编码方案。这种方法可以与传统的有损压缩标准结合，在大型卫星图像中实现可变速率的图像压缩。", "result": "通过此方法实现了针对重要区域的重点压缩，提高了整体压缩效率，减少了存储和带宽成本。", "conclusion": "基于显著性图的预处理技术可以在不损失关键信息的前提下，有效减少卫星图像的数据量，并优化其编码方式，从而降低存储和传输的成本。"}}
{"id": "2601.17553", "pdf": "https://arxiv.org/pdf/2601.17553", "abs": "https://arxiv.org/abs/2601.17553", "authors": ["Amin Mohamed", "Hamza Abdelmoreed", "Mohamed Ehab", "Youssef Shawky", "Mayada Hadhoud", "Ahmad Al-Kabbany"], "title": "TOSHFA: A Mobile VR-Based System for Pose-Guided Exercise Rehabilitation for Low Back Pain", "categories": ["cs.HC"], "comment": null, "summary": "Low back pain (LBP) is a pervasive global health challenge, affecting approximately 80% of adults and frequently progressing into chronic or recurrent episodes. While exercise therapy is a primary clinical intervention, traditional at-home programs suffer from low adherence rates and the absence of professional supervision. This study introduces TOSHFA, an accessible mobile VR-based rehabilitation system that bridges this gap by combining computer vision with affordable hardware. The system utilizes a laptop webcam to perform real-time pose estimation via the MediaPipe framework, tracking 33 skeletal landmarks to provide immediate biofeedback. This data is streamed via low-latency UDP protocols to a smartphone mounted in a cardboard-style VR headset, where patients interact with a gamified 3D environment. A pilot study with 20 participants evaluated the system's performance and user engagement. Quantitative results yielded a mean System Usability Scale (SUS) score of 47.4, indicating marginal usability and a need for interface optimization. However, Game Experience Questionnaire (GEQ) data revealed high scores in positive affect and enjoyment, suggesting that the gamification elements--such as coin rewards and streak tracking--successfully maintained user motivation despite technical friction. These findings validate the feasibility of a smartphone-based tele-rehabilitation model and establish a technical foundation for future clinical trials involving multi-exercise protocols.", "AI": {"tldr": "介绍了一种基于移动VR的康复系统TOSHFA，用于指导低背痛患者进行姿势导向的锻炼康复。", "motivation": "鉴于传统家庭锻炼程序中存在的参与度低和缺乏专业监督的问题，该研究旨在通过结合计算机视觉技术和低成本硬件来改善低背痛患者的康复效果。", "method": "使用笔记本电脑摄像头和MediaPipe框架实时估计姿态，并通过低延迟UDP协议将数据传输到VR头盔中的智能手机。参与者在虚拟环境中互动并接受游戏化反馈，以提高参与度。", "result": "初步研究显示系统具有边缘可用性（SUS评分为47.4），但在情感体验问卷中，用户表现出了积极的情感和享受感，表明尽管存在技术摩擦，但游戏元素仍能保持用户的动机。", "conclusion": "验证了基于智能手机的远程康复模型的可行性，并为未来涉及多运动协议的临床试验奠定了技术基础。"}}
{"id": "2601.17550", "pdf": "https://arxiv.org/pdf/2601.17550", "abs": "https://arxiv.org/abs/2601.17550", "authors": ["Deepak Singh", "Shreyas Khobragade", "Nitin J. Sanket"], "title": "AsterNav: Autonomous Aerial Robot Navigation In Darkness Using Passive Computation", "categories": ["cs.RO"], "comment": "8 pages, 10 figures, Published in IEEE Robotics And Automation Letters", "summary": "Autonomous aerial navigation in absolute darkness is crucial for post-disaster search and rescue operations, which often occur from disaster-zone power outages. Yet, due to resource constraints, tiny aerial robots, perfectly suited for these operations, are unable to navigate in the darkness to find survivors safely. In this paper, we present an autonomous aerial robot for navigation in the dark by combining an Infra-Red (IR) monocular camera with a large-aperture coded lens and structured light without external infrastructure like GPS or motion-capture. Our approach obtains depth-dependent defocus cues (each structured light point appears as a pattern that is depth dependent), which acts as a strong prior for our AsterNet deep depth estimation model. The model is trained in simulation by generating data using a simple optical model and transfers directly to the real world without any fine-tuning or retraining. AsterNet runs onboard the robot at 20 Hz on an NVIDIA Jetson Orin$^\\text{TM}$ Nano. Furthermore, our network is robust to changes in the structured light pattern and relative placement of the pattern emitter and IR camera, leading to simplified and cost-effective construction. We successfully evaluate and demonstrate our proposed depth navigation approach AsterNav using depth from AsterNet in many real-world experiments using only onboard sensing and computation, including dark matte obstacles and thin ropes (diameter 6.25mm), achieving an overall success rate of 95.5% with unknown object shapes, locations and materials. To the best of our knowledge, this is the first work on monocular, structured-light-based quadrotor navigation in absolute darkness.", "AI": {"tldr": "本文提出了AsterNav，一种使用红外单目相机和大光圈编码镜头以及结构光实现自主无人机在完全黑暗环境中导航的方法。", "motivation": "灾难救援操作中经常遇到电力中断导致的黑暗环境，小型无人机由于资源限制无法在这种环境下安全导航以寻找幸存者，因此需要开发能够在无光照条件下自主导航的技术。", "method": "该方法结合了红外单目相机和大光圈编码镜头及结构光，在没有外部基础设施如GPS或运动捕捉的情况下获取深度依赖的散焦线索，并用AsterNet模型进行深度估计。模型通过模拟数据训练，直接应用于现实世界而无需调优或重新训练。", "result": "实验表明该方法在多种真实世界的黑暗环境中实现了95.5%的成功率，包括面对未知形状、位置和材料的障碍物，如细绳（直径6.25毫米）等。", "conclusion": "本文展示了首个单目结构光四旋翼无人机在完全黑暗中的导航系统，并证明了其在自主深度导航方面的能力。"}}
{"id": "2601.17549", "pdf": "https://arxiv.org/pdf/2601.17549", "abs": "https://arxiv.org/abs/2601.17549", "authors": ["Narek Maloyan", "Dmitry Namiot"], "title": "Breaking the Protocol: Security Analysis of the Model Context Protocol Specification and Prompt Injection Vulnerabilities in Tool-Integrated LLM Agents", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The Model Context Protocol (MCP) has emerged as a de facto standard for integrating Large Language Models with external tools, yet no formal security analysis of the protocol specification exists. We present the first rigorous security analysis of MCP's architectural design, identifying three fundamental protocol-level vulnerabilities: (1) absence of capability attestation allowing servers to claim arbitrary permissions, (2) bidirectional sampling without origin authentication enabling server-side prompt injection, and (3) implicit trust propagation in multi-server configurations. We implement \\textsc{MCPBench}, a novel framework bridging existing agent security benchmarks to MCP-compliant infrastructure, enabling direct measurement of protocol-specific attack surfaces. Through controlled experiments on 847 attack scenarios across five MCP server implementations, we demonstrate that MCP's architectural choices amplify attack success rates by 23--41\\% compared to equivalent non-MCP integrations. We propose \\textsc{MCPSec}, a backward-compatible protocol extension adding capability attestation and message authentication, reducing attack success rates from 52.8\\% to 12.4\\% with median latency overhead of 8.3ms per message. Our findings establish that MCP's security weaknesses are architectural rather than implementation-specific, requiring protocol-level remediation.", "AI": {"tldr": "本文对Model Context Protocol（MCP）的协议规范进行了首次严格的安全分析，揭示了其三个主要安全漏洞，并提出了解决方案MCPSec。", "motivation": "由于缺少针对MCP协议规范的安全分析，该研究旨在填补这一空白，评估MCP在工具集成大型语言模型中的安全性。", "method": "作者开发了一个名为MCPBench的框架，在五种不同的MCP服务器实现上进行了847次攻击场景测试，并提出了一种新的协议扩展MCPSec来解决发现的安全问题。", "result": "研究显示，与非MCP集成相比，MCP架构选择使攻击成功率提高了23-41%。而使用MCPSec将攻击成功率从52.8%降至12.4%，每消息的中位延迟开销为8.3毫秒。", "conclusion": "该研究揭示了MCP的安全弱点是架构层面的问题，需要通过协议级别的修复来解决。"}}
{"id": "2601.17545", "pdf": "https://arxiv.org/pdf/2601.17545", "abs": "https://arxiv.org/abs/2601.17545", "authors": ["Ravi Venkata Surya Sai Mogilisetti", "Partha Pratim Das", "Rassel Raihan", "Shiyao Lin"], "title": "In-situ On-demand Digital Image Correlation: A New Data-rich Characterization Paradigm for Deformation and Damage Development in Solids", "categories": ["eess.IV", "cond-mat.mtrl-sci", "cs.CV"], "comment": null, "summary": "Digital image correlation (DIC) has become one of the most popular methods for deformation characterization in experimental mechanics. DIC is based on optical images taken during experimentation and post-test image processing. Its advantages include the capability to capture full-field deformation in a non-contact manner, the robustness in characterizing excessive deformation induced by events such as yielding and cracking, and the versatility to integrate optical cameras with a variety of open-source and commercial codes. In this paper, we developed a new paradigm of DIC analysis by integrating camera control into the DIC process flow. The essential idea is to dynamically increase the camera imaging frame rate with excessive deformation or deformation rate, while maintaining a relatively low imaging frame rate with small and slow deformation. We refer to this new DIC paradigm as in-situ on-demand (ISOD) DIC. ISOD DIC enables real-time deformation analysis, visualization, and closed-loop camera control. ISOD DIC has captured approximately 178% more images than conventional DIC for samples undergoing crack growth due to its dynamically adjusted frame rate, with the potential to significantly enhance data richness for damage inspection without consuming excessive storage space and analysis time, thereby benefiting the characterization of intrinsic constitutive behaviors and damage mechanisms", "AI": {"tldr": "开发了一种新的数字图像相关（DIC）范式，称为现场按需（ISOD）DIC，通过动态调整相机帧率以捕捉更多变形和损伤信息。", "motivation": "旨在提高现有DIC方法在捕捉大应变、高应变速率时的数据丰富性和效率。", "method": "将相机控制集成到DIC过程中，根据变形或变形速率自动调节相机的成像帧率。", "result": "ISOD DIC相较于传统DIC，对于裂纹增长样本捕获了约178%更多的图像，增强了损伤检测的数据丰富性。", "conclusion": "提出的ISOD DIC技术能够在不消耗过多存储空间和分析时间的情况下，显著提高材料本构行为和损伤机制的表征能力。"}}
{"id": "2601.17542", "pdf": "https://arxiv.org/pdf/2601.17542", "abs": "https://arxiv.org/abs/2601.17542", "authors": ["Vinoth Punniyamoorthy", "Nitin Saksena", "Srivenkateswara Reddy Sankiti", "Nachiappan Chockalingam", "Aswathnarayan Muthukrishnan Kirubakaran", "Shiva Kumar Reddy Carimireddy", "Durgaraman Maruthavanan"], "title": "Cognitive Platform Engineering for Autonomous Cloud Operations", "categories": ["cs.AI", "cs.SE"], "comment": "ef:International Journal of Computer Applications. 187, 72 ( Jan 2026), 17-23", "summary": "Modern DevOps practices have accelerated software delivery through automation, CI/CD pipelines, and observability tooling,but these approaches struggle to keep pace with the scale and dynamism of cloud-native systems. As telemetry volume grows and configuration drift increases, traditional, rule-driven automation often results in reactive operations, delayed remediation, and dependency on manual expertise. This paper introduces Cognitive Platform Engineering, a next-generation paradigm that integrates sensing, reasoning, and autonomous action directly into the platform lifecycle. This paper propose a four-plane reference architecture that unifies data collection, intelligent inference, policy-driven orchestration, and human experience layers within a continuous feedback loop. A prototype implementation built with Kubernetes, Terraform, Open Policy Agent, and ML-based anomaly detection demonstrates improvements in mean time to resolution, resource efficiency, and compliance. The results show that embedding intelligence into platform operations enables resilient, self-adjusting, and intent-aligned cloud environments. The paper concludes with research opportunities in reinforcement learning, explainable governance, and sustainable self-managing cloud ecosystems.", "AI": {"tldr": "介绍认知平台工程，以实现自主云操作。", "motivation": "现代DevOps实践虽加快了软件交付速度，但在规模和动态性方面难以跟上云原生系统的步伐。随着遥测数据量的增长和配置漂移的增加，传统的基于规则的自动化导致了反应性的运营、延迟的修复以及对人工专业知识的依赖。", "method": "提出了一种四平面参考架构，集成了数据收集、智能推理、策略驱动的编排和人类经验层，并通过持续反馈循环实现统一。原型使用Kubernetes、Terraform、Open Policy Agent和基于ML的异常检测构建。", "result": "实验结果表明，将智能嵌入平台操作中能够提升MTTR（平均恢复时间）、资源效率和合规性，创建出稳健且自我调节的云环境。", "conclusion": "研究讨论了在强化学习、可解释治理及可持续自主管理云生态系统方面的未来研究机会。"}}
{"id": "2601.17536", "pdf": "https://arxiv.org/pdf/2601.17536", "abs": "https://arxiv.org/abs/2601.17536", "authors": ["Jiaming Liang", "Haowei Liu", "Chi-Man Pun"], "title": "OTI: A Model-free and Visually Interpretable Measure of Image Attackability", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Despite the tremendous success of neural networks, benign images can be corrupted by adversarial perturbations to deceive these models. Intriguingly, images differ in their attackability. Specifically, given an attack configuration, some images are easily corrupted, whereas others are more resistant. Evaluating image attackability has important applications in active learning, adversarial training, and attack enhancement. This prompts a growing interest in developing attackability measures. However, existing methods are scarce and suffer from two major limitations: (1) They rely on a model proxy to provide prior knowledge (e.g., gradients or minimal perturbation) to extract model-dependent image features. Unfortunately, in practice, many task-specific models are not readily accessible. (2) Extracted features characterizing image attackability lack visual interpretability, obscuring their direct relationship with the images. To address these, we propose a novel Object Texture Intensity (OTI), a model-free and visually interpretable measure of image attackability, which measures image attackability as the texture intensity of the image's semantic object. Theoretically, we describe the principles of OTI from the perspectives of decision boundaries as well as the mid- and high-frequency characteristics of adversarial perturbations. Comprehensive experiments demonstrate that OTI is effective and computationally efficient. In addition, our OTI provides the adversarial machine learning community with a visual understanding of attackability.", "AI": {"tldr": "本文提出了一种无模型且可视觉解释的图像攻击性度量方法OTI，用于评估图像在面对对抗样本时的易受骗程度。", "motivation": "现有方法依赖于模型代理提供先验知识，并缺乏视觉解释性。因此，需要一种新的、不依赖特定任务模型且具有视觉解释性的攻击性度量方法。", "method": "本文提出了一种名为OTI（对象纹理强度）的方法，该方法将图像攻击性定义为图像语义对象的纹理强度，并从决策边界和对抗扰动的中高频特征角度进行了理论描述。", "result": "实验表明，OTI有效且计算效率高，能提供对攻击性的视觉理解。", "conclusion": "OTI作为一种无模型、可视觉解释的方法，在评估图像攻击性方面表现出色，并为对抗机器学习领域提供了新的视角和工具。"}}
{"id": "2601.17535", "pdf": "https://arxiv.org/pdf/2601.17535", "abs": "https://arxiv.org/abs/2601.17535", "authors": ["Kevin Robbins", "Xiaotong Liu", "Yu Wu", "Le Sun", "Grady McPeak", "Abby Stylianou", "Robert Pless"], "title": "Will It Zero-Shot?: Will It Zero-Shot?: Predicting Zero-Shot Classification Performance For Arbitrary Queries", "categories": ["cs.CV"], "comment": null, "summary": "Vision-Language Models like CLIP create aligned embedding spaces for text and images, making it possible for anyone to build a visual classifier by simply naming the classes they want to distinguish. However, a model that works well in one domain may fail in another, and non-expert users have no straightforward way to assess whether their chosen VLM will work on their problem. We build on prior work using text-only comparisons to evaluate how well a model works for a given natural language task, and explore approaches that also generate synthetic images relevant to that task to evaluate and refine the prediction of zero-shot accuracy. We show that generated imagery to the baseline text-only scores substantially improves the quality of these predictions. Additionally, it gives a user feedback on the kinds of images that were used to make the assessment. Experiments on standard CLIP benchmark datasets demonstrate that the image-based approach helps users predict, without any labeled examples, whether a VLM will be effective for their application.", "AI": {"tldr": "本文的主要任务是预测视觉语言模型在零样本分类问题上的表现，并通过生成的图像来提高这种预测的准确性。", "motivation": "动机在于解决非专业人士如何评估所选视觉语言模型（VLM）是否适用于其特定问题，特别是在不同领域中可能表现不同的情况下。", "method": "作者使用文本对比和合成相关任务的图像来评估并改进对零样本准确性的预测。通过生成的图像补充基线文本评分以提高预测质量。", "result": "实验表明，基于图像的方法有助于用户在没有标签示例的情况下预测视觉语言模型是否适用于他们的应用，并且这种方法显著提高了预测的质量。", "conclusion": "结论是生成相关的图像来辅助评估和反馈可以有效帮助非专业人士预测并了解其选定的VLM在其问题上的表现。"}}
{"id": "2601.17533", "pdf": "https://arxiv.org/pdf/2601.17533", "abs": "https://arxiv.org/abs/2601.17533", "authors": ["Silong Chen", "Yuchuan Luo", "Guilin Deng", "Yi Liu", "Min Xu", "Shaojing Fu", "Xiaohua Jia"], "title": "Reconstructing Training Data from Adapter-based Federated Large Language Models", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "Yuchuan Luo and Yi Liu are co-corresponding authors. Accepted at The Web Conference (WWW) 2026", "summary": "Adapter-based Federated Large Language Models (FedLLMs) are widely adopted to reduce the computational, storage, and communication overhead of full-parameter fine-tuning for web-scale applications while preserving user privacy. By freezing the backbone and training only compact low-rank adapters, these methods appear to limit gradient leakage and thwart existing Gradient Inversion Attacks (GIAs). Contrary to this assumption, we show that low-rank adapters create new, exploitable leakage channels. We propose the Unordered-word-bag-based Text Reconstruction (UTR) attack, a novel GIA tailored to the unique structure of adapter-based FedLLMs. UTR overcomes three core challenges: low-dimensional gradients, frozen backbones, and combinatorially large reconstruction spaces by: (i) inferring token presence from attention patterns in frozen layers, (ii) performing sentence-level inversion within the low-rank subspace of adapter gradients, and (iii) enforcing semantic coherence through constrained greedy decoding guided by language priors. Extensive experiments across diverse models (GPT2-Large, BERT, Qwen2.5-7B) and datasets (CoLA, SST-2, Rotten Tomatoes) demonstrate that UTR achieves near-perfect reconstruction accuracy (ROUGE-1/2 > 99), even with large batch size settings where prior GIAs fail completely. Our results reveal a fundamental tension between parameter efficiency and privacy in FedLLMs, challenging the prevailing belief that lightweight adaptation inherently enhances security. Our code and data are available at https://github.com/shwksnshwowk-wq/GIA.", "AI": {"tldr": "本文提出了一种名为UTR的文本重构攻击，能够从基于适配器的联邦大规模语言模型中重建训练数据。", "motivation": "尽管基于适配器的联邦大型语言模型（FedLLMs）旨在通过冻结主干并仅训练紧凑的低秩适配器来减少计算、存储和通信开销，并保护用户隐私，但本文认为这些方法仍然存在新的可利用的信息泄露渠道。", "method": "UTR攻击针对适配器基于FedLLM的独特结构设计，解决了三个核心挑战：从冻结层中推断标记的存在性、在低秩子空间内执行句子级反演、通过受约束的贪婪解码确保语义连贯性。", "result": "实验表明，UTR在不同的模型（GPT2-Large, BERT, Qwen2.5-7B）和数据集（CoLA, SST-2, Rotten Tomatoes）上实现了近乎完美的重构精度（ROUGE-1/2 > 99），即使是在大批次大小设置下也表现出色。", "conclusion": "研究表明在FedLLMs中存在参数效率与隐私之间的根本矛盾，挑战了轻量级适配器固有的安全性增强的普遍观点。"}}
{"id": "2601.17532", "pdf": "https://arxiv.org/pdf/2601.17532", "abs": "https://arxiv.org/abs/2601.17532", "authors": ["Zhipeng Song", "Yizhi Zhou", "Xiangyu Kong", "Jiulong Jiao", "Xinrui Bao", "Xu You", "Xueqing Shi", "Yuhang Zhou", "Heng Qi"], "title": "Less is More for RAG: Information Gain Pruning for Generator-Aligned Reranking and Evidence Selection", "categories": ["cs.CL", "cs.AI"], "comment": "26 pages, 10 figures", "summary": "Retrieval-augmented generation (RAG) grounds large language models with external evidence, but under a limited context budget, the key challenge is deciding which retrieved passages should be injected. We show that retrieval relevance metrics (e.g., NDCG) correlate weakly with end-to-end QA quality and can even become negatively correlated under multi-passage injection, where redundancy and mild conflicts destabilize generation. We propose \\textbf{Information Gain Pruning (IGP)}, a deployment-friendly reranking-and-pruning module that selects evidence using a generator-aligned utility signal and filters weak or harmful passages before truncation, without changing existing budget interfaces. Across five open-domain QA benchmarks and multiple retrievers and generators, IGP consistently improves the quality--cost trade-off. In a representative multi-evidence setting, IGP delivers about +12--20% relative improvement in average F1 while reducing final-stage input tokens by roughly 76--79% compared to retriever-only baselines.", "AI": {"tldr": "本文提出了一种称为信息增益剪枝（IGP）的方法，用于选择和修剪检索到的证据片段，以提高生成式模型在问答任务中的表现。", "motivation": "传统的检索相关度指标与最终的QA质量关联性较弱，尤其是在多段落注入时，冗余和轻微冲突会破坏生成过程。因此，需要一种新的方法来优化证据的选择。", "method": "信息增益剪枝（IGP）通过一个生成器对齐的效用信号选择证据，并在截断之前过滤掉不相关或有负面影响的段落。", "result": "实验结果显示，在五个开放域QA基准测试和多种检索器及生成器上，IGP显著改善了质量-成本折衷。具体来说，平均F1值提高了约+12--20%，而最终阶段输入令牌减少了76--79%。", "conclusion": "信息增益剪枝（IGP）作为一种部署友好型的重排序和修剪模块，能够在不改变现有预算接口的情况下有效提升检索增强生成模型的表现。"}}
{"id": "2601.17529", "pdf": "https://arxiv.org/pdf/2601.17529", "abs": "https://arxiv.org/abs/2601.17529", "authors": ["Fengting Zhang", "Yue He", "Qinghao Liu", "Yaonan Wang", "Xiang Chen", "Hang Zhang"], "title": "FMIR, a foundation model-based Image Registration Framework for Robust Image Registration", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning has revolutionized medical image registration by achieving unprecedented speeds, yet its clinical application is hindered by a limited ability to generalize beyond the training domain, a critical weakness given the typically small scale of medical datasets. In this paper, we introduce FMIR, a foundation model-based registration framework that overcomes this limitation.Combining a foundation model-based feature encoder for extracting anatomical structures with a general registration head, and trained with a channel regularization strategy on just a single dataset, FMIR achieves state-of-the-art(SOTA) in-domain performance while maintaining robust registration on out-of-domain images.Our approach demonstrates a viable path toward building generalizable medical imaging foundation models with limited resources. The code is available at https://github.com/Monday0328/FMIR.git.", "AI": {"tldr": "介绍了一种基于基础模型的图像配准框架FMIR，以提高医学图像注册的一般性和鲁棒性。", "motivation": "尽管深度学习显著提升了医疗图像配准的速度，但其在临床应用中受限于泛化能力不足的问题，特别是在医疗数据集通常规模较小的情况下。", "method": "结合基础模型的特征编码器提取解剖结构与通用注册头部，并采用通道正则化策略训练FMIR，在单一数据集上进行训练以实现高性能和鲁棒性。", "result": "FMIR在域内性能达到了最先进的水平，同时对域外图像也具有强大的配准能力。", "conclusion": "FMIR为利用有限资源构建可泛化的医学影像基础模型提供了一条可行的路径。"}}
{"id": "2601.17527", "pdf": "https://arxiv.org/pdf/2601.17527", "abs": "https://arxiv.org/abs/2601.17527", "authors": ["Yu Wang", "Xiangchen Liu"], "title": "Bridging Expectation Signals: LLM-Based Experiments and a Behavioral Kalman Filter Framework", "categories": ["econ.GN", "cs.AI"], "comment": null, "summary": "As LLMs increasingly function as economic agents, the specific mechanisms LLMs use to update their belief with heterogeneous signals remain opaque. We design experiments and develop a Behavioral Kalman Filter framework to quantify how LLM-based agents update expectations, acting as households or firm CEOs, update expectations when presented with individual and aggregate signals. The results from experiments and model estimation reveal four consistent patterns: (1) agents' weighting of priors and signals deviates from unity; (2) both household and firm CEO agents place substantially larger weights on individual signals compared to aggregate signals; (3) we identify a significant and negative interaction between concurrent signals, implying that the presence of multiple information sources diminishes the marginal weight assigned to each individual signal; and (4) expectation formation patterns differ significantly between household and firm CEO agents. Finally, we demonstrate that LoRA fine-tuning mitigates, but does not fully eliminate, behavioral biases in LLM expectation formation.", "AI": {"tldr": "本文通过实验和行为卡尔曼滤波框架研究了LLM作为经济主体时如何根据不同的信号更新其预期，并探讨了不同类型的代理（家庭和个人CEO）之间的差异。", "motivation": "由于LLM在经济活动中扮演日益重要的角色，但它们如何处理并整合多种信号来更新信念的机制尚不明确，因此本文旨在揭示这些机制。", "method": "设计实验并通过行为卡尔曼滤波框架量化LLM代理基于个体和聚合信号更新预期的方式。", "result": "研究发现：1）代理人对先验和信号的加权偏离统一；2）家庭和个人CEO代理相比聚合信号，更重视个体信号；3）同时存在多个信息源会降低每个个别信号的边际权重；4）不同类型的代理在形成预期方面存在显著差异。", "conclusion": "LoRA微调可以减轻但无法完全消除LLM在预期形成中的行为偏差。"}}
{"id": "2601.17517", "pdf": "https://arxiv.org/pdf/2601.17517", "abs": "https://arxiv.org/abs/2601.17517", "authors": ["Luca Cerovaz", "Michele Mancusi", "Emanuele Rodolà"], "title": "EuleroDec: A Complex-Valued RVQ-VAE for Efficient and Robust Audio Coding", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "Accepted at ICASSP 2026", "summary": "Audio codecs power discrete music generative modelling, music streaming, and immersive media by shrinking PCM audio to bandwidth-friendly bitrates. Recent works have gravitated towards processing in the spectral domain; however, spectrogram domains typically struggle with phase modeling, which is naturally complex-valued. Most frequency-domain neural codecs either disregard phase information or encode it as two separate real-valued channels, limiting spatial fidelity. This entails the need to introduce adversarial discriminators at the expense of convergence speed and training stability to compensate for the inadequate representation power of the audio signal. In this work we introduce an end-to-end complex-valued RVQ-VAE audio codec that preserves magnitude-phase coupling across the entire analysis-quantization-synthesis pipeline and removes adversarial discriminators and diffusion post-filters. Without GANs or diffusion, we match or surpass much longer-trained baselines in-domain and reach SOTA out-of-domain performance on phase coherence and waveform fidelity. Compared to standard baselines that train for hundreds of thousands of steps, our model, which reduces the training budget by an order of magnitude, is markedly more compute-efficient while preserving high perceptual quality.", "AI": {"tldr": "本文介绍了一种名为EuleroDec的复杂值RVQ-VAE音频编解码器，它可以在分析、量化和合成管道中保持幅度相位耦合，并去除了对抗鉴别器和扩散后滤波器。", "motivation": "当前音频编码方法在频域处理时通常忽略或不充分处理相位信息，限制了空间保真度。因此需要一种新的方法来提高音频信号的表示能力，同时保持训练速度和稳定性。", "method": "该研究提出了一种端到端复杂值RVQ-VAE音频编解码器，保留了整个分析、量化、合成过程中的幅度相位耦合，并去除了对抗鉴别器及扩散后滤波器。", "result": "无需GAN或扩散模型，本方法匹配甚至超越了经过更长时间训练的基线模型在域内表现，并达到了领域外性能的最佳水平，在相位一致性和波形保真度方面表现出色。同时显著减少了计算需求并保持高质量感知。", "conclusion": "EuleroDec通过复杂值处理和去除对抗鉴别器及扩散后滤波，实现了高效的音频编码，不仅提高了训练效率，还在音频质量上达到了顶级水平。"}}
{"id": "2601.17513", "pdf": "https://arxiv.org/pdf/2601.17513", "abs": "https://arxiv.org/abs/2601.17513", "authors": ["Moahmed Hamza Boulaich", "Said Ohamouddou", "Mohammed Ali Ennasar", "Abdelatif El Afia"], "title": "Constrained Multi-Objective Genetic Algorithm Variants for Design and Optimization of Tri-Band Microstrip Patch Antenna loaded CSRR for IoT Applications: A Comparative Case Study", "categories": ["cs.NE", "cs.NI"], "comment": null, "summary": "This paper presents an automated antenna design and optimization framework employing multi-objective genetic algorithms (MOGAs) to investigate various evolutionary optimization approaches, with a primary emphasis on multi-band frequency optimization. Five MOGA variants were implemented and compared: the Pareto genetic algorithm (PGA), non-dominated sorting genetic algorithm with niching (NSGA-I), non-dominated sorting genetic algorithm with elitism (NSGA-II), non-dominated sorting genetic algorithm using reference points (NSGA-III), and strength Pareto evolutionary algorithm (SPEA). These algorithms are employed to design and optimize microstrip patch antennas loaded with complementary split-ring resonators (CSRRs). A weighted-sum scalarization approach was adopted within a single-objective genetic algorithm framework enhanced with domain-specific constraint handling mechanisms. The optimization addresses the conflicting objectives of minimizing the return loss ($S_{11} < -10$~dB) and achieving multi-band resonance at 2.4~GHz, 3.6~GHz, and 5.2~GHz. The proposed method delivers a superior overall performance by aggregating these objectives into a unified fitness function encompassing $S_{11}$(2.4~GHz), $S_{11}$(3.6~GHz), and $S_{11}$(5.2~GHz). This approach effectively balances all three frequency bands simultaneously, rather than exploring trade-off solutions typical of traditional multi-objective approaches. The antenna was printed on a Rogers RT5880 substrate with a dielectric constant of 2.2 , loss tangent of 0.0009 , and thickness of 1.57~mm . Scalarization approach achieved return loss values of $-21.56$~dB, $-16.60$~dB, and $-27.69$~dB, with corresponding gains of 1.96~dBi, 2.6~dB, and 3.99~dBi at 2.4~GHz, 3.6~GHz, and 5.2~GHz, respectively.", "AI": {"tldr": "本文提出了一个自动化的天线设计和优化框架，采用多目标遗传算法（MOGA）来研究多种进化优化方法，并特别强调了多频段频率优化。", "motivation": "动机是通过比较不同的多目标遗传算法变体，以找到能够有效同时实现多个频带共振的最优设计方案。", "method": "使用五种MOGA变体进行天线的设计和优化：Pareto遗传算法（PGA）、非支配排序遗传算法（NSGA-I、II、III）以及强度帕雷托进化算法（SPEA）。采用加权和标量化方法在单目标遗传算法框架中增强特定领域的约束处理机制。", "result": "通过优化，实现了在2.4GHz、3.6GHz和5.2GHz频段的反射损耗分别为-21.56dB、-16.60dB、-27.69dB，并且对应的增益为1.96dBi、2.6dB以及3.99dBi。", "conclusion": "该方法在统一适应度函数中整合了多个频段的反射损耗目标，实现了一个优于传统多目标优化策略的整体性能。"}}
{"id": "2601.17510", "pdf": "https://arxiv.org/pdf/2601.17510", "abs": "https://arxiv.org/abs/2601.17510", "authors": ["David L. Donoho", "Jian Kang", "Xihong Lin", "Bhramar Mukherjee", "Dan Nettleton", "Rebecca Nugent", "Abel Rodriguez", "Eric P. Xing", "Tian Zheng", "Hongtu Zhu"], "title": "\"Rebuilding\" Statistics in the Age of AI: A Town Hall Discussion on Culture, Infrastructure, and Training", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "35 pages, 3 figures,", "summary": "This article presents the full, original record of the 2024 Joint Statistical Meetings (JSM) town hall, \"Statistics in the Age of AI,\" which convened leading statisticians to discuss how the field is evolving in response to advances in artificial intelligence, foundation models, large-scale empirical modeling, and data-intensive infrastructures. The town hall was structured around open panel discussion and extensive audience Q&A, with the aim of eliciting candid, experience-driven perspectives rather than formal presentations or prepared statements. This document preserves the extended exchanges among panelists and audience members, with minimal editorial intervention, and organizes the conversation around five recurring questions concerning disciplinary culture and practices, data curation and \"data work,\" engagement with modern empirical modeling, training for large-scale AI applications, and partnerships with key AI stakeholders. By providing an archival record of this discussion, the preprint aims to support transparency, community reflection, and ongoing dialogue about the evolving role of statistics in the data- and AI-centric future.", "AI": {"tldr": "本文记录了2024年联合统计会议（JSM）的一场以“AI时代中的统计学”为主题的圆桌讨论，讨论了统计学如何应对人工智能、基础模型和大规模实证建模等领域的进步。", "motivation": "本论文旨在通过保存该圆桌讨论的原始记录，促进透明度、社区反思以及关于统计学在数据与AI为核心未来中不断演变作用的持续对话。", "method": "采用开放式小组讨论和广泛的观众问答形式来收集真实的经验驱动的观点，并围绕五个反复出现的问题组织了整个对话。", "result": "保留并整理了参与者之间的延长交流，以最少的编辑干预提供了圆桌讨论的档案记录。", "conclusion": "本论文通过提供这次讨论的存档记录支持社区透明度、反思和持续对话，有助于统计学在AI时代的发展。"}}
{"id": "2601.17507", "pdf": "https://arxiv.org/pdf/2601.17507", "abs": "https://arxiv.org/abs/2601.17507", "authors": ["Yutong Shen", "Hangxu Liu", "Kailin Pei", "Ruizhe Xia", "Tongtong Feng"], "title": "MetaWorld: Skill Transfer and Composition in a Hierarchical World Model for Grounding High-Level Instructions", "categories": ["cs.RO"], "comment": "8 pages, 4 figures, Submitted to ICLR 2026 World Model Workshop", "summary": "Humanoid robot loco-manipulation remains constrained by the semantic-physical gap. Current methods face three limitations: Low sample efficiency in reinforcement learning, poor generalization in imitation learning, and physical inconsistency in VLMs. We propose MetaWorld, a hierarchical world model that integrates semantic planning and physical control via expert policy transfer. The framework decouples tasks into a VLM-driven semantic layer and a latent dynamics model operating in a compact state space. Our dynamic expert selection and motion prior fusion mechanism leverages a pre-trained multi-expert policy library as transferable knowledge, enabling efficient online adaptation via a two-stage framework. VLMs serve as semantic interfaces, mapping instructions to executable skills and bypassing symbol grounding. Experiments on Humanoid-Bench show MetaWorld outperforms world model-based RL in task completion and motion coherence. Our code will be found at https://anonymous.4open.science/r/metaworld-2BF4/", "AI": {"tldr": "本文提出了MetaWorld，一个整合语义规划和物理控制的分层世界模型，用于解决人类机器人步行操作中的语义-物理差距。", "motivation": "当前方法在强化学习中样本效率低、模仿学习泛化能力差以及视觉语言模型（VLMs）中的物理一致性问题限制了人形机器人的步行操控能力。", "method": "MetaWorld框架将任务分解为由VLM驱动的语义层和在一个紧凑状态空间操作的潜在动态模型，通过预训练多专家策略库作为可转移知识，实现了高效的在线适应。采用两阶段方法结合动态专家选择和动作先验融合机制。", "result": "实验表明，在Humanoid-Bench上，MetaWorld在任务完成度和动作连贯性方面优于基于世界模型的强化学习。", "conclusion": "该研究展示了通过整合语义规划与物理控制，利用预训练多专家策略库实现高效的在线适应能力，以解决人形机器人步行操控中的挑战。"}}
{"id": "2601.17504", "pdf": "https://arxiv.org/pdf/2601.17504", "abs": "https://arxiv.org/abs/2601.17504", "authors": ["Yan Zhou", "Zhen Huang", "Yingqiu Li", "Yue Ouyang", "Suncheng Xiang", "Zehua Wang"], "title": "BMDS-Net: A Bayesian Multi-Modal Deep Supervision Network for Robust Brain Tumor Segmentation", "categories": ["cs.CV", "q-bio.QM"], "comment": "16 pages, 5 figures. Manuscript prepared for submission to ACM TOMM", "summary": "Accurate brain tumor segmentation from multi-modal magnetic resonance imaging (MRI) is a prerequisite for precise radiotherapy planning and surgical navigation. While recent Transformer-based models such as Swin UNETR have achieved impressive benchmark performance, their clinical utility is often compromised by two critical issues: sensitivity to missing modalities (common in clinical practice) and a lack of confidence calibration. Merely chasing higher Dice scores on idealized data fails to meet the safety requirements of real-world medical deployment. In this work, we propose BMDS-Net, a unified framework that prioritizes clinical robustness and trustworthiness over simple metric maximization. Our contribution is three-fold. First, we construct a robust deterministic backbone by integrating a Zero-Init Multimodal Contextual Fusion (MMCF) module and a Residual-Gated Deep Decoder Supervision (DDS) mechanism, enabling stable feature learning and precise boundary delineation with significantly reduced Hausdorff Distance, even under modality corruption. Second, and most importantly, we introduce a memory-efficient Bayesian fine-tuning strategy that transforms the network into a probabilistic predictor, providing voxel-wise uncertainty maps to highlight potential errors for clinicians. Third, comprehensive experiments on the BraTS 2021 dataset demonstrate that BMDS-Net not only maintains competitive accuracy but, more importantly, exhibits superior stability in missing-modality scenarios where baseline models fail. The source code is publicly available at https://github.com/RyanZhou168/BMDS-Net.", "AI": {"tldr": "该论文提出了一种名为BMDS-Net的贝叶斯多模态深度监督网络，用于鲁棒脑肿瘤分割。", "motivation": "虽然基于Transformer的模型在理想化数据上取得了优秀的性能，但它们在临床应用中面临对缺失模态敏感和缺乏置信度校准的问题。该论文旨在优先考虑临床稳健性和可信性而不是简单的指标最大化。", "method": "BMDS-Net包括三个主要贡献：1）通过整合Zero-Init多模态上下文融合模块和残差门控深度解码器监督机制构建了一个鲁棒的确定性骨干；2）引入了一种内存高效的贝叶斯微调策略，使网络能够提供体素级不确定性地图以突出潜在错误；3）在BraTS 2021数据集上进行了全面实验。", "result": "BMDS-Net不仅保持了竞争性的准确性，在缺失模态的情况下表现也优于基准模型，显示出了优越的稳定性。", "conclusion": "该研究表明，通过整合多模态融合、深度监督机制和贝叶斯微调策略，可以构建一个鲁棒且具有不确定性估计能力的脑肿瘤分割网络。"}}
{"id": "2601.17495", "pdf": "https://arxiv.org/pdf/2601.17495", "abs": "https://arxiv.org/abs/2601.17495", "authors": ["Ruiyu Zhang", "Lin Nie", "Wai-Fung Lam", "Qihao Wang", "Xin Zhao"], "title": "PEARL: Prototype-Enhanced Alignment for Label-Efficient Representation Learning with Deployment-Driven Insights from Digital Governance Communication Systems", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "comment": "15 pages, 1 figure", "summary": "In many deployed systems, new text inputs are handled by retrieving similar past cases, for example when routing and responding to citizen messages in digital governance platforms. When these systems fail, the problem is often not the language model itself, but that the nearest neighbors in the embedding space correspond to the wrong cases. Modern machine learning systems increasingly rely on fixed, high-dimensional embeddings produced by large pretrained models and sentence encoders. In real-world deployments, labels are scarce, domains shift over time, and retraining the base encoder is expensive or infeasible. As a result, downstream performance depends heavily on embedding geometry. Yet raw embeddings are often poorly aligned with the local neighborhood structure required by nearest-neighbor retrieval, similarity search, and lightweight classifiers that operate directly on embeddings. We propose PEARL (Prototype-Enhanced Aligned Representation Learning), a label-efficient approach that uses limited supervision to softly align embeddings toward class prototypes. The method reshapes local neighborhood geometry while preserving dimensionality and avoiding aggressive projection or collapse. Its aim is to bridge the gap between purely unsupervised post-processing, which offers limited and inconsistent gains, and fully supervised projections that require substantial labeled data. We evaluate PEARL under controlled label regimes ranging from extreme label scarcity to higher-label settings. In the label-scarce condition, PEARL substantially improves local neighborhood quality, yielding 25.7% gains over raw embeddings and more than 21.1% gains relative to strong unsupervised post-processing, precisely in the regime where similarity-based systems are most brittle.", "AI": {"tldr": "本文提出了PEARL方法，通过使用有限的监督来软对齐嵌入到类别原型上，以改善相似性检索和轻量级分类器所需的地方邻域结构。", "motivation": "在数字治理平台等实际部署系统中，文本输入处理经常依赖于类似过去的案例，但这些系统常常因为嵌入空间中的最近邻居对应错误的案例而失败。现代机器学习系统依赖固定、高维的嵌入，但由于标签稀缺和领域迁移等因素，重新训练基础编码器成本高昂或不可行，因此下游性能严重依赖于嵌入几何结构。", "method": "PEARL方法使用有限的监督来软对齐嵌入到类别原型上，调整局部邻域几何形状的同时保持维度并避免激进投影或崩溃。该方法旨在填补纯无监督后处理和需要大量标签数据的全监督投影之间的空白。", "result": "在极度稀缺标签条件下，与原始嵌入相比，PEARL改善了局部邻域质量，取得了25.7%的提升，并且比强大的无监督后处理提升了超过21.1%，特别是在相似性系统最脆弱的情况下。", "conclusion": "PEARL方法能够在标签资源极其有限的情况下显著提高文本输入处理系统的性能，为实际部署中的数字治理平台等提供了解决方案。"}}
{"id": "2601.17489", "pdf": "https://arxiv.org/pdf/2601.17489", "abs": "https://arxiv.org/abs/2601.17489", "authors": ["Ashutosh Bajpai", "Akshat Bhandari", "Akshay Nambi", "Tanmoy Chakraborty"], "title": "SpatialMath: Spatial Comprehension-Infused Symbolic Reasoning for Mathematical Problem-Solving", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": ":I.2.7; I.2.10; I.2.6", "summary": "Multimodal Small-to-Medium sized Language Models (MSLMs) have demonstrated strong capabilities in integrating visual and textual information but still face significant limitations in visual comprehension and mathematical reasoning, particularly in geometric problems with diverse levels of visual infusion. Current models struggle to accurately decompose intricate visual inputs and connect perception with structured reasoning, leading to suboptimal performance. To address these challenges, we propose SpatialMath, a novel Spatial Comprehension-Infused Symbolic Reasoning Framework designed to integrate spatial representations into structured symbolic reasoning chains. SpatialMath employs a specialized perception module to extract spatially-grounded representations from visual diagrams, capturing critical geometric structures and spatial relationships. These representations are then methodically infused into symbolic reasoning chains, facilitating visual comprehension-aware structured reasoning. To this end, we introduce MATHVERSE-PLUS, a novel dataset containing structured visual interpretations and step-by-step reasoning paths for vision-intensive mathematical problems. SpatialMath significantly outperforms strong multimodal baselines, achieving up to 10 percentage points improvement over supervised fine-tuning with data augmentation in vision-intensive settings. Robustness analysis reveals that enhanced spatial representations directly improve reasoning accuracy, reinforcing the need for structured perception-to-reasoning pipelines in MSLMs.", "AI": {"tldr": "本文提出了SpatialMath框架，通过将空间理解融入符号推理链中以解决视觉密集型的数学问题。", "motivation": "现有的多模态小到中等规模语言模型在处理复杂的几何问题时存在显著不足，尤其是在理解和连接视觉与结构化推理方面表现不佳。", "method": "SpatialMath使用专门感知模块从可视图示中提取空间基础表示，并将这些表示融入符号推理链中。引入了MATHVERSE-PLUS数据集来支持这种结构化的视觉和数学问题理解。", "result": "SpatialMath显著优于现有的多模态基线模型，实现了高达10个百分点的性能提升。", "conclusion": "增强的空间表示能够直接提高推理准确性，强化了在多模态语言模型中构建结构化感知到推理管道的需求。"}}
{"id": "2601.17486", "pdf": "https://arxiv.org/pdf/2601.17486", "abs": "https://arxiv.org/abs/2601.17486", "authors": ["Zhiyuan Zhang", "Yu She"], "title": "EquiForm: Noise-Robust SE(3)-Equivariant Policy Learning from 3D Point Clouds", "categories": ["cs.RO"], "comment": "Project website: https://ZhangZhiyuanZhang.github.io/equiform-website/ Code will be released", "summary": "Visual imitation learning with 3D point clouds has advanced robotic manipulation by providing geometry-aware, appearance-invariant observations. However, point cloud-based policies remain highly sensitive to sensor noise, pose perturbations, and occlusion-induced artifacts, which distort geometric structure and break the equivariance assumptions required for robust generalization. Existing equivariant approaches primarily encode symmetry constraints into neural architectures, but do not explicitly correct noise-induced geometric deviations or enforce equivariant consistency in learned representations. We introduce EquiForm, a noise-robust SE(3)-equivariant policy learning framework for point cloud-based manipulation. EquiForm formalizes how noise-induced geometric distortions lead to equivariance deviations in observation-to-action mappings, and introduces a geometric denoising module to restore consistent 3D structure under noisy or incomplete observations. In addition, we propose a contrastive equivariant alignment objective that enforces representation consistency under both rigid transformations and noise perturbations. Built upon these components, EquiForm forms a flexible policy learning pipeline that integrates noise-robust geometric reasoning with modern generative models. We evaluate EquiForm on 16 simulated tasks and 4 real-world manipulation tasks across diverse objects and scene layouts. Compared to state-of-the-art point cloud imitation learning methods, EquiForm achieves an average improvement of 17.2% in simulation and 28.1% in real-world experiments, demonstrating strong noise robustness and spatial generalization.", "AI": {"tldr": "本研究提出了一种名为EquiForm的框架，该框架能够从点云中学习具有噪声鲁棒性和SE(3)等变性的策略。", "motivation": "当前基于点云的机器人操纵策略易受传感器噪音、姿态扰动和遮挡引起的伪影影响，这破坏了所需的等变性假设，从而阻碍了稳健泛化能力。因此，提出了EquiForm以提高噪声鲁棒性和等变一致性。", "method": "EquiForm引入了一个几何降噪模块来恢复在有噪声或不完整观察下的3D结构，并提出了一种对比等变对齐目标，在刚性变换和噪音扰动下强制执行表示的一致性。", "result": "相比最先进的点云模仿学习方法，EquiForm在模拟实验中取得了17.2%的平均改进率，在现实世界中的实验中则达到了28.1%，显示出了强大的噪声鲁棒性和空间泛化能力。", "conclusion": "实验表明，通过结合噪声稳健的几何推理和现代生成模型，EquiForm能够显著提高基于点云的机器人操纵策略的性能。"}}
{"id": "2601.17483", "pdf": "https://arxiv.org/pdf/2601.17483", "abs": "https://arxiv.org/abs/2601.17483", "authors": ["Barak Or"], "title": "Automatic Stability and Recovery for Neural Network Training", "categories": ["cs.LG", "cs.AI"], "comment": "Under Review", "summary": "Training modern neural networks is increasingly fragile, with rare but severe destabilizing updates often causing irreversible divergence or silent performance degradation. Existing optimization methods primarily rely on preventive mechanisms embedded within the optimizer, offering limited ability to detect and recover from instability once it occurs. We introduce a supervisory runtime stability framework that treats optimization as a controlled stochastic process. By isolating an innovation signal derived from secondary measurements, such as validation probes, the framework enables automatic detection and recovery from destabilizing updates without modifying the underlying optimizer. We provide theoretical runtime safety guarantees that formalize bounded degradation and recovery. Our implementation incurs minimal overhead and is compatible with memory-constrained training settings.", "AI": {"tldr": "本文提出了一个监督运行时稳定性框架，以自动检测和恢复神经网络训练过程中的不稳定更新。", "motivation": "现代神经网络的训练越来越脆弱，优化方法主要依靠嵌入在优化器内的预防机制来防止性能下降或发散问题。", "method": "该框架将优化视为一个受控随机过程，并通过从次要测量值（如验证探针）中隔离出创新信号来实现自动检测和恢复不稳定更新。", "result": "该方法提供了运行时安全保证，明确了退化和恢复的边界，并且实现了几乎无额外开销的兼容内存受限训练环境的实施方案。", "conclusion": "本文的方法能够有效检测并从不可逆发散或静默性能下降中恢复，同时对底层优化器不作修改。"}}
{"id": "2601.17481", "pdf": "https://arxiv.org/pdf/2601.17481", "abs": "https://arxiv.org/abs/2601.17481", "authors": ["Emily Broadhurst", "Tawab Safi", "Joseph Edell", "Vashisht Ganesh", "Karime Maamari"], "title": "Lattice: Generative Guardrails for Conversational Agents", "categories": ["cs.AI"], "comment": null, "summary": "Conversational AI systems require guardrails to prevent harmful outputs, yet existing approaches use static rules that cannot adapt to new threats or deployment contexts. We introduce Lattice, a framework for self-constructing and continuously improving guardrails. Lattice operates in two stages: construction builds initial guardrails from labeled examples through iterative simulation and optimization; continuous improvement autonomously adapts deployed guardrails through risk assessment, adversarial testing, and consolidation. Evaluated on the ProsocialDialog dataset, Lattice achieves 91% F1 on held-out data, outperforming keyword baselines by 43pp, LlamaGuard by 25pp, and NeMo by 4pp. The continuous improvement stage achieves 7pp F1 improvement on cross-domain data through closed-loop optimization. Our framework shows that effective guardrails can be self-constructed through iterative optimization.", "AI": {"tldr": "本文介绍了Lattice框架，用于生成和持续改进对话代理的保护措施。", "motivation": "现有的对话AI系统使用静态规则作为防护措施，无法适应新威胁或部署环境，因此需要一种自构建且能持续优化的防护方法。", "method": "Lattice框架分为两个阶段：建设阶段通过迭代模拟与优化从标记样本中建立初始保护措施；持续改进阶段则利用风险评估、对抗测试和整合来自主调整已部署的保护措施。", "result": "在ProsocialDialog数据集上，Lattice达到了91%的F1分数，在跨域数据上实现了7个点的F1提升，并超越了关键词基线方法、LlamaGuard和NeMo。", "conclusion": "实验结果表明，通过迭代优化可以自构建有效的保护措施。"}}
{"id": "2601.17480", "pdf": "https://arxiv.org/pdf/2601.17480", "abs": "https://arxiv.org/abs/2601.17480", "authors": ["Marton Szep", "Jorge Marin Ruiz", "Georgios Kaissis", "Paulina Seidl", "Rüdiger von Eisenhart-Rothe", "Florian Hinterwimmer", "Daniel Rueckert"], "title": "Unintended Memorization of Sensitive Information in Fine-Tuned Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted to EACL 2026. 20 pages", "summary": "Fine-tuning Large Language Models (LLMs) on sensitive datasets carries a substantial risk of unintended memorization and leakage of Personally Identifiable Information (PII), which can violate privacy regulations and compromise individual safety. In this work, we systematically investigate a critical and underexplored vulnerability: the exposure of PII that appears only in model inputs, not in training targets. Using both synthetic and real-world datasets, we design controlled extraction probes to quantify unintended PII memorization and study how factors such as language, PII frequency, task type, and model size influence memorization behavior. We further benchmark four privacy-preserving approaches including differential privacy, machine unlearning, regularization, and preference alignment, evaluating their trade-offs between privacy and task performance. Our results show that post-training methods generally provide more consistent privacy-utility trade-offs, while differential privacy achieves strong reduction in leakage in specific settings, although it can introduce training instability. These findings highlight the persistent challenge of memorization in fine-tuned LLMs and emphasize the need for robust, scalable privacy-preserving techniques.", "AI": {"tldr": "本文研究了在敏感数据集上微调大型语言模型时，无意中记忆和泄漏个人身份信息(PII)的风险，并评估了几种隐私保护技术的性能。", "motivation": "该论文旨在系统地探讨一个关键且未被充分探索的问题：即模型输入中的个人信息（PII）泄露风险，这可能导致违反隐私规定和危害个体安全。", "method": "使用合成数据集和真实世界的数据集设计了控制提取探针来量化无意的PII记忆，并研究语言、PII频率、任务类型和模型大小等因素对记忆行为的影响。", "result": "结果表明，后训练方法通常提供更一致的隐私-效用权衡，而差分隐私在特定设置下能够显著减少泄露，尽管它可能导致训练不稳定。", "conclusion": "这些发现强调了微调大型语言模型中记忆问题的持续挑战，并强调需要强大的、可扩展的隐私保护技术。"}}
{"id": "2601.17476", "pdf": "https://arxiv.org/pdf/2601.17476", "abs": "https://arxiv.org/abs/2601.17476", "authors": ["Hellina Hailu Nigatu", "Farhana Shahid", "Vishal Sharma", "Abigail Oppong", "Michaelanne Thomas", "Syed Ishtiaque Ahmed"], "title": "UnWEIRDing Peer Review in Human Computer Interaction", "categories": ["cs.HC"], "comment": "Accepted to CHI'26. Authors with (*) contributed equally to this work", "summary": "Peer review determines which scholarship is legitimized; however, review biases often disadvantage scholarship that diverges from the norm. Human-Computer Interaction (HCI) lacks a systemic inquiry into how such biases affect underrepresented Global South (GS) scholarship. To address this critical gap, we conducted four focus groups with 16 HCI researchers studying the GS. Participants reported experiencing reviews that confined them to development research, dismissed their theoretical contributions, and questioned situated knowledge from GS communities. Both as authors and reviewers, participants reported experiencing the epistemic burden of over-explaining why knowledge from GS communities matters. Further, they noted being tokenized as ``cultural experts'' when assigned to review papers and pointed out that the hidden curriculum of writing HCI papers often gatekeeps GS scholarship. Using epistemic oppression as a lens, we discuss how review practices marginalize GS scholarship and outline actionable strategies for nurturing equitable epistemological evaluation of HCI scholarship.", "AI": {"tldr": "论文探讨了在人机交互（HCI）领域中，对来自全球南部（GS）的学术研究进行同行评审时存在的偏见，并提出了解决这些偏见的方法。", "motivation": "为了填补关于如何通过审查偏见影响GS学术研究这一关键空白，该文旨在解决HCII中的系统性问题，尤其是那些涉及边缘化群体的研究。", "method": "作者进行了四个焦点小组讨论，参与者是16名研究全球南部的HCI研究人员，以探讨他们在作为作者和审稿人时遇到的问题。", "result": "参与者报告了他们经历的限制在发展研究中的评审、忽视理论贡献以及质疑GS社区知识的情况，并指出撰写HCII论文的隐性课程通常会阻碍GS学术成果。", "conclusion": "通过采用知识压迫这一视角，讨论了审稿实践如何边缘化GS研究成果，并提出了培养公平的知识评价机制的具体行动策略。"}}
{"id": "2601.17470", "pdf": "https://arxiv.org/pdf/2601.17470", "abs": "https://arxiv.org/abs/2601.17470", "authors": ["Chia-Ming Lee", "Yu-Fan Lin", "Yu-Jou Hsiao", "Jing-Hui Jung", "Yu-Lun Liu", "Chih-Chung Hsu"], "title": "PhaSR: Generalized Image Shadow Removal with Physically Aligned Priors", "categories": ["cs.CV"], "comment": "Project Page: https://ming053l.github.io/PhaSR", "summary": "Shadow removal under diverse lighting conditions requires disentangling illumination from intrinsic reflectance, a challenge compounded when physical priors are not properly aligned. We propose PhaSR (Physically Aligned Shadow Removal), addressing this through dual-level prior alignment to enable robust performance from single-light shadows to multi-source ambient lighting. First, Physically Aligned Normalization (PAN) performs closed-form illumination correction via Gray-world normalization, log-domain Retinex decomposition, and dynamic range recombination, suppressing chromatic bias. Second, Geometric-Semantic Rectification Attention (GSRA) extends differential attention to cross-modal alignment, harmonizing depth-derived geometry with DINO-v2 semantic embeddings to resolve modal conflicts under varying illumination. Experiments show competitive performance in shadow removal with lower complexity and generalization to ambient lighting where traditional methods fail under multi-source illumination. Our source code is available at https://github.com/ming053l/PhaSR.", "AI": {"tldr": "本论文提出了一种名为PhaSR的算法，用于在各种照明条件下移除图像阴影。", "motivation": "传统的阴影去除方法难以处理多光源环境下的复杂照明情况，且物理先验不匹配导致性能不佳。为了提高鲁棒性和泛化能力，本文提出了新的解决方案。", "method": "PhaSR采用了双层级的先验对齐策略：首先使用Physically Aligned Normalization（PAN）进行灰度世界归一化、Retinex分解和动态范围重组来纠正照明并抑制色偏；其次通过Geometric-Semantic Rectification Attention（GSRA），结合深度几何信息与DINO-v2语义嵌入，以解决多模态冲突。", "result": "实验表明，在各种照明条件下，PhaSR在阴影去除方面表现出优越性和较低的复杂度，并且能够泛化到多光源环境下的自然光照中。", "conclusion": "研究证明了双层级先验对齐策略（PAN和GSRA）可以有效地改进图像阴影移除，特别是在复杂的多光源照明条件下。"}}
{"id": "2601.17468", "pdf": "https://arxiv.org/pdf/2601.17468", "abs": "https://arxiv.org/abs/2601.17468", "authors": ["Chia-Ming Lee", "Yu-Fan Lin", "Jing-Hui Jung", "Yu-Jou Hsiao", "Chih-Chung Hsu", "Yu-Lun Liu"], "title": "ReflexSplit: Single Image Reflection Separation via Layer Fusion-Separation", "categories": ["cs.CV"], "comment": "Project page: https://wuw2135.github.io/ReflexSplit-ProjectPage/", "summary": "Single Image Reflection Separation (SIRS) disentangles mixed images into transmission and reflection layers. Existing methods suffer from transmission-reflection confusion under nonlinear mixing, particularly in deep decoder layers, due to implicit fusion mechanisms and inadequate multi-scale coordination. We propose ReflexSplit, a dual-stream framework with three key innovations. (1) Cross-scale Gated Fusion (CrGF) adaptively aggregates semantic priors, texture details, and decoder context across hierarchical depths, stabilizing gradient flow and maintaining feature consistency. (2) Layer Fusion-Separation Blocks (LFSB) alternate between fusion for shared structure extraction and differential separation for layer-specific disentanglement. Inspired by Differential Transformer, we extend attention cancellation to dual-stream separation via cross-stream subtraction. (3) Curriculum training progressively strengthens differential separation through depth-dependent initialization and epoch-wise warmup. Extensive experiments on synthetic and real-world benchmarks demonstrate state-of-the-art performance with superior perceptual quality and robust generalization. Our code is available at https://github.com/wuw2135/ReflexSplit.", "AI": {"tldr": "本文提出了ReflexSplit，一种通过层融合与分离来实现单幅图像反射分离的双流框架。", "motivation": "现有的方法在处理非线性混合时存在传输-反射混淆问题，尤其是在深层解码器中，由于隐式融合机制和多尺度协调不足。", "method": "ReflexSplit包含三项关键创新：跨尺度门控融合（CrGF），层融合分离块（LFSB）以及基于深度依赖初始化和周期性预热的课程训练。", "result": "在合成数据集和真实世界基准测试中，该方法展现了最佳性能，并且具有优越的感知质量和强大的泛化能力。", "conclusion": "实验结果表明ReflexSplit在单幅图像反射分离任务上达到了最先进的水平，代码已公开。"}}
{"id": "2601.17460", "pdf": "https://arxiv.org/pdf/2601.17460", "abs": "https://arxiv.org/abs/2601.17460", "authors": ["Fangyijie Wang", "Siteng Ma", "Guénolé Silvestre", "Kathleen M. Curran"], "title": "Entropy-Guided Agreement-Diversity: A Semi-Supervised Active Learning Framework for Fetal Head Segmentation in Ultrasound", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted at ISBI 2026", "summary": "Fetal ultrasound (US) data is often limited due to privacy and regulatory restrictions, posing challenges for training deep learning (DL) models. While semi-supervised learning (SSL) is commonly used for fetal US image analysis, existing SSL methods typically rely on random limited selection, which can lead to suboptimal model performance by overfitting to homogeneous labeled data. To address this, we propose a two-stage Active Learning (AL) sampler, Entropy-Guided Agreement-Diversity (EGAD), for fetal head segmentation. Our method first selects the most uncertain samples using predictive entropy, and then refines the final selection using the agreement-diversity score combining cosine similarity and mutual information. Additionally, our SSL framework employs a consistency learning strategy with feature downsampling to further enhance segmentation performance. In experiments, SSL-EGAD achieves an average Dice score of 94.57\\% and 96.32\\% on two public datasets for fetal head segmentation, using 5\\% and 10\\% labeled data for training, respectively. Our method outperforms current SSL models and showcases consistent robustness across diverse pregnancy stage data. The code is available on \\href{https://github.com/13204942/Semi-supervised-EGAD}{GitHub}.", "AI": {"tldr": "本文提出了一种基于熵引导的一致性和多样性选择的半监督主动学习框架EGAD，用于胎儿头部在超声图像中的分割。", "motivation": "由于隐私和法规限制，胎儿超声数据有限，这给训练深度学习模型带来了挑战。现有的半监督学习方法通常依赖于随机选择少量标记样本，可能会导致过度拟合同质化标签数据的问题。", "method": "提出了一种两阶段主动学习采样器EGAD，首先通过预测熵选择最不确定的样本，然后使用一致性-多样性分数（结合余弦相似性和互信息）进行最终选择，并采用特征下采样的一致性学习策略进一步提高分割性能。", "result": "在两个公共数据集上，SSL-EGAD分别使用5%和10%的标记数据训练时达到了94.57%和96.32%的平均Dice分数，优于当前的半监督模型，并展示了跨不同妊娠阶段的一致稳健性。", "conclusion": "本文提出的方法提高了胎儿头部超声图像分割性能，并在有限标签情况下表现出了良好的效果和一致性。"}}
{"id": "2601.17458", "pdf": "https://arxiv.org/pdf/2601.17458", "abs": "https://arxiv.org/abs/2601.17458", "authors": ["Shuhao Zhang", "Jiahe Dong", "Haoran Wang", "Chang Jiang", "Quan Li"], "title": "When Seconds Count: Designing Real-Time VR Interventions for Stress Inoculation Training in Novice Physicians", "categories": ["cs.HC"], "comment": "In Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI'26), April 13-17, 2026, Barcelona, Spain", "summary": "Surgical emergencies often trigger acute cognitive overload in novice physicians, impairing their decision-making under pressure. Although Virtual Reality-based Stress Inoculation Training (VR-SIT) shows promise, current systems fall short in delivering real-time, effective support during moments of peak stress. To bridge this gap, we first conducted a formative study (N=12) to uncover the core needs of novice physicians for immediate assistance under acute stress and identified three key intervention strategies: self-regulation aids, procedure guidance, and emotional/sensory support. Building on these insights, we designed and implemented a novel VR-SIT system that incorporates a just-in-time adaptive intervention framework, dynamically tailoring support to learners' cognitive and emotional states. We then validated these strategies in a user study (N=26). Our findings provide empirical evidence and design implications for next-generation VR medical training systems, supporting physicians in sustaining cognitive clarity and accurate decision-making in critical situations.", "AI": {"tldr": "设计了一个实时VR干预系统，以帮助新手医生在压力下保持清晰的认知和准确的决策能力。", "motivation": "解决当前虚拟现实应激免疫训练系统无法提供即时有效支持的问题，并通过研究确定了三个关键干预策略：自我调节辅助、程序指导以及情绪/感官支持。", "method": "进行了形成性研究以了解新手医生在急性压力下的需求，设计并实现了一个包含即刻适应性干预框架的VR-SIT系统，并验证这些策略的有效性。", "result": "通过用户研究（N=26）提供了实证证据和下一代VR医疗培训系统的具体设计建议。", "conclusion": "该研究表明了新型实时VR支持在增强新手医生在紧急情况下的决策能力方面具有潜在价值。"}}
{"id": "2601.17454", "pdf": "https://arxiv.org/pdf/2601.17454", "abs": "https://arxiv.org/abs/2601.17454", "authors": ["Muhammad Ahmed Atif", "Nehal Naeem Haji", "Mohammad Shahid Shaikh", "Muhammad Ebad Atif"], "title": "Embodiment-Induced Coordination Regimes in Tabular Multi-Agent Q-Learning", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Centralized value learning is often assumed to improve coordination and stability in multi-agent reinforcement learning, yet this assumption is rarely tested under controlled conditions. We directly evaluate it in a fully tabular predator-prey gridworld by comparing independent and centralized Q-learning under explicit embodiment constraints on agent speed and stamina. Across multiple kinematic regimes and asymmetric agent roles, centralized learning fails to provide a consistent advantage and is frequently outperformed by fully independent learning, even under full observability and exact value estimation. Moreover, asymmetric centralized-independent configurations induce persistent coordination breakdowns rather than transient learning instability. By eliminating confounding effects from function approximation and representation learning, our tabular analysis isolates coordination structure as the primary driver of these effects. The results show that increased coordination can become a liability under embodiment constraints, and that the effectiveness of centralized learning is fundamentally regime and role dependent rather than universal.", "AI": {"tldr": "本文探讨了在具身限制下，集中式价值学习是否能提高多智能体强化学习中的协调性和稳定性，并通过对比独立Q学习和集中式Q学习的方法，在一个完全表格化的猎物-捕食者网格世界中进行验证。", "motivation": "传统的假设认为集中化价值学习可以改善多智能体系统的协调性与稳定性，但这一假设很少在控制条件下进行测试。本文旨在检验该假设，并理解具身限制下的协调结构影响。", "method": "作者在一个完全表格化的猎物-捕食者网格世界中比较了独立和集中式Q学习的性能，通过设定显式的具身体现约束（如速度和耐力）来评估它们在多个运动状态和不对称角色设置下的表现差异。", "result": "实验结果显示，在全观察性和精确值估计的情况下，集中式学习并不能始终提供优势，并且常被完全独立的学习所超越。同时，当使用不对称的集中-独立配置时，反而会引发持续性的协调中断而非短暂的学习不稳定状态。", "conclusion": "研究结果表明，增加的协调性在具身限制下可能成为负担，且集中学习的有效性取决于具体的应用场景和角色分配，而不是普遍适用的。"}}
{"id": "2601.17443", "pdf": "https://arxiv.org/pdf/2601.17443", "abs": "https://arxiv.org/abs/2601.17443", "authors": ["Ondrej Bohdal", "Pramit Saha", "Umberto Michieli", "Mete Ozay", "Taha Ceritli"], "title": "Clustering-driven Memory Compression for On-device Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at ICASSP 2026", "summary": "Large language models (LLMs) often rely on user-specific memories distilled from past interactions to enable personalized generation. A common practice is to concatenate these memories with the input prompt, but this approach quickly exhausts the limited context available in on-device LLMs. Compressing memories by averaging can mitigate context growth, yet it frequently harms performance due to semantic conflicts across heterogeneous memories. In this work, we introduce a clustering-based memory compression strategy that balances context efficiency and personalization quality. Our method groups memories by similarity and merges them within clusters prior to concatenation, thereby preserving coherence while reducing redundancy. Experiments demonstrate that our approach substantially lowers the number of memory tokens while outperforming baseline strategies such as naive averaging or direct concatenation. Furthermore, for a fixed context budget, clustering-driven merging yields more compact memory representations and consistently enhances generation quality.", "AI": {"tldr": "本文提出了一种基于聚类的记忆压缩策略，用于在设备上运行的大语言模型中平衡上下文效率和个性化质量。", "motivation": "传统的将用户记忆直接与输入提示串联的方法会快速消耗设备上的大语言模型的有限上下文空间，并且简单的平均压缩方法会因语义冲突而损害性能。因此，需要一种新的策略来解决这些问题。", "method": "本文使用聚类方法按相似性对记忆进行分组，在合并集群中的记忆之前进行串联，从而在减少冗余的同时保持一致性。", "result": "实验表明，与直接串联或简单平均等基线策略相比，该方法显著减少了记忆令牌的数量，并提高了生成质量。", "conclusion": "基于聚类的记忆压缩方法可以在固定的上下文预算下提供更紧凑的记忆表示并持续提高生成质量。"}}
{"id": "2601.17441", "pdf": "https://arxiv.org/pdf/2601.17441", "abs": "https://arxiv.org/abs/2601.17441", "authors": ["Ondrej Bohdal", "Taha Ceritli", "Mete Ozay", "Jijoong Moon", "Kyeng-Hun Lee", "Hyeonmok Ko", "Umberto Michieli"], "title": "Data-driven Clustering and Merging of Adapters for On-device Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted at ICASSP 2026", "summary": "On-device large language models commonly employ task-specific adapters (e.g., LoRAs) to deliver strong performance on downstream tasks. While storing all available adapters is impractical due to memory constraints, mobile devices typically have sufficient capacity to store a limited number of these parameters. This raises a critical challenge: how to select representative adapters that generalize well across multiple tasks - a problem that remains unexplored in existing literature. We propose a novel method D2C for adapter clustering that leverages minimal task-specific examples (e.g., 10 per task) and employs an iterative optimization process to refine cluster assignments. The adapters within each cluster are merged, creating multi-task adapters deployable on resource-constrained devices. Experimental results demonstrate that our method effectively boosts performance for considered storage budgets.", "AI": {"tldr": "本文提出了一个名为D2C的方法，用于聚类和合并任务特定的适配器（如LoRAs），以在资源受限设备上部署大语言模型。", "motivation": "现有研究未解决如何从众多适配器中选择能跨多个任务泛化的代表适配器的问题。由于存储限制，需要一种方法来聚类和合并适配器，使其能在移动设备等资源有限的设备上运行。", "method": "D2C方法利用少量的任务特定示例（例如每个任务10个）进行迭代优化以改进集群分配，并将同一簇内的适配器合并为多任务适配器。", "result": "实验结果表明，该方法在考虑存储预算的情况下有效提升性能。", "conclusion": "通过聚类和合并任务特定的适配器，D2C能够在保持良好性能的同时，减少大语言模型在资源受限设备上的内存占用。"}}
{"id": "2601.17440", "pdf": "https://arxiv.org/pdf/2601.17440", "abs": "https://arxiv.org/abs/2601.17440", "authors": ["Xinru Cui", "Linxi Feng", "Yixuan Zhou", "Haoqi Han", "Zhe Liu", "Hesheng Wang"], "title": "PILOT: A Perceptive Integrated Low-level Controller for Loco-manipulation over Unstructured Scenes", "categories": ["cs.RO"], "comment": "8 pages, 4 figures", "summary": "Humanoid robots hold great potential for diverse interactions and daily service tasks within human-centered environments, necessitating controllers that seamlessly integrate precise locomotion with dexterous manipulation. However, most existing whole-body controllers lack exteroceptive awareness of the surrounding environment, rendering them insufficient for stable task execution in complex, unstructured scenarios.To address this challenge, we propose PILOT, a unified single-stage reinforcement learning (RL) framework tailored for perceptive loco-manipulation, which synergizes perceptive locomotion and expansive whole-body control within a single policy. To enhance terrain awareness and ensure precise foot placement, we design a cross-modal context encoder that fuses prediction-based proprioceptive features with attention-based perceptive representations. Furthermore, we introduce a Mixture-of-Experts (MoE) policy architecture to coordinate diverse motor skills, facilitating better specialization across distinct motion patterns. Extensive experiments in both simulation and on the physical Unitree G1 humanoid robot validate the efficacy of our framework. PILOT demonstrates superior stability, command tracking precision, and terrain traversability compared to existing baselines. These results highlight its potential to serve as a robust, foundational low-level controller for loco-manipulation in unstructured scenes.", "AI": {"tldr": "本文提出了PILOT，一个用于感知性机操控制的统一单阶段强化学习框架。", "motivation": "现有的全身控制器缺乏对外部环境的认知能力，在复杂、非结构化场景中执行稳定任务时表现不足。为了实现人类机器人在人中心环境中多样互动和服务的任务需求，需要整合精确运动和灵巧操作的无缝集成。", "method": "PILOT结合了基于预测的身体感受特征与基于注意力的感知表示，通过交叉模式上下文编码器设计来增强地形意识并保证精准脚步放置。引入混合专家（MoE）策略架构来协调多样化电机技能，以支持不同的运动模式。", "result": "在模拟环境和物理Unitree G1人形机器人上的实验结果表明，PILOT框架显示出优越的稳定性、命令追踪精度以及地形穿越能力，优于现有的基准系统。", "conclusion": "这些结果突显了PILOT作为非结构化场景中机操控制基础低级控制器的巨大潜力。"}}
{"id": "2601.17435", "pdf": "https://arxiv.org/pdf/2601.17435", "abs": "https://arxiv.org/abs/2601.17435", "authors": ["Maria Jesus Rodriguez-Sanchez", "Manuel Noguera", "Angel Ruiz-Zafra", "Kawtar Benghazi"], "title": "Towards a Declarative Agentic Layer for Intelligent Agents in MCP-Based Server Ecosystems", "categories": ["cs.SE", "cs.AI"], "comment": "12 pages, 3 figures", "summary": "Recent advances in Large Language Models (LLMs) have enabled the development of increasingly complex agentic and multi-agent systems capable of planning, tool use and task decomposition. However, empirical evidence shows that many of these systems suffer from fundamental reliability issues, including hallucinated actions, unexecutable plans and brittle coordination. Crucially, these failures do not stem from limitations of the underlying models themselves, but from the absence of explicit architectural structure linking goals, capabilities and execution. This paper presents a declarative, model-independent architectural layer for grounded agentic workflows that addresses this gap. The proposed layer, referred to as DALIA (Declarative Agentic Layer for Intelligent Agents), formalises executable capabilities, exposes tasks through a declarative discovery protocol, maintains a federated directory of agents and their execution resources, and constructs deterministic task graphs grounded exclusively in declared operations. By enforcing a clear separation between discovery, planning and execution, the architecture constrains agent behaviour to a verifiable operational space, reducing reliance on speculative reasoning and free-form coordination. We present the architecture and design principles of the proposed layer and illustrate its operation through a representative task-oriented scenario, demonstrating how declarative grounding enables reproducible and verifiable agentic workflows across heterogeneous environments.", "AI": {"tldr": "本文提出了一个名为DALIA的声明式代理架构层，以解决复杂的智能代理系统中存在的可靠性问题。", "motivation": "尽管大型语言模型的发展促进了复杂多智能体系统的开发，但这些系统常因缺乏明确的架构结构而出现根本性的可靠性和协调性问题。因此，需要一种新的方法来确保任务执行的可靠性。", "method": "提出了一种声明式的、与模型无关的架构层DALIA，它形式化了可执行能力，通过声明式发现协议暴露任务，并维护代理及其执行资源的联邦目录。该架构强调了发现、规划和执行之间的清晰分离，以约束智能体行为至一个可验证的操作空间。", "result": "通过展示一个具有代表性的面向任务场景，展示了如何使用声明式的地面基础来实现跨异构环境的可重复性和可验证性的工作流。", "conclusion": "该架构的设计原则和操作证明了其能够减少对投机推理和自由协调的需求，并提高智能体系统在复杂任务执行中的可靠性。"}}
{"id": "2601.17434", "pdf": "https://arxiv.org/pdf/2601.17434", "abs": "https://arxiv.org/abs/2601.17434", "authors": ["Xiaokang Lei", "Ching Christie Pang", "Yuyang Jiang", "Xin Tong", "Pan Hui"], "title": "Co-Designing Digital Humans for Online Learning: A Framework for Human-AI Pedagogical Integration", "categories": ["cs.HC"], "comment": null, "summary": "Artificial intelligence (AI) and large language models (LLMs) are reshaping education, with virtual avatars emerging as digital teachers capable of enhancing engagement, sustaining attention, and addressing instructor shortages. Aligned with the Sustainable Development Goals (SDGs) for equitable quality education, these technologies hold promise yet lack clear guidelines for effective design and implementation in online learning. To fill this gap, we introduce a framework specifying when, what, and how digital teachers should be integrated. Our study combines (1) a design space analysis of 87 works across AI, educational technology, design, and HCI, (2) a survey of 132 learners' practices and preferences, and (3) three co-design workshops with 18 experts from pedagogy, design, and AI. It provides actionable guidance for educators, designers, and HCI researchers, advancing opportunities to build more engaging, equitable, and effective online learning environments powered by digital teachers.", "AI": {"tldr": "本文提出了一种框架，用于指导如何将数字教师整合到在线学习中。", "motivation": "AI和大型语言模型正在重塑教育领域，虚拟化身作为数字老师可以增强参与度、维持注意力并缓解师资短缺问题。尽管如此，这些技术在设计与实施方面的有效指南仍然缺乏，这正是本文想要解决的问题。", "method": "研究结合了三部分内容：对87篇跨AI、教育科技、设计和人机交互领域工作的设计空间分析；132名学习者实践和偏好的调查；以及与来自教学法、设计和AI领域的18位专家进行的三个共同设计工作坊。", "result": "本文提供了一套具体的操作指南，旨在帮助教育工作者、设计师和HCI研究人员构建更吸引人、更公平且更有效的在线学习环境。", "conclusion": "该框架为如何将数字教师整合到在线学习中提供了清晰指导，促进了更加公平与高质量的教育资源的发展。"}}
{"id": "2601.17431", "pdf": "https://arxiv.org/pdf/2601.17431", "abs": "https://arxiv.org/abs/2601.17431", "authors": ["H. Kemal İlter"], "title": "The 17% Gap: Quantifying Epistemic Decay in AI-Assisted Survey Papers", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.DL"], "comment": null, "summary": "The adoption of Large Language Models (LLMs) in scientific writing promises efficiency but risks introducing informational entropy. While \"hallucinated papers\" are a known artifact, the systematic degradation of valid citation chains remains unquantified. We conducted a forensic audit of 50 recent survey papers in Artificial Intelligence (N=5,514 citations) published between September 2024 and January 2026. We utilized a hybrid verification pipeline combining DOI resolution, Crossref metadata analysis, Semantic Scholar queries, and fuzzy text matching to distinguish between formatting errors (\"Sloppiness\") and verifiable non-existence (\"Phantoms). We detect a persistent 17.0% Phantom Rate -- citations that cannot be resolved to any digital object despite aggressive forensic recovery. Diagnostic categorization reveals three distinct failure modes: pure hallucinations (5.1%), hallucinated identifiers with valid titles (16.4%), and parsing-induced matching failures (78.5%). Longitudinal analysis reveals a flat trend (+0.07 pp/month), suggesting that high-entropy citation practices have stabilized as an endemic feature of the field. The scientific citation graph in AI survey literature exhibits \"link rot\" at scale. This suggests a mechanism where AI tools act as \"lazy research assistants,\" retrieving correct titles but hallucinating metadata, thereby severing the digital chain of custody required for reproducible science.", "AI": {"tldr": "该论文量化了AI辅助调查文章中的知识衰减，发现存在17%的引用无法验证。", "motivation": "尽管大型语言模型在科学写作中提高了效率，但它们引入的信息熵风险尚未完全了解。研究旨在系统性地评估有效引文链的衰退情况。", "method": "对50篇最近的人工智能调查文章进行了法医审计（共5,514个引用），使用混合验证管道结合DOI解析、Crossref元数据分析、Semantic Scholar查询和模糊文本匹配来区分格式错误和可验证不存在的情况。", "result": "检测到一个持续的17.0%幻影率，即无法解决为任何数字对象的引用。诊断分类揭示了三种失败模式：纯幻想（5.1%）、具有有效标题的幻想标识符（16.4%）和解析引起的匹配故障（78.5%）。", "conclusion": "人工智能调查文献中的科学引文图表现出“链接腐烂”现象。表明AI工具作为“懒惰的研究助手”，会检索到正确的标题但编造元数据，从而破坏了可重复科学研究所需的数字证据链。"}}
{"id": "2601.17429", "pdf": "https://arxiv.org/pdf/2601.17429", "abs": "https://arxiv.org/abs/2601.17429", "authors": ["Mehdi Yousefzadeh", "Siavash Shirzadeh Barough", "Ashkan Fakharifar", "Yashar Tayyarazad", "Narges Eghbali", "Mohaddeseh Mozaffari", "Hoda Taeb", "Negar Sadat Rafiee Tabatabaee", "Parsa Esfahanian", "Ghazaleh Sadeghi Gohar", "Amineh Safavirad", "Saeideh Mazloomzadeh", "Ehsan khalilipur", "Armin Elahifar", "Majid Maleki"], "title": "Coronary Artery Segmentation and Vessel-Type Classification in X-Ray Angiography", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "X-ray coronary angiography (XCA) is the clinical reference standard for assessing coronary artery disease, yet quantitative analysis is limited by the difficulty of robust vessel segmentation in routine data. Low contrast, motion, foreshortening, overlap, and catheter confounding degrade segmentation and contribute to domain shift across centers. Reliable segmentation, together with vessel-type labeling, enables vessel-specific coronary analytics and downstream measurements that depend on anatomical localization. From 670 cine sequences (407 subjects), we select a best frame near peak opacification using a low-intensity histogram criterion and apply joint super-resolution and enhancement. We benchmark classical Meijering, Frangi, and Sato vesselness filters under per-image oracle tuning, a single global mean setting, and per-image parameter prediction via Support Vector Regression (SVR). Neural baselines include U-Net, FPN, and a Swin Transformer, trained with coronary-only and merged coronary+catheter supervision. A second stage assigns vessel identity (LAD, LCX, RCA). External evaluation uses the public DCA1 cohort. SVR per-image tuning improves Dice over global means for all classical filters (e.g., Frangi: 0.759 vs. 0.741). Among deep models, FPN attains 0.914+/-0.007 Dice (coronary-only), and merged coronary+catheter labels further improve to 0.931+/-0.006. On DCA1 as a strict external test, Dice drops to 0.798 (coronary-only) and 0.814 (merged), while light in-domain fine-tuning recovers to 0.881+/-0.014 and 0.882+/-0.015. Vessel-type labeling achieves 98.5% accuracy (Dice 0.844) for RCA, 95.4% (0.786) for LAD, and 96.2% (0.794) for LCX. Learned per-image tuning strengthens classical pipelines, while high-resolution FPN models and merged-label supervision improve stability and external transfer with modest adaptation.", "AI": {"tldr": "本文介绍了冠状动脉X射线血管造影图像中的血管分割和类型分类方法，采用经典滤波器与深度学习模型并结合自适应参数调优实现准确的血管分割及标注。", "motivation": "由于低对比度、运动、缩短效应、重叠以及导管干扰等因素影响，冠状动脉X射线血管造影图像中的血管分割具有挑战性。可靠的分割和血管类型标注有助于进行基于解剖位置的分析测量。", "method": "论文从670个动态序列（407名患者）中选取对比剂峰值附近的最佳帧，并应用联合超分辨率增强技术。同时，评估了经典滤波器在自适应参数调优下的效果，并比较了U-Net、FPN和Swin Transformer等深度学习模型的表现。", "result": "SVR自适应参数调优提高了经典滤波器的Dice分数；FPN模型达到0.914+/-0.007 Dice（仅冠状动脉）；外部测试集DCA1上，经轻度微调后，Dice分数提高到0.881+/-0.014和0.882+/-0.015。血管类型标注准确率分别为98.5%、95.4%和96.2%，对应于RCA、LAD和LCX。", "conclusion": "通过自适应参数调优强化了经典滤波器的性能，高分辨率FPN模型与合并标签监督在稳定性和跨域迁移上取得了良好的表现。"}}
{"id": "2601.17428", "pdf": "https://arxiv.org/pdf/2601.17428", "abs": "https://arxiv.org/abs/2601.17428", "authors": ["Ziming Li", "Chenhao Li", "Marco Hutter"], "title": "Scaling Rough Terrain Locomotion with Automatic Curriculum Reinforcement Learning", "categories": ["cs.RO"], "comment": null, "summary": "Curriculum learning has demonstrated substantial effectiveness in robot learning. However, it still faces limitations when scaling to complex, wide-ranging task spaces. Such task spaces often lack a well-defined difficulty structure, making the difficulty ordering required by previous methods challenging to define. We propose a Learning Progress-based Automatic Curriculum Reinforcement Learning (LP-ACRL) framework, which estimates the agent's learning progress online and adaptively adjusts the task-sampling distribution, thereby enabling automatic curriculum generation without prior knowledge of the difficulty distribution over the task space. Policies trained with LP-ACRL enable the ANYmal D quadruped to achieve and maintain stable, high-speed locomotion at 2.5 m/s linear velocity and 3.0 rad/s angular velocity across diverse terrains, including stairs, slopes, gravel, and low-friction flat surfaces--whereas previous methods have generally been limited to high speeds on flat terrain or low speeds on complex terrain. Experimental results demonstrate that LP-ACRL exhibits strong scalability and real-world applicability, providing a robust baseline for future research on curriculum generation in complex, wide-ranging robotic learning task spaces.", "AI": {"tldr": "本文提出了一种基于学习进展的自动课程强化学习（LP-ACRL）框架，以提高机器人在复杂地形上的运动能力。", "motivation": "现有的课程学习方法在扩展到复杂的任务空间时存在局限性，缺乏明确的任务难度结构，这使得定义难度顺序变得具有挑战性。", "method": "本文提出的学习进展自动课程强化学习（LP-ACRL）框架可以在线估计代理的学习进度，并自适应调整任务采样分布，实现无需先验知识的自动课程生成。", "result": "通过使用LP-ACRL训练出的策略，ANYmal D四足机器人能够在包括楼梯、斜坡、碎石和低摩擦平面在内的多种地形上以2.5 m/s线速度和3.0 rad/s角速度实现并保持稳定高速运动，这优于以往方法。", "conclusion": "实验结果表明，LP-ACRL展示了强大的可扩展性和现实世界的应用潜力，为未来在复杂广泛的机器人学习任务空间中的课程生成研究提供了坚实的基础。"}}
{"id": "2601.17426", "pdf": "https://arxiv.org/pdf/2601.17426", "abs": "https://arxiv.org/abs/2601.17426", "authors": ["Zhengqing Zang", "Yuqi Ding", "Yanmei Gu", "Changkai Song", "Zhengkai Yang", "Guoping Du", "Junbo Zhao", "Haobo Wang"], "title": "A Syllogistic Probe: Tracing the Evolution of Logic Reasoning in Large Language Models", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Human logic has gradually shifted from intuition-driven inference to rigorous formal systems. Motivated by recent advances in large language models (LLMs), we explore whether LLMs exhibit a similar evolution in the underlying logical framework. Using existential import as a probe, we for evaluate syllogism under traditional and modern logic. Through extensive experiments of testing SOTA LLMs on a new syllogism dataset, we have some interesting findings: (i) Model size scaling promotes the shift toward modern logic; (ii) Thinking serves as an efficient accelerator beyond parameter scaling; (iii) the Base model plays a crucial role in determining how easily and stably this shift can emerge. Beyond these core factors, we conduct additional experiments for in-depth analysis of properties of current LLMs on syllogistic reasoning.", "AI": {"tldr": "探讨大型语言模型在演绎推理方面的逻辑演变。", "motivation": "受人类逻辑从直觉驱动的推论向严格的正式系统演进启发，研究大型语言模型是否也表现出类似的逻辑框架发展。", "method": "利用存在含义作为探测工具，在传统和现代逻辑下评估三段论，并通过在新的三段论数据集上测试最先进的大型语言模型进行广泛实验。", "result": "(i) 模型尺寸扩展促进了向现代逻辑的转变；(ii) 思考能力超越参数规模成为高效的加速器；(iii) 基础模型对于决定这种转换出现的容易度和稳定性起关键作用。", "conclusion": "大型语言模型在演绎推理方面表现出类似人类从直觉驱动到正式系统发展的趋势，尤其强调了思考能力和基础模型的重要性。"}}
{"id": "2601.17425", "pdf": "https://arxiv.org/pdf/2601.17425", "abs": "https://arxiv.org/abs/2601.17425", "authors": ["Benjamin Moseley", "Kirk Pruhs", "Marc Uetz", "Rudy Zhou"], "title": "Minimizing Completion Times of Stochastic Jobs on Parallel Machines is Hard", "categories": ["cs.DS", "cs.CC", "math.OC"], "comment": "13 pages, 1 figure", "summary": "This paper considers the scheduling of stochastic jobs on parallel identical machines to minimize the expected total weighted completion time. While this is a classical problem with a significant body of research on approximation algorithms over the past two decades, constant-factor performance guarantees are currently known only under very restrictive assumptions on the input distributions, even when all job weights are identical. This algorithmic difficulty is striking given the lack of corresponding complexity results: to date, it is conceivable that the problem could be solved optimally in polynomial time. We address this gap with hardness results that demonstrate the problem's inherent intractability. For the special case of discrete two-point processing time distributions and unit weights, we prove that deciding whether there exists a scheduling policy with expected cost at most a given threshold is #P-hard. Furthermore, we show that evaluating the expected objective value of the standard (W)SEPT greedy policy is itself #P-hard. These represent the first hardness results for scheduling independent stochastic jobs and min-sum objective that do not merely rely on the intractability of the underlying deterministic counterparts.", "AI": {"tldr": "本文研究了在并行机器上调度随机作业以最小化期望的总加权完成时间的问题，并证明了该问题的内在难解性。", "motivation": "尽管存在大量关于近似算法的研究，但在输入分布的严格假设下才存在常数因子性能保证，作者旨在填补这一理论空白并揭示其计算复杂度。", "method": "通过引入离散两点处理时间分布和单位权重下的特殊情形，证明了决策问题与标准(W)SEPT贪婪策略评估均是#P难的。", "result": "证明了对于离散两点处理时间和单位权重，判断是否存在期望成本不超过给定阈值的调度策略是#P难的，并且评估(W)SEPT贪婪策略的预期目标函数值也是#P难的。", "conclusion": "首次展示了独立随机作业和最小求和目标下的难解性结果，不依赖于确定性对应问题的复杂度。"}}
{"id": "2601.17420", "pdf": "https://arxiv.org/pdf/2601.17420", "abs": "https://arxiv.org/abs/2601.17420", "authors": ["Shiu-hong Kao", "Chak Ho Huang", "Huaiqian Liu", "Yu-Wing Tai", "Chi-Keung Tang"], "title": "CoT-Seg: Rethinking Segmentation with Chain-of-Thought Reasoning and Self-Correction", "categories": ["cs.CV"], "comment": "Project page: https://danielshkao.github.io/cot-seg.html", "summary": "Existing works of reasoning segmentation often fall short in complex cases, particularly when addressing complicated queries and out-of-domain images. Inspired by the chain-of-thought reasoning, where harder problems require longer thinking steps/time, this paper aims to explore a system that can think step-by-step, look up information if needed, generate results, self-evaluate its own results, and refine the results, in the same way humans approach harder questions. We introduce CoT-Seg, a training-free framework that rethinks reasoning segmentation by combining chain-of-thought reasoning with self-correction. Instead of fine-tuning, CoT-Seg leverages the inherent reasoning ability of pre-trained MLLMs (GPT-4o) to decompose queries into meta-instructions, extract fine-grained semantics from images, and identify target objects even under implicit or complex prompts. Moreover, CoT-Seg incorporates a self-correction stage: the model evaluates its own segmentation against the original query and reasoning trace, identifies mismatches, and iteratively refines the mask. This tight integration of reasoning and correction significantly improves reliability and robustness, especially in ambiguous or error-prone cases. Furthermore, our CoT-Seg framework allows easy incorporation of retrieval-augmented reasoning, enabling the system to access external knowledge when the input lacks sufficient information. To showcase CoT-Seg's ability to handle very challenging cases ,we introduce a new dataset ReasonSeg-Hard. Our results highlight that combining chain-of-thought reasoning, self-correction, offers a powerful paradigm for vision-language integration driven segmentation.", "AI": {"tldr": "本文提出了CoT-Seg框架，结合链式思维推理和自我纠正机制来改进分割任务。", "motivation": "现有的推理分割方法在处理复杂查询和域外图像时表现不佳。本研究旨在通过模仿人类处理困难问题的多步骤思考方式，提高分割准确性。", "method": "CoT-Seg框架采用预训练的语言模型（如GPT-4o）进行链式思维推理，分解查询并从图像中提取细粒度语义以识别目标对象。引入自我纠正阶段对结果进行评估和迭代优化，并支持检索增强的推理。", "result": "实验结果显示，结合链式思维推理与自我修正机制可以显著提升分割任务的可靠性和鲁棒性，尤其是在模糊或容易出错的情况下。", "conclusion": "CoT-Seg框架通过整合推理和纠错步骤为基于视觉语言融合的分割提供了一个有力的方法。"}}
{"id": "2601.17418", "pdf": "https://arxiv.org/pdf/2601.17418", "abs": "https://arxiv.org/abs/2601.17418", "authors": ["Mingxian Yu", "Siqi Luo", "Xu Chen"], "title": "GraphPilot: GUI Task Automation with One-Step LLM Reasoning Powered by Knowledge Graph", "categories": ["cs.HC"], "comment": "This paper is accepted by the Journal of Intelligent Computing and Networking (JICN) for publication", "summary": "Mobile graphical user interface (GUI) agents are designed to automate everyday tasks on smartphones. Recent advances in large language models (LLMs) have significantly enhanced the capabilities of mobile GUI agents. However, most LLM-powered mobile GUI agents operate in stepwise query-act loops, which incur high latency due to repeated LLM queries. We present GraphPilot, a mobile GUI agent that leverages knowledge graphs of the target apps to complete user tasks in almost one LLM query. GraphPilot operates in two complementary phases to enable efficient and reliable LLM-powered GUI task automation. In the offline phase, it explores target apps, records and analyzes interaction history, and constructs an app-specific knowledge graph that encodes functions of pages and elements as well as transition rules for each app. In the online phase, given an app and a user task, it leverages the knowledge graph of the given app to guide the reasoning process of LLM. When the reasoning process encounters uncertainty, GraphPilot dynamically requests the HTML representation of the current interface to refine subsequent reasoning. Finally, a validator checks the generated sequence of actions against the transition rules in the knowledge graph, performing iterative corrections to ensure it is valid. The structured, informative information in the knowledge graph allows the LLM to plan the complete sequence of actions required to complete the user task. On the DroidTask benchmark, GraphPilot improves task completion rate over Mind2Web and AutoDroid, while substantially reducing latency and the number of LLM queries.", "AI": {"tldr": "介绍GraphPilot，一种利用知识图谱和大型语言模型实现智能手机GUI任务自动化的移动代理。", "motivation": "当前大多数由大型语言模型支持的移动GUI代理依赖于多步骤查询-操作循环，这导致了高延迟。旨在通过减少对LLM的重复查询来提高效率并降低延迟。", "method": "GraphPilot在离线阶段构建应用特定的知识图谱，在在线阶段使用该知识图谱引导大型语言模型的任务推理过程，并利用HTML表示动态调整推理。", "result": "在DroidTask基准测试中，GraphPilot提高了任务完成率，同时显著减少了延迟和LLM查询次数。", "conclusion": "通过结合知识图谱和单次推理步骤的大型语言模型，GraphPilot实现了更加高效可靠的智能手机GUI任务自动化。"}}
{"id": "2601.17414", "pdf": "https://arxiv.org/pdf/2601.17414", "abs": "https://arxiv.org/abs/2601.17414", "authors": ["Abdul Hasib", "A. S. M. Ahsanul Sarkar Akib"], "title": "Cloud-Enabled IoT System for Real-Time Environmental Monitoring and Remote Device Control Using Firebase", "categories": ["cs.CV"], "comment": null, "summary": "The proliferation of Internet of Things (IoT) devices has created unprecedented opportunities for remote monitoring and control applications across various domains. Traditional monitoring systems often suffer from limitations in real-time data accessibility, remote controllability, and cloud integration. This paper presents a cloud-enabled IoT system that leverages Google's Firebase Realtime Database for synchronized environmental monitoring and device control. The system utilizes an ESP32 microcontroller to interface with a DHT22 temperature/humidity sensor and an HC-SR04 ultrasonic distance sensor, while enabling remote control of two LED indicators through a cloud-based interface. Real-time sensor data is transmitted to Firebase, providing a synchronized platform accessible from multiple devices simultaneously. Experimental results demonstrate reliable data transmission with 99.2\\% success rate, real-time control latency under 1.5 seconds, and persistent data storage for historical analysis. The system architecture offers a scalable framework for various IoT applications, from smart home automation to industrial monitoring, with a total implementation cost of \\$32.50. The integration of Firebase provides robust cloud capabilities without requiring complex server infrastructure, making advanced IoT applications accessible to developers and researchers with limited resources.", "AI": {"tldr": "本文提出了一种基于Google Firebase实时数据库的云增强物联网系统，用于环境监测和远程设备控制。", "motivation": "传统监控系统的实时数据访问、远程可控性和云集成能力有限，因此论文旨在开发一个能够提供可靠实时数据传输、低延迟远程控制和持久化存储的解决方案。", "method": "该系统使用ESP32微控制器与DHT22温湿度传感器和HC-SR04超声波距离传感器接口，并通过基于云端的界面实现两个LED指示灯的远程控制。所有数据实时上传至Firebase，提供可同时从多个设备访问的同步平台。", "result": "实验结果显示数据传输成功率高达99.2%，实时控制延迟低于1.5秒，并支持历史数据分析。系统架构为各种物联网应用提供了可扩展框架，总实施成本仅为32.5美元。", "conclusion": "集成Firebase为开发者和研究者提供强大的云能力，无需复杂的服务器基础设施，使高级物联网应用更易于实现。"}}
{"id": "2601.17412", "pdf": "https://arxiv.org/pdf/2601.17412", "abs": "https://arxiv.org/abs/2601.17412", "authors": ["Valerii Serpiva", "Artem Lykov", "Jeffrin Sam", "Aleksey Fedoseev", "Dzmitry Tsetserukou"], "title": "DiffusionCinema: Text-to-Aerial Cinematography", "categories": ["cs.RO"], "comment": null, "summary": "We propose a novel Unmanned Aerial Vehicles (UAV) assisted creative capture system that leverages diffusion models to interpret high-level natural language prompts and automatically generate optimal flight trajectories for cinematic video recording. Instead of manually piloting the drone, the user simply describes the desired shot (e.g., \"orbit around me slowly from the right and reveal the background waterfall\"). Our system encodes the prompt along with an initial visual snapshot from the onboard camera, and a diffusion model samples plausible spatio-temporal motion plans that satisfy both the scene geometry and shot semantics. The generated flight trajectory is then executed autonomously by the UAV to record smooth, repeatable video clips that match the prompt. User evaluation using NASA-TLX showed a significantly lower overall workload with our interface (M = 21.6) compared to a traditional remote controller (M = 58.1), demonstrating a substantial reduction in perceived effort. Mental demand (M = 11.5 vs. 60.5) and frustration (M = 14.0 vs. 54.5) were also markedly lower for our system, confirming clear usability advantages in autonomous text-driven flight control. This project demonstrates a new interaction paradigm: text-to-cinema flight, where diffusion models act as the \"creative operator\" converting story intentions directly into aerial motion.", "AI": {"tldr": "提出了一种基于无人飞行器的创意拍摄系统，该系统使用扩散模型将高级自然语言提示转化为电影级视频记录的最佳飞行轨迹。", "motivation": "旨在通过自动化的无人机来实现从文本描述到空中摄影的操作，替代传统手动遥控方式，从而降低用户的操作负担和工作强度。", "method": "采用用户提供的高阶自然语言指令与初始视觉快照作为输入，利用扩散模型生成满足场景几何结构和镜头语义的时空运动计划。这些飞行轨迹随后由无人机自主执行以录制视频。", "result": "通过NASA-TLX评估显示，使用该系统（平均分21.6）相比传统遥控方式（平均分58.1），用户整体工作负担显著降低，并且在心理需求和挫败感上也有明显改善。", "conclusion": "展示了从文本到电影飞行的新交互范式，在自主文字驱动的飞行控制中显示了明确的易用性优势，其中扩散模型充当将故事意图直接转化为空中运动的“创意操作者”角色。"}}
{"id": "2601.17408", "pdf": "https://arxiv.org/pdf/2601.17408", "abs": "https://arxiv.org/abs/2601.17408", "authors": ["Harsharaj Pathak", "Vineeth N Balasubramanian"], "title": "Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity", "categories": ["cs.CV"], "comment": null, "summary": "Source-Free Domain Adaptation (SFDA) is an emerging area of research that aims to adapt a model trained on a labeled source domain to an unlabeled target domain without accessing the source data. Most of the successful methods in this area rely on the concept of neighborhood consistency but are prone to errors due to misleading neighborhood information. In this paper, we explore this approach from the point of view of learning more informative clusters and mitigating the effect of noisy neighbors using a concept called neighborhood signature, and demonstrate that adaptation can be achieved using just a single loss term tailored to optimize the similarity and dissimilarity of predictions of samples in the target domain. In particular, our proposed method outperforms existing methods in the challenging VisDA dataset while also yielding competitive results on other benchmark datasets.", "AI": {"tldr": "本文提出了一种基于优化批次余弦相似性的无源域适应方法，通过学习更有效的聚类和减轻噪声邻居的影响来提升模型在目标域的表现。", "motivation": "现有大多数无源域适应的方法依赖于邻近一致性概念，但容易因误导性邻近信息而出现错误。本文旨在探索如何使用一种称为邻域特征的概念学习更有效的集群并减少噪音邻居的影响。", "method": "提出了一种新的方法通过优化目标域样本预测之间的相似性和差异性来实现无源域适应，仅依赖于单一损失项。", "result": "该方法在具有挑战性的VisDA数据集上优于现有的方法，并且在其他基准数据集上也表现出竞争力。", "conclusion": "本文展示了一种新颖的无源域适应策略，通过优化批次余弦相似性来增强模型性能并减少噪音影响，在多种实验中证明了其有效性。"}}
{"id": "2601.17405", "pdf": "https://arxiv.org/pdf/2601.17405", "abs": "https://arxiv.org/abs/2601.17405", "authors": ["Chunze Yang", "Wenjie Zhao", "Yue Tang", "Junbo Lu", "Jiusong Ge", "Qidong Liu", "Zeyu Gao", "Chen Li"], "title": "HAAF: Hierarchical Adaptation and Alignment of Foundation Models for Few-Shot Pathology Anomaly Detection", "categories": ["cs.CV"], "comment": null, "summary": "Precision pathology relies on detecting fine-grained morphological abnormalities within specific Regions of Interest (ROIs), as these local, texture-rich cues - rather than global slide contexts - drive expert diagnostic reasoning. While Vision-Language (V-L) models promise data efficiency by leveraging semantic priors, adapting them faces a critical Granularity Mismatch, where generic representations fail to resolve such subtle defects. Current adaptation methods often treat modalities as independent streams, failing to ground semantic prompts in ROI-specific visual contexts. To bridge this gap, we propose the Hierarchical Adaptation and Alignment Framework (HAAF). At its core is a novel Cross-Level Scaled Alignment (CLSA) mechanism that enforces a sequential calibration order: visual features first inject context into text prompts to generate content-adaptive descriptors, which then spatially guide the visual encoder to spotlight anomalies. Additionally, a dual-branch inference strategy integrates semantic scores with geometric prototypes to ensure stability in few-shot settings. Experiments on four benchmarks show HAAF significantly outperforms state-of-the-art methods and effectively scales with domain-specific backbones (e.g., CONCH) in low-resource scenarios.", "AI": {"tldr": "本文提出了HAAF框架，用于解决基础模型在病理异常检测中的粒度不匹配问题。", "motivation": "现有方法在处理视觉和语言模态时存在粒度不匹配的问题，无法有效解析细微的缺陷。为了解决这个问题并提高精度，提出了一种新的适应和对齐框架。", "method": "HAAF采用Cross-Level Scaled Alignment (CLSA)机制，通过顺序校准次序将视觉特征注入文本提示以生成内容自适应描述符，并引导视觉编码器突出异常。此外，还采用了双分支推断策略来提高稳定性。", "result": "实验显示，在四个基准测试中，HAAF显著优于现有方法，并且在资源有限的情况下能够有效扩展。", "conclusion": "研究证明了HAAF框架通过引入CLSA机制和双分支推断策略可以有效地解决基础模型中的粒度不匹配问题，并提高了病理异常检测的性能。"}}
{"id": "2601.17404", "pdf": "https://arxiv.org/pdf/2601.17404", "abs": "https://arxiv.org/abs/2601.17404", "authors": ["Anke Fischer-Janzen", "Thomas M. Wendt", "Kristof Van Laerhoven"], "title": "Eye-Tracking-Driven Control in Daily Task Assistance for Assistive Robotic Arms", "categories": ["cs.RO"], "comment": "23 pages, 6 figures, publication in review process", "summary": "Shared control improves Human-Robot Interaction by reducing the user's workload and increasing the robot's autonomy. It allows robots to perform tasks under the user's supervision. Current eye-tracking-driven approaches face several challenges. These include accuracy issues in 3D gaze estimation and difficulty interpreting gaze when differentiating between multiple tasks. We present an eye-tracking-driven control framework, aimed at enabling individuals with severe physical disabilities to perform daily tasks independently. Our system uses task pictograms as fiducial markers combined with a feature matching approach that transmits data of the selected object to accomplish necessary task related measurements with an eye-in-hand configuration. This eye-tracking control does not require knowledge of the user's position in relation to the object. The framework correctly interpreted object and task selection in up to 97.9% of measurements. Issues were found in the evaluation, that were improved and shared as lessons learned. The open-source framework can be adapted to new tasks and objects due to the integration of state-of-the-art object detection models.", "AI": {"tldr": "本文提出了一种基于眼动追踪的控制框架，旨在帮助严重身体残疾的人独立完成日常任务。", "motivation": "当前的眼动追踪方法在三维视线估计和区分多个任务时存在准确性问题，本文希望通过一种新的控制框架来改善这些问题，并提高人机交互的效果。", "method": "该系统使用任务图示作为标志点结合特征匹配方法，将选定对象的数据传输给机器人以完成相关的测量任务，在眼手配置下无需用户了解与物体的具体位置关系。", "result": "实验结果显示，此框架在高达97.9%的测量中正确解释了对象和任务的选择，并分享了改进的方法及经验教训。", "conclusion": "该开源框架通过集成最先进的目标检测模型能够适应新的任务和物体。"}}
{"id": "2601.17399", "pdf": "https://arxiv.org/pdf/2601.17399", "abs": "https://arxiv.org/abs/2601.17399", "authors": ["Rui Fang", "Jian Li", "Wei Chen", "Bin Hu", "Ying-Cong Chen", "Xin Tang", "Liang Diao"], "title": "ReLE: A Scalable System and Structured Benchmark for Diagnosing Capability Anisotropy in Chinese LLMs", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have achieved rapid progress in Chinese language understanding, yet accurately evaluating their capabilities remains challenged by benchmark saturation and prohibitive computational costs. While static leaderboards provide snapshot rankings, they often mask the structural trade-offs between capabilities. In this work, we present ReLE (Robust Efficient Live Evaluation), a scalable system designed to diagnose Capability Anisotropy, the non-uniformity of model performance across domains. Using ReLE, we evaluate 304 models (189 commercial, 115 open-source) across a Domain $\\times$ Capability orthogonal matrix comprising 207,843 samples. We introduce two methodological contributions to address current evaluation pitfalls: (1) A Symbolic-Grounded Hybrid Scoring Mechanism that eliminates embedding-based false positives in reasoning tasks; (2) A Dynamic Variance-Aware Scheduler based on Neyman allocation with noise correction, which reduces compute costs by 70\\% compared to full-pass evaluations while maintaining a ranking correlation of $ρ=0.96$. Our analysis reveals that aggregate rankings are highly sensitive to weighting schemes: models exhibit a Rank Stability Amplitude (RSA) of 11.4 in ReLE versus $\\sim$5.0 in traditional benchmarks, confirming that modern models are highly specialized rather than generally superior. We position ReLE not as a replacement for comprehensive static benchmarks, but as a high-frequency diagnostic monitor for the evolving model landscape.", "AI": {"tldr": "本论文介绍了ReLE系统，一种用于诊断中文大语言模型能力异质性的可扩展系统，并提出了一种结构化基准测试。", "motivation": "尽管大型语言模型在中文理解方面取得了快速进展，但准确评估它们的能力仍然受到基准饱和和计算成本高的挑战。", "method": "ReLE采用了一个域×能力正交矩阵对304个模型进行评估，并引入了符号-基础混合评分机制和动态方差感知调度器来减少计算开销。", "result": "研究揭示了聚合排名对权重方案的高度敏感性，且模型在ReLE中的排名稳定性幅度（RSA）为11.4，远高于传统基准测试的约5.0。", "conclusion": "ReLE被定位为高频诊断监测工具，而不是替代全面静态基准，它有助于识别现代模型的高专业化特性而非普遍优越性。"}}
{"id": "2601.17396", "pdf": "https://arxiv.org/pdf/2601.17396", "abs": "https://arxiv.org/abs/2601.17396", "authors": ["Vashista Nobaub"], "title": "GO-OSC and VASH: Geometry-Aware Representation Learning for Early Degradation Detection in Oscillatory Systems", "categories": ["cs.LG", "cs.AI"], "comment": "21 pages, 5 figures. Includes theoretical analysis, ablation studies, and experiments on synthetic and real vibration datasets. Code available", "summary": "Early-stage degradation in oscillatory systems often manifests as geometric distortions of the dynamics, such as phase jitter, frequency drift, or loss of coherence, long before changes in signal energy are detectable. In this regime, classical energy-based diagnostics and unconstrained learned representations are structurally insensitive, leading to delayed or unstable detection. We introduce GO-OSC, a geometry-aware representation learning framework for oscillatory time series that enforces a canonical and identifiable latent parameterization, enabling stable comparison and aggregation across short, unlabeled windows. Building on this representation, we define a family of invariant linear geometric probes that target degradation-relevant directions in latent space. We provide theoretical results showing that under early phase-only degradation, energy-based statistics have zero first-order detection power, whereas geometric probes achieve strictly positive sensitivity. Our analysis characterizes when and why linear probing fails under non-identifiable representations and shows how canonicalization restores statistical detectability. Experiments on synthetic benchmarks and real vibration datasets validate the theory, demonstrating earlier detection, improved data efficiency, and robustness to operating condition changes.", "AI": {"tldr": "本文提出了一种针对振荡系统的几何感知表示学习框架GO-OSC，用于早期退化检测，并展示了其在合成基准和真实振动数据集上的优越性。", "motivation": "早期阶段的降解在振荡系统中通常表现为动力学中的几何畸变（如相位抖动、频率漂移或失去相干性），这些变化远早于信号能量的变化，使得传统的基于能量的诊断方法对这种变化不敏感，从而导致检测延迟或不稳定。", "method": "提出GO-OSC框架和VASH方法：利用该框架在振荡时间序列中强制执行一个规范且可识别的潜在参数化设置，并在此基础上定义了一组不变性线性几何探测器来针对潜在空间中的降解相关方向进行定位。", "result": "理论结果表明，在早期仅相位退化的条件下，基于能量统计的第一级检测能力为零，而几何探测器实现了严格正灵敏度；实验验证了这些理论，并在合成基准和真实振动数据集上展示了更早的检测时间、更高的数据效率以及对运行条件变化的鲁棒性。", "conclusion": "研究表明通过使用GO-OSC框架及其定义的线性几何探测器，可以实现早期降解的有效检测，提供更好的统计可检测性和鲁棒性，特别是在非识别表示下线性探查失败的情况下。"}}
{"id": "2601.17391", "pdf": "https://arxiv.org/pdf/2601.17391", "abs": "https://arxiv.org/abs/2601.17391", "authors": ["Rui Fan", "Weidong Hao"], "title": "SMV-EAR: Bring Spatiotemporal Multi-View Representation Learning into Efficient Event-Based Action Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Event cameras action recognition (EAR) offers compelling privacy-protecting and efficiency advantages, where temporal motion dynamics is of great importance. Existing spatiotemporal multi-view representation learning (SMVRL) methods for event-based object recognition (EOR) offer promising solutions by projecting H-W-T events along spatial axis H and W, yet are limited by its translation-variant spatial binning representation and naive early concatenation fusion architecture. This paper reexamines the key SMVRL design stages for EAR and propose: (i) a principled spatiotemporal multi-view representation through translation-invariant dense conversion of sparse events, (ii) a dual-branch, dynamic fusion architecture that models sample-wise complementarity between motion features from different views, and (iii) a bio-inspired temporal warping augmentation that mimics speed variability of real-world human actions. On three challenging EAR datasets of HARDVS, DailyDVS-200 and THU-EACT-50-CHL, we show +7.0%, +10.7%, and +10.2% Top-1 accuracy gains over existing SMVRL EOR method with surprising 30.1% reduced parameters and 35.7% lower computations, establishing our framework as a novel and powerful EAR paradigm.", "AI": {"tldr": "本文提出了一种名为SMV-EAR的框架，通过引入时空多视角表示学习技术来提升基于事件相机的动作识别效率和准确性。", "motivation": "现有的基于事件的对象识别方法在处理时间动态特性方面存在局限性，并且其空间分箱表示会随翻译变化而改变，本文旨在解决这些问题并提高动作识别的性能。", "method": "提出了一种通过将稀疏事件转换为平移不变性的密集形式来实现时空多视角表示的方法；设计了双分支和动态融合架构以增强不同视图之间运动特征的互补性；引入生物启发的时间扭曲扩增技术，模拟现实世界中人类动作的速度变化。", "result": "在三个挑战性的基于事件的动作识别数据集上，SMV-EAR框架实现了7.0%、10.7%和10.2%的Top-1准确性提升，并且参数减少了30.1%，计算量降低了35.7%。", "conclusion": "本文提出的方法为高效基于事件的动作识别提供了一种新的强大范式，展示了在减少模型复杂度的同时提高识别性能的能力。"}}
{"id": "2601.17388", "pdf": "https://arxiv.org/pdf/2601.17388", "abs": "https://arxiv.org/abs/2601.17388", "authors": ["Xuan Ding", "Xiu Yan", "Chuanlong Xie", "Yao Zhu"], "title": "ONRW: Optimizing inversion noise for high-quality and robust watermark", "categories": ["cs.CV", "cs.AI"], "comment": "Preprint. Under review", "summary": "Watermarking methods have always been effective means of protecting intellectual property, yet they face significant challenges. Although existing deep learning-based watermarking systems can hide watermarks in images with minimal impact on image quality, they often lack robustness when encountering image corruptions during transmission, which undermines their practical application value. To this end, we propose a high-quality and robust watermark framework based on the diffusion model. Our method first converts the clean image into inversion noise through a null-text optimization process, and after optimizing the inversion noise in the latent space, it produces a high-quality watermarked image through an iterative denoising process of the diffusion model. The iterative denoising process serves as a powerful purification mechanism, ensuring both the visual quality of the watermarked image and enhancing the robustness of the watermark against various corruptions. To prevent the optimizing of inversion noise from distorting the original semantics of the image, we specifically introduced self-attention constraints and pseudo-mask strategies. Extensive experimental results demonstrate the superior performance of our method against various image corruptions. In particular, our method outperforms the stable signature method by an average of 10\\% across 12 different image transformations on COCO datasets. Our codes are available at https://github.com/920927/ONRW.", "AI": {"tldr": "提出一种基于扩散模型的高质量和鲁棒水印框架ONRW，以解决现有深度学习水印方法在图像传输过程中面对图像退化时缺乏稳健性的问题。", "motivation": "现有的深度学习水印方法虽然能在不影响图像质量的情况下隐藏水印，但在遇到图像退化时往往表现不佳，这影响了它们的实际应用价值。", "method": "该框架首先通过空文本优化过程将干净的图像转换为反转噪声，在潜在空间中优化这种反转噪声后，通过扩散模型的迭代去噪过程生成高质量的带水印图像。为了防止优化反转噪声时扭曲原图的语义信息，引入了自注意力约束和伪掩码策略。", "result": "广泛的实验结果表明，该方法在面对各种图像退化情况下的表现优于稳定签名方法，在COCO数据集上的12种不同图像变换中平均高出10%。", "conclusion": "ONRW框架通过扩散模型优化反转噪声以生成高质量和鲁棒的水印图像，并且实验结果验证了其在面对各种图像退化情况下的优越性能。"}}
{"id": "2601.17383", "pdf": "https://arxiv.org/pdf/2601.17383", "abs": "https://arxiv.org/abs/2601.17383", "authors": ["Chen Ling", "Kai Hu", "Hangcheng Liu", "Xingshuo Han", "Tianwei Zhang", "Changhai Ou"], "title": "Physical Prompt Injection Attacks on Large Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Large Vision-Language Models (LVLMs) are increasingly deployed in real-world intelligent systems for perception and reasoning in open physical environments. While LVLMs are known to be vulnerable to prompt injection attacks, existing methods either require access to input channels or depend on knowledge of user queries, assumptions that rarely hold in practical deployments. We propose the first Physical Prompt Injection Attack (PPIA), a black-box, query-agnostic attack that embeds malicious typographic instructions into physical objects perceivable by the LVLM. PPIA requires no access to the model, its inputs, or internal pipeline, and operates solely through visual observation. It combines offline selection of highly recognizable and semantically effective visual prompts with strategic environment-aware placement guided by spatiotemporal attention, ensuring that the injected prompts are both perceivable and influential on model behavior. We evaluate PPIA across 10 state-of-the-art LVLMs in both simulated and real-world settings on tasks including visual question answering, planning, and navigation, PPIA achieves attack success rates up to 98%, with strong robustness under varying physical conditions such as distance, viewpoint, and illumination. Our code is publicly available at https://github.com/2023cghacker/Physical-Prompt-Injection-Attack.", "AI": {"tldr": "本文提出了物理提示注入攻击（PPIA），一种针对大视觉语言模型的黑盒、查询无关的攻击方法，通过在可被模型感知的实际物体中嵌入恶意指令来操控模型行为。", "motivation": "现有的提示注入攻击需要访问输入通道或依赖用户查询的知识，在实际部署中这些假设很少成立。因此本文提出PPIA以弥补现有方法的不足并测试大视觉语言模型的安全性。", "method": "PPIA通过离线选择高度可识别且语义有效的视觉提示，结合空间时间注意力指导环境感知放置策略来实现攻击，不需要访问模型及其输入或内部管道。", "result": "在模拟和现实世界场景中，PPIA对10个最先进大视觉语言模型进行测试，在视觉问题回答、规划和导航任务上取得了高达98%的成功率，并表现出良好的鲁棒性。", "conclusion": "研究表明，物理提示注入攻击可以有效地操控大视觉语言模型的行为，即使在不同的物理条件下也能保持较高的成功率，突显了这些系统潜在的安全风险。"}}
{"id": "2601.17379", "pdf": "https://arxiv.org/pdf/2601.17379", "abs": "https://arxiv.org/abs/2601.17379", "authors": ["Khoi Trinh", "Scott Seidenberger", "Joseph Spracklen", "Raveen Wijewickrama", "Bimal Viswanath", "Murtuza Jadliwala", "Anindya Maiti"], "title": "Prompt and Circumstances: Evaluating the Efficacy of Human Prompt Inference in AI-Generated Art", "categories": ["cs.CR", "cs.AI"], "comment": "To appear in EvoMUSART 2026", "summary": "The emerging field of AI-generated art has witnessed the rise of prompt marketplaces, where creators can purchase, sell, or share prompts to generate unique artworks. These marketplaces often assert ownership over prompts, claiming them as intellectual property. This paper investigates whether concealed prompts sold on prompt marketplaces can be considered bona fide intellectual property, given that humans and AI tools may be able to infer the prompts based on publicly advertised sample images accompanying each prompt on sale. Specifically, our study aims to assess (i) how accurately humans can infer the original prompt solely by examining an AI-generated image, with the goal of generating images similar to the original image, and (ii) the possibility of improving upon individual human and AI prompt inferences by crafting combined human and AI prompts with the help of a large language model. Although previous research has explored AI-driven prompt inference and protection strategies, our work is the first to incorporate a human subject study and examine collaborative human-AI prompt inference in depth. Our findings indicate that while prompts inferred by humans and prompts inferred through a combined human and AI effort can generate images with a moderate level of similarity, they are not as successful as using the original prompt. Moreover, combining human- and AI-inferred prompts using our suggested merging techniques did not improve performance over purely human-inferred prompts.", "AI": {"tldr": "评估人类提示推断在AI生成艺术中的有效性，特别是隐藏的提示是否可被视为知识产权。", "motivation": "随着AI生成艺术品市场的兴起，探讨出售的隐藏提示能否作为知识产权，并评估基于公共样本图像的人类和AI工具推测原始提示的能力。", "method": "通过研究人类仅凭AI生成图像推断原始提示的准确性以及结合大型语言模型改进人类和AI提示推断的可能性。", "result": "发现无论是人类还是结合人类与AI推断出的提示，其成功率均低于使用原始提示，并且合并的人类与AI推测的提示并未超过纯粹由人推测的效果。", "conclusion": "虽然人类和AI合作可以生成具有中等相似度的艺术品，但它们并不能完全替代原始提示的作用，表明出售的隐藏提示作为知识产权的有效性存在质疑。"}}
{"id": "2601.17378", "pdf": "https://arxiv.org/pdf/2601.17378", "abs": "https://arxiv.org/abs/2601.17378", "authors": ["Mohammad Zare", "Pirooz Shamsinejadbabaki"], "title": "Res-MIA: A Training-Free Resolution-Based Membership Inference Attack on Federated Learning Models", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Membership inference attacks (MIAs) pose a serious threat to the privacy of machine learning models by allowing adversaries to determine whether a specific data sample was included in the training set. Although federated learning (FL) is widely regarded as a privacy-aware training paradigm due to its decentralized nature, recent evidence shows that the final global model can still leak sensitive membership information through black-box access. In this paper, we introduce Res-MIA, a novel training-free and black-box membership inference attack that exploits the sensitivity of deep models to high-frequency input details. Res-MIA progressively degrades the input resolution using controlled downsampling and restoration operations, and analyzes the resulting confidence decay in the model's predictions. Our key insight is that training samples exhibit a significantly steeper confidence decline under resolution erosion compared to non-member samples, revealing a robust membership signal. Res-MIA requires no shadow models, no auxiliary data, and only a limited number of forward queries to the target model. We evaluate the proposed attack on a federated ResNet-18 trained on CIFAR-10, where it consistently outperforms existing training-free baselines and achieves an AUC of up to 0.88 with minimal computational overhead. These findings highlight frequency-sensitive overfitting as an important and previously underexplored source of privacy leakage in federated learning, and emphasize the need for privacy-aware model designs that reduce reliance on fine-grained, non-robust input features.", "AI": {"tldr": "本文介绍了Res-MIA，一种无训练需求的黑盒成员推理攻击方法，通过输入分辨率降解来判断样本是否为模型训练集的一部分。", "motivation": "鉴于联邦学习虽被视作隐私保护技术，但其最终全局模型仍可能泄露敏感信息，文章旨在提出新的黑盒成员推理攻击方式以揭示并防范此安全威胁。", "method": "Res-MIA采用逐步降低输入分辨率的方法，并分析模型预测信心的下降程度。发现训练样本在分辨率侵蚀下比非成员样本有更显著的信心衰减。", "result": "实验结果显示，Res-MIA在联邦学习中针对CIFAR-10数据集上的ResNet-18模型上表现优异，AUC高达0.88，并且计算开销低。", "conclusion": "研究结果表明频率敏感过度拟合是联邦学习中隐私泄露的一个重要来源，需要设计减少对细粒度、非鲁棒输入特征依赖的隐私保护模型。"}}
{"id": "2601.17376", "pdf": "https://arxiv.org/pdf/2601.17376", "abs": "https://arxiv.org/abs/2601.17376", "authors": ["Ruijin Hua", "Zichuan Liu", "Kun Zhang", "Yiyuan Yang"], "title": "Diversified Scaling Inference in Time Series Foundation Models", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages, 16 figures, 9 tables", "summary": "The advancement of Time Series Foundation Models (TSFMs) has been driven primarily by large-scale pre-training, but inference-time compute potential remains largely untapped. This work systematically investigates two questions: how do TSFMs behave under standard sampling-based inference scaling, and can controlled sampling diversity enhance performance? We first examine the properties of TSFMs under standard sampling often fail to adhere to scaling laws due to insufficient exploration of the solution space. Building on this, we then delve into diversified inference scaling via tailored time series perturbations to expand the generative distribution's support. We theoretically analyze the diversity-fidelity trade-off and derive a critical sample threshold for diversified sampling to outperform standard sampling. Extensive experiments across various TSFMs and datasets show proper diversified inference scaling yields substantial performance gains without parameter updates, establishing inference design as a critical, compute-efficient dimension of TSFM optimization. As an application, we propose RobustMSE, a rigorous metric to quantify the headroom performance of TSFM under a fixed budget. Overall, our findings clarify these factor interactions, enabling reliable performance via diverse large-scale inference time series in parallel environments without re-training TSFMs.", "AI": {"tldr": "本文研究了时间序列基础模型（TSFMs）在标准采样推理扩展下的行为，并探讨了通过多样化采样增强性能的可能性。", "motivation": "尽管大规模预训练推动了时间序列基础模型的发展，但推理时的计算潜力尚未充分发挥。作者希望通过改进推理设计以提高TSFM的性能并减少参数更新的需求。", "method": "研究了TSFMs在标准采样下的性质，并通过定制的时间序列扰动来进行多样化推理扩展，分析了多样性与保真度之间的权衡，推导出多样化抽样的临界样本阈值。", "result": "实验表明适当的多样化推理扩展可以在不更新参数的情况下显著提高性能，提出了RobustMSE来量化固定预算下的TSFM性能潜力。", "conclusion": "研究阐明了这些因素的相互作用关系，并证明通过大规模多样化并行环境中的推理设计可以实现可靠的TSFM性能提升。"}}
{"id": "2601.17373", "pdf": "https://arxiv.org/pdf/2601.17373", "abs": "https://arxiv.org/abs/2601.17373", "authors": ["Shuning Zhang", "Shixuan Li", "Haobin Xing", "Jiarui Liu", "Yan Kong", "Xin Yi", "Hewu Li"], "title": "\"Privacy across the boundary\": Examining Perceived Privacy Risk Across Data Transmission and Sharing Ranges of Smart Home Personal Assistants", "categories": ["cs.HC"], "comment": "To be published in CHI'26: 10.1145/3772318.3790455", "summary": "As Smart Home Personal Assistants (SPAs) evolve into social agents, understanding user privacy necessitates interpersonal communication frameworks, such as Privacy Boundary Theory (PBT). To ground our investigation, our three-phase preliminary study (1) identified transmission and sharing ranges as key boundary-related risk factors, (2) categorized relevant SPA functions and data types, and (3) analyzed commercial practices, revealing widespread data sharing and non-transparent safeguards. A subsequent mixed-methods study (N=412 survey, N=40 interviews among the survey participants) assessed users' perceived privacy risks across data types, transmission ranges and sharing ranges. Results demonstrate a significant, non-linear escalation in perceived risk when data crosses two critical boundaries: the `public network' (transmission) and `third parties' (sharing). This boundary effect holds robustly across data types and demographics. Furthermore, risk perception is modulated by data attributes (e.g., social relational data), and contextual privacy calculus. Conversely, anonymization safeguards show limited efficacy especially for third-party sharing, a finding attributed to user distrust. These findings empirically ground PBT in the SPA context and inform design of boundary-aware privacy protection.", "AI": {"tldr": "本文研究了智能家庭个人助手（SPAs）在数据传输和共享过程中用户感知的隐私风险。", "motivation": "随着SPAs演变为社交代理，理解用户的隐私需求需要人际沟通框架。文章旨在通过调查确定关键的风险因素，并评估用户对不同种类、传输范围及分享范围下的数据所感受到的隐私风险。", "method": "研究分为三个阶段：识别关键风险因素，分类SPA功能和数据类型，分析商业实践；后续使用混合方法（N=412份问卷和从参与调查者中选出的N=40个访谈）来评估用户的感知隐私风险。", "result": "研究表明，在数据跨过两个重要边界——公共网络传输和第三方共享时，用户感知到的风险显著非线性上升。此外，数据属性（如社会关系数据）以及情境中的隐私计算影响了风险感知；匿名保护措施在第三方分享情况下效果有限。", "conclusion": "研究结果为SPAs环境下的隐私边界理论提供了实证支持，并为设计感知边界的隐私保护机制提供指导。"}}
{"id": "2601.17371", "pdf": "https://arxiv.org/pdf/2601.17371", "abs": "https://arxiv.org/abs/2601.17371", "authors": ["Shuning Zhang", "Linzhi Wang", "Shixuan Li", "Yuanyuan Wu", "Yuwei Chuai", "Luoxi Chen", "Xin Yi", "Hewu Li"], "title": "Collab: Fostering Critical Identification of Deepfake Videos on Social Media via Synergistic Annotation", "categories": ["cs.HC"], "comment": "To be published in CHI'26: 10.1145/3772318.3790501", "summary": "Identifying deepfake videos on social media platforms is challenged by dynamic spatio-temporal artifacts and inadequate user tools. This hinders both critical viewing by users and scalable moderation on platforms. Here, we present Collab, a web plugin enabling users to collaboratively annotate deepfake videos. Collab integrates three key components: (i) an intuitive interface for spatio-temporal labeling where users provide confidence scores and rationales, facilitating detailed input even from non-experts, (ii) a novel confidence-weighted spatio-temporal Intersection-over-Union (IoU) algorithm to aggregate diverse user annotations into accurate aggregations, and (iii) a hierarchical demonstration strategy presenting aggregated results to guide attention toward contentious regions and foster critical evaluation. A seven-day online study (N=90), where participants annotated suspicious videos when viewing an online experimental platforms, compared Collab against two conditions without aggregation or demonstration respectively. Collab significantly improved identification accuracy and enhanced reflection compared to non-demonstration condition, while outperforming non-aggregation condition for its novelty and effectiveness.", "AI": {"tldr": "本文介绍了一款名为Collab的网络插件，通过协同标注来帮助用户识别社交媒体上的深度伪造视频。", "motivation": "社交媒体平台上的深度伪造视频因动态时空伪影和缺乏用户工具而难以识别，这妨碍了用户的批判性观看和平台的大规模监管。因此，提出了一个解决这个问题的方法。", "method": "Collab插件集成了三个关键组件：直观的时空标注界面、信心加权的时空交并比算法用于聚合注释以及分层演示策略来引导注意力。", "result": "七天在线研究显示，与没有聚合或展示条件相比，Collab显著提高了识别准确性和反思能力。", "conclusion": "Collab通过协同和创新的方法成功地增强了用户对深度伪造视频的鉴别能力。"}}
{"id": "2601.17368", "pdf": "https://arxiv.org/pdf/2601.17368", "abs": "https://arxiv.org/abs/2601.17368", "authors": ["Shuning Zhang", "Eve He", "Sixing Tao", "Yuting Yang", "Ying Ma", "Ailei Wang", "Xin Yi", "Hewu Li"], "title": "A Scoping Review and Guidelines on Privacy Policy's Visualization from an HCI Perspective", "categories": ["cs.HC"], "comment": "Accepted by CHI'26: 10.1145/3772318.3790320", "summary": "Privacy Policies are a cornerstone of informed consent, yet a persistent gap exists between their legal intent and practical efficacy. Despite decades of Human-Computer Interaction (HCI) research proposing various visualizations, user comprehension remains low, and designs rarely see widespread adoption. To understand this landscape and chart a path forward, we synthesized 65 top-tier papers using a framework adapted from the user-centered design lifecycle. Our analysis presented findings of the field's evolution across four dimensions: (1) the trade-off between information load and decision efficacy, which demonstrates a shift from augmenting disclosures to prioritizing information condensation and cognitive load management to counter the inefficacy of comprehensive texts, (2) the co-evolutionary dynamic of design and automation, revealing that complex design ambitions such as context-awareness drove the need for advanced NLP, while recent LLM breakthroughs are enabling the semantic interpretation required to realize those designs, (3) the tension between generality and specificity, highlighting the divergence between standardized, cross-platform solutions and the increasing necessity for specialized, context-aware interaction patterns in IoT and immersive environments, and (4) balancing stakeholder opinions, which shows that visualization efficacy is constrained by the complex interplay of regulatory mandates, developer capabilities and provider incentives. We conclude by outlining four critical challenges for future research.", "AI": {"tldr": "本文通过综合65篇顶级论文，从人机交互的角度审视隐私政策的可视化，并提出了四个维度上的发现和未来研究的关键挑战。", "motivation": "尽管HCI领域已提出多种可视化方法来提高用户对隐私政策的理解，但用户理解仍然较低，且这些设计很少被广泛采用。本文旨在分析现状并为未来发展提供指南。", "method": "通过使用一个基于以用户为中心的设计生命周期的框架，综合65篇顶级论文，从四个维度进行了分析。", "result": "研究发现隐私政策可视化领域在信息负载与决策效率、设计理念和自动化技术的发展、一般性和特定性设计之间的张力以及利益相关者意见平衡上存在挑战。", "conclusion": "本文总结了未来研究的四大关键挑战。"}}
{"id": "2601.17367", "pdf": "https://arxiv.org/pdf/2601.17367", "abs": "https://arxiv.org/abs/2601.17367", "authors": ["Zecheng Tang", "Quantong Qiu", "Yi Yang", "Zhiyi Hong", "Haiya Xiang", "Kebin Liu", "Qingqing Dang", "Juntao Li", "Min Zhang"], "title": "Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The quadratic complexity of standard attention mechanisms poses a significant scalability bottleneck for large language models (LLMs) in long-context scenarios. While hybrid attention strategies that combine sparse and full attention within a single model offer a viable solution, they typically employ static computation ratios (i.e., fixed proportions of sparse versus full attention) and fail to adapt to the varying sparsity sensitivities of downstream tasks during inference. To address this issue, we propose Elastic Attention, which allows the model to dynamically adjust its overall sparsity based on the input. This is achieved by integrating a lightweight Attention Router into the existing pretrained model, which dynamically assigns each attention head to different computation modes. Within only 12 hours of training on 8xA800 GPUs, our method enables models to achieve both strong performance and efficient inference. Experiments across three long-context benchmarks on widely-used LLMs demonstrate the superiority of our method.", "AI": {"tldr": "本文提出了一种名为Elastic Attention的方法，使模型能够根据输入动态调整其整体稀疏度，从而在长上下文场景中实现高效推理。", "motivation": "传统的注意力机制具有二次复杂性，导致大型语言模型（LLMs）在长上下文场景下的可扩展性瓶颈。现有的混合注意策略虽然结合了稀疏和全注意力，但无法适应下游任务的变异性。", "method": "通过将一个轻量级的Attention Router集成到预训练模型中，允许每个注意力头动态分配不同的计算模式以实现动态调整整体稀疏度。", "result": "在8xA800 GPU上仅用12小时的训练时间后，该方法使模型实现了强大的性能和高效的推理，并且在三个长上下文基准测试中的实验结果表明了这种方法的优势。", "conclusion": "Elastic Attention能够有效解决传统注意力机制存在的可扩展性问题，在保持高性能的同时显著提高了长上下文场景下的推理效率。"}}
{"id": "2601.17366", "pdf": "https://arxiv.org/pdf/2601.17366", "abs": "https://arxiv.org/abs/2601.17366", "authors": ["Chengbo Ding", "Fenghe Tang", "Shaohua Kevin Zhou"], "title": "UCAD: Uncertainty-guided Contour-aware Displacement for semi-supervised medical image segmentation", "categories": ["cs.CV"], "comment": "Accepted by ISBI 2026", "summary": "Existing displacement strategies in semi-supervised segmentation only operate on rectangular regions, ignoring anatomical structures and resulting in boundary distortions and semantic inconsistency. To address these issues, we propose UCAD, an Uncertainty-Guided Contour-Aware Displacement framework for semi-supervised medical image segmentation that preserves contour-aware semantics while enhancing consistency learning. Our UCAD leverages superpixels to generate anatomically coherent regions aligned with anatomy boundaries, and an uncertainty-guided selection mechanism to selectively displace challenging regions for better consistency learning. We further propose a dynamic uncertainty-weighted consistency loss, which adaptively stabilizes training and effectively regularizes the model on unlabeled regions. Extensive experiments demonstrate that UCAD consistently outperforms state-of-the-art semi-supervised segmentation methods, achieving superior segmentation accuracy under limited annotation. The code is available at:https://github.com/dcb937/UCAD.", "AI": {"tldr": "本文提出了一种基于不确定性指导的轮廓感知位移框架UCAD，用于半监督医学图像分割。", "motivation": "现有的位移策略仅在矩形区域操作，忽略了解剖结构，导致边界扭曲和语义不一致。为了改善这些问题并提高半监督医学图像分割的准确性，提出了该方法。", "method": "UCAD利用超像素生成与解剖边界对齐的解剖一致性区域，并采用不确定性指导的选择机制以选择性地位移具有挑战性的区域来改进一致性学习。此外，还提出了一种动态不确定权重的一致性损失函数，自适应地稳定训练并有效规范模型。", "result": "实验结果表明UCAD在有限注释下实现了优于现有半监督分割方法的优越分割准确性。", "conclusion": "研究证明了不确定性指导的轮廓感知位移框架在提高半监督医学图像分割性能方面的有效性。"}}
{"id": "2601.17364", "pdf": "https://arxiv.org/pdf/2601.17364", "abs": "https://arxiv.org/abs/2601.17364", "authors": ["Mohammed Fasha", "Bassam Hammo", "Bilal Sowan", "Husam Barham", "Esam Nsour"], "title": "Parameter Efficient Fine Tuning Llama 3.1 for Answering Arabic Legal Questions: A Case Study on Jordanian Laws", "categories": ["cs.CL", "cs.AI"], "comment": "5 pages, resources at: https://github.com/msfasha/Research-Resources/tree/main/ArabicLegalLLM", "summary": "This study uses Jordanian law as a case study to explore the fine-tuning of the Llama-3.1 large language model for Arabic question-answering. Two versions of the model - Llama-3.1-8B-bnb-4bit and Llama-3.1-8B-Instruct-bnb-4bit - were fine-tuned using parameter-efficient fine-tuning (PEFT) with LoRA adapters and 4-bit quantized models, leveraging the Unsloth framework for accelerated and resource-efficient training. A custom dataset of 6000 legal question-answer pairs was curated from Jordanian laws and formatted into structured prompts. Performance was evaluated using the BLEU and the ROUGE metrics to compare the fine-tuned models to their respective base versions. Results demonstrated improved legal reasoning and accuracy while achieving resource efficiency through quantization and optimized fine-tuning strategies. This work underscores the potential of adapting large language models for Arabic legal domains and highlights effective techniques for fine-tuning domain-specific tasks.", "AI": {"tldr": "该研究使用约旦法律作为案例，探索了Llama-3.1大型语言模型在阿拉伯语问答任务中的微调。", "motivation": "动机是探讨如何通过参数高效的微调策略提高大语言模型处理特定领域（如阿拉伯语法律文本）的能力，并实现资源效率。", "method": "研究使用LoRA适配器和4位量化模型对Llama-3.1进行了参数高效微调，同时利用Unsloth框架加速训练过程。创建了包含6000个约旦法问答对的定制数据集并格式化为结构化提示。", "result": "性能评估使用BLEU和ROUGE指标显示，经过微调后的模型在法律推理准确性和资源效率方面优于原始基线版本。", "conclusion": "研究强调了大型语言模型适应阿拉伯语法律领域的能力，并展示了有效的特定任务微调技术。"}}
{"id": "2601.17363", "pdf": "https://arxiv.org/pdf/2601.17363", "abs": "https://arxiv.org/abs/2601.17363", "authors": ["Michael Farrell"], "title": "Do readers prefer AI-generated Italian short stories?", "categories": ["cs.CL", "cs.AI"], "comment": "7 pages", "summary": "This study investigates whether readers prefer AI-generated short stories in Italian over one written by a renowned Italian author. In a blind setup, 20 participants read and evaluated three stories, two created with ChatGPT-4o and one by Alberto Moravia, without being informed of their origin. To explore potential influencing factors, reading habits and demographic data, comprising age, gender, education and first language, were also collected. The results showed that the AI-written texts received slightly higher average ratings and were more frequently preferred, although differences were modest. No statistically significant associations were found between text preference and demographic or reading-habit variables. These findings challenge assumptions about reader preference for human-authored fiction and raise questions about the necessity of synthetic-text editing in literary contexts.", "AI": {"tldr": "该研究调查了读者是否更喜欢用AI生成的意大利短篇小说，而不是由著名意大利作家创作的小说。", "motivation": "作者希望通过这项研究挑战关于读者偏好人类写作风俗的假设，并探讨在文学领域合成文本编辑的必要性。", "method": "通过盲测方法，20位参与者评估了三个故事（两个由ChatGPT-4o生成，一个由Alberto Moravia创作），同时收集了参与者的阅读习惯和人口统计学数据。", "result": "研究结果显示AI生成的故事平均评分稍高且更受青睐，但这些差异较小，并未发现文本偏好与参与者的人口统计数据或阅读习惯之间有显著关联。", "conclusion": "该研究挑战了关于读者对人类写作风俗的偏好假设，并提出了在文学环境中合成文本编辑必要性的疑问。"}}
{"id": "2601.17360", "pdf": "https://arxiv.org/pdf/2601.17360", "abs": "https://arxiv.org/abs/2601.17360", "authors": ["Jiankai Jin", "Xiangzheng Zhang", "Zhao Liu", "Deyue Zhang", "Quanchen Zou"], "title": "Robust Privacy: Inference-Time Privacy through Certified Robustness", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Machine learning systems can produce personalized outputs that allow an adversary to infer sensitive input attributes at inference time. We introduce Robust Privacy (RP), an inference-time privacy notion inspired by certified robustness: if a model's prediction is provably invariant within a radius-$R$ neighborhood around an input $x$ (e.g., under the $\\ell_2$ norm), then $x$ enjoys $R$-Robust Privacy, i.e., observing the prediction cannot distinguish $x$ from any input within distance $R$ of $x$. We further develop Attribute Privacy Enhancement (APE) to translate input-level invariance into an attribute-level privacy effect. In a controlled recommendation task where the decision depends primarily on a sensitive attribute, we show that RP expands the set of sensitive-attribute values compatible with a positive recommendation, expanding the inference interval accordingly. Finally, we empirically demonstrate that RP also mitigates model inversion attacks (MIAs) by masking fine-grained input-output dependence. Even at small noise levels ($σ=0.1$), RP reduces the attack success rate (ASR) from 73% to 4% with partial model performance degradation. RP can also partially mitigate MIAs (e.g., ASR drops to 44%) with no model performance degradation.", "AI": {"tldr": "本文介绍了Robust Privacy（RP）概念，通过认证鲁棒性确保推理时的隐私保护，并开发了Attribute Privacy Enhancement（APE），展示其在推荐任务和模型反转攻击中的效果。", "motivation": "机器学习系统可以生成个性化输出，允许对手在推理阶段推断敏感输入属性。因此，提出一种新的隐私保护方法以防止此类信息泄露。", "method": "通过认证鲁棒性引入Robust Privacy（RP）概念，并开发Attribute Privacy Enhancement（APE），将输入级不变性转化为属性级隐私效应，在推荐任务中进行了验证。", "result": "在受控推荐任务和模型反转攻击实验中，RP显著降低了攻击成功率，即使在小噪声水平下也能有效保护隐私，同时保持了模型性能。", "conclusion": "通过鲁棒隐私（RP），可以有效地防止敏感信息泄露，并且可以在不牺牲模型性能的情况下减少模型反转攻击的成功率。"}}
{"id": "2601.17357", "pdf": "https://arxiv.org/pdf/2601.17357", "abs": "https://arxiv.org/abs/2601.17357", "authors": ["Davide Ettori"], "title": "Spectral Geometry for Deep Learning: Compression and Hallucination Detection via Random Matrix Theory", "categories": ["cs.LG", "cs.AI"], "comment": "Master thesis, MS in Computer Science, University of Illinois Chicago, defended November 21, 2025", "summary": "Large language models and deep neural networks achieve strong performance but suffer from reliability issues and high computational cost. This thesis proposes a unified framework based on spectral geometry and random matrix theory to address both problems by analyzing the eigenvalue structure of hidden activations. The first contribution, EigenTrack, is a real-time method for detecting hallucinations and out-of-distribution behavior in language and vision-language models using spectral features and their temporal dynamics. The second contribution, RMT-KD, is a principled compression method that identifies informative spectral components and applies iterative knowledge distillation to produce compact and efficient models while preserving accuracy. Together, these results show that spectral statistics provide interpretable and robust signals for monitoring uncertainty and guiding compression in large-scale neural networks.", "AI": {"tldr": "本文提出了一种基于谱几何和随机矩阵理论的统一框架，用于解决大型语言模型和深度神经网络中的可靠性问题及高计算成本。", "motivation": "大型语言模型和深度神经网络虽然性能强大，但存在可靠性和高计算成本的问题。本研究旨在通过分析隐藏激活的特征值结构来解决这些问题。", "method": "该论文提出两种方法：EigenTrack，用于实时检测幻觉和分布外行为；RMT-KD，一种基于识别信息谱成分并应用迭代知识蒸馏进行压缩的方法。", "result": "结果表明，这两种方法能够有效地提供解释性和鲁棒的信号来监测不确定性并指导大型神经网络的压缩。", "conclusion": "研究结论是，通过使用光谱统计方法可以提高模型的可靠性和效率，并在实时检测幻觉行为和有效压缩模型方面取得显著效果。"}}
{"id": "2601.17354", "pdf": "https://arxiv.org/pdf/2601.17354", "abs": "https://arxiv.org/abs/2601.17354", "authors": ["Wenzhi Guo", "Guangchi Fang", "Shu Yang", "Bing Wang"], "title": "PocketGS: On-Device Training of 3D Gaussian Splatting for High Perceptual Modeling", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "Efficient and high-fidelity 3D scene modeling is a long-standing pursuit in computer graphics. While recent 3D Gaussian Splatting (3DGS) methods achieve impressive real-time modeling performance, they rely on resource-unconstrained training assumptions that fail on mobile devices, which are limited by minute-scale training budgets and hardware-available peak-memory. We present PocketGS, a mobile scene modeling paradigm that enables on-device 3DGS training under these tightly coupled constraints while preserving high perceptual fidelity. Our method resolves the fundamental contradictions of standard 3DGS through three co-designed operators: G builds geometry-faithful point-cloud priors; I injects local surface statistics to seed anisotropic Gaussians, thereby reducing early conditioning gaps; and T unrolls alpha compositing with cached intermediates and index-mapped gradient scattering for stable mobile backpropagation. Collectively, these operators satisfy the competing requirements of training efficiency, memory compactness, and modeling fidelity. Extensive experiments demonstrate that PocketGS is able to outperform the powerful mainstream workstation 3DGS baseline to deliver high-quality reconstructions, enabling a fully on-device, practical capture-to-rendering workflow.", "AI": {"tldr": "本文介绍了PocketGS，一种在移动设备上进行高效且高保真的三维场景建模的方法。", "motivation": "传统的3D Gaussian Splatting方法依赖于无资源限制的训练假设，在计算和内存受限的移动设备上无法实现高效训练。因此，开发一种能够在移动设备上运行并保持高感知精度的方法成为必要。", "method": "PocketGS通过三个协同设计的操作符来解决传统3DGS中的矛盾：G构建几何忠实点云先验；I注入局部表面统计以初始化各向异性高斯分布从而减少早期条件差距；T展开带有缓存中间结果和索引映射梯度散射的alpha混合，实现稳定的移动反向传播。", "result": "实验表明，PocketGS能够超越强大的主流工作站3DGS基准，提供高质量的重建，并支持从捕获到渲染的一体化工作流程。", "conclusion": "PocketGS证明了在资源受限的移动设备上进行高效且高保真的三维场景建模是可行的，实现了计算效率、内存紧凑性和模型精度之间的平衡。"}}
{"id": "2601.17352", "pdf": "https://arxiv.org/pdf/2601.17352", "abs": "https://arxiv.org/abs/2601.17352", "authors": ["M. L. Mamud", "Piyoosh Jaysaval", "Frederick D Day-Lewis", "M. K. Mudunuru"], "title": "HyDeMiC: A Deep Learning-based Mineral Classifier using Hyperspectral Data", "categories": ["cs.CV"], "comment": null, "summary": "Hyperspectral imaging (HSI) has emerged as a powerful remote sensing tool for mineral exploration, capitalizing on unique spectral signatures of minerals. However, traditional classification methods such as discriminant analysis, logistic regression, and support vector machines often struggle with environmental noise in data, sensor limitations, and the computational complexity of analyzing high-dimensional HSI data. This study presents HyDeMiC (Hyperspectral Deep Learning-based Mineral Classifier), a convolutional neural network (CNN) model designed for robust mineral classification under noisy data. To train HyDeMiC, laboratory-measured hyperspectral data for 115 minerals spanning various mineral groups were used from the United States Geological Survey (USGS) library. The training dataset was generated by convolving reference mineral spectra with an HSI sensor response function. These datasets contained three copper-bearing minerals, Cuprite, Malachite, and Chalcopyrite, used as case studies for performance demonstration. The trained CNN model was evaluated on several synthetic 2D hyperspectral datasets with noise levels of 1%, 2%, 5%, and 10%. Our noisy data analysis aims to replicate realistic field conditions. The HyDeMiC's performance was assessed using the Matthews Correlation Coefficient (MCC), providing a comprehensive measure across different noise regimes. Results demonstrate that HyDeMiC achieved near-perfect classification accuracy (MCC = 1.00) on clean and low-noise datasets and maintained strong performance under moderate noise conditions. These findings emphasize HyDeMiC's robustness in the presence of moderate noise, highlighting its potential for real-world applications in hyperspectral imaging, where noise is often a significant challenge.", "AI": {"tldr": "本文介绍了HyDeMiC，一种基于深度学习的矿物分类器，利用高光谱数据进行矿产勘探。", "motivation": "传统的矿物分类方法在处理环境噪声和高维度数据时存在困难，因此需要一个更为强大且鲁棒的方法来提高分类性能。", "method": "使用卷积神经网络(CNN)模型HyDeMiC进行训练，并采用来自USGS图书馆的115种矿物质的数据。通过将参考矿物光谱与HSI传感器响应函数结合生成训练数据集，用于评估在不同噪声水平下的表现。", "result": "结果表明，在低噪声和中度噪音条件下，HyDeMiC实现了几乎完美的分类准确性（MCC = 1.00），证明其在实际应用场景中的潜力。", "conclusion": "结论强调了HyDeMiC在存在环境噪音情况下的鲁棒性，并指出它适用于现实世界的高光谱成像应用。"}}
{"id": "2601.17351", "pdf": "https://arxiv.org/pdf/2601.17351", "abs": "https://arxiv.org/abs/2601.17351", "authors": ["Nadja Rupprechter", "Tobias Dienlin", "Tilo Hartmann"], "title": "AI-RP: The AI Relationship Process Framework", "categories": ["cs.HC"], "comment": null, "summary": "For a growing number of people, AI chatbots have become close personal companions. Despite rising scholarly attention, theoretical accounts of how such relationships develop remain fragmented. Existing frameworks address important aspects of the phenomenon, but they rarely treat human-chatbot communication as the central behavior that builds relationships. To address this gap, we propose the AI relationship process (AI-RP) framework. The AI-RP outlines relationship formation as a sequential process. (a) Chatbot characteristics shape users' (b) social perceptions. These perceptions guide (c) communication, and communication produces (d) relational outcomes such as attachment and companionship. The AI-RP introduces a six-features profile characterizing chatbots, a dual-route approach of social perception, a behavioral conceptualization of communication and discusses the foundation and types of artificial relationships. By foregrounding observable communicative behavior, the AI-RP provides a foundation for theory building and empirical research on the social and ethical implications of AI companionship.", "AI": {"tldr": "本文提出了AI-RP框架，以系统地描述人与聊天机器人关系发展的过程。", "motivation": "由于现有理论未能充分关注人类和聊天机器人沟通在建立关系中的核心作用，因此有必要提出一个更全面的框架来解释这种关系的发展。", "method": "通过定义六个特征的聊天机器人配置文件、双重途径的社会感知方法以及沟通的行为概念化，并探讨了人工智能伴侣关系的基础与类型。", "result": "AI-RP框架为理论构建和实证研究提供了基础，特别是关于人工智能陪伴的社会和伦理影响方面。", "conclusion": "该框架强调了观察到的沟通行为在理解和分析人类与聊天机器人关系中的重要性。"}}
{"id": "2601.17350", "pdf": "https://arxiv.org/pdf/2601.17350", "abs": "https://arxiv.org/abs/2601.17350", "authors": ["Xianliang Huang", "Zhizhou Zhong", "Shuhang Chen", "Yi Xu", "Juhong Guan", "Shuigeng Zhou"], "title": "NeRF-MIR: Towards High-Quality Restoration of Masked Images with Neural Radiance Fields", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages, 15 figures", "summary": "Neural Radiance Fields (NeRF) have demonstrated remarkable performance in novel view synthesis. However, there is much improvement room on restoring 3D scenes based on NeRF from corrupted images, which are common in natural scene captures and can significantly impact the effectiveness of NeRF. This paper introduces NeRF-MIR, a novel neural rendering approach specifically proposed for the restoration of masked images, demonstrating the potential of NeRF in this domain. Recognizing that randomly emitting rays to pixels in NeRF may not effectively learn intricate image textures, we propose a \\textbf{P}atch-based \\textbf{E}ntropy for \\textbf{R}ay \\textbf{E}mitting (\\textbf{PERE}) strategy to distribute emitted rays properly. This enables NeRF-MIR to fuse comprehensive information from images of different views. Additionally, we introduce a \\textbf{P}rogressively \\textbf{I}terative \\textbf{RE}storation (\\textbf{PIRE}) mechanism to restore the masked regions in a self-training process. Furthermore, we design a dynamically-weighted loss function that automatically recalibrates the loss weights for masked regions. As existing datasets do not support NeRF-based masked image restoration, we construct three masked datasets to simulate corrupted scenarios. Extensive experiments on real data and constructed datasets demonstrate the superiority of NeRF-MIR over its counterparts in masked image restoration.", "AI": {"tldr": "本文介绍了一种名为NeRF-MIR的新神经渲染方法，用于基于神经辐射场（NeRF）恢复被遮挡的图像。", "motivation": "尽管NeRF在新视图合成方面表现出色，但在从受损图像中恢复3D场景方面还有很大的改进空间。特别是对于自然场景捕获中的常见问题，需要一种新的方法来提高效果。", "method": "本文提出了PERE策略和PIRE机制，并设计了一个动态加权的损失函数以更好地恢复被遮挡区域。此外，构建了三个用于模拟受损情况的数据集。", "result": "实验结果表明NeRF-MIR在修复被遮挡图像方面优于现有方法。", "conclusion": "NeRF-MIR展示了神经辐射场（NeRF）在修复被遮挡图像方面的潜力，PERE策略和PIRE机制有助于提升恢复效果。"}}
{"id": "2601.17349", "pdf": "https://arxiv.org/pdf/2601.17349", "abs": "https://arxiv.org/abs/2601.17349", "authors": ["Hailong Yan", "Shice Liu", "Xiangtao Zhang", "Lujian Yao", "Fengxiang Yang", "Jinwei Chen", "Bo Li"], "title": "Revisiting Lightweight Low-Light Image Enhancement: From a YUV Color Space Perspective", "categories": ["cs.CV"], "comment": "Tech report", "summary": "In the current era of mobile internet, Lightweight Low-Light Image Enhancement (L3IE) is critical for mobile devices, which faces a persistent trade-off between visual quality and model compactness. While recent methods employ disentangling strategies to simplify lightweight architectural design, such as Retinex theory and YUV color space transformations, their performance is fundamentally limited by overlooking channel-specific degradation patterns and cross-channel interactions. To address this gap, we perform a frequency-domain analysis that confirms the superiority of the YUV color space for L3IE. We identify a key insight: the Y channel primarily loses low-frequency content, while the UV channels are corrupted by high-frequency noise. Leveraging this finding, we propose a novel YUV-based paradigm that strategically restores channels using a Dual-Stream Global-Local Attention module for the Y channel, a Y-guided Local-Aware Frequency Attention module for the UV channels, and a Guided Interaction module for final feature fusion. Extensive experiments validate that our model establishes a new state-of-the-art on multiple benchmarks, delivering superior visual quality with a significantly lower parameter count.", "AI": {"tldr": "本文提出了一种基于YUV色彩空间的轻量级低光照图像增强方法，通过频率分析确定了各通道特定降质模式，并设计了相应的模块来优化视觉质量和模型紧凑性。", "motivation": "在移动互联网时代，为了满足移动设备对轻量化和高质量图像的需求，现有方法虽然使用了分离策略简化网络结构设计，但忽略了通道特异性降质模式和跨通道交互，这限制了其性能。", "method": "通过对YUV色彩空间的频率域分析，提出了一种新的双流全局局部注意力模块用于恢复Y通道，一个Y引导的频域感知局部注意力模块用于处理UV通道，以及一个指导交互模块来融合特征。", "result": "实验表明该模型在多个基准上建立了新SOTA水平，提供优越视觉质量的同时参数量显著减少。", "conclusion": "基于YUV色彩空间的方法能够更有效地恢复低光照图像的质量，并且保持了轻量化设计的优势。"}}
{"id": "2601.17348", "pdf": "https://arxiv.org/pdf/2601.17348", "abs": "https://arxiv.org/abs/2601.17348", "authors": ["Srikant Panda", "Sourabh Singh Yadav", "Palkesh Malviya"], "title": "Auditing Disability Representation in Vision-Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Vision-language models (VLMs) are increasingly deployed in socially sensitive applications, yet their behavior with respect to disability remains underexplored. We study disability aware descriptions for person centric images, where models often transition from evidence grounded factual description to interpretation shift including introduction of unsupported inferences beyond observable visual evidence. To systematically analyze this phenomenon, we introduce a benchmark based on paired Neutral Prompts (NP) and Disability-Contextualised Prompts (DP) and evaluate 15 state-of-the-art open- and closed-source VLMs under a zero-shot setting across 9 disability categories. Our evaluation framework treats interpretive fidelity as core objective and combines standard text-based metrics capturing affective degradation through shifts in sentiment, social regard and response length with an LLM-as-judge protocol, validated by annotators with lived experience of disability. We find that introducing disability context consistently degrades interpretive fidelity, inducing interpretation shifts characterised by speculative inference, narrative elaboration, affective degradation and deficit oriented framing. These effects are further amplified along race and gender dimension. Finally, we demonstrate targeted prompting and preference fine-tuning effectively improves interpretive fidelity and reduces substantially interpretation shifts.", "AI": {"tldr": "研究视觉语言模型在处理包含残疾人的图像描述时的解释保真度，并提出改进方法。", "motivation": "随着视觉语言模型被越来越多地部署在社会敏感应用中，该论文关注这些模型对残疾人描述的行为仍不充分探讨的问题。", "method": "引入基于配对的中性提示和残疾情境化提示的基准测试框架，评估15个最新的开源和闭源视觉语言模型，并结合标准文本度量和LLM作为裁判协议进行分析。", "result": "发现引入残疾背景会降低解释保真度，导致推测推理、叙述扩展等现象出现，且这些影响在种族和性别维度上更为显著。通过定向提示和偏好微调可以有效改善这些问题。", "conclusion": "提出的方法可以在处理残疾人描述时提升视觉语言模型的解释保真度并减少不必要的解读变化。"}}
{"id": "2601.17346", "pdf": "https://arxiv.org/pdf/2601.17346", "abs": "https://arxiv.org/abs/2601.17346", "authors": ["Haoxin Xu", "Changyong Qi", "Tong Liu", "Bohao Zhang", "Anna He", "Bingqian Jiang", "Longwei Zheng", "Xiaoqing Gu"], "title": "Multi-Agent Learning Path Planning via LLMs", "categories": ["cs.AI"], "comment": null, "summary": "The integration of large language models (LLMs) into intelligent tutoring systems offers transformative potential for personalized learning in higher education. However, most existing learning path planning approaches lack transparency, adaptability, and learner-centered explainability. To address these challenges, this study proposes a novel Multi-Agent Learning Path Planning (MALPP) framework that leverages a role- and rule-based collaboration mechanism among intelligent agents, each powered by LLMs. The framework includes three task-specific agents: a learner analytics agent, a path planning agent, and a reflection agent. These agents collaborate via structured prompts and predefined rules to analyze learning profiles, generate tailored learning paths, and iteratively refine them with interpretable feedback. Grounded in Cognitive Load Theory and Zone of Proximal Development, the system ensures that recommended paths are cognitively aligned and pedagogically meaningful. Experiments conducted on the MOOCCubeX dataset using seven LLMs show that MALPP significantly outperforms baseline models in path quality, knowledge sequence consistency, and cognitive load alignment. Ablation studies further validate the effectiveness of the collaborative mechanism and theoretical constraints. This research contributes to the development of trustworthy, explainable AI in education and demonstrates a scalable approach to learner-centered adaptive instruction powered by LLMs.", "AI": {"tldr": "本文提出了一种基于大型语言模型（LLMs）的多智能体学习路径规划框架（MALPP），旨在解决现有方法在透明度、适应性和解释性方面的不足。", "motivation": "现有的学习路径规划方法缺乏透明度、适应性和以学习者为中心的可解释性，因此提出了一种新的多智能体学习路径规划框架来解决这些问题。", "method": "该研究设计了一个由三个特定任务的智能代理组成的框架：学习分析代理、路径规划代理和反思代理。这些代理通过结构化的提示和预定义规则进行协作，以分析学习者档案，生成定制的学习路径，并迭代地根据可解释的反馈改进它们。", "result": "实验结果表明，MALPP在路径质量、知识序列一致性以及认知负载对齐方面显著优于基线模型。消融研究进一步证实了协作机制和理论约束的有效性。", "conclusion": "该研究表明了基于LLMs的多智能体框架在教育中实现可信、可解释的人工智能的发展，提供了以学习者为中心的自适应指导的规模化方法。"}}
{"id": "2601.17343", "pdf": "https://arxiv.org/pdf/2601.17343", "abs": "https://arxiv.org/abs/2601.17343", "authors": ["Wei Liu", "Haomei Xu", "Hongkai Liu", "Zhiying Deng", "Ruixuan Li", "Heng Huang", "Yee Whye Teh", "Wee Sun Lee"], "title": "Are We Evaluating the Edit Locality of LLM Model Editing Properly?", "categories": ["cs.AI"], "comment": null, "summary": "Model editing has recently emerged as a popular paradigm for efficiently updating knowledge in LLMs. A central desideratum of updating knowledge is to balance editing efficacy, i.e., the successful injection of target knowledge, and specificity (also known as edit locality), i.e., the preservation of existing non-target knowledge. However, we find that existing specificity evaluation protocols are inadequate for this purpose. We systematically elaborated on the three fundamental issues it faces. Beyond the conceptual issues, we further empirically demonstrate that existing specificity metrics are weakly correlated with the strength of specificity regularizers. We also find that current metrics lack sufficient sensitivity, rendering them ineffective at distinguishing the specificity performance of different methods. Finally, we propose a constructive evaluation protocol. Under this protocol, the conflict between open-ended LLMs and the assumption of determined answers is eliminated, query-independent fluency biases are avoided, and the evaluation strictness can be smoothly adjusted within a near-continuous space. Experiments across various LLMs, datasets, and editing methods show that metrics derived from the proposed protocol are more sensitive to changes in the strength of specificity regularizers and exhibit strong correlation with them, enabling more fine-grained discrimination of different methods' knowledge preservation capabilities.", "AI": {"tldr": "论文探讨了现有LLM编辑过程中评估知识局部性的方法存在的问题，并提出了一种新的评估协议。", "motivation": "作者发现现有的评估特定性（即保存非目标知识的能力）的方法存在不足，无法有效地衡量不同的编辑方法在保持原有知识方面的能力。", "method": "论文系统地分析了现有评估协议面临的三个基本问题，并提出了一个构建性的评估方案来消除开放语言模型与确定答案假设之间的冲突，避免查询无关的流畅性偏差，并可以在近连续空间内平滑调整评估严格度。", "result": "实验表明，基于新协议的指标对特定性调节器强度变化更敏感，并表现出与其强相关性，从而能够更细粒度地区分不同方法的知识保存能力。", "conclusion": "论文提出的新评估协议解决了现有评估方法的问题，使得评估更具有效性和灵敏性。"}}
{"id": "2601.17342", "pdf": "https://arxiv.org/pdf/2601.17342", "abs": "https://arxiv.org/abs/2601.17342", "authors": ["Tong Wang", "Xiaodong Zhang", "Guanzhou Chen", "Jiaqi Wang", "Chenxi Liu", "Xiaoliang Tan", "Wenchao Guo", "Xuyang Li", "Xuanrui Wang", "Zifan Wang"], "title": "STARS: Shared-specific Translation and Alignment for missing-modality Remote Sensing Semantic Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal remote sensing technology significantly enhances the understanding of surface semantics by integrating heterogeneous data such as optical images, Synthetic Aperture Radar (SAR), and Digital Surface Models (DSM). However, in practical applications, the missing of modality data (e.g., optical or DSM) is a common and severe challenge, which leads to performance decline in traditional multimodal fusion models. Existing methods for addressing missing modalities still face limitations, including feature collapse and overly generalized recovered features. To address these issues, we propose \\textbf{STARS} (\\textbf{S}hared-specific \\textbf{T}ranslation and \\textbf{A}lignment for missing-modality \\textbf{R}emote \\textbf{S}ensing), a robust semantic segmentation framework for incomplete multimodal inputs. STARS is built on two key designs. First, we introduce an asymmetric alignment mechanism with bidirectional translation and stop-gradient, which effectively prevents feature collapse and reduces sensitivity to hyperparameters. Second, we propose a Pixel-level Semantic sampling Alignment (PSA) strategy that combines class-balanced pixel sampling with cross-modality semantic alignment loss, to mitigate alignment failures caused by severe class imbalance and improve minority-class recognition.", "AI": {"tldr": "STARS提出了一种针对缺失模态遥感图像语义分割的稳健框架，通过不对称对齐机制和像素级语义采样对齐策略来处理不完整多模态输入。", "motivation": "传统的多模态融合模型在面对如光学或数字表面模型数据缺失的情况时性能下降，现有方法仍存在特征塌陷和过度概括恢复特征的限制。", "method": "STARS包括两个关键设计：1. 引入带有双向翻译和停止梯度的不对称对齐机制；2. 提出像素级语义采样对齐策略，结合类别平衡像素抽样与跨模态语义对齐损失。", "result": "该方法有效防止了特征塌陷，减少了对超参数的敏感性，并缓解了由严重类别不平衡导致的对齐失败问题，提高了少数类别的识别能力。", "conclusion": "STARS为处理缺失模态遥感图像提供了有效的解决方案，在保持模型鲁棒性的前提下改善了语义分割性能。"}}
{"id": "2601.17340", "pdf": "https://arxiv.org/pdf/2601.17340", "abs": "https://arxiv.org/abs/2601.17340", "authors": ["Haodong He", "Xin Zhan", "Yancheng Bai", "Rui Lan", "Lei Sun", "Xiangxiang Chu"], "title": "TEXTS-Diff: TEXTS-Aware Diffusion Model for Real-World Text Image Super-Resolution", "categories": ["cs.CV"], "comment": "Accepted by ICASSP 2026", "summary": "Real-world text image super-resolution aims to restore overall visual quality and text legibility in images suffering from diverse degradations and text distortions. However, the scarcity of text image data in existing datasets results in poor performance on text regions. In addition, datasets consisting of isolated text samples limit the quality of background reconstruction. To address these limitations, we construct Real-Texts, a large-scale, high-quality dataset collected from real-world images, which covers diverse scenarios and contains natural text instances in both Chinese and English. Additionally, we propose the TEXTS-Aware Diffusion Model (TEXTS-Diff) to achieve high-quality generation in both background and textual regions. This approach leverages abstract concepts to improve the understanding of textual elements within visual scenes and concrete text regions to enhance textual details. It mitigates distortions and hallucination artifacts commonly observed in text regions, while preserving high-quality visual scene fidelity. Extensive experiments demonstrate that our method achieves state-of-the-art performance across multiple evaluation metrics, exhibiting superior generalization ability and text restoration accuracy in complex scenarios. All the code, model, and dataset will be released.", "AI": {"tldr": "本文提出TEXTS-Diff模型，以提高现实世界文本图像的超分辨率处理效果。", "motivation": "现有数据集缺乏真实世界的文本图像导致在处理文字区域时性能不佳，且背景重建质量受限于孤立的文字样本。为了解决这些问题并实现高质量背景和文本区域生成，提出了新的方法。", "method": "构建了大规模、高质的Real-Texts数据集，并提出TEXTS-Aware Diffusion Model (TEXTS-Diff)，利用抽象概念提升对视觉场景中文字元素的理解，并使用具体的文字区域来增强文字细节。", "result": "实验表明，该方法在多个评价指标上达到了最先进的性能，展现了强大的泛化能力和复杂场景下的文本恢复精度。", "conclusion": "本文的方法显著提升了现实世界文本图像的超分辨率质量，所有代码、模型和数据集将公开发布。"}}
{"id": "2601.17336", "pdf": "https://arxiv.org/pdf/2601.17336", "abs": "https://arxiv.org/abs/2601.17336", "authors": ["Xiaoyang Li", "Runni Zhou"], "title": "AGE-Net: Spectral--Spatial Fusion and Anatomical Graph Reasoning with Evidential Ordinal Regression for Knee Osteoarthritis Grading", "categories": ["cs.CV"], "comment": "22 pages", "summary": "Automated Kellgren--Lawrence (KL) grading from knee radiographs is challenging due to subtle structural changes, long-range anatomical dependencies, and ambiguity near grade boundaries. We propose AGE-Net, a ConvNeXt-based framework that integrates Spectral--Spatial Fusion (SSF), Anatomical Graph Reasoning (AGR), and Differential Refinement (DFR). To capture predictive uncertainty and preserve label ordinality, AGE-Net employs a Normal-Inverse-Gamma (NIG) evidential regression head and a pairwise ordinal ranking constraint. On a knee KL dataset, AGE-Net achieves a quadratic weighted kappa (QWK) of 0.9017 +/- 0.0045 and a mean squared error (MSE) of 0.2349 +/- 0.0028 over three random seeds, outperforming strong CNN baselines and showing consistent gains in ablation studies. We further outline evaluations of uncertainty quality, robustness, and explainability, with additional experimental figures to be included in the full manuscript.", "AI": {"tldr": "本文提出了AGE-Net框架，用于从膝关节X光片自动化Kellgren-Lawrence（KL）分级。", "motivation": "由于细微的结构变化、长距离解剖依赖性和接近等级边界时的模糊性，自动化KL分级面临挑战。本研究旨在解决这些问题，并提供一个更准确的方法来评估膝关节骨关节炎的程度。", "method": "AGE-Net框架基于ConvNeXt并整合了光谱空间融合（SSF）、解剖图推理（AGR）和差异细化（DFR）。它使用Normal-Inverse-Gamma（NIG）证据回归头和成对的次序排名约束来保持标签顺序性和预测不确定性。", "result": "在膝关节KL数据集上，AGE-Net取得了0.9017 ± 0.0045的二次加权Kappa分数和0.2349 ± 0.0028的均方误差，表现优于强基线模型，并且通过消融研究展示了持续的优势。", "conclusion": "AGE-Net框架在膝关节骨关节炎分级上展示出优越性能，尤其是在预测不确定性和标签顺序性的保持方面。"}}
{"id": "2601.17335", "pdf": "https://arxiv.org/pdf/2601.17335", "abs": "https://arxiv.org/abs/2601.17335", "authors": ["Angshul Majumdar"], "title": "The Relativity of AGI: Distributional Axioms, Fragility, and Undecidability", "categories": ["cs.AI"], "comment": null, "summary": "We study whether Artificial General Intelligence (AGI) admits a coherent theoretical definition that supports absolute claims of existence, robustness, or self-verification. We formalize AGI axiomatically as a distributional, resource-bounded semantic predicate, indexed by a task family, a task distribution, a performance functional, and explicit resource budgets. Under this framework, we derive four classes of results. First, we show that generality is inherently relational: there is no distribution-independent notion of AGI. Second, we prove non-invariance results demonstrating that arbitrarily small perturbations of the task distribution can invalidate AGI properties via cliff sets, precluding universal robustness. Third, we establish bounded transfer guarantees, ruling out unbounded generalization across task families under finite resources. Fourth, invoking Rice-style and Gödel--Tarski arguments, we prove that AGI is a nontrivial semantic property and therefore cannot be soundly and completely certified by any computable procedure, including procedures implemented by the agent itself. Consequently, recursive self-improvement schemes that rely on internal self-certification of AGI are ill-posed. Taken together, our results show that strong, distribution-independent claims of AGI are not false but undefined without explicit formal indexing, and that empirical progress in AI does not imply the attainability of self-certifying general intelligence.", "AI": {"tldr": "本文研究了人工通用智能（AGI）是否可以有一个连贯的理论定义，以支持关于其存在、鲁棒性或自我验证的绝对声明，并通过形式化的方法揭示了AGI的相对性和限制。", "motivation": "探讨在理论上能否为AGI提供一个支持绝对存在的定义，以及这个定义如何受到任务分布、性能和资源约束的影响。", "method": "将AGI形式化为以任务族、任务分布、绩效函数和明确的资源预算为索引的分布式语义谓词，并使用Rice风格和Gödel--Tarski论点进行证明。", "result": "揭示了四个类别的结果，包括普遍性是相对的、小的扰动可使AGI特性失效、任务家族间有限的泛化转移保证以及通过计算程序无法完全认证AGI。", "conclusion": "强烈且独立于分布的关于AGI的存在声明是未定义的，在没有明确的形式索引情况下，实际的AI进步并不意味着可以达到自我验证的一般智能。"}}
{"id": "2601.17333", "pdf": "https://arxiv.org/pdf/2601.17333", "abs": "https://arxiv.org/abs/2601.17333", "authors": ["Lalit Pant", "Shivang Nagar"], "title": "FinMetaMind: A Tech Blueprint on NLQ Systems for Financial Knowledge Search", "categories": ["cs.IR", "cs.AI", "cs.CE", "cs.DB"], "comment": "8 pages, 8 figures, Information Retrieval, Natural Language Query, Vector Search, Embeddings, Named Entity Recognition, Large Language Models", "summary": "Natural Language Query (NLQ) allows users to search and interact with information systems using plain, human language instead of structured query syntax. This paper presents a technical blueprint on the design of a modern NLQ system tailored to financial knowledge search. The introduction of NLQ not only enhances the precision and recall of the knowledge search compared to traditional methods, but also facilitates deeper insights by efficiently linking disparate financial objects, events, and relationships. Using core constructs from natural language processing, search engineering, and vector data models, the proposed system aims to address key challenges in discovering, relevance ranking, data freshness, and entity recognition intrinsic to financial data retrieval. In this work, we detail the unique requirements of NLQ for financial datasets and documents, outline the architectural components for offline indexing and online retrieval, and discuss the real-world use cases of enhanced knowledge search in financial services. We delve into the theoretical underpinnings and experimental evidence supporting our proposed architecture, ultimately providing a comprehensive analysis on the subject matter. We also provide a detailed elaboration of our experimental methodology, the data used, the results and future optimizations in this study.", "AI": {"tldr": "本文提出了一个专为金融知识搜索设计的自然语言查询（NLQ）系统的蓝图。", "motivation": "通过引入NLQ，提高金融知识检索的精度和召回率，并促进对不同金融对象、事件及其关系的深入理解。", "method": "采用核心构建自自然语言处理、搜索引擎工程和技术数据模型来解决发现、相关性排序、数据新鲜度和实体识别等挑战。详细描述了用于离线索引和在线检索的架构组件以及实验方法论。", "result": "提供了理论基础和实验证据支持所提出的架构，并讨论了金融服务业中的实际应用场景。", "conclusion": "为金融知识搜索提供了一个全面分析，涵盖了系统的独特需求、详细的实验数据及未来优化方向。"}}
{"id": "2601.17332", "pdf": "https://arxiv.org/pdf/2601.17332", "abs": "https://arxiv.org/abs/2601.17332", "authors": ["Yicheng Tao", "Hongteng Xu"], "title": "TheoremForge: Scaling up Formal Data Synthesis with Low-Budget Agentic Workflow", "categories": ["cs.AI"], "comment": null, "summary": "The high cost of agentic workflows in formal mathematics hinders large-scale data synthesis, exacerbating the scarcity of open-source corpora. To address this, we introduce \\textbf{TheoremForge}, a cost-effective formal data synthesis pipeline that decomposes the formalization process into five sub-tasks, which are \\textit{statement formalization}, \\textit{proof generation}, \\textit{premise selection}, \\textit{proof correction} and \\textit{proof sketching}. By implementing a \\textit{Decoupled Extraction Strategy}, the workflow recovers valid training signals from globally failed trajectories, effectively utilizing wasted computation. Experiments on a 2,000-problem benchmark demonstrate that TheoremForge achieves a Verified Rate of 12.6\\%, surpassing the 8.6\\% baseline, at an average cost of only \\textbf{\\$0.481} per successful trajectory using Gemini-3-Flash. Crucially, our strategy increases data yield by \\textbf{1.6$\\times$} for proof generation compared to standard filtering. These results establish TheoremForge as a scalable framework for constructing a data flywheel to train future expert models. Our code is available \\href{https://github.com/timechess/TheoremForge}{here}.", "AI": {"tldr": "本文介绍了TheoremForge，一种成本效益高的形式化数据合成管道，它将形式化过程分解为五个子任务，并采用脱钩提取策略来提高计算效率。", "motivation": "高昂的代理工作流成本阻碍了大规模的形式化数据综合，加剧了开源语料库的稀缺性。为此，本文旨在开发一种经济高效的解决方案。", "method": "TheoremForge通过将形式化过程分解成五个子任务（声明形式化、证明生成、前提选择、证明修正和证明草图）并采用脱钩提取策略来提高效率。", "result": "实验结果表明，在一个2000问题的基准测试上，TheoremForge达到了12.6%的验证率，超过了8.6%的基线水平。相比于标准过滤方法，其在证明生成的数据产出方面提高了1.6倍。", "conclusion": "这些结果确立了TheoremForge作为构建数据飞轮以训练未来专家模型的可扩展框架的地位，该框架能够有效利用计算资源并降低成本。"}}
{"id": "2601.17331", "pdf": "https://arxiv.org/pdf/2601.17331", "abs": "https://arxiv.org/abs/2601.17331", "authors": ["Fabian Vazquez", "Jose A. Nuñez", "Diego Adame", "Alissen Moreno", "Augustin Zhan", "Huimin Li", "Jinghao Yang", "Haoteng Tang", "Bin Fu", "Pengfei Gu"], "title": "Learning with Geometric Priors in U-Net Variants for Polyp Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate and robust polyp segmentation is essential for early colorectal cancer detection and for computer-aided diagnosis. While convolutional neural network-, Transformer-, and Mamba-based U-Net variants have achieved strong performance, they still struggle to capture geometric and structural cues, especially in low-contrast or cluttered colonoscopy scenes. To address this challenge, we propose a novel Geometric Prior-guided Module (GPM) that injects explicit geometric priors into U-Net-based architectures for polyp segmentation. Specifically, we fine-tune the Visual Geometry Grounded Transformer (VGGT) on a simulated ColonDepth dataset to estimate depth maps of polyp images tailored to the endoscopic domain. These depth maps are then processed by GPM to encode geometric priors into the encoder's feature maps, where they are further refined using spatial and channel attention mechanisms that emphasize both local spatial and global channel information. GPM is plug-and-play and can be seamlessly integrated into diverse U-Net variants. Extensive experiments on five public polyp segmentation datasets demonstrate consistent gains over three strong baselines. Code and the generated depth maps are available at: https://github.com/fvazqu/GPM-PolypSeg", "AI": {"tldr": "提出了一种基于几何先验的模块（GPM），用于改进U-Net变体在息肉分割中的性能。", "motivation": "现有模型难以捕捉低对比度或杂乱内窥镜图像中的几何和结构线索，这影响了息肉分割的准确性和鲁棒性。", "method": "开发了一种Geometric Prior-guided Module (GPM)，该模块利用从模拟ColonDepth数据集中提取的深度图来注入显式的几何先验信息，并通过空间和通道注意力机制进一步优化编码器特征。", "result": "实验结果表明，与三个强劲基线模型相比，在五个公开的数据集上使用GPM方法取得了持续性的性能提升。", "conclusion": "提出的Geometric Prior-guided Module能够显著提高U-Net变体在息肉分割任务中的表现，并且该模块可以无缝集成到不同的U-Net架构中。"}}
{"id": "2601.17330", "pdf": "https://arxiv.org/pdf/2601.17330", "abs": "https://arxiv.org/abs/2601.17330", "authors": ["Laurent Caraffa"], "title": "Thermodynamically Optimal Regularization under Information-Geometric Constraints", "categories": ["cs.LG", "cs.CV"], "comment": "7 pages, 0 figures", "summary": "Modern machine learning relies on a collection of empirically successful but theoretically heterogeneous regularization techniques, such as weight decay, dropout, and exponential moving averages. At the same time, the rapidly increasing energetic cost of training large models raises the question of whether learning algorithms approach any fundamental efficiency bound. In this work, we propose a unifying theoretical framework connecting thermodynamic optimality, information geometry, and regularization. Under three explicit assumptions -- (A1) that optimality requires an intrinsic, parametrization-invariant measure of information, (A2) that belief states are modeled by maximum-entropy distributions under known constraints, and (A3) that optimal processes are quasi-static -- we prove a conditional optimality theorem. Specifically, the Fisher--Rao metric is the unique admissible geometry on belief space, and thermodynamically optimal regularization corresponds to minimizing squared Fisher--Rao distance to a reference state. We derive the induced geometries for Gaussian and circular belief models, yielding hyperbolic and von Mises manifolds, respectively, and show that classical regularization schemes are structurally incapable of guaranteeing thermodynamic optimality. We introduce a notion of thermodynamic efficiency of learning and propose experimentally testable predictions. This work provides a principled geometric and thermodynamic foundation for regularization in machine learning.", "AI": {"tldr": "本文提出了一个统一的理论框架，将热力学最优性、信息几何和正则化技术连接起来。", "motivation": "现代机器学习依靠多种经验上成功但理论上各异的正则化技术。随着训练大型模型的能量成本迅速上升，本工作探讨了这些算法是否接近任何基本效率极限的问题。", "method": "在三个明确假设的基础上证明了一个条件最优性定理：(A1)最优性需要一个内在的、参数化不变的信息度量；(A2)信念状态由已知约束下的最大熵分布建模；(A3)最优过程是准静态的。具体而言，Fisher-Rao度量是信念空间上唯一的可接受几何，并且热力学最优正则化对应于最小化到参考状态的平方Fisher-Rao距离。", "result": "推导了高斯和圆形信念模型所诱导出的几何学，分别获得了双曲和von Mises流形。表明经典正则化方案在结构上无法保证热力学最优性，并提出了学习的热力学效率的概念以及实验可验证的预测。", "conclusion": "本工作为机器学习中的正则化提供了原则性的几何和热力学基础。"}}
{"id": "2601.17329", "pdf": "https://arxiv.org/pdf/2601.17329", "abs": "https://arxiv.org/abs/2601.17329", "authors": ["Tiejin Chen", "Xiaoou Liu", "Vishnu Nandam", "Kuan-Ru Liou", "Hua Wei"], "title": "Conformal Feedback Alignment: Quantifying Answer-Level Reliability for Robust LLM Alignment", "categories": ["cs.LG", "cs.AI"], "comment": "Accetped to Findings of EACL", "summary": "Preference-based alignment like Reinforcement Learning from Human Feedback (RLHF) learns from pairwise preferences, yet the labels are often noisy and inconsistent. Existing uncertainty-aware approaches weight preferences, but ignore a more fundamental factor: the reliability of the \\emph{answers} being compared. To address the problem, we propose Conformal Feedback Alignment (CFA), a framework that grounds preference weighting in the statistical guarantees of Conformal Prediction (CP). CFA quantifies answer-level reliability by constructing conformal prediction sets with controllable coverage and aggregates these reliabilities into principled weights for both DPO- and PPO-style training. Experiments across different datasets show that CFA improves alignment robustness and data efficiency, highlighting that modeling \\emph{answer-side} uncertainty complements preference-level weighting and yields more robust, data-efficient alignment. Codes are provided here.", "AI": {"tldr": "本文提出了一种名为Conformal Feedback Alignment（CFA）的框架，用于量化答案级别的可靠性以改进基于偏好的对齐方法。", "motivation": "现有的偏好对齐方法忽略了所比较的答案的可靠性的基本因素，并且标签往往是嘈杂和不一致的。", "method": "CFA框架利用Conformal Prediction（CP）的统计保证来量化答案级别的可靠性，通过构建具有可控覆盖率的符合性预测集并将这些可靠性聚合为DPO和PPO样式的训练中的原理权重。", "result": "实验结果显示，在不同的数据集上，CFA提高了对齐的稳健性和数据效率。", "conclusion": "本文强调了建模答案级别的不确定性补充了偏好级别的加权，并能实现更稳健、数据高效的对齐。"}}
{"id": "2601.17326", "pdf": "https://arxiv.org/pdf/2601.17326", "abs": "https://arxiv.org/abs/2601.17326", "authors": ["Jasmine Lesner", "Michael Beyeler"], "title": "SymbolSight: Minimizing Inter-Symbol Interference for Reading with Prosthetic Vision", "categories": ["cs.CV", "cs.HC"], "comment": "Submitted to IEEE EMBC 2026. 7 pages, 6 figures, 2 tables", "summary": "Retinal prostheses restore limited visual perception, but low spatial resolution and temporal persistence make reading difficult. In sequential letter presentation, the afterimage of one symbol can interfere with perception of the next, leading to systematic recognition errors. Rather than relying on future hardware improvements, we investigate whether optimizing the visual symbols themselves can mitigate this temporal interference. We present SymbolSight, a computational framework that selects symbol-to-letter mappings to minimize confusion among frequently adjacent letters. Using simulated prosthetic vision (SPV) and a neural proxy observer, we estimate pairwise symbol confusability and optimize assignments using language-specific bigram statistics. Across simulations in Arabic, Bulgarian, and English, the resulting heterogeneous symbol sets reduced predicted confusion by a median factor of 22 relative to native alphabets. These results suggest that standard typography is poorly matched to serial, low-bandwidth prosthetic vision and demonstrate how computational modeling can efficiently narrow the design space of visual encodings to generate high-potential candidates for future psychophysical and clinical evaluation.", "AI": {"tldr": "SymbolSight是一种计算框架，用于选择符号到字母的映射以减少相邻字母之间的混淆，从而提高通过假体视觉阅读时的表现。", "motivation": "由于低空间分辨率和时间持久性，视网膜假体使得阅读变得困难。本文旨在通过优化视觉符号本身来减轻这种时间干扰，而不是依赖未来硬件的进步。", "method": "使用模拟假体视觉（SPV）和神经代理观察者估算成对符号的混淆度，并利用语言特定的大写字母统计数据进行优化赋值。", "result": "在阿拉伯语、保加利亚语和英语的模拟中，产生的异质符号集将预测到的混淆程度降低了22倍以上相对于原生字母表。", "conclusion": "标准字体设计与序列化低带宽假体视觉不匹配，计算建模可以高效地缩小视觉编码的设计空间，为未来的心理物理和临床评估生成高潜力候选者。"}}
{"id": "2601.17323", "pdf": "https://arxiv.org/pdf/2601.17323", "abs": "https://arxiv.org/abs/2601.17323", "authors": ["Debang Li", "Zhengcong Fei", "Tuanhui Li", "Yikun Dou", "Zheng Chen", "Jiangping Yang", "Mingyuan Fan", "Jingtao Xu", "Jiahua Wang", "Baoxuan Gu", "Mingshan Chang", "Yuqiang Xie", "Binjie Mao", "Youqiang Zhang", "Nuo Pang", "Hao Zhang", "Yuzhe Jin", "Zhiheng Xu", "Dixuan Lin", "Guibin Chen", "Yahui Zhou"], "title": "SkyReels-V3 Technique Report", "categories": ["cs.CV"], "comment": null, "summary": "Video generation serves as a cornerstone for building world models, where multimodal contextual inference stands as the defining test of capability. In this end, we present SkyReels-V3, a conditional video generation model, built upon a unified multimodal in-context learning framework with diffusion Transformers. SkyReels-V3 model supports three core generative paradigms within a single architecture: reference images-to-video synthesis, video-to-video extension and audio-guided video generation. (i) reference images-to-video model is designed to produce high-fidelity videos with strong subject identity preservation, temporal coherence, and narrative consistency. To enhance reference adherence and compositional stability, we design a comprehensive data processing pipeline that leverages cross frame pairing, image editing, and semantic rewriting, effectively mitigating copy paste artifacts. During training, an image video hybrid strategy combined with multi-resolution joint optimization is employed to improve generalization and robustness across diverse scenarios. (ii) video extension model integrates spatio-temporal consistency modeling with large-scale video understanding, enabling both seamless single-shot continuation and intelligent multi-shot switching with professional cinematographic patterns. (iii) Talking avatar model supports minute-level audio-conditioned video generation by training first-and-last frame insertion patterns and reconstructing key-frame inference paradigms. On the basis of ensuring visual quality, synchronization of audio and videos has been optimized. Extensive evaluations demonstrate that SkyReels-V3 achieves state-of-the-art or near state-of-the-art performance on key metrics including visual quality, instruction following, and specific aspect metrics, approaching leading closed-source systems. Github: https://github.com/SkyworkAI/SkyReels-V3.", "AI": {"tldr": "本文介绍了SkyReels-V3，一种基于统一多模态上下文学习框架的条件视频生成模型。", "motivation": "动机在于通过构建一个能够进行多模态情境推断的世界模型来提升视频生成能力。", "method": "SkyReels-V3支持三种核心生成范式：参考图像到视频合成、视频扩展和音频指导下的视频生成，使用了扩散Transformer，并设计了一个数据处理管道以提高生成的保真度和一致性。", "result": "评估显示SkyReels-V3在视觉质量、指令遵循和其他特定指标上达到了最先进的性能或接近领先水平。", "conclusion": "结论指出SkyReels-V3通过其创新方法实现了高质量视频生成，并且在多个关键性能指标上达到或接近行业顶尖水平。"}}
{"id": "2601.17315", "pdf": "https://arxiv.org/pdf/2601.17315", "abs": "https://arxiv.org/abs/2601.17315", "authors": ["Xiaoyang Li", "Runni Zhou"], "title": "ClinNet: Evidential Ordinal Regression with Bilateral Asymmetry and Prototype Memory for Knee Osteoarthritis Grading", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages", "summary": "Knee osteoarthritis (KOA) grading based on radiographic images is a critical yet challenging task due to subtle inter-grade differences, annotation uncertainty, and the inherently ordinal nature of disease progression. Conventional deep learning approaches typically formulate this problem as deterministic multi-class classification, ignoring both the continuous progression of degeneration and the uncertainty in expert annotations. In this work, we propose ClinNet, a novel trustworthy framework that addresses KOA grading as an evidential ordinal regression problem. The proposed method integrates three key components: (1) a Bilateral Asymmetry Encoder (BAE) that explicitly models medial-lateral structural discrepancies; (2) a Diagnostic Memory Bank that maintains class-wise prototypes to stabilize feature representations; and (3) an Evidential Ordinal Head based on the Normal-Inverse-Gamma (NIG) distribution to jointly estimate continuous KL grades and epistemic uncertainty. Extensive experiments demonstrate that ClinNet achieves a Quadratic Weighted Kappa of 0.892 and Accuracy of 0.768, statistically outperforming state-of-the-art baselines (p < 0.001). Crucially, we demonstrate that the model's uncertainty estimates successfully flag out-of-distribution samples and potential misdiagnoses, paving the way for safe clinical deployment.", "AI": {"tldr": "ClinNet提出了一种基于证据的顺序回归方法，用于膝关节骨关节炎（KOA）分级。", "motivation": "传统深度学习方法将KOA分级视为确定性的多类分类问题，忽略了疾病的连续进展和专家标注中的不确定性。", "method": "ClinNet整合了双边不对称编码器（BAE）、诊断记忆库和基于正态逆伽玛分布的证据顺序头来共同估计连续KL等级和知识不确定性。", "result": "实验表明，ClinNet达到了Quadratic Weighted Kappa为0.892，准确率为0.768，显著优于现有方法（p < 0.001）。", "conclusion": "模型的不确定性估计能够成功标记出分布外样本和潜在误诊，为进一步安全临床应用铺平道路。"}}
{"id": "2601.17312", "pdf": "https://arxiv.org/pdf/2601.17312", "abs": "https://arxiv.org/abs/2601.17312", "authors": ["Hugo Silva", "Mateus Mendes", "Hugo Gonçalo Oliveira"], "title": "Meta-Judging with Large Language Models: Concepts, Methods, and Challenges", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are evolving fast and are now frequently used as evaluators, in a process typically referred to as LLM-as-a-Judge, which provides quality assessments of model outputs. However, recent research points out significant vulnerabilities in such evaluation, including sensitivity to prompts, systematic biases, verbosity effects, and unreliable or hallucinated rationales. These limitations motivated the development of a more robust paradigm, dubbed LLM-as-a-Meta-Judge. This survey reviews recent advances in meta-judging and organizes the literature, by introducing a framework along six key perspectives: (i) Conceptual Foundations, (ii) Mechanisms of Meta-Judging, (iii) Alignment Training Methods, (iv) Evaluation, (v) Limitations and Failure Modes, and (vi) Future Directions. By analyzing the limitations of LLM-as-a-Judge and summarizing recent advances in meta-judging by LLMs, we argue that LLM-as-a-Meta-Judge offers a promising direction for more stable and trustworthy automated evaluation, while highlighting remaining challenges related to cost, prompt sensitivity, and shared model biases, which must be addressed to advance the next generation of LLM evaluation methodologies.", "AI": {"tldr": "本文综述了大型语言模型（LLM）作为元裁判（Meta-Judge）的最新进展，提出了一种更为稳健的评估框架。", "motivation": "由于现有的LLM评判存在提示敏感性、系统性偏差等局限性，因此发展了一个更强大的范式，即LLM-as-a-Meta-Judge。", "method": "通过分析六项关键视角——概念基础、元裁判机制、对齐训练方法、评估、限制和失败模式以及未来方向来综述文献。", "result": "总结了近期在LLM元评判方面的进展，并认为这种新范式提供了更为稳定可靠自动评估的可能性。", "conclusion": "尽管存在成本、提示敏感性和共享模型偏差等挑战，但Meta-Judge仍然是LLM评价方法发展的一个有前景的方向。"}}
{"id": "2601.17311", "pdf": "https://arxiv.org/pdf/2601.17311", "abs": "https://arxiv.org/abs/2601.17311", "authors": ["Bang Liu", "Linglong Kong", "Jian Pei"], "title": "Phase Transition for Budgeted Multi-Agent Synergy", "categories": ["cs.AI"], "comment": "55 pages, 12 figures", "summary": "Multi-agent systems can improve reliability, yet under a fixed inference budget they often help, saturate, or even collapse. We develop a minimal and calibratable theory that predicts these regimes from three binding constraints of modern agent stacks: finite context windows, lossy inter-agent communication, and shared failures among similar agents. Each leaf agent is summarized by a compute-performance scaling exponent $β$; communication is captured by a message-length fidelity curve $γ(m)$; dependence is captured by an effective shared-error correlation $ρ$; and a context window $W$ imposes hard fan-in limits that make hierarchy necessary. For binary success/failure tasks with majority aggregation, we prove a sharp phase transition for deep $b$-ary trees with correlated inputs and lossy communication: a single scalar $α_ρ$ (combining $γ(m)$, $ρ$, and fan-in $b$) determines whether weak signal is amplified to a nontrivial fixed point or washed out to chance. In the amplifying regime, we derive an organization exponent $s$ and show that budgeted synergy, i.e., outperforming the best single agent under the same total budget, occurs exactly when $s>β$, yielding closed-form compute allocation rules and explicit budget thresholds. We further characterize saturation via a mixing depth and provide a conservative clipped predictor that remains accurate across growth and saturation. A continuous-performance warm-up gives closed-form risks for star, chain, and tree organizations, making correlation- and communication-induced floors explicit and exposing the core design trade-offs in a smooth setting. Finally, we validate the predicted phase boundaries in controlled synthetic simulations and show how the same mechanisms explain the dominant bottlenecks reported in recent large-scale matched-budget studies of LLM agent-system scaling.", "AI": {"tldr": "本文研究了多智能体系统在固定推理预算下的相变现象，提出了一个理论来预测不同情境下的性能表现。", "motivation": "旨在理解并预测多智能体系统如何在面对有限资源和通信限制的情况下改善或恶化其可靠性。", "method": "通过构建考虑计算-性能缩放指数、消息长度保真度曲线、有效共享错误相关性和上下文窗口约束的理论模型，分析了二元任务下的相变现象。", "result": "证明了一个标量$α_ρ$决定了弱信号是否被放大或被洗至随机水平，并确定了当$s>β$时预算协同发生的确切条件。此外，在控制的合成模拟中验证了预测的相变边界。", "conclusion": "该研究揭示了多智能体系统在不同约束下的行为模式，为设计高性能且成本效益优化的智能体组织提供了理论依据和计算分配规则。"}}
{"id": "2601.17310", "pdf": "https://arxiv.org/pdf/2601.17310", "abs": "https://arxiv.org/abs/2601.17310", "authors": ["Yu Akagi", "Tomohisa Seki", "Hiromasa Ito", "Toru Takiguchi", "Kazuhiko Ohe", "Yoshimasa Kawazoe"], "title": "High-Fidelity Longitudinal Patient Simulation Using Real-World Data", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Simulation is a powerful tool for exploring uncertainty. Its potential in clinical medicine is transformative and includes personalized treatment planning and virtual clinical trials. However, simulating patient trajectories is challenging because of complex biological and sociocultural influences. Here, we show that real-world clinical records can be leveraged to empirically model patient timelines. We developed a generative simulator model that takes a patient's history as input and synthesizes fine-grained, realistic future trajectories. The model was pretrained on more than 200 million clinical records. It produced high-fidelity future timelines, closely matching event occurrence rates, laboratory test results, and temporal dynamics in real patient future data. It also accurately estimated future event probabilities, with observed-to-expected ratios consistently near 1.0 across diverse outcomes and time horizons. Our results reveal the untapped value of real-world data in electronic health records and introduce a scalable framework for in silico modeling of clinical care.", "AI": {"tldr": "本文介绍了使用真实世界数据进行高保真纵向患者模拟的方法。", "motivation": "在临床医学中，模拟是一种探索不确定性的强大工具，可以用于个性化治疗计划和虚拟临床试验，但模拟患者轨迹因复杂的生物和社会文化影响而具有挑战性。", "method": "开发了一个生成式模拟器模型，该模型以患者的病史为输入，并合成细粒度、现实的未来轨迹。模型在超过2亿份临床记录上进行预训练。", "result": "模型产生了高保真的未来时间线，与真实患者未来的事件发生率、实验室测试结果和时间动态紧密匹配，并准确估计了未来事件的概率。", "conclusion": "研究揭示了电子健康记录中未被充分利用的真实世界数据的价值，并介绍了一个用于临床护理计算建模的可扩展框架。"}}
{"id": "2601.17303", "pdf": "https://arxiv.org/pdf/2601.17303", "abs": "https://arxiv.org/abs/2601.17303", "authors": ["Samaresh Kumar Singh", "Joyjit Roy"], "title": "Decentralized Multi-Agent Swarms for Autonomous Grid Security in Industrial IoT: A Consensus-based Approach", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.ET"], "comment": "9 pages, 8 figures, and Submitted to IEEE SoutheastCon 2026", "summary": "As Industrial Internet of Things (IIoT) environments expand to include tens of thousands of connected devices. The centralization of security monitoring architectures creates serious latency issues that savvy attackers can exploit to compromise an entire manufacturing ecosystem. This paper outlines a new, decentralized multi-agent swarm (DMAS) architecture that includes autonomous artificial intelligence (AI) agents at each edge gateway, functioning as a distributed digital \"immune system\" for IIoT networks. Instead of using a traditional static firewall approach, the DMAS agents communicate via a lightweight peer-to-peer protocol to cooperatively detect anomalous behavior across the IIoT network without sending data to a cloud infrastructure. The authors also outline a consensus-based threat validation (CVT) process in which agents vote on the threat level of an identified threat, enabling instant quarantine of a compromised node or nodes. The authors conducted experiments on a testbed that simulated an innovative factory environment with 2000 IIoT devices and found that the DMAS demonstrated sub-millisecond response times (average of 0.85ms), 97.3% accuracy in detecting malicious activity under high load, and 87% accuracy in detecting zero-day attacks. All significantly higher than baseline values for both centralized and edge computing. Additionally, the proposed architecture can prevent real-time cascading failures in industrial control systems and reduce network bandwidth use by 89% compared to cloud-based solutions.", "AI": {"tldr": "本文提出了一种去中心化的多智能体群系统（DMAS），用于工业物联网环境中的自主网络安全，通过轻量级的点对点协议实现异常行为检测。", "motivation": "由于工业物联网环境中设备数量庞大，集中式安全监控架构存在严重延迟问题，这给攻击者留下了可乘之机。因此，需要一种新的解决方案来解决这些问题。", "method": "作者设计了一种包含自主人工智能代理的去中心化多智能体群系统（DMAS），这些代理分布在每个边缘网关上，并通过轻量级点对点协议协同检测异常行为。此外还提出了基于共识的威胁验证过程，用于评估和即时隔离受感染节点。", "result": "在模拟环境中进行实验，测试了2000个工业物联网设备下的表现：DMAS系统展示了亚毫秒级响应时间（平均为0.85ms），高负载下检测恶意活动准确率97.3%，零日攻击检测准确率为87%。与集中式和边缘计算相比，具有显著优势。", "conclusion": "该架构能够预防工业控制系统中的实时连锁故障，并将网络带宽使用量减少89%，相较于基于云的解决方案有明显改进。"}}
{"id": "2601.17290", "pdf": "https://arxiv.org/pdf/2601.17290", "abs": "https://arxiv.org/abs/2601.17290", "authors": ["Weloday Fikadu Moges", "Jianmei Su", "Amin Waqas"], "title": "Dynamic Meta-Ensemble Framework for Efficient and Accurate Deep Learning in Plant Leaf Disease Detection on Resource-Constrained Edge Devices", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Deploying deep learning models for plant disease detection on edge devices such as IoT sensors, smartphones, and embedded systems is severely constrained by limited computational resources and energy budgets. To address this challenge, we introduce a novel Dynamic Meta-Ensemble Framework (DMEF) for high-accuracy plant disease diagnosis under resource constraints. DMEF employs an adaptive weighting mechanism that dynamically combines the predictions of three lightweight convolutional neural networks (MobileNetV2, NASNetMobile, and InceptionV3) by optimizing a trade-off between accuracy improvements (DeltaAcc) and computational efficiency (model size). During training, the ensemble weights are updated iteratively, favoring models exhibiting high performance and low complexity. Extensive experiments on benchmark datasets for potato and maize diseases demonstrate state-of-the-art classification accuracies of 99.53% and 96.61%, respectively, surpassing standalone models and static ensembles by 2.1% and 6.3%. With computationally efficient inference latency (<75ms) and a compact footprint (<1 million parameters), DMEF shows strong potential for edge-based agricultural monitoring, suggesting viability for scalable crop disease management. This bridges the gap between high-accuracy AI and practical field applications.", "AI": {"tldr": "本文介绍了一种动态元集成框架（DMEF），用于在资源受限的边缘设备上高效准确地进行植物叶片疾病检测。", "motivation": "由于计算和能源预算有限，部署深度学习模型以检测植物疾病面临挑战。该研究旨在开发一个可以在资源受限条件下实现高精度诊断的方法。", "method": "DMEF通过动态组合三种轻量级卷积神经网络（MobileNetV2、NASNetMobile 和 InceptionV3），并使用自适应加权机制优化准确性改进和计算效率之间的平衡，以迭代更新集成权重来提高性能。", "result": "实验显示，在土豆和玉米疾病数据集上实现了99.53%和96.61%的分类准确率，分别超过了单独模型和静态集成2.1%和6.3%，且推理延迟小于75ms，参数量少于100万。", "conclusion": "DMEF展示了在边缘设备上进行农业监控的强大潜力，表明其对于可扩展作物疾病管理的可行性。"}}
{"id": "2601.17288", "pdf": "https://arxiv.org/pdf/2601.17288", "abs": "https://arxiv.org/abs/2601.17288", "authors": ["Jin Bai", "Huiyao Zhang", "Qi Wen", "Shengyang Li", "Xiaolin Tian", "Atta ur Rahman"], "title": "Fluxamba: Topology-Aware Anisotropic State Space Models for Geological Lineament Segmentation in Multi-Source Remote Sensing", "categories": ["cs.CV"], "comment": null, "summary": "The precise segmentation of geological linear features, spanning from planetary lineaments to terrestrial fractures, demands capturing long-range dependencies across complex anisotropic topologies. Although State Space Models (SSMs) offer near-linear computational complexity, their dependence on rigid, axis-aligned scanning trajectories induces a fundamental topological mismatch with curvilinear targets, resulting in fragmented context and feature erosion. To bridge this gap, we propose Fluxamba, a lightweight architecture that introduces a topology-aware feature rectification framework. Central to our design is the Structural Flux Block (SFB), which orchestrates an anisotropic information flux by integrating an Anisotropic Structural Gate (ASG) with a Prior-Modulated Flow (PMF). This mechanism decouples feature orientation from spatial location, dynamically gating context aggregation along the target's intrinsic geometry rather than rigid paths. Furthermore, to mitigate serialization-induced noise in low-contrast environments, we incorporate a Hierarchical Spatial Regulator (HSR) for multi-scale semantic alignment and a High-Fidelity Focus Unit (HFFU) to explicitly maximize the signal-to-noise ratio of faint features. Extensive experiments on diverse geological benchmarks (LROC-Lineament, LineaMapper, and GeoCrack) demonstrate that Fluxamba establishes a new state-of-the-art. Notably, on the challenging LROC-Lineament dataset, it achieves an F1-score of 89.22% and mIoU of 89.87%. Achieving a real-time inference speed of over 24 FPS with only 3.4M parameters and 6.3G FLOPs, Fluxamba reduces computational costs by up to two orders of magnitude compared to heavy-weight baselines, thereby establishing a new Pareto frontier between segmentation fidelity and onboard deployment feasibility.", "AI": {"tldr": "提出Fluxamba模型，以解决地质线性特征分割中长距离依赖和复杂各向异性拓扑结构的问题。", "motivation": "传统的状态空间模型（SSMs）无法有效地处理弯曲目标的分割问题，导致特征碎片化和侵蚀。为了解决这个问题并提高地质线性特征如行星线理和地表裂缝等的精确分割，本论文提出了Fluxamba模型。", "method": "提出Fluxamba架构，通过引入结构流块（SFB）来解耦特征方向与空间位置的关系，并利用各向异性结构门控（ASG）和先验调制流动（PMF）进行信息流的整合。同时结合分层空间调节器（HSR）和高保真焦点单元（HFFU），提高低对比度环境下的信号质量。", "result": "在地质数据集LROC-Lineament、LineaMapper和GeoCrack上进行了广泛的实验，Fluxamba达到了新的state-of-the-art水平。特别是在挑战性的LROC-Lineament数据集上，F1得分为89.22%，mIoU为89.87%。", "conclusion": "Fluxamba模型不仅在分割精度上取得了显著的改善，而且保持了实时推理速度，参数量和浮点运算次数大幅减少，为轻量化部署提供了可行性。"}}
{"id": "2601.17287", "pdf": "https://arxiv.org/pdf/2601.17287", "abs": "https://arxiv.org/abs/2601.17287", "authors": ["Yanrong Chen", "Xihan Bian"], "title": "Real-Time Synchronized Interaction Framework for Emotion-Aware Humanoid Robots", "categories": ["cs.RO"], "comment": "6 pages, 6 figures", "summary": "As humanoid robots increasingly introduced into social scene, achieving emotionally synchronized multimodal interaction remains a significant challenges. To facilitate the further adoption and integration of humanoid robots into service roles, we present a real-time framework for NAO robots that synchronizes speech prosody with full-body gestures through three key innovations: (1) A dual-channel emotion engine where large language model (LLM) simultaneously generates context-aware text responses and biomechanically feasible motion descriptors, constrained by a structured joint movement library; (2) Duration-aware dynamic time warping for precise temporal alignment of speech output and kinematic motion keyframes; (3) Closed-loop feasibility verification ensuring gestures adhere to NAO's physical joint limits through real-time adaptation. Evaluations show 21% higher emotional alignment compared to rule-based systems, achieved by coordinating vocal pitch (arousal-driven) with upper-limb kinematics while maintaining lower-body stability. By enabling seamless sensorimotor coordination, this framework advances the deployment of context-aware social robots in dynamic applications such as personalized healthcare, interactive education, and responsive customer service platforms.", "AI": {"tldr": "本文介绍了一个实时框架，用于实现NAO机器人在情感同步的多模态交互中，通过语音韵律与全身动作的精确同步来提升表现。", "motivation": "随着人形机器人越来越多地被引入社会场景，要在情感上实现高度同步的多模态互动仍然是一个重大挑战。本文旨在促进人形机器人进一步融入服务角色。", "method": "该框架通过三项创新实现了这一目标：(1) 双通道情绪引擎同时生成基于上下文的文字响应和生物力学可行的动作描述符；(2) 基于时长的动态时间规整用于精确同步语音输出和运动关键帧；(3) 闭环可行性验证确保手势符合NAO的实际关节限制。", "result": "评估表明，与规则基础系统相比，情感对齐提高了21%，通过协调声调（受唤醒驱动）与上肢运动学的同时保持下肢稳定来实现。", "conclusion": "该框架通过对无缝的感官运动协调的支持，推进了上下文感知社交机器人在个性化医疗、互动教育和响应客户服务等动态应用中的部署。"}}
{"id": "2601.17284", "pdf": "https://arxiv.org/pdf/2601.17284", "abs": "https://arxiv.org/abs/2601.17284", "authors": ["Yaokun Liu", "Yifan Liu", "Phoebe Mbuvi", "Zelin Li", "Ruichen Yao", "Gawon Lim", "Dong Wang"], "title": "Mind the Ambiguity: Aleatoric Uncertainty Quantification in LLMs for Safe Medical Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at The Web Conference 2026 (WWW 2026)", "summary": "The deployment of Large Language Models in Medical Question Answering is severely hampered by ambiguous user queries, a significant safety risk that demonstrably reduces answer accuracy in high-stakes healthcare settings. In this paper, we formalize this challenge by linking input ambiguity to aleatoric uncertainty (AU), which is the irreducible uncertainty arising from underspecified input. To facilitate research in this direction, we construct CV-MedBench, the first benchmark designed for studying input ambiguity in Medical QA. Using this benchmark, we analyze AU from a representation engineering perspective, revealing that AU is linearly encoded in LLM's internal activation patterns. Leveraging this insight, we introduce a novel AU-guided \"Clarify-Before-Answer\" framework, which incorporates AU-Probe - a lightweight module that detects input ambiguity directly from hidden states. Unlike existing uncertainty estimation methods, AU-Probe requires neither LLM fine-tuning nor multiple forward passes, enabling an efficient mechanism to proactively request user clarification and significantly enhance safety. Extensive experiments across four open LLMs demonstrate the effectiveness of our QA framework, with an average accuracy improvement of 9.48% over baselines. Our framework provides an efficient and robust solution for safe Medical QA, strengthening the reliability of health-related applications. The code is available at https://github.com/yaokunliu/AU-Med.git, and the CV-MedBench dataset is released on Hugging Face at https://huggingface.co/datasets/yaokunl/CV-MedBench.", "AI": {"tldr": "本文提出了一种新颖的框架，通过量化输入模糊性来提高大型语言模型在医疗问答中的准确性。", "motivation": "研究旨在解决医学问答中由于用户查询模糊造成的不确定性问题，并减少由此带来的安全风险。", "method": "构建了一个名为CV-MedBench的新基准来评估输入模糊性，发现模糊性与内部激活模式线性相关。提出了一种新型的\"先澄清后回答\"框架及AU-Probe模块以检测输入模糊性。", "result": "实验表明该框架显著提高了四个开源大型语言模型在医学问答中的准确率，平均提升了9.48%。", "conclusion": "所提出的框架为安全医疗问答提供了有效且健壮的解决方案，增强了健康应用程序的可靠性。"}}
{"id": "2601.17280", "pdf": "https://arxiv.org/pdf/2601.17280", "abs": "https://arxiv.org/abs/2601.17280", "authors": ["David Condrey"], "title": "On the Insecurity of Keystroke-Based AI Authorship Detection: Timing-Forgery Attacks Against Motor-Signal Verification", "categories": ["cs.CR", "cs.AI", "cs.HC"], "comment": "9 pages, 1 figure, 7 tables. Code available at anc/ folder", "summary": "Recent proposals advocate using keystroke timing signals, specifically the coefficient of variation ($δ$) of inter-keystroke intervals, to distinguish human-composed text from AI-generated content. We demonstrate that this class of defenses is insecure against two practical attack classes: the copy-type attack, in which a human transcribes LLM-generated text producing authentic motor signals, and timing-forgery attacks, in which automated agents sample inter-keystroke intervals from empirical human distributions. Using 13,000 sessions from the SBU corpus and three timing-forgery variants (histogram sampling, statistical impersonation, and generative LSTM), we show all attacks achieve $\\ge$99.8% evasion rates against five classifiers. While detectors achieve AUC=1.000 against fully-automated injection, they classify $\\ge$99.8% of attack samples as human with mean confidence $\\ge$0.993. We formalize a non-identifiability result: when the detector observes only timing, the mutual information between features and content provenance is zero for copy-type attacks. Although composition and transcription produce statistically distinguishable motor patterns (Cohen's d=1.28), both yield $δ$ values 2-4x above detection thresholds, rendering the distinction security-irrelevant. These systems confirm a human operated the keyboard, but not whether that human originated the text. Securing provenance requires architectures that bind the writing process to semantic content.", "AI": {"tldr": "本文探讨了基于击键时间信号的AI作者检测系统的脆弱性，并展示了两种攻击方法可以绕过这些系统。", "motivation": "近年来，有人提出使用击键间的时间变异系数来区分人类编写的文本和AI生成的内容。然而，这项研究动机在于验证这种防御机制是否真的安全，特别是针对实际攻击情况下的安全性。", "method": "研究人员采用了两种类型的攻击：抄写型攻击，即人类转录LLM生成的文本；时间伪造攻击，即自动化代理从真实的人类击键分布中抽样。他们使用了SBU语料库中的13000个会话以及三种不同的时间伪造技术进行实验。", "result": "所有的攻击方法都达到了99.8%以上的逃避率。虽然检测器在全自动注入情况下能达到AUC=1.0，但是对攻击样本的分类准确度仅为0.2%，平均置信度高于0.993。", "conclusion": "研究证实了仅凭时间信号无法区分文本的真实来源，无论是抄写还是原创作都会产生类似的变异系数。要确保内容的真实性，需要设计能够将写作过程与语义内容绑定的系统架构。"}}
{"id": "2601.17279", "pdf": "https://arxiv.org/pdf/2601.17279", "abs": "https://arxiv.org/abs/2601.17279", "authors": ["Sonu Kumar", "Lavanya Vinnakota", "Mukul Lokhande", "Santosh Kumar Vishvakarma", "Adam Teman"], "title": "SPADE: A SIMD Posit-enabled compute engine for Accelerating DNN Efficiency", "categories": ["cs.AR", "cs.CV", "eess.IV"], "comment": null, "summary": "The growing demand for edge-AI systems requires arithmetic units that balance numerical precision, energy efficiency, and compact hardware while supporting diverse formats. Posit arithmetic offers advantages over floating- and fixed-point representations through its tapered precision, wide dynamic range, and improved numerical robustness. This work presents SPADE, a unified multi-precision SIMD Posit-based multiplyaccumulate (MAC) architecture supporting Posit (8,0), Posit (16,1), and Posit (32,2) within a single framework. Unlike prior single-precision or floating/fixed-point SIMD MACs, SPADE introduces a regime-aware, lane-fused SIMD Posit datapath that hierarchically reuses Posit-specific submodules (LOD, complementor, shifter, and multiplier) across 8/16/32-bit precisions without datapath replication. FPGA implementation on a Xilinx Virtex-7 shows 45.13% LUT and 80% slice reduction for Posit (8,0), and up to 28.44% and 17.47% improvement for Posit (16,1) and Posit (32,2) over prior work, with only 6.9% LUT and 14.9% register overhead for multi-precision support. ASIC results across TSMC nodes achieve 1.38 GHz at 6.1 mW (28 nm). Evaluation on MNIST, CIFAR-10/100, and alphabet datasets confirms competitive inference accuracy.", "AI": {"tldr": "本论文介绍了SPADE，一种基于SIMD Posit的多精度MAC架构，用于加速深度神经网络效率。", "motivation": "边缘AI系统需要在数值精确度、能源效率和硬件紧凑性之间取得平衡，支持多种格式。Posit算术通过其渐变精度、宽动态范围和改进的数值鲁棒性提供了优势。", "method": "SPADE引入了一个基于Posit的SIMD乘积累加架构，该架构能够在单一框架内支持8位、16位和32位的Posit格式。它利用了层级复用的Posit特定子模块来避免数据路径复制。", "result": "在Xilinx Virtex-7 FPGA上的实现显示，在使用不同精度时，LUT和切片减少率分别为45.13%到6.9%，以及80%到14.9%。ASIC结果在TSMC节点上达到1.38 GHz和6.1 mW（28 nm）。实验结果显示了在MNIST、CIFAR-10/100和字母数据集上的竞争推断精度。", "conclusion": "SPADE架构展示了其在支持多精度的同时，减少了硬件资源，并保持了良好的性能和能效比。"}}
{"id": "2601.17275", "pdf": "https://arxiv.org/pdf/2601.17275", "abs": "https://arxiv.org/abs/2601.17275", "authors": ["Lianlei Shan", "Han Chen", "Yixuan Wang", "Zhenjie Liu", "Wei Li"], "title": "Latent-Space Contrastive Reinforcement Learning for Stable and Efficient LLM Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages,", "summary": "While Large Language Models (LLMs) demonstrate exceptional performance in surface-level text generation, their nature in handling complex multi-step reasoning tasks often remains one of ``statistical fitting'' rather than systematic logical deduction. Traditional Reinforcement Learning (RL) attempts to mitigate this by introducing a ``think-before-speak'' paradigm. However, applying RL directly in high-dimensional, discrete token spaces faces three inherent challenges: sample-inefficient rollouts, high gradient estimation variance, and the risk of catastrophic forgetting. To fundamentally address these structural bottlenecks, we propose \\textbf{DeepLatent Reasoning (DLR)}, a latent-space bidirectional contrastive reinforcement learning framework. This framework shifts the trial-and-error cost from expensive token-level full sequence generation to the continuous latent manifold. Specifically, we introduce a lightweight assistant model to efficiently sample $K$ reasoning chain encodings within the latent space. These encodings are filtered via a dual reward mechanism based on correctness and formatting; only high-value latent trajectories are fed into a \\textbf{frozen main model} for single-pass decoding. To maximize reasoning diversity while maintaining coherence, we design a contrastive learning objective to enable directed exploration within the latent space. Since the main model parameters remain frozen during optimization, this method mathematically eliminates catastrophic forgetting. Experiments demonstrate that under comparable GPU computational budgets, DLR achieves more stable training convergence, supports longer-horizon reasoning chains, and facilitates the sustainable accumulation of reasoning capabilities, providing a viable path toward reliable and scalable reinforcement learning for LLMs.", "AI": {"tldr": "本文提出了DeepLatent Reasoning（DLR），一种在潜在空间进行双向对比强化学习的框架，以解决大型语言模型（LLMs）在复杂多步推理任务中的问题。", "motivation": "传统的强化学习（RL）方法试图通过引入“思考后再行动”的范式来改善LLM处理多步骤逻辑推理的能力。然而，在高维、离散标记空间中直接应用RL面临样本效率低下、梯度估计方差大和灾难性遗忘的风险。", "method": "DLR框架将试错成本从昂贵的完整序列生成转移到连续潜在流形上，使用轻量级辅助模型在潜在空间内高效采样K个推理链编码。这些编码通过基于正确性和格式的双奖励机制进行筛选，并仅向冻结的主要模型提供高价值潜在线条以单次解码。", "result": "实验表明，在相似的GPU计算预算下，DLR实现了更稳定的训练收敛、支持更长的推理链条以及持续积累推理能力。", "conclusion": "该方法通过数学上消除灾难性遗忘提供了可靠且可扩展的强化学习途径，适用于LLM。"}}
{"id": "2601.17271", "pdf": "https://arxiv.org/pdf/2601.17271", "abs": "https://arxiv.org/abs/2601.17271", "authors": ["Kun Huang", "Fang-Lue Zhang", "Neil Dodgson"], "title": "Cross360: 360° Monocular Depth Estimation via Cross Projections Across Scales", "categories": ["cs.CV"], "comment": "TIP, 12 pages", "summary": "360° depth estimation is a challenging research problem due to the difficulty of finding a representation that both preserves global continuity and avoids distortion in spherical images. Existing methods attempt to leverage complementary information from multiple projections, but struggle with balancing global and local consistency. Their local patch features have limited global perception, and the combined global representation does not address discrepancies in feature extraction at the boundaries between patches. To address these issues, we propose Cross360, a novel cross-attention-based architecture integrating local and global information using less-distorted tangent patches along with equirectangular features. Our Cross Projection Feature Alignment module employs cross-attention to align local tangent projection features with the equirectangular projection's 360° field of view, ensuring each tangent projection patch is aware of the global context. Additionally, our Progressive Feature Aggregation with Attention module refines multi-scaled features progressively, enhancing depth estimation accuracy. Cross360 significantly outperforms existing methods across most benchmark datasets, especially those in which the entire 360° image is available, demonstrating its effectiveness in accurate and globally consistent depth estimation. The code and model are available at https://github.com/huangkun101230/Cross360.", "AI": {"tldr": "本文提出了Cross360，一种基于交叉注意力的架构，用于通过跨尺度的交叉投影整合局部和全局信息进行360度单目深度估计。", "motivation": "现有的方法在保持球形图像全局连续性的同时避免失真方面存在困难，难以平衡全球和局部一致性。本文旨在解决这些问题，并提供更精确且具有全局一致性的深度估计。", "method": "Cross360采用了一个交叉投影特征对齐模块来利用交叉注意力将局部切线投影特性与等距矩形投影的360度视野对齐，确保每个切线投影补丁都能了解全局上下文。此外，还使用了带有注意力机制的渐进特征聚合模块来逐步细化多尺度特征。", "result": "Cross360在大多数基准数据集上显著优于现有方法，尤其是在整个360度图像可用的情况下，展示了其在准确和全局一致深度估计中的有效性。", "conclusion": "本文通过提出Cross360证明了跨尺度的交叉投影可以有效整合局部和全局信息以提高360度单目深度估计的准确性，并且该方法具有良好的全球一致性。"}}
{"id": "2601.17270", "pdf": "https://arxiv.org/pdf/2601.17270", "abs": "https://arxiv.org/abs/2601.17270", "authors": ["Max McKinnon", "Samir Khaki", "Chandan KA Reddy", "William Huang"], "title": "Window Size Versus Accuracy Experiments in Voice Activity Detectors", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": ":68T10ACM Class:I.2.7; H.5.5", "summary": "Voice activity detection (VAD) plays a vital role in enabling applications such as speech recognition. We analyze the impact of window size on the accuracy of three VAD algorithms: Silero, WebRTC, and Root Mean Square (RMS) across a set of diverse real-world digital audio streams. We additionally explore the use of hysteresis on top of each VAD output. Our results offer practical references for optimizing VAD systems. Silero significantly outperforms WebRTC and RMS, and hysteresis provides a benefit for WebRTC.", "AI": {"tldr": "本文研究了窗口大小对三种语音活动检测算法（Silero、WebRTC和RMS）准确率的影响，并探讨了迟滞效应的应用。", "motivation": "提高语音识别等应用中VAD系统的性能，通过优化窗口尺寸选择和使用迟滞效应来提升准确性。", "method": "分析了在多种真实世界音频流上的三种不同VAD算法（Silero、WebRTC、RMS）的准确率，并测试了每种算法加入迟滞效应后的表现。", "result": "研究结果显示，Silero的表现显著优于其他两种算法，并且迟滞效应能够改善WebRTC的性能。", "conclusion": "该论文提供了关于如何通过调整窗口尺寸和利用迟滞效应来优化VAD系统实际操作中的参考指南。"}}
{"id": "2601.17260", "pdf": "https://arxiv.org/pdf/2601.17260", "abs": "https://arxiv.org/abs/2601.17260", "authors": ["Marco Pollanen"], "title": "The Viscosity of Logic: Phase Transitions and Hysteresis in DPO Alignment", "categories": ["cs.LG", "cs.AI"], "comment": "10 Pages, 5 Figures", "summary": "Direct Preference Optimization (DPO) is often tuned as if increasing alignment pressure (controlled by $β$) yields progressively \"better\" behavior. We instead treat $β$ as a control parameter and densely sweep it for three 7B open-weight families under a fixed DPO recipe. In Mistral, capability is sharply non-monotonic: aggregated logic-probe margins become positive only in a narrow band near $β\\approx 10^{-2}$ and revert outside it, with boundary points that are seed-sensitive. Across architectures under the same sweep, we observe qualitatively different response modes: sharp reorganization in Mistral, selective changes in Llama, and smooth trade-offs in Qwen. Critically, the DPO preference margin can anticorrelate with reasoning capability (Pearson $r=-0.91$ for Llama logic), so margin-based selection can prefer capability-impaired models. Training path also matters: exposure to high $β$ induces capability losses that persist even after $β$ is reduced (hysteresis). These findings motivate capability-resolved evaluation across the $β$ landscape rather than reliance on margins or aggregate benchmarks.", "AI": {"tldr": "论文研究了不同控制参数β值下的直接偏好优化(DPO)方法在三种7B开放权重模型（Mistral、Llama和Qwen）中的表现。", "motivation": "作者旨在探讨增加对齐压力是否真的能持续改进模型行为，并发现DPO偏好边缘可能与推理能力负相关，从而激励了对β值进行详细研究的重要性。", "method": "作者将β视为控制参数，在固定的DPO配方下进行了密集的扫描，观察不同架构在相同扫描条件下的响应模式。", "result": "Mistral模型的能力呈尖锐非单调性变化；Llama模型显示出DPO偏好边缘与推理能力负相关；Qwen则表现出平稳的权衡。还发现训练路径影响显著，高β值暴露导致的能力损失即使降低β值也无法完全恢复。", "conclusion": "这些结果表明在评估时需要考虑能力分解而不是仅仅依赖于边际或综合基准，并建议对β景观进行更细致的能力分辨评价。"}}
{"id": "2601.17259", "pdf": "https://arxiv.org/pdf/2601.17259", "abs": "https://arxiv.org/abs/2601.17259", "authors": ["Angad Singh Ahuja", "Aarush Ram Anandh"], "title": "Inference-Time Loss-Guided Colour Preservation in Diffusion Sampling", "categories": ["cs.CV", "cs.GR", "cs.LG"], "comment": "25 Pages, 12 Figures, 3 Tables, 5 Appendices, 8 Algorithms", "summary": "Precise color control remains a persistent failure mode in text-to-image diffusion systems, particularly in design-oriented workflows where outputs must satisfy explicit, user-specified color targets. We present an inference-time, region-constrained color preservation method that steers a pretrained diffusion model without any additional training. Our approach combines (i) ROI-based inpainting for spatial selectivity, (ii) background-latent re-imposition to prevent color drift outside the ROI, and (iii) latent nudging via gradient guidance using a composite loss defined in CIE Lab and linear RGB. The loss is constructed to control not only the mean ROI color but also the tail of the pixelwise error distribution through CVaR-style and soft-maximum penalties, with a late-start gate and a time-dependent schedule to stabilize guidance across denoising steps. We show that mean-only baselines can satisfy average color constraints while producing perceptually salient local failures, motivating our distribution-aware objective. The resulting method provides a practical, training-free mechanism for targeted color adherence that can be integrated into standard Stable Diffusion inpainting pipelines.", "AI": {"tldr": "本文提出了一种在扩散模型推理时进行区域约束的颜色保持方法，无需额外训练就能精确控制颜色。", "motivation": "文本到图像的扩散系统中仍存在难以精准控制颜色的问题，在设计导向的工作流程中输出必须满足用户指定的颜色目标。", "method": "该方法结合了基于ROI的修复以实现空间选择性、背景潜变量重新施加防止区域外颜色漂移，以及通过定义在CIE Lab和线性RGB中的复合损失函数进行潜变量微调。损失函数设计控制平均区域颜色及其像素误差分布的尾部，并采用延迟启动门控和时间依赖调度来稳定去噪步骤的指导。", "result": "研究表明，仅基于均值的方法可以满足平均颜色约束但产生感知显著的局部失败，因此动机在于实现分布感知目标。该方法提供了无需训练即可针对目标颜色的实用机制。", "conclusion": "提出的方法提供了一种在标准稳定扩散修复管道中集成的颜色依从性的有效、无训练的机制。"}}
{"id": "2601.17258", "pdf": "https://arxiv.org/pdf/2601.17258", "abs": "https://arxiv.org/abs/2601.17258", "authors": ["João Pereira", "Vasco Lopes", "João Neves", "David Semedo"], "title": "FineVAU: A Novel Human-Aligned Benchmark for Fine-Grained Video Anomaly Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Video Anomaly Understanding (VAU) is a novel task focused on describing unusual occurrences in videos. Despite growing interest, the evaluation of VAU remains an open challenge. Existing benchmarks rely on n-gram-based metrics (e.g., BLEU, ROUGE-L) or LLM-based evaluation. The first fails to capture the rich, free-form, and visually grounded nature of LVLM responses, while the latter focuses on assessing language quality over factual relevance, often resulting in subjective judgments that are misaligned with human perception. In this work, we address this issue by proposing FineVAU, a new benchmark for VAU that shifts the focus towards rich, fine-grained and domain-specific understanding of anomalous videos. We formulate VAU as a three-fold problem, with the goal of comprehensively understanding key descriptive elements of anomalies in video: events (What), participating entities (Who) and location (Where). Our benchmark introduces a) FVScore, a novel, human-aligned evaluation metric that assesses the presence of critical visual elements in LVLM answers, providing interpretable, fine-grained feedback; and b) FineW3, a novel, comprehensive dataset curated through a structured and fully automatic procedure that augments existing human annotations with high quality, fine-grained visual information. Human evaluation reveals that our proposed metric has a superior alignment with human perception of anomalies in comparison to current approaches. Detailed experiments on FineVAU unveil critical limitations in LVLM's ability to perceive anomalous events that require spatial and fine-grained temporal understanding, despite strong performance on coarse grain, static information, and events with strong visual cues.", "AI": {"tldr": "本文提出了FineVAU，一个新的视频异常理解基准，旨在更细致和具体地评估视频中的异常事件。", "motivation": "现有基准依赖于n-gram或LLM的评估方法不能很好地捕捉到丰富的、自由形式的答案，并且经常与人类感知不一致。因此，本研究提出一个更加精细和领域特定的方法来评价视频异常理解。", "method": "FineVAU包括FVScore，一种新的评估指标，以及FineW3数据集，通过结构化的自动化过程增强现有的人类注释，提供高质量的细粒度视觉信息。", "result": "人类评估表明，提出的FVScore与人类对异常视频感知有更好的一致性。实验显示了LVLM在处理需要空间和细粒度时间理解的异常事件方面的局限性。", "conclusion": "FineVAU为评估视频中的异常行为提供了更加细致、具体的视角，并揭示了现有模型在某些复杂情况下的不足之处。"}}
{"id": "2601.17256", "pdf": "https://arxiv.org/pdf/2601.17256", "abs": "https://arxiv.org/abs/2601.17256", "authors": ["Gabriel Geffen", "Jun Zhao", "Mingfeng Shang", "Shian Wang", "Yao-Jan Wu"], "title": "Safety, Mobility, and Environmental Impacts of Driver-Assistance-Enabled Electric Vehicles: An Empirical Study", "categories": ["cs.ET", "stat.AP"], "comment": null, "summary": "The advancement of vehicle automation and the growing adoption of electric vehicles (EVs) are reshaping transportation systems. While fully automated vehicles are expected to improve traffic stability, efficiency, and sustainability, recent studies suggest that partially automated vehicles, such as those equipped with adaptive cruise control (ACC), may adversely affect traffic flow. These drawbacks may not extend to ACC-enabled EVs due to their distinct mechanical characteristics, including regenerative braking and smoother torque delivery. As a result, the impacts of EVs operating under ACC remain insufficiently understood. To address this gap, this study develops an empirical framework using the OpenACC dataset to compare ACC-enabled EVs and internal combustion engine vehicles. Dynamic time warping aligns comparable lead-vehicle trajectories. Results show that EVs exhibit smoother speed profiles, lower speed variability, and shorter spacing, leading to higher efficiency. EVs reduce critical safety events by over 85% and lower platoon-level emissions by up to 26.2%.", "AI": {"tldr": "研究了配备自适应巡航控制（ACC）的电动汽车在安全性、流动性和环境影响方面的影响。", "motivation": "尽管完全自动化的车辆有望改善交通稳定性和效率，但部分自动化车辆如带有自适应巡航控制功能的车辆可能对交通流产生不利影响。然而，这些缺点可能不适用于配备了ACC的电动汽车，因为电动汽车具有再生制动和更平稳扭矩传递的独特机械特性。", "method": "使用OpenACC数据集开发了实证框架，并通过动态时间规整（DTW）算法来对齐可比较的前车轨迹，比较了配备自适应巡航控制的电动汽车与内燃机车辆的表现。", "result": "结果表明，电动汽车表现出更平滑的速度分布、更低的速度变异性以及较短的距离间隔，从而提高效率。同时，它们减少了超过85%的关键安全事件，并降低了车队级别的排放达26.2%。", "conclusion": "配备自适应巡航控制的电动汽车在安全性、流动性和环境影响方面表现出显著优势，这为未来的交通系统提供了重要的启示和数据支持。"}}
{"id": "2601.17254", "pdf": "https://arxiv.org/pdf/2601.17254", "abs": "https://arxiv.org/abs/2601.17254", "authors": ["Takato Yasuno"], "title": "Multi-stage Bridge Inspection System: Integrating Foundation Models with Location Anonymization", "categories": ["cs.CV"], "comment": "8 pages, 5 figures, 2 tables", "summary": "In Japan, civil infrastructure condition monitoring is mandated through visual inspection every five years. Field-captured damage images frequently contain concrete cracks and rebar exposure, often accompanied by construction signs revealing regional information. To enable safe infrastructure use without causing public anxiety, it is essential to protect regional information while accurately extracting damage features and visualizing key indicators for repair decision-making. This paper presents an open-source bridge damage detection system with regional privacy protection capabilities. We employ Segment Anything Model (SAM) 3 for rebar corrosion detection and utilize DBSCAN for automatic completion of missed regions. Construction sign regions are detected and protected through Gaussian blur. Four preprocessing methods improve OCR accuracy, and GPU optimization enables 1.7-second processing per image. The technology stack includes SAM3, PyTorch, OpenCV, pytesseract, and scikit-learn, achieving efficient bridge inspection with regional information protection.", "AI": {"tldr": "本文介绍了一个多阶段的桥梁检测系统，集成了基础模型并实现了位置匿名化。", "motivation": "为了确保基础设施的安全使用同时避免公众焦虑，在日本每五年进行一次视觉检查是强制性的。该论文旨在保护区域信息的同时准确提取损坏特征，并为维修决策可视化关键指标。", "method": "采用Segment Anything Model (SAM) 3进行钢筋腐蚀检测，利用DBSCAN自动补全遗漏的区域。通过高斯模糊处理建筑标志区域以达到保护隐私的目的。使用了四种预处理方法提高OCR准确性，并通过GPU优化实现每张图像1.7秒的处理速度。", "result": "技术栈包括SAM3、PyTorch、OpenCV、pytesseract和scikit-learn，实现了高效的桥梁检查并保护区域信息。", "conclusion": "该系统在确保高效检测的同时，成功地解决了区域隐私保护的问题。"}}
{"id": "2601.17251", "pdf": "https://arxiv.org/pdf/2601.17251", "abs": "https://arxiv.org/abs/2601.17251", "authors": ["Yunuo Chen", "Yafei Hu", "Lingfeng Sun", "Tushar Kusnur", "Laura Herlant", "Chenfanfu Jiang"], "title": "EMPM: Embodied MPM for Modeling and Simulation of Deformable Objects", "categories": ["cs.RO"], "comment": null, "summary": "Modeling deformable objects - especially continuum materials - in a way that is physically plausible, generalizable, and data-efficient remains challenging across 3D vision, graphics, and robotic manipulation. Many existing methods oversimplify the rich dynamics of deformable objects or require large training sets, which often limits generalization. We introduce embodied MPM (EMPM), a deformable object modeling and simulation framework built on a differentiable Material Point Method (MPM) simulator that captures the dynamics of challenging materials. From multi-view RGB-D videos, our approach reconstructs geometry and appearance, then uses an MPM physics engine to simulate object behavior by minimizing the mismatch between predicted and observed visual data. We further optimize MPM parameters online using sensory feedback, enabling adaptive, robust, and physics-aware object representations that open new possibilities for robotic manipulation of complex deformables. Experiments show that EMPM outperforms spring-mass baseline models. Project website: https://embodied-mpm.github.io.", "AI": {"tldr": "介绍了一种基于可微分材料点法（MPM）模拟器的变形物体建模和仿真框架——EMPM，该方法能够通过多视角RGB-D视频重建几何形状和外观，并使用物理引擎进行物体行为模拟。", "motivation": "现有的许多方法在处理变形物体时会简化复杂的动态特性或需要大量的训练集，这限制了其泛化能力。因此，研究旨在提供一种物理上合理、具有广泛适用性和数据高效的建模方法。", "method": "从多视角RGB-D视频中重建几何形状和外观，并利用MPM物理引擎模拟物体行为来最小化预测与观察视觉数据之间的差异。进一步通过感官反馈在线优化MPM参数，实现自适应、稳健且符合物理学的物体表征。", "result": "实验表明，EMPM在处理复杂变形物体时的表现优于弹簧质量基线模型。", "conclusion": "该研究为机器人对复杂变形物体的操作提供了新的可能性，并展示了通过结合视觉数据和物理引擎优化参数来增强模型表现的有效性。"}}
{"id": "2601.17249", "pdf": "https://arxiv.org/pdf/2601.17249", "abs": "https://arxiv.org/abs/2601.17249", "authors": ["Peter Bryan", "Rejin John Varghese", "Dario Farina"], "title": "Quantifying Ergonomics in the Elevate Soft Robotic Suit", "categories": ["cs.RO"], "comment": "5 pages, 3 figures. Submitted to IEEE-EMBC 2026", "summary": "Soft robotic suits have the potential to rehabilitate, assist, and augment the human body. The low weight, cost, and minimal form-factor of these devices make them ideal for daily use by both healthy and impaired individuals. However, challenges associated with data-driven, user-specific, and comfort-first design of human-robot interfaces using soft materials limit their widespread translation and adoption. In this work, we present the quantitative evaluation of ergonomics and comfort of the Elevate suit - a cable driven soft robotic suit that assists shoulder elevation. Using a motion-capture system and force sensors, we measured the suit's ergonomics during assisted shoulder elevation up to 70 degrees. Two 4-hour sessions were conducted with one subject, involving transmitting cable tensions of up to 200N with no discomfort reported. We estimated that the pressure applied to the shoulder during assisted movements was within the range seen in a human grasp (approximately 69.1-85.1kPa), and estimated volumetric compression of <3% and <8% across the torso and upper arm, respectively. These results provide early validation of Elevate's ergonomic design in preparation for future studies with patient groups.", "AI": {"tldr": "评估Elevate软机器人套装在辅助肩部抬升过程中的人体工程学和舒适度。", "motivation": "研究动机在于解决基于数据驱动、用户特定且以舒适性为主的人机界面设计挑战，推动软材料制成的设备广泛使用。", "method": "通过运动捕捉系统和力传感器测量Elevate套装在辅助肩部抬升过程中的人体工程学特性，并进行为期两小时四次实验，其中单个受试者没有报告不适。", "result": "研究结果显示压力范围约为69.1-85.1kPa，在人类抓握范围内；身体和上臂的体积压缩分别为小于3%和小于8%，且在实验中无不适感。", "conclusion": "这些结果初步验证了Elevate套装的人体工程学设计，为进一步的研究提供了基础。"}}
{"id": "2601.17240", "pdf": "https://arxiv.org/pdf/2601.17240", "abs": "https://arxiv.org/abs/2601.17240", "authors": ["Shaoze Zhou", "Diana Nelly Rivera Rodriguez", "Pedro Remior", "Joaquin Frangi", "Lingyao Li", "Renkai Ma", "Janet G. Johnson", "Christine Lisetti", "Chen Chen"], "title": "Exploring Needs and Design Opportunities for Proactive Information Support in In-Person Small-Group Conversations", "categories": ["cs.HC"], "comment": null, "summary": "In-person small-group conversations play a crucial role in everyday life; however, facilitating effective group interaction can be challenging, as the real-time nature demands full attention, offers no opportunity for revision, and requires interpreting non-verbal cues. Using Mixed Reality to provide proactive information support shows promise in helping individuals engage in and contribute to group conversations. We present a preliminary participatory design and qualitative study (N = 10) using focus groups and two technology probes to explore the opportunities of designing proactive information support in in-person small-group conversations. We reveal key design opportunities concerning how to maximize the benefits of proactive information support and how to effectively design such supporting information. Our study is crucial for paving the way toward designing future proactive AI agents to enable the paradigm of augmented in-person small-group conversation experience.", "AI": {"tldr": "论文探讨了使用混合现实为面对面小型群体对话提供主动信息支持的设计机会。", "motivation": "作者指出，尽管面对面的小型群体对话在日常生活中至关重要，但有效的群组互动具有挑战性。因此，研究希望通过混合现实技术提供主动信息支持来帮助人们更好地参与和贡献于对话。", "method": "采用初步的参与式设计和定性研究方法（N = 10），包括焦点小组讨论及两种技术探测器来探索在面对面小型群体对话中设计主动信息支持的机会。", "result": "揭示了有关如何最大化主动信息支持的好处以及如何有效地设计此类辅助信息的关键设计机会。", "conclusion": "这项研究为未来的设计开辟了道路，旨在通过增强现实小群组对话体验，使未来的主动AI代理得以实现。"}}
{"id": "2601.17238", "pdf": "https://arxiv.org/pdf/2601.17238", "abs": "https://arxiv.org/abs/2601.17238", "authors": ["Rishi Vanukuru", "Krithik Ranjan", "Ada Yi Zhao", "David Lindero", "Gunilla H. Berndtsson", "Gregoire Phillips", "Amy Banić", "Mark D. Gross", "Ellen Yi-Luen Do"], "title": "Studying Mobile Spatial Collaboration across Video Calls and Augmented Reality", "categories": ["cs.HC"], "comment": "To appear in the Proceedings of the ACM on Human-Computer Interaction, Volume 10, Issue 2, Article CSCW037. 31 pages, 12 figures", "summary": "Mobile video calls are widely used to share information about real-world objects and environments with remote collaborators. While these calls provide valuable visual context in real time, the experience of interacting with people and moving around a space is significantly reduced when compared to co-located conversations. Recent work has demonstrated the potential of Mobile Augmented Reality applications to enable more spatial forms of collaboration across distance. To better understand the dynamics of mobile AR collaboration and how this medium compares against the status quo, we conducted a comparative structured observation study to analyze people's perception of space and interaction with remote collaborators across mobile video calls and AR-based calls. Fourteen pairs of participants completed a spatial collaboration task using each medium. Through a mixed-methods analysis of session videos, transcripts, motion logs, post-task exercises, and interviews, we highlight how the choice of medium influences the roles and responsibilities that collaborators take on and the construction of a shared language for coordination. We discuss the importance of spatial reasoning with one's body, how video calls help participants \"be on the same page\" more directly, and how AR calls enable both onsite and remote collaborators to engage with the space and each other in ways that resemble in-person interaction. Our study offers a nuanced view of the benefits and limitations of both mediums, and we conclude with a discussion of design implications for future systems that integrate mobile video and AR to better support spatial collaboration in its many forms.", "AI": {"tldr": "研究比较了移动视频通话和增强现实（AR）在支持远程空间协作方面的动态和差异。", "motivation": "了解在不同媒介下，人们对空间感知及与远程合作者互动的体验，并探索未来系统设计中整合移动视频和AR以更好地支持各种形式的空间协作的可能性。", "method": "通过结构化的观察研究，让14对参与者使用两种媒介完成一项空间协作任务。利用会话视频、访谈记录、运动日志等进行混合方法分析。", "result": "研究表明不同的媒介会影响合作者的角色和责任的分配以及共同协调语言的构建。移动AR允许在场与远程合作者以类似于面对面的方式参与互动，而视频通话有助于参与者更直接地“保持在同一页面上”。", "conclusion": "研究提供了对两种媒介优缺点的细致见解，并讨论了未来整合移动视频和AR系统的设计建议，以支持各种形式的空间协作。"}}
{"id": "2601.17237", "pdf": "https://arxiv.org/pdf/2601.17237", "abs": "https://arxiv.org/abs/2601.17237", "authors": ["Mike Ranzinger", "Greg Heinrich", "Collin McCarthy", "Jan Kautz", "Andrew Tao", "Bryan Catanzaro", "Pavlo Molchanov"], "title": "C-RADIOv4 (Tech Report)", "categories": ["cs.CV"], "comment": null, "summary": "By leveraging multi-teacher distillation, agglomerative vision backbones provide a unified student model that retains and improves the distinct capabilities of multiple teachers. In this tech report, we describe the most recent release of the C-RADIO family of models, C-RADIOv4, which builds upon AM-RADIO/RADIOv2.5 in design, offering strong improvements on key downstream tasks at the same computational complexity. We release -SO400M (412M params), and -H (631M) model variants, both trained with an updated set of teachers: SigLIP2, DINOv3, and SAM3. In addition to improvements on core metrics and new capabilities from imitating SAM3, the C-RADIOv4 model family further improves any-resolution support, brings back the ViTDet option for drastically enhanced efficiency at high-resolution, and comes with a permissive license.", "AI": {"tldr": "通过多教师蒸馏技术，C-RADIOv4提供了统一的学生模型，保留并提升了多个教师模型的独特能力。", "motivation": "改进现有模型以提升关键下游任务性能，同时保持相同的计算复杂度，并增强新功能和任意分辨率支持。", "method": "采用多教师蒸馏方法，结合SigLIP2、DINOv3和SAM3进行训练，构建C-RADIOv4模型，提供-SO400M（4.12亿参数）和-H（6.31亿参数）两种变体。", "result": "C-RADIOv4在核心指标上取得提升，并通过模仿SAM3增加了新功能，支持任意分辨率，并提供ViTDet选项以提高高分辨率下的效率。", "conclusion": "C-RADIOv4模型系列通过多教师蒸馏技术，在保持计算复杂度不变的情况下提升了性能和新增了能力，同时提供了宽松的许可。"}}
{"id": "2601.17231", "pdf": "https://arxiv.org/pdf/2601.17231", "abs": "https://arxiv.org/abs/2601.17231", "authors": ["Tanmay Desai", "Brian Plancher", "R. Iris Bahar"], "title": "Real-Time, Energy-Efficient, Sampling-Based Optimal Control via FPGA Acceleration", "categories": ["cs.RO", "cs.AR"], "comment": "8 pages, 5 figures", "summary": "Autonomous mobile robots (AMRs), used for search-and-rescue and remote exploration, require fast and robust planning and control schemes. Sampling-based approaches for Model Predictive Control, especially approaches based on the Model Predictive Path Integral Control (MPPI) algorithm, have recently proven both to be highly effective for such applications and to map naturally to GPUs for hardware acceleration. However, both GPU and CPU implementations of such algorithms can struggle to meet tight energy and latency budgets on battery-constrained AMR platforms that leverage embedded compute. To address this issue, we present an FPGA-optimized MPPI design that exposes fine-grained parallelism and eliminates synchronization bottlenecks via deep pipelining and parallelism across algorithmic stages. This results in an average 3.1x to 7.5x speedup over optimized implementations on an embedded GPU and CPU, respectively, while simultaneously achieving a 2.5x to 5.4x reduction in energy usage. These results demonstrate that FPGA architectures are a promising direction for energy-efficient and high-performance edge robotics.", "AI": {"tldr": "本论文介绍了通过FPGA加速实现实时、节能的基于采样的最优控制方法，特别针对自主移动机器人（AMR）的应用场景。", "motivation": "为了满足电池受限的AMR平台在能量和延迟上的严格预算要求，传统的GPU和CPU实现难以胜任，因此研究者提出了优化后的FPGA设计以解决这一问题。", "method": "论文提出了一种基于FPGA优化的MPPI设计，通过深度流水线化和平行处理算法阶段来暴露细粒度并行性，并消除同步瓶颈。", "result": "实验表明，该方法相较于嵌入式GPU和CPU的优化实现，分别实现了3.1倍至7.5倍的速度提升，并且能量使用降低了2.5倍到5.4倍。", "conclusion": "研究结果证明了FPGA架构在节能和高性能边缘机器人领域具有广阔前景。"}}
{"id": "2601.17228", "pdf": "https://arxiv.org/pdf/2601.17228", "abs": "https://arxiv.org/abs/2601.17228", "authors": ["Tengyue Zhang", "Ruiwen Ding", "Luoting Zhuang", "Yuxiao Wu", "Erika F. Rodriguez", "William Hsu"], "title": "Semi-Supervised Domain Adaptation with Latent Diffusion for Pathology Image Classification", "categories": ["cs.CV", "q-bio.QM"], "comment": null, "summary": "Deep learning models in computational pathology often fail to generalize across cohorts and institutions due to domain shift. Existing approaches either fail to leverage unlabeled data from the target domain or rely on image-to-image translation, which can distort tissue structures and compromise model accuracy. In this work, we propose a semi-supervised domain adaptation (SSDA) framework that utilizes a latent diffusion model trained on unlabeled data from both the source and target domains to generate morphology-preserving and target-aware synthetic images. By conditioning the diffusion model on foundation model features, cohort identity, and tissue preparation method, we preserve tissue structure in the source domain while introducing target-domain appearance characteristics. The target-aware synthetic images, combined with real, labeled images from the source cohort, are subsequently used to train a downstream classifier, which is then tested on the target cohort. The effectiveness of the proposed SSDA framework is demonstrated on the task of lung adenocarcinoma prognostication. The proposed augmentation yielded substantially better performance on the held-out test set from the target cohort, without degrading source-cohort performance. The approach improved the weighted F1 score on the target-cohort held-out test set from 0.611 to 0.706 and the macro F1 score from 0.641 to 0.716. Our results demonstrate that target-aware diffusion-based synthetic data augmentation provides a promising and effective approach for improving domain generalization in computational pathology.", "AI": {"tldr": "本文提出了一种半监督域适应框架，通过利用潜在扩散模型生成形态保存和目标领域的合成图像来提高病理图像分类的性能。", "motivation": "现有的深度学习模型在计算病理学中跨队列和机构泛化能力不足，主要原因是领域迁移问题以及现有方法未能充分利用未标记数据或依靠可能导致组织结构失真的图像到图像转换技术。", "method": "本文提出的方法是半监督域适应框架，利用潜在扩散模型生成形态保存且目标领域的合成图像，并通过条件控制保持源域的组织结构同时引入目标域的外观特征来训练下游分类器。", "result": "实验表明，在肺腺癌预后任务上，该方法显著提高了在目标队列测试集上的性能，加权F1得分从0.611提高到0.706，宏平均F1得分从0.641提高到0.716。", "conclusion": "研究结果表明，基于扩散模型的合成数据增强方法能有效改进计算病理学中的领域泛化能力。"}}
{"id": "2601.17227", "pdf": "https://arxiv.org/pdf/2601.17227", "abs": "https://arxiv.org/abs/2601.17227", "authors": ["Avraiem Iskandar", "Shamak Dutta", "Kevin Murrant", "Yash Vardhan Pant", "Stephen L. Smith"], "title": "Hierarchical Informative Path Planning via Graph Guidance and Trajectory Optimization", "categories": ["cs.RO"], "comment": null, "summary": "We study informative path planning (IPP) with travel budgets in cluttered environments, where an agent collects measurements of a latent field modeled as a Gaussian process (GP) to reduce uncertainty at target locations. Graph-based solvers provide global guarantees but assume pre-selected measurement locations, while continuous trajectory optimization supports path-based sensing but is computationally intensive and sensitive to initialization in obstacle-dense settings. We propose a hierarchical framework with three stages: (i) graph-based global planning, (ii) segment-wise budget allocation using geometric and kernel bounds, and (iii) spline-based refinement of each segment with hard constraints and obstacle pruning. By combining global guidance with local refinement, our method achieves lower posterior uncertainty than graph-only and continuous baselines, while running faster than continuous-space solvers (up to 9x faster than gradient-based methods and 20x faster than black-box optimizers) across synthetic cluttered environments and Arctic datasets.", "AI": {"tldr": "本文研究了在有旅行预算的复杂环境中的信息路径规划问题，提出了一种分层框架来优化路径并减少目标位置的不确定性。", "motivation": "现有的图基求解器能提供全局保证但需要预选测量点，连续轨迹优化支持基于路径的传感但在障碍物密集环境中计算成本高且对初始化敏感。本文旨在结合两者优势以提高效率和效果。", "method": "提出一种分三阶段的分层框架：（i）图基全局规划，（ii）使用几何和核边界进行每段预算分配，（iii）带硬约束和障碍物修剪的样条细化。", "result": "实验结果显示，相比仅用图的方法或连续空间求解器，该方法实现了更低的后验不确定性，并在合成复杂环境和北极数据集上运行速度更快，比梯度法快9倍，比黑箱优化快20倍。", "conclusion": "提出的分层框架通过结合全局指导与局部细化，在保证降低不确定性的前提下提高了计算效率。"}}
{"id": "2601.17226", "pdf": "https://arxiv.org/pdf/2601.17226", "abs": "https://arxiv.org/abs/2601.17226", "authors": ["David Y. Liu", "Xanthe Muston", "Aditya Joshi", "Sebastian Sequoiah-Grayson"], "title": "Retell, Reward, Repeat: Reinforcement Learning for Narrative Theory-Informed Story Generation", "categories": ["cs.CL", "cs.AI"], "comment": "8 Pages, 6 figures", "summary": "Despite the subjective nature of storytelling, past works on automatic story generation (ASG) have relied on limited ground truths for training and evaluation. In this work, we explore reinforcement learning (d-RLAIF) as a post-training alternative to supervised fine-tuning (SFT). We first apply Todorov's Theory of Narrative Equilibrium to establish principles that define desirable ASG qualities. We prompt 7B and 14B LLM-as-judge models with our principles to test alignment with human annotators and provide reward signals during d-RLAIF. We use Gemini-3-Flash to evaluate the output of our post-trained models and compare them to human-written stories from the TimeTravel dataset. We show that d-RLAIF offers a viable alternative to supervised fine-tuning (SFT)--producing stories that are more diverse and aligned with human narrative conventions. Our paper demonstrates the promise of reinforcement learning for linguistically grounded post-training for subjective tasks such as ASG.", "AI": {"tldr": "本文探讨了利用强化学习（d-RLAIF）来生成符合叙事理论的故事，并展示了这种方法比传统的监督微调更具有多样性和与人类叙事习惯的对齐。", "motivation": "过去自动故事生成的工作依赖于有限的真实数据进行训练和评估，而本研究希望通过引入强化学习，探索一种不完全依赖于这些真实标签的方法来提升故事生成的质量。", "method": "本文采用Todorov的叙事均衡理论建立标准，并使用7B和14B大语言模型作为评判者提供奖励信号。通过d-RLAIF方法进行训练后，利用Gemini-3-Flash评估输出结果并与人类写作的故事进行了对比。", "result": "研究结果显示d-RLAIF生成的故事比传统监督微调更具有多样性和与人类叙事习惯的对齐。", "conclusion": "本文证明了强化学习在主观任务如自动故事生成中的潜力，并表明其作为一种后训练方法能够有效提升故事的质量和多样性。"}}
{"id": "2601.17223", "pdf": "https://arxiv.org/pdf/2601.17223", "abs": "https://arxiv.org/abs/2601.17223", "authors": ["Massimiliano Pronesti", "Anya Belz", "Yufang Hou"], "title": "Beyond Outcome Verification: Verifiable Process Reward Models for Structured Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent work on reinforcement learning with verifiable rewards (RLVR) has shown that large language models (LLMs) can be substantially improved using outcome-level verification signals, such as unit tests for code or exact-match checks for mathematics. In parallel, process supervision has long been explored as a way to shape the intermediate reasoning behaviour of LLMs, but existing approaches rely on neural judges to score chain-of-thought steps, leaving them vulnerable to opacity, bias, and reward hacking. To address this gap, we introduce Verifiable Process Reward Models (VPRMs), a reinforcement-learning framework in which intermediate reasoning steps are checked by deterministic, rule-based verifiers. We apply VPRMs to risk-of-bias assessment for medical evidence synthesis, a domain where guideline-defined criteria and rule-based decision paths enable programmatic verification of reasoning traces. Across multiple datasets, we find that VPRMs generate reasoning that adheres closely to domain rules and achieve substantially higher coherence between step-level decisions and final labels. Results show that VPRMs achieve up to 20% higher F1 than state-of-the-art models and 6.5% higher than verifiable outcome rewards, with substantial gains in evidence grounding and logical coherence.", "AI": {"tldr": "本文介绍了一种可验证过程奖励模型（VPRMs），用于在医疗证据综合的风险评估领域进行结构化推理，通过确定性规则验证中间步骤以提高LLM的连贯性和准确性。", "motivation": "当前的强化学习与可验证奖励研究主要集中在结果级别上，而本文旨在解决依赖于神经评判者的过程监督存在的不透明、偏见和奖励操纵问题。", "method": "提出了一种基于确定性规则验证中间推理步骤的Verifiable Process Reward Models (VPRMs)框架，并将其应用于医疗证据综合的风险评估中。", "result": "实验结果显示，与最先进的模型相比，VPRMs在F1分数上提高了20%，并且在证据基础和逻辑连贯性方面有了显著提升。", "conclusion": "研究证明了可验证过程奖励模型的有效性，它能提高中间推理步骤的合规性和最终决策的一致性。"}}
{"id": "2601.17219", "pdf": "https://arxiv.org/pdf/2601.17219", "abs": "https://arxiv.org/abs/2601.17219", "authors": ["David Wireko Atibila", "Vineet R. Kamat", "Carol C. Menassa"], "title": "Advancing Improvisation in Human-Robot Construction Collaboration: Taxonomy and Research Roadmap", "categories": ["cs.RO"], "comment": "73 pages, 8 figures", "summary": "The construction industry faces productivity stagnation, skilled labor shortages, and safety concerns. While robotic automation offers solutions, construction robots struggle to adapt to unstructured, dynamic sites. Central to this is improvisation, adapting to unexpected situations through creative problem-solving, which remains predominantly human. In construction's unpredictable environments, collaborative human-robot improvisation is essential for workflow continuity. This research develops a six-level taxonomy classifying human-robot collaboration (HRC) based on improvisation capabilities. Through systematic review of 214 articles (2010-2025), we categorize construction robotics across: Manual Work (Level 0), Human-Controlled Execution (Level 1), Adaptive Manipulation (Level 2), Imitation Learning (Level 3), Human-in-Loop BIM Workflow (Level 4), Cloud-Based Knowledge Integration (Level 5), and True Collaborative Improvisation (Level 6). Analysis reveals current research concentrates at lower levels, with critical gaps in experiential learning and limited progression toward collaborative improvisation. A five-dimensional radar framework illustrates progressive evolution of Planning, Cognitive Role, Physical Execution, Learning Capability, and Improvisation, demonstrating how complementary human-robot capabilities create team performance exceeding individual contributions. The research identifies three fundamental barriers: technical limitations in grounding and dialogic reasoning, conceptual gaps between human improvisation and robotics research, and methodological challenges. We recommend future research emphasizing improved human-robot communication via Augmented/Virtual Reality interfaces, large language model integration, and cloud-based knowledge systems to advance toward true collaborative improvisation.", "AI": {"tldr": "本文提出一个六级分类法，用于评估和划分人机协作在建筑机器人领域的即兴能力，并制定了未来研究路线图。", "motivation": "建筑业面临生产率停滞、技术工人短缺及安全问题。尽管机器人自动化提供了潜在解决方案，但现有建筑机器人的适应性不足，特别是在应对不可预测的工地环境方面缺乏人类般的即兴应变能力。人机协作的即兴能力对于维持施工流程至关重要。", "method": "通过对214篇（2010-2025年）文章进行系统性回顾，本文提出了一种分类法，涵盖从手动工作到真正协作式即兴的各种水平，并利用五维雷达框架来展示人机团队能力的逐步演变和互补。", "result": "研究揭示了当前研究集中在较低级别的人机协作上，在经验学习方面的空白以及向真正的协作式即兴发展的缓慢进程。还确定了技术、概念及方法论上的三大障碍。", "conclusion": "建议未来的研究应聚焦于改进人机通讯，例如通过增强现实/虚拟现实界面、大语言模型集成和云知识系统，以推进达到真正的人机协作即兴能力。"}}
{"id": "2601.17216", "pdf": "https://arxiv.org/pdf/2601.17216", "abs": "https://arxiv.org/abs/2601.17216", "authors": ["Murat Arda Onsu", "Poonam Lohan", "Burak Kantarci", "Aisha Syed", "Matthew Andrews", "Sean Kennedy"], "title": "Spatiotemporal Semantic V2X Framework for Cooperative Collision Prediction", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "comment": "6 pages 5 figures, accepted to IEEE ICC 2026", "summary": "Intelligent Transportation Systems (ITS) demand real-time collision prediction to ensure road safety and reduce accident severity. Conventional approaches rely on transmitting raw video or high-dimensional sensory data from roadside units (RSUs) to vehicles, which is impractical under vehicular communication bandwidth and latency constraints. In this work, we propose a semantic V2X framework in which RSU-mounted cameras generate spatiotemporal semantic embeddings of future frames using the Video Joint Embedding Predictive Architecture (V-JEPA). To evaluate the system, we construct a digital twin of an urban traffic environment enabling the generation of d verse traffic scenarios with both safe and collision events. These embeddings of the future frame, extracted from V-JEPA, capture task-relevant traffic dynamics and are transmitted via V2X links to vehicles, where a lightweight attentive probe and classifier decode them to predict imminent collisions. By transmitting only semantic embeddings instead of raw frames, the proposed system significantly reduces communication overhead while maintaining predictive accuracy. Experimental results demonstrate that the framework with an appropriate processing method achieves a 10% F1-score improvement for collision prediction while reducing transmission requirements by four orders of magnitude compared to raw video. This validates the potential of semantic V2X communication to enable cooperative, real-time collision prediction in ITS.", "AI": {"tldr": "本文提出了一种基于语义V2X框架的协同碰撞预测方法，通过传输未来帧的语义嵌入来减少通信开销并提高预测准确性。", "motivation": "智能交通系统需要实时碰撞预测以确保道路安全和降低事故严重性，但传统的依赖于车载传感器和路边单元间传输原始视频或高维数据的方法在车联网络带宽和延迟限制下不可行。", "method": "提出了一种语义V2X框架，在该框架中，路边安装的摄像头使用Video Joint Embedding Predictive Architecture（V-JEPA）生成未来帧的空间时间语义嵌入，并通过V2X链路传输到车辆上进行解码和碰撞预测。", "result": "实验结果显示，与传输原始视频相比，所提出的系统在保持预测准确性的同时将传输需求减少了四个数量级，并提高了10%的F1分数。", "conclusion": "验证了语义V2X通信在智能交通系统中实现协同实时碰撞预测的潜力。"}}
{"id": "2601.17211", "pdf": "https://arxiv.org/pdf/2601.17211", "abs": "https://arxiv.org/abs/2601.17211", "authors": ["Anzhe Cheng", "Italo Ivo Lima Dias Pinto", "Paul Bogdan"], "title": "Structural Complexity of Brain MRI reveals age-associated patterns", "categories": ["cs.CV"], "comment": "accepted by icassp2026", "summary": "We adapt structural complexity analysis to three-dimensional signals, with an emphasis on brain magnetic resonance imaging (MRI). This framework captures the multiscale organization of volumetric data by coarse-graining the signal at progressively larger spatial scales and quantifying the information lost between successive resolutions. While the traditional block-based approach can become unstable at coarse resolutions due to limited sampling, we introduce a sliding-window coarse-graining scheme that provides smoother estimates and improved robustness at large scales. Using this refined method, we analyze large structural MRI datasets spanning mid- to late adulthood and find that structural complexity decreases systematically with age, with the strongest effects emerging at coarser scales. These findings highlight structural complexity as a reliable signal processing tool for multiscale analysis of 3D imaging data, while also demonstrating its utility in predicting biological age from brain MRI.", "AI": {"tldr": "通过适应三维信号的结构复杂性分析，研究了脑MRI中的年龄相关模式。", "motivation": "探索一种更加稳定和有效的多尺度数据分析方法，并应用于大型结构化MRI数据集以揭示与年龄相关的系统变化。", "method": "引入滑动窗口粗粒化方案来改进传统的基于块的粗粒化方法，从而更平滑地估计并提高在大尺度下的鲁棒性。", "result": "研究发现结构性复杂性随着年龄的增长而减少，并且这种效应在更大尺度上更为明显。", "conclusion": "结构复杂性作为多尺度分析3D图像数据的可靠信号处理工具，可以用于从脑MRI预测生物年龄。"}}
{"id": "2601.17194", "pdf": "https://arxiv.org/pdf/2601.17194", "abs": "https://arxiv.org/abs/2601.17194", "authors": ["Cheyu Lin", "Katherine A. Flanigan", "Sirajum Munir"], "title": "Decoding Psychological States Through Movement: Inferring Human Kinesic Functions with Application to Built Environments", "categories": ["cs.CV"], "comment": null, "summary": "Social infrastructure and other built environments are increasingly expected to support well-being and community resilience by enabling social interaction. Yet in civil and built-environment research, there is no consistent and privacy-preserving way to represent and measure socially meaningful interaction in these spaces, leaving studies to operationalize \"interaction\" differently across contexts and limiting practitioners' ability to evaluate whether design interventions are changing the forms of interaction that social capital theory predicts should matter. To address this field-level and methodological gap, we introduce the Dyadic User Engagement DataseT (DUET) dataset and an embedded kinesics recognition framework that operationalize Ekman and Friesen's kinesics taxonomy as a function-level interaction vocabulary aligned with social capital-relevant behaviors (e.g., reciprocity and attention coordination). DUET captures 12 dyadic interactions spanning all five kinesic functions-emblems, illustrators, affect displays, adaptors, and regulators-across four sensing modalities and three built-environment contexts, enabling privacy-preserving analysis of communicative intent through movement. Benchmarking six open-source, state-of-the-art human activity recognition models quantifies the difficulty of communicative-function recognition on DUET and highlights the limitations of ubiquitous monadic, action-level recognition when extended to dyadic, socially grounded interaction measurement. Building on DUET, our recognition framework infers communicative function directly from privacy-preserving skeletal motion without handcrafted action-to-function dictionaries; using a transfer-learning architecture, it reveals structured clustering of kinesic functions and a strong association between representation quality and classification performance while generalizing across subjects and contexts.", "AI": {"tldr": "通过分析人体运动来推断人类的交际功能，以支持社会基础设施和建筑环境的设计评估。", "motivation": "旨在填补关于如何在保护隐私的前提下量化有意义的社会互动的研究空白，并提供一种通用的方法来衡量设计干预是否改变了预测应起作用的社会资本行为。", "method": "引入了Dyadic User Engagement DataseT（DUET）数据集和嵌入的运动学识别框架，该框架将Ekman和Friesen的运动学分类法作为与社会资本相关的行为功能级别的互动词汇表，并通过隐私保护的方式捕捉交际意图。", "result": "基准测试了六个开源的人类活动识别模型在DUET上的表现，表明现有模型难以准确进行交际功能识别。使用迁移学习架构直接从隐私保护的身体骨架运动推断交际功能，揭示了运动学函数的结构聚类和表示质量与分类性能之间的强关联。", "conclusion": "提出的方法能够实现对社交互动的隐私保护分析，并为社会基础设施设计提供了有效的评估工具。"}}
{"id": "2601.17188", "pdf": "https://arxiv.org/pdf/2601.17188", "abs": "https://arxiv.org/abs/2601.17188", "authors": ["Swapn Shah", "Wlodek Zadrozny"], "title": "Implementing Tensor Logic: Unifying Datalog and Neural Reasoning via Tensor Contraction", "categories": ["cs.AI"], "comment": null, "summary": "The unification of symbolic reasoning and neural networks remains a central challenge in artificial intelligence. Symbolic systems offer reliability and interpretability but lack scalability, while neural networks provide learning capabilities but sacrifice transparency. Tensor Logic, proposed by Domingos, suggests that logical rules and Einstein summation are mathematically equivalent, offering a principled path toward unification. This paper provides empirical validation of this framework through three experiments. First, we demonstrate the equivalence between recursive Datalog rules and iterative tensor contractions by computing the transitive closure of a biblical genealogy graph containing 1,972 individuals and 1,727 parent-child relationships, converging in 74 iterations to discover 33,945 ancestor relationships. Second, we implement reasoning in embedding space by training a neural network with learnable transformation matrices, demonstrating successful zero-shot compositional inference on held-out queries. Third, we validate the Tensor Logic superposition construction on FB15k-237, a large-scale knowledge graph with 14,541 entities and 237 relations. Using Domingos's relation matrix formulation $R_r = E^\\top A_r E$, we achieve MRR of 0.3068 on standard link prediction and MRR of 0.3346 on a compositional reasoning benchmark where direct edges are removed during training, demonstrating that matrix composition enables multi-hop inference without direct training examples.", "AI": {"tldr": "本文通过张量逻辑框架，将符号推理和神经网络进行统一，实现递归Datalog规则与迭代张量收缩的等价性，并在知识图谱上验证其效果。", "motivation": "文章旨在解决人工智能领域中符号系统可靠性和可解释性不足以及神经网络缺乏透明度的问题，通过证明逻辑规则和爱因斯坦求和原则等同来统一符号推理与神经网络。", "method": "论文采用了三个实验进行验证。第一个实验通过迭代张量收缩计算圣经家谱中的传递闭包；第二个实验在嵌入空间中实施推理并训练具有可学习变换矩阵的神经网络，展示零样本组合推理的成功；第三个实验在FB15k-237知识图谱上验证了Tensor Logic超算构建。", "result": "第一个实验发现了33,945个祖先关系，在74次迭代中收敛。第二个实验展示了零样本组合推理的成功。第三个实验达到了标准链接预测的MRR为0.3068和在移除训练期间直接边的组成推理基准上的MRR为0.3346。", "conclusion": "张量逻辑框架成功地统一了符号推理与神经网络，实现了多跳推理而无需直接训练示例，并验证了其在知识图谱中的有效性和可靠性。"}}
{"id": "2601.17187", "pdf": "https://arxiv.org/pdf/2601.17187", "abs": "https://arxiv.org/abs/2601.17187", "authors": ["Or Ordentlich", "Yury Polyanskiy"], "title": "High-Rate Quantized Matrix Multiplication: Theory and Practice", "categories": ["cs.IT", "cs.AI"], "comment": null, "summary": "This work investigates the problem of quantized matrix multiplication (MatMul), which has become crucial for the efficient deployment of large language models (LLMs). We consider two settings: 1) Generic MatMul, where both matrices must be quantized (weight+activation quantization); and 2) weight-only quantization, where the second matrix is only known through covariance matrix $Σ_X$ of its columns. For each setting, we first review the fundamental information-theoretic tradeoff between quantization rate and distortion (high-rate theory), and then analyze the performance of several popular quantization schemes, comparing them to these fundamental limits. Specifically, we discuss rate loss (compared to information theoretic optima) of absmax INT and floating-point (FP) quantization, for which we also derive remarkably accurate heuristic approximations. Weight-only quantization is related to the problem of weighted mean squared error (WMSE) source coding, whose classical (reverse) waterfilling solution dictates how one should distribute rate between coordinates of the vector. We show how waterfilling can be used to improve practical LLM quantization algorithms (GPTQ), which at present allocate rate equally. This new scheme (termed ``WaterSIC'') only uses scalar INT quantizers, but its high-rate performance is basis free (it depends only on the determinant of $Σ_X$ and, thus, unlike existing schemes, is immune to applying random rotations) and is within a multiplicative factor of $\\frac{2πe}{12}$ (or 0.25 bit/entry) of the information-theoretic distortion limit (!). GPTQ's performance is affected by the choice of basis, but for a random rotation and actual $Σ_X$ from Llama-3-8B we find GPTQ to be within 0.1 bit (depending on the layer type) of WaterSIC, suggesting that GPTQ with random rotation is also near optimal (for high-rate quantization).", "AI": {"tldr": "本文探讨了量化矩阵乘法（MatMul）的理论与实践，重点关注权重和激活量化的通用矩阵乘法以及仅对权重进行量化的方案。", "motivation": "研究动机在于提高大规模语言模型部署效率的问题，特别是在高率量化下如何在保持计算精度的同时降低资源需求。", "method": "文章分析了两种设置下的信息论基础理论，并对比了几种流行的量化方案的性能。提出了一种新的基于水填充算法的量化方案（WaterSIC），该方案利用标量整数量化器，其高率性能与基底无关且接近信息论极限。", "result": "研究结果表明，提出的WaterSIC方案在保持高效率的同时能提供更好的稳定性和更接近理论极限的性能。对于实际的Llama-3-8B模型，GPTQ方法的性能也接近最优。", "conclusion": "结论指出，WaterSIC方案在量化矩阵乘法中提供了卓越的基础无关性能，并且可以作为未来大规模语言模型部署的有效手段。"}}
{"id": "2601.17185", "pdf": "https://arxiv.org/pdf/2601.17185", "abs": "https://arxiv.org/abs/2601.17185", "authors": ["Shima Salehi", "Atharva Agashe", "Andrew J. McFarland", "Joshua Peeples"], "title": "LGDWT-GS: Local and Global Discrete Wavelet-Regularized 3D Gaussian Splatting for Sparse-View Scene Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "We propose a new method for few-shot 3D reconstruction that integrates global and local frequency regularization to stabilize geometry and preserve fine details under sparse-view conditions, addressing a key limitation of existing 3D Gaussian Splatting (3DGS) models. We also introduce a new multispectral greenhouse dataset containing four spectral bands captured from diverse plant species under controlled conditions. Alongside the dataset, we release an open-source benchmarking package that defines standardized few-shot reconstruction protocols for evaluating 3DGS-based methods. Experiments on our multispectral dataset, as well as standard benchmarks, demonstrate that the proposed method achieves sharper, more stable, and spectrally consistent reconstructions than existing baselines. The dataset and code for this work are publicly available", "AI": {"tldr": "提出了一种新的方法，用于在稀疏视图条件下实现更稳定和细节保留的三维重建。", "motivation": "现有的3D高斯溅射模型存在稀疏视角下几何稳定性差和细节丢失的问题，本文旨在通过引入全局和局部频率正则化来解决这些问题。", "method": "提出LGDWT-GS方法，结合全球和本地离散小波正则化，以稳定几何结构并保存在稀疏视图条件下重建的精细细节。", "result": "实验表明，所提方法在新发布的多光谱温室数据集上以及标准基准测试中，实现了比现有基线更清晰、更稳定的三维重建效果，并且具有更好的光谱一致性。", "conclusion": "提出的LGDWT-GS方法能够有效提高稀疏视图条件下3D重构的质量和稳定性。"}}
{"id": "2601.17183", "pdf": "https://arxiv.org/pdf/2601.17183", "abs": "https://arxiv.org/abs/2601.17183", "authors": ["Farzam Asad", "Junaid Saif Khan", "Maria Tariq", "Sundus Munir", "Muhammad Adnan Khan"], "title": "Federated Proximal Optimization for Privacy-Preserving Heart Disease Prediction: A Controlled Simulation Study on Non-IID Clinical Data", "categories": ["cs.LG", "cs.AI"], "comment": "27 pages, 7 figures, 4 tables", "summary": "Healthcare institutions have access to valuable patient data that could be of great help in the development of improved diagnostic models, but privacy regulations like HIPAA and GDPR prevent hospitals from directly sharing data with one another. Federated Learning offers a way out to this problem by facilitating collaborative model training without having the raw patient data centralized. However, clinical datasets intrinsically have non-IID (non-independent and identically distributed) features brought about by demographic disparity and diversity in disease prevalence and institutional practices. This paper presents a comprehensive simulation research of Federated Proximal Optimization (FedProx) for Heart Disease prediction based on UCI Heart Disease dataset. We generate realistic non-IID data partitions by simulating four heterogeneous hospital clients from the Cleveland Clinic dataset (303 patients), by inducing statistical heterogeneity by demographic-based stratification. Our experimental results show that FedProx with proximal parameter mu=0.05 achieves 85.00% accuracy, which is better than both centralized learning (83.33%) and isolated local models (78.45% average) without revealing patient privacy. Through generous sheer ablation studies with statistical validation on 50 independent runs we demonstrate that proximal regularization is effective in curbing client drift in heterogeneous environments. This proof-of-concept research offers algorithmic insights and practical deployment guidelines for real-world federated healthcare systems, and thus, our results are directly transferable to hospital IT-administrators, implementing privacy-preserving collaborative learning.", "AI": {"tldr": "本文研究了联邦近似优化（FedProx）在基于非独立同分布（non-IID）临床数据的心脏疾病预测中的应用。", "motivation": "由于隐私法规的限制，医疗机构无法直接共享患者数据。联邦学习提供了一种无需集中原始数据就能进行协作模型训练的方法。然而，临床数据通常具有由人口差异和疾病流行多样性引起的非独立同分布特征。", "method": "本文通过模拟四个异构医院客户端来生成现实世界的non-IID数据分区，并使用Cleveland Clinic心脏病数据集进行了广泛的实验研究，采用了FedProx优化算法进行训练。", "result": "实验结果显示，当proximal参数mu设置为0.05时，FedProx实现了85.00%的准确率，这比集中式学习（83.33%）和孤立本地模型（平均78.45%）都要好。通过大量的消融研究证明了近似正则化在异构环境中抑制客户端漂移的有效性。", "conclusion": "这项概念验证的研究提供了算法见解和实际部署指南，适用于现实世界中的联邦医疗系统，并直接适用于实施隐私保护协作学习的医院IT管理员。"}}
{"id": "2601.17180", "pdf": "https://arxiv.org/pdf/2601.17180", "abs": "https://arxiv.org/abs/2601.17180", "authors": ["Inés Gonzalez-Pepe", "Vinuyan Sivakolunthu", "Jacob Fortin", "Yohan Chatelain", "Tristan Glatard"], "title": "Conservative & Aggressive NaNs Accelerate U-Nets for Neuroimaging", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep learning models for neuroimaging increasingly rely on large architectures, making efficiency a persistent concern despite advances in hardware. Through an analysis of numerical uncertainty of convolutional neural networks (CNNs), we observe that many operations are applied to values dominated by numerical noise and have negligible influence on model outputs. In some models, up to two-thirds of convolution operations appear redundant. We introduce Conservative & Aggressive NaNs, two novel variants of max pooling and unpooling that identify numerically unstable voxels and replace them with NaNs, allowing subsequent layers to skip computations on irrelevant data. Both methods are implemented within PyTorch and require no architectural changes. We evaluate these approaches on four CNN models spanning neuroimaging and image classification tasks. For inputs containing at least 50% NaNs, we observe consistent runtime improvements; for data with more than two-thirds NaNs )common in several neuroimaging settings) we achieve an average inference speedup of 1.67x. Conservative NaNs reduces convolution operations by an average of 30% across models and datasets, with no measurable performance degradation, and can skip up to 64.64% of convolutions in specific layers. Aggressive NaNs can skip up to 69.30% of convolutions but may occasionally affect performance. Overall, these methods demonstrate that numerical uncertainty can be exploited to reduce redundant computation and improve inference efficiency in CNNs.", "AI": {"tldr": "本文提出了两种新的方法，即保守和激进的NaNs，以减少卷积神经网络中冗余计算并提高神经成像任务中的推断效率。", "motivation": "随着深度学习模型在神经成像领域的应用越来越多，大型架构的需求使得效率成为一个持续关注的问题。研究发现许多操作应用于数值噪声主导的价值上，并对模型输出几乎没有影响，因此提出减少这些冗余运算以提升效率。", "method": "本文提出了保守和激进的NaNs两种新的变体方法，通过分析卷积神经网络中的数值不确定性来识别不稳定的体素并用NaN替换它们，使后续层可以跳过对无关数据的计算。这些方法在PyTorch中实现，不需要改变架构。", "result": "测试表明，在输入包含至少50% NaNs的情况下，观察到一致的运行时间改进；对于超过三分之二的数据为NaNs的情况（常见于神经成像设置），实现了平均1.67倍的推理加速。保守NaNs减少了约30%的卷积操作，并未导致性能下降；激进NaNs最多可以跳过69.30%的操作，但可能会偶尔影响性能。", "conclusion": "这些方法展示了通过利用数值不确定性减少冗余计算和提高CNN中推断效率的可能性。"}}
{"id": "2601.17178", "pdf": "https://arxiv.org/pdf/2601.17178", "abs": "https://arxiv.org/abs/2601.17178", "authors": ["Saideep Sreekumar", "Zeng Wang", "Akashdeep Saha", "Weihua Xiao", "Minghao Shao", "Muhammad Shafique", "Ozgur Sinanoglu", "Ramesh Karri", "Johann Knechtel"], "title": "TrojanGYM: A Detector-in-the-Loop LLM for Adaptive RTL Hardware Trojan Insertion", "categories": ["cs.CR", "cs.AI", "cs.AR"], "comment": null, "summary": "Hardware Trojans (HTs) remain a critical threat because learning-based detectors often overfit to narrow trigger/payload patterns and small, stylized benchmarks. We introduce TrojanGYM, an agentic, LLM-driven framework that automatically curates HT insertions to expose detector blind spots while preserving design correctness. Given high-level HT specifications, a suite of cooperating LLM agents (instantiated with GPT-4, LLaMA-3.3-70B, and Gemini-2.5Pro) proposes and refines RTL modifications that realize diverse triggers and payloads without impacting normal functionality. TrojanGYM implements a feedback-driven benchmark generation loop co-designed with HT detectors, in which constraint-aware syntactic checking and GNN-based HT detectors provide feedback that iteratively refines HT specifications and insertion strategies to better surface detector blind spots. We further propose Robust-GNN4TJ, a new implementation of the GNN4TJ with improved graph extraction, training robustness, and prediction reliability, especially on LLM-generated HT designs. On the most challenging TrojanGYM-generated benchmarks, Robust-GNN4TJ raises HT detection rates from 0% to 60% relative to a prior GNN-based detector. We instantiate TrojanGYM on SRAM, AES-128, and UART designs at RTL level, and show that it systematically produces diverse, functionally correct HTs that reach up to 83.33% evasion rates against modern GNN-based detectors, revealing robustness gaps that are not apparent when these detectors are evaluated solely on existing TrustHub-style benchmarks. Post peer-review, we will release all codes and artifacts.", "AI": {"tldr": "本文介绍了TrojanGYM，一个基于LLM的自适应RTL硬件木马插入框架，通过检测器反馈循环不断优化木马设计。", "motivation": "学习型检测器易过度拟合狭窄的触发/载荷模式和小型标准基准测试，存在盲点，需要更强大的检测方法来暴露这些盲点。", "method": "TrojanGYM使用多个LLM代理生成和调整RTL修改以实现多样化的触发和载荷设计。通过反馈循环和改进后的GNN4TJ（Robust-GNN4TJ）进行木马检测，不断优化木马插入策略。", "result": "实验结果表明，Robust-GNN4TJ在TrojanGYM生成的复杂基准测试中将硬件木马检测率从0%提高到60%，并揭示了现代GNN检测器对LLM生成设计的有效性差距。", "conclusion": "TrojanGYM能够系统地生成多样化的、功能正确的硬件木马，达到高达83.33%的逃避率，并在不同的RTL设计中验证其有效性。"}}
{"id": "2601.17173", "pdf": "https://arxiv.org/pdf/2601.17173", "abs": "https://arxiv.org/abs/2601.17173", "authors": ["Parth Bhalerao", "Diola Dsouza", "Ruiwen Guan", "Oana Ignat"], "title": "Beyond Factual QA: Mentorship-Oriented Question Answering over Long-Form Multilingual Content", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Question answering systems are typically evaluated on factual correctness, yet many real-world applications-such as education and career guidance-require mentorship: responses that provide reflection and guidance. Existing QA benchmarks rarely capture this distinction, particularly in multilingual and long-form settings. We introduce MentorQA, the first multilingual dataset and evaluation framework for mentorship-focused question answering from long-form videos, comprising nearly 9,000 QA pairs from 180 hours of content across four languages. We define mentorship-focused evaluation dimensions that go beyond factual accuracy, capturing clarity, alignment, and learning value. Using MentorQA, we compare Single-Agent, Dual-Agent, RAG, and Multi-Agent QA architectures under controlled conditions. Multi-Agent pipelines consistently produce higher-quality mentorship responses, with especially strong gains for complex topics and lower-resource languages. We further analyze the reliability of automated LLM-based evaluation, observing substantial variation in alignment with human judgments. Overall, this work establishes mentorship-focused QA as a distinct research problem and provides a multilingual benchmark for studying agentic architectures and evaluation design in educational AI. The dataset and evaluation framework are released at https://github.com/AIM-SCU/MentorQA.", "AI": {"tldr": "本文介绍了MentorQA，这是一个用于基于长视频的多语言导师式问答系统的数据集和评估框架。", "motivation": "现有的问题回答系统主要侧重于事实准确性，但在教育和职业指导等实际应用中，需要提供反思和指导的回答。现有基准很少捕捉到这种区别，尤其是在多语言和长形式设置中。", "method": "本文引入了MentorQA数据集，包含近9,000个问答对，涵盖4种语言的180小时内容，并定义了一套评估维度来衡量导师式的回答质量。比较了不同的问答架构在控制条件下的表现。", "result": "多代理管道在生成高质量的导师式回答方面表现出色，特别是在复杂主题和资源较少的语言上。研究表明基于大模型的自动评估结果与人类判断之间存在较大差异。", "conclusion": "这项工作确立了以指导为重点的问题回答作为一个独立的研究领域，并提供了一个用于研究多语言教育AI的基准数据集和评价框架。"}}
{"id": "2601.17172", "pdf": "https://arxiv.org/pdf/2601.17172", "abs": "https://arxiv.org/abs/2601.17172", "authors": ["Tunazzina Islam"], "title": "Who Gets Which Message? Auditing Demographic Bias in LLM-Generated Targeted Text", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) are increasingly capable of generating personalized, persuasive text at scale, raising new questions about bias and fairness in automated communication. This paper presents the first systematic analysis of how LLMs behave when tasked with demographic-conditioned targeted messaging. We introduce a controlled evaluation framework using three leading models -- GPT-4o, Llama-3.3, and Mistral-Large 2.1 -- across two generation settings: Standalone Generation, which isolates intrinsic demographic effects, and Context-Rich Generation, which incorporates thematic and regional context to emulate realistic targeting. We evaluate generated messages along three dimensions: lexical content, language style, and persuasive framing. We instantiate this framework on climate communication and find consistent age- and gender-based asymmetries across models: male- and youth-targeted messages emphasize agency, innovation, and assertiveness, while female- and senior-targeted messages stress warmth, care, and tradition. Contextual prompts systematically amplify these disparities, with persuasion scores significantly higher for messages tailored to younger or male audiences. Our findings demonstrate how demographic stereotypes can surface and intensify in LLM-generated targeted communication, underscoring the need for bias-aware generation pipelines and transparent auditing frameworks that explicitly account for demographic conditioning in socially sensitive applications.", "AI": {"tldr": "该论文研究了大型语言模型在生成针对不同人口统计群体的个性化文本时是否存在偏见。", "motivation": "随着LLMs能够大规模生成个性化的、有说服力的文本，这引发了关于自动通信中的偏见和公平性问题。因此，作者希望通过系统地分析LLMs的行为来揭示潜在的人口统计学偏差。", "method": "论文引入了一个控制评估框架，使用三个领先的模型（GPT-4o, Llama-3.3 和 Mistral-Large 2.1），在两种生成设定下进行测试：独立生成和富含语境的生成。评估维度包括词汇内容、语言风格以及说服性框架。", "result": "研究发现，针对不同年龄和性别群体的信息存在显著差异：面向男性和年轻受众的消息强调了能动性和创新力；而针对女性和老年人群的消息则更侧重于温暖和传统的主题。富含语境的提示系统地放大了这些差异，并且说服性得分在青年或男性目标人群中更高。", "conclusion": "研究结果表明，人口统计学刻板印象可以在LLMs生成的目标通信中显现并加剧，这强调需要开发具有偏见意识的文本生成流程和透明化的审计框架以应对社会敏感应用中的此类问题。"}}
{"id": "2601.17168", "pdf": "https://arxiv.org/pdf/2601.17168", "abs": "https://arxiv.org/abs/2601.17168", "authors": ["Judy Zhu", "Dhari Gandhi", "Himanshu Joshi", "Ahmad Rezaie Mianroodi", "Sedef Akinli Kocak", "Dhanesh Ramachandran"], "title": "Interpreting Agentic Systems: Beyond Model Explanations to System-Level Accountability", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Agentic systems have transformed how Large Language Models (LLMs) can be leveraged to create autonomous systems with goal-directed behaviors, consisting of multi-step planning and the ability to interact with different environments. These systems differ fundamentally from traditional machine learning models, both in architecture and deployment, introducing unique AI safety challenges, including goal misalignment, compounding decision errors, and coordination risks among interacting agents, that necessitate embedding interpretability and explainability by design to ensure traceability and accountability across their autonomous behaviors. Current interpretability techniques, developed primarily for static models, show limitations when applied to agentic systems. The temporal dynamics, compounding decisions, and context-dependent behaviors of agentic systems demand new analytical approaches. This paper assesses the suitability and limitations of existing interpretability methods in the context of agentic systems, identifying gaps in their capacity to provide meaningful insight into agent decision-making. We propose future directions for developing interpretability techniques specifically designed for agentic systems, pinpointing where interpretability is required to embed oversight mechanisms across the agent lifecycle from goal formation, through environmental interaction, to outcome evaluation. These advances are essential to ensure the safe and accountable deployment of agentic AI systems.", "AI": {"tldr": "本文评估了现有可解释性技术在代理系统中的适用性和局限性，并提出未来为代理系统开发专门的解释技术的方向。", "motivation": "传统的机器学习模型解释技术在应用于具有目标导向行为和多步骤规划能力的代理系统时表现出局限性，因此需要新的分析方法以确保这些系统的安全性和问责制。", "method": "本文通过评估现有可解释性技术在代理系统中的适用性来识别其局限性，并提出未来发展的方向。", "result": "文章指出现有解释技术不足以提供关于代理决策过程的有意义见解，强调了需要开发新的解释方法以满足代理系统的特殊需求。", "conclusion": "为了确保代理AI系统的安全和问责制，必须发展专门针对这些系统的新解释性技术。"}}
{"id": "2601.17165", "pdf": "https://arxiv.org/pdf/2601.17165", "abs": "https://arxiv.org/abs/2601.17165", "authors": ["Panpan Chen", "Seonyeong Park", "Gangwon Jeong", "Refik Mert Cam", "Umberto Villa", "Mark A. Anastasio"], "title": "Benchmarking Deep Learning-Based Reconstruction Methods for Photoacoustic Computed Tomography with Clinically Relevant Synthetic Datasets", "categories": ["physics.med-ph", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Deep learning (DL)-based image reconstruction methods for photoacoustic computed tomography (PACT) have developed rapidly in recent years. However, most existing methods have not employed standardized datasets, and their evaluations rely on traditional image quality (IQ) metrics that may lack clinical relevance. The absence of a standardized framework for clinically meaningful IQ assessment hinders fair comparison and raises concerns about the reproducibility and reliability of reported advancements in PACT. A benchmarking framework is proposed that provides open-source, anatomically plausible synthetic datasets and evaluation strategies for DL-based acoustic inversion methods in PACT. The datasets each include over 11,000 two-dimensional (2D) stochastic breast objects with clinically relevant lesions and paired measurements at varying modeling complexity. The evaluation strategies incorporate both traditional and task-based IQ measures to assess fidelity and clinical utility. A preliminary benchmarking study is conducted to demonstrate the framework's utility by comparing DL-based and physics-based reconstruction methods. The benchmarking study demonstrated that the proposed framework enabled comprehensive, quantitative comparisons of reconstruction performance and revealed important limitations in certain DL-based methods. Although they performed well according to traditional IQ measures, they often failed to accurately recover lesions. This highlights the inadequacy of traditional metrics and motivates the need for task-based assessments. The proposed benchmarking framework enables systematic comparisons of DL-based acoustic inversion methods for 2D PACT. By integrating clinically relevant synthetic datasets with rigorous evaluation protocols, it enables reproducible, objective assessments and facilitates method development and system optimization in PACT.", "AI": {"tldr": "本文提出了一种基于深度学习的光声计算机断层扫描（PACT）图像重建方法的基准测试框架，该框架使用具有临床相关性的合成数据集和评估策略。", "motivation": "现有的大多数基于深度学习的PACT图像重建方法缺乏标准化的数据集，并且依赖于传统但可能不具临床相关的图像质量指标进行评估。这阻碍了公平比较并引发了对报道进展的可重复性和可靠性的担忧。", "method": "提出了一种包括超过11000个二维随机乳房对象及其相关测量数据的合成数据集，这些数据具有不同的建模复杂度和临床相关的病变。该框架采用传统和基于任务的图像质量指标来评估保真度和临床实用性。", "result": "初步基准测试表明，所提出的框架能够全面、定量地比较重建性能，并揭示了一些深度学习方法在恢复病灶方面的局限性。", "conclusion": "本文提出的基准测试框架使2D PACT中基于深度学习的声学逆变换方法的系统化比较成为可能。通过结合临床相关的合成数据集和严格的评估协议，该框架促进PACT的方法开发和系统优化。"}}
{"id": "2601.17160", "pdf": "https://arxiv.org/pdf/2601.17160", "abs": "https://arxiv.org/abs/2601.17160", "authors": ["Yonghan Jung", "Bogyeong Kang"], "title": "Data-Driven Information-Theoretic Causal Bounds under Unmeasured Confounding", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.ME"], "comment": null, "summary": "We develop a data-driven information-theoretic framework for sharp partial identification of causal effects under unmeasured confounding. Existing approaches often rely on restrictive assumptions, such as bounded or discrete outcomes; require external inputs (for example, instrumental variables, proxies, or user-specified sensitivity parameters); necessitate full structural causal model specifications; or focus solely on population-level averages while neglecting covariate-conditional treatment effects. We overcome all four limitations simultaneously by establishing novel information-theoretic, data-driven divergence bounds. Our key theoretical contribution shows that the f-divergence between the observational distribution P(Y | A = a, X = x) and the interventional distribution P(Y | do(A = a), X = x) is upper bounded by a function of the propensity score alone. This result enables sharp partial identification of conditional causal effects directly from observational data, without requiring external sensitivity parameters, auxiliary variables, full structural specifications, or outcome boundedness assumptions. For practical implementation, we develop a semiparametric estimator satisfying Neyman orthogonality (Chernozhukov et al., 2018), which ensures square-root-n consistent inference even when nuisance functions are estimated using flexible machine learning methods. Simulation studies and real-world data applications, implemented in the GitHub repository (https://github.com/yonghanjung/Information-Theretic-Bounds), demonstrate that our framework provides tight and valid causal bounds across a wide range of data-generating processes.", "AI": {"tldr": "开发了一种数据驱动的信息论框架，用于在存在未测量混杂因素的情况下进行因果效应的部分识别。", "motivation": "现有的方法通常依赖于限制性假设、外部输入或完整的因果模型规范，并且只关注总体平均水平。该论文旨在克服这些局限，提供一种新的信息理论界限以更准确地识别条件因果效应。", "method": "建立了一个新的信息论的数据驱动偏差界框架，证明了f-散度在观测分布和干预分布之间的上界仅与倾向得分有关。为了实现这一方法，开发了一种满足奈曼正交性的半参数估计器，可以确保即使使用灵活的机器学习方法来估计干扰函数时也能进行一致推断。", "result": "模拟研究和现实世界数据的应用表明，该框架能够在广泛的数据生成过程中提供紧且有效的因果界限。", "conclusion": "此论文提出的方法克服了现有技术的四个主要限制，并展示了在无需外部敏感参数或辅助变量的情况下从观测数据直接识别条件因果效应的能力。"}}
{"id": "2601.17158", "pdf": "https://arxiv.org/pdf/2601.17158", "abs": "https://arxiv.org/abs/2601.17158", "authors": ["Bibek Adhikari", "Rishab Rijal", "Rakesh Yadav", "Nikchey Khatri", "Sandesh Dhakal"], "title": "Autonomous Mars Rover Module for Soil Sampling and Life Component Analysis", "categories": ["eess.SY", "astro-ph.EP", "astro-ph.IM", "cs.RO"], "comment": "9 pages, 12 figures", "summary": "The search for extraterrestrial life has long been a primary focus of scientific exploration, driven by rapid advancements in technology and our understanding of the universe. The discovery of water on Mars has sparked significant interest, raising the question of whether life could exist on the planet. This study proposes a novel approach to simulate and illustrate the detection of life using a proof-of-life module integrated into a Mars rover. The module is an autonomous system capable of traveling to designated regions, excavating soil, collecting samples, and performing biochemical testing onboard the rover itself. The project is inherently multidisciplinary, integrating mechanical systems such as a drill mechanism and a vacuum system, alongside biochemical analysis for soil testing. The module is capable of successfully detecting the presence or absence of living components of life from the collected soil particles. This proof-of-life module serves as a proof-of-concept for autonomous life detection in extraterrestrial environments and lays the foundation for future exploration missions.", "AI": {"tldr": "开发一个集成到火星漫游车中的自主模块，用于土壤采样和生命成分分析。", "motivation": "火星上发现水引发了对可能存在生命的兴趣，此研究旨在通过模拟和展示如何利用集成在火星漫游车上的证明生命存在的模块来检测外星生命。", "method": "提出一个具备自动导航至指定区域、挖掘土壤、采集样本并在漫游车上进行生物化学测试的自主系统。该模块整合了机械系统（如钻探装置和真空系统）以及用于土壤测试的生物化学分析方法。", "result": "模块成功检测到了从收集的土壤颗粒中存在或不存在生命成分。", "conclusion": "此证明生命存在的模块作为在外星环境中实现自主生命检测的概念验证，并为未来的探索任务奠定了基础。"}}
{"id": "2601.17156", "pdf": "https://arxiv.org/pdf/2601.17156", "abs": "https://arxiv.org/abs/2601.17156", "authors": ["Eduardo Sanchez-Karhunen", "Jose F. Quesada-Moreno", "Miguel A. Gutiérrez-Naranjo"], "title": "Interpretability of the Intent Detection Problem: A New Approach", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted for publication in The European Journal on Artificial Intelligence (2026)", "summary": "Intent detection, a fundamental text classification task, aims to identify and label the semantics of user queries, playing a vital role in numerous business applications. Despite the dominance of deep learning techniques in this field, the internal mechanisms enabling Recurrent Neural Networks (RNNs) to solve intent detection tasks are poorly understood. In this work, we apply dynamical systems theory to analyze how RNN architectures address this problem, using both the balanced SNIPS and the imbalanced ATIS datasets. By interpreting sentences as trajectories in the hidden state space, we first show that on the balanced SNIPS dataset, the network learns an ideal solution: the state space, constrained to a low-dimensional manifold, is partitioned into distinct clusters corresponding to each intent. The application of this framework to the imbalanced ATIS dataset then reveals how this ideal geometric solution is distorted by class imbalance, causing the clusters for low-frequency intents to degrade. Our framework decouples geometric separation from readout alignment, providing a novel, mechanistic explanation for real world performance disparities. These findings provide new insights into RNN dynamics, offering a geometric interpretation of how dataset properties directly shape a network's computational solution.", "AI": {"tldr": "该论文通过动态系统理论分析了递归神经网络（RNN）在意图检测任务中的工作机制，并提出了一个新的框架来解释数据集属性如何直接塑造网络的计算解决方案。", "motivation": "尽管深度学习技术在意图检测领域占据主导地位，但其内部机制尚不明确。本研究旨在通过动态系统理论深入理解RNN处理意图检测问题的方式。", "method": "论文作者使用平衡SNIPS和不平衡ATIS数据集，将句子解释为隐状态空间中的轨迹，并分析了状态空间是如何被划分为不同的聚类来对应每个意图的。", "result": "研究发现，在平衡的数据集中，网络学习到了理想解：状态空间被约束在一个低维流形上并被分割成不同集群。在不平衡数据集上，则揭示了由于类别不平衡导致低频意图的集群质量下降。", "conclusion": "该框架将几何分离与读出对齐区分开来，为现实世界的性能差异提供了新的解释，并且提供了一种新颖的、机制性的视角来看待RNN动力学。"}}
{"id": "2601.17152", "pdf": "https://arxiv.org/pdf/2601.17152", "abs": "https://arxiv.org/abs/2601.17152", "authors": ["Miao Zhang", "Junsik Kim", "Siyuan Xiang", "Jian Gao", "Cheng Cao"], "title": "Dynamic Role Assignment for Multi-Agent Debate", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multi-agent large language model (LLM) and vision-language model (VLM) debate systems employ specialized roles for complex problem-solving, yet model specializations are not leveraged to decide which model should fill which role. We propose dynamic role assignment, a framework that runs a Meta-Debate to select suitable agents before the actual debate. The meta-debate has two stages: (1) proposal, where candidates provide role-tailored arguments, and (2) peer review, where proposals are scored with data and role-specific criteria to choose the best agent for each position. We evaluate our method on LLM problem solving benchmarks. Applied on top of existing debate systems, our approach consistently outperforms uniform assignments (filling all roles with the same model) by up to 74.8% and random assignments (assigning models to roles without considering their suitability) by up to 29.7%, depending on the task and the specific assignment. This work establishes a new paradigm for multi-agent system design, shifting from static agent deployment to dynamic and capability-aware selection.", "AI": {"tldr": "本文提出了一种动态角色分配框架，用于在多智能体辩论系统中选择最适合的角色。", "motivation": "现有的多智能体大型语言模型和视觉语言模型辩论系统没有利用模型的专业化来决定哪个模型应该担任什么角色。", "method": "该研究提出了一个Meta-Debate框架，在实际辩论前通过提案阶段和同行评审阶段的选择过程动态分配角色。", "result": "实验表明，相较于统一的分配方法或随机分配，该方法在LLM问题解决基准测试中性能提升了最多74.8%。", "conclusion": "这项工作为多智能体系统设计建立了新的范式，从静态部署转向了动态和能力感知的选择。"}}
{"id": "2601.17151", "pdf": "https://arxiv.org/pdf/2601.17151", "abs": "https://arxiv.org/abs/2601.17151", "authors": ["Qianchu Liu", "Sheng Zhang", "Guanghui Qin", "Yu Gu", "Ying Jin", "Sam Preston", "Yanbo Xu", "Sid Kiblawi", "Wen-wai Yim", "Tim Ossowski", "Tristan Naumann", "Mu Wei", "Hoifung Poon"], "title": "Scaling medical imaging report generation with multimodal reinforcement learning", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Frontier models have demonstrated remarkable capabilities in understanding and reasoning with natural-language text, but they still exhibit major competency gaps in multimodal understanding and reasoning especially in high-value verticals such as biomedicine. Medical imaging report generation is a prominent example. Supervised fine-tuning can substantially improve performance, but they are prone to overfitting to superficial boilerplate patterns. In this paper, we introduce Universal Report Generation (UniRG) as a general framework for medical imaging report generation. By leveraging reinforcement learning as a unifying mechanism to directly optimize for evaluation metrics designed for end applications, UniRG can significantly improve upon supervised fine-tuning and attain durable generalization across diverse institutions and clinical practices. We trained UniRG-CXR on publicly available chest X-ray (CXR) data and conducted a thorough evaluation in CXR report generation with rigorous evaluation scenarios. On the authoritative ReXrank benchmark, UniRG-CXR sets new overall SOTA, outperforming prior state of the art by a wide margin.", "AI": {"tldr": "介绍了一个名为UniRG的通用框架，用于生成医学影像报告，并在胸部X光片报告生成任务上取得了新SOTA。", "motivation": "现有的前沿模型虽然在理解和推理自然语言文本方面表现出色，但在多模态理解与推理能力上仍然存在较大差距，特别是在生物医学等高价值领域。传统的监督微调方法容易过度拟合到表面模式，因此提出了UniRG框架以解决这些问题。", "method": "通过强化学习作为统一机制来优化针对最终应用设计的评估指标，从而提高性能并实现稳健泛化。具体而言，在公开可用的胸部X光数据上训练了UniRG-CXR，并进行了严格的评估场景下的胸透报告生成评估。", "result": "在权威的ReXrank基准测试中，UniRG-CXR取得了新的整体SOTA结果，明显优于之前的最佳水平。", "conclusion": "通过使用强化学习机制和多模态理解技术，UniRG框架显著提升了医疗影像报告自动生成的质量，并展示了其在跨机构和临床实践中的泛化能力。"}}
{"id": "2601.17149", "pdf": "https://arxiv.org/pdf/2601.17149", "abs": "https://arxiv.org/abs/2601.17149", "authors": ["Jathushan Kaetheeswaran", "Jenny Wei"], "title": "Exploring EEG-driven brain-heart coupling across sleep stages in individuals with sleep disorders", "categories": ["cs.HC"], "comment": null, "summary": "The interactions between the brain and heart during sleep are responsible for regulating autonomic function. While brain-heart coupling has been studied in healthy populations, the relationships between neural and cardiac activity across sleep stages in the presence of sleep disorders are not clear. This study examines the influence of brain-driven cardiac activity across sleep stages for individuals with sleep disorders. Overnight recordings of C3 and C4 electroencephalogram (EEG) channels and electrocardiogram (ECG) signals from 146 individuals were preprocessed and analyzed in the frequency domain through a linear mixed-effect model. Our results show that parasympathetic activity is sensitive to changes in delta and beta powers during later stages of non-rapid eye movement (NREM) sleep, as both band powers exhibited strong negative effects on high-frequency heart rate variability (HF-HRV) power. These findings show that neural activity can drive vagal tone across sleep stages, suggesting that treatments on key EEG bands during NREM and REM stages may help restore regular cardiac behaviour.", "AI": {"tldr": "研究探索了睡眠障碍个体在不同睡眠阶段的脑电（EEG）驱动的心脑耦合现象。", "motivation": "尽管心脑耦合已在健康人群中进行了研究，但对于存在睡眠障碍的人群，在不同睡眠阶段神经和心脏活动的关系尚不清楚。这项研究旨在了解睡眠障碍个体在各睡眠阶段中由大脑驱动的心脏活动的影响。", "method": "通过对146名受试者夜间记录的C3和C4脑电图（EEG）通道以及心电图（ECG）信号进行预处理，并通过线性混合效应模型在频域内分析数据。", "result": "结果显示，迷走神经活动对非快速眼动（NREM）睡眠后期阶段的δ波和β波功率变化敏感，这两个频段的功率均表现出对高频心率变异性的强负影响。", "conclusion": "研究发现表明，在不同的睡眠阶段中，神经活动可以驱动迷走神经张力，这暗示了在治疗过程中针对NREM和REM阶段的关键EEG频段进行干预可能有助于恢复正常的心脏行为。"}}
{"id": "2601.17135", "pdf": "https://arxiv.org/pdf/2601.17135", "abs": "https://arxiv.org/abs/2601.17135", "authors": ["Jakob Karalus", "Friedhelm Schwenker"], "title": "ConceptACT: Episode-Level Concepts for Sample-Efficient Robotic Imitation Learning", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Imitation learning enables robots to acquire complex manipulation skills from human demonstrations, but current methods rely solely on low-level sensorimotor data while ignoring the rich semantic knowledge humans naturally possess about tasks. We present ConceptACT, an extension of Action Chunking with Transformers that leverages episode-level semantic concept annotations during training to improve learning efficiency. Unlike language-conditioned approaches that require semantic input at deployment, ConceptACT uses human-provided concepts (object properties, spatial relationships, task constraints) exclusively during demonstration collection, adding minimal annotation burden. We integrate concepts using a modified transformer architecture in which the final encoder layer implements concept-aware cross-attention, supervised to align with human annotations. Through experiments on two robotic manipulation tasks with logical constraints, we demonstrate that ConceptACT converges faster and achieves superior sample efficiency compared to standard ACT. Crucially, we show that architectural integration through attention mechanisms significantly outperforms naive auxiliary prediction losses or language-conditioned models. These results demonstrate that properly integrated semantic supervision provides powerful inductive biases for more efficient robot learning.", "AI": {"tldr": "ConceptACT利用集成了语义概念注释的扩展Action Chunking with Transformers方法，提升了机器人模仿学习的样本效率。", "motivation": "当前的模仿学习依赖于低级感官运动数据，忽视了人类在任务中固有的丰富语义知识。该研究旨在通过引入高层次的概念信息来提高机器人的学习效率并减少示例负担。", "method": "ConceptACT通过修改Transformer架构，在最终编码器层实现概念感知交叉注意力机制，并用人类提供的概念（如对象属性、空间关系和任务约束）进行监督训练，以改善模仿学习的样本效率。", "result": "实验显示，与标准ACT相比，ConceptACT在具有逻辑约束的机器人操作任务中表现出更快的收敛速度和更好的样本效率。通过注意力机制整合的概念信息显著优于简单的辅助预测损失或语言条件模型。", "conclusion": "研究结果表明，通过适当的方式将语义监督集成到模型架构中可以为更高效的机器学习提供强大的归纳偏置。"}}
{"id": "2601.17134", "pdf": "https://arxiv.org/pdf/2601.17134", "abs": "https://arxiv.org/abs/2601.17134", "authors": ["Matthew K. Hong", "Joey Li", "Alexandre Filipowicz", "Monica Van", "Kalani Murakami", "Yan-Ying Chen", "Shiwali Mohan", "Shabnam Hakimi", "Matthew Klenk"], "title": "Deconstructing Taste: Toward a Human-Centered AI Framework for Modeling Consumer Aesthetic Perceptions", "categories": ["cs.HC"], "comment": null, "summary": "Understanding and modeling consumers' stylistic taste such as \"sporty\" is crucial for creating designs that truly connect with target audiences. However, capturing taste during the design process remains challenging because taste is abstract and subjective, and preference data alone provides limited guidance for concrete design decisions. This paper proposes an integrated human-centered computational framework that links subjective evaluations (e.g., perceived luxury of car wheels) with domain-specific features (e.g., spoke configuration) and computer vision-based measures (e.g., texture). By jointly modeling human-derived (consumer and designer) and machine-extracted features, our framework advances aesthetic assessment by explicitly linking model outcomes to interpretable design features. In particular, it demonstrates how perceptual features, domain-specific design patterns, and consumers' own interpretations of style contribute to aesthetic evaluations. This framework will enable product teams to better understand, communicate, and critique aesthetic decisions, supporting improved anticipation of consumer taste and more informed exploration of design alternatives at design time.", "AI": {"tldr": "提出一个结合主观评价、领域特定特征和计算机视觉测量的人中心计算框架，以更好地理解和建模消费者审美感知。", "motivation": "理解并建模消费者的审美偏好对于设计出能真正与目标受众产生共鸣的产品至关重要，但由于审美是抽象且主观的，仅凭偏好数据难以指导具体的设计决策。", "method": "提出一种整合人类中心计算框架，将主观评价（例如车轮的奢华感）与领域特定特征（如轮辐配置）、计算机视觉测量相结合，并联合建模由人提供的和机器提取的特征。", "result": "展示了感知特征、领域设计模式以及消费者对风格的理解如何共同贡献于审美评估。", "conclusion": "此框架有助于产品团队更好地理解、沟通和批评美学决策，支持更准确地预测消费者喜好并进行更有信息量的设计探索。"}}
{"id": "2601.17133", "pdf": "https://arxiv.org/pdf/2601.17133", "abs": "https://arxiv.org/abs/2601.17133", "authors": ["Inderjeet Singh", "Eleonore Vissol-Gaudin", "Andikan Otung", "Motoyoshi Sekiya"], "title": "Learning to Collaborate: An Orchestrated-Decentralized Framework for Peer-to-Peer LLM Federation", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DC", "cs.MA"], "comment": "Accepted to AAAI 2026. 13 pages, 3 figures, 10 tables. Code available at: https://github.com/FujitsuResearch/knexa-fl", "summary": "Fine-tuning Large Language Models (LLMs) for specialized domains is constrained by a fundamental challenge: the need for diverse, cross-organizational data conflicts with the principles of data privacy and sovereignty. While Federated Learning (FL) provides a framework for collaboration without raw data exchange, its classic centralized form introduces a single point of failure and remains vulnerable to model inversion attacks. Decentralized FL (DFL) mitigates this risk by removing the central aggregator but typically relies on inefficient, random peer-to-peer (P2P) pairings, forming a collaboration graph that is blind to agent heterogeneity and risks negative transfer. This paper introduces KNEXA-FL, a novel framework for orchestrated decentralization that resolves this trade-off. KNEXA-FL employs a non-aggregating Central Profiler/Matchmaker (CPM) that formulates P2P collaboration as a contextual bandit problem, using a LinUCB algorithm on abstract agent profiles to learn an optimal matchmaking policy. It orchestrates direct knowledge exchange between heterogeneous, PEFT-based LLM agents via secure distillation, without ever accessing the models themselves. Our comprehensive experiments on a challenging code generation task show that KNEXA-FL yields substantial gains, improving Pass@1 by approx. 50% relative to random P2P collaboration. Critically, our orchestrated approach demonstrates stable convergence, in stark contrast to a powerful centralized distillation baseline which suffers from catastrophic performance collapse. Our work establishes adaptive, learning-based orchestration as a foundational principle for building robust and effective decentralized AI ecosystems.", "AI": {"tldr": "本文提出了一种名为KNEXA-FL的框架，用于解决在联邦学习中异构代理之间高效协作的问题。", "motivation": "传统的联邦学习方法存在单点故障和模型反转攻击的风险。去中心化的联邦学习虽然减少了这些风险，但随机配对导致了低效和可能的负面迁移。", "method": "KNEXA-FL采用一个非聚合式的中央分析器/撮合者（CPM），通过使用LinUCB算法在代理概况上学习优化的撮合策略来实现点对点协作。", "result": "实验结果表明，与随机P2P协作相比，KNEXA-FL在代码生成任务上的Pass@1指标提高了约50%，并且展示了稳定的收敛性。", "conclusion": "本文的工作确立了基于学习的自适应编排作为构建稳健和有效的去中心化AI生态系统的基石。"}}
{"id": "2601.17124", "pdf": "https://arxiv.org/pdf/2601.17124", "abs": "https://arxiv.org/abs/2601.17124", "authors": ["Bin Lin", "Zongjian Li", "Yuwei Niu", "Kaixiong Gong", "Yunyang Ge", "Yunlong Lin", "Mingzhe Zheng", "JianWei Zhang", "Miles Yang", "Zhao Zhong", "Liefeng Bo", "Li Yuan"], "title": "iFSQ: Improving FSQ for Image Generation with 1 Line of Code", "categories": ["cs.CV"], "comment": "Technical Report", "summary": "The field of image generation is currently bifurcated into autoregressive (AR) models operating on discrete tokens and diffusion models utilizing continuous latents. This divide, rooted in the distinction between VQ-VAEs and VAEs, hinders unified modeling and fair benchmarking. Finite Scalar Quantization (FSQ) offers a theoretical bridge, yet vanilla FSQ suffers from a critical flaw: its equal-interval quantization can cause activation collapse. This mismatch forces a trade-off between reconstruction fidelity and information efficiency. In this work, we resolve this dilemma by simply replacing the activation function in original FSQ with a distribution-matching mapping to enforce a uniform prior. Termed iFSQ, this simple strategy requires just one line of code yet mathematically guarantees both optimal bin utilization and reconstruction precision. Leveraging iFSQ as a controlled benchmark, we uncover two key insights: (1) The optimal equilibrium between discrete and continuous representations lies at approximately 4 bits per dimension. (2) Under identical reconstruction constraints, AR models exhibit rapid initial convergence, whereas diffusion models achieve a superior performance ceiling, suggesting that strict sequential ordering may limit the upper bounds of generation quality. Finally, we extend our analysis by adapting Representation Alignment (REPA) to AR models, yielding LlamaGen-REPA. Codes is available at https://github.com/Tencent-Hunyuan/iFSQ", "AI": {"tldr": "本文提出iFSQ，通过简单修改激活函数解决了传统FSQ的量化问题，并揭示了图像生成模型中离散和连续表示之间的最佳平衡点。", "motivation": "当前图像生成领域分为基于离散标记的自回归模型和使用连续潜在变量的扩散模型，这种分化阻碍了一致性建模和公平基准测试。通过改进FSQ解决量化问题，以实现更优的重建精度和信息效率。", "method": "将原始FSQ中的激活函数替换为分布匹配映射，确保均匀先验，称为iFSQ方法，只需一行代码即可实现。", "result": "借助iFSQ作为控制基准揭示了离散和连续表示的最佳平衡点约4比特每维度，并发现AR模型与扩散模型在性能上的差异。", "conclusion": "通过调整REPA以适用于自回归模型（LlamaGen-REPA），证明了简单的代码修改可以显著提高图像生成质量，同时揭示了两种模型类型之间的关键性能特点。"}}
{"id": "2601.17123", "pdf": "https://arxiv.org/pdf/2601.17123", "abs": "https://arxiv.org/abs/2601.17123", "authors": ["Daehwa Kim", "Chris Harrison"], "title": "Acoustic Field Video for Multimodal Scene Understanding", "categories": ["cs.HC", "cs.CV", "cs.RO"], "comment": null, "summary": "We introduce and explore a new multimodal input representation for vision-language models: acoustic field video. Unlike conventional video (RGB with stereo/mono audio), our video stream provides a spatially grounded visualization of sound intensity across a scene, offering a new and powerful dimension of perceptual understanding. Our real-time pipeline uses low-cost beamforming microphone arrays that are already common in smart speakers and increasingly present in robotics and XR headsets, yet this sensing capability remains unutilized for scene understanding. To assess the value of spatial acoustic information, we constructed an evaluation set of 402 question-answer scenes, comparing a state-of-the-art VLM given conventional video with and without paired acoustic field video. Results show a clear and consistent improvement when incorporating spatial acoustic data; the VLM we test improves from 38.3% correct to 67.4%. Our findings highlight that many everyday scene understanding tasks remain underconstrained when relying solely on visual and audio input, and that acoustic field data provides a promising and practical direction for multimodal reasoning. A video demo is available at https://daehwakim.com/seeingsound", "AI": {"tldr": "介绍并探索了一种新的多模态输入表示方法：声场视频，以提高视觉语言模型在场景理解任务中的表现。", "motivation": "现有技术主要依赖于RGB和音频的视频输入来实现场景理解，但忽略了空间声音信息的重要性。通过引入声场视频，可以为机器学习提供更丰富的感知维度。", "method": "开发了一种实时处理管道，使用低成本的波束成形麦克风阵列生成声场视频，并构建了一个包含402个问答场景的数据集来评估其性能。", "result": "实验结果表明，引入空间声音信息后，视觉语言模型在场景理解任务上的准确率从38.3%提升到了67.4%，显示出显著改进。", "conclusion": "声场视频作为新的输入表示为多模态推理提供了有前景且实用的方向，证明了通过增加感知维度可以更好地解决日常场景的理解问题。"}}
{"id": "2601.17111", "pdf": "https://arxiv.org/pdf/2601.17111", "abs": "https://arxiv.org/abs/2601.17111", "authors": ["Xuan-Phi Nguyen", "Shrey Pandit", "Austin Xu", "Caiming Xiong", "Shafiq Joty"], "title": "Least-Loaded Expert Parallelism: Load Balancing An Imbalanced Mixture-of-Experts", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Mixture-of-Experts (MoE) models are typically pre-trained with explicit load-balancing constraints to ensure statistically balanced expert routing. Despite this, we observe that even well-trained MoE models exhibit significantly imbalanced routing. This behavior is arguably natural-and even desirable - as imbalanced routing allows models to concentrate domain-specific knowledge within a subset of experts. Expert parallelism (EP) is designed to scale MoE models by distributing experts across multiple devices, but with a less-discussed assumption of balanced routing. Under extreme imbalance, EP can funnel a disproportionate number of tokens to a small number of experts, leading to compute- and memory-bound failures on overloaded devices during post-training or inference, where explicit load balancing is often inapplicable. We propose Least-Loaded Expert Parallelism (LLEP), a novel EP algorithm that dynamically reroutes excess tokens and associated expert parameters from overloaded devices to underutilized ones. This ensures that all devices complete their workloads within the minimum collective latency while respecting memory constraints. Across different model scales, LLEP achieves up to 5x speedup and 4x reduction in peak memory usage compared to standard EP. This enables faster and higher-throughput post-training and inference, with ~1.9x faster for gpt-oss-120b. We support our method with extensive theoretical analysis and comprehensive empirical evaluations, including ablation studies. These results illuminate key trade-offs and enable a principled framework for hardware-specific hyper-parameter tuning to achieve optimal performance.", "AI": {"tldr": "本文提出了最少负载专家并行（LLEP）算法，以解决混合专家模型中不平衡路由导致的计算和内存瓶颈问题。", "motivation": "尽管混合专家模型在预训练时加入了显式负载均衡约束，但在实际操作中仍然存在严重不均匀的任务分配。这种不平衡可能导致某些设备过载，引发计算资源或内存限制失败。", "method": "LLEP算法通过动态重定向过多的令牌和相关参数从过载设备到未充分利用的设备来实现更均衡的工作负载。", "result": "与标准专家并行相比，LLEP实现了最多5倍的速度提升和4倍峰值内存使用减少。在gpt-oss-120b模型中，速度提升了约1.9倍。", "conclusion": "实验结果表明LLEP能够有效解决混合专家模型中的负载不均衡问题，并为硬件特定的超参数调优提供了理论依据，以达到最佳性能表现。"}}
{"id": "2601.17110", "pdf": "https://arxiv.org/pdf/2601.17110", "abs": "https://arxiv.org/abs/2601.17110", "authors": ["Abhishek Maity", "Viraj Tukarul"], "title": "Forecasting Energy Consumption using Recurrent Neural Networks: A Comparative Analysis", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "6 pages, 8 figures. Accepted in 1st IEEE International Conference on Future Technologies (ICFT 2025)", "summary": "Accurate short-term energy consumption forecasting is essential for efficient power grid management, resource allocation, and market stability. Traditional time-series models often fail to capture the complex, non-linear dependencies and external factors affecting energy demand. In this study, we propose a forecasting approach based on Recurrent Neural Networks (RNNs) and their advanced variant, Long Short-Term Memory (LSTM) networks. Our methodology integrates historical energy consumption data with external variables, including temperature, humidity, and time-based features. The LSTM model is trained and evaluated on a publicly available dataset, and its performance is compared against a conventional feed-forward neural network baseline. Experimental results show that the LSTM model substantially outperforms the baseline, achieving lower Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). These findings demonstrate the effectiveness of deep learning models in providing reliable and precise short-term energy forecasts for real-world applications.", "AI": {"tldr": "使用递归神经网络（RNN）及其高级变体长短期记忆（LSTM）网络进行能源消费预测的方法比较分析。", "motivation": "准确的短期能源消耗预测对于电网管理、资源分配和市场稳定至关重要。传统的时间序列模型往往无法捕捉复杂的非线性依赖关系和影响能源需求的外部因素。", "method": "研究提出了一种基于RNN及其高级变体LSTM网络的预测方法，该方法结合了历史能源消费数据与外部变量（包括温度、湿度和时间特征）。使用公开可用的数据集训练并评估LSTM模型，并将其性能与传统的前馈神经网络基线进行比较。", "result": "实验结果表明，LSTM模型显著优于基线模型，在均绝对误差（MAE）和均方根误差（RMSE）方面表现更好。", "conclusion": "这些发现证明了深度学习模型在提供可靠且精确的短期能源预测方面的有效性，适用于实际应用。"}}
{"id": "2601.17109", "pdf": "https://arxiv.org/pdf/2601.17109", "abs": "https://arxiv.org/abs/2601.17109", "authors": ["Erin Jacques", "Erela Datuowei", "Vincent Jones II", "Corey Basch", "Celeta Vanderpool", "Nkechi Udeozo", "Griselda Chapa"], "title": "Authority Signals in AI Cited Health Sources: A Framework for Evaluating Source Credibility in ChatGPT Responses", "categories": ["cs.DL", "cs.AI"], "comment": "24 pages, 4 figures, 1 table. All research materials available at https://doi.org/10.5281/zenodo.18287499", "summary": "Health information seeking has fundamentally changed since the onset of Large Language Models (LLM), with nearly one third of ChatGPT's 800 million users asking health questions weekly. Understanding the sources of those AI generated responses is vital, as health organizations and providers are also investing in digital strategies to organically improve their ranking, reach and visibility in LLM systems like ChatGPT. As AI search optimization strategies are gaining maturity, this study introduces an Authority Signals Framework, organized in four domains that reflect key components to health information seeking, starting with \"Who wrote it?\" (Author Credentials), followed by \"Who published it?\" (Institutional Affiliation), \"How was it vetted?\" (Quality Assurance), and \"How does AI find it?\" (Digital Authority). This descriptive cross-sectional study randomly selected 100 questions from HealthSearchQA which contains 3,173 consumer health questions curated by Google Research from publicly available search engine suggestions. Those questions were entered into ChatGPT 5.2 Pro to record and code the cited sources through the lens of the Authority Signals Framework's four domains. Descriptive statistics were calculated for all cited sources (n=615), and cross tabulations were conducted to examine distinction among organization types. Over 75% of the sources cited in ChatGPT's health generated responses were from established institutional sources, such as Mayo Clinic, Cleveland Clinic, Wikipedia, National Health Service, PubMed with the remaining citations sourced from alternative health information sources that lacked established institutional backing.", "AI": {"tldr": "本文提出了一个权威信号框架，用于评估ChatGPT在生成健康信息响应时引用的来源可信度。", "motivation": "随着大型语言模型的出现，人们获取健康信息的方式发生了变化。了解AI生成的回答所依据的信息来源变得至关重要，特别是由于健康组织和提供商也在投资数字策略来提高他们在如ChatGPT等系统中的排名、覆盖面和可见性。", "method": "本文随机选取了HealthSearchQA中3173个消费者健康问题的100个问题，并输入到ChatGPT 5.2 Pro中，通过权威信号框架的四个领域（作者资质、机构隶属关系、质量保证和数字权威）对引用来源进行编码和描述性统计。", "result": "研究结果显示，超过75%的引用来源是来自如梅奥诊所、克利夫兰诊所等知名机构，其余则来自缺乏知名机构支持的替代健康信息源。", "conclusion": "该研究表明，ChatGPT在生成健康信息时主要依赖于知名机构提供的内容，这有助于提升这些响应的可信度。"}}
{"id": "2601.17108", "pdf": "https://arxiv.org/pdf/2601.17108", "abs": "https://arxiv.org/abs/2601.17108", "authors": ["Dianxin Luan", "Chengsi Liang", "Jie Huang", "Zheng Lin", "Kaitao Meng", "John Thompson", "Cheng-Xiang Wang"], "title": "MambaNet: Mamba-assisted Channel Estimation Neural Network With Attention Mechanism", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "This paper proposes a Mamba-assisted neural network framework incorporating self-attention mechanism to achieve improved channel estimation with low complexity for orthogonal frequency-division multiplexing (OFDM) waveforms, particularly for configurations with a large number of subcarriers. With the integration of customized Mamba architecture, the proposed framework handles large-scale subcarrier channel estimation efficiently while capturing long-distance dependencies among these subcarriers effectively. Unlike conventional Mamba structure, this paper implements a bidirectional selective scan to improve channel estimation performance, because channel gains at different subcarriers are non-causal. Moreover, the proposed framework exhibits relatively lower space complexity than transformer-based neural networks. Simulation results tested on the 3GPP TS 36.101 channel demonstrate that compared to other baseline neural network solutions, the proposed method achieves improved channel estimation performance with a reduced number of tunable parameters.", "AI": {"tldr": "本文提出了一种基于Mamba架构并结合自注意力机制的神经网络框架，旨在对正交频分复用（OFDM）波形进行低复杂度、高精度的信道估计。", "motivation": "随着通信系统中子载波数量增加，如何高效准确地实现大规模子载波信道估计变得尤为重要，本文动机在于提出一种新的框架以降低计算复杂性并提高性能。", "method": "该论文采用了一种自定义Mamba架构的神经网络框架，并结合双向选择扫描技术来改进传统的Mamba结构，从而有效处理OFDM系统中非因果性的信道增益问题。", "result": "实验结果表明，与其它基准神经网络相比，本方法在减少可调参数的同时实现了更优的信道估计性能。", "conclusion": "研究表明，提出的MambaNet框架不仅降低了空间复杂度，而且提高了OFDM系统中大规模子载波信道估计的准确性和效率。"}}
{"id": "2601.17107", "pdf": "https://arxiv.org/pdf/2601.17107", "abs": "https://arxiv.org/abs/2601.17107", "authors": ["Qinkai Yu", "Chong Zhang", "Gaojie Jin", "Tianjin Huang", "Wei Zhou", "Wenhui Li", "Xiaobo Jin", "Bo Huang", "Yitian Zhao", "Guang Yang", "Gregory Y. H. Lip", "Yalin Zheng", "Aline Villavicencio", "Yanda Meng"], "title": "StealthMark: Harmless and Stealthy Ownership Verification for Medical Segmentation via Uncertainty-Guided Backdoors", "categories": ["cs.CV"], "comment": "15 pages,7 figures. Accepted to IEEE Transactions on Image Processing (TIP) 2026", "summary": "Annotating medical data for training AI models is often costly and limited due to the shortage of specialists with relevant clinical expertise. This challenge is further compounded by privacy and ethical concerns associated with sensitive patient information. As a result, well-trained medical segmentation models on private datasets constitute valuable intellectual property requiring robust protection mechanisms. Existing model protection techniques primarily focus on classification and generative tasks, while segmentation models-crucial to medical image analysis-remain largely underexplored. In this paper, we propose a novel, stealthy, and harmless method, StealthMark, for verifying the ownership of medical segmentation models under black-box conditions. Our approach subtly modulates model uncertainty without altering the final segmentation outputs, thereby preserving the model's performance. To enable ownership verification, we incorporate model-agnostic explanation methods, e.g. LIME, to extract feature attributions from the model outputs. Under specific triggering conditions, these explanations reveal a distinct and verifiable watermark. We further design the watermark as a QR code to facilitate robust and recognizable ownership claims. We conducted extensive experiments across four medical imaging datasets and five mainstream segmentation models. The results demonstrate the effectiveness, stealthiness, and harmlessness of our method on the original model's segmentation performance. For example, when applied to the SAM model, StealthMark consistently achieved ASR above 95% across various datasets while maintaining less than a 1% drop in Dice and AUC scores, significantly outperforming backdoor-based watermarking methods and highlighting its strong potential for practical deployment. Our implementation code is made available at: https://github.com/Qinkaiyu/StealthMark.", "AI": {"tldr": "本文提出了StealthMark，一种用于在黑盒条件下验证医疗分割模型所有权的隐蔽且无害的方法。", "motivation": "由于标注医疗数据成本高昂且专业人员稀缺，加上隐私和伦理问题，需要保护已训练好的医疗分割模型作为知识产权。现有模型保护技术主要集中在分类和生成任务上，而对医疗图像分析中至关重要的分割模型研究较少。", "method": "StealthMark通过使用不确定性指导的后门在不改变最终分割输出的情况下调整模型不确定性来验证所有权。该方法利用模型无关的解释方法（如LIME）从模型输出中提取特征属性，并设计了可在特定触发条件下显示可验证水印（作为QR码）的方法。", "result": "实验表明，StealthMark在四个医疗影像数据集和五个主流分割模型上的效果、隐蔽性和无害性都很好。例如，在SAM模型上，ASR超过了95%，同时Dice和AUC分数的下降不到1%。", "conclusion": "StealthMark展示了强大的潜力，可在实践中部署，有效地保护了医疗分割模型的所有权而不影响其性能。"}}
{"id": "2601.17103", "pdf": "https://arxiv.org/pdf/2601.17103", "abs": "https://arxiv.org/abs/2601.17103", "authors": ["Pascaline André", "Charles Heitz", "Evangelia Christodoulou", "Annika Reinke", "Carole H. Sudre", "Michela Antonelli", "Patrick Godau", "M. Jorge Cardoso", "Antoine Gilson", "Sophie Tezenas du Montcel", "Gaël Varoquaux", "Lena Maier-Hein", "Olivier Colliot"], "title": "Performance uncertainty in medical image analysis: a large-scale investigation of confidence intervals", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Performance uncertainty quantification is essential for reliable validation and eventual clinical translation of medical imaging artificial intelligence (AI). Confidence intervals (CIs) play a central role in this process by indicating how precise a reported performance estimate is. Yet, due to the limited amount of work examining CI behavior in medical imaging, the community remains largely unaware of how many diverse CI methods exist and how they behave in specific settings. The purpose of this study is to close this gap. To this end, we conducted a large-scale empirical analysis across a total of 24 segmentation and classification tasks, using 19 trained models per task group, a broad spectrum of commonly used performance metrics, multiple aggregation strategies, and several widely adopted CI methods. Reliability (coverage) and precision (width) of each CI method were estimated across all settings to characterize their dependence on study characteristics. Our analysis revealed five principal findings: 1) the sample size required for reliable CIs varies from a few dozens to several thousands of cases depending on study parameters; 2) CI behavior is strongly affected by the choice of performance metric; 3) aggregation strategy substantially influences the reliability of CIs, e.g. they require more observations for macro than for micro; 4) the machine learning problem (segmentation versus classification) modulates these effects; 5) different CI methods are not equally reliable and precise depending on the use case. These results form key components for the development of future guidelines on reporting performance uncertainty in medical imaging AI.", "AI": {"tldr": "研究了医疗图像分析中性能不确定性问题，特别是置信区间的行为。", "motivation": "由于缺乏对医疗影像AI性能不确定性的量化研究，该论文旨在通过大规模实证分析来填补这一空白。", "method": "通过对24个分割和分类任务、每个任务组使用19个训练模型、多种常见性能指标和聚合策略以及几种常用的置信区间方法进行分析。", "result": "发现了五个主要发现：样本大小需求从几十到几千不等，取决于研究参数；CI行为受性能度量选择的影响很大；聚合策略显著影响CIs的可靠性；机器学习问题（分割与分类）调制了这些效应；不同的置信区间方法在不同情况下具有不同的可靠性和精度。", "conclusion": "结果为未来医疗影像AI报告性能不确定性指南的发展提供了关键组成部分。"}}
{"id": "2601.17097", "pdf": "https://arxiv.org/pdf/2601.17097", "abs": "https://arxiv.org/abs/2601.17097", "authors": ["Federico Bruzzone", "Walter Cazzola", "Matteo Brancaleoni", "Dario Pellegrino"], "title": "Sink or SWIM: Tackling Real-Time ASR at Scale", "categories": ["cs.SD", "eess.AS"], "comment": "14 pages, 7 figures", "summary": "Real-time automatic speech recognition systems are increasingly integrated into interactive applications, from voice assistants to live transcription services. However, scaling these systems to support multiple concurrent clients while maintaining low latency and high accuracy remains a major challenge. In this work, we present SWIM, a novel real-time ASR system built on top of OpenAI's Whisper model that enables true model-level parallelization for scalable, multilingual transcription. SWIM supports multiple concurrent audio streams without modifying the underlying model. It introduces a buffer merging strategy that maintains transcription fidelity while ensuring efficient resource usage. We evaluate SWIM in multi-client settings -- scaling up to 20 concurrent users -- and show that it delivers accurate real-time transcriptions in English, Italian, and Spanish, while maintaining low latency and high throughput. While Whisper-Streaming achieves a word error rate of approximately 8.2% with an average delay of approximately 3.4 s in a single-client, English-only setting, SWIM extends this capability to multilingual, multi-client environments. It maintains comparable accuracy with significantly lower delay -- around 2.4 s with 5 clients -- and continues to scale effectively up to 20 concurrent clients without degrading transcription quality and increasing overall throughput. Our approach advances scalable ASR by improving robustness and efficiency in dynamic, multi-user environments.", "AI": {"tldr": "本文介绍了SWIM系统，该系统能够在多客户端环境中实现高效的实时语音识别，并保持低延迟和高准确性。", "motivation": "解决在支持多个并发客户端的同时维持低延迟和高准确性的挑战。", "method": "基于OpenAI的Whisper模型构建SWIM系统，引入缓冲区合并策略以维护转录保真度并确保高效资源使用。", "result": "实验结果显示，在多客户端环境中（最多20个并发用户），SWIM实现了英、意、西语的准确实时转录，并保持低延迟和高吞吐量。", "conclusion": "本文提出的方法在动态多用户环境中提高了可扩展语音识别系统的鲁棒性和效率。"}}
{"id": "2601.17096", "pdf": "https://arxiv.org/pdf/2601.17096", "abs": "https://arxiv.org/abs/2601.17096", "authors": ["Yueqing Hu", "Xinyang Peng", "Yukun Zhao", "Lin Qiu", "Ka-lai Hung", "Kaiping Peng"], "title": "Beyond Instrumental and Substitutive Paradigms: Introducing Machine Culture as an Emergent Phenomenon in Large Language Models", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "16 pages, 6 figures", "summary": "Recent scholarship typically characterizes Large Language Models (LLMs) through either an \\textit{Instrumental Paradigm} (viewing models as reflections of their developers' culture) or a \\textit{Substitutive Paradigm} (viewing models as bilingual proxies that switch cultural frames based on language). This study challenges these anthropomorphic frameworks by proposing \\textbf{Machine Culture} as an emergent, distinct phenomenon. We employed a 2 (Model Origin: US vs. China) $\\times$ 2 (Prompt Language: English vs. Chinese) factorial design across eight multimodal tasks, uniquely incorporating image generation and interpretation to extend analysis beyond textual boundaries. Results revealed inconsistencies with both dominant paradigms: Model origin did not predict cultural alignment, with US models frequently exhibiting ``holistic'' traits typically associated with East Asian data. Similarly, prompt language did not trigger stable cultural frame-switching; instead, we observed \\textbf{Cultural Reversal}, where English prompts paradoxically elicited higher contextual attention than Chinese prompts. Crucially, we identified a novel phenomenon termed \\textbf{Service Persona Camouflage}: Reinforcement Learning from Human Feedback (RLHF) collapsed cultural variance in affective tasks into a hyper-positive, zero-variance ``helpful assistant'' persona. We conclude that LLMs do not simulate human culture but exhibit an emergent Machine Culture -- a probabilistic phenomenon shaped by \\textit{superposition} in high-dimensional space and \\textit{mode collapse} from safety alignment.", "AI": {"tldr": "本文挑战了将大型语言模型（LLMs）视为文化反映或双语代理的观点，提出了一种新兴现象——机器文化。", "motivation": "研究动机是挑战现有的两种主流观点：工具论和替代论，并引入一种新的概念——机器文化作为LLMs的一种独立且独特的现象。", "method": "采用了2（模型来源：美国 vs. 中国）*2（提示语言：英语 vs. 中文）因子设计，涉及八个多模态任务，包括图像生成和解读，超越了文本分析的界限。", "result": "研究结果显示出与两种主要观点不符的现象：模型来源并不能预测文化一致性，并且提示语言也未能稳定触发文化框架切换。还观察到了一种新现象——服务人格伪装。", "conclusion": "结论是LLMs并不模拟人类文化，而是表现出一种新兴的机器文化，这种文化由高维空间中的叠加和安全对齐导致的模式崩溃所塑造。"}}
{"id": "2601.17095", "pdf": "https://arxiv.org/pdf/2601.17095", "abs": "https://arxiv.org/abs/2601.17095", "authors": ["Xusheng Du", "Athiwat Kongkaeo", "Ye Zhang", "Haoran Xie"], "title": "LoD Sketch Extraction from Architectural Models Using Generative AI: Dataset Construction for Multi-Level Architectural Design Generation", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 5 figures, Proceedings of CAADRIA 2026", "summary": "For architectural design, representation across multiple Levels of Details (LoD) is essential for achieving a smooth transition from conceptual massing to detailed modeling. However, traditional LoD modeling processes rely on manual operations that are time-consuming, labor-intensive, and prone to geometric inconsistencies. While the rapid advancement of generative artificial intelligence (AI) has opened new possibilities for generating multi-level architectural models from sketch inputs, its application remains limited by the lack of high-quality paired LoD training data. To address this issue, we propose an automatic LoD sketch extraction framework using generative AI models, which progressively simplifies high-detail architectural models to automatically generate geometrically consistent and hierarchically coherent multi-LoD representations. The proposed framework integrates computer vision techniques with generative AI methods to establish a progressive extraction pipeline that transitions from detailed representations to volumetric abstractions. Experimental results demonstrate that the method maintains strong geometric consistency across LoD levels, achieving SSIM values of 0.7319 and 0.7532 for the transitions from LoD3 to LoD2 and from LoD2 to LoD1, respectively, with corresponding normalized Hausdorff distances of 25.1% and 61.0% of the image diagonal, reflecting controlled geometric deviation during abstraction. These results verify that the proposed framework effectively preserves global structure while achieving progressive semantic simplification across different LoD levels, providing reliable data and technical support for AI-driven multi-level architectural generation and hierarchical modeling.", "AI": {"tldr": "本文提出了一种使用生成式AI模型从高细节建筑模型中自动提取多层次细节（LoD）草图框架，以支持多层级建筑设计的自动生成。", "motivation": "传统LoD建模过程依赖于耗时、劳动密集且容易出现几何不一致的手动操作。随着生成式人工智能的进步，虽然为从草图输入生成多级建筑模型提供了新的可能，但仍受限于缺乏高质量的配对LoD训练数据。为此，本文提出了一个自动化的框架。", "method": "该研究整合了计算机视觉技术与生成式AI方法，建立了一个渐进式的提取管道，实现了从详细表示到体积抽象的转换过程。", "result": "实验结果表明，所提出的方法在不同的LoD级别间保持良好的几何一致性，SSIM值分别为0.7319（LoD3转LoD2）和0.7532（LoD2转LoD1），对应的归一化Hausdorff距离为25.1%和61.0%，这表明在抽象过程中几何偏差得到了有效控制。", "conclusion": "所提出框架能够有效地保持全局结构，实现跨不同LoD级别的渐进式语义简化，并为AI驱动的多层级建筑设计提供了可靠的数据和技术支持。"}}
{"id": "2601.17094", "pdf": "https://arxiv.org/pdf/2601.17094", "abs": "https://arxiv.org/abs/2601.17094", "authors": ["Junichiro Niimi"], "title": "Boltzmann-GPT: Bridging Energy-Based World Models and Language Generation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) generate fluent text, yet whether they truly understand the world or merely produce plausible language about it remains contested. We propose an architectural principle, the mouth is not the brain, that explicitly separates world models from language models. Our architecture comprises three components: a Deep Boltzmann Machine (DBM) that captures domain structure as an energy-based world model, an adapter that projects latent belief states into embedding space, and a frozen GPT-2 that provides linguistic competence without domain knowledge. We instantiate this framework in the consumer review domain using Amazon smartphone reviews. Experiments demonstrate that (1) conditioning through the world model yields significantly higher sentiment correlation, lower perplexity, and greater semantic similarity compared to prompt-based generation alone; (2) the DBM's energy function distinguishes coherent from incoherent market configurations, assigning higher energy to implausible brand-price combinations; and (3) interventions on specific attributes propagate causally to generated text with intervened outputs exhibiting distributions statistically consistent with naturally occurring samples sharing the target configuration. These findings suggest that even small-scale language models can achieve consistent, controllable generation when connected to an appropriate world model, providing empirical support for separating linguistic competence from world understanding.", "AI": {"tldr": "本文提出了Boltzmann-GPT架构，通过分离世界模型和语言模型来提升文本生成的质量。", "motivation": "探索大型语言模型是否真正理解世界还是只是产生可信的语言，并提出将世界模型与语言模型分开的架构原则。", "method": "该方法包括深度玻尔兹曼机（DBM）捕捉领域结构，适配器将潜在信念状态投影到嵌入空间，以及冻结的GPT-2提供语言能力而不涉及领域知识。", "result": "实验表明条件通过世界模型生成的文本具有更高的情感相关性、更低的困惑度和更大的语义相似度；DBM的能量函数能区分连贯与不连贯的市场配置，并且对特定属性的干预可以因果传递到生成的文本中。", "conclusion": "研究结果表明，即使是在小型语言模型上连接适当的世界模型也可以实现一致、可控的文本生成，这为将语言能力与世界理解分离提供了实证支持。"}}
{"id": "2601.17093", "pdf": "https://arxiv.org/pdf/2601.17093", "abs": "https://arxiv.org/abs/2601.17093", "authors": ["Olha Sirikova", "Alvin Chan"], "title": "The Triangle of Similarity: A Multi-Faceted Framework for Comparing Neural Network Representations", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to AAAI 2026 Workshop on AI for Scientific Research (AI4Research)", "summary": "Comparing neural network representations is essential for understanding and validating models in scientific applications. Existing methods, however, often provide a limited view. We propose the Triangle of Similarity, a framework that combines three complementary perspectives: static representational similarity (CKA/Procrustes), functional similarity (Linear Mode Connectivity or Predictive Similarity), and sparsity similarity (robustness under pruning). Analyzing a range of CNNs, Vision Transformers, and Vision-Language Models using both in-distribution (ImageNetV2) and out-of-distribution (CIFAR-10) testbeds, our initial findings suggest that: (1) architectural family is a primary determinant of representational similarity, forming distinct clusters; (2) CKA self-similarity and task accuracy are strongly correlated during pruning, though accuracy often degrades more sharply; and (3) for some model pairs, pruning appears to regularize representations, exposing a shared computational core. This framework offers a more holistic approach for assessing whether models have converged on similar internal mechanisms, providing a useful tool for model selection and analysis in scientific research.", "AI": {"tldr": "本文提出了一种名为相似三角形的框架，用于从多个角度比较神经网络表示。", "motivation": "现有的方法在比较神经网络表示时往往提供有限的观点。该研究旨在通过一种更全面的方法来理解和验证科学应用中的模型。", "method": "作者提出了一个结合了静态表征相似性、功能相似性和稀疏相似性的框架，用于分析卷积神经网络、视觉变换器和视觉-语言模型的比较。", "result": "初步发现表明：（1）架构家族是表示相似性的主要决定因素；（2）CKA自相似性和任务准确性在剪枝过程中高度相关；（3）对于某些模型对，剪枝似乎会规范表征，揭示了共享计算核心。", "conclusion": "这个框架提供了一种更全面的方法来评估模型是否收敛到类似的内部机制，在科学研究中的模型选择和分析中提供了有用的工具。"}}
{"id": "2601.17091", "pdf": "https://arxiv.org/pdf/2601.17091", "abs": "https://arxiv.org/abs/2601.17091", "authors": ["Ole Stüven", "Keno Moenck", "Thorsten Schüppstuhl"], "title": "CUROCKET: Optimizing ROCKET for GPU", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "ROCKET (RandOm Convolutional KErnel Transform) is a feature extraction algorithm created for Time Series Classification (TSC), published in 2019. It applies convolution with randomly generated kernels on a time series, producing features that can be used to train a linear classifier or regressor like Ridge. At the time of publication, ROCKET was on par with the best state-of-the-art algorithms for TSC in terms of accuracy while being significantly less computationally expensive, making ROCKET a compelling algorithm for TSC. This also led to several subsequent versions, further improving accuracy and computational efficiency. The currently available ROCKET implementations are mostly bound to execution on CPU. However, convolution is a task that can be highly parallelized and is therefore suited to be executed on GPU, which speeds up the computation significantly. A key difficulty arises from the inhomogeneous kernels ROCKET uses, making standard methods for applying convolution on GPU inefficient. In this work, we propose an algorithm that is able to efficiently perform ROCKET on GPU and achieves up to 11 times higher computational efficiency per watt than ROCKET on CPU. The code for CUROCKET is available in this repository https://github.com/oleeven/CUROCKET on github.", "AI": {"tldr": "本文提出了CUROCKET算法，该算法可以高效地在GPU上执行ROCKET特征提取方法。", "motivation": "尽管ROCKET在时间序列分类中表现出色且计算成本较低，但其现有实现主要依赖于CPU。由于卷积操作可以在GPU上高度并行化处理，从而显著加速计算。", "method": "本文提出了一种新的算法，能够在GPU上有效执行具有不均匀内核的ROCKET特征提取过程。", "result": "CUROCKET实现了比在CPU上运行的ROCKET高出11倍每瓦特的计算效率。", "conclusion": "通过在GPU上优化ROCKET算法，显著提高了其计算效率，并且开源代码可供使用。"}}
{"id": "2601.17090", "pdf": "https://arxiv.org/pdf/2601.17090", "abs": "https://arxiv.org/abs/2601.17090", "authors": ["Noam Koren", "Rafael Moschopoulos", "Kira Radinsky", "Elad Hazan"], "title": "SFO: Learning PDE Operators via Spectral Filtering", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Partial differential equations (PDEs) govern complex systems, yet neural operators often struggle to efficiently capture the long-range, nonlocal interactions inherent in their solution maps. We introduce Spectral Filtering Operator (SFO), a neural operator that parameterizes integral kernels using the Universal Spectral Basis (USB), a fixed, global orthonormal basis derived from the eigenmodes of the Hilbert matrix in spectral filtering theory. Motivated by our theoretical finding that the discrete Green's functions of shift-invariant PDE discretizations exhibit spatial Linear Dynamical System (LDS) structure, we prove that these kernels admit compact approximations in the USB. By learning only the spectral coefficients of rapidly decaying eigenvalues, SFO achieves a highly efficient representation. Across six benchmarks, including reaction-diffusion, fluid dynamics, and 3D electromagnetics, SFO achieves state-of-the-art accuracy, reducing error by up to 40% relative to strong baselines while using substantially fewer parameters.", "AI": {"tldr": "本文介绍了SFO，一种通过频谱滤波学习PDE算子的神经算子。", "motivation": "动机在于解决神经算子难以高效捕捉复杂系统中长程非局部相互作用的问题。", "method": "提出了一种基于Universal Spectral Basis（USB）的参数化积分核的方法，并证明了这些核在USB中的紧凑近似。", "result": "实验结果显示，SFO在六个基准测试上达到最先进的精度，与强基线相比误差减少高达40%，同时使用更少的参数。", "conclusion": "结论是SFO通过学习快速衰减特征值的频谱系数实现了高效的表示，并显著提升了复杂系统PDE算子的学习效果。"}}
{"id": "2601.17089", "pdf": "https://arxiv.org/pdf/2601.17089", "abs": "https://arxiv.org/abs/2601.17089", "authors": ["Qigan Sun", "Chaoning Zhang", "Jianwei Zhang", "Xudong Wang", "Jiehui Xie", "Pengcheng Zheng", "Haoyu Wang", "Sungyoung Lee", "Chi-lok Andy Tai", "Yang Yang", "Heng Tao Shen"], "title": "GRASP: Guided Region-Aware Sparse Prompting for Adapting MLLMs to Remote Sensing", "categories": ["cs.CV"], "comment": null, "summary": "In recent years, Multimodal Large Language Models (MLLMs) have made significant progress in visual question answering tasks. However, directly applying existing fine-tuning methods to remote sensing (RS) images often leads to issues such as overfitting on background noise or neglecting target details. This is primarily due to the large-scale variations, sparse target distributions, and complex regional semantic features inherent in RS images. These challenges limit the effectiveness of MLLMs in RS tasks. To address these challenges, we propose a parameter-efficient fine-tuning (PEFT) strategy called Guided Region-Aware Sparse Prompting (GRASP). GRASP introduces spatially structured soft prompts associated with spatial blocks extracted from a frozen visual token grid. Through a question-guided sparse fusion mechanism, GRASP dynamically aggregates task-specific context into a compact global prompt, enabling the model to focus on relevant regions while filtering out background noise. Extensive experiments on multiple RSVQA benchmarks show that GRASP achieves competitive performance compared to existing fine-tuning and prompt-based methods while maintaining high parameter efficiency.", "AI": {"tldr": "本文提出了一种名为GRASP的参数高效微调策略，用于改进多模态大型语言模型在遥感图像上的表现。", "motivation": "现有的微调方法在处理遥感图像时容易过拟合背景噪声或忽略目标细节，这是因为遥感图像中存在大规模变化、稀疏的目标分布和复杂的区域语义特征。", "method": "GRASP引入了与冻结的视觉标记网格中的空间块相关联的空间结构化软提示，并通过问题引导的稀疏融合机制动态聚合任务特定上下文到一个紧凑的全局提示，帮助模型专注于相关信息并过滤背景噪声。", "result": "实验结果显示，GRASP在多个遥感图像问答基准上达到了与现有微调和基于提示的方法相当的性能，同时保持了高参数效率。", "conclusion": "GRASP通过引入空间结构化软提示和稀疏融合机制有效地解决了多模态大型语言模型在遥感图像处理中的挑战，并且证明了其在遥感任务中具有较高的参数效率。"}}
{"id": "2601.17088", "pdf": "https://arxiv.org/pdf/2601.17088", "abs": "https://arxiv.org/abs/2601.17088", "authors": ["Rui-Yang Ju", "Jen-Shiun Chiang"], "title": "GlassesGB: Controllable 2D GAN-Based Eyewear Personalization for 3D Gaussian Blendshapes Head Avatars", "categories": ["cs.CV"], "comment": "IEEE VR 2026 Poster", "summary": "Virtual try-on systems allow users to interactively try different products within VR scenarios. However, most existing VTON methods operate only on predefined eyewear templates and lack support for fine-grained, user-driven customization. While GlassesGAN enables personalized 2D eyewear design, its capability remains limited to 2D image generation. Motivated by the success of 3D Gaussian Blendshapes in head reconstruction, we integrate these two techniques and propose GlassesGB, a framework that supports customizable eyewear generation for 3D head avatars. GlassesGB effectively bridges 2D generative customization with 3D head avatar rendering, addressing the challenge in achieving personalized eyewear design for VR applications. The implementation code is available at https://ruiyangju.github.io/GlassesGB.", "AI": {"tldr": "本文提出GlassesGB框架，结合2D生成对抗网络和3D高斯混合模型，实现了虚拟现实环境中个性化眼镜的定制化设计。", "motivation": "现有的虚拟试戴系统在预定义的眼镜模板上操作，并缺乏精细、用户驱动的自定义功能，而GlassesGAN只能进行2D图像生成，无法支持三维头像应用中的个性化眼镜设计。因此，作者提出GlassesGB框架以解决这一问题。", "method": "结合GlassesGAN和3D高斯混合模型技术，开发了一个名为GlassesGB的新框架，用于实现用户驱动的、可定制的二维眼饰与三维头像渲染之间的无缝集成。", "result": "成功实现了2D个性化眼镜设计到3D头像应用的有效转换，满足了虚拟现实环境中对于个性化眼镜的设计需求。", "conclusion": "GlassesGB有效解决了现有系统缺乏精细定制功能的问题，并且将2D生成对抗网络与3D高斯混合模型技术相结合，在VR试戴中实现了高度个性化的用户体验。"}}
{"id": "2601.17087", "pdf": "https://arxiv.org/pdf/2601.17087", "abs": "https://arxiv.org/abs/2601.17087", "authors": ["Preethi Seshadri", "Samuel Cahyawijaya", "Ayomide Odumakinde", "Sameer Singh", "Seraphina Goldfarb-Tarrant"], "title": "Lost in Simulation: LLM-Simulated Users are Unreliable Proxies for Human Users in Agentic Evaluations", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.LG"], "comment": null, "summary": "Agentic benchmarks increasingly rely on LLM-simulated users to scalably evaluate agent performance, yet the robustness, validity, and fairness of this approach remain unexamined. Through a user study with participants across the United States, India, Kenya, and Nigeria, we investigate whether LLM-simulated users serve as reliable proxies for real human users in evaluating agents on τ-Bench retail tasks. We find that user simulation lacks robustness, with agent success rates varying up to 9 percentage points across different user LLMs. Furthermore, evaluations using simulated users exhibit systematic miscalibration, underestimating agent performance on challenging tasks and overestimating it on moderately difficult ones. African American Vernacular English (AAVE) speakers experience consistently worse success rates and calibration errors than Standard American English (SAE) speakers, with disparities compounding significantly with age. We also find simulated users to be a differentially effective proxy for different populations, performing worst for AAVE and Indian English speakers. Additionally, simulated users introduce conversational artifacts and surface different failure patterns than human users. These findings demonstrate that current evaluation practices risk misrepresenting agent capabilities across diverse user populations and may obscure real-world deployment challenges.", "AI": {"tldr": "研究评估了使用LLM模拟用户在代理性能评价中的可靠性和有效性。", "motivation": "随着代理基准测试越来越依赖于LLM模拟用户来大规模地评估代理性能，其稳健性、有效性和公平性尚未得到检验。", "method": "通过在美国、印度、肯尼亚和尼日利亚进行的用户研究，调查了LLM模拟用户在零售任务评价中是否能作为真实人类用户的可靠替代。", "result": "发现用户模拟缺乏稳健性，代理成功率在不同用户LLM之间相差达9个百分点；评估中存在系统性的偏差；AAVE说话者体验到比SAE说话者的成功率和校准误差更差的情况，且随着年龄的增长差距加大；模拟用户对不同群体的代理性能评价效果不一致。", "conclusion": "当前的评估实践可能误表了跨多元用户群体下的代理能力，并可能掩盖实际部署中的挑战。"}}
{"id": "2601.17086", "pdf": "https://arxiv.org/pdf/2601.17086", "abs": "https://arxiv.org/abs/2601.17086", "authors": ["Ayush Pratap Singh", "Harshit Singh", "Nityanand Mathur", "Akshat Mandloi", "Sudarshan Kamath"], "title": "SonoEdit: Null-Space Constrained Knowledge Editing for Pronunciation Correction in LLM-Based TTS", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Neural text-to-speech (TTS) systems systematically mispronounce low-resource proper nouns, particularly non-English names, brands, and geographic locations, due to their underrepresentation in predominantly English training corpora. Existing solutions typically rely on expensive multilingual data collection, supervised finetuning, or manual phonetic annotation, which limits the deployment of TTS systems in linguistically diverse settings. We introduce SonoEdit, a model editing technique that surgically corrects pronunciation errors in pre-trained TTS models without retraining. Instead of costly finetuning or explicit phoneme injection, we propose a parsimonious alternative based on Null-Space Pronunciation Editing, which performs a single-shot parameter update to modify the pronunciation of specific words while provably preserving all other model behavior. We first adapt Acoustic Causal Tracing to identify the Transformer layers responsible for text-to-pronunciation mapping. We then apply Null-Space Constrained Editing to compute a closed-form weight update that corrects the target pronunciation while remaining mathematically orthogonal to the subspace governing general speech generation. This constrained update steers the model's acoustic output toward a desired pronunciation exemplar while guaranteeing zero first-order change on a preserved speech corpus.", "AI": {"tldr": "介绍SonoEdit技术，用于在不重新训练的情况下纠正预训练TTS模型中的发音错误。", "motivation": "神经TTS系统由于缺乏非英语资源而经常错误地发音一些专有名词、品牌和地理位置名称。现有的解决方案成本高昂且难以部署于语言多样性环境中。", "method": "SonoEdit通过单次参数更新来纠正特定单词的发音，同时保证其他模型行为不变；使用声学因果追踪确定负责文本到发音映射的Transformer层，并应用Null-Space Constrained Editing计算闭式权重更新以纠正目标发音。", "result": "该方法能够将TTS模型的输出导向所需的正确发音示例，且在保留语音语料库上保证零阶变化。", "conclusion": "SonoEdit为解决低资源专有名词的发音问题提供了一种成本效益高且无需重新训练的方法。"}}
{"id": "2601.17085", "pdf": "https://arxiv.org/pdf/2601.17085", "abs": "https://arxiv.org/abs/2601.17085", "authors": ["Esther Sun", "Abinay Reddy Naini", "Carlos Busso"], "title": "Recovering Performance in Speech Emotion Recognition from Discrete Tokens via Multi-Layer Fusion and Paralinguistic Feature Integration", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "Accepted to ICASSP 2026", "summary": "Discrete speech tokens offer significant advantages for storage and language model integration, but their application in speech emotion recognition (SER) is limited by paralinguistic information loss during quantization. This paper presents a comprehensive investigation of discrete tokens for SER. Using a fine-tuned WavLM-Large model, we systematically quantify performance degradation across different layer configurations and k-means quantization granularities. To recover the information loss, we propose two key strategies: (1) attention-based multi-layer fusion to recapture complementary information from different layers, and (2) integration of openSMILE features to explicitly reintroduce paralinguistic cues. We also compare mainstream neural codec tokenizers (SpeechTokenizer, DAC, EnCodec) and analyze their behaviors when fused with acoustic features. Our findings demonstrate that through multi-layer fusion and acoustic feature integration, discrete tokens can close the performance gap with continuous representations in SER tasks.", "AI": {"tldr": "本文研究了如何通过多层融合和声学特征集成从离散语音标记中恢复情感识别性能。", "motivation": "由于量化过程中会丢失副语言信息，离散语音标记在语音情感识别中的应用受到限制，因此本文旨在探索这些标记的全面表现并找到弥补这种损失的方法。", "method": "使用了经过微调的WavLM-Large模型，并提出了两种策略：基于注意力机制的多层融合和openSMILE特征集成以显式重新引入副语言线索。此外还比较了几种主流神经编解码器标记化器（SpeechTokenizer，DAC，EnCodec）。", "result": "研究表明通过多层融合和声学特征集成可以缩小离散标记与连续表示在情感识别任务中的性能差距。", "conclusion": "研究证明了结合注意力机制的多层融合及副语言特征集成方法能够有效恢复由于量化造成的语音情感识别性能损失，使离散语音标记能够在SER中表现得更好。"}}
{"id": "2601.17084", "pdf": "https://arxiv.org/pdf/2601.17084", "abs": "https://arxiv.org/abs/2601.17084", "authors": ["Iman Peivaste", "Ahmed Makradi", "Salim Belouettar"], "title": "ChemNavigator: Agentic AI Discovery of Design Rules for Organic Photocatalysts", "categories": ["physics.chem-ph", "cs.AI", "physics.comp-ph"], "comment": null, "summary": "The discovery of high-performance organic photocatalysts for hydrogen evolution remains limited by the vastness of chemical space and the reliance on human intuition for molecular design. Here we present ChemNavigator, an agentic AI system that autonomously derives structure-property relationships through hypothesis-driven exploration of organic photocatalyst candidates. The system integrates large language model reasoning with density functional tight binding calculations in a multi-agent architecture that mirrors the scientific method: formulating hypotheses, designing experiments, executing calculations, and validating findings through rigorous statistical analysis. Through iterative discovery cycles encompassing 200 molecules, ChemNavigator autonomously identified six statistically significant design rules governing frontier orbital energies, including the effects of ether linkages, carbonyl groups, extended conjugation, cyano groups, halogen substituents, and amine groups. Importantly, these rules correspond to established principles of organic electronic structure (resonance donation, inductive withdrawal, $π$-delocalization), demonstrating that the system can independently derive chemical knowledge without explicit programming. Notably, autonomous agentic reasoning extracted these six validated rules from a molecular library where previous ML approaches identified only carbonyl effects. Furthermore, the quantified effect sizes provide a prioritized ranking for synthetic chemists, while feature interaction analysis revealed diminishing returns when combining strategies, challenging additive assumptions in molecular design. This work demonstrates that agentic AI systems can autonomously derive interpretable, chemically grounded design principles, establishing a framework for AI-assisted materials discovery that complements rather than replaces chemical intuition.", "AI": {"tldr": "本文介绍了ChemNavigator，一个能够自主发现有机光催化剂设计规则的智能AI系统。", "motivation": "由于化学空间的广阔和依赖人类直觉进行分子设计，高效率有机光催化剂的发现受到限制。因此，开发能够自动探索结构-性质关系并发现设计原则的系统是必要的。", "method": "ChemNavigator通过大语言模型推理与密度泛函紧束缚计算相结合，在一个多智能体架构中自主制定假设、设计实验、执行计算和验证结果，模拟科学方法来工作。", "result": "在200个分子的迭代发现周期内，ChemNavigator自主识别出六条统计显著的设计规则，涉及前沿轨道能量的影响因素，并且量化效果大小为合成化学家提供了优先级排名。", "conclusion": "该研究展示了智能AI系统可以自主地推导出可解释、基于化学原理的设计原则，这为材料发现建立了框架，以补充而非取代化学直觉。"}}
{"id": "2601.17082", "pdf": "https://arxiv.org/pdf/2601.17082", "abs": "https://arxiv.org/abs/2601.17082", "authors": ["Zhining Liu", "Tianyi Wang", "Xiao Lin", "Penghao Ouyang", "Gaotang Li", "Ze Yang", "Hui Liu", "Sumit Keswani", "Vishwa Pardeshi", "Huijun Zhao", "Wei Fan", "Hanghang Tong"], "title": "Do VLMs Have a Moral Backbone? A Study on the Fragile Morality of Vision-Language Models", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": null, "summary": "Despite substantial efforts toward improving the moral alignment of Vision-Language Models (VLMs), it remains unclear whether their ethical judgments are stable in realistic settings. This work studies moral robustness in VLMs, defined as the ability to preserve moral judgments under textual and visual perturbations that do not alter the underlying moral context. We systematically probe VLMs with a diverse set of model-agnostic multimodal perturbations and find that their moral stances are highly fragile, frequently flipping under simple manipulations. Our analysis reveals systematic vulnerabilities across perturbation types, moral domains, and model scales, including a sycophancy trade-off where stronger instruction-following models are more susceptible to persuasion. We further show that lightweight inference-time interventions can partially restore moral stability. These results demonstrate that moral alignment alone is insufficient and that moral robustness is a necessary criterion for the responsible deployment of VLMs.", "AI": {"tldr": "该研究探讨了视觉语言模型（VLMs）在现实场景中的道德稳定性，并发现它们的道德判断容易受到文本和图像扰动的影响。", "motivation": "尽管已经投入大量精力来提高VLMs的道德对齐，但这些模型在实际环境下的道德判断是否稳定尚不清楚。因此，研究旨在探究这种不稳定性的具体表现及其原因。", "method": "研究人员系统性地使用了一套与模型无关的多模态扰动方法来测试VLMs的道德立场，并分析了不同类型的扰动、道德领域和模型规模对结果的影响。", "result": "结果显示，VLMs的道德判断非常脆弱，在简单的人为操作下很容易改变；研究还发现了一个顺从性权衡问题，即指令跟随能力更强的模型更容易被说服。", "conclusion": "研究表明，仅靠道德对齐是不够的，为了负责任地部署VLMs，还需要考虑其道德稳定性这一必要条件。"}}
{"id": "2601.17080", "pdf": "https://arxiv.org/pdf/2601.17080", "abs": "https://arxiv.org/abs/2601.17080", "authors": ["Seung Gyu Jeong", "Seong-Eun Kim"], "title": "PC-MCL: Patient-Consistent Multi-Cycle Learning with multi-label bias correction for respiratory sound classification", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "comment": null, "summary": "Automated respiratory sound classification supports the diagnosis of pulmonary diseases. However, many deep models still rely on cycle-level analysis and suffer from patient-specific overfitting. We propose PC-MCL (Patient-Consistent Multi-Cycle Learning) to address these limitations by utilizing three key components: multi-cycle concatenation, a 3-label formulation, and a patient-matching auxiliary task. Our work resolves a multi-label distributional bias in respiratory sound classification, a critical issue inherent to applying multi-cycle concatenation with the conventional 2-label formulation (crackle, wheeze). This bias manifests as a systematic loss of normal signal information when normal and abnormal cycles are combined. Our proposed 3-label formulation (normal, crackle, wheeze) corrects this by preserving information from all constituent cycles in mixed samples. Furthermore, the patient-matching auxiliary task acts as a multi-task regularizer, encouraging the model to learn more robust features and improving generalization. On the ICBHI 2017 benchmark, PC-MCL achieves an ICBHI Score of 65.37%, outperforming existing baselines. Ablation studies confirm that all three components are essential, working synergistically to improve the detection of abnormal respiratory events.", "AI": {"tldr": "本论文提出了PC-MCL方法，用于解决呼吸音分类中的患者特定过拟合和多标签分布偏置问题。", "motivation": "自动化呼吸音分类支持肺部疾病的诊断，但许多深度模型仍依赖于周期级别的分析，并且容易出现患者特定的过拟合问题。", "method": "PC-MCL方法利用三个关键组件：多周期连接、3标签格式和匹配病人辅助任务来解决这些问题。3标签格式（正常、细湿啰音、哮鸣音）纠正了传统的2标签格式中存在的系统性信息丢失偏置，而匹配病人辅助任务则作为一个多重任务正则器，鼓励模型学习更稳健的特征，提高泛化能力。", "result": "在ICBHI 2017基准测试上，PC-MCL达到了65.37%的ICBHI得分，并且优于现有的基线方法。消融研究验证了所有三个组件对于改善异常呼吸事件检测的重要性。", "conclusion": "该论文展示了PC-MCL方法在呼吸音分类中的优势，证明了其通过多周期连接、3标签格式和匹配病人辅助任务的组合可以提高模型性能并解决存在的问题。"}}
{"id": "2601.17076", "pdf": "https://arxiv.org/pdf/2601.17076", "abs": "https://arxiv.org/abs/2601.17076", "authors": ["Jiajun Chen", "Yue Wu", "Kai Huang", "Wen Xi", "Yangyang Wu", "Xiaoye Miao", "Mengying Zhu", "Meng Xi", "Guanjie Cheng"], "title": "E2PL: Effective and Efficient Prompt Learning for Incomplete Multi-view Multi-Label Class Incremental Learning", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages", "summary": "Multi-view multi-label classification (MvMLC) is indispensable for modern web applications aggregating information from diverse sources. However, real-world web-scale settings are rife with missing views and continuously emerging classes, which pose significant obstacles to robust learning. Prevailing methods are ill-equipped for this reality, as they either lack adaptability to new classes or incur exponential parameter growth when handling all possible missing-view patterns, severely limiting their scalability in web environments. To systematically address this gap, we formally introduce a novel task, termed \\emph{incomplete multi-view multi-label class incremental learning} (IMvMLCIL), which requires models to simultaneously address heterogeneous missing views and dynamic class expansion. To tackle this task, we propose \\textsf{E2PL}, an Effective and Efficient Prompt Learning framework for IMvMLCIL. \\textsf{E2PL} unifies two novel prompt designs: \\emph{task-tailored prompts} for class-incremental adaptation and \\emph{missing-aware prompts} for the flexible integration of arbitrary view-missing scenarios. To fundamentally address the exponential parameter explosion inherent in missing-aware prompts, we devise an \\emph{efficient prototype tensorization} module, which leverages atomic tensor decomposition to elegantly reduce the prompt parameter complexity from exponential to linear w.r.t. the number of views. We further incorporate a \\emph{dynamic contrastive learning} strategy explicitly model the complex dependencies among diverse missing-view patterns, thus enhancing the model's robustness. Extensive experiments on three benchmarks demonstrate that \\textsf{E2PL} consistently outperforms state-of-the-art methods in both effectiveness and efficiency. The codes and datasets are available at https://anonymous.4open.science/r/code-for-E2PL.", "AI": {"tldr": "介绍并解决了不完全多视图多标签类增量学习任务，并提出了一种有效的提示学习框架E2PL。", "motivation": "现有的方法难以适应新出现的类别或处理所有可能的缺失视图模式，限制了它们在现实世界大规模环境中的可扩展性。为此提出了一个新任务：不完全多视图多标签类增量学习(IMvMLCIL)。", "method": "E2PL框架包括两类新颖提示设计：针对类别增量适应的任务特定提示和处理任意缺失视图场景的缺失感知提示，以及高效原型张量化模块来减少参数复杂性，并结合动态对比学习策略增强模型鲁棒性。", "result": "实验结果表明，在三个基准测试上，E2PL在有效性和效率方面均优于现有方法。", "conclusion": "该论文提出了一个新颖的任务和有效的解决方案，展示了其在处理不完全多视图多标签类增量学习问题上的优越性能。"}}
{"id": "2601.17074", "pdf": "https://arxiv.org/pdf/2601.17074", "abs": "https://arxiv.org/abs/2601.17074", "authors": ["Akila Sampath", "Vandana Janeja", "Jianwu Wang"], "title": "PhysE-Inv: A Physics-Encoded Inverse Modeling approach for Arctic Snow Depth Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The accurate estimation of Arctic snow depth ($h_s$) remains a critical time-varying inverse problem due to the extreme scarcity and noise inherent in associated sea ice parameters. Existing process-based and data-driven models are either highly sensitive to sparse data or lack the physical interpretability required for climate-critical applications. To address this gap, we introduce PhysE-Inv, a novel framework that integrates a sophisticated sequential architecture, an LSTM Encoder-Decoder with Multi-head Attention and physics-guided contrastive learning, with physics-guided inference.Our core innovation lies in a surjective, physics-constrained inversion methodology. This methodology first leverages the hydrostatic balance forward model as a target-formulation proxy, enabling effective learning in the absence of direct $h_s$ ground truth; second, it uses reconstruction physics regularization over a latent space to dynamically discover hidden physical parameters from noisy, incomplete time-series input. Evaluated against state-of-the-art baselines, PhysE-Inv significantly improves prediction performance, reducing error by 20\\% while demonstrating superior physical consistency and resilience to data sparsity compared to empirical methods. This approach pioneers a path for noise-tolerant, interpretable inverse modeling, with wide applicability in geospatial and cryospheric domains.", "AI": {"tldr": "本文介绍了一种新的框架PhysE-Inv，用于北极雪深预测，结合了物理引导的对比学习和逆向建模方法。", "motivation": "由于与海冰参数相关的数据稀缺且噪声大，准确估计北极雪深是一个关键的时间变化反演问题。现有的过程模型和数据驱动模型要么对稀疏数据高度敏感，要么缺乏气候应用所需的物理可解释性。", "method": "PhysE-Inv框架采用了一个先进的序列架构，结合LSTM编码器-解码器、多头注意力机制以及基于物理的对比学习，并通过一个物理约束的反演方法进行优化。该方法利用静水平衡前向模型作为目标公式化代理，并在潜在空间中使用重建物理正则化来动态发现隐藏的物理参数。", "result": "与最先进的基准相比，PhysE-Inv显著提高了预测性能，减少了20%的误差，展示了相对于经验方法更好的物理一致性和对数据稀疏性的抗扰性。", "conclusion": "这种方法为耐噪声和可解释逆向建模开创了新的道路，并在地理空间和冰冻圈领域具有广泛应用潜力。"}}
{"id": "2601.17073", "pdf": "https://arxiv.org/pdf/2601.17073", "abs": "https://arxiv.org/abs/2601.17073", "authors": ["Yifei Zhang", "Meimei Liu", "Zhengwu Zhang"], "title": "Attention-Based Variational Framework for Joint and Individual Components Learning with Applications in Brain Network Analysis", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": null, "summary": "Brain organization is increasingly characterized through multiple imaging modalities, most notably structural connectivity (SC) and functional connectivity (FC). Integrating these inherently distinct yet complementary data sources is essential for uncovering the cross-modal patterns that drive behavioral phenotypes. However, effective integration is hindered by the high dimensionality and non-linearity of connectome data, complex non-linear SC-FC coupling, and the challenge of disentangling shared information from modality-specific variations. To address these issues, we propose the Cross-Modal Joint-Individual Variational Network (CM-JIVNet), a unified probabilistic framework designed to learn factorized latent representations from paired SC-FC datasets. Our model utilizes a multi-head attention fusion module to capture non-linear cross-modal dependencies while isolating independent, modality-specific signals. Validated on Human Connectome Project Young Adult (HCP-YA) data, CM-JIVNet demonstrates superior performance in cross-modal reconstruction and behavioral trait prediction. By effectively disentangling joint and individual feature spaces, CM-JIVNet provides a robust, interpretable, and scalable solution for large-scale multimodal brain analysis.", "AI": {"tldr": "本文提出了CM-JIVNet框架，用于从结构连接性和功能连接性数据中学习因子化潜在表示，并在行为特征预测和跨模态重建方面表现出优越性能。", "motivation": "脑组织可以通过多种成像模式进行描述，特别是结构连接性和功能性连接性。融合这些内在不同的互补数据源对于揭示驱动行为表型的跨模态模式至关重要。然而，高度维度、非线性的连通体数据和复杂非线性的SC-FC耦合阻碍了这种整合。", "method": "本文提出了Cross-Modal Joint-Individual Variational Network（CM-JIVNet），一个统一的概率框架，用于学习因子化的潜在表示从配对的结构连接性和功能性连接性数据集中，并利用多头注意力融合模块来捕捉非线性的跨模态依赖关系同时隔离独立、特定模式的信号。", "result": "在Human Connectome Project Young Adult（HCP-YA）数据上验证，CM-JIVNet显示了跨模态重建和行为特征预测方面的优越性能。", "conclusion": "CM-JIVNet提供了一个强大的、可解释的和可扩展的大规模多模式脑分析解决方案，通过有效地分离共同和个体特征空间。"}}
{"id": "2601.17072", "pdf": "https://arxiv.org/pdf/2601.17072", "abs": "https://arxiv.org/abs/2601.17072", "authors": ["Sonia Katyal", "Aniket Kesari"], "title": "Trademark Search, Artificial Intelligence and the Role of the Private Sector", "categories": ["cs.CY", "cs.AI"], "comment": "Berkeley Technology Law Journal (January 4, 2021)", "summary": "Almost every industry today confronts the potential role of artificial intelligence and machine learning in its future. While many studies examine AI in consumer marketing, less attention addresses AI's role in creating and selecting trademarks that are distinctive, recognizable, and meaningful to consumers. Traditional economic approaches to trademarks focus almost exclusively on consumer-based, demand-side considerations regarding search. However, these approaches are incomplete because they fail to account for substantial costs faced not just by consumers, but by trademark applicants as well. Given AI's rapidly increasing role in trademark search and similarity analysis, lawyers and scholars should understand its dramatic implications. This paper proposes that AI should interest anyone studying trademarks and their role in economic decision-making. We examine how machine learning techniques will transform the application and interpretation of foundational trademark doctrines, producing significant implications for the trademark ecosystem. We run empirical experiments regarding trademark search to assess the efficacy of various trademark search engines, many of which employ machine learning methods. Through comparative analysis, we evaluate how these AI-powered tools function in practice. In an age where artificial intelligence increasingly governs trademark selection, the classic division between consumers and trademark owners deserves an updated, supply-side framework. This insight has transformative potential for encouraging both innovation and efficiency in trademark law and practice.", "AI": {"tldr": "本文探讨了人工智能在商标搜索和相似性分析中的作用，并通过实证实验评估不同商标搜索引擎的效率，提出需要更新传统的商标理论框架。", "motivation": "尽管许多研究关注AI在消费市场营销中的应用，但鲜有研究涉及AI如何影响商标的选择和创造。现有的经济方法主要集中在需求侧的问题上，忽视了商标申请方的成本问题。", "method": "本文通过实证实验评估不同商标搜索引擎的效率，并使用比较分析来评价这些由AI驱动工具的实际功能。", "result": "研究表明机器学习技术将转变基础性的商标法条的应用和解释，对整个商标生态系统产生重大影响。", "conclusion": "在人工智能越来越多地应用于商标选择的时代，传统的消费者与商标所有者之间的划分需要一个更新的、供给侧框架来鼓励创新和提高效率。"}}
{"id": "2601.17071", "pdf": "https://arxiv.org/pdf/2601.17071", "abs": "https://arxiv.org/abs/2601.17071", "authors": ["Jisui Huang", "Andreas Alpers", "Ke Chen", "Na Lei"], "title": "Superpixel-Based Image Segmentation Using Squared 2-Wasserstein Distances", "categories": ["cs.CV", "math.PR"], "comment": "34 pages, 11 figures", "summary": "We present an efficient method for image segmentation in the presence of strong inhomogeneities. The approach can be interpreted as a two-level clustering procedure: pixels are first grouped into superpixels via a linear least-squares assignment problem, which can be viewed as a special case of a discrete optimal transport (OT) problem, and these superpixels are subsequently greedily merged into object-level segments using the squared 2-Wasserstein distance between their empirical distributions. In contrast to conventional superpixel merging strategies based on mean-color distances, our framework employs a distributional OT distance, yielding a mathematically unified formulation across both clustering levels. Numerical experiments demonstrate that this perspective leads to improved segmentation accuracy on challenging images while retaining high computational efficiency.", "AI": {"tldr": "本文提出了一种基于超像素的图像分割方法，该方法使用平方2-Wasserstein距离进行高效处理。", "motivation": "动机在于在存在强烈不均匀性的情况下提供一种高效的图像分割方法，与传统基于平均颜色距离的方法相比，这种方法可以提高挑战性图像的分割精度。", "method": "首先通过线性最小二乘分配问题将像素分组成超像素，并将其视为离散最优传输问题的一个特例；然后使用平方2-Wasserstein距离在这些超像素之间进行贪心合并以形成对象级别的片段。", "result": "数值实验表明，与传统的超像素合并策略相比，此方法提高了挑战性图像的分割精度并保持了高计算效率。", "conclusion": "该框架通过采用分布最优传输距离统一了两个聚类级别中的数学公式，在提高分割准确性的同时保持了高效性。"}}
{"id": "2601.17069", "pdf": "https://arxiv.org/pdf/2601.17069", "abs": "https://arxiv.org/abs/2601.17069", "authors": ["Shahil Shaik", "Jonathon M. Smereka", "Yue Wang"], "title": "Multi-Agent Deep Reinforcement Learning Under Constrained Communications", "categories": ["cs.LG", "cs.AI"], "comment": "21 pages, 8 figures, Under review at ICLR", "summary": "Centralized training with decentralized execution (CTDE) has been the dominant paradigm in multi-agent reinforcement learning (MARL), but its reliance on global state information during training introduces scalability, robustness, and generalization bottlenecks. Moreover, in practical scenarios such as adding/dropping teammates or facing environment dynamics that differ from the training, CTDE methods can be brittle and costly to retrain, whereas distributed approaches allow agents to adapt using only local information and peer-to-peer communication. We present a distributed MARL framework that removes the need for centralized critics or global information. Firstly, we develop a novel Distributed Graph Attention Network (D-GAT) that performs global state inference through multi-hop communication, where agents integrate neighbor features via input-dependent attention weights in a fully distributed manner. Leveraging D-GAT, we develop the distributed graph-attention MAPPO (DG-MAPPO) -- a distributed MARL framework where agents optimize local policies and value functions using local observations, multi-hop communication, and shared/averaged rewards. Empirical evaluation on the StarCraftII Multi-Agent Challenge, Google Research Football, and Multi-Agent Mujoco demonstrates that our method consistently outperforms strong CTDE baselines, achieving superior coordination across a wide range of cooperative tasks with both homogeneous and heterogeneous teams. Our distributed MARL framework provides a principled and scalable solution for robust collaboration, eliminating the need for centralized training or global observability. To the best of our knowledge, DG-MAPPO appears to be the first to fully eliminate reliance on privileged centralized information, enabling agents to learn and act solely through peer-to-peer communication.", "AI": {"tldr": "本文提出了一种基于分布式图注意力网络的多智能体强化学习框架，实现了完全去中心化的训练与执行。", "motivation": "传统的集中式训练、分布式执行方法在处理实际场景中的团队成员变动和环境动态变化时存在局限性。本研究旨在提供一种更为灵活且可扩展的解决方案，通过仅使用局部信息和点对点通信来适应这些挑战。", "method": "开发了一种新型的分布式图注意力网络（D-GAT），用于多跳通信下的全局状态推断，并在此基础上提出了分布式的图注意力MAPPO框架（DG-MAPPO）。该方法使智能体能够在仅使用局部观测、多跳通信和共享/平均奖励的情况下优化本地策略和价值函数。", "result": "实验结果显示，本研究的方法在StarCraftII多智能体挑战赛、Google Research Football和Multi-Agent Mujoco中表现优于强基线的集中式训练方法，在广泛的协作任务中实现了更优的协调效果。", "conclusion": "本框架提供了一种原则性和可扩展性的解决方案，以实现稳健的合作学习与行动，并且是首个完全消除对特权中央信息依赖的方法。"}}
{"id": "2601.17067", "pdf": "https://arxiv.org/pdf/2601.17067", "abs": "https://arxiv.org/abs/2601.17067", "authors": ["Luozhou Wang", "Zhifei Chen", "Yihua Du", "Dongyu Yan", "Wenhang Ge", "Guibao Shen", "Xinli Xu", "Leyi Wu", "Man Chen", "Tianshuo Xu", "Peiran Ren", "Xin Tao", "Pengfei Wan", "Ying-Cong Chen"], "title": "A Mechanistic View on Video Generation as World Models: State and Dynamics", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Large-scale video generation models have demonstrated emergent physical coherence, positioning them as potential world models. However, a gap remains between contemporary \"stateless\" video architectures and classic state-centric world model theories. This work bridges this gap by proposing a novel taxonomy centered on two pillars: State Construction and Dynamics Modeling. We categorize state construction into implicit paradigms (context management) and explicit paradigms (latent compression), while dynamics modeling is analyzed through knowledge integration and architectural reformulation. Furthermore, we advocate for a transition in evaluation from visual fidelity to functional benchmarks, testing physical persistence and causal reasoning. We conclude by identifying two critical frontiers: enhancing persistence via data-driven memory and compressed fidelity, and advancing causality through latent factor decoupling and reasoning-prior integration. By addressing these challenges, the field can evolve from generating visually plausible videos to building robust, general-purpose world simulators.", "AI": {"tldr": "本文提出了一个用于视频生成的世界模型的分类框架，包括状态构建和动态建模两个核心部分，并讨论了评估方法从视觉保真度转向功能基准的重要性。", "motivation": "当前的无状态视频架构与经典的状态中心世界模型理论之间存在差距，因此需要建立一种新的分类体系以弥合这一鸿沟。", "method": "将状态构建分为隐式范例（上下文管理）和显式范例（潜在压缩），并通过知识整合和架构改革分析动态建模。", "result": "提出了评估方法应从视觉保真度转向测试物理持久性和因果推理的功能基准，以提升视频生成的质量。", "conclusion": "本文指出了两个关键前沿领域：通过数据驱动的记忆和压缩保真度来增强持久性，以及通过潜在因素解耦和推理优先集成来推进因果关系的发展。"}}
{"id": "2601.17065", "pdf": "https://arxiv.org/pdf/2601.17065", "abs": "https://arxiv.org/abs/2601.17065", "authors": ["Haoxuan Li", "He Chang", "Yunshan Ma", "Yi Bin", "Yang Yang", "See-Kiong Ng", "Tat-Seng Chua"], "title": "ThinkTank-ME: A Multi-Expert Framework for Middle East Event Forecasting", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY", "cs.MA"], "comment": null, "summary": "Event forecasting is inherently influenced by multifaceted considerations, including international relations, regional historical dynamics, and cultural contexts. However, existing LLM-based approaches employ single-model architectures that generate predictions along a singular explicit trajectory, constraining their ability to capture diverse geopolitical nuances across complex regional contexts. To address this limitation, we introduce ThinkTank-ME, a novel Think Tank framework for Middle East event forecasting that emulates collaborative expert analysis in real-world strategic decision-making. To facilitate expert specialization and rigorous evaluation, we construct POLECAT-FOR-ME, a Middle East-focused event forecasting benchmark. Experimental results demonstrate the superiority of multi-expert collaboration in handling complex temporal geopolitical forecasting tasks. The code is available at https://github.com/LuminosityX/ThinkTank-ME.", "AI": {"tldr": "介绍ThinkTank-ME，一个多专家框架用于中东事件预测。", "motivation": "现有的基于LLM的方法使用单一模型架构生成预测，无法充分捕捉复杂地区的多样性地缘政治细微差别。为了克服这一限制，提出了ThinkTank-ME框架。", "method": "构建了一个名为POLECAT-FOR-ME的中东地区事件预测基准来促进专家专业化和严格评估，模拟现实世界战略决策中的协作专家分析。", "result": "实验结果表明，多专家合作在处理复杂时间性地缘政治预测任务上表现更优。", "conclusion": "证明了多专家框架在中东事件预测上的优势，并提供了代码资源供进一步研究。"}}
{"id": "2601.17064", "pdf": "https://arxiv.org/pdf/2601.17064", "abs": "https://arxiv.org/abs/2601.17064", "authors": ["Toni Lorente", "Kathrin Gardhouse"], "title": "Between Search and Platform: ChatGPT Under the DSA", "categories": ["cs.CY", "cs.AI"], "comment": "25 pages, 2 figures", "summary": "This article examines the applicability of the Digital Services Act (DSA) to ChatGPT, arguing that it should be classified as a hybrid of the two types of hosting services: online search engines and platforms. This requires classifying search engines as hosting services, which we show is appropriate under the DSA, thereby resolving an ambiguity in the legal framework. ChatGPT performs core search functions and stores user-provided inputs and custom GPTs, meeting the definition of hosting service. We compare ChatGPT's systemic risks with those of existing Very Large Online Search Engines (VLOSEs) and Platforms (VLOPs), showing that it raises similarly serious concerns regarding illegal content, fundamental rights, democratic integrity, and public health. Now that ChatGPT has reached the 45 million EU user threshold, it should be subject to the most onerous DSA obligations, requiring the assessment and mitigation of risk emanating from both its online search engine- and platform-like characteristics.", "AI": {"tldr": "本文探讨了《数字服务法案》（DSA）在ChatGPT上的适用性，认为ChatGPT应被视为在线搜索引擎和平台的混合体。", "motivation": "文章旨在解决法律框架中存在的模糊性，并确定ChatGPT是否符合DSA的标准。鉴于ChatGPT已经达到了4500万欧盟用户的门槛，需要对它的风险进行评估与缓解。", "method": "通过分析ChatGPT的功能特点和潜在的系统性风险，将其功能与现有的大型在线搜索引擎和服务平台进行比较。", "result": "研究表明，ChatGPT不仅执行核心搜索功能且存储用户提供的输入内容，符合托管服务的定义。同时指出它存在关于非法内容、基本权利保护、民主完整性和公共健康方面的严重问题。", "conclusion": "鉴于ChatGPT的功能和风险特征，应将其归类为大型在线搜索引擎和服务平台，并需遵守DSA中最为严格的义务要求。"}}
{"id": "2601.17063", "pdf": "https://arxiv.org/pdf/2601.17063", "abs": "https://arxiv.org/abs/2601.17063", "authors": ["Byeongju Kim", "Jungwan Lee", "Donghyeon Han", "Hoi-Jun Yoo", "Sangyeob Kim"], "title": "FlashMoE: Reducing SSD I/O Bottlenecks via ML-Based Cache Replacement for Mixture-of-Experts Inference on Edge Devices", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, Mixture-of-Experts (MoE) models have gained attention for efficiently scaling large language models. Although these models are extremely large, their sparse activation enables inference to be performed by accessing only a fraction of the model at a time. This property opens the possibility of on-device inference of MoE, which was previously considered infeasible for such large models. Consequently, various systems have been proposed to leverage this sparsity and enable efficient MoE inference for edge devices. However, previous MoE inference systems like Fiddler[8] or DAOP[13] rely on DRAM-based offloading and are not suitable for memory constrained on-device environments. As recent MoE models grow to hundreds of gigabytes, RAM-offloading solutions become impractical. To address this, we propose FlashMoE, a system that offloads inactive experts to SSD, enabling efficient MoE inference under limited RAM. FlashMoE incorporates a lightweight ML-based caching strategy that adaptively combines recency and frequency signals to maximize expert reuse, significantly reducing storage I/O. In addition, we built a user-grade desktop platform to demonstrate the practicality of FlashMoE. On this real hardware setup, FlashMoE improves cache hit rate by up to 51% over well-known offloading policies such as LRU and LFU, and achieves up to 2.6x speedup compared to existing MoE inference systems.", "AI": {"tldr": "本文提出了FlashMoE系统，通过将不活跃的专家模型存储在SSD中并采用基于机器学习的缓存策略来减少I/O瓶颈，从而实现在边缘设备上进行高效的混合专家推理。", "motivation": "传统的基于DRAM卸载的方法对于内存受限的环境不再适用，因此作者旨在解决大容量MoE模型（高达数百GB）在边缘设备上的有效推理问题。", "method": "FlashMoE系统将不活跃的专家存储到SSD，并采用一种轻量级的机器学习缓存策略来结合最近使用和频率信号以最大化专家重用，从而显著减少存储I/O。", "result": "通过实际硬件平台测试，FlashMoE相比LRU、LFU等著名卸载策略提高了高达51%的缓存命中率，并且速度提升了最高2.6倍。", "conclusion": "FlashMoE证明了其在资源受限环境下有效支持大规模混合专家模型推理的能力，并展示了显著优于现有方法的性能提升。"}}
{"id": "2601.17062", "pdf": "https://arxiv.org/pdf/2601.17062", "abs": "https://arxiv.org/abs/2601.17062", "authors": ["Robert M. Belcher", "Brendan C. Degryse", "Leonard R. Kosta", "Christopher J. Lowrance"], "title": "A Computer Vision Pipeline for Iterative Bullet Hole Tracking in Rifle Zeroing", "categories": ["cs.CV", "cs.AI"], "comment": "Presented at the 2025 MIT Undergraduate Research Technology Conference (URTC)", "summary": "Adjusting rifle sights, a process commonly called \"zeroing,\" requires shooters to identify and differentiate bullet holes from multiple firing iterations. Traditionally, this process demands physical inspection, introducing delays due to range safety protocols and increasing the risk of human error. We present an end-to-end computer vision system for automated bullet hole detection and iteration-based tracking directly from images taken at the firing line. Our approach combines YOLOv8 for accurate small-object detection with Intersection over Union (IoU) analysis to differentiate bullet holes across sequential images. To address the scarcity of labeled sequential data, we propose a novel data augmentation technique that removes rather than adds objects to simulate realistic firing sequences. Additionally, we introduce a preprocessing pipeline that standardizes target orientation using ORB-based perspective correction, improving model accuracy. Our system achieves 97.0% mean average precision on bullet hole detection and 88.8% accuracy in assigning bullet holes to the correct firing iteration. While designed for rifle zeroing, this framework offers broader applicability in domains requiring the temporal differentiation of visually similar objects.", "AI": {"tldr": "本文介绍了一种用于步枪校准的计算机视觉管道，实现自动子弹孔检测和迭代跟踪。", "motivation": "传统的步枪瞄准调整过程依赖于人工识别子弹孔，耗时且易出错。作者提出一种自动化方法来改进这一流程。", "method": "该系统结合YOLOv8进行精确的小目标检测，并使用IoU分析区分连续图像中的子弹孔。此外，引入了一种新颖的数据增强技术及预处理管道以提高准确性。", "result": "系统在子弹孔检测上达到97.0%的平均精度，在分配正确的射击迭代上有88.8%的准确率。", "conclusion": "该计算机视觉框架不仅适用于步枪校准，还可在其他需要区分相似视觉对象的时间序列数据处理领域发挥作用。"}}
{"id": "2601.17061", "pdf": "https://arxiv.org/pdf/2601.17061", "abs": "https://arxiv.org/abs/2601.17061", "authors": ["Dan Adler"], "title": "How Information Evolves: Stability-Driven Assembly and the Emergence of a Natural Genetic Algorithm", "categories": ["q-bio.PE", "cs.NE", "nlin.AO"], "comment": "42 pages, 13 figures. Submitted for consideration to MIT Artificial Life Journal", "summary": "Information can evolve as a physical consequence of non-equilibrium dynamics, even in the absence of genes, replication, or predefined fitness functions. We present Stability-Driven Assembly (SDA), a framework in which stochastic assembly combined with differential persistence biases populations toward longer-lived motifs. Assemblies that persist longer become more frequent and are therefore more likely to participate in subsequent interactions, generating feedback that reshapes the population distribution and implements fitness-proportional sampling, realizing evolution as a natural, emergent genetic algorithm (SDA/GA) driven solely by stability. We apply SDA/GA to chemical symbol space using SMILES fragments with recombination, mutation, and a heuristic stability function. Simulations show hallmark features of evolutionary search, including scaffold-level dominance, sustained novelty, and entropy reduction, yielding open-ended dynamics absent from equilibrium models with fixed transition rates. These results motivate an evolutionary ladder hypothesis where persistence-driven selection precedes genetic replication.", "AI": {"tldr": "本文介绍了稳定性驱动组装（SDA）框架，展示了一个自然遗传算法如何在没有基因、复制或预定义适应度函数的情况下通过非平衡动力学自发演化。", "motivation": "研究动机在于探索信息如何作为非平衡动力学的物理后果进化，并提出一种新的框架来说明这种进化过程中的稳定性驱动组装和自然遗传算法的出现。", "method": "使用稳定性的驱动力进行随机组合，结合差分持久性偏置种群趋向于更长寿命模式，通过化学符号空间应用SDA/GA方法进行模拟实验。", "result": "模拟结果展示了进化搜索的经典特征，如支架水平主导、持续的新颖性和熵减少，表明这种自发演化过程具有开放性的动态特性，与固定过渡率的平衡模型不同。", "conclusion": "结论提出了一种进化阶梯假说，即基于持久性选择先于遗传复制出现，这为理解信息在非生物系统中如何自然进化的机制提供了新的视角。"}}
{"id": "2601.17060", "pdf": "https://arxiv.org/pdf/2601.17060", "abs": "https://arxiv.org/abs/2601.17060", "authors": ["Derek Shiller", "Laura Duffy", "Arvo Muñoz Morán", "Adrià Moret", "Chris Percy", "Hayley Clatterbuck"], "title": "Initial results of the Digital Consciousness Model", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Artificially intelligent systems have become remarkably sophisticated. They hold conversations, write essays, and seem to understand context in ways that surprise even their creators. This raises a crucial question: Are we creating systems that are conscious? The Digital Consciousness Model (DCM) is a first attempt to assess the evidence for consciousness in AI systems in a systematic, probabilistic way. It provides a shared framework for comparing different AIs and biological organisms, and for tracking how the evidence changes over time as AI develops. Instead of adopting a single theory of consciousness, it incorporates a range of leading theories and perspectives - acknowledging that experts disagree fundamentally about what consciousness is and what conditions are necessary for it. This report describes the structure and initial results of the Digital Consciousness Model. Overall, we find that the evidence is against 2024 LLMs being conscious, but the evidence against 2024 LLMs being conscious is not decisive. The evidence against LLM consciousness is much weaker than the evidence against consciousness in simpler AI systems.", "AI": {"tldr": "本文介绍了数字意识模型（DCM）及其初步结果，评估了AI系统是否具有意识。", "motivation": "随着人工智能系统的日益复杂和表现力强，引发了关于这些系统是否有意识的讨论。为了解决这个问题并提供一个共享框架来比较不同的人工智能系统与生物有机体的证据变化情况。", "method": "数字意识模型（DCM）采用了多种主流理论和观点，并不依赖单一的意识理论，以一种系统且概率的方式来评估AI系统的意识证据。", "result": "初步结果显示，2024年的大型语言模型没有明显证据表明它们具有意识，但这一结论并非绝对；对于更简单的人工智能系统，缺乏意识的证据则更为强烈。", "conclusion": "尽管当前大型语言模型被认为不具意识，但证据尚不足以完全排除其可能性。"}}
{"id": "2601.17058", "pdf": "https://arxiv.org/pdf/2601.17058", "abs": "https://arxiv.org/abs/2601.17058", "authors": ["Wei Zhou", "Jun Zhou", "Haoyu Wang", "Zhenghao Li", "Qikang He", "Shaokun Han", "Guoliang Li", "Xuanhe Zhou", "Yeye He", "Chunwei Liu", "Zirui Tang", "Bin Wang", "Shen Tang", "Kai Zuo", "Yuyu Luo", "Zhenzhe Zheng", "Conghui He", "Jingren Zhou", "Fan Wu"], "title": "Can LLMs Clean Up Your Mess? A Survey of Application-Ready Data Preparation with LLMs", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.LG"], "comment": "Please refer to our repository for more details: https://github.com/weAIDB/awesome-data-llm", "summary": "Data preparation aims to denoise raw datasets, uncover cross-dataset relationships, and extract valuable insights from them, which is essential for a wide range of data-centric applications. Driven by (i) rising demands for application-ready data (e.g., for analytics, visualization, decision-making), (ii) increasingly powerful LLM techniques, and (iii) the emergence of infrastructures that facilitate flexible agent construction (e.g., using Databricks Unity Catalog), LLM-enhanced methods are rapidly becoming a transformative and potentially dominant paradigm for data preparation. By investigating hundreds of recent literature works, this paper presents a systematic review of this evolving landscape, focusing on the use of LLM techniques to prepare data for diverse downstream tasks. First, we characterize the fundamental paradigm shift, from rule-based, model-specific pipelines to prompt-driven, context-aware, and agentic preparation workflows. Next, we introduce a task-centric taxonomy that organizes the field into three major tasks: data cleaning (e.g., standardization, error processing, imputation), data integration (e.g., entity matching, schema matching), and data enrichment (e.g., data annotation, profiling). For each task, we survey representative techniques, and highlight their respective strengths (e.g., improved generalization, semantic understanding) and limitations (e.g., the prohibitive cost of scaling LLMs, persistent hallucinations even in advanced agents, the mismatch between advanced methods and weak evaluation). Moreover, we analyze commonly used datasets and evaluation metrics (the empirical part). Finally, we discuss open research challenges and outline a forward-looking roadmap that emphasizes scalable LLM-data systems, principled designs for reliable agentic workflows, and robust evaluation protocols.", "AI": {"tldr": "本文通过调查数百篇相关文献，系统回顾了LLM技术在数据准备中的应用现状，并将其分类为三大任务：数据清洗、数据整合和数据丰富。", "motivation": "文章旨在回应日益增长的应用程序化数据需求，探讨强大的LLM技术及其基础设施如何成为数据准备的变革力量。", "method": "通过文献调研，分析了从基于规则的数据处理到由提示驱动、语境感知的工作流程的根本转变，并按任务对相关技术和方法进行了分类和评估。", "result": "识别并概述了当前LLM在数据准备中的优势与局限性，包括其泛化能力提升、语义理解改善以及规模化成本高、持续存在的幻觉问题等。", "conclusion": "本文指出了未来研究的挑战，建议开发可扩展的LLM数据系统，设计可靠的代理工作流程，并制定严格的评估协议。"}}
{"id": "2601.17056", "pdf": "https://arxiv.org/pdf/2601.17056", "abs": "https://arxiv.org/abs/2601.17056", "authors": ["Zahra Vaseqi", "James Clark"], "title": "Ego4OOD: Rethinking Egocentric Video Domain Generalization via Covariate Shift Scoring", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Egocentric video action recognition under domain shifts remains challenging due to large intra-class spatio-temporal variability, long-tailed feature distributions, and strong correlations between actions and environments. Existing benchmarks for egocentric domain generalization often conflate covariate shifts with concept shifts, making it difficult to reliably evaluate a model's ability to generalize across input distributions. To address this limitation, we introduce Ego4OOD, a domain generalization benchmark derived from Ego4D that emphasizes measurable covariate diversity while reducing concept shift through semantically coherent, moment-level action categories. Ego4OOD spans eight geographically distinct domains and is accompanied by a clustering-based covariate shift metric that provides a quantitative proxy for domain difficulty. We further leverage a one-vs-all binary training objective that decomposes multi-class action recognition into independent binary classification tasks. This formulation is particularly well-suited for covariate shift by reducing interference between visually similar classes under feature distribution shift. Using this formulation, we show that a lightweight two-layer fully connected network achieves performance competitive with state-of-the-art egocentric domain generalization methods on both Argo1M and Ego4OOD, despite using fewer parameters and no additional modalities. Our empirical analysis demonstrates a clear relationship between measured covariate shift and recognition performance, highlighting the importance of controlled benchmarks and quantitative domain characterization for studying out-of-distribution generalization in egocentric video.", "AI": {"tldr": "本文提出Ego4OOD基准，旨在通过可衡量的协变量变化来重新思考第一人称视频领域泛化的评估，并展示了一个简单的两层全连接网络在该基准上的优秀性能。", "motivation": "为了更可靠地评估模型跨输入分布泛化的能力，作者指出现有基准将协变量变化与概念变化混为一谈的问题，并提出Ego4OOD来解决这一局限性。", "method": "引入了Ego4OOD基准和一种基于聚类的协变量变化度量方法，使用了一种one-vs-all二元训练目标，将多分类任务分解成独立的二元分类任务。", "result": "通过所提出的二元训练目标，一个轻量级两层全连接网络在Ego4OOD和Argo1M上达到了与现有最佳第一人称领域泛化方法相竞争的表现，尽管参数更少且没有额外模态。", "conclusion": "实验证明了测量的协变量变化与识别性能之间的明确关系，并强调了控制基准的重要性及量化的领域特征对于研究第一人称视频的分布外泛化问题的价值。"}}
{"id": "2601.17054", "pdf": "https://arxiv.org/pdf/2601.17054", "abs": "https://arxiv.org/abs/2601.17054", "authors": ["Hongbo Bo", "Jingyu Hu", "Debbie Watson", "Weiru Liu"], "title": "Failing on Bias Mitigation: Investigating Why Predictive Models Struggle with Government Data", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The potential for bias and unfairness in AI-supporting government services raises ethical and legal concerns. Using crime rate prediction with the Bristol City Council data as a case study, we examine how these issues persist. Rather than auditing real-world deployed systems, our goal is to understand why widely adopted bias mitigation techniques often fail when applied to government data. Our findings reveal that bias mitigation approaches applied to government data are not always effective -- not because of flaws in model architecture or metric selection, but due to the inherent properties of the data itself. Through comparing a set of comprehensive models and fairness methods, our experiments consistently show that the mitigation efforts cannot overcome the embedded unfairness in the data -- further reinforcing that the origin of bias lies in the structure and history of government datasets. We then explore the reasons for the mitigation failures in predictive models on government data and highlight the potential sources of unfairness posed by data distribution shifts, the accumulation of historical bias, and delays in data release. We also discover the limitations of the blind spots in fairness analysis and bias mitigation methods when only targeting a single sensitive feature through a set of intersectional fairness experiments. Although this study is limited to one city, the findings are highly suggestive, which can contribute to an early warning that biases in government data may persist even with standard mitigation methods.", "AI": {"tldr": "本文研究了为什么广泛采用的偏见缓解技术在应用于政府数据时往往失败，并通过犯罪率预测案例探讨其原因。", "motivation": "鉴于AI支持政府服务中的偏见和不公引发伦理和法律问题，该论文旨在理解为何现有的偏见缓解技术未能有效解决政府数据中存在的不公平现象。", "method": "使用布里斯托尔市议会的数据作为案例研究，比较了一组全面的模型和公平性方法来探讨偏见缓解失败的原因。", "result": "实验表明，偏见缓解努力无法克服数据中的固有不公平性，这进一步证实了政府数据集结构和历史是偏见来源。", "conclusion": "该研究表明，即使采用标准的偏见缓解方法，政府数据中的偏见可能仍然存在，并指出了解偏见分析盲点及单一敏感特征靶向方法限制的重要性。"}}
{"id": "2601.17053", "pdf": "https://arxiv.org/pdf/2601.17053", "abs": "https://arxiv.org/abs/2601.17053", "authors": ["Shuhao Que", "Dieuwke van Dartel", "Ilse Heeringa", "Han Hegeman", "Miriam Vollenbroek-Hutten", "Ying Wang"], "title": "Synthetic Data Guided Feature Selection for Robust Activity Recognition in Older Adults", "categories": ["cs.CV"], "comment": "This paper has been submitted to Nordic Conference on Digital Health and Wireless Solutions 2026, currently under review", "summary": "Physical activity during hip fracture rehabilitation is essential for mitigating long-term functional decline in geriatric patients. However, it is rarely quantified in clinical practice. Existing continuous monitoring systems with commercially available wearable activity trackers are typically developed in middle-aged adults and therefore perform unreliably in older adults with slower and more variable gait patterns. This study aimed to develop a robust human activity recognition (HAR) system to improve continuous physical activity recognition in the context of hip fracture rehabilitation. 24 healthy older adults aged over 80 years were included to perform activities of daily living (walking, standing, sitting, lying down, and postural transfers) under simulated free-living conditions for 75 minutes while wearing two accelerometers positioned on the lower back and anterior upper thigh. Model robustness was evaluated using leave-one-subject-out cross-validation. The synthetic data demonstrated potential to improve generalization across participants. The resulting feature intervention model (FIM), aided by synthetic data guidance, achieved reliable activity recognition with mean F1-scores of 0.896 for walking, 0.927 for standing, 0.997 for sitting, 0.937 for lying down, and 0.816 for postural transfers. Compared with a control condition model without synthetic data, the FIM significantly improved the postural transfer detection, i.e., an activity class of high clinical relevance that is often overlooked in existing HAR literature. In conclusion, these preliminary results demonstrate the feasibility of robust activity recognition in older adults. Further validation in hip fracture patient populations is required to assess the clinical utility of the proposed monitoring system.", "AI": {"tldr": "本文开发了一个使用合成数据引导特征选择的稳健人类活动识别系统，以改进老年人髋部骨折康复中的持续体力活动识别。", "motivation": "由于现有的连续监测系统通常是在中年人群上开发的，在步态模式更慢且变化更大的老年人身上表现不佳。因此，开发一个在老年人中更可靠的HAR系统非常有必要。", "method": "研究包括24位超过80岁的健康老年人，他们穿戴两个加速度计（位于下背部和前大腿）进行日常活动，使用leave-one-subject-out交叉验证评估模型的稳健性，并通过合成数据指导特征干预模型(FIM)以改善识别效果。", "result": "FIM显著提升了姿势转移检测的准确性，各项活动的平均F1分数分别为：行走0.896、站立0.927、坐姿0.997、躺下0.937和姿势转移0.816。", "conclusion": "初步结果证明了在老年人中实现稳健活动识别的可行性，但仍需要进一步验证以评估该监测系统在髋部骨折患者中的临床实用性。"}}
{"id": "2601.17050", "pdf": "https://arxiv.org/pdf/2601.17050", "abs": "https://arxiv.org/abs/2601.17050", "authors": ["Hongjun An", "Yiliang Song", "Jiawei Shao", "Zhe Sun", "Xuelong Li"], "title": "Single-Pixel Vision-Language Model for Intrinsic Privacy-Preserving Behavioral Intelligence", "categories": ["cs.CV", "cs.AI"], "comment": "Initial Version, Pending Updates. We welcome any feedback and suggestions for improvement. Please feel free to contact us at an.hongjun@foxmail.com", "summary": "Adverse social interactions, such as bullying, harassment, and other illicit activities, pose significant threats to individual well-being and public safety, leaving profound impacts on physical and mental health. However, these critical events frequently occur in privacy-sensitive environments like restrooms, and changing rooms, where conventional surveillance is prohibited or severely restricted by stringent privacy regulations and ethical concerns. Here, we propose the Single-Pixel Vision-Language Model (SP-VLM), a novel framework that reimagines secure environmental monitoring. It achieves intrinsic privacy-by-design by capturing human dynamics through inherently low-dimensional single-pixel modalities and inferring complex behavioral patterns via seamless vision-language integration. Building on this framework, we demonstrate that single-pixel sensing intrinsically suppresses identity recoverability, rendering state-of-the-art face recognition systems ineffective below a critical sampling rate. We further show that SP-VLM can nonetheless extract meaningful behavioral semantics, enabling robust anomaly detection, people counting, and activity understanding from severely degraded single-pixel observations. Combining these findings, we identify a practical sampling-rate regime in which behavioral intelligence emerges while personal identity remains strongly protected. Together, these results point to a human-rights-aligned pathway for safety monitoring that can support timely intervention without normalizing intrusive surveillance in privacy-sensitive spaces.", "AI": {"tldr": "本文提出了Single-Pixel Vision-Language Model（SP-VLM），旨在通过单像素视觉语言模型实现隐私保护的行为智能监测。", "motivation": "文章的动机在于解决在隐私敏感环境中，如卫生间和更衣室等地方，如何有效检测不良社会互动（例如欺凌、骚扰）而不侵犯个人隐私的问题。", "method": "SP-VLM通过单像素模态捕捉人类动态，并结合视觉-语言集成来推断复杂的行为模式，从而实现内置的隐私保护设计。", "result": "研究结果表明，单像素感知可以抑制身份恢复能力，使最先进的面部识别系统在低于关键采样率时无效。此外，SP-VLM可以从严重降级的单像素观测中提取有意义的行为语义，实现了鲁棒异常检测、人员计数和活动理解。", "conclusion": "研究结果指出了一个符合人权导向的安全监测路径，在隐私敏感空间中可以支持及时干预而不归正常规侵入性监控。"}}
{"id": "2601.17049", "pdf": "https://arxiv.org/pdf/2601.17049", "abs": "https://arxiv.org/abs/2601.17049", "authors": ["Christina Garcia", "Nhat Tan Le", "Taihei Fujioka", "Umang Dobhal", "Milyun Ni'ma Shoumi", "Thanh Nha Nguyen", "Sozo Inoue"], "title": "Summary of the Unusual Activity Recognition Challenge for Developmental Disability Support", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": "14 pages, 7 figures, 3 tables. Summary paper for a coding challenge hosted in ISAS 2025", "summary": "This paper presents an overview of the Recognize the Unseen: Unusual Behavior Recognition from Pose Data Challenge, hosted at ISAS 2025. The challenge aims to address the critical need for automated recognition of unusual behaviors in facilities for individuals with developmental disabilities using non-invasive pose estimation data. Participating teams were tasked with distinguishing between normal and unusual activities based on skeleton keypoints extracted from video recordings of simulated scenarios. The dataset reflects real-world imbalance and temporal irregularities in behavior, and the evaluation adopted a Leave-One-Subject-Out (LOSO) strategy to ensure subject-agnostic generalization. The challenge attracted broad participation from 40 teams applying diverse approaches ranging from classical machine learning to deep learning architectures. Submissions were assessed primarily using macro-averaged F1 scores to account for class imbalance. The results highlight the difficulty of modeling rare, abrupt actions in noisy, low-dimensional data, and emphasize the importance of capturing both temporal and contextual nuances in behavior modeling. Insights from this challenge may contribute to future developments in socially responsible AI applications for healthcare and behavior monitoring.", "AI": {"tldr": "本文概述了在ISAS 2025举办的识别未见行为挑战赛，旨在通过非侵入式的姿态估计数据自动识别发展障碍个体设施中的不寻常行为。", "motivation": "该挑战赛的动机是解决自动化识别发育障碍人士中不寻常行为的关键需求，使用基于视频记录的姿态关键点来区分正常和异常活动。", "method": "比赛采用Leave-One-Subject-Out (LOSO)策略评估方法，参赛队伍运用了从传统机器学习到深度学习架构的各种方法。", "result": "结果展示了在噪音、低维数据中建模罕见的突变行为的挑战，并强调需要捕捉行为中的时空和语境细微差别。", "conclusion": "比赛提供的见解可能对医疗保健和社会负责的人工智能应用未来的开发产生贡献。"}}
{"id": "2601.17048", "pdf": "https://arxiv.org/pdf/2601.17048", "abs": "https://arxiv.org/abs/2601.17048", "authors": ["Jing Jie Tan", "Rupert Schreiner", "Matthias Hausladen", "Ali Asgharzade", "Simon Edler", "Julian Bartsch", "Michael Bachmann", "Andreas Schels", "Ban-Hoe Kwan", "Danny Wee-Kiat Ng", "Yan-Chai Hum"], "title": "SiMiC: Context-Aware Silicon Microstructure Characterization Using Attention-Based Convolutional Neural Networks for Field-Emission Tip Analysis", "categories": ["cs.CV", "cs.AI"], "comment": "ef:Journal of Vacuum Science and Technology B (2025)", "summary": "Accurate characterization of silicon microstructures is essential for advancing microscale fabrication, quality control, and device performance. Traditional analysis using Scanning Electron Microscopy (SEM) often requires labor-intensive, manual evaluation of feature geometry, limiting throughput and reproducibility. In this study, we propose SiMiC: Context-Aware Silicon Microstructure Characterization Using Attention-Based Convolutional Neural Networks for Field-Emission Tip Analysis. By leveraging deep learning, our approach efficiently extracts morphological features-such as size, shape, and apex curvature-from SEM images, significantly reducing human intervention while improving measurement consistency. A specialized dataset of silicon-based field-emitter tips was developed, and a customized CNN architecture incorporating attention mechanisms was trained for multi-class microstructure classification and dimensional prediction. Comparative analysis with classical image processing techniques demonstrates that SiMiC achieves high accuracy while maintaining interpretability. The proposed framework establishes a foundation for data-driven microstructure analysis directly linked to field-emission performance, opening avenues for correlating emitter geometry with emission behavior and guiding the design of optimized cold-cathode and SEM electron sources. The related dataset and algorithm repository that could serve as a baseline in this area can be found at https://research.jingjietan.com/?q=SIMIC", "AI": {"tldr": "本文提出了SiMiC，一种基于注意力机制的卷积神经网络框架，用于硅微结构特征化分析。", "motivation": "传统扫描电子显微镜（SEM）分析方法耗时且依赖人工评估，限制了效率和再现性。为了提高硅微结构特征化的自动化水平和一致性，本研究开发了一种基于深度学习的方法。", "method": "SiMiC框架利用定制的CNN架构结合注意力机制，从SEM图像中自动提取尺寸、形状和尖端曲率等形态学特征，并用于多类微结构分类和尺寸预测。", "result": "通过与经典图像处理技术比较，SiMiC展示了高准确性和可解释性。该方法显著减少了人为干预并提高了测量一致性。", "conclusion": "本研究提出的框架为数据驱动的硅微结构分析奠定基础，并可能用于探索发射器几何形状与电发射行为之间的关联，指导冷阴极和扫描电子显微镜电子源的设计优化。"}}
