{"id": "2602.12281", "pdf": "https://arxiv.org/pdf/2602.12281", "abs": "https://arxiv.org/abs/2602.12281", "authors": ["Jacky Kwok", "Xilun Zhang", "Mengdi Xu", "Yuejiang Liu", "Azalia Mirhoseini", "Chelsea Finn", "Marco Pavone"], "title": "Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment", "categories": ["cs.RO", "cs.AI", "eess.SY"], "comment": null, "summary": "The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the \"intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce \"boot-time compute\" and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14% gains in task progress and 9% in success rate.", "AI": {"tldr": "该论文探讨了通过测试时的验证来缩小视觉语言行动模型中的意图和动作之间的差距，提出了一种名为CoVer的对比验证器，并展示了其在提升任务完成度和成功率方面的优越性。", "motivation": "通用机器人需要理解并根据自然语言指令执行操作。虽然现有模型有所进步，但生成的动作仍可能与给定指令不一致。因此，研究者希望通过测试时验证来缩小这种“意图-动作”差距，从而提高模型的准确性。", "method": "该论文提出了一种名为CoVer的对比验证器，并介绍了一种通过“启动计算”和分层验证推理管道来增强视觉语言行动对齐的方法。这种方法在部署期间预计算一组多样化的重述指令，并利用一个验证器选择最佳高阶提示和低级动作片段。", "result": "与在相同数据集上进行策略预训练相比，该论文提出的验证方法在SIMPLER基准测试中获得了22%的内部分布增益和13%的外部分布增益。此外，在现实世界实验中还取得了45%的进步。在PolaRiS基准测试中，CoVer实现了任务进度提高14%，成功率提高9%。", "conclusion": "该论文展示了通过验证而不是策略学习来提升视觉语言行动模型的能力。这种方法不仅能够有效地缩小意图与动作之间的差距，而且还能显著提高任务完成度和成功率，并在现实世界的应用场景中展现出优越性。"}}
{"id": "2602.12280", "pdf": "https://arxiv.org/pdf/2602.12280", "abs": "https://arxiv.org/abs/2602.12280", "authors": ["Huai-Hsun Cheng", "Siang-Ling Zhang", "Yu-Lun Liu"], "title": "Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching", "categories": ["cs.CV"], "comment": "Project page: https://stroke-of-surprise.github.io/ Code: https://github.com/stroke-of-surprise/Stroke-Of-Surprise", "summary": "Visual illusions traditionally rely on spatial manipulations such as multi-view consistency. In this work, we introduce Progressive Semantic Illusions, a novel vector sketching task where a single sketch undergoes a dramatic semantic transformation through the sequential addition of strokes. We present Stroke of Surprise, a generative framework that optimizes vector strokes to satisfy distinct semantic interpretations at different drawing stages. The core challenge lies in the \"dual-constraint\": initial prefix strokes must form a coherent object (e.g., a duck) while simultaneously serving as the structural foundation for a second concept (e.g., a sheep) upon adding delta strokes. To address this, we propose a sequence-aware joint optimization framework driven by a dual-branch Score Distillation Sampling (SDS) mechanism. Unlike sequential approaches that freeze the initial state, our method dynamically adjusts prefix strokes to discover a \"common structural subspace\" valid for both targets. Furthermore, we introduce a novel Overlay Loss that enforces spatial complementarity, ensuring structural integration rather than occlusion. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines in recognizability and illusion strength, successfully expanding visual anagrams from the spatial to the temporal dimension. Project page: https://stroke-of-surprise.github.io/", "AI": {"tldr": "本文提出了渐进语义错觉，这是一个新颖的矢量素描任务，其中单个素描通过逐步添加笔划经历戏剧性的语义转变。", "motivation": "视觉错觉传统上依赖于空间操作。然而，作者引入了渐进式语义错觉的概念，并希望通过这一创新来挑战传统的视觉错觉方法。", "method": "本文提出了一种名为Stroke of Surprise的生成框架，该框架通过双分支评分蒸馏采样机制进行序列感知联合优化，以解决初始前缀笔划需同时形成一个连贯的对象以及作为第二个概念的基础的问题。此方法动态调整前缀笔画以发现两个目标之间的“公共结构子空间”。此外还引入了叠加损失来确保空间互补性。", "result": "实验结果表明该方法在可识别性和错觉强度方面显著优于现有的基线模型，成功地将视觉字谜从空间维度扩展到时间维度。", "conclusion": "作者通过渐进式语义错觉任务和Stroke of Surprise框架展示了新颖的素描变换方法，并证明了这种方法在生成具有强语义变化的矢量素描时的有效性。"}}
{"id": "2602.12279", "pdf": "https://arxiv.org/pdf/2602.12279", "abs": "https://arxiv.org/abs/2602.12279", "authors": ["Leon Liangyu Chen", "Haoyu Ma", "Zhipeng Fan", "Ziqi Huang", "Animesh Sinha", "Xiaoliang Dai", "Jialiang Wang", "Zecheng He", "Jianwei Yang", "Chunyuan Li", "Junzhe Sun", "Chu Wang", "Serena Yeung-Levy", "Felix Juefei-Xu"], "title": "UniT: Unified Multimodal Chain-of-Thought Test-time Scaling", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extending this paradigm to unified multimodal models remains an open challenge. We introduce UniT, a framework for multimodal chain-of-thought test-time scaling that enables a single unified model to reason, verify, and refine across multiple rounds. UniT combines agentic data synthesis, unified model training, and flexible test-time inference to elicit cognitive behaviors including verification, subgoal decomposition, and content memory. Our key findings are: (1) unified models trained on short reasoning trajectories generalize to longer inference chains at test time; (2) sequential chain-of-thought reasoning provides a more scalable and compute-efficient TTS strategy than parallel sampling; (3) training on generation and editing trajectories improves out-of-distribution visual reasoning. These results establish multimodal test-time scaling as an effective paradigm for advancing both generation and understanding in unified models.", "AI": {"tldr": "UniT 是一种用于统一多模态模型在测试时间迭代推理的框架，旨在提高复杂任务中的表现。", "motivation": "现有的统一多模态模型通常仅进行一次性的推理而缺少多次验证和修正过程。为了提升其在处理复杂空间组合、多个交互对象或动态指令等任务上的性能，作者提出了Uni-T框架以实现测试时间迭代推理。", "method": "该方法结合了代理数据合成、统一模型训练以及灵活的测试时推理策略来激发认知行为如验证、子目标分解及内容记忆。它通过序列化的链式思想推理提供了一个比并行采样更可扩展且计算效率更高的测试时间缩放策略。", "result": "实验结果显示，经过短推理轨迹训练的统一模型可以在长推断链中泛化；序列化链式思想推理比并行抽样更具规模性和计算效率；通过生成和编辑轨迹进行培训可以改进视觉推理的分布外性能。这些结果证明了多模态测试时间缩放作为一种有效方法，能够提升统一模型中的生成能力和理解能力。", "conclusion": "该研究提出了一种新的框架Uni-T用于提高统一多模态模型在复杂任务上的表现，并验证其有效性及改进方向。"}}
{"id": "2602.12278", "pdf": "https://arxiv.org/pdf/2602.12278", "abs": "https://arxiv.org/abs/2602.12278", "authors": ["David Jiahao Fu", "Lam Thanh Do", "Jiayu Li", "Kevin Chen-Chuan Chang"], "title": "AttentionRetriever: Attention Layers are Secretly Long Document Retrievers", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, including context-awareness, causal dependence, and scope of retrieval. In this paper, we proposed AttentionRetriever, a novel long document retrieval model that leverages attention mechanism and entity-based retrieval to build context-aware embeddings for long document and determine the scope of retrieval. With extensive experiments, we found AttentionRetriever is able to outperform existing retrieval models on long document retrieval datasets by a large margin while remaining as efficient as dense retrieval models.", "AI": {"tldr": "本文提出了一种名为AttentionRetriever的新型长文档检索模型，该模型利用注意力机制和基于实体的检索来构建上下文感知嵌入，以改善长文档检索。", "motivation": "现有的检索模型在处理涉及长文档的任务时未能解决如上下文感知、因果依赖性和检索范围等关键挑战。为此，作者设计了AttentionRetriever。", "method": "AttentionRetriever利用注意力机制和实体基础的检索来构建长文档的上下文感知嵌入，并确定检索范围。", "result": "实验结果表明，AttentionRetriever在长文档检索数据集上显著优于现有的检索模型，同时保持了密集型检索模型的效率。", "conclusion": "提出的AttentionRetriever通过解决现有模型无法处理的关键挑战，在长文档检索任务中表现优异且高效。"}}
{"id": "2602.12276", "pdf": "https://arxiv.org/pdf/2602.12276", "abs": "https://arxiv.org/abs/2602.12276", "authors": ["Nicholas Lee", "Lutfi Eren Erdogan", "Chris Joseph John", "Surya Krishnapillai", "Michael W. Mahoney", "Kurt Keutzer", "Amir Gholami"], "title": "Agentic Test-Time Scaling for WebAgents", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive policies that uniformly increase sampling show diminishing returns. In this work, we present CATTS, a simple technique for dynamically allocating compute for multi-step agents. We first conduct an empirical study of inference-time scaling for web agents. We find that uniformly increasing per-step compute quickly saturates in long-horizon environments. We then investigate stronger aggregation strategies, including an LLM-based Arbiter that can outperform naive voting, but that can overrule high-consensus decisions. We show that uncertainty statistics derived from the agent's own vote distribution (entropy and top-1/top-2 margin) correlate with downstream success and provide a practical signal for dynamic compute allocation. Based on these findings, we introduce Confidence-Aware Test-Time Scaling (CATTS), which uses vote-derived uncertainty to allocate compute only when decisions are genuinely contentious. CATTS improves performance on WebArena-Lite and GoBrowse by up to 9.1% over React while using up to 2.3x fewer tokens than uniform scaling, providing both efficiency gains and an interpretable decision rule.", "AI": {"tldr": "该论文提出了CATTS，一种用于多步代理的动态计算分配技术。", "motivation": "现有的测试时间缩放方法在长步骤任务上表现不佳，并且随着采样增加而回报递减。该研究旨在解决这些问题并提高性能与可靠性。", "method": "首先进行推理时间缩放的实证研究，发现均匀增加每步计算量会快速饱和；接着探索更强的聚合策略，包括可以超越简单投票的LLM仲裁器，并引入基于代理投票分布不确定性（熵和top-1/top-2差距）来动态分配计算。", "result": "CATTS在WebArena-Lite和GoBrowse上提高了9.1%的性能，同时减少了高达2.3倍的令牌使用量。", "conclusion": "CATTS提供了一种既高效又可解释的方法，在多步代理任务中显著提高了模型的表现和效率。"}}
{"id": "2602.12271", "pdf": "https://arxiv.org/pdf/2602.12271", "abs": "https://arxiv.org/abs/2602.12271", "authors": ["Krish Agarwal", "Zhuoming Chen", "Cheng Luo", "Yongqi Chen", "Haizhong Zheng", "Xun Huang", "Atri Rudra", "Beidi Chen"], "title": "MonarchRT: Efficient Attention for Real-Time Video Generation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Real-time video generation with Diffusion Transformers is bottlenecked by the quadratic cost of 3D self-attention, especially in real-time regimes that are both few-step and autoregressive, where errors compound across time and each denoising step must carry substantially more information. In this setting, we find that prior sparse-attention approximations break down, despite showing strong results for bidirectional, many-step diffusion. Specifically, we observe that video attention is not reliably sparse, but instead combines pronounced periodic structure driven by spatiotemporal position with dynamic, sparse semantic correspondences and dense mixing, exceeding the representational capacity of even oracle top-k attention. Building on this insight, we propose Monarch-RT, a structured attention parameterization for video diffusion models that factorizes attention using Monarch matrices. Through appropriately aligned block structure and our extended tiled Monarch parameterization, we achieve high expressivity while preserving computational efficiency. We further overcome the overhead of parameterization through finetuning, with custom Triton kernels. We first validate the high efficacy of Monarch-RT over existing sparse baselines designed only for bidirectional models. We further observe that Monarch-RT attains up to 95% attention sparsity with no loss in quality when applied to the state-of-the-art model Self-Forcing, making Monarch-RT a pioneering work on highly-capable sparse attention parameterization for real-time video generation. Our optimized implementation outperforms FlashAttention-2, FlashAttention-3, and FlashAttention-4 kernels on Nvidia RTX 5090, H100, and B200 GPUs respectively, providing kernel speedups in the range of 1.4-11.8X. This enables us, for the first time, to achieve true real-time video generation with Self-Forcing at 16 FPS on a single RTX 5090.", "AI": {"tldr": "提出MonarchRT，一种结构化注意力参数化方法，用于视频扩散模型的实时生成。", "motivation": "现有稀疏注意力近似在实时生成中的表现不佳，尤其是在自回归模式下错误累积。该研究旨在解决此问题并提高计算效率和效果。", "method": "通过因子分解使用Monarch矩阵实现注意力结构化参数化，并引入扩展的平铺Monarch参数化以保持高表达力的同时保留计算效率。优化实现通过微调和定制Triton内核克服了参数化的开销。", "result": "在对比现有稀疏基准时，验证了Monarch-RT的有效性。当应用于Self-Forcing模型时，可以达到95%的注意力稀疏度而没有质量损失，并且优化实现提供1.4到11.8倍的速度提升。", "conclusion": "首次实现了使用Self-Forcing以16FPS在单个RTX 5090上进行真正的实时视频生成。"}}
{"id": "2602.12270", "pdf": "https://arxiv.org/pdf/2602.12270", "abs": "https://arxiv.org/abs/2602.12270", "authors": ["Annie Liang", "Jay Lu"], "title": "Creative Ownership in the Age of AI", "categories": ["econ.TH", "cs.AI", "cs.GT"], "comment": null, "summary": "Copyright law focuses on whether a new work is \"substantially similar\" to an existing one, but generative AI can closely imitate style without copying content, a capability now central to ongoing litigation. We argue that existing definitions of infringement are ill-suited to this setting and propose a new criterion: a generative AI output infringes on an existing work if it could not have been generated without that work in its training corpus. To operationalize this definition, we model generative systems as closure operators mapping a corpus of existing works to an output of new works. AI generated outputs are \\emph{permissible} if they do not infringe on any existing work according to our criterion. Our results characterize structural properties of permissible generation and reveal a sharp asymptotic dichotomy: when the process of organic creations is light-tailed, dependence on individual works eventually vanishes, so that regulation imposes no limits on AI generation; with heavy-tailed creations, regulation can be persistently constraining.", "AI": {"tldr": "提出了一个新的侵权标准来解决AI生成作品时的版权问题。", "motivation": "当前的版权法律在处理由AI生成的作品时存在不足，特别是在风格相似但不复制内容的情况下。现有的定义无法很好地适应这种情况。", "method": "将生成系统建模为闭包操作符，将现有作品集映射到新作品集中，并根据新的侵权标准判断这些新作品是否合规。", "result": "通过模型研究了在不同类型的有机创作过程中AI生成的合法性和版权限制的影响。", "conclusion": "结果表明，在轻尾分布的情况下，随着时间推移，依赖于单个作品的情况会消失；而在重尾分布下，法律限制将持续存在。"}}
{"id": "2602.12268", "pdf": "https://arxiv.org/pdf/2602.12268", "abs": "https://arxiv.org/abs/2602.12268", "authors": ["Zhen Zhang", "Kaiqiang Song", "Xun Wang", "Yebowen Hu", "Weixiang Yan", "Chenyang Zhao", "Henry Peng Zou", "Haoyun Deng", "Sathish Reddy Indurthi", "Shujian Liu", "Simin Ma", "Xiaoyang Wang", "Xin Eric Wang", "Song Wang"], "title": "CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use", "categories": ["cs.AI"], "comment": null, "summary": "AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behaviors; moreover, RL for multi-turn, multi-step agentic tool use is still underexplored; and building and maintaining executable tool environments is costly, limiting scale and coverage. We propose CM2, an RL framework that replaces verifiable outcome rewards with checklist rewards. CM2 decomposes each turn's intended behavior into fine-grained binary criteria with explicit evidence grounding and structured metadata, turning open-ended judging into more stable classification-style decisions. To balance stability and informativeness, our method adopts a strategy of sparse reward assignment but dense evaluation criteria. Training is performed in a scalable LLM-simulated tool environment, avoiding heavy engineering for large tool sets. Experiments show that CM2 consistently improves over supervised fine-tuning. Starting from an 8B Base model and training on an 8k-example RL dataset, CM2 improves over the SFT counterpart by 8 points on tau^-Bench, by 10 points on BFCL-V4, and by 12 points on ToolSandbox. The results match or even outperform similarly sized open-source baselines, including the judging model. CM2 thus provides a scalable recipe for optimizing multi-turn, multi-step tool-using agents without relying on verifiable rewards. Code provided by the open-source community: https://github.com/namezhenzhang/CM2-RLCR-Tool-Agent.", "AI": {"tldr": "提出了一种使用检查表奖励的强化学习框架CM2，用于多轮和多步骤的代理工具使用。", "motivation": "现实世界的任务通常缺乏可验证的结果奖励，并且强调开放式行为；在多轮、多步骤的代理工具使用场景中应用强化学习仍处于探索阶段；构建并维护执行工具环境成本高昂。", "method": "CM2将每一轮意图行为分解为细粒度的二进制标准，采用稀疏奖励分配策略但具有密集评估标准。训练在可扩展的LLM模拟工具环境中进行。", "result": "实验表明，CM2在tau^-Bench、BFCL-V4和ToolSandbox上分别比监督微调模型提高了8分、10分和12分。", "conclusion": "CM2提供了一种优化多轮、多步骤代理工具使用的方法，在无需依赖可验证奖励的情况下表现出色。"}}
{"id": "2602.12259", "pdf": "https://arxiv.org/pdf/2602.12259", "abs": "https://arxiv.org/abs/2602.12259", "authors": ["Jianke Yang", "Ohm Venkatachalam", "Mohammad Kianezhad", "Sharvaree Vadgama", "Rose Yu"], "title": "Think like a Scientist: Physics-guided LLM Agent for Equation Discovery", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries, then using these as priors to restrict the space of candidate equations. We introduce KeplerAgent, an agentic framework that explicitly follows this scientific reasoning process. The agent coordinates physics-based tools to extract intermediate structure and uses these results to configure symbolic regression engines such as PySINDy and PySR, including their function libraries and structural constraints. Across a suite of physical equation benchmarks, KeplerAgent achieves substantially higher symbolic accuracy and greater robustness to noisy data than both LLM and traditional baselines.", "AI": {"tldr": "该论文提出了KeplerAgent，一种基于物理指导的大型语言模型代理框架，用于从数据中发现符号方程。", "motivation": "现有的LLM系统直接从数据猜测公式，忽略了科学家通常遵循的多步推理过程。因此，提出了一种新的方法来改进这一过程。", "method": "该论文引入了KeplerAgent框架，它协调物理基工具提取中间结构，并用这些结果配置符号回归引擎如PySINDy和PySR，包括其函数库和结构约束。", "result": "在一系列物理方程基准测试中，KeplerAgent比LLM和传统方法具有更高的符号准确性和更强的噪音数据鲁棒性。", "conclusion": "通过模拟科学推理过程，KeplerAgent可以更有效地从数据中发现精确且可解释的数学公式。"}}
{"id": "2602.12257", "pdf": "https://arxiv.org/pdf/2602.12257", "abs": "https://arxiv.org/abs/2602.12257", "authors": ["Govind Menon", "Austin J. Stromme", "Adrien Vacher"], "title": "On the implicit regularization of Langevin dynamics with projected noise", "categories": ["math.PR", "cs.AI"], "comment": "30 pages, 1 figure", "summary": "We study Langevin dynamics with noise projected onto the directions orthogonal to an isometric group action. This mathematical model is introduced to shed new light on the effects of symmetry on stochastic gradient descent for over-parametrized models. Our main result identifies a novel form of implicit regularization: when the initial and target density are both invariant under the group action, Langevin dynamics with projected noise is equivalent in law to Langevin dynamics with isotropic diffusion but with an additional drift term proportional to the negative log volume of the group orbit. We prove this result by constructing a coupling of the two processes via a third process on the group itself, and identify the additional drift as the mean curvature of the orbits.", "AI": {"tldr": "研究了噪声投影到等距群作用正交方向上的兰格VIN动力学，揭示了其隐式正则化形式。", "motivation": "通过数学模型探讨对称性在过参数化模型中随机梯度下降的影响。", "method": "构造了一个耦合过程来研究两种不同噪声下的兰格VIN动力学的等价性。", "result": "发现当初始和目标密度都保持不变时，带有投影噪声的动力学与具有额外漂移项的同质扩散等效。", "conclusion": "提出了一种新的隐式正则化形式，并通过构造耦合过程证明了该结果。"}}
{"id": "2602.12251", "pdf": "https://arxiv.org/pdf/2602.12251", "abs": "https://arxiv.org/abs/2602.12251", "authors": ["Ralph Krüger"], "title": "A technical curriculum on language-oriented artificial intelligence in translation and specialised communication", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "10 pages, 1 figure, EAMT 2026, TAITT Workshop", "summary": "This paper presents a technical curriculum on language-oriented artificial intelligence (AI) in the language and translation (L&T) industry. The curriculum aims to foster domain-specific technical AI literacy among stakeholders in the fields of translation and specialised communication by exposing them to the conceptual and technical/algorithmic foundations of modern language-oriented AI in an accessible way. The core curriculum focuses on 1) vector embeddings, 2) the technical foundations of neural networks, 3) tokenization and 4) transformer neural networks. It is intended to help users develop computational thinking as well as algorithmic awareness and algorithmic agency, ultimately contributing to their digital resilience in AI-driven work environments. The didactic suitability of the curriculum was tested in an AI-focused MA course at the Institute of Translation and Multilingual Communication at TH Koeln. Results suggest the didactic effectiveness of the curriculum, but participant feedback indicates that it should be embedded into higher-level didactic scaffolding - e.g., in the form of lecturer support - in order to enable optimal learning conditions.", "AI": {"tldr": "本文提出了一个针对语言和技术翻译及专业交流领域的基于人工智能的技术课程。", "motivation": "该课程旨在通过引入现代语言导向的人工智能概念和算法基础，提升领域内利益相关者的特定技术AI素养。", "method": "核心课程涵盖了向量嵌入、神经网络的基础知识、分词以及转换器神经网络。这些内容被应用在一个专注于人工智能的硕士课程中进行测试。", "result": "结果表明该课程具有教学有效性，但参与者反馈建议将此课程嵌入更高层次的教学支持框架中以实现最佳学习条件。", "conclusion": "通过提供专门的技术AI教育，可以帮助用户培养计算思维、算法意识和算法能力，并在人工智能驱动的工作环境中增强他们的数字韧性。"}}
{"id": "2602.12249", "pdf": "https://arxiv.org/pdf/2602.12249", "abs": "https://arxiv.org/abs/2602.12249", "authors": ["Kaitlyn Zhou", "Martijn Bartelds", "Federico Bianchi", "James Zou"], "title": "\"Sorry, I Didn't Catch That\": How Speech Models Miss What Matters Most", "categories": ["cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "Despite speech recognition systems achieving low word error rates on standard benchmarks, they often fail on short, high-stakes utterances in real-world deployments. Here, we study this failure mode in a high-stakes task: the transcription of U.S. street names as spoken by U.S. participants. We evaluate 15 models from OpenAI, Deepgram, Google, and Microsoft on recordings from linguistically diverse U.S. speakers and find an average transcription error rate of 44%. We quantify the downstream impact of failed transcriptions by geographic locations and show that mis-transcriptions systematically cause errors for all speakers, but that routing distance errors are twice as large for non-English primary speakers compared to English primary speakers. To mitigate this harm, we introduce a synthetic data generation approach that produces diverse pronunciations of named entities using open-source text-to-speech models. Fine-tuning with less than 1,000 synthetic samples improves street name transcription accuracy by nearly 60% (relative to base models) for non-English primary speakers. Our results highlight a critical gap between benchmark performance and real-world reliability in speech systems and demonstrate a simple, scalable path to reducing high-stakes transcription errors.", "AI": {"tldr": "研究探讨了语音识别系统在真实世界中的高风险短语转录失败的问题，特别是美国街道名称的转录。", "motivation": "虽然现有的语音识别系统在标准基准测试中取得了低单词错误率，但在实际部署时仍常常对简短、重要的口语表达产生误读。", "method": "研究评估了来自OpenAI, Deepgram, Google和Microsoft的15个模型，并引入了一个使用开源文本转语音技术生成多发音实体数据集的方法来改善街道名称的转录准确性。", "result": "合成数据微调后，非英语母语者的街道名字转录准确率提高了近60%，但整体而言，误读对所有说话者的影响显著，尤其是对于非英语使用者来说影响更大。", "conclusion": "研究结果揭示了语音系统在基准性能和实际可靠性之间的关键差距，并展示了减少高风险转录错误的简单且可扩展的方法。"}}
{"id": "2602.12247", "pdf": "https://arxiv.org/pdf/2602.12247", "abs": "https://arxiv.org/abs/2602.12247", "authors": ["Nick Ferguson", "Josh Pennington", "Narek Beghian", "Aravind Mohan", "Douwe Kiela", "Sheshansh Agrawal", "Thien Hang Nguyen"], "title": "ExtractBench: A Benchmark and Evaluation Methodology for Complex Structured Extraction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Unstructured documents like PDFs contain valuable structured information, but downstream systems require this data in reliable, standardized formats. LLMs are increasingly deployed to automate this extraction, making accuracy and reliability paramount. However, progress is bottlenecked by two gaps. First, no end-to-end benchmark evaluates PDF-to-JSON extraction under enterprise-scale schema breadth. Second, no principled methodology captures the semantics of nested extraction, where fields demand different notions of correctness (exact match for identifiers, tolerance for quantities, semantic equivalence for names), arrays require alignment, and omission must be distinguished from hallucination. We address both gaps with ExtractBench, an open-source benchmark and evaluation framework for PDF-to-JSON structured extraction. The benchmark pairs 35 PDF documents with JSON Schemas and human-annotated gold labels across economically valuable domains, yielding 12,867 evaluatable fields spanning schema complexities from tens to hundreds of fields. The evaluation framework treats the schema as an executable specification: each field declares its scoring metric. Baseline evaluations reveal that frontier models (GPT-5/5.2, Gemini-3 Flash/Pro, Claude 4.5 Opus/Sonnet) remain unreliable on realistic schemas. Performance degrades sharply with schema breadth, culminating in 0% valid output on a 369-field financial reporting schema across all tested models. We release ExtractBench at https://github.com/ContextualAI/extract-bench.", "AI": {"tldr": "论文提出了一种评估PDF文档到JSON结构提取的基准测试ExtractBench。", "motivation": "现有方法无法在大规模和复杂的模式下准确评估LLM（大型语言模型）进行PDF数据提取的能力，因此需要一种能够全面评价LLM性能的方法论。", "method": "通过创建包含35个PDF文档、JSON架构及人工注释的黄金标签的数据集来构建ExtractBench。该框架利用可执行规范对每个字段定义其评分标准，并评估了前沿模型在不同复杂度模式下的表现。", "result": "基准测试显示，尽管模型在简单任务上表现出色，但在具有大量字段的企业级模式下性能急剧下降，甚至无法生成有效输出。", "conclusion": "ExtractBench是一个开放源代码的评估框架，它揭示了现有模型在复杂和大规模数据提取方面的局限性，并为未来的研究提供了方向。"}}
{"id": "2602.12246", "pdf": "https://arxiv.org/pdf/2602.12246", "abs": "https://arxiv.org/abs/2602.12246", "authors": ["Mona Ghassemian", "Andrés Meseguer Valenzuela", "Ana Garcia Armada", "Dejan Vukobratovic", "Periklis Chatzimisios", "Kaspar Althoefer", "Ranga Rao Venkatesha Prasad"], "title": "6G Empowering Future Robotics: A Vision for Next-Generation Autonomous Systems", "categories": ["cs.NI", "cs.RO"], "comment": "7 pages, 3 figures, 2 tables, submitted to IEEE magazine publication", "summary": "The convergence of robotics and next-generation communication is a critical driver of technological advancement. As the world transitions from 5G to 6G, the foundational capabilities of wireless networks are evolving to support increasingly complex and autonomous robotic systems. This paper examines the transformative impact of 6G on enhancing key robotics functionalities. It provides a systematic mapping of IMT-2030 key performance indicators to robotic functional blocks including sensing, perception, cognition, actuation and self-learning. Building upon this mapping, we propose a high-level architectural framework integrating robotic, intelligent, and network service planes, underscoring the need for a holistic approach. As an example use case, we present a real-time, dynamic safety framework enabled by IMT-2030 capabilities for safe and efficient human-robot collaboration in shared spaces.", "AI": {"tldr": "探讨6G技术如何赋能未来机器人，特别是在感知、认知和自学习等功能上的提升", "motivation": "随着从5G向6G的过渡，无线网络的基础能力正在发展以支持更加复杂和自主的机器人系统。本文旨在研究6G对关键机器人功能增强的影响，并提出一个综合的方法论框架来促进人机协作的安全高效性", "method": "系统地将IMT-2030的关键性能指标映射到包括感知、认知和自学习在内的机器人功能块上，构建一个集成机器人智能和服务平面的高层次架构模型。作为实例应用，本文提供了一个由IMT-2030能力支持的实时动态安全框架", "result": "提出了一个基于6G技术的机器人系统架构，该架构能够促进未来复杂环境中的人机协作", "conclusion": "通过6G的技术赋能，未来的机器人将能够在更加复杂的环境和任务中实现高度自主的功能，并且这种融合将进一步推动智能社会的发展"}}
{"id": "2602.12245", "pdf": "https://arxiv.org/pdf/2602.12245", "abs": "https://arxiv.org/abs/2602.12245", "authors": ["Anthony Kobanda", "Waris Radji"], "title": "Intrinsic-Energy Joint Embedding Predictive Architectures Induce Quasimetric Spaces", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Joint-Embedding Predictive Architectures (JEPAs) aim to learn representations by predicting target embeddings from context embeddings, inducing a scalar compatibility energy in a latent space. In contrast, Quasimetric Reinforcement Learning (QRL) studies goal-conditioned control through directed distance values (cost-to-go) that support reaching goals under asymmetric dynamics. In this short article, we connect these viewpoints by restricting attention to a principled class of JEPA energy functions : intrinsic (least-action) energies, defined as infima of accumulated local effort over admissible trajectories between two states. Under mild closure and additivity assumptions, any intrinsic energy is a quasimetric. In goal-reaching control, optimal cost-to-go functions admit exactly this intrinsic form ; inversely, JEPAs trained to model intrinsic energies lie in the quasimetric value class targeted by QRL. Moreover, we observe why symmetric finite energies are structurally mismatched with one-way reachability, motivating asymmetric (quasimetric) energies when directionality matters.", "AI": {"tldr": "本文探讨了联合嵌入预测架构(JEPAs)与准度量强化学习(QRL)之间的联系，并发现通过限制JEPAs的能量函数为内在能量，可以将这种结构转化为准度量空间。", "motivation": "文章的动机在于建立联合嵌入预测架构和准度量强化学习之间理论上的联系，以便更好地理解两者在目标导向控制中的作用机制。", "method": "通过引入一种新的限制条件，即仅关注内在能量函数（定义为两状态间允许轨迹累积局部努力的最小值），研究者发现这些能量函数可以转化为准度量空间。此外还观察到对称有限能量与单向可达性存在结构上的不匹配。", "result": "当JEPAs训练用来建模内在能量时，它们处于QRL所关注的目标类别中；并且任何内在能量都是准度量的。", "conclusion": "通过限制JEPAs的能量函数为内在能量，可以将这种架构与准度量强化学习联系起来，并且在目标导向控制任务中使用准度量空间有助于更精确地建模不对称的动力学特性。"}}
{"id": "2602.12244", "pdf": "https://arxiv.org/pdf/2602.12244", "abs": "https://arxiv.org/abs/2602.12244", "authors": ["Zhihong Liu", "Yang Li", "Rengming Huang", "Cewu Lu", "Panpan Cai"], "title": "Any House Any Task: Scalable Long-Horizon Planning for Abstract Human Tasks", "categories": ["cs.RO"], "comment": null, "summary": "Open world language conditioned task planning is crucial for robots operating in large-scale household environments. While many recent works attempt to address this problem using Large Language Models (LLMs) via prompting or training, a key challenge remains scalability. Performance often degrades rapidly with increasing environment size, plan length, instruction ambiguity, and constraint complexity. In this work, we propose Any House Any Task (AHAT), a household task planner optimized for long-horizon planning in large environments given ambiguous human instructions. At its core, AHAT utilizes an LLM trained to map task instructions and textual scene graphs into grounded subgoals defined in the Planning Domain Definition Language (PDDL). These subgoals are subsequently solved to generate feasible and optimal long-horizon plans through explicit symbolic reasoning. To enhance the model's ability to decompose complex and ambiguous intentions, we introduce TGPO, a novel reinforcement learning algorithm that integrates external correction of intermediate reasoning traces into Group Relative Policy Optimization (GRPO). Experiments demonstrate that AHAT achieves significant performance gains over state-of-the-art prompting, planning, and learning methods, particularly in human-style household tasks characterized by brief instructions but requiring complex execution plans.", "AI": {"tldr": "提出了一种名为Any House Any Task (AHAT) 的家庭任务规划器，用于在大规模环境中基于模糊指令进行长期规划。", "motivation": "在大型环境中的语言条件下的开放式任务规划对于机器人至关重要。现有的工作大多通过提示或训练大型语言模型来解决该问题，但性能随着环境规模、计划长度、指令歧义和约束复杂性增加而迅速下降。", "method": "AHAT 利用一个大型语言模型将任务指令和文本场景图映射到定义在PDDL中的具体子目标。这些子目标随后通过显式的符号推理来解决，生成可行且最优的长期计划。为了增强分解复杂和模糊意图的能力，引入了TGPO算法。", "result": "实验结果表明AHAT显著优于现有的提示、规划和学习方法，在人类风格的家庭任务中尤其表现出色，这些任务特点是简短指令但需要复杂的执行计划。", "conclusion": "提出的AHAT在处理大规模环境中的语言条件下的开放式任务规划方面取得了显著进展。"}}
{"id": "2602.12241", "pdf": "https://arxiv.org/pdf/2602.12241", "abs": "https://arxiv.org/abs/2602.12241", "authors": ["Manjunath Kudlur", "Evan King", "James Wang", "Pete Warden"], "title": "Moonshine v2: Ergodic Streaming Encoder ASR for Latency-Critical Speech Applications", "categories": ["cs.CL", "cs.LG", "cs.SD"], "comment": "7 pages, 5 figures", "summary": "Latency-critical speech applications (e.g., live transcription, voice commands, and real-time translation) demand low time-to-first-token (TTFT) and high transcription accuracy, particularly on resource-constrained edge devices. Full-attention Transformer encoders remain a strong accuracy baseline for automatic speech recognition (ASR) because every frame can directly attend to every other frame, which resolves otherwise locally ambiguous acoustics using distant lexical context. However, this global dependency incurs quadratic complexity in sequence length, inducing an inherent \"encode-the-whole-utterance\" latency profile. For streaming use cases, this causes TTFT to grow linearly with utterance length as the encoder must process the entire prefix before any decoder token can be emitted. To better meet the needs of on-device, streaming ASR use cases we introduce Moonshine v2, an ergodic streaming-encoder ASR model that employs sliding-window self-attention to achieve bounded, low-latency inference while preserving strong local context. Our models achieve state of the art word error rates across standard benchmarks, attaining accuracy on-par with models 6x their size while running significantly faster. These results demonstrate that carefully designed local attention is competitive with the accuracy of full attention at a fraction of the size and latency cost, opening new possibilities for interactive speech interfaces on edge devices.", "AI": {"tldr": "介绍Moonshine v2模型，一种用于低延迟语音识别的滑动窗口自注意力流式编码器。", "motivation": "为了满足低延时、高准确率的需求，特别是在资源受限的边缘设备上运行的实时语音应用中，传统全注意力Transformer编码器存在全局依赖性导致的时间复杂度问题。", "method": "采用局部自注意力机制来构建滑动窗口流式编码器模型Moonshine v2，以实现在保持强大局部上下文的同时降低延迟和大小需求。", "result": "实验表明，Moonshine v2在标准基准测试中达到了最佳的字错误率，并且实现了与六倍大小模型相当的准确性同时运行速度更快。", "conclusion": "精心设计的局部注意力机制能够以更低的时间复杂度提供与全注意力相同的准确率，为边缘设备上的交互式语音接口提供了新的可能性。"}}
{"id": "2602.12237", "pdf": "https://arxiv.org/pdf/2602.12237", "abs": "https://arxiv.org/abs/2602.12237", "authors": ["Mayee F. Chen", "Tyler Murray", "David Heineman", "Matt Jordan", "Hannaneh Hajishirzi", "Christopher Ré", "Luca Soldaini", "Kyle Lo"], "title": "Olmix: A Framework for Data Mixing Throughout LM Development", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Data mixing -- determining the ratios of data from different domains -- is a first-order concern for training language models (LMs). While existing mixing methods show promise, they fall short when applied during real-world LM development. We present Olmix, a framework that addresses two such challenges. First, the configuration space for developing a mixing method is not well understood -- design choices across existing methods lack justification or consensus and overlook practical issues like data constraints. We conduct a comprehensive empirical study of this space, identifying which design choices lead to a strong mixing method. Second, in practice, the domain set evolves throughout LM development as datasets are added, removed, partitioned, and revised -- a problem setting largely unaddressed by existing works, which assume fixed domains. We study how to efficiently recompute the mixture after the domain set is updated, leveraging information from past mixtures. We introduce mixture reuse, a mechanism that reuses existing ratios and recomputes ratios only for domains affected by the update. Over a sequence of five domain-set updates mirroring real-world LM development, mixture reuse matches the performance of fully recomputing the mix after each update with 74% less compute and improves over training without mixing by 11.6% on downstream tasks.", "AI": {"tldr": "Olmix是一个框架，旨在解决语言模型开发过程中的数据混合问题，特别是在领域集变化时高效地重新计算混合。", "motivation": "现有数据混合方法在实际应用中存在不足，如配置空间未被充分理解以及领域集变动情况下的处理缺失。因此，本文提出了一种新框架以解决这些问题。", "method": "通过全面实证研究探索设计选择的影响，并引入了混合重用机制，在领域集更新时利用过去混合信息高效重新计算数据比例。", "result": "在一系列五个领域集更新中，Olmix与完全重新计算混合相比减少了74%的计算量，并且提升了11.6％的任务性能。", "conclusion": "通过有效的设计选择研究和混合重用机制，Olmix能更好地适应实际语言模型开发过程中的数据混合需求。"}}
{"id": "2602.12236", "pdf": "https://arxiv.org/pdf/2602.12236", "abs": "https://arxiv.org/abs/2602.12236", "authors": ["Anika Tabassum Meem", "Muntasir Hossain Nadid", "Md Zesun Ahmed Mia"], "title": "Energy-Aware Spike Budgeting for Continual Learning in Spiking Neural Networks for Neuromorphic Vision", "categories": ["cs.NE", "cs.AI", "cs.CV"], "comment": null, "summary": "Neuromorphic vision systems based on spiking neural networks (SNNs) offer ultra-low-power perception for event-based and frame-based cameras, yet catastrophic forgetting remains a critical barrier to deployment in continually evolving environments. Existing continual learning methods, developed primarily for artificial neural networks, seldom jointly optimize accuracy and energy efficiency, with particularly limited exploration on event-based datasets. We propose an energy-aware spike budgeting framework for continual SNN learning that integrates experience replay, learnable leaky integrate-and-fire neuron parameters, and an adaptive spike scheduler to enforce dataset-specific energy constraints during training. Our approach exhibits modality-dependent behavior: on frame-based datasets (MNIST, CIFAR-10), spike budgeting acts as a sparsity-inducing regularizer, improving accuracy while reducing spike rates by up to 47\\%; on event-based datasets (DVS-Gesture, N-MNIST, CIFAR-10-DVS), controlled budget relaxation enables accuracy gains up to 17.45 percentage points with minimal computational overhead. Across five benchmarks spanning both modalities, our method demonstrates consistent performance improvements while minimizing dynamic power consumption, advancing the practical viability of continual learning in neuromorphic vision systems.", "AI": {"tldr": "提出了一种能量感知脉冲预算框架，用于连续学习的神经形态视觉系统中的持续性学习，以优化精度和能源效率。", "motivation": "现有的连续学习方法在人工神经网络上开发，并不经常联合优化准确性和能源效率。对于基于事件的数据集上的探索尤其有限。", "method": "提出了一种能量感知脉冲预算框架，结合经验回放、可学的漏电流积聚-触发（LIF）神经元参数和自适应脉冲调度器来执行特定数据集的能量约束。", "result": "在帧基数据集上，准确度提高并减少脉冲率；事件基数据集中，通过控制预算放松使准确性增加。在五项基准测试中均表现出一致的性能改进，并减少了动态能耗。", "conclusion": "该方法推进了连续学习在神经形态视觉系统的实际可行性"}}
{"id": "2602.12224", "pdf": "https://arxiv.org/pdf/2602.12224", "abs": "https://arxiv.org/abs/2602.12224", "authors": ["Amirmahdi Mirfakhar", "Xuchuang Wang", "Mengfan Xu", "Hedyeh Beyhaghi", "Mohammad Hajiesmaili"], "title": "Bandit Learning in Matching Markets with Interviews", "categories": ["cs.GT", "cs.AI", "econ.TH"], "comment": null, "summary": "Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews, modeling interviews as \\textit{low-cost hints} that reveal partial preference information to both sides. Our framework departs from existing work by allowing firm-side uncertainty: firms, like agents, may be unsure of their own preferences and can make early hiring mistakes by hiring less preferred agents. To handle this, we extend the firm's action space to allow \\emph{strategic deferral} (choosing not to hire in a round), enabling recovery from suboptimal hires and supporting decentralized learning without coordination. We design novel algorithms for (i) a centralized setting with an omniscient interview allocator and (ii) decentralized settings with two types of firm-side feedback. Across all settings, our algorithms achieve time-independent regret, a substantial improvement over the $O(\\log T)$ regret bounds known for learning stable matchings without interviews. Also, under mild structured markets, decentralized performance matches the centralized counterpart up to polynomial factors in the number of agents and firms.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.12222", "pdf": "https://arxiv.org/pdf/2602.12222", "abs": "https://arxiv.org/abs/2602.12222", "authors": ["Miaosen Zhang", "Yishan Liu", "Shuxia Lin", "Xu Yang", "Qi Dai", "Chong Luo", "Weihao Jiang", "Peng Hou", "Anxiang Zeng", "Xin Geng", "Baining Guo"], "title": "Towards On-Policy SFT: Distribution Discriminant Theory and its Applications in LLM Training", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Supervised fine-tuning (SFT) is computationally efficient but often yields inferior generalization compared to reinforcement learning (RL). This gap is primarily driven by RL's use of on-policy data. We propose a framework to bridge this chasm by enabling On-Policy SFT. We first present \\textbf{\\textit{Distribution Discriminant Theory (DDT)}}, which explains and quantifies the alignment between data and the model-induced distribution. Leveraging DDT, we introduce two complementary techniques: (i) \\textbf{\\textit{In-Distribution Finetuning (IDFT)}}, a loss-level method to enhance generalization ability of SFT, and (ii) \\textbf{\\textit{Hinted Decoding}}, a data-level technique that can re-align the training corpus to the model's distribution. Extensive experiments demonstrate that our framework achieves generalization performance on par with prominent offline RL algorithms, including DPO and SimPO, while maintaining the efficiency of an SFT pipeline. The proposed framework thus offers a practical alternative in domains where RL is infeasible. We open-source the code here: https://github.com/zhangmiaosen2000/Towards-On-Policy-SFT", "AI": {"tldr": "该论文提出了一种新的框架，通过引入分布判别理论（DDT），实现了在线策略监督微调（On-Policy SFT）。", "motivation": "传统的监督微调虽然计算效率高，但在泛化能力上不如强化学习。本文旨在通过使监督微调能够使用在线策略数据来提高其性能。", "method": "提出了分布判别理论（DDT）；引入了在分布微调（IDFT），一种增强SFT泛化的损失级别方法；以及提示解码，一种重新对齐训练语料与模型分布的数据级技术。", "result": "实验结果表明，该框架的泛化性能与主流离线RL算法相当，同时保持了SFT的效率。", "conclusion": "本文提出的框架为在强化学习不可行的领域提供了一个实用的选择。"}}
{"id": "2602.12221", "pdf": "https://arxiv.org/pdf/2602.12221", "abs": "https://arxiv.org/abs/2602.12221", "authors": ["Onkar Susladkar", "Tushar Prakash", "Gayatri Deshmukh", "Kiet A. Nguyen", "Jiaxun Zhang", "Adheesh Juvekar", "Tianshu Bao", "Lin Chai", "Sparsh Mittal", "Inderjit S Dhillon", "Ismini Lourentzou"], "title": "Best of Both Worlds: Multimodal Reasoning and Generation via Unified Discrete Flow Matching", "categories": ["cs.CV"], "comment": null, "summary": "We propose UniDFlow, a unified discrete flow-matching framework for multimodal understanding, generation, and editing. It decouples understanding and generation via task-specific low-rank adapters, avoiding objective interference and representation entanglement, while a novel reference-based multimodal preference alignment optimizes relative outcomes under identical conditioning, improving faithfulness and controllability without large-scale retraining. UniDFlpw achieves SOTA performance across eight benchmarks and exhibits strong zero-shot generalization to tasks including inpainting, in-context image generation, reference-based editing, and compositional generation, despite no explicit task-specific training.", "AI": {"tldr": "提出了一种名为UniDFlow的统一离散流匹配框架，用于多模态理解和生成任务", "motivation": "解决在单一模型中同时进行理解与生成时出现的目标干扰和表示纠缠问题，并提高忠实度和可控性", "method": "通过特定任务低秩适配器将理解和生成解耦，利用基于参考的跨模态偏好对齐优化相对结果，在同一条件下提升性能，无需大规模再训练", "result": "在八个基准测试中达到了SOTA水平，并展示了强大的零样本泛化能力，涵盖上色、上下文图像生成、基于参考的编辑和组合式生成等任务", "conclusion": "UniDFlow框架能有效解决多模态理解与生成中的挑战，提供高性能表现"}}
{"id": "2602.12218", "pdf": "https://arxiv.org/pdf/2602.12218", "abs": "https://arxiv.org/abs/2602.12218", "authors": ["Christian Internò", "Jumpei Yamaguchi", "Loren Amdahl-Culleton", "Markus Olhofer", "David Klindt", "Barbara Hammer"], "title": "The Observer Effect in World Models: Invasive Adaptation Corrupts Latent Physics", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Determining whether neural models internalize physical laws as world models, rather than exploiting statistical shortcuts, remains challenging, especially under out-of-distribution (OOD) shifts. Standard evaluations often test latent capability via downstream adaptation (e.g., fine-tuning or high-capacity probes), but such interventions can change the representations being measured and thus confound what was learned during self-supervised learning (SSL). We propose a non-invasive evaluation protocol, PhyIP. We test whether physical quantities are linearly decodable from frozen representations, motivated by the linear representation hypothesis. Across fluid dynamics and orbital mechanics, we find that when SSL achieves low error, latent structure becomes linearly accessible. PhyIP recovers internal energy and Newtonian inverse-square scaling on OOD tests (e.g., $ρ> 0.90$). In contrast, adaptation-based evaluations can collapse this structure ($ρ\\approx 0.05$). These findings suggest that adaptation-based evaluation can obscure latent structures and that low-capacity probes offer a more accurate evaluation of physical world models.", "AI": {"tldr": "该论文提出了一个新的评估协议PhyIP，用于测试神经模型是否在自我监督学习过程中理解了物理规律。", "motivation": "现有的标准评估方法往往通过下游适应（例如微调或高容量探测）来测试潜在能力，但这可能会改变正在测量的表示，并使学到的内容混淆。作者希望通过非侵入性协议PhyIP更好地了解模型是否真正掌握了物理学知识。", "method": "论文提出了一个基于线性可解码性的评估方法PhyIP，通过冻结模型参数并检查物理量能否从这些固定表示中以线性方式解码来判断模型对物理规律的理解。", "result": "在流体动力学和轨道力学上进行测试后发现，在自我监督学习期间表现良好的情况下，潜在结构可以被线性解码。PhyIP能够在OOD测试下恢复内部能量和牛顿平方反比定律（例如ρ>0.90）。相比之下，基于适应性的评估方法可能破坏这种结构。", "conclusion": "论文得出结论认为，基于适应性的评估可能会掩盖模型中的潜在结构，并且使用低容量探测可以提供对物理世界的更准确评价。"}}
{"id": "2602.12215", "pdf": "https://arxiv.org/pdf/2602.12215", "abs": "https://arxiv.org/abs/2602.12215", "authors": ["Jiangran Lyu", "Kai Liu", "Xuheng Zhang", "Haoran Liao", "Yusen Feng", "Wenxuan Zhu", "Tingrui Shen", "Jiayi Chen", "Jiazhao Zhang", "Yifei Dong", "Wenbo Cui", "Senmao Qi", "Shuo Wang", "Yixin Zheng", "Mi Yan", "Xuesong Shi", "Haoran Li", "Dongbin Zhao", "Ming-Yu Liu", "Zhizheng Zhang", "Li Yi", "Yizhou Wang", "He Wang"], "title": "LDA-1B: Scaling Latent Dynamics Action Model via Universal Embodied Data Ingestion", "categories": ["cs.RO"], "comment": "Project Page:https://pku-epic.github.io/LDA", "summary": "Recent robot foundation models largely rely on large-scale behavior cloning, which imitates expert actions but discards transferable dynamics knowledge embedded in heterogeneous embodied data. While the Unified World Model (UWM) formulation has the potential to leverage such diverse data, existing instantiations struggle to scale to foundation-level due to coarse data usage and fragmented datasets. We introduce LDA-1B, a robot foundation model that scales through universal embodied data ingestion by jointly learning dynamics, policy, and visual forecasting, assigning distinct roles to data of varying quality. To support this regime at scale, we assemble and standardize EI-30k, an embodied interaction dataset comprising over 30k hours of human and robot trajectories in a unified format. Scalable dynamics learning over such heterogeneous data is enabled by prediction in a structured DINO latent space, which avoids redundant pixel-space appearance modeling. Complementing this representation, LDA-1B employs a multi-modal diffusion transformer to handle asynchronous vision and action streams, enabling stable training at the 1B-parameter scale. Experiments in simulation and the real world show LDA-1B outperforms prior methods (e.g., $π_{0.5}$) by up to 21\\%, 48\\%, and 23\\% on contact-rich, dexterous, and long-horizon tasks, respectively. Notably, LDA-1B enables data-efficient fine-tuning, gaining 10\\% by leveraging 30\\% low-quality trajectories typically harmful and discarded.", "AI": {"tldr": "介绍LDA-1B，一种通过通用沉浸式数据摄取进行扩展的机器人基础模型。", "motivation": "现有机器人基础模型主要依赖大规模行为克隆技术，该技术模仿专家行动但忽略了嵌入在异质沉浸式数据中的可转移动态知识。为了利用这种多样化数据，提出了LDA-1B来解决当前方法难以规模化到基础级别的问题。", "method": "通过联合学习动力学、策略和视觉预测，并根据不同质量的数据分配不同的角色，实现了一种新的机器人基础模型LDA-1B。该模型使用EI-30k数据集中的异构数据进行可扩展的动力学学习，在结构化的DINO潜在空间中避免了冗余的像素级外观建模。此外，采用多模式扩散变压器处理异步视觉和行动流，以实现大规模训练。", "result": "在模拟和真实世界的实验中，LDA-1B分别比先前的方法$π_{0.5}$在接触密集型、灵巧性和长期任务上表现更好21%，48%和23%。此外，该模型还能够通过利用低质量轨迹进行数据高效的微调。", "conclusion": "LDA-1B证明了其处理大规模异构沉浸式数据的能力，并展示了在多种机器人操作任务上的优越性能。"}}
{"id": "2602.12209", "pdf": "https://arxiv.org/pdf/2602.12209", "abs": "https://arxiv.org/abs/2602.12209", "authors": ["Alessandro Epasto", "Xin Lyu", "Pasin Manurangsi"], "title": "Keeping a Secret Requires a Good Memory: Space Lower-Bounds for Private Algorithms", "categories": ["cs.CR", "cs.CC", "cs.DS"], "comment": "comments welcome", "summary": "We study the computational cost of differential privacy in terms of memory efficiency. While the trade-off between accuracy and differential privacy is well-understood, the inherent cost of privacy regarding memory use remains largely unexplored. This paper establishes for the first time an unconditional space lower bound for user-level differential privacy by introducing a novel proof technique based on a multi-player communication game. Central to our approach, this game formally links the hardness of low-memory private algorithms to the necessity of ``contribution capping'' -- tracking and limiting the users who disproportionately impact the dataset. We demonstrate that winning this communication game requires transmitting information proportional to the number of over-active users, which translates directly to memory lower bounds. We apply this framework, as an example, to the fundamental problem of estimating the number of distinct elements in a stream and we prove that any private algorithm requires almost $\\widetildeΩ(T^{1/3})$ space to achieve certain error rates in a promise variant of the problem. This resolves an open problem in the literature (by Jain et al. NeurIPS 2023 and Cummings et al. ICML 2025) and establishes the first exponential separation between the space complexity of private algorithms and their non-private $\\widetilde{O}(1)$ counterparts for a natural statistical estimation task. Furthermore, we show that this communication-theoretic technique generalizes to broad classes of problems, yielding lower bounds for private medians, quantiles, and max-select.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.12207", "pdf": "https://arxiv.org/pdf/2602.12207", "abs": "https://arxiv.org/abs/2602.12207", "authors": ["Emma Hoes", "K. Jonathan Klueser", "Fabrizio Gilardi"], "title": "VIRENA: Virtual Arena for Research, Education, and Democratic Innovation", "categories": ["cs.HC", "cs.AI", "cs.SI"], "comment": "VIRENA is under active development and currently in use at the University of Zurich, supported by the DIZH Innovation Program: 2nd Founder-Call. This preprint will be updated as new features are released. For the latest version and to inquire about demos or pilot collaborations, contact the authors", "summary": "Digital platforms shape how people communicate, deliberate, and form opinions. Studying these dynamics has become increasingly difficult due to restricted data access, ethical constraints on real-world experiments, and limitations of existing research tools. VIRENA (Virtual Arena) is a platform that enables controlled experimentation in realistic social media environments. Multiple participants interact simultaneously in realistic replicas of feed-based platforms (Instagram, Facebook, Reddit) and messaging apps (WhatsApp, Messenger). Large language model-powered AI agents participate alongside humans with configurable personas and realistic behavior. Researchers can manipulate content moderation approaches, pre-schedule stimulus content, and run experiments across conditions through a visual interface requiring no programming skills. VIRENA makes possible research designs that were previously impractical: studying human--AI interaction in realistic social contexts, experimentally comparing moderation interventions, and observing group deliberation as it unfolds. Built on open-source technologies that ensure data remain under institutional control and comply with data protection requirements, VIRENA is currently in use at the University of Zurich and available for pilot collaborations. Designed for researchers, educators, and public organizations alike, VIRENA's no-code interface makes controlled social media simulation accessible across disciplines and sectors. This paper documents its design, architecture, and capabilities.", "AI": {"tldr": "VIRENA是一个研究和教育平台，用于在模拟的社交媒体环境中进行受控实验。", "motivation": "当前研究社交媒体互动面临数据访问受限、伦理约束及现有工具不足的问题。VIRENA旨在解决这些问题，并支持对人类与AI交互的研究以及内容管理干预的效果比较。", "method": "使用开源技术构建了一个仿真真实社交平台（如Instagram，Facebook等）的虚拟环境，允许研究人员通过可视化界面设计实验而无需编程技能。该系统还提供人工智能代理以模拟真人行为参与互动。", "result": "目前VIRENA已在苏黎世大学投入使用，并对跨学科研究和社会组织开放试点合作。它提供了以前难以实现的研究设计能力。", "conclusion": "VIRENA为研究人员、教育工作者和公共机构提供了一个无需编程技能即可进行受控社交网络模拟的平台，促进了一系列新的研究可能性。"}}
{"id": "2602.12205", "pdf": "https://arxiv.org/pdf/2602.12205", "abs": "https://arxiv.org/abs/2602.12205", "authors": ["Dianyi Wang", "Ruihang Li", "Feng Han", "Chaofan Ma", "Wei Song", "Siyuan Wang", "Yibin Wang", "Yi Xin", "Hongjian Liu", "Zhixiong Zhang", "Shengyuan Ding", "Tianhang Wang", "Zhenglin Cheng", "Tao Lin", "Cheng Jin", "Kaicheng Yu", "Jingjing Chen", "Wenjie Wang", "Zhongyu Wei", "Jiaqi Wang"], "title": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.", "AI": {"tldr": "介绍了一种轻量级的统一多模态模型DeepGen 1.0，用于图像生成和编辑。", "motivation": "当前的统一多模态模型依赖于庞大的参数规模（如>10B），这带来了高昂的训练成本和部署开销。本文旨在开发一种性能优异且轻量级的模型来降低成本并提高效率。", "method": "提出了一种深度对齐框架Stacked Channel Bridging (SCB)，该框架从多个VLM层提取分层次特征并与可学习的'思考令牌'think tokens融合，以增强生成骨干网。采用数据为中心的训练策略，包括预训练、监督微调和强化学习。", "result": "尽管仅使用了约50M样本进行训练，但DeepGen 1.0在多个基准测试中表现出色，超越了80B参数规模的HunyuanImage模型28%以及27B参数规模的Qwen-Image-Edit模型37%，证明其性能卓越。", "conclusion": "通过开源代码、权重和数据集，DeepGen 1.0为研究者提供了一种高效且高性能的替代方案，以推进统一多模态的研究。"}}
{"id": "2602.12199", "pdf": "https://arxiv.org/pdf/2602.12199", "abs": "https://arxiv.org/abs/2602.12199", "authors": ["Oliver Gross", "Florine Hartwig", "Martin Rumpf", "Peter Schröder"], "title": "Sub--Riemannian boundary value problems for Optimal Geometric Locomotion", "categories": ["cs.RO", "math.NA"], "comment": ":65K10; 53C17; 37J60; 70G45", "summary": "We propose a geometric model for optimal shape-change-induced motions of slender locomotors, e.g., snakes slithering on sand. In these scenarios, the motion of a body in world coordinates is completely determined by the sequence of shapes it assumes. Specifically, we formulate Lagrangian least-dissipation principles as boundary value problems whose solutions are given by sub-Riemannian geodesics. Notably, our geometric model accounts not only for the energy dissipated by the body's displacement through the environment, but also for the energy dissipated by the animal's metabolism or a robot's actuators to induce shape changes such as bending and stretching, thus capturing overall locomotion efficiency. Our continuous model, together with a consistent time and space discretization, enables numerical computation of sub-Riemannian geodesics for three different types of boundary conditions, i.e., fixing initial and target body, restricting to cyclic motion, or solely prescribing body displacement and orientation. The resulting optimal deformation gaits qualitatively match observed motion trajectories of organisms such as snakes and spermatozoa, as well as known optimality results for low-dimensional systems such as Purcell's swimmers. Moreover, being geometrically less rigid than previous frameworks, our model enables new insights into locomotion mechanisms of, e.g., generalized Purcell's swimmers. The code is publicly available.", "AI": {"tldr": "提出了一种几何模型来描述最优形状变化诱导的运动，特别是在蛇在沙地上滑行的情况。", "motivation": "为了更准确地描述和分析像蛇等生物或机器人的高效移动机制，考虑了通过环境位移消耗的能量以及由代谢或电机驱动的变形所消耗的能量。", "method": "通过拉格朗日最小耗散原则作为边界值问题，采用子黎曼几何来计算最优变形姿态，并进行了时间和空间的一致离散化处理。", "result": "模型计算出的结果与观察到的蛇和精子等生物的运动轨迹一致，同时为更广泛的游泳者提供了新的见解。", "conclusion": "这种几何框架比之前的模型更加灵活，可以更好地理解各种移动机制并提供数值计算的代码支持。"}}
{"id": "2602.12196", "pdf": "https://arxiv.org/pdf/2602.12196", "abs": "https://arxiv.org/abs/2602.12196", "authors": ["Mohamed Huti", "Alasdair Mackintosh", "Amy Waldock", "Dominic Andrews", "Maxime Lelièvre", "Moritz Boos", "Tobias Murray", "Paul Atherton", "Robin A. A. Ince", "Oliver G. B. Garrod"], "title": "Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual reasoning benchmark (VRB), a novel dataset designed to evaluate Multimodal Large Language Models (MLLMs) on their ability to solve authentic visual problems from classrooms. This benchmark is built on a set of 701 questions sourced from primary school examinations in Zambia and India, which cover a range of tasks such as reasoning by analogy, pattern completion, and spatial matching. We outline the methodology and development of the benchmark which intentionally uses unedited, minimal-text images to test if models can meet realistic needs of primary education. Our findings reveal a ``jagged frontier'' of capability where models demonstrate better proficiency in static skills such as counting and scaling, but reach a distinct ``spatial ceiling'' when faced with dynamic operations like folding, reflection, and rotation. These weaknesses pose a risk for classroom use on visual reasoning problems, with the potential for incorrect marking, false scaffolding, and reinforcing student misconceptions. Consequently, education-focused benchmarks like the VRB are essential for determining the functional boundaries of multimodal tools used in classrooms.", "AI": {"tldr": "介绍了一种评估多模态大型语言模型在解决小学课堂中视觉问题能力的新基准测试——VRB。", "motivation": "旨在评价AI模型处理空间和关系结构的能力，尤其是在早期数学教育中的表现。当前模型在静态技能方面表现出色，但在动态操作如折叠、反射和旋转时存在瓶颈。", "method": "基于来自赞比亚和印度小学考试的701个问题构建了一个新数据集，涵盖了类比推理、模式完成等任务，并测试了模型的实际需求能力。", "result": "发现模型在静态技能上表现较好，但在动态操作中存在天花板效应。", "conclusion": "教育导向的基准测试如VRB对于确定多模态工具的功能边界至关重要。"}}
{"id": "2602.12187", "pdf": "https://arxiv.org/pdf/2602.12187", "abs": "https://arxiv.org/abs/2602.12187", "authors": ["Sunghwan Kim", "Wooseok Jeong", "Serin Kim", "Sangam Lee", "Dongha Lee"], "title": "SAGEO Arena: A Realistic Environment for Evaluating Search-Augmented Generative Engine Optimization", "categories": ["cs.IR", "cs.AI"], "comment": "Work in Progress", "summary": "Search-Augmented Generative Engines (SAGE) have emerged as a new paradigm for information access, bridging web-scale retrieval with generative capabilities to deliver synthesized answers. This shift has fundamentally reshaped how web content gains exposure online, giving rise to Search-Augmented Generative Engine Optimization (SAGEO), the practice of optimizing web documents to improve their visibility in AI-generated responses. Despite growing interest, no evaluation environment currently supports comprehensive investigation of SAGEO. Specifically, existing benchmarks lack end-to-end visibility evaluation of optimization strategies, operating on pre-determined candidate documents that abstract away retrieval and reranking preceding generation. Moreover, existing benchmarks discard structural information (e.g., schema markup) present in real web documents, overlooking the rich signals that search systems actively leverage in practice. Motivated by these gaps, we introduce SAGEO Arena, a realistic and reproducible environment for stage-level SAGEO analysis. Our objective is to jointly target search-oriented optimization (SEO) and generation-centric optimization (GEO). To achieve this, we integrate a full generative search pipeline over a large-scale corpus of web documents with rich structural information. Our findings reveal that existing approaches remain largely impractical under realistic conditions and often degrade performance in retrieval and reranking. We also find that structural information helps mitigate these limitations, and that effective SAGEO requires tailoring optimization to each pipeline stage. Overall, our benchmark paves the way for realistic SAGEO evaluation and optimization beyond simplified settings.", "AI": {"tldr": "介绍SAGEO Arena，一种评估搜索增强生成引擎优化的现实环境。", "motivation": "现有基准缺乏对搜索引擎优化策略的端到端可见性评测，并忽略了真实网页文档中的结构信息。因此，开发了一种新的评估环境以支持全面研究和优化。", "method": "引入SAGEO Arena，结合大规模带有丰富结构信息的网络文档库与完整的生成搜索管道。", "result": "发现现有方法在现实条件下大多不实用且可能降低检索和重排序性能。使用结构信息有助于缓解这些限制，并证明了对每个阶段进行个性化优化的重要性。", "conclusion": "该基准为真实条件下的SAGEO评估和优化提供了途径，超越简化的设定。"}}
{"id": "2602.12177", "pdf": "https://arxiv.org/pdf/2602.12177", "abs": "https://arxiv.org/abs/2602.12177", "authors": ["Nils Lehmann", "Yi Wang", "Zhitong Xiong", "Xiaoxiang Zhu"], "title": "EO-VAE: Towards A Multi-sensor Tokenizer for Earth Observation Data", "categories": ["cs.CV"], "comment": null, "summary": "State-of-the-art generative image and video models rely heavily on tokenizers that compress high-dimensional inputs into more efficient latent representations. While this paradigm has revolutionized RGB generation, Earth observation (EO) data presents unique challenges due to diverse sensor specifications and variable spectral channels. We propose EO-VAE, a multi-sensor variational autoencoder designed to serve as a foundational tokenizer for the EO domain. Unlike prior approaches that train separate tokenizers for each modality, EO-VAE utilizes a single model to encode and reconstruct flexible channel combinations via dynamic hypernetworks. Our experiments on the TerraMesh dataset demonstrate that EO-VAE achieves superior reconstruction fidelity compared to the TerraMind tokenizers, establishing a robust baseline for latent generative modeling in remote sensing.", "AI": {"tldr": "本论文提出了EO-VAE，一种用于地球观测数据的多传感器变分自动编码器。", "motivation": "现有的生成模型高度依赖于将高维输入压缩成更高效的潜在表示的方法。然而，由于地球观测数据具有多样化的传感规格和可变的光谱通道，这种方法面临独特挑战。", "method": "EO-VAE利用动态超网络在单一模型中编码并重建灵活的信道组合，以适应不同模态的数据。", "result": "实验显示，与TerraMind令牌化器相比，EO-VAE具有更高的重构保真度。", "conclusion": "EO-VAE为遥感数据中的潜在生成建模提供了一个坚实的基线。"}}
{"id": "2602.12175", "pdf": "https://arxiv.org/pdf/2602.12175", "abs": "https://arxiv.org/abs/2602.12175", "authors": ["David Shmoys", "Varun Suriyanarayana", "Seeun William Umboh"], "title": "Improved Online Algorithms for Inventory Management Problems with Holding and Delay Costs: Riding the Wave Makes Things Simpler, Stronger, & More General", "categories": ["cs.DS"], "comment": "19 pages, 1 figure, appeared at SODA 2026", "summary": "The Joint Replenishment Problem (JRP) is a classical inventory management problem, that aims to model the trade-off between coordinating orders for multiple commodities (and their cost) with holding costs incurred by meeting demand in advance. Moseley, Niaparast and Ravi introduced a natural online generalization of the JRP in which inventory corresponding to demands may be replenished late, for a delay cost, or early, for a holding cost. They established that when the holding and delay costs are monotone and uniform across demands, there is a 30-competitive algorithm that employs a greedy strategy and a dual-fitting based analysis. We develop a 5-competitive algorithm that handles arbitrary monotone demand-specific holding and delay cost functions, thus simultaneously improving upon the competitive ratio and relaxing the uniformity assumption. Our primal-dual algorithm is in the spirit of the work Buchbinder, Kimbrel, Levi, Makarychev, and Sviridenko, which maintains a wavefront dual solution to decide when to place an order and which items to order. The main twist is in deciding which requests to serve early. In contrast to the work of Moseley et al., which ranks early requests in ascending order of desired service time and serves them until their total holding cost matches the ordering cost incurred for that item, we extend to the non-uniform case by instead ranking in ascending order of when the delay cost of a demand would reach its current holding cost. An important special case of the JRP is the single-item lot-sizing problem. Here, Moseley et al. gave a 3-competitive algorithm when the holding and delay costs are uniform across demands. We provide a new algorithm for which the competitive ratio is $φ+1 \\approx 2.681$, where $φ$ is the golden ratio, which again holds for arbitrary monotone holding-delay costs.", "AI": {"tldr": "本文提出了改进的在线算法，用于解决带有持有和延迟成本的库存管理问题。", "motivation": "针对现有的联合补给问题（JRP）模型，在保持需求提前满足的持有成本与按需补充的成本之间权衡的基础上，引入了非均匀的需求特定持有和延迟成本函数，并尝试开发出一种更优的竞争算法。", "method": "基于原始对偶算法的思想，通过维护波前对偶解决方案来决定订单的时间及内容。对于早期服务请求的选择，本文采用了一种新的排名策略：按需求延迟成本达到当前持有成本的顺序排列。", "result": "开发出一种5-竞争比的算法，该算法处理任意单调的需求特定持有和延迟成本函数，改进了竞争比率并放松了统一性假设。在单项批次大小问题中，给出了一个竞争比为φ+1≈2.681的新算法（φ为黄金比例）。", "conclusion": "本文提出的在线算法不仅提高了JRP的竞争率，并且扩展到了非均匀成本情况下的更广泛的应用场景。"}}
{"id": "2602.12173", "pdf": "https://arxiv.org/pdf/2602.12173", "abs": "https://arxiv.org/abs/2602.12173", "authors": ["Chengxi Zeng", "Yuxuan Jiang", "Ge Gao", "Shuai Wang", "Duolikun Danier", "Bin Zhu", "Stevan Rudinac", "David Bull", "Fan Zhang"], "title": "SAM3-LiteText: An Anatomical Study of the SAM3 Text Encoder for Efficient Vision-Language Segmentation", "categories": ["cs.AI"], "comment": null, "summary": "Vision-language segmentation models such as SAM3 enable flexible, prompt-driven visual grounding, but inherit large, general-purpose text encoders originally designed for open-ended language understanding. In practice, segmentation prompts are short, structured, and semantically constrained, leading to substantial over-provisioning in text encoder capacity and persistent computational and memory overhead. In this paper, we perform a large-scale anatomical analysis of text prompting in vision-language segmentation, covering 404,796 real prompts across multiple benchmarks. Our analysis reveals severe redundancy: most context windows are underutilized, vocabulary usage is highly sparse, and text embeddings lie on low-dimensional manifold despite high-dimensional representations. Motivated by these findings, we propose SAM3-LiteText, a lightweight text encoding framework that replaces the original SAM3 text encoder with a compact MobileCLIP student that is optimized by knowledge distillation. Extensive experiments on image and video segmentation benchmarks show that SAM3-LiteText reduces text encoder parameters by up to 88%, substantially reducing static memory footprint, while maintaining segmentation performance comparable to the original model. Code: https://github.com/SimonZeng7108/efficientsam3/tree/sam3_litetext.", "AI": {"tldr": "本文对SAM3文本编码器在视觉语言分割中的冗余进行了大规模解剖学分析，并提出了一个轻量级的文本编码框架SAM3-LiteText，以减少计算和内存开销。", "motivation": "实践中，分割提示短且结构化，导致原始文本编码器容量过剩。本文通过解剖学分析发现这些模型存在严重冗余：上下文窗口利用率低，词汇使用稀疏，尽管表示高维但嵌入在低维流形上。因此提出优化。", "method": "基于知识蒸馏训练一个紧凑的MobileCLIP学生来替换原始文本编码器。", "result": "实验表明，SAM3-LiteText将文本编码器参数减少至多88%，减少了静态内存占用，同时保持了与原模型相当的分割性能。", "conclusion": "本文通过大规模解剖学分析揭示了视觉语言分割任务中使用大型通用文本编码器的不足，并提出了一种高效的替代方法。"}}
{"id": "2602.12172", "pdf": "https://arxiv.org/pdf/2602.12172", "abs": "https://arxiv.org/abs/2602.12172", "authors": ["Bowei He", "Yankai Chen", "Xiaokun Zhang", "Linghe Kong", "Philip S. Yu", "Xue Liu", "Chen Ma"], "title": "Pedagogically-Inspired Data Synthesis for Language Model Knowledge Distillation", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted by ICLR 2026", "summary": "Knowledge distillation from Large Language Models (LLMs) to smaller models has emerged as a critical technique for deploying efficient AI systems. However, current methods for distillation via synthetic data lack pedagogical awareness, treating knowledge transfer as a one-off data synthesis and training task rather than a systematic learning process. In this paper, we propose a novel pedagogically-inspired framework for LLM knowledge distillation that draws from fundamental educational principles. Our approach introduces a three-stage pipeline -- Knowledge Identifier, Organizer, and Adapter (IOA) -- that systematically identifies knowledge deficiencies in student models, organizes knowledge delivery through progressive curricula, and adapts representations to match the cognitive capacity of student models. We integrate Bloom's Mastery Learning Principles and Vygotsky's Zone of Proximal Development to create a dynamic distillation process where student models approach teacher model's performance on prerequisite knowledge before advancing, and new knowledge is introduced with controlled, gradual difficulty increments. Extensive experiments using LLaMA-3.1/3.2 and Qwen2.5 as student models demonstrate that IOA achieves significant improvements over baseline distillation methods, with student models retaining 94.7% of teacher performance on DollyEval while using less than 1/10th of the parameters. Our framework particularly excels in complex reasoning tasks, showing 19.2% improvement on MATH and 22.3% on HumanEval compared with state-of-the-art baselines.", "AI": {"tldr": "本文提出了一种基于教育原理的大型语言模型知识蒸馏框架，通过系统化的学习过程提高学生模型的表现。", "motivation": "当前的知识蒸馏方法缺乏教育指导意识，将其视为一次性数据生成和训练任务，而非系统化学习过程。本文旨在解决这一问题，引入一种新型的教学启发式框架。", "method": "提出了一种三阶段知识蒸馏管道（知识识别、组织者与适配器），通过借鉴布卢姆掌握学习原理和维果斯基最近发展区理论，实现对学生模型的系统化知识传递及性能提升。", "result": "实验结果表明，所提方法在复杂推理任务上表现出色，如MATH任务提高了19.2%，HumanEval任务提高了22.3%。", "conclusion": "该框架通过引入教育原理显著改善了学生模型的知识蒸馏效果，在保证性能的同时减少了参数量。"}}
{"id": "2602.12170", "pdf": "https://arxiv.org/pdf/2602.12170", "abs": "https://arxiv.org/abs/2602.12170", "authors": ["Greg Coppola"], "title": "Statistical Parsing for Logical Information Retrieval", "categories": ["cs.AI"], "comment": "23 pages, 6 tables", "summary": "In previous work (Coppola, 2024) we introduced the Quantified Boolean Bayesian Network (QBBN), a logical graphical model that implements the forward fragment of natural deduction (Prawitz, 1965) as a probabilistic factor graph. That work left two gaps: no negation/backward reasoning, and no parser for natural language. This paper addresses both gaps across inference, semantics, and syntax. For inference, we extend the QBBN with NEG factors enforcing P(x) + P(neg x) = 1, enabling contrapositive reasoning (modus tollens) via backward lambda messages, completing Prawitz's simple elimination rules. The engine handles 44/44 test cases spanning 22 reasoning patterns. For semantics, we present a typed logical language with role-labeled predicates, modal quantifiers, and three tiers of expressiveness following Prawitz: first-order quantification, propositions as arguments, and predicate quantification via lambda abstraction. For syntax, we present a typed slot grammar that deterministically compiles sentences to logical form (33/33 correct, zero ambiguity). LLMs handle disambiguation (95% PP attachment accuracy) but cannot produce structured parses directly (12.4% UAS), confirming grammars are necessary. The architecture: LLM preprocesses, grammar parses, LLM reranks, QBBN infers. We argue this reconciles formal semantics with Sutton's \"bitter lesson\" (2019): LLMs eliminate the annotation bottleneck that killed formal NLP, serving as annotator while the QBBN serves as verifier. Code: https://github.com/gregorycoppola/world", "AI": {"tldr": "本文介绍了扩展的量化布尔贝叶斯网络（QBBN）和一种类型化的槽语法，用于逻辑信息检索。", "motivation": "填补了先前工作中没有否定和反向推理以及缺乏自然语言解析器的空白。", "method": "通过引入NEG因素来完成Prawitz的简单消除规则，并提出了一种类型化的逻辑语言和确定性编译句子到逻辑形式的语法，同时利用LLM进行预处理、解码和重排序，QBBN进行推理。", "result": "扩展后的QBBN能够处理44/44测试案例；语法实现了33/33正确的无歧义编译；LLMs在附带关系上表现出95%的准确率，在句法分析上表现较差（12.4% UAS）。", "conclusion": "论文表明，通过结合正式语义和机器学习方法，可以有效地进行逻辑信息检索，并解决了形式化自然语言处理中的注释瓶颈问题。"}}
{"id": "2602.12164", "pdf": "https://arxiv.org/pdf/2602.12164", "abs": "https://arxiv.org/abs/2602.12164", "authors": ["Xiaohan He", "Shiyang Feng", "Songtao Huang", "Lei Bai", "Bin Wang", "Bo Zhang"], "title": "Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have demonstrated exceptional reasoning capabilities, and co-evolving paradigms have shown promising results in domains such as code and math. However, in scientific reasoning tasks, these models remain fragile due to unreliable solution evaluation and limited diversity in verification strategies. In this work, we propose Sci-CoE, a two-stage scientific co-evolving framework that enables models to self-evolve as both solver and verifier through a transition from sparse supervision to unsupervised learning. In the first stage, the model uses a small set of annotated data to establish fundamental correctness judgment anchors for the Verifier. In the second stage, we introduce a geometric reward mechanism that jointly considers consensus, reliability, and diversity, driving large-scale self-iteration on unlabeled data. Experiments on several general scientific benchmarks demonstrate that Sci-CoE enhances complex reasoning capabilities and exhibits strong scalability, facilitating the construction of more robust and diverse evaluation systems. Codes are available at https://github.com/InternScience/Sci-CoE.", "AI": {"tldr": "提出了一种用于科学推理任务的双阶段框架Sci-CoE，使模型在自我进化过程中同时扮演解算器和验证者的角色。", "motivation": "现有的大型语言模型在科学推理任务中表现出脆弱性，原因是解决方案评估不可靠且验证策略多样性不足。为解决这一问题，提出了一个两阶段协同演进框架，以增强复杂推理能力并构建更稳健的评价系统。", "method": "第一阶段使用少量标注数据建立基础正确性判断锚点；第二阶段引入几何奖励机制，考虑共识、可靠性和多样性，在未标记的数据上进行大规模自我迭代。", "result": "实验结果表明，Sci-CoE显著提升了复杂推理能力，并表现出强可扩展性。", "conclusion": "通过结合自监督和无监督学习技术，提出的方法能够构建更稳健且多样化的科学推理系统。"}}
{"id": "2602.12160", "pdf": "https://arxiv.org/pdf/2602.12160", "abs": "https://arxiv.org/abs/2602.12160", "authors": ["Xu Guo", "Fulong Ye", "Qichao Sun", "Liyang Chen", "Bingchuan Li", "Pengze Zhang", "Jiawei Liu", "Songtao Zhao", "Qian He", "Xiangwang Hou"], "title": "DreamID-Omni: Unified Framework for Controllable Human-Centric Audio-Video Generation", "categories": ["cs.CV"], "comment": "Project: https://guoxu1233.github.io/DreamID-Omni/", "summary": "Recent advancements in foundation models have revolutionized joint audio-video generation. However, existing approaches typically treat human-centric tasks including reference-based audio-video generation (R2AV), video editing (RV2AV) and audio-driven video animation (RA2V) as isolated objectives. Furthermore, achieving precise, disentangled control over multiple character identities and voice timbres within a single framework remains an open challenge. In this paper, we propose DreamID-Omni, a unified framework for controllable human-centric audio-video generation. Specifically, we design a Symmetric Conditional Diffusion Transformer that integrates heterogeneous conditioning signals via a symmetric conditional injection scheme. To resolve the pervasive identity-timbre binding failures and speaker confusion in multi-person scenarios, we introduce a Dual-Level Disentanglement strategy: Synchronized RoPE at the signal level to ensure rigid attention-space binding, and Structured Captions at the semantic level to establish explicit attribute-subject mappings. Furthermore, we devise a Multi-Task Progressive Training scheme that leverages weakly-constrained generative priors to regularize strongly-constrained tasks, preventing overfitting and harmonizing disparate objectives. Extensive experiments demonstrate that DreamID-Omni achieves comprehensive state-of-the-art performance across video, audio, and audio-visual consistency, even outperforming leading proprietary commercial models. We will release our code to bridge the gap between academic research and commercial-grade applications.", "AI": {"tldr": "DreamID-Omni是一个统一框架，用于可控的人类中心音频视频生成。", "motivation": "现有的方法通常将参考基于的音视频生成、视频编辑和声音驱动的视频动画视为孤立的目标，并且在单一框架中实现对多个身份和声音特质的精准解耦控制仍然是一个开放性挑战。", "method": "设计了一种对称条件扩散变压器，通过对称条件注入方案集成异构条件信号；引入双级解耦策略解决多个人场景中的身份-声调绑定失败和说话者混淆问题，并提出多任务渐进式训练计划以防止过拟合并协调不同目标。", "result": "实验表明DreamID-Omni在视频、音频以及音视频一致性方面实现了跨领域的SOTA性能，甚至超越了领先的商业模型。", "conclusion": "DreamID-Omni提供了一种解决人类中心音频视频生成挑战的新方法，并将开源代码以弥合学术研究与商业应用之间的差距。"}}
{"id": "2602.12159", "pdf": "https://arxiv.org/pdf/2602.12159", "abs": "https://arxiv.org/abs/2602.12159", "authors": ["Wancai Zheng", "Hao Chen", "Xianlong Lu", "Linlin Ou", "Xinyi Yu"], "title": "3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Object navigation is a core capability of embodied intelligence, enabling an agent to locate target objects in unknown environments. Recent advances in vision-language models (VLMs) have facilitated zero-shot object navigation (ZSON). However, existing methods often rely on scene abstractions that convert environments into semantic maps or textual representations, causing high-level decision making to be constrained by the accuracy of low-level perception. In this work, we present 3DGSNav, a novel ZSON framework that embeds 3D Gaussian Splatting (3DGS) as persistent memory for VLMs to enhance spatial reasoning. Through active perception, 3DGSNav incrementally constructs a 3DGS representation of the environment, enabling trajectory-guided free-viewpoint rendering of frontier-aware first-person views. Moreover, we design structured visual prompts and integrate them with Chain-of-Thought (CoT) prompting to further improve VLM reasoning. During navigation, a real-time object detector filters potential targets, while VLM-driven active viewpoint switching performs target re-verification, ensuring efficient and reliable recognition. Extensive evaluations across multiple benchmarks and real-world experiments on a quadruped robot demonstrate that our method achieves robust and competitive performance against state-of-the-art approaches.The Project Page:https://aczheng-cai.github.io/3dgsnav.github.io/", "AI": {"tldr": "本论文提出了一种新的零样本对象导航框架3DGSNav，该框架利用3D高斯点云表示和视觉语言模型相结合的方法来提高空间推理能力。", "motivation": "现有的方法依赖于场景抽象将环境转换为语义地图或文本表示，这限制了高层次决策的准确性。因此，本研究旨在通过引入更准确的空间表示和增强视觉语言模型的能力来解决这一问题。", "method": "该框架使用3D高斯点云作为持久记忆，并结合链式思考（CoT）提示以提高空间推理能力。通过主动感知逐步构建环境的3DGS表示，实现轨迹引导下的自由视图渲染，并采用实时目标检测器和视觉语言模型驱动的视角切换来验证目标。", "result": "在多个基准测试中以及真实世界实验中显示该方法达到了稳健且具有竞争力的表现，优于现有最先进的技术。", "conclusion": "3DGSNav通过结合更精确的空间表示和增强的视觉语言模型推理能力，在零样本对象导航任务上实现了显著的进步。"}}
{"id": "2602.12157", "pdf": "https://arxiv.org/pdf/2602.12157", "abs": "https://arxiv.org/abs/2602.12157", "authors": ["Ziteng Lu", "Yushuang Wu", "Chongjie Ye", "Yuda Qiu", "Jing Shao", "Xiaoyang Guo", "Jiaqing Zhou", "Tianlei Hu", "Kun Zhou", "Xiaoguang Han"], "title": "TexSpot: 3D Texture Enhancement with Spatially-uniform Point Latent Representation", "categories": ["cs.CV", "cs.GR"], "comment": "Project page: https://anonymous.4open.science/w/TexSpot-page-2D91", "summary": "High-quality 3D texture generation remains a fundamental challenge due to the view-inconsistency inherent in current mainstream multi-view diffusion pipelines. Existing representations either rely on UV maps, which suffer from distortion during unwrapping, or point-based methods, which tightly couple texture fidelity to geometric density that limits high-resolution texture generation. To address these limitations, we introduce TexSpot, a diffusion-based texture enhancement framework. At its core is Texlet, a novel 3D texture representation that merges the geometric expressiveness of point-based 3D textures with the compactness of UV-based representation. Each Texlet latent vector encodes a local texture patch via a 2D encoder and is further aggregated using a 3D encoder to incorporate global shape context. A cascaded 3D-to-2D decoder reconstructs high-quality texture patches, enabling the Texlet space learning. Leveraging this representation, we train a diffusion transformer conditioned on Texlets to refine and enhance textures produced by multi-view diffusion methods. Extensive experiments demonstrate that TexSpot significantly improves visual fidelity, geometric consistency, and robustness over existing state-of-the-art 3D texture generation and enhancement approaches. Project page: https://anonymous.4open.science/w/TexSpot-page-2D91.", "AI": {"tldr": "TexSpot是一个基于扩散的纹理增强框架，通过新型3D纹理表示Texlet合并点基和UV基的优点来改善3D纹理生成的质量。", "motivation": "当前主流多视角扩散管线在3D纹理生成中存在视图不一致的问题。现有的方法依赖于容易产生扭曲的UV映射或受到几何密度限制的点基方法，无法生成高分辨率纹理。", "method": "Texlet是一种新的3D纹理表示方式，通过2D编码器编码局部纹理块并通过3D编码器融合全局形状上下文。使用级联3D到2D解码器重构高质量纹理块，并利用这个表示训练条件于Texlets上的扩散变换器来细化和增强多视角扩散方法生成的纹理。", "result": "实验表明，与现有最先进的3D纹理生成和增强方法相比，TexSpot在视觉保真度、几何一致性以及鲁棒性上有了显著提高。", "conclusion": "TexSpot通过结合点基和UV基表示的优点，解决了传统方法中的限制问题，并且验证了这种方法的有效性和优越性。"}}
{"id": "2602.12155", "pdf": "https://arxiv.org/pdf/2602.12155", "abs": "https://arxiv.org/abs/2602.12155", "authors": ["Yeyao Ma", "Chen Li", "Xiaosong Zhang", "Han Hu", "Weidi Xie"], "title": "FAIL: Flow Matching Adversarial Imitation Learning for Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "Post-training of flow matching models-aligning the output distribution with a high-quality target-is mathematically equivalent to imitation learning. While Supervised Fine-Tuning mimics expert demonstrations effectively, it cannot correct policy drift in unseen states. Preference optimization methods address this but require costly preference pairs or reward modeling. We propose Flow Matching Adversarial Imitation Learning (FAIL), which minimizes policy-expert divergence through adversarial training without explicit rewards or pairwise comparisons. We derive two algorithms: FAIL-PD exploits differentiable ODE solvers for low-variance pathwise gradients, while FAIL-PG provides a black-box alternative for discrete or computationally constrained settings. Fine-tuning FLUX with only 13,000 demonstrations from Nano Banana pro, FAIL achieves competitive performance on prompt following and aesthetic benchmarks. Furthermore, the framework generalizes effectively to discrete image and video generation, and functions as a robust regularizer to mitigate reward hacking in reward-based optimization. Code and data are available at https://github.com/HansPolo113/FAIL.", "AI": {"tldr": "该论文提出了FAIL，一种通过对抗训练最小化策略与专家差异的图像生成方法。", "motivation": "传统的监督微调虽然能模仿专家演示，但在未见过的状态中无法纠正策略漂移。偏好优化法虽解决了这一问题但需要昂贵的偏好对或奖励建模。", "method": "FAIL通过对抗训练最小化策略与专家差异而无需显式奖励或成对比方法。它包含两个算法：FAIL-PD利用可微分ODE求解器以获得低方差路径梯度，而FAIL-PG则适用于离散图像生成和计算受限场景。", "result": "在Nano Banana pro中仅用13,000个演示进行微调后，FAIL在提示跟随及美学基准上的表现与FLUX相当。该框架能有效推广至离散图像、视频生成，并作为稳健正则化项以减轻基于奖励优化中的奖励操控问题。", "conclusion": "FAIL通过对抗训练解决了策略漂移和未见过状态的问题，展示了其在图像生成中的有效性及通用性。"}}
{"id": "2602.12153", "pdf": "https://arxiv.org/pdf/2602.12153", "abs": "https://arxiv.org/abs/2602.12153", "authors": ["Sicheng Feng", "Zigeng Chen", "Xinyin Ma", "Gongfan Fang", "Xinchao Wang"], "title": "dVoting: Fast Voting for dLLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Diffusion Large Language Models (dLLMs) represent a new paradigm beyond autoregressive modeling, offering competitive performance while naturally enabling a flexible decoding process. Specifically, dLLMs can generate tokens at arbitrary positions in parallel, endowing them with significant potential for parallel test-time scaling, which was previously constrained by severe inefficiency in autoregressive modeling. In this work, we introduce dVoting, a fast voting technique that boosts reasoning capability without training, with only an acceptable extra computational overhead. dVoting is motivated by the observation that, across multiple samples for the same prompt, token predictions remain largely consistent, whereas performance is determined by a small subset of tokens exhibiting cross-sample variability. Leveraging the arbitrary-position generation capability of dLLMs, dVoting performs iterative refinement by sampling, identifying uncertain tokens via consistency analysis, regenerating them through voting, and repeating this process until convergence. Extensive evaluations demonstrate that dVoting consistently improves performance across various benchmarks. It achieves gains of 6.22%-7.66% on GSM8K, 4.40%-7.20% on MATH500, 3.16%-14.84% on ARC-C, and 4.83%-5.74% on MMLU. Our code is available at https://github.com/fscdc/dVoting", "AI": {"tldr": "dVoting是一种用于扩散大型语言模型（dLLMs）的快速投票技术，能够在无需重新训练的情况下提高推理能力。", "motivation": "该研究观察到，在相同的提示下生成多个样本时，某些令牌在各个样本之间表现出较大的变化性，这些变化性是影响性能的关键因素。因此，提出了一种利用扩散大型语言模型任意位置生成的能力来提升推理质量的方法。", "method": "dVoting通过迭代采样、一致性分析识别不确定的令牌，并对其进行投票再生，以提高预测的一致性和准确性。重复此过程直到收敛。", "result": "实验表明，在多个基准测试中，dVoting可以显著提高性能，特别是在GSM8K、MATH500、ARC-C和MMLU等任务上取得了6.22%-14.84%的提升。", "conclusion": "dVoting在无需额外训练的情况下有效地提高了扩散大型语言模型的推理能力，并且具有较低的计算开销。"}}
{"id": "2602.12150", "pdf": "https://arxiv.org/pdf/2602.12150", "abs": "https://arxiv.org/abs/2602.12150", "authors": ["John Muchovej", "Amanda Royka", "Shane Lee", "Julian Jara-Ettinger"], "title": "GPT-4o Lacks Core Features of Theory of Mind", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Submitted to CogSci 2025; see more at https://jmuchovej.com/projects/llm-tom. Note: \"abstractness\" is the second feature we test for, but due to arXiv's abstract requirements, the text has been altered", "summary": "Do Large Language Models (LLMs) possess a Theory of Mind (ToM)? Research into this question has focused on evaluating LLMs against benchmarks and found success across a range of social tasks. However, these evaluations do not test for the actual representations posited by ToM: namely, a causal model of mental states and behavior. Here, we use a cognitively-grounded definition of ToM to develop and test a new evaluation framework. Specifically, our approach probes whether LLMs have a coherent, domain-general, and consistent model of how mental states cause behavior -- regardless of whether that model matches a human-like ToM. We find that even though LLMs succeed in approximating human judgments in a simple ToM paradigm, they fail at a logically equivalent task and exhibit low consistency between their action predictions and corresponding mental state inferences. As such, these findings suggest that the social proficiency exhibited by LLMs is not the result of an domain-general or consistent ToM.", "AI": {"tldr": "该论文通过开发新的评估框架，研究大型语言模型是否具有理论心智。", "motivation": "现有研究主要集中在评价LLM在社交任务上的表现，但未测试它们是否具备理论心智的核心代表：即心理状态和行为之间的因果模型。因此，作者旨在使用认知基础定义的ToM来开发新的评估框架。", "method": "该论文提出了一种基于认知的定义来构建新型评估体系，具体来说，他们探索了LLMs在逻辑上等价的任务中的表现，并观察其行动预测与心理状态推断之间的连贯性。", "result": "研究表明尽管LLM在简单的ToM范式中成功地接近人类判断，但在逻辑上等效的任务中却失败了，并且它们的行为预测和相应的心理状态推断之间表现出低一致性。", "conclusion": "这些发现表明LLMs展现的社交能力不是由于一种普遍一致的心理模型的结果。"}}
{"id": "2602.12146", "pdf": "https://arxiv.org/pdf/2602.12146", "abs": "https://arxiv.org/abs/2602.12146", "authors": ["Mahdi Khodabandeh", "Ghazal Shabani", "Arash Yousefi Jordehi", "Seyed Abolghasem Mirroshandel"], "title": "Seq2Seq2Seq: Lossless Data Compression via Discrete Latent Transformers and Reinforcement Learning", "categories": ["cs.AI", "cs.CL", "cs.IT"], "comment": null, "summary": "Efficient lossless compression is essential for minimizing storage costs and transmission overhead while preserving data integrity. Traditional compression techniques, such as dictionary-based and statistical methods, often struggle to optimally exploit the structure and redundancy in complex data formats. Recent advancements in deep learning have opened new avenues for compression; however, many existing approaches depend on dense vector representations that obscure the underlying token structure. To address these limitations, we propose a novel lossless compression method that leverages Reinforcement Learning applied to a T5 language model architecture. This approach enables the compression of data into sequences of tokens rather than traditional vector representations. Unlike auto-encoders, which typically encode information into continuous latent spaces, our method preserves the token-based structure, aligning more closely with the original data format. This preservation allows for higher compression ratios while maintaining semantic integrity. By training the model using an off-policy Reinforcement Learning algorithm, we optimize sequence length to minimize redundancy and enhance compression efficiency. Our method introduces an efficient and adaptive data compression system built upon advanced Reinforcement Learning techniques, functioning independently of external grammatical or world knowledge. This approach shows significant improvements in compression ratios compared to conventional methods. By leveraging the latent information within language models, our system effectively compresses data without requiring explicit content understanding, paving the way for more robust and practical compression solutions across various applications.", "AI": {"tldr": "通过离散潜在变换器和强化学习提出了一种无损数据压缩方法，能够高效地利用语言模型中的潜在信息进行序列化压缩。", "motivation": "传统压缩技术难以充分利用复杂格式的数据结构和冗余。此研究旨在开发一种保持原始数据令牌结构的同时实现更高压缩比的方法，以减少存储成本并提高传输效率。", "method": "采用T5语言模型架构，并通过强化学习训练模型优化序列长度，从而最小化冗余，增强压缩效率。", "result": "相比传统方法，该方法在压缩比率上表现出显著改进。", "conclusion": "此研究提出了一种基于先进强化学习技术的高效自适应数据压缩系统，在不依赖外部语法或世界知识的情况下实现了无损且高效的压缩效果。"}}
{"id": "2602.12144", "pdf": "https://arxiv.org/pdf/2602.12144", "abs": "https://arxiv.org/abs/2602.12144", "authors": ["Muhammad Ahmad Khan", "Hasnain Ali", "Muneeb Rana", "Muhammad Saqib Ilyas", "Abdul Ali Bangash"], "title": "On the Adoption of AI Coding Agents in Open-source Android and iOS Development", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted at MSR 2026 Mining Challenge track", "summary": "AI coding agents are increasingly contributing to software development, yet their impact on mobile development has received little empirical attention. In this paper, we present the first category-level empirical study of agent-generated code in open-source mobile app projects. We analyzed PR acceptance behaviors across mobile platforms, agents, and task categories using 2,901 AI-authored pull requests (PRs) in 193 verified Android and iOS open-source GitHub repositories in the AIDev dataset. We find that Android projects have received 2x more AI-authored PRs and have achieved higher PR acceptance rate (71%) than iOS (63%), with significant agent-level variation on Android. Across task categories, PRs with routine tasks (feature, fix, and ui) achieve the highest acceptance, while structural changes like refactor and build achieve lower success and longer resolution times. Furthermore, our evolution analysis shows improvement in PR resolution time on Android through mid-2025 before it declined again. Our findings offer the first evidence-based characterization of AI agents effects on OSS mobile projects and establish empirical baselines for evaluating agent-generated contributions to design platform aware agentic systems.", "AI": {"tldr": "研究分析了AI编码代理在开源移动应用程序项目中的使用情况，特别是在Android和iOS平台上的代码贡献。", "motivation": "探讨人工智能编码代理对软件开发的影响，并通过实证研究填补有关其在移动开发领域应用的空白。", "method": "利用包含2,901个由AI生成的拉取请求（PR）的数据集，分析了开源Android和iOS项目中PR接受行为的变化趋势及不同类别的任务效果。", "result": "发现Android项目的PR接收率高于iOS，并且具有更高的成功率；常规任务类型的PR（如功能添加、修复和UI改进等）比结构重构等任务更容易被采纳和快速解决。", "conclusion": "提供关于AI代理在开源移动项目中的影响的第一手实证证据，为设计平台意识型的代理系统建立了经验基准。"}}
{"id": "2602.12143", "pdf": "https://arxiv.org/pdf/2602.12143", "abs": "https://arxiv.org/abs/2602.12143", "authors": ["Xiaoxiao Wang", "Chunxiao Li", "Junying Wang", "Yijin Guo", "Zijian Chen", "Chunyi Li", "Xiaohong Liu", "Zicheng Zhang", "Guangtao Zhai"], "title": "STAR : Bridging Statistical and Agentic Reasoning for Large Model Performance Prediction", "categories": ["cs.AI", "cs.LG"], "comment": "10 pages, 8 figures, 17 tables. Code available at https://github.com/xiaoxiaostudy/star", "summary": "As comprehensive large model evaluation becomes prohibitively expensive, predicting model performance from limited observations has become essential. However, existing statistical methods struggle with pattern shifts, data sparsity, and lack of explanation, while pure LLM methods remain unreliable. We propose STAR, a framework that bridges data-driven STatistical expectations with knowledge-driven Agentic Reasoning. STAR leverages specialized retrievers to gather external knowledge and embeds semantic features into Constrained Probabilistic Matrix Factorization (CPMF) to generate statistical expectations with uncertainty. A reasoning module guided by Expectation Violation Theory (EVT) then refines predictions through intra-family analysis, cross-model comparison, and credibility-aware aggregation, producing adjustments with traceable explanations. Extensive experiments show that STAR consistently outperforms all baselines on both score-based and rank-based metrics, delivering a 14.46% gain in total score over the strongest statistical method under extreme sparsity, with only 1--2 observed scores per test model.", "AI": {"tldr": "STAR是一个预测大型模型性能的框架，结合了统计方法和代理推理。", "motivation": "当前大型模型评估成本过高，现有统计方法在模式偏移、数据稀疏性和缺乏解释性方面存在问题，纯LLM方法也不够可靠。因此，提出一种新的框架来解决这些问题。", "method": "STAR通过使用专门的检索器收集外部知识，并将语义特征嵌入到受限概率矩阵分解中生成带有不确定性的统计期望。然后，利用期望违反理论指导推理模块进行预测调整和可追溯解释。", "result": "实验表明，在极端稀疏条件下，STAR在基于分数和排名的度量上都超过了所有基准方法，总分比最强的统计方法高出14.46%，仅用每个测试模型一到两个观察值。", "conclusion": "STAR框架通过结合统计期望与代理推理，提供了更准确、可解释性的性能预测，在各种实验中表现优异。"}}
{"id": "2602.12136", "pdf": "https://arxiv.org/pdf/2602.12136", "abs": "https://arxiv.org/abs/2602.12136", "authors": ["Kaisa Vaananen", "Niels van Berkel", "Donald McMillan", "Thomas Olsson"], "title": "Embodied AI Agents for Team Collaboration in Co-located Blue-Collar Work", "categories": ["cs.HC"], "comment": "4 pages, 1 figure, a short synopsis of this paper has been submitted to CHI 2026 workshop on Embodying Relationships, Designing TUIs for Co-Located Human-Human Dynamics", "summary": "Blue-collar work is often highly collaborative, embodied, and situated in shared physical environments, yet most research on collaborative AI has focused on white-collar work. This position paper explores how the embodied nature of AI agents can support team collaboration and communication in co-located blue-collar workplaces. From the context of our newly started CAI-BLUE research project, we present two speculative scenarios from industrial and maintenance contexts that illustrate how embodied AI agents can support shared situational awareness and facilitate inclusive communication across experience levels. We outline open questions related to embodied AI agent design around worker inclusion, agency, transformation of blue-collar collaboration practices over time, and forms of acceptable AI embodiments. We argue that embodiment is not just an aesthetic choice but should become a socio-material design strategy of AI systems in blue-collar workplaces.", "AI": {"tldr": "本文探讨了实体AI代理在同地蓝领工作中支持团队协作和沟通的潜力。", "motivation": "大多数关于合作AI的研究集中在白领工作上，忽略了蓝领工作的高度协作性和实体性。本文旨在通过两个假设场景来探索实体AI如何改善共享情况感知及跨经验水平的包容性沟通。", "method": "提出了两个与工业和维护相关的假设情景，并讨论了相关的设计问题，如工人参与度、合作实践的变化等。", "result": "展示了实体AI在促进团队协作方面的可能性，提出了一些设计策略和开放性问题。", "conclusion": "实体AI不应仅仅是一种美学选择，而是应该成为蓝领工作场所中的一个社会物质设计策略。"}}
{"id": "2602.12134", "pdf": "https://arxiv.org/pdf/2602.12134", "abs": "https://arxiv.org/abs/2602.12134", "authors": ["Jiajun Chen", "Hua Shen"], "title": "Value Alignment Tax: Measuring Value Trade-offs in LLM Alignment", "categories": ["cs.AI", "cs.HC"], "comment": "Preprint. Under review. 20 pages, 13 figures", "summary": "Existing work on value alignment typically characterizes value relations statically, ignoring how interventions - such as prompting, fine-tuning, or preference optimization - reshape the broader value system. We introduce the Value Alignment Tax (VAT), a framework that measures how alignment-induced changes propagate across interconnected values relative to achieved on-target gain. VAT captures the dynamics of value expression under alignment pressure. Using a controlled scenario-action dataset grounded in Schwartz value theory, we collect paired pre-post normative judgments and analyze alignment effects across models, values, and alignment strategies. Our results show that alignment often produces uneven, structured co-movement among values. These effects are invisible under conventional target-only evaluation, revealing systemic, process-level alignment risks and offering new insights into the dynamics of value alignment in LLMs.", "AI": {"tldr": "本文提出了价值对齐税（VAT）框架，用于量化在大语言模型中因对齐操作导致的价值系统变化。", "motivation": "现有研究通常静态地表征价值观关系，并忽视了干预措施如何改变整个价值观体系。引入VAT来捕捉这些动态过程中的价值表达。", "method": "通过基于Schwartz价值观理论的控制情景-行动数据集，收集预后规范判断并对不同模型、价值观和对齐策略下的影响进行分析。", "result": "结果显示，对齐操作往往导致价值观之间出现不均匀但有结构化的共同运动。这些效应在传统的目标评估中难以发现，揭示了系统性过程层面的风险。", "conclusion": "VAT框架为研究大语言模型中的价值动态提供了新的视角，并指出了其中存在的复杂性和潜在风险。"}}
{"id": "2602.12133", "pdf": "https://arxiv.org/pdf/2602.12133", "abs": "https://arxiv.org/abs/2602.12133", "authors": ["Roberto Balestri"], "title": "Neutral Prompts, Non-Neutral People: Quantifying Gender and Skin-Tone Bias in Gemini Flash 2.5 Image and GPT Image 1.5", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC"], "comment": null, "summary": "This study quantifies gender and skin-tone bias in two widely deployed commercial image generators - Gemini Flash 2.5 Image (NanoBanana) and GPT Image 1.5 - to test the assumption that neutral prompts yield demographically neutral outputs. We generated 3,200 photorealistic images using four semantically neutral prompts. The analysis employed a rigorous pipeline combining hybrid color normalization, facial landmark masking, and perceptually uniform skin tone quantification using the Monk (MST), PERLA, and Fitzpatrick scales. Neutral prompts produced highly polarized defaults. Both models exhibited a strong \"default white\" bias (>96% of outputs). However, they diverged sharply on gender: Gemini favored female-presenting subjects, while GPT favored male-presenting subjects with lighter skin tones. This research provides a large-scale, comparative audit of state-of-the-art models using an illumination-aware colorimetric methodology, distinguishing aesthetic rendering from underlying pigmentation in synthetic imagery. The study demonstrates that neutral prompts function as diagnostic probes rather than neutral instructions. It offers a robust framework for auditing algorithmic visual culture and challenges the sociolinguistic assumption that unmarked language results in inclusive representation.", "AI": {"tldr": "量化分析Gemini Flash 2.5 Image和GPT Image 1.5在中性提示下的性别和肤色偏见。", "motivation": "检验假设：中性提示能够生成无偏差的输出。", "method": "使用四个语义上中性的提示，生成3200张图像。采用混合颜色归一化、面部特征遮挡和Monk、PERLA及Fitzpatrick肤色量表进行量化分析。", "result": "两个模型在性别和肤色偏见方面存在显著差异：Gemini倾向女性，而GPT倾向男性且皮肤较浅；两者均显示强烈“默认白”偏好（超过96％的输出为白色）。", "conclusion": "中性提示并非中立指令，而是诊断探针。该研究提供了对算法视觉文化的严谨框架，并挑战了无标记语言导致包容性的假设。"}}
{"id": "2602.12128", "pdf": "https://arxiv.org/pdf/2602.12128", "abs": "https://arxiv.org/abs/2602.12128", "authors": ["Hanno Ackermann", "Hong Cai", "Mohsen Ghafoorian", "Amirhossein Habibian"], "title": "HLA: Hadamard Linear Attention", "categories": ["cs.AI"], "comment": null, "summary": "The attention mechanism is an important reason for the success of transformers. It relies on computing pairwise relations between tokens. To reduce the high computational cost of standard quadratic attention, linear attention has been proposed as an efficient approximation. It employs kernel functions that are applied independently to the inputs before the pairwise similarities are calculated. That allows for an efficient computational procedure which, however, amounts to a low-degree rational function approximating softmax. We propose Hadamard Linear Attention (HLA). Unlike previous works on linear attention, the nonlinearity in HLA is not applied separately to queries and keys, but, analogously to standard softmax attention, after the pairwise similarities have been computed. It will be shown that the proposed nonlinearity amounts to a higher-degree rational function to approximate softmax. An efficient computational scheme for the proposed method is derived that is similar to that of standard linear attention. In contrast to other approaches, no time-consuming tensor reshaping is necessary to apply the proposed algorithm. The effectiveness of the approach is demonstrated by applying it to a large diffusion transformer model for video generation, an application that involves very large amounts of tokens.", "AI": {"tldr": "提出了Hadamard线性注意力机制，通过在计算完成对相似度后应用非线性来改进传统线性注意力。", "motivation": "为了减少标准二次注意力的高计算成本，并提高线性注意力中非线性的近似精度。", "method": "引入了新的非线性函数应用于计算完成后的成对相似度，以更精确地逼近softmax。提出了高效的计算方案。", "result": "该方法在大型扩散变换器模型视频生成任务中显示出有效性。", "conclusion": "Hadamard线性注意力机制改进了传统线性注意力的非线性处理方式，并展示了更好的近似精度和效率。"}}
{"id": "2602.12127", "pdf": "https://arxiv.org/pdf/2602.12127", "abs": "https://arxiv.org/abs/2602.12127", "authors": ["Sixiang Chen", "Jianyu Lai", "Jialin Gao", "Hengyu Shi", "Zhongying Liu", "Tian Ye", "Junfeng Luo", "Xiaoming Wei", "Lei Zhu"], "title": "PosterOmni: Generalized Artistic Poster Creation via Task Distillation and Unified Reward Feedback", "categories": ["cs.CV"], "comment": null, "summary": "Image-to-poster generation is a high-demand task requiring not only local adjustments but also high-level design understanding. Models must generate text, layout, style, and visual elements while preserving semantic fidelity and aesthetic coherence. The process spans two regimes: local editing, where ID-driven generation, rescaling, filling, and extending must preserve concrete visual entities; and global creation, where layout- and style-driven tasks rely on understanding abstract design concepts. These intertwined demands make image-to-poster a multi-dimensional process coupling entity-preserving editing with concept-driven creation under image-prompt control. To address these challenges, we propose PosterOmni, a generalized artistic poster creation framework that unlocks the potential of a base edit model for multi-task image-to-poster generation. PosterOmni integrates the two regimes, namely local editing and global creation, within a single system through an efficient data-distillation-reward pipeline: (i) constructing multi-scenario image-to-poster datasets covering six task types across entity-based and concept-based creation; (ii) distilling knowledge between local and global experts for supervised fine-tuning; and (iii) applying unified PosterOmni Reward Feedback to jointly align visual entity-preserving and aesthetic preference across all tasks. Additionally, we establish PosterOmni-Bench, a unified benchmark for evaluating both local editing and global creation. Extensive experiments show that PosterOmni significantly enhances reference adherence, global composition quality, and aesthetic harmony, outperforming all open-source baselines and even surpassing several proprietary systems.", "AI": {"tldr": "提出PosterOmni框架，通过任务提炼和统一反馈奖励机制实现多任务图像到海报的生成。", "motivation": "现有模型难以同时处理局部调整与高层次设计理解的任务需求。需要一种方法来融合实体保护编辑和概念驱动创作两个方面。", "method": "构建了涵盖六种任务类型的多场景数据集，通过知识提炼在本地和全局专家间传递监督微调，并引入统一反馈奖励机制以实现视觉实体保护及美学偏好的一致性。", "result": "实验表明PosterOmni显著提升了参考一致性、全局构图质量和美学和谐度，优于所有开源基线并超越了一些专有系统。", "conclusion": "通过整合局部编辑和全球创作的多任务框架，PosterOmni展示了其在生成高质量艺术海报方面的优越性。"}}
{"id": "2602.12126", "pdf": "https://arxiv.org/pdf/2602.12126", "abs": "https://arxiv.org/abs/2602.12126", "authors": ["Daniele Carnevale", "Gianlorenzo D'Angelo"], "title": "Optimizing Distances for Multi-Broadcast in Temporal Graphs", "categories": ["cs.DS"], "comment": null, "summary": "Temporal graphs represent networks in which connections change over time, with edges available only at specific moments. Motivated by applications in logistics, multi-agent information spreading, and wireless networks, we introduce the D-Temporal Multi-Broadcast (D-TMB) problem, which asks for scheduling the availability of edges so that a predetermined subset of sources reach all other vertices while optimizing the worst-case temporal distance D from any source. We show that D-TMB generalizes ReachFast (arXiv:2112.08797). We then characterize the computational complexity and approximability of D-TMB under six definitions of temporal distance D, namely Earliest-Arrival (EA), Latest-Departure (LD), Fastest-Time (FT), Shortest-Traveling (ST), Minimum-Hop (MH), and Minimum-Waiting (MW). For a single source, we show that D-TMB can be solved in polynomial time for EA and LD, while for the other temporal distances it is NP-hard and hard to approximate within a factor that depends on the adopted distance function. We give approximation algorithms for FT and MW. For multiple sources, if feasibility is not assumed a priori, the problem is inapproximable within any factor unless P = NP, even with just two sources. We complement this negative result by identifying structural conditions that guarantee tractability for EA and LD for any number of sources.", "AI": {"tldr": "论文研究了时变图中的多广播问题，旨在优化从一组预定源到达所有其他顶点的最坏情况时间距离D。", "motivation": "受物流、多代理信息传播和无线网络应用驱动，提出了一种新的调度边可用性的方法以最小化最坏情况下的时间距离。", "method": "论文针对六种时变距离定义（最早到达EA、最晚离开LD、最快时间FT、最短旅行ST、最少跳数MH和最少等待MW），研究了D-TMB问题的计算复杂性和近似可解性。对于单一源，EA和LD情况下可以多项式时间内解决，其他情况为NP难，并且难以在与所选距离函数相关的因素内进行近似。", "result": "论文展示了在某些条件下单个源的EA和LD问题是可处理的；多个源情况下，在没有预先假设可行性的情况下问题不可近似求解。", "conclusion": "论文提供了时变图中多广播优化的新视角，揭示了不同距离定义下的复杂性和近似性挑战，并为特定情况提出了有效的解决策略。"}}
{"id": "2602.12125", "pdf": "https://arxiv.org/pdf/2602.12125", "abs": "https://arxiv.org/abs/2602.12125", "authors": ["Wenkai Yang", "Weijie Liu", "Ruobing Xie", "Kai Yang", "Saiyong Yang", "Yankai Lin"], "title": "Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Work in progress. Github repo: https://github.com/RUCBM/G-OPD", "summary": "On-policy distillation (OPD), which aligns the student with the teacher's logit distribution on student-generated trajectories, has demonstrated strong empirical gains in improving student performance and often outperforms off-policy distillation and reinforcement learning (RL) paradigms. In this work, we first theoretically show that OPD is a special case of dense KL-constrained RL where the reward function and the KL regularization are always weighted equally and the reference model can by any model. Then, we propose the Generalized On-Policy Distillation (G-OPD) framework, which extends the standard OPD objective by introducing a flexible reference model and a reward scaling factor that controls the relative weight of the reward term against the KL regularization. Through comprehensive experiments on math reasoning and code generation tasks, we derive two novel insights: (1) Setting the reward scaling factor to be greater than 1 (i.e., reward extrapolation), which we term ExOPD, consistently improves over standard OPD across a range of teacher-student size pairings. In particular, in the setting where we merge the knowledge from different domain experts, obtained by applying domain-specific RL to the same student model, back into the original student, ExOPD enables the student to even surpass the teacher's performance boundary and outperform the domain teachers. (2) Building on ExOPD, we further find that in the strong-to-weak distillation setting (i.e., distilling a smaller student from a larger teacher), performing reward correction by choosing the reference model as the teacher's base model before RL yields a more accurate reward signal and further improves distillation performance. However, this choice assumes access to the teacher's pre-RL variant and incurs more computational overhead. We hope our work offers new insights for future research on OPD.", "AI": {"tldr": "提出了一种改进的在策略蒸馏方法，通过引入奖励外推和灵活参考模型来提升学生模型表现。", "motivation": "为了提高学生模型的表现，尤其是在教师与学生的规模差异较大时，研究人员希望通过理论分析和实验探索更有效的蒸馏技术。", "method": "提出了广义的在策略蒸馏（G-OPD）框架，并通过奖励外推（ExOPD）和适当的参考模型选择来提升蒸馏效果。引入了可调的奖励尺度因子以控制奖励项与KL正则化之间的权衡。", "result": "实验结果表明，采用奖励外推可以提高标准在策略蒸馏的表现；同时，在从大型教师到小型学生的蒸馏中，使用适当的参考模型进行奖励校正能够进一步提升表现。", "conclusion": "该研究提供了新的见解和方法来改进在策略蒸馏技术，并为未来的研究提供了方向。"}}
{"id": "2602.12123", "pdf": "https://arxiv.org/pdf/2602.12123", "abs": "https://arxiv.org/abs/2602.12123", "authors": ["Xubin Wang", "Weijia Jia"], "title": "Meta-Sel: Efficient Demonstration Selection for In-Context Learning via Supervised Meta-Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Demonstration selection is a practical bottleneck in in-context learning (ICL): under a tight prompt budget, accuracy can change substantially depending on which few-shot examples are included, yet selection must remain cheap enough to run per query over large candidate pools. We propose Meta-Sel, a lightweight supervised meta-learning approach for intent classification that learns a fast, interpretable scoring function for (candidate, query) pairs from labeled training data. Meta-Sel constructs a meta-dataset by sampling pairs from the training split and using class agreement as supervision, then trains a calibrated logistic regressor on two inexpensive meta-features: TF--IDF cosine similarity and a length-compatibility ratio. At inference time, the selector performs a single vectorized scoring pass over the full candidate pool and returns the top-k demonstrations, requiring no model fine-tuning, no online exploration, and no additional LLM calls. This yields deterministic rankings and makes the selection mechanism straightforward to audit via interpretable feature weights. Beyond proposing Meta-Sel, we provide a broad empirical study of demonstration selection, benchmarking 12 methods -- spanning prompt engineering baselines, heuristic selection, reinforcement learning, and influence-based approaches -- across four intent datasets and five open-source LLMs. Across this benchmark, Meta-Sel consistently ranks among the top-performing methods, is particularly effective for smaller models where selection quality can partially compensate for limited model capacity, and maintains competitive selection-time overhead.", "AI": {"tldr": "提出了一种轻量级的监督元学习方法Meta-Sel，用于在有限提示预算下高效选择演示样本以提高上下文学习效果。", "motivation": "在有限的提示预算下准确地选择演示样本是上下文学习中的瓶颈问题。现有的解决方案往往过于昂贵且难以解释，因此需要一种快速、可解释的选择机制。", "method": "Meta-Sel通过从标记的训练数据中学习一个评分函数来解决这个问题。该方法构建了一个元数据集并使用类一致性作为监督信号进行训练，最终选择两个廉价特征：TF-IDF余弦相似度和长度兼容性比率。", "result": "在广泛的基准测试中，Meta-Sel表现优异，并且对于较小的模型特别有效。它能够以较低的时间开销提供高质量的选择结果。", "conclusion": "Meta-Sel是一种高效、可解释的方法，在多个数据集和模型上均展示了优越的表现。"}}
{"id": "2602.12120", "pdf": "https://arxiv.org/pdf/2602.12120", "abs": "https://arxiv.org/abs/2602.12120", "authors": ["Jittarin Jetwiriyanon", "Teo Susnjak", "Surangika Ranathunga"], "title": "Commencing-Student Enrolment Forecasting Under Data Sparsity with Time Series Foundation Models", "categories": ["cs.AI"], "comment": "31 pages, 5 figures, 3 tables", "summary": "Many universities face increasing financial pressure and rely on accurate forecasts of commencing enrolments. However, enrolment forecasting in higher education is often data-sparse; annual series are short and affected by reporting changes and regime shifts. Popular classical approaches can be unreliable, as parameter estimation and model selection are unstable with short samples, and structural breaks degrade extrapolation. Recently, TSFMs have provided zero-shot priors, delivering strong gains in annual, data-sparse institutional forecasting under leakage-disciplined covariate construction. We benchmark multiple TSFM families in a zero-shot setting and test a compact, leakage-safe covariate set and introduce the Institutional Operating Conditions Index (IOCI), a transferable 0-100 regime covariate derived from time-stamped documentary evidence available at each forecast origin, alongside Google Trends demand proxies with stabilising feature engineering. Using an expanding-window backtest with strict vintage alignment, covariate-conditioned TSFMs perform on par with classical benchmarks without institution-specific training, with performance differences varying by cohort and model.", "AI": {"tldr": "本文研究了在数据稀疏环境下，利用时间序列基础模型对高校新生入学人数进行预测。", "motivation": "许多大学面临着财政压力，并依赖准确的新生入学预测。但是高等教育中的入学预测常常因为年度系列较短、报告变化和制度变动而面临挑战。", "method": "本文比较了多种时间序列基础模型在零样本设置下的表现，同时引入了一种新的转移性制度协变量——机构运营状况指数（IOCI），以及带有稳定特征工程的谷歌趋势需求代理。通过严格版本对齐的滚动窗口回测方法进行了测试。", "result": "使用条件化的时序模型进行预测，在不经过特定机构训练的情况下，表现与传统基准相似，但在不同群体和模型间存在性能差异。", "conclusion": "在数据稀疏的环境下，时间序列基础模型可以提供可靠的新生入学人数预测。引入新的协变量IOCI以及稳定特征工程后的谷歌趋势需求代理能够进一步提高预测准确性。"}}
{"id": "2602.12117", "pdf": "https://arxiv.org/pdf/2602.12117", "abs": "https://arxiv.org/abs/2602.12117", "authors": ["Jiakang Shen", "Qinghui Chen", "Runtong Wang", "Chenrui Xu", "Jinglin Zhang", "Cong Bai", "Feng Zhang"], "title": "KAN-FIF: Spline-Parameterized Lightweight Physics-based Tropical Cyclone Estimation on Meteorological Satellite", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Tropical cyclones (TC) are among the most destructive natural disasters, causing catastrophic damage to coastal regions through extreme winds, heavy rainfall, and storm surges. Timely monitoring of tropical cyclones is crucial for reducing loss of life and property, yet it is hindered by the computational inefficiency and high parameter counts of existing methods on resource-constrained edge devices. Current physics-guided models suffer from linear feature interactions that fail to capture high-order polynomial relationships between TC attributes, leading to inflated model sizes and hardware incompatibility. To overcome these challenges, this study introduces the Kolmogorov-Arnold Network-based Feature Interaction Framework (KAN-FIF), a lightweight multimodal architecture that integrates MLP and CNN layers with spline-parameterized KAN layers. For Maximum Sustained Wind (MSW) prediction, experiments demonstrate that the KAN-FIF framework achieves a $94.8\\%$ reduction in parameters (0.99MB vs 19MB) and $68.7\\%$ faster inference per sample (2.3ms vs 7.35ms) compared to baseline model Phy-CoCo, while maintaining superior accuracy with $32.5\\%$ lower MAE. The offline deployment experiment of the FY-4 series meteorological satellite processor on the Qingyun-1000 development board achieved a 14.41ms per-sample inference latency with the KAN-FIF framework, demonstrating promising feasibility for operational TC monitoring and extending deployability to edge-device AI applications. The code is released at https://github.com/Jinglin-Zhang/KAN-FIF.", "AI": {"tldr": "介绍了一种基于Kolmogorov-Arnold网络的轻量级多模态架构，用于热带气旋监测。", "motivation": "当前方法在资源受限设备上存在计算效率低下和模型参数过多的问题，导致难以实现有效监控。现有的物理引导模型无法捕捉高阶多项式关系，增加了模型大小且不兼容硬件。", "method": "提出了一种融合MLP、CNN层与基于样条参数化的KAN层的轻量级架构KAN-FIF，以改善TC监测效率和准确性。", "result": "实验表明，相较于基线模型Phy-CoCo，KAN-FIF在MSW预测中减少了94.8%的参数，并加快了68.7%的推理速度，同时保持了更低的MAE。实际部署测试显示，其在边缘设备上的延迟仅为14.41ms。", "conclusion": "提出的KAN-FIF框架成功降低了模型复杂度和计算成本，增强了TC监测的实时性和准确性，并展示了应用于边缘设备AI应用的巨大潜力。"}}
{"id": "2602.12113", "pdf": "https://arxiv.org/pdf/2602.12113", "abs": "https://arxiv.org/abs/2602.12113", "authors": ["Zewei Yu", "Lirong Gao", "Yuke Zhu", "Bo Zheng", "Sheng Guo", "Haobo Wang", "Junbo Zhao"], "title": "Stop Unnecessary Reflection: Training LRMs for Efficient Reasoning with Adaptive Reflection and Length Coordinated Penalty", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted to ICLR 2026", "summary": "Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning tasks by employing test-time scaling. However, they often generate over-long chains-of-thought that, driven by substantial reflections such as repetitive self-questioning and circular reasoning, lead to high token consumption, substantial computational overhead, and increased latency without improving accuracy, particularly in smaller models. Our observation reveals that increasing problem complexity induces more excessive and unnecessary reflection, which in turn reduces accuracy and increases token overhead. To address this challenge, we propose Adaptive Reflection and Length Coordinated Penalty (ARLCP), a novel reinforcement learning framework designed to dynamically balance reasoning efficiency and solution accuracy. ARLCP introduces two key innovations: (1) a reflection penalty that adaptively curtails unnecessary reflective steps while preserving essential reasoning, and (2) a length penalty calibrated to the estimated complexity of the problem. By coordinating these penalties, ARLCP encourages the model to generate more concise and effective reasoning paths. We evaluate our method on five mathematical reasoning benchmarks using DeepSeek-R1-Distill-Qwen-1.5B and DeepSeek-R1-Distill-Qwen-7B models. Experimental results show that ARLCP achieves a superior efficiency-accuracy trade-off compared to existing approaches. For the 1.5B model, it reduces the average response length by 53.1% while simultaneously improving accuracy by 5.8%. For the 7B model, it achieves a 35.0% reduction in length with a 2.7% accuracy gain. The code is released at https://github.com/ZeweiYu1/ARLCP .", "AI": {"tldr": "本文提出了自适应反思和长度协调惩罚（ARLCP），用于提高大推理模型的推理效率并减少不必要的反射步骤，从而优化准确性和计算资源使用。", "motivation": "大型推理模型在复杂任务中表现出色但存在过度生成长链条思维的问题，导致过多无用的自我提问和循环推理，增加了计算成本和延迟。为解决这一问题，提出了ARLCP框架以平衡效率与准确性。", "method": "ARLCP包括两个关键创新：反射惩罚动态削减不必要的反思步骤同时保持必要的推理过程；长度惩罚根据任务复杂度调整，通过协调这两种惩罚来促进更简洁有效的推理路径生成。", "result": "实验结果表明，ARLCP在5个数学推理基准测试中表现出比现有方法更好的效率-准确性权衡。对于1.5B模型，响应平均长度减少53.1%，准确率提高5.8%；7B模型则分别减少了35.0%和提高了2.7%。", "conclusion": "ARLCP框架有效改善了大型推理模型在复杂任务中的表现，通过动态平衡反思步骤来优化效率和准确性。"}}
{"id": "2602.12108", "pdf": "https://arxiv.org/pdf/2602.12108", "abs": "https://arxiv.org/abs/2602.12108", "authors": ["Xiaoyuan Liu", "Tian Liang", "Dongyang Ma", "Deyu Zhou", "Haitao Mi", "Pinjia He", "Yan Wang"], "title": "The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context", "categories": ["cs.AI"], "comment": null, "summary": "In the world of Harry Potter, when Dumbledore's mind is overburdened, he extracts memories into a Pensieve to be revisited later. In the world of AI, while we possess the Pensieve-mature databases and retrieval systems, our models inexplicably lack the \"wand\" to operate it. They remain like a Dumbledore without agency, passively accepting a manually engineered context as their entire memory. This work finally places the wand in the model's hand. We introduce StateLM, a new class of foundation models endowed with an internal reasoning loop to manage their own state. We equip our model with a suite of memory tools, such as context pruning, document indexing, and note-taking, and train it to actively manage these tools. By learning to dynamically engineering its own context, our model breaks free from the architectural prison of a fixed window. Experiments across various model sizes demonstrate StateLM's effectiveness across diverse scenarios. On long-document QA tasks, StateLMs consistently outperform standard LLMs across all model scales; on the chat memory task, they achieve absolute accuracy improvements of 10% to 20% over standard LLMs. On the deep research task BrowseComp-Plus, the performance gap becomes even more pronounced: StateLM achieves up to 52% accuracy, whereas standard LLM counterparts struggle around 5%. Ultimately, our approach shifts LLMs from passive predictors to state-aware agents where reasoning becomes a stateful and manageable process.", "AI": {"tldr": "引入StateLM模型，使其能够主动管理其内部状态和记忆工具，从而在多种任务上超越标准LLM。", "motivation": "当前的AI模型缺乏自主管理自身上下文的能力，类似于《哈利·波特》中的邓布利多无法操作他自己的思考池（Pensieve）。作者希望通过赋予模型内部推理循环来解决这一问题。", "method": "提出StateLM模型，配备记忆工具如上下文剪裁、文档索引和笔记记录，并训练它主动管理这些工具。通过动态调整其上下文，使模型从固定窗口的限制中解放出来。", "result": "在长文档问答任务上，各种规模的StateLM均优于标准LLM；在聊天记忆任务上，性能提升10%至20%；在深度研究任务BrowseComp-Plus上，StateLM表现显著更优，准确率高达52%，而标准LLM仅为5%", "conclusion": "该方法使LLM从被动预测者转变为具有状态意识的代理，并将推理过程转化为可管理的状态化过程。"}}
{"id": "2602.12107", "pdf": "https://arxiv.org/pdf/2602.12107", "abs": "https://arxiv.org/abs/2602.12107", "authors": ["Haolin Liu", "Braham Snyder", "Chen-Yu Wei"], "title": "On the Complexity of Offline Reinforcement Learning with $Q^\\star$-Approximation and Partial Coverage", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We study offline reinforcement learning under $Q^\\star$-approximation and partial coverage, a setting that motivates practical algorithms such as Conservative $Q$-Learning (CQL; Kumar et al., 2020) but has received limited theoretical attention. Our work is inspired by the following open question: \"Are $Q^\\star$-realizability and Bellman completeness sufficient for sample-efficient offline RL under partial coverage?\" We answer in the negative by establishing an information-theoretic lower bound. Going substantially beyond this, we introduce a general framework that characterizes the intrinsic complexity of a given $Q^\\star$ function class, inspired by model-free decision-estimation coefficients (DEC) for online RL (Foster et al., 2023b; Liu et al., 2025b). This complexity recovers and improves the quantities underlying the guarantees of Chen and Jiang (2022) and Uehara et al. (2023), and extends to broader settings. Our decision-estimation decomposition can be combined with a wide range of $Q^\\star$ estimation procedures, modularizing and generalizing existing approaches. Beyond the general framework, we make further contributions: By developing a novel second-order performance difference lemma, we obtain the first $ε^{-2}$ sample complexity under partial coverage for soft $Q$-learning, improving the $ε^{-4}$ bound of Uehara et al. (2023). We remove Chen and Jiang's (2022) need for additional online interaction when the value gap of $Q^\\star$ is unknown. We also give the first characterization of offline learnability for general low-Bellman-rank MDPs without Bellman completeness (Jiang et al., 2017; Du et al., 2021; Jin et al., 2021), a canonical setting in online RL that remains unexplored in offline RL except for special cases. Finally, we provide the first analysis for CQL under $Q^\\star$-realizability and Bellman completeness beyond the tabular case.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.12105", "pdf": "https://arxiv.org/pdf/2602.12105", "abs": "https://arxiv.org/abs/2602.12105", "authors": ["Ana Dodik", "Ahmed H. Mahmoud", "Justin Solomon"], "title": "Iskra: A System for Inverse Geometry Processing", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "We propose a system for differentiating through solutions to geometry processing problems. Our system differentiates a broad class of geometric algorithms, exploiting existing fast problem-specific schemes common to geometry processing, including local-global and ADMM solvers. It is compatible with machine learning frameworks, opening doors to new classes of inverse geometry processing applications. We marry the scatter-gather approach to mesh processing with tensor-based workflows and rely on the adjoint method applied to user-specified imperative code to generate an efficient backward pass behind the scenes. We demonstrate our approach by differentiating through mean curvature flow, spectral conformal parameterization, geodesic distance computation, and as-rigid-as-possible deformation, examining usability and performance on these applications. Our system allows practitioners to differentiate through existing geometry processing algorithms without needing to reformulate them, resulting in low implementation effort, fast runtimes, and lower memory requirements than differentiable optimization tools not tailored to geometry processing.", "AI": {"tldr": "提出了一种逆几何处理系统Iskra，用于通过几何处理问题的解进行微分。", "motivation": "为了解决机器学习框架中对逆几何处理应用的需求，开发了一个能够兼容现有几何处理算法并支持微分操作的系统。", "method": "将散射-聚集方法与基于张量的工作流程相结合，并通过用户指定的操作代码应用伴随法生成高效的反向传递过程。", "result": "该系统在均值曲率流、谱共形参数化、测地线距离计算和尽可能刚性的变形等多种几何处理算法中展示了其适用性和性能，实现了低实施工作量、快速运行时间和较低的内存需求。", "conclusion": "Iskra 系统允许实践者通过现有的几何处理算法进行微分操作，而无需重新制定这些算法。"}}
{"id": "2602.12100", "pdf": "https://arxiv.org/pdf/2602.12100", "abs": "https://arxiv.org/abs/2602.12100", "authors": ["Lingting Zhu", "Shengju Qian", "Haidi Fan", "Jiayu Dong", "Zhenchao Jin", "Siwei Zhou", "Gen Dong", "Xin Wang", "Lequan Yu"], "title": "AssetFormer: Modular 3D Assets Generation with Autoregressive Transformer", "categories": ["cs.CV"], "comment": "Accepted by ICLR 2026. 23 pages, 14 figures", "summary": "The digital industry demands high-quality, diverse modular 3D assets, especially for user-generated content~(UGC). In this work, we introduce AssetFormer, an autoregressive Transformer-based model designed to generate modular 3D assets from textual descriptions. Our pilot study leverages real-world modular assets collected from online platforms. AssetFormer tackles the challenge of creating assets composed of primitives that adhere to constrained design parameters for various applications. By innovatively adapting module sequencing and decoding techniques inspired by language models, our approach enhances asset generation quality through autoregressive modeling. Initial results indicate the effectiveness of AssetFormer in streamlining asset creation for professional development and UGC scenarios. This work presents a flexible framework extendable to various types of modular 3D assets, contributing to the broader field of 3D content generation. The code is available at https://github.com/Advocate99/AssetFormer.", "AI": {"tldr": "介绍了一种基于自回归Transformer的模型AssetFormer，用于根据文本描述生成模块化3D资产。", "motivation": "为了满足数字行业对高质量、多样化模块化3D资产的需求，特别是用户生成内容（UGC），提出了一种新的方法来提高3D资产创建的质量和效率。", "method": "通过创新地利用语言模型中的模块排序和解码技术，AssetFormer能够自回归建模以提升资产生成质量。该模型使用真实的在线平台收集的模块化3D资产数据进行训练。", "result": "初步结果显示，AssetFormer在专业开发和UGC场景中简化了资产创建过程，并展示了其在多种类型模块化3D资产生成中的灵活性和可扩展性。", "conclusion": "AssetFormer提供了一个灵活的框架来生成高质量的模块化3D资产，为更广泛的3D内容生成领域做出了贡献。"}}
{"id": "2602.12099", "pdf": "https://arxiv.org/pdf/2602.12099", "abs": "https://arxiv.org/abs/2602.12099", "authors": ["GigaBrain Team", "Boyuan Wang", "Chaojun Ni", "Guan Huang", "Guosheng Zhao", "Hao Li", "Jie Li", "Jindi Lv", "Jingyu Liu", "Lv Feng", "Mingming Yu", "Peng Li", "Qiuping Deng", "Tianze Liu", "Xinyu Zhou", "Xinze Chen", "Xiaofeng Wang", "Yang Wang", "Yifan Li", "Yifei Nie", "Yilong Li", "Yukun Zhou", "Yun Ye", "Zhichao Liu", "Zheng Zhu"], "title": "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning", "categories": ["cs.CV"], "comment": "https://gigabrain05m.github.io/", "summary": "Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose \\textit{GigaBrain-0.5M*}, a VLA model trained via world model-based reinforcement learning. Built upon \\textit{GigaBrain-0.5}, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. \\textit{GigaBrain-0.5M*} further integrates world model-based reinforcement learning via \\textit{RAMP} (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that \\textit{RAMP} achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\\% on challenging tasks including \\texttt{Laundry Folding}, \\texttt{Box Packing}, and \\texttt{Espresso Preparation}. Critically, \\textit{GigaBrain-0.5M$^*$} exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our \\href{https://gigabrain05m.github.io}{project page}.", "AI": {"tldr": "提出了一种基于世界模型强化学习的视觉语言动作(VLA)模型GigaBrain-0.5M*，以提高复杂任务中的执行性能。", "motivation": "现有的VLA模型在多步行动预测中面临场景理解受限和未来预判能力弱的问题。通过引入视频世界模型预训练，可以增强时空推理能力和未来的准确预测。", "method": "基于GigaBrain-0.5进行进一步的改进，加入RAMP（通过世界模型条件策略的强化学习）以实现跨任务适应性，并展示在特定基准测试中表现优异的能力。", "result": "实验结果表明，在洗衣折叠、打包盒子和准备浓缩咖啡等复杂任务上，GigaBrain-0.5M*相较于RECAP基线提升了约30%的性能。", "conclusion": "GigaBrain-0.5M*通过整合世界模型强化学习能够有效解决现有VLA模型的问题，并且在多个真实场景中验证了其可靠的长期执行能力。"}}
{"id": "2602.12096", "pdf": "https://arxiv.org/pdf/2602.12096", "abs": "https://arxiv.org/abs/2602.12096", "authors": ["Itamar Mishani", "Maxim Likhachev"], "title": "Multi Graph Search for High-Dimensional Robot Motion Planning", "categories": ["cs.RO", "cs.AI"], "comment": "Submitted for Publication", "summary": "Efficient motion planning for high-dimensional robotic systems, such as manipulators and mobile manipulators, is critical for real-time operation and reliable deployment. Although advances in planning algorithms have enhanced scalability to high-dimensional state spaces, these improvements often come at the cost of generating unpredictable, inconsistent motions or requiring excessive computational resources and memory. In this work, we introduce Multi-Graph Search (MGS), a search-based motion planning algorithm that generalizes classical unidirectional and bidirectional search to a multi-graph setting. MGS maintains and incrementally expands multiple implicit graphs over the state space, focusing exploration on high-potential regions while allowing initially disconnected subgraphs to be merged through feasible transitions as the search progresses. We prove that MGS is complete and bounded-suboptimal, and empirically demonstrate its effectiveness on a range of manipulation and mobile manipulation tasks. Demonstrations, benchmarks and code are available at https://multi-graph-search.github.io/.", "AI": {"tldr": "本文提出了一种新的基于搜索的机器人运动规划算法——多图搜索（MGS），旨在解决高维空间中高效且一致的路径规划问题。", "motivation": "随着机器人系统维度的增加，传统的路径规划算法在实时操作和资源消耗方面面临着挑战。现有的改进方法要么生成不可预测或不一致的运动轨迹，要么需要过多的计算资源和内存。", "method": "多图搜索（MGS）通过维护多个隐式图并逐步扩展这些图来探索状态空间中的高潜力区域，并允许最初分离的子图在可行转换时合并。这种方法既保证了搜索的有效性又保持了较低的计算成本。", "result": "实验验证表明，该算法在多种操作和移动操作任务中均表现出色。MGS被证明是完备且有界次优解的方法。", "conclusion": "通过引入多图搜索（MGS），本文提供了一种新的路径规划策略，能够有效解决高维空间中的运动规划问题，并为实际应用提供了可靠的基础。"}}
{"id": "2602.12095", "pdf": "https://arxiv.org/pdf/2602.12095", "abs": "https://arxiv.org/abs/2602.12095", "authors": ["David Russell", "Zisong Xu", "Maximo A. Roa", "Mehmet Dogar"], "title": "Pack it in: Packing into Partially Filled Containers Through Contact", "categories": ["cs.RO"], "comment": "8 pages, 5 figures", "summary": "The automation of warehouse operations is crucial for improving productivity and reducing human exposure to hazardous environments. One operation frequently performed in warehouses is bin-packing where items need to be placed into containers, either for delivery to a customer, or for temporary storage in the warehouse. Whilst prior bin-packing works have largely been focused on packing items into empty containers and have adopted collision-free strategies, it is often the case that containers will already be partially filled with items, often in suboptimal arrangements due to transportation about a warehouse. This paper presents a contact-aware packing approach that exploits purposeful interactions with previously placed objects to create free space and enable successful placement of new items. This is achieved by using a contact-based multi-object trajectory optimizer within a model predictive controller, integrated with a physics-aware perception system that estimates object poses even during inevitable occlusions, and a method that suggests physically-feasible locations to place the object inside the container.", "AI": {"tldr": "介绍了一种利用接触感知技术优化已部分填充容器内物品放置的方法。", "motivation": "传统打包方法多集中在空容器中无碰撞放置，忽略了现实中容器往往已有不规则分布的物体，提出一种新策略以改善此类情况下的打包效率和安全性。", "method": "使用基于物理感知系统、预测控制器及轨迹优化器相结合的技术，通过有目的性接触已放置物品创造空间来实现新物件的有效放置。", "result": "该方法能在部分填充容器中成功定位并放置新物件，并能处理过程中不可避免的遮挡问题。", "conclusion": "提出的接触感知打包策略能够有效解决现实仓库环境中物品重新排列和优化的问题，提高仓储作业效率与安全性。"}}
{"id": "2602.12092", "pdf": "https://arxiv.org/pdf/2602.12092", "abs": "https://arxiv.org/abs/2602.12092", "authors": ["Bo Zhang", "Jiaxuan Guo", "Lijun Li", "Dongrui Liu", "Sujin Chen", "Guanxu Chen", "Zhijie Zheng", "Qihao Lin", "Lewen Yan", "Chen Qian", "Yijin Zhou", "Yuyao Wu", "Shaoxiong Guo", "Tianyi Du", "Jingyi Yang", "Xuhao Hu", "Ziqi Miao", "Xiaoya Lu", "Jing Shao", "Xia Hu"], "title": "DeepSight: An All-in-One LM Safety Toolkit", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.CV"], "comment": "Technical report, 29 pages, 24 figures", "summary": "As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) safety workflow, evaluation, diagnosis, and alignment are often handled by separate tools. Specifically, safety evaluation can only locate external behavioral risks but cannot figure out internal root causes. Meanwhile, safety diagnosis often drifts from concrete risk scenarios and remains at the explainable level. In this way, safety alignment lack dedicated explanations of changes in internal mechanisms, potentially degrading general capabilities. To systematically address these issues, we propose an open-source project, namely DeepSight, to practice a new safety evaluation-diagnosis integrated paradigm. DeepSight is low-cost, reproducible, efficient, and highly scalable large-scale model safety evaluation project consisting of a evaluation toolkit DeepSafe and a diagnosis toolkit DeepScan. By unifying task and data protocols, we build a connection between the two stages and transform safety evaluation from black-box to white-box insight. Besides, DeepSight is the first open source toolkit that support the frontier AI risk evaluation and joint safety evaluation and diagnosis.", "AI": {"tldr": "DeepSight是一个开源项目，旨在通过整合安全评估和诊断来系统地解决大型模型的安全问题。", "motivation": "现有的大型语言模型和多模态大型语言模型的安全工作流中，安全性评估、诊断和对齐通常由不同的工具处理。这种分离导致无法定位内部根本原因，并且缺乏内部机制变化的具体解释，可能导致通用能力的下降。", "method": "DeepSight项目包含一个安全评估工具包DeepSafe和一个诊断工具包DeepScan。通过统一任务和数据协议，它建立了一个连接这两个阶段的方法，并将安全性评估从黑盒转变为白盒洞察。", "result": "DeepSight是第一个支持前沿AI风险评估的开源工具集，能够进行联合的安全性评估和诊断。", "conclusion": "DeepSight作为一个开放源代码项目，提供了一种新的安全评估-诊断集成方法，可以有效地处理大型模型的安全问题。"}}
{"id": "2602.12089", "pdf": "https://arxiv.org/pdf/2602.12089", "abs": "https://arxiv.org/abs/2602.12089", "authors": ["Kehang Zhu", "Lithium Thain", "Vivian Tsai", "James Wexler", "Crystal Qian"], "title": "Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation", "categories": ["cs.GT", "cs.AI", "cs.HC"], "comment": null, "summary": "As AI usage becomes more prevalent in social contexts, understanding agent-user interaction is critical to designing systems that improve both individual and group outcomes. We present an online behavioral experiment (N = 243) in which participants play three multi-turn bargaining games in groups of three. Each game, presented in randomized order, grants \\textit{access to} a single LLM assistance modality: proactive recommendations from an \\textit{Advisor}, reactive feedback from a \\textit{Coach}, or autonomous execution by a \\textit{Delegate}; all modalities are powered by an underlying LLM that achieves superhuman performance in an all-agent environment. On each turn, participants privately decide whether to act manually or use the AI modality available in that game. Despite preferring the \\textit{Advisor} modality, participants achieve the highest mean individual gains with the \\textit{Delegate}, demonstrating a preference-performance misalignment. Moreover, delegation generates positive externalities; even non-adopting users in \\textit{access-to-delegate} treatment groups benefit by receiving higher-quality offers. Mechanism analysis reveals that the \\textit{Delegate} agent acts as a market maker, injecting rational, Pareto-improving proposals that restructure the trading environment. Our research reveals a gap between agent capabilities and realized group welfare. While autonomous agents can exhibit super-human strategic performance, their impact on realized welfare gains can be constrained by interfaces, user perceptions, and adoption barriers. Assistance modalities should be designed as mechanisms with endogenous participation; adoption-compatible interaction rules are a prerequisite to improving human welfare with automated assistance.", "AI": {"tldr": "本文通过在线行为实验研究了参与者在多轮谈判中采用不同类型的人工智能助手时的行为和效果。", "motivation": "随着AI在社交场合中的使用越来越普遍，理解代理与用户之间的交互对于设计既能提高个人又能改善群体结果的系统至关重要。", "method": "进行了一项在线行为实验（N = 243），参与者以三人一组的形式玩三个多轮讨价还价游戏。每个游戏中都提供一种不同的LLM助手模式：顾问、教练或代理人。", "result": "尽管更倾向于使用“顾问”模式，但参与者在使用“代理人”时实现了最高的平均个人收益，表明了偏好和表现之间的不一致。此外，“代理”生成积极的外部性，即使非采用者也从中受益。", "conclusion": "研究揭示了一个差距：虽然自主代理能够表现出超人的战略性能，但其对实现群体福利的影响可能受到界面、用户感知及采用障碍的限制。辅助模式应作为具有内生参与规则的机制来设计，以改善人类福祉。"}}
{"id": "2602.12083", "pdf": "https://arxiv.org/pdf/2602.12083", "abs": "https://arxiv.org/abs/2602.12083", "authors": ["Antonin Sulc"], "title": "Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication", "categories": ["cs.AI", "cs.LO"], "comment": "29 pages, 8 figures, 8 tables, Tutorial at 3rd International Conference on Neuro-Symbolic Systems (NeuS)", "summary": "As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relationship structures that are unknown or dynamic in real systems. This tutorial demonstrates differentiable modal logic (DML), implemented via Modal Logical Neural Networks (MLNNs), enabling systems to learn trust networks, causal chains, and regulatory boundaries from behavioral data alone. We present a unified neurosymbolic debugging framework through four modalities: epistemic (who to trust), temporal (when events cause failures), deontic (what actions are permitted), and doxastic (how to interpret agent confidence). Each modality is demonstrated on concrete multi-agent scenarios, from discovering deceptive alliances in diplomacy games to detecting LLM hallucinations, with complete implementations showing how logical contradictions become learnable optimization objectives. Key contributions for the neurosymbolic community: (1) interpretable learned structures where trust and causality are explicit parameters, not opaque embeddings; (2) knowledge injection via differentiable axioms that guide learning with sparse data (3) compositional multi-modal reasoning that combines epistemic, temporal, and deontic constraints; and (4) practical deployment patterns for monitoring, active control and communication of multi-agent systems. All code provided as executable Jupyter notebooks.", "AI": {"tldr": "本文介绍了可微分模态逻辑（DML）及其在多智能体系统中的应用，通过神经符号调试框架解决知识推理和故障诊断问题。", "motivation": "随着多代理AI系统的复杂性增加，传统的手动指定关系结构变得不可行。因此需要一种新的方法来自动学习信任网络、因果链等。", "method": "本文提出了一种基于可微分模态逻辑（DML）的方法，通过模态逻辑神经网络（MLNNs），实现从行为数据中自动学习知识和推理的能力。", "result": "该方法在不同的多代理场景下进行了验证，展示了如何将逻辑矛盾转化为可学习的优化目标，并提供了完整的代码实施。", "conclusion": "本文提出的方法为解决复杂多代理系统的故障诊断问题提供了一种新的途径。"}}
{"id": "2602.12078", "pdf": "https://arxiv.org/pdf/2602.12078", "abs": "https://arxiv.org/abs/2602.12078", "authors": ["Wenlong Wang", "Fergal Reid"], "title": "Tiny Recursive Reasoning with Mamba-2 Attention Hybrid", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent work on recursive reasoning models like TRM demonstrates that tiny networks (7M parameters) can achieve strong performance on abstract reasoning tasks through latent recursion -- iterative refinement in hidden representation space without emitting intermediate tokens. This raises a natural question about operator choice: Mamba-2's state space recurrence is itself a form of iterative refinement, making it a natural candidate for recursive reasoning -- but does introducing Mamba-2 into the recursive scaffold preserve reasoning capability? We investigate this by replacing the Transformer blocks in TRM with Mamba-2 hybrid operators while maintaining parameter parity (6.83M vs 6.86M parameters). On ARC-AGI-1, we find that the hybrid improves pass@2 (the official metric) by +2.0\\% (45.88\\% vs 43.88\\%) and consistently outperforms at higher K values (+4.75\\% at pass@100), whilst maintaining pass@1 parity. This suggests improved candidate coverage -- the model generates correct solutions more reliably -- with similar top-1 selection. Our results validate that Mamba-2 hybrid operators preserve reasoning capability within the recursive scaffold, establishing SSM-based operators as viable candidates in the recursive operator design space and taking a first step towards understanding the best mixing strategies for recursive reasoning.", "AI": {"tldr": "本文研究了在递归推理模型中使用Mamba-2注意力混合操作符的效果。", "motivation": "探讨将TRM中的Transformer块替换为Mamba-2混合操作符是否能保持推理能力，同时提升性能。", "method": "通过替换TRM的Transformer模块为Mamba-2混合操作符，在参数数量一致的情况下进行实验，并在ARC-AGI-1数据集上评估模型表现。", "result": "该方法提高了pass@2指标（45.88％ vs 43.88％），并在高K值时性能更优，表明了改进的候选覆盖率和可靠的正确解决方案生成能力。", "conclusion": "研究证实Mamba-2混合操作符在递归框架中保持推理能力，并为理解最佳递归推理策略提供了初步见解。"}}
{"id": "2602.12074", "pdf": "https://arxiv.org/pdf/2602.12074", "abs": "https://arxiv.org/abs/2602.12074", "authors": ["Lorin Achey", "Breanne Crockett", "Christoffer Heckman", "Bradley Hayes"], "title": "RF-Modulated Adaptive Communication Improves Multi-Agent Robotic Exploration", "categories": ["cs.RO"], "comment": null, "summary": "Reliable coordination and efficient communication are critical challenges for multi-agent robotic exploration of environments where communication is limited. This work introduces Adaptive-RF Transmission (ART), a novel communication-aware planning algorithm that dynamically modulates transmission location based on signal strength and data payload size, enabling heterogeneous robot teams to share information efficiently without unnecessary backtracking. We further explore an extension to this approach called ART-SST, which enforces signal strength thresholds for high-fidelity data delivery. Through over 480 simulations across three cave-inspired environments, ART consistently outperforms existing strategies, including full rendezvous and minimum-signal heuristic approaches, achieving up to a 58% reduction in distance traveled and up to 52% faster exploration times compared to baseline methods. These results demonstrate that adaptive, payload-aware communication significantly improves coverage efficiency and mission speed in complex, communication-constrained environments, offering a promising foundation for future planetary exploration and search-and-rescue missions.", "AI": {"tldr": "本文提出了一种自适应调制的通信算法ART，用于多机器人环境探索中信息的有效共享和传输。", "motivation": "在限制了通讯条件下的多机器人环境中，可靠的协调和高效的通讯是关键挑战。文章旨在通过优化信号强度和数据负载大小来改进机器人团队之间的信息传递效率。", "method": "引入了一种新型的通信感知规划算法ART，根据信号强度与数据负载动态调整传输位置；进一步扩展为ART-SST方法，在该方法中施加了信号强度阈值以确保高精度的数据交付。", "result": "通过模拟实验显示，ART比现有的策略（包括完全会合和最小信号启发式法）更能提高覆盖效率和任务速度，减少了58%的行走距离，并将探索时间缩短了52%。", "conclusion": "自适应负载感知通讯显著提高了复杂、受限环境中的覆盖效率与任务速率，为未来的行星探测和搜索救援任务奠定了坚实基础。"}}
{"id": "2602.12065", "pdf": "https://arxiv.org/pdf/2602.12065", "abs": "https://arxiv.org/abs/2602.12065", "authors": ["Xiang Liu", "Sen Cui", "Guocai Yao", "Zhong Cao", "Jingheng Ma", "Min Zhang", "Changshui Zhang"], "title": "Affordance-Graphed Task Worlds: Self-Evolving Task Generation for Scalable Embodied Learning", "categories": ["cs.RO"], "comment": null, "summary": "Training robotic policies directly in the real world is expensive and unscalable. Although generative simulation enables large-scale data synthesis, current approaches often fail to generate logically coherent long-horizon tasks and struggle with dynamic physical uncertainties due to open-loop execution. To address these challenges, we propose Affordance-Graphed Task Worlds (AGT-World), a unified framework that autonomously constructs interactive simulated environments and corresponding robot task policies based on real-world observations. Unlike methods relying on random proposals or static replication, AGT-World formalizes the task space as a structured graph, enabling the precise, hierarchical decomposition of complex goals into theoretically grounded atomic primitives. Furthermore, we introduce a Self-Evolution mechanism with hybrid feedback to autonomously refine policies, combining Vision-Language Model reasoning and geometric verification. Extensive experiments demonstrate that our method significantly outperforms in success rates and generalization, achieving a self-improving cycle of proposal, execution, and correction for scalable robot learning.", "AI": {"tldr": "提出了一种基于现实世界观察的自主构建模拟环境和机器人任务策略的方法，以解决直接在真实环境中训练机器人的成本高且不可扩展的问题。", "motivation": "为了克服直接在实际世界中训练政策的成本高昂和难以扩大规模的问题以及现有方法生成逻辑上连贯的任务困难及动态物理不确定性问题，提出了一种新的框架来解决这些问题。", "method": "该方法将任务空间定义为结构化图，通过基于现实世界的观察自动构建模拟环境，并引入自我进化机制结合视觉语言模型推理和几何验证来自主修正策略。", "result": "实验表明，所提方法在成功率和泛化性能方面均优于现有方法，并能实现提案、执行与纠正的循环改进。", "conclusion": "该研究提出了一种新的框架AGT-World，解决了机器人学习中的任务生成逻辑不连贯及动态物理不确定性问题，实现了自主进化并提高了机器人的学习效率。"}}
{"id": "2602.12063", "pdf": "https://arxiv.org/pdf/2602.12063", "abs": "https://arxiv.org/abs/2602.12063", "authors": ["Yanjiang Guo", "Tony Lee", "Lucy Xiaoyang Shi", "Jianyu Chen", "Percy Liang", "Chelsea Finn"], "title": "VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model", "categories": ["cs.RO"], "comment": "13 pages", "summary": "The goal of this paper is to improve the performance and reliability of vision-language-action (VLA) models through iterative online interaction. Since collecting policy rollouts in the real world is expensive, we investigate whether a learned simulator-specifically, an action-conditioned video generation model-can be used to generate additional rollout data. Unfortunately, existing world models lack the physical fidelity necessary for policy improvement: they are predominantly trained on demonstration datasets that lack coverage of many different physical interactions (particularly failure cases) and struggle to accurately model small yet critical physical details in contact-rich object manipulation. We propose a simple iterative improvement algorithm that uses real-world roll-out data to improve the fidelity of the world model, which can then, in turn, be used to generate supplemental synthetic data for improving the VLA model. In our experiments on a real robot, we use this approach to improve the performance of a state-of-the-art VLA model on multiple downstream tasks. We achieve a 39.2% absolute success rate improvement over the base policy and 11.6% improvement from training with the generated synthetic rollouts. Videos can be found at this anonymous website: https://sites.google.com/view/vla-w", "AI": {"tldr": "通过迭代在线交互提高视觉-语言-行动（VLA）模型的性能和可靠性。", "motivation": "收集现实世界中的策略回滚数据成本高昂，现有世界模型缺乏足够的物理真实感来改进政策。因此，论文旨在探索通过学习仿真器生成额外的数据以提升VLA模型的表现。", "method": "提出了一种简单的迭代改进算法，利用真实世界的回滚数据提高世界模型的精确度，进而使用此模型生成补充合成数据用于改善VLA模型。", "result": "在实际机器人实验中，该方法使得一个最先进的VLA模型在多个下游任务中的表现有所提升，成功率提高了39.2%，通过训练生成的数据提升了11.6%的成功率。", "conclusion": "迭代改进算法成功地利用合成数据提高了VLA模型的性能和可靠性，在现实世界的应用中展示了其有效性。"}}
{"id": "2602.12062", "pdf": "https://arxiv.org/pdf/2602.12062", "abs": "https://arxiv.org/abs/2602.12062", "authors": ["Xuewu Lin", "Tianwei Lin", "Yun Du", "Hongyu Xie", "Yiwei Jin", "Jiawei Li", "Shijie Wu", "Qingze Wang", "Mengdi Li", "Mengao Zhao", "Ziang Li", "Chaodong Huang", "Hongzhe Bi", "Lichao Huang", "Zhizhong Su"], "title": "HoloBrain-0 Technical Report", "categories": ["cs.RO"], "comment": "32 pages", "summary": "In this work, we introduce HoloBrain-0, a comprehensive Vision-Language-Action (VLA) framework that bridges the gap between foundation model research and reliable real-world robot deployment. The core of our system is a novel VLA architecture that explicitly incorporates robot embodiment priors, including multi-view camera parameters and kinematic descriptions (URDF), to enhance 3D spatial reasoning and support diverse embodiments. We validate this design through a scalable ``pre-train then post-train\" paradigm, achieving state-of-the-art results on simulation benchmarks such as RoboTwin 2.0, LIBERO, and GenieSim, as well as strong results on challenging long-horizon real-world manipulation tasks. Notably, our efficient 0.2B-parameter variant rivals significantly larger baselines, enabling low-latency on-device deployment. To further accelerate research and practical adoption, we fully open-source the entire HoloBrain ecosystem, which includes: (1) powerful pre-trained VLA foundations; (2) post-trained checkpoints for multiple simulation suites and real-world tasks; and (3) RoboOrchard, a full-stack VLA infrastructure for data curation, model training and deployment. Together with standardized data collection protocols, this release provides the community with a complete, reproducible path toward high-performance robotic manipulation.", "AI": {"tldr": "介绍HoloBrain-0，一种结合视觉、语言和行动的框架，用于机器人部署。", "motivation": "通过引入新的VLA架构来增强3D空间推理并支持多样化身体表现，以解决基础模型研究与可靠现实世界机器人部署之间的差距。", "method": "采用“预训练后微调”范式验证设计，并利用开源HoloBrain生态系统实现。", "result": "在多个仿真基准和挑战性的长时域真实场景操纵任务中取得最先进的结果。", "conclusion": "提供一个完整的，可重复的路径向高性能机器人操作迈进。"}}
{"id": "2602.12058", "pdf": "https://arxiv.org/pdf/2602.12058", "abs": "https://arxiv.org/abs/2602.12058", "authors": ["Zhiyong Chen", "Jialun Cao", "Chang Xu", "Shing-Chi Cheung"], "title": "ModelWisdom: An Integrated Toolkit for TLA+ Model Visualization, Digest and Repair", "categories": ["cs.SE", "cs.AI", "cs.FL"], "comment": "Accepted by FM 2026 Research Track (Tool)", "summary": "Model checking in TLA+ provides strong correctness guarantees, yet practitioners continue to face significant challenges in interpreting counterexamples, understanding large state-transition graphs, and repairing faulty models. These difficulties stem from the limited explainability of raw model-checker output and the substantial manual effort required to trace violations back to source specifications. Although the TLA+ Toolbox includes a state diagram viewer, it offers only a static, fully expanded graph without folding, color highlighting, or semantic explanations, which limits its scalability and interpretability. We present ModelWisdom, an interactive environment that uses visualization and large language models to make TLA+ model checking more interpretable and actionable. ModelWisdom offers: (i) Model Visualization, with colorized violation highlighting, click-through links from transitions to TLA+ code, and mapping between violating states and broken properties; (ii) Graph Optimization, including tree-based structuring and node/edge folding to manage large models; (iii) Model Digest, which summarizes and explains subgraphs via large language models (LLMs) and performs preprocessing and partial explanations; and (iv) Model Repair, which extracts error information and supports iterative debugging. Together, these capabilities turn raw model-checker output into an interactive, explainable workflow, improving understanding and reducing debugging effort for nontrivial TLA+ specifications. The website to ModelWisdom is available: https://model-wisdom.pages.dev. A demonstrative video can be found at https://www.youtube.com/watch?v=plyZo30VShA.", "AI": {"tldr": "提出了ModelWisdom工具包，通过可视化和大语言模型来提升TLA+模型检查的可解释性和操作性。", "motivation": "解决TLA+模型检查中对反例的理解、大规模状态转换图的解读以及修复错误模型面临的挑战。现有工具存在解释能力不足和手动工作量大的问题。", "method": "ModelWisdom提供四种功能：可视化，图形优化，模型摘要及修复；通过这些功能将原始模型检查输出转化为交互式可解释的工作流程，改善理解和减少调试时间。", "result": "提供了交互式的环境来提升TLA+模型的可理解性和操作性，从而帮助用户更好地处理和理解复杂的TLM+规格说明。", "conclusion": "ModelWisdom通过其综合工具包增强了对TLA+模型检查的理解和支持，实现了更有效的错误识别、调试和修复过程。"}}
{"id": "2602.12056", "pdf": "https://arxiv.org/pdf/2602.12056", "abs": "https://arxiv.org/abs/2602.12056", "authors": ["Xinyu Yang", "Chenlong Deng", "Tongyu Wen", "Binyu Xie", "Zhicheng Dou"], "title": "LawThinker: A Deep Research Legal Agent in Dynamic Environments", "categories": ["cs.AI"], "comment": null, "summary": "Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To address this, we propose LawThinker, an autonomous legal research agent that adopts an Explore-Verify-Memorize strategy for dynamic judicial environments. The core idea is to enforce verification as an atomic operation after every knowledge exploration step. A DeepVerifier module examines each retrieval result along three dimensions of knowledge accuracy, fact-law relevance, and procedural compliance, with a memory module for cross-round knowledge reuse in long-horizon tasks. Experiments on the dynamic benchmark J1-EVAL show that LawThinker achieves a 24% improvement over direct reasoning and an 11% gain over workflow-based methods, with particularly strong improvements on process-oriented metrics. Evaluations on three static benchmarks further confirm its generalization capability. The code is available at https://github.com/yxy-919/LawThinker-agent .", "AI": {"tldr": "提出了一种名为LawThinker的法律研究代理，该代理采用探索、验证和记忆策略来处理动态司法环境中的问题。", "motivation": "现有方法缺乏中间推理步骤的验证机制，可能导致错误传播。LawThinker旨在通过在每一步后进行验证来解决这一问题。", "method": "LawThinker使用一个深度验证模块检查知识准确性、事实与法律的相关性以及程序合规性，并利用记忆模块实现跨回合的知识重用。", "result": "实验表明，LawThinker在动态基准J1-EVAL中比直接推理和基于工作流的方法分别提高了24%和11%，特别是在过程相关的指标上表现优异。静态基准测试进一步证实了其泛化能力。", "conclusion": "LawThinker通过验证机制确保法律推理的程序合规性，提升了处理动态司法环境的能力，并展示了良好的性能与泛化能力。"}}
{"id": "2602.12055", "pdf": "https://arxiv.org/pdf/2602.12055", "abs": "https://arxiv.org/abs/2602.12055", "authors": ["Amath Sow", "Mauricio Rodriguez Cesen", "Fabiola Martins Campos de Oliveira", "Mariusz Wzorek", "Daniel de Leng", "Mattias Tiger", "Fredrik Heintz", "Christian Esteve Rothenberg"], "title": "Multi UAVs Preflight Planning in a Shared and Dynamic Airspace", "categories": ["cs.AI", "cs.MA", "cs.RO"], "comment": "AAMAS 2026 accepted paper", "summary": "Preflight planning for large-scale Unmanned Aerial Vehicle (UAV) fleets in dynamic, shared airspace presents significant challenges, including temporal No-Fly Zones (NFZs), heterogeneous vehicle profiles, and strict delivery deadlines. While Multi-Agent Path Finding (MAPF) provides a formal framework, existing methods often lack the scalability and flexibility required for real-world Unmanned Traffic Management (UTM). We propose DTAPP-IICR: a Delivery-Time Aware Prioritized Planning method with Incremental and Iterative Conflict Resolution. Our framework first generates an initial solution by prioritizing missions based on urgency. Secondly, it computes roundtrip trajectories using SFIPP-ST, a novel 4D single-agent planner (Safe Flight Interval Path Planning with Soft and Temporal Constraints). SFIPP-ST handles heterogeneous UAVs, strictly enforces temporal NFZs, and models inter-agent conflicts as soft constraints. Subsequently, an iterative Large Neighborhood Search, guided by a geometric conflict graph, efficiently resolves any residual conflicts. A completeness-preserving directional pruning technique further accelerates the 3D search. On benchmarks with temporal NFZs, DTAPP-IICR achieves near-100% success with fleets of up to 1,000 UAVs and gains up to 50% runtime reduction from pruning, outperforming batch Enhanced Conflict-Based Search in the UTM context. Scaling successfully in realistic city-scale operations where other priority-based methods fail even at moderate deployments, DTAPP-IICR is positioned as a practical and scalable solution for preflight planning in dense, dynamic urban airspace.", "AI": {"tldr": "本文提出了一种用于大型无人机群在动态空域中进行起飞前规划的新方法DTAPP-IICR。", "motivation": "现有的多智能体路径寻找方法缺乏处理大规模无人机编队时所需的可扩展性和灵活性。因此，文章旨在开发一种新的方法来解决这一问题。", "method": "该方法首先基于紧急程度优先生成初步解决方案，然后使用SFIPP-ST计算往返轨迹，并通过迭代的大邻域搜索和方向性修剪技术解决冲突。", "result": "实验结果表明，在具有时间禁飞区的基准上，DTAPP-IICR能够在大型无人机编队中达到接近100%的成功率，并且与传统的批次增强冲突基于搜索方法相比，提高了50%的运行效率。", "conclusion": "DTAPP-IICR作为一种实用和可扩展的方法，在密集、动态的城市空域中的起飞前规划任务上具有显著优势。"}}
{"id": "2602.12047", "pdf": "https://arxiv.org/pdf/2602.12047", "abs": "https://arxiv.org/abs/2602.12047", "authors": ["Anutam Srinivasan", "Antoine Leeman", "Glen Chou"], "title": "Safety Beyond the Training Data: Robust Out-of-Distribution MPC via Conformalized System Level Synthesis", "categories": ["cs.RO", "cs.LG", "eess.SY", "math.OC"], "comment": null, "summary": "We present a novel framework for robust out-of-distribution planning and control using conformal prediction (CP) and system level synthesis (SLS), addressing the challenge of ensuring safety and robustness when using learned dynamics models beyond the training data distribution. We first derive high-confidence model error bounds using weighted CP with a learned, state-control-dependent covariance model. These bounds are integrated into an SLS-based robust nonlinear model predictive control (MPC) formulation, which performs constraint tightening over the prediction horizon via volume-optimized forward reachable sets. We provide theoretical guarantees on coverage and robustness under distributional drift, and analyze the impact of data density and trajectory tube size on prediction coverage. Empirically, we demonstrate our method on nonlinear systems of increasing complexity, including a 4D car and a {12D} quadcopter, improving safety and robustness compared to fixed-bound and non-robust baselines, especially outside of the data distribution.", "AI": {"tldr": "该论文提出了一种新的框架，利用符合预测和系统级综合进行鲁棒的出界分布规划与控制。", "motivation": "旨在解决使用学习的动力学模型在训练数据之外的安全性和稳健性问题。", "method": "通过加权符合预测导出高置信度模型误差界限，并将其整合到基于SLS的鲁棒非线性模型预测控制形式中，实现约束收紧。", "result": "理论保证了分布漂移下的覆盖和鲁棒性，并分析了数据密度和轨迹管大小对预测覆盖率的影响。实验证明在4D汽车和12D四旋翼等复杂系统中的安全性与稳健性优于固定边界和非鲁棒基准，尤其是在出界分布之外。", "conclusion": "提出的方法能够在训练数据之外提供安全且鲁棒的规划控制，并通过实证测试证明了其有效性。"}}
{"id": "2602.12045", "pdf": "https://arxiv.org/pdf/2602.12045", "abs": "https://arxiv.org/abs/2602.12045", "authors": ["Jed A. Duersch", "Elohan Veillon", "Astrid Klipfel", "Adlane Sayede", "Zied Bouraoui"], "title": "Fourier Transformers for Latent Crystallographic Diffusion and Generative Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The discovery of new crystalline materials calls for generative models that handle periodic boundary conditions, crystallographic symmetries, and physical constraints, while scaling to large and structurally diverse unit cells. We propose a reciprocal-space generative pipeline that represents crystals through a truncated Fourier transform of the species-resolved unit-cell density, rather than modeling atomic coordinates directly. This representation is periodicity-native, admits simple algebraic actions of space-group symmetries, and naturally supports variable atomic multiplicities during generation, addressing a common limitation of particle-based approaches. Using only nine Fourier basis functions per spatial dimension, our approach reconstructs unit cells containing up to 108 atoms per chemical species. We instantiate this pipeline with a transformer variational autoencoder over complex-valued Fourier coefficients, and a latent diffusion model that generates in the compressed latent space. We evaluate reconstruction and latent diffusion on the LeMaterial benchmark and compare unconditional generation against coordinate-based baselines in the small-cell regime ($\\leq 16$ atoms per unit cell).", "AI": {"tldr": "该论文提出了一种基于傅里叶变换的晶体生成模型，用于处理周期性边界条件和晶体对称性。", "motivation": "发现新材料需要能够应对周期性边界条件、晶格对称性和物理约束的生成模型，并且能够在大规模结构多样性的单元胞中扩展。", "method": "该方法通过傅里叶变换表示晶体，使用变压器变分自动编码器和潜在扩散模型在压缩后的潜在空间内进行生成。", "result": "实验评估了重建和潜在扩散效果，在小单元晶胞（≤16个原子）的无条件生成方面与基线坐标法进行了对比。", "conclusion": "该方法成功地提高了晶体生成的质量，展示了对周期性边界条件、物理约束及多样结构的有效处理能力。"}}
{"id": "2602.12044", "pdf": "https://arxiv.org/pdf/2602.12044", "abs": "https://arxiv.org/abs/2602.12044", "authors": ["Banglei Guan", "Jing Tao", "Liang Xu", "Dongcai Tan", "Pengju Sun", "Jianbing Liu", "Yang Shang", "Qifeng Yu"], "title": "A DMD-Based Adaptive Modulation Method for High Dynamic Range Imaging in High-Glare Environments", "categories": ["cs.CV"], "comment": "This paper has been accepted by Experimental Mechanics", "summary": "Background The accuracy of photomechanics measurements critically relies on image quality,particularly under extreme illumination conditions such as welding arc monitoring and polished metallic surface analysis. High dynamic range (HDR) imaging above 120 dB is essential in these contexts. Conventional CCD/CMOS sensors, with dynamic ranges typically below 70 dB, are highly susceptible to saturation under glare, resulting in irreversible loss of detail and significant errors in digital image correlation (DIC). Methods This paper presents an HDR imaging system that leverages the spatial modulation capability of a digital micromirror device (DMD). The system architecture enables autonomous regional segmentation and adaptive exposure control for high-dynamic-range scenes through an integrated framework comprising two synergistic subsystems: a DMD-based optical modulation unit and an adaptive computational imaging pipeline. Results The system achieves a measurable dynamic range of 127 dB, effectively eliminating satu ration artifacts under high glare. Experimental results demonstrate a 78% reduction in strain error and improved DIC positioning accuracy, confirming reliable performance across extreme intensity variations. Conclusion The DMD-based system provides high fidelity adaptive HDR imaging, overcoming key limitations of conventional sensors. It exhibits strong potential for optical metrology and stress analysis in high-glare environments where traditional methods are inadequate.", "AI": {"tldr": "本文提出了一种基于DMD的自适应调制方法，用于高光晕环境下的高动态范围成像。", "motivation": "在极端照明条件下（如焊接弧监测和抛光金属表面分析），图像质量对光力学测量精度至关重要。传统CCD/CMOS传感器在强光下容易饱和，导致细节丢失和误差增加，因此需要一种新的HDR技术来提高图像质量。", "method": "该系统通过一个集成了DMD光学调制单元和自适应计算成像管道的框架，实现了区域分割和自适应曝光控制，从而在高动态范围场景中消除饱和现象。", "result": "系统达到了127分贝的实际可测量动态范围，并减少了78%的应变误差，提高了DIC定位精度，在极端强度变化下表现出可靠的性能。", "conclusion": "基于DMD的系统提供了高质量自适应HDR成像技术，克服了传统传感器的关键限制，在高光晕环境中具有显著优势。"}}
{"id": "2602.12038", "pdf": "https://arxiv.org/pdf/2602.12038", "abs": "https://arxiv.org/abs/2602.12038", "authors": ["Yuejun Guo", "Qiang Hu", "Qiang Tang", "Yves Le Traon"], "title": "An Empirical Study of the Imbalance Issue in Software Vulnerability Detection", "categories": ["cs.SE", "cs.AI"], "comment": "This paper was accepted by the 28th European Symposium on Research in Computer Security (ESORICS), 2023", "summary": "Vulnerability detection is crucial to protect software security. Nowadays, deep learning (DL) is the most promising technique to automate this detection task, leveraging its superior ability to extract patterns and representations within extensive code volumes. Despite its promise, DL-based vulnerability detection remains in its early stages, with model performance exhibiting variability across datasets. Drawing insights from other well-explored application areas like computer vision, we conjecture that the imbalance issue (the number of vulnerable code is extremely small) is at the core of the phenomenon. To validate this, we conduct a comprehensive empirical study involving nine open-source datasets and two state-of-the-art DL models. The results confirm our conjecture. We also obtain insightful findings on how existing imbalance solutions perform in vulnerability detection. It turns out that these solutions perform differently as well across datasets and evaluation metrics. Specifically: 1) Focal loss is more suitable to improve the precision, 2) mean false error and class-balanced loss encourages the recall, and 3) random over-sampling facilitates the F1-measure. However, none of them excels across all metrics. To delve deeper, we explore external influences on these solutions and offer insights for developing new solutions.", "AI": {"tldr": "本文研究了软件漏洞检测中的不平衡问题，并测试了不同的解决方案。", "motivation": "深度学习在自动化的软件漏洞检测中展现出巨大潜力，但模型性能因数据集差异而不同。作者推测这与训练集中正样本数量少有关，通过实验验证这一假设并探讨如何解决。", "method": "使用九个开源数据集和两个先进的深度学习模型进行研究，评估了多种不平衡解决方案的效果。", "result": "结果表明，不同的解决方案在提高精度、召回率或F1度量方面表现出差异性，但没有一种方案可以同时在所有指标上取得优异表现。", "conclusion": "深入探讨外部因素对这些解决方案的影响，并提出开发新解决方案的建议。"}}
{"id": "2602.12032", "pdf": "https://arxiv.org/pdf/2602.12032", "abs": "https://arxiv.org/abs/2602.12032", "authors": ["Jingxian Lu", "Wenke Xia", "Yuxuan Wu", "Zhiwu Lu", "Di Hu"], "title": "When would Vision-Proprioception Policies Fail in Robotic Manipulation?", "categories": ["cs.RO"], "comment": "Accepted by ICLR 2026", "summary": "Proprioceptive information is critical for precise servo control by providing real-time robotic states. Its collaboration with vision is highly expected to enhance performances of the manipulation policy in complex tasks. However, recent studies have reported inconsistent observations on the generalization of vision-proprioception policies. In this work, we investigate this by conducting temporally controlled experiments. We found that during task sub-phases that robot's motion transitions, which require target localization, the vision modality of the vision-proprioception policy plays a limited role. Further analysis reveals that the policy naturally gravitates toward concise proprioceptive signals that offer faster loss reduction when training, thereby dominating the optimization and suppressing the learning of the visual modality during motion-transition phases. To alleviate this, we propose the Gradient Adjustment with Phase-guidance (GAP) algorithm that adaptively modulates the optimization of proprioception, enabling dynamic collaboration within the vision-proprioception policy. Specifically, we leverage proprioception to capture robotic states and estimate the probability of each timestep in the trajectory belonging to motion-transition phases. During policy learning, we apply fine-grained adjustment that reduces the magnitude of proprioception's gradient based on estimated probabilities, leading to robust and generalizable vision-proprioception policies. The comprehensive experiments demonstrate GAP is applicable in both simulated and real-world environments, across one-arm and dual-arm setups, and compatible with both conventional and Vision-Language-Action models. We believe this work can offer valuable insights into the development of vision-proprioception policies in robotic manipulation.", "AI": {"tldr": "本文研究了在机器人操作中视觉和本体感觉策略的失败情况，并提出了一种适应性优化算法。", "motivation": "近期研究表明视觉-本体感觉策略在复杂任务中的泛化表现不一，作者希望通过控制实验揭示其原因及改进方法。", "method": "通过设计时空受控试验分析了机器人操作过程中不同阶段视觉和本体感觉作用的差异，并提出了一种基于相位引导的梯度调整算法（GAP）来优化策略学习过程。", "result": "实验证明，GAP算法能够增强视觉-本体感觉策略在模拟与实际场景中的适应性和泛化能力，适用于单臂和双臂系统。", "conclusion": "该研究为改进机器人操作中视觉-本体感觉策略提供了有价值的见解。"}}
{"id": "2602.12028", "pdf": "https://arxiv.org/pdf/2602.12028", "abs": "https://arxiv.org/abs/2602.12028", "authors": ["Althaf P V", "Amit Chattopadhyay", "Osamu Saeki"], "title": "An Improved FPT Algorithm for Computing the Interleaving Distance between Merge Trees via Path-Preserving Maps", "categories": ["cs.CG", "cs.DS"], "comment": "42 pages", "summary": "A merge tree is a fundamental topological structure used to capture the sub-level set (and similarly, super-level set) topology in scalar data analysis. The interleaving distance is a theoretically sound, stable metric for comparing merge trees. However, computing this distance exactly is NP-hard. First fixed-parameter tractable (FPT) algorithm for it's exact computation introduces the concept of an $\\varepsilon$-good map between two merge trees, where $\\varepsilon$ is a candidate value for the interleaving distance. The complexity of their algorithm is $O(2^{2τ}(2τ)^{2τ+2}\\cdot n^2\\log^3n)$ where $τ$ is the degree-bound parameter and $n$ is the total number of nodes in both the merge trees. Their algorithm exhibits exponential complexity in $τ$, which increases with the increasing value of $\\varepsilon$. In the current paper, we propose an improved FPT algorithm for computing the $\\varepsilon$-good map between two merge trees. Our algorithm introduces two new parameters, $η_f$ and $η_g$, corresponding to the numbers of leaf nodes in the merge trees $M_f$ and $M_g$, respectively. This parametrization is motivated by the observation that a merge tree can be decomposed into a collection of unique leaf-to-root paths. The proposed algorithm achieves a complexity of $O\\!\\left(n^2\\log n+η_g^{η_f}(η_f+η_g)\\, n \\log n \\right)$. To obtain this reduced complexity, we assume that number of possible $\\varepsilon$-good maps from $M_f$ to $M_g$ does not exceed that from $M_g$ to $M_f$. Notably, the parameters $η_f$ and $η_g$ are independent of the choice of $\\varepsilon$. Compared to their algorithm, our approach substantially reduces the search space for computing an optimal $\\varepsilon$-good map. We also provide a formal proof of correctness for the proposed algorithm.", "AI": {"tldr": "提出了改进的FPT算法以计算两个合并树之间的ε-good映射，从而提高计算效率。", "motivation": "为了解决现有计算交错距离算法在τ参数上的指数复杂度问题，并通过引入新参数η_f和η_g来优化搜索空间。", "method": "利用新的参数化方法减少了算法的复杂性，并假设从Mf到Mg的ε-good映射的数量不超过从Mg到Mf的数量，从而实现更高效的计算。", "result": "提出了一个复杂度为O(n^2*log n+η_g^η_f*(η_f+η_g)*n*log n)的新算法，相比现有方法在搜索空间上进行了显著的优化。", "conclusion": "通过引入新的参数化和假设条件，新算法提供了计算ε-good映射的有效方法，并且证明了其正确性。"}}
{"id": "2602.12024", "pdf": "https://arxiv.org/pdf/2602.12024", "abs": "https://arxiv.org/abs/2602.12024", "authors": ["Jiarui Li", "Federico Pecora", "Runyu Zhang", "Gioele Zardini"], "title": "Adaptive-Horizon Conflict-Based Search for Closed-Loop Multi-Agent Path Finding", "categories": ["cs.RO"], "comment": null, "summary": "MAPF is a core coordination problem for large robot fleets in automated warehouses and logistics. Existing approaches are typically either open-loop planners, which generate fixed trajectories and struggle to handle disturbances, or closed-loop heuristics without reliable performance guarantees, limiting their use in safety-critical deployments. This paper presents ACCBS, a closed-loop algorithm built on a finite-horizon variant of CBS with a horizon-changing mechanism inspired by iterative deepening in MPC. ACCBS dynamically adjusts the planning horizon based on the available computational budget, and reuses a single constraint tree to enable seamless transitions between horizons. As a result, it produces high-quality feasible solutions quickly while being asymptotically optimal as the budget increases, exhibiting anytime behavior. Extensive case studies demonstrate that ACCBS combines flexibility to disturbances with strong performance guarantees, effectively bridging the gap between theoretical optimality and practical robustness for large-scale robot deployment.", "AI": {"tldr": "本文提出了一种自适应规划窗口的冲突基搜索算法ACCBS，以解决大规模机器人编队在自动化仓库和物流中的路径规划问题。", "motivation": "现有方法通常为固定轨迹规划器或无可靠性能保证的闭环启发式方法，难以应对干扰且无法确保安全关键部署中的可靠性。", "method": "基于有限窗口版本的CBS并结合模型预测控制中的迭代深化机制，动态调整规划窗口，并利用单一约束树实现不同窗口间的平滑过渡。", "result": "ACCBS能够快速生成高质量解方案，在计算预算增加时表现出渐近最优性与任何时间行为。实验表明其具有灵活性和强大性能保证。", "conclusion": "ACCBS结合了理论上的最优性和实际鲁棒性的优势，解决了大规模机器人部署中的路径规划问题。"}}
{"id": "2602.12013", "pdf": "https://arxiv.org/pdf/2602.12013", "abs": "https://arxiv.org/abs/2602.12013", "authors": ["Xiuping Wu", "Zhao Yu", "Yuxin Cheng", "Ngai Wong", "Liangjun Ke", "Tapas Mishra", "Konstantinos V. Katsikopoulos"], "title": "InjectRBP: Steering Large Language Model Reasoning Behavior via Pattern Injection", "categories": ["cs.AI"], "comment": null, "summary": "Reasoning can significantly enhance the performance of Large Language Models. While recent studies have exploited behavior-related prompts adjustment to enhance reasoning, these designs remain largely intuitive and lack a systematic analysis of the underlying behavioral patterns. Motivated by this, we investigate how models' reasoning behaviors shape reasoning from the perspective of behavioral patterns. We observe that models exhibit adaptive distributions of reasoning behaviors when responding to specific types of questions, and that structurally injecting these patterns can substantially influence the quality of the models' reasoning processes and outcomes. Building on these findings, we propose two optimization methods that require no parameter updates: InjectCorrect and InjectRLOpt. InjectCorrect guides the model by imitating behavioral patterns derived from its own past correct answers. InjectRLOpt learns a value function from historical behavior-pattern data and, via our proposed Reliability-Aware Softmax Policy, generates behavioral injectant during inference to steer the reasoning process. Our experiments demonstrate that both methods can improve model performance across various reasoning tasks without requiring any modifications to model parameters, achieving gains of up to 5.34% and 8.67%, respectively.", "AI": {"tldr": "通过注入模式来引导大型语言模型的推理行为，提升其性能。", "motivation": "现有研究主要依赖于直观调整提示词以增强模型推理能力，缺乏对潜在行为模式系统的分析。作者意图从行为模式角度探索如何影响和优化模型推理。", "method": "提出InjectCorrect方法模仿过去正确答案的行为模式，并提出InjectRLOpt方法通过可靠性感知的softmax策略生成注入物来引导推理过程。", "result": "实验结果显示，两种方法无需参数修改即可提升模型在各种推理任务中的性能，改进幅度分别达5.34%和8.67%。", "conclusion": "基于行为模式注入的方法有效改善了大型语言模型的推理质量与效果。"}}
{"id": "2602.12012", "pdf": "https://arxiv.org/pdf/2602.12012", "abs": "https://arxiv.org/abs/2602.12012", "authors": ["Muhammad Farhan Ahmed", "Vincent Frémont"], "title": "Decentralized Multi-Robot Obstacle Detection and Tracking in a Maritime Scenario", "categories": ["cs.RO"], "comment": "10 pages, 10 figures", "summary": "Autonomous aerial-surface robot teams are promising for maritime monitoring. Robust deployment requires reliable perception over reflective water and scalable coordination under limited communication. We present a decentralized multi-robot framework for detecting and tracking floating containers using multiple UAVs cooperating with an autonomous surface vessel. Each UAV performs YOLOv8 and stereo-disparity-based visual detection, then tracks targets with per-object EKFs using uncertainty-aware data association. Compact track summaries are exchanged and fused conservatively via covariance intersection, ensuring consistency under unknown correlations. An information-driven assignment module allocates targets and selects UAV hover viewpoints by trading expected uncertainty reduction against travel effort and safety separation. Simulation results in a maritime scenario demonstrate improved coverage, localization accuracy, and tracking consistency while maintaining modest communication requirements.", "AI": {"tldr": "提出了一种去中心化的多机器人框架，用于在海上场景中使用多个无人机与自主水面船合作检测和跟踪浮动容器。", "motivation": "为了实现可靠的感知和可扩展的协调，在反射性水域中的自动航拍-表面机器人团队需要一个可靠的方法进行障碍物检测和定位。", "method": "每个无人机执行YOLOv8和立体视差基视觉检测，然后使用不确定性感知数据关联跟踪目标。通过协方差交叉交换并保守地融合简化的轨迹摘要以确保一致性。信息驱动分配模块根据预期的不确定度减少与旅行努力和安全距离进行任务分配。", "result": "模拟结果表明，在海上场景中提高了覆盖范围、定位精度和跟踪一致性，同时保持了适度的通信需求。", "conclusion": "所提出的去中心化多机器人框架在海洋监测方面表现出色。通过高效的协作实现了更好的性能并维持了较低的通讯成本。"}}
{"id": "2602.12009", "pdf": "https://arxiv.org/pdf/2602.12009", "abs": "https://arxiv.org/abs/2602.12009", "authors": ["Luiz Pereira", "Mirko Perkusich", "Dalton Valadares", "Kyller Gorgônio"], "title": "On the Sensitivity of Firing Rate-Based Federated Spiking Neural Networks to Differential Privacy", "categories": ["cs.LG", "cs.AI"], "comment": "To be published in 2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "summary": "Federated Neuromorphic Learning (FNL) enables energy-efficient and privacy-preserving learning on devices without centralizing data. However, real-world deployments require additional privacy mechanisms that can significantly alter training signals. This paper analyzes how Differential Privacy (DP) mechanisms, specifically gradient clipping and noise injection, perturb firing-rate statistics in Spiking Neural Networks (SNNs) and how these perturbations are propagated to rate-based FNL coordination. On a speech recognition task under non-IID settings, ablations across privacy budgets and clipping bounds reveal systematic rate shifts, attenuated aggregation, and ranking instability during client selection. Moreover, we relate these shifts to sparsity and memory indicators. Our findings provide actionable guidance for privacy-preserving FNL, specifically regarding the balance between privacy strength and rate-dependent coordination.", "AI": {"tldr": "本文研究了差分隐私机制对基于发放率的联邦尖峰神经网络训练信号的影响。", "motivation": "为了实现在不集中数据的情况下进行能效高且保护隐私的学习，本文探讨如何通过差分隐私机制来平衡隐私保护和学习性能之间的关系。", "method": "使用梯度裁剪与噪声注入这两种差分隐私技术，在语音识别任务中研究了对发放率统计的影响以及在非独立同分布（non-IID）数据下的影响。", "result": "实验结果表明，不同的隐私预算和裁剪边界导致发放率出现系统性偏移，聚合效率下降，并且客户端选择过程中稳定性较差。这些变化与稀疏性和内存指标有关联。", "conclusion": "本文的结果为联邦神经形态学习中的隐私保护提供了具体指导，特别是在如何平衡隐私强度和发放率依赖协调之间的关系方面。"}}
{"id": "2602.12004", "pdf": "https://arxiv.org/pdf/2602.12004", "abs": "https://arxiv.org/abs/2602.12004", "authors": ["Robert Cronshaw", "Konstantinos Vilouras", "Junyu Yan", "Yuning Du", "Feng Chen", "Steven McDonagh", "Sotirios A. Tsaftaris"], "title": "CSEval: A Framework for Evaluating Clinical Semantics in Text-to-Image Generation", "categories": ["cs.AI"], "comment": null, "summary": "Text-to-image generation has been increasingly applied in medical domains for various purposes such as data augmentation and education. Evaluating the quality and clinical reliability of these generated images is essential. However, existing methods mainly assess image realism or diversity, while failing to capture whether the generated images reflect the intended clinical semantics, such as anatomical location and pathology. In this study, we propose the Clinical Semantics Evaluator (CSEval), a framework that leverages language models to assess clinical semantic alignment between the generated images and their conditioning prompts. Our experiments show that CSEval identifies semantic inconsistencies overlooked by other metrics and correlates with expert judgment. CSEval provides a scalable and clinically meaningful complement to existing evaluation methods, supporting the safe adoption of generative models in healthcare.", "AI": {"tldr": "提出了一种评估文本到图像生成在医疗领域中临床语义一致性的框架CSEval。", "motivation": "现有的评价方法主要关注图像的现实感或多样性，而未能捕捉到生成图像是否准确反映了预期的临床语义，如解剖位置和病理情况。因此提出了CSEval来评估文本到图像生成在医疗领域的临床可靠性。", "method": "利用语言模型来评估生成的图像与其条件提示之间的临床语义一致性，并通过实验验证了CSEval能够识别出其他度量标准所忽略的语义不一致，且与专家判断具有相关性。", "result": "实验表明，CSEval在检测语义不一致性方面优于现有的评价方法，并能提供可扩展、临床有意义的结果，有助于医疗领域中生成模型的安全采用。", "conclusion": "CSEval为评估文本到图像生成的临床可靠性提供了一种有效的方法，能够补充现有度量标准并支持在医疗领域的安全应用。"}}
{"id": "2602.12003", "pdf": "https://arxiv.org/pdf/2602.12003", "abs": "https://arxiv.org/abs/2602.12003", "authors": ["Min-Seop Kwak", "Minkyung Kwon", "Jinhyeok Choi", "Jiho Park", "Seungryong Kim"], "title": "Projected Representation Conditioning for High-fidelity Novel View Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "We propose a novel framework for diffusion-based novel view synthesis in which we leverage external representations as conditions, harnessing their geometric and semantic correspondence properties for enhanced geometric consistency in generated novel viewpoints. First, we provide a detailed analysis exploring the correspondence capabilities emergent in the spatial attention of external visual representations. Building from these insights, we propose a representation-guided novel view synthesis through dedicated representation projection modules that inject external representations into the diffusion process, a methodology named ReNoV, short for representation-guided novel view synthesis. Our experiments show that this design yields marked improvements in both reconstruction fidelity and inpainting quality, outperforming prior diffusion-based novel-view methods on standard benchmarks and enabling robust synthesis from sparse, unposed image collections.", "AI": {"tldr": "本论文提出了一种新的框架，通过利用外部表示作为条件来增强生成的新视角中的几何一致性。", "motivation": "该研究旨在提高扩散模型在合成新视图时的几何一致性和图像质量。", "method": "基于空间注意力中出现的对应能力分析，提出了一个将外部表示投影到扩散过程的方法（ReNoV）以指导新颖视图合成。", "result": "实验表明，此设计显著提高了重建准确度和图像填充质量，并在标准基准测试中优于先前的扩散方法。", "conclusion": "该框架能够从稀疏、未对齐的图像集合中稳健地生成高质量的新视角。"}}
{"id": "2602.12002", "pdf": "https://arxiv.org/pdf/2602.12002", "abs": "https://arxiv.org/abs/2602.12002", "authors": ["Enrico Guerriero", "Kjersti Engan", "Øyvind Meinich-Bache"], "title": "Can Local Vision-Language Models improve Activity Recognition over Vision Transformers? -- Case Study on Newborn Resuscitation", "categories": ["cs.CV"], "comment": "Presented at the Satellite Workshop on Workshop 15: Generative AI for World Simulations and Communications & Celebrating 40 Years of Excellence in Education: Honoring Professor Aggelos Katsaggelos, IEEE International Conference on Image Processing (ICIP), 2025", "summary": "Accurate documentation of newborn resuscitation is essential for quality improvement and adherence to clinical guidelines, yet remains underutilized in practice. Previous work using 3D-CNNs and Vision Transformers (ViT) has shown promising results in detecting key activities from newborn resuscitation videos, but also highlighted the challenges in recognizing such fine-grained activities. This work investigates the potential of generative AI (GenAI) methods to improve activity recognition from such videos. Specifically, we explore the use of local vision-language models (VLMs), combined with large language models (LLMs), and compare them to a supervised TimeSFormer baseline. Using a simulated dataset comprising 13.26 hours of newborn resuscitation videos, we evaluate several zero-shot VLM-based strategies and fine-tuned VLMs with classification heads, including Low-Rank Adaptation (LoRA). Our results suggest that small (local) VLMs struggle with hallucinations, but when fine-tuned with LoRA, the results reach F1 score at 0.91, surpassing the TimeSformer results of 0.70.", "AI": {"tldr": "研究探讨了局部视觉语言模型在新生儿复苏视频活动识别中的应用，并与监督学习的TimeSFormer进行对比。", "motivation": "准确记录新生儿复苏过程对于质量改进和遵循临床指南至关重要，但实际使用中仍存在不足。通过探索生成式AI方法，尤其是结合大型语言模型的局部视觉语言模型，以期改善视频活动识别性能。", "method": "研究利用模拟数据集（包含13.26小时的新生儿复苏视频），评估了几种零样本策略以及带有分类头的微调视觉语言模型，并采用低秩适应方法进行实验。", "result": "结果显示，小型局部视觉语言模型在无指导情况下容易产生幻觉，但在使用LoRA技术进行微调后，其F1分数可达0.91，超过了TimeSFormer的0.70结果。", "conclusion": "结合大型语言模型的局部视觉语言模型，在新生儿复苏视频活动识别任务中展现出优于传统方法的结果。"}}
{"id": "2602.11988", "pdf": "https://arxiv.org/pdf/2602.11988", "abs": "https://arxiv.org/abs/2602.11988", "authors": ["Thibaud Gloaguen", "Niels Mündler", "Mark Müller", "Veselin Raychev", "Martin Vechev"], "title": "Evaluating AGENTS.md: Are Repository-Level Context Files Helpful for Coding Agents?", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "A widespread practice in software development is to tailor coding agents to repositories using context files, such as AGENTS.md, by either manually or automatically generating them. Although this practice is strongly encouraged by agent developers, there is currently no rigorous investigation into whether such context files are actually effective for real-world tasks. In this work, we study this question and evaluate coding agents' task completion performance in two complementary settings: established SWE-bench tasks from popular repositories, with LLM-generated context files following agent-developer recommendations, and a novel collection of issues from repositories containing developer-committed context files. Across multiple coding agents and LLMs, we find that context files tend to reduce task success rates compared to providing no repository context, while also increasing inference cost by over 20%. Behaviorally, both LLM-generated and developer-provided context files encourage broader exploration (e.g., more thorough testing and file traversal), and coding agents tend to respect their instructions. Ultimately, we conclude that unnecessary requirements from context files make tasks harder, and human-written context files should describe only minimal requirements.", "AI": {"tldr": "评估AGENTS.md文件是否对编码代理在实际任务中的表现有帮助。", "motivation": "尽管通过上下文文件定制代码代理的做法被广泛采用，但是缺乏对其有效性的严谨研究。作者希望填补这一空白。", "method": "使用流行仓库中的SWE-bench任务和包含开发人员提交的上下文文件的新问题集合来评估编码代理的任务完成性能。", "result": "发现与不提供仓库上下文相比，上下文文件通常会导致任务成功率降低，并且增加了20%以上的推理成本。无论是LLM生成还是开发者提供的上下文文件都鼓励更广泛的探索。", "conclusion": "不必要的上下文要求使得任务变得更难，建议人类编写的上下文文件应只描述最小的要求。"}}
{"id": "2602.11980", "pdf": "https://arxiv.org/pdf/2602.11980", "abs": "https://arxiv.org/abs/2602.11980", "authors": ["Wei Chen", "Yancheng Long", "Mingqiao Liu", "Haojie Ding", "Yankai Yang", "Hongyang Wei", "Yi-Fan Zhang", "Bin Wen", "Fan Yang", "Tingting Gao", "Han Li", "Long Chen"], "title": "Spatial Chain-of-Thought: Bridging Understanding and Generation Models for Spatial Reasoning Generation", "categories": ["cs.CV"], "comment": "19 pages, 4 figures", "summary": "While diffusion models have shown exceptional capabilities in aesthetic image synthesis, they often struggle with complex spatial understanding and reasoning. Existing approaches resort to Multimodal Large Language Models (MLLMs) to enhance this capability. However, they either incur high computational costs through joint training or suffer from spatial information loss when relying solely on textual prompts. To alleviate these limitations, we propose a Spatial Chain-of-Thought (SCoT) framework, a plug-and-play approach that effectively bridges the reasoning capabilities of MLLMs with the generative power of diffusion models. Specifically, we first enhance the diffusion model's layout awareness by training it on an interleaved text-coordinate instruction format. We then leverage state-of-the-art MLLMs as planners to generate comprehensive layout plans, transferring their spatial planning capabilities directly to the generation process. Extensive experiments demonstrate that our method achieves state-of-the-art performance on image generation benchmarks and significantly outperforms baselines on complex reasoning tasks, while also showing strong efficacy in image editing scenarios.", "AI": {"tldr": "提出了一种名为Spatial Chain-of-Thought (SCoT)的框架，用于改善扩散模型在空间理解和推理方面的表现。", "motivation": "现有的方法通过多模态大型语言模型来增强扩散模型的空间理解和生成能力，但它们要么需要高昂的计算成本进行联合训练，要么由于仅依赖文本提示而导致空间信息丢失。因此提出了SCoT框架解决这些问题。", "method": "首先通过训练扩散模型使用交错的文本-坐标指令格式来提高其布局意识；然后利用最先进的多模态大型语言模型作为规划器生成详细的布局计划，并直接将它们的空间规划能力转移到生成过程中。", "result": "实验结果表明，该方法在图像生成基准上达到了SOTA性能，在复杂推理任务中显著优于基线，并且在图像编辑场景中也表现出强大的效果。", "conclusion": "SCoT框架通过有效结合多模态大型语言模型的空间理解和扩散模型的生成能力，解决了现有方法中的限制。"}}
{"id": "2602.11978", "pdf": "https://arxiv.org/pdf/2602.11978", "abs": "https://arxiv.org/abs/2602.11978", "authors": ["Haojun Chen", "Zili Zou", "Chengdong Ma", "Yaoxiang Pu", "Haotong Zhang", "Yuanpei Chen", "Yaodong Yang"], "title": "Accelerating Robotic Reinforcement Learning with Agent Guidance", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) offers a powerful paradigm for autonomous robots to master generalist manipulation skills through trial-and-error. However, its real-world application is stifled by severe sample inefficiency. Recent Human-in-the-Loop (HIL) methods accelerate training by using human corrections, yet this approach faces a scalability barrier. Reliance on human supervisors imposes a 1:1 supervision ratio that limits fleet expansion, suffers from operator fatigue over extended sessions, and introduces high variance due to inconsistent human proficiency. We present Agent-guided Policy Search (AGPS), a framework that automates the training pipeline by replacing human supervisors with a multimodal agent. Our key insight is that the agent can be viewed as a semantic world model, injecting intrinsic value priors to structure physical exploration. By using executable tools, the agent provides precise guidance via corrective waypoints and spatial constraints for exploration pruning. We validate our approach on two tasks, ranging from precision insertion to deformable object manipulation. Results demonstrate that AGPS outperforms HIL methods in sample efficiency. This automates the supervision pipeline, unlocking the path to labor-free and scalable robot learning. Project website: https://agps-rl.github.io/agps.", "AI": {"tldr": "本文提出了一种名为Agent-guided Policy Search (AGPS) 的框架，该框架通过使用多模态代理来替换人类监督者，从而加速机器人强化学习的训练过程。", "motivation": "现有的Human-in-the-Loop（HIL）方法虽然能够通过人类纠正来提高机器人的训练效率，但是这种方式存在扩展性差、操作员疲劳以及操作一致性问题。因此需要一种替代方案来提升机器人强化学习的样本效率和可扩展性。", "method": "AGPS框架采用多模态代理作为语义世界模型，以注入先验价值来指导物理探索，通过使用执行工具提供精确的指引和空间约束，实现训练过程自动化。", "result": "实验结果表明，在精度插入与变形物体处理两种任务下，AGPS方法在样本效率上超过了现有的HIL方法。", "conclusion": "本文提出的AGPS框架实现了监督管道的自动化，并解锁了无劳动、可扩展的机器人学习路径。"}}
{"id": "2602.11973", "pdf": "https://arxiv.org/pdf/2602.11973", "abs": "https://arxiv.org/abs/2602.11973", "authors": ["Hua Xu", "Julián D. Arias-Londoño", "Juan I. Godino-Llorente"], "title": "Calibrated Bayesian Deep Learning for Explainable Decision Support Systems Based on Medical Imaging", "categories": ["cs.CV", "cs.LG"], "comment": "24 pages, 3 figures", "summary": "In critical decision support systems based on medical imaging, the reliability of AI-assisted decision-making is as relevant as predictive accuracy. Although deep learning models have demonstrated significant accuracy, they frequently suffer from miscalibration, manifested as overconfidence in erroneous predictions. To facilitate clinical acceptance, it is imperative that models quantify uncertainty in a manner that correlates with prediction correctness, allowing clinicians to identify unreliable outputs for further review. In order to address this necessity, the present paper proposes a generalizable probabilistic optimization framework grounded in Bayesian deep learning. Specifically, a novel Confidence-Uncertainty Boundary Loss (CUB-Loss) is introduced that imposes penalties on high-certainty errors and low-certainty correct predictions, explicitly enforcing alignment between prediction correctness and uncertainty estimates. Complementing this training-time optimization, a Dual Temperature Scaling (DTS) strategy is devised for post-hoc calibration, further refining the posterior distribution to improve intuitive explainability. The proposed framework is validated on three distinct medical imaging tasks: automatic screening of pneumonia, diabetic retinopathy detection, and identification of skin lesions. Empirical results demonstrate that the proposed approach achieves consistent calibration improvements across diverse modalities, maintains robust performance in data-scarce scenarios, and remains effective on severely imbalanced datasets, underscoring its potential for real clinical deployment.", "AI": {"tldr": "提出了一种基于贝叶斯深度学习的校准方法，以提高医学影像辅助决策系统的可靠性与可解释性。", "motivation": "现有深度学习模型在医学影像上的预测准确性高但存在过拟合问题，难以量化不确定性。为提升临床接受度，需改进模型使其能准确评估自身预测的不确定性。", "method": "引入了新的置信度-不确定边界损失（CUB-Loss），并在训练阶段优化；设计了双温度缩放策略（DTS）进行后处理校准，以提高后验分布的直观可解释性。", "result": "该方法在肺炎筛查、糖尿病视网膜病变检测及皮肤病变识别等医学影像任务上均表现出色，在不同数据集上的性能一致且稳健。", "conclusion": "所提框架有望应用于实际临床决策支持系统中，提升其可靠性和可解释性。"}}
{"id": "2602.11969", "pdf": "https://arxiv.org/pdf/2602.11969", "abs": "https://arxiv.org/abs/2602.11969", "authors": ["Bingxu Xie", "Fang Zhou", "Jincan Wu", "Yonghui Liu", "Weiqing Li", "Zhiyong Su"], "title": "UPDA: Unsupervised Progressive Domain Adaptation for No-Reference Point Cloud Quality Assessment", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": "to be published in IEEE Transactions on Broadcasting", "summary": "While no-reference point cloud quality assessment (NR-PCQA) approaches have achieved significant progress over the past decade, their performance often degrades substantially when a distribution gap exists between the training (source domain) and testing (target domain) data. However, to date, limited attention has been paid to transferring NR-PCQA models across domains. To address this challenge, we propose the first unsupervised progressive domain adaptation (UPDA) framework for NR-PCQA, which introduces a two-stage coarse-to-fine alignment paradigm to address domain shifts. At the coarse-grained stage, a discrepancy-aware coarse-grained alignment method is designed to capture relative quality relationships between cross-domain samples through a novel quality-discrepancy-aware hybrid loss, circumventing the challenges of direct absolute feature alignment. At the fine-grained stage, a perception fusion fine-grained alignment approach with symmetric feature fusion is developed to identify domain-invariant features, while a conditional discriminator selectively enhances the transfer of quality-relevant features. Extensive experiments demonstrate that the proposed UPDA effectively enhances the performance of NR-PCQA methods in cross-domain scenarios, validating its practical applicability. The code is available at https://github.com/yokeno1/UPDA-main.", "AI": {"tldr": "提出了一种无监督的渐进领域适应框架UPDA，用于点云质量评估。", "motivation": "目前的非参考点云质量评估方法在训练集与测试集数据分布差异大的情况下表现不佳，而跨域转移模型的研究较少。为了解决这个问题，作者提出了一个两阶段粗细粒度对齐的无监督领域适应框架。", "method": "该框架首先通过一种新颖的质量差异感知混合损失来捕捉跨域样本之间的相对质量关系，然后采用对称特征融合的感知融合细化对齐方法识别不变特征，并利用条件判别器增强质量相关特征的迁移。", "result": "实验结果表明UPDA在跨域场景中能够有效提升非参考点云质量评估方法的表现。", "conclusion": "通过引入两阶段粗细粒度对齐，UPDA框架解决了不同数据集分布差异的问题，并验证了其实际应用价值。"}}
{"id": "2602.11965", "pdf": "https://arxiv.org/pdf/2602.11965", "abs": "https://arxiv.org/abs/2602.11965", "authors": ["Yiheng Yao", "Zekun Cai", "Xinyuan Song", "Hiroki Hill Kobayashi", "Xuan Song", "Ryosuke Shibasaki", "Liang Zhao"], "title": "Manifold-Aware Temporal Domain Generalization for Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 2 figures", "summary": "Temporal distribution shifts are pervasive in real-world deployments of Large Language Models (LLMs), where data evolves continuously over time. While Temporal Domain Generalization (TDG) seeks to model such structured evolution, existing approaches characterize model adaptation in the full parameter space. This formulation becomes computationally infeasible for modern LLMs. This paper introduces a geometric reformulation of TDG under parameter-efficient fine-tuning. We establish that the low-dimensional temporal structure underlying model evolution can be preserved under parameter-efficient reparameterization, enabling temporal modeling without operating in the ambient parameter space. Building on this principle, we propose Manifold-aware Temporal LoRA (MaT-LoRA), which constrains temporal updates to a shared low-dimensional manifold within a low-rank adaptation subspace, and models its evolution through a structured temporal core. This reparameterization dramatically reduces temporal modeling complexity while retaining expressive power. Extensive experiments on synthetic and real-world datasets, including scientific documents, news publishers, and review ratings, demonstrate that MaT-LoRA achieves superior temporal generalization performance with practical scalability for LLMs.", "AI": {"tldr": "本论文提出了一种基于低秩适应的时序领域泛化方法，旨在解决大型语言模型在时间分布偏移情况下的性能下降问题。", "motivation": "现有的时序域泛化方法由于计算复杂度高，在现代大型语言模型中难以应用。因此需要一种更高效的方案来处理这种挑战。", "method": "通过参数高效重参数化，本论文提出了一个几何重新表述的时序领域泛化框架，并在此基础上引入了Manifold-aware Temporal LoRA（MaT-LoRA）方法，将时间更新约束在一个共享低维流形内，并利用结构化的时间核心来建模其演变。", "result": "实验结果表明，在合成数据集和真实世界的数据集上，MaT-LoRA能够实现更好的时序泛化性能并保持可扩展性。", "conclusion": "本文提出的方法可以有效地处理大型语言模型在时间分布偏移情况下的挑战，并为该领域提供了新的解决方案。"}}
{"id": "2602.11964", "pdf": "https://arxiv.org/pdf/2602.11964", "abs": "https://arxiv.org/abs/2602.11964", "authors": ["Romain Froger", "Pierre Andrews", "Matteo Bettini", "Amar Budhiraja", "Ricardo Silveira Cabral", "Virginie Do", "Emilien Garreau", "Jean-Baptiste Gaya", "Hugo Laurençon", "Maxime Lecanu", "Kunal Malkan", "Dheeraj Mekala", "Pierre Ménard", "Gerard Moreno-Torres Bertran", "Ulyana Piterbarg", "Mikhail Plekhanov", "Mathieu Rita", "Andrey Rusakov", "Vladislav Vorotilov", "Mengjue Wang", "Ian Yu", "Amine Benhalloum", "Grégoire Mialon", "Thomas Scialom"], "title": "Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments", "categories": ["cs.AI"], "comment": "Accepted as Oral at ICLR 2026", "summary": "We introduce Gaia2, a benchmark for evaluating large language model agents in realistic, asynchronous environments. Unlike prior static or synchronous evaluations, Gaia2 introduces scenarios where environments evolve independently of agent actions, requiring agents to operate under temporal constraints, adapt to noisy and dynamic events, resolve ambiguity, and collaborate with other agents. Each scenario is paired with a write-action verifier, enabling fine-grained, action-level evaluation and making Gaia2 directly usable for reinforcement learning from verifiable rewards. Our evaluation of state-of-the-art proprietary and open-source models shows that no model dominates across capabilities: GPT-5 (high) reaches the strongest overall score of 42% pass@1 but fails on time-sensitive tasks, Claude-4 Sonnet trades accuracy and speed for cost, Kimi-K2 leads among open-source models with 21% pass@1. These results highlight fundamental trade-offs between reasoning, efficiency, robustness, and expose challenges in closing the \"sim2real\" gap. Gaia2 is built on a consumer environment with the open-source Agents Research Environments platform and designed to be easy to extend. By releasing Gaia2 alongside the foundational ARE framework, we aim to provide the community with a flexible infrastructure for developing, benchmarking, and training the next generation of practical agent systems.", "AI": {"tldr": "介绍Gaia2，一个用于评估大型语言模型代理在动态和异步环境中表现的基准。", "motivation": "为了真实地模拟实际环境中的复杂情况，提出了一种新的测试框架来衡量代理在时间和资源限制下的适应性和协作能力。", "method": "通过设计一系列具有挑战性的场景和独立运行环境，评估语言模型代理的表现，并利用写操作验证器进行精细化评价。", "result": "结果表明没有单一的模型能够在所有任务中表现出色，揭示了推理、效率、鲁棒性之间的权衡问题。", "conclusion": "Gaia2提供了一个灵活的基础框架用于开发和训练下一代实用型代理系统。"}}
{"id": "2602.11962", "pdf": "https://arxiv.org/pdf/2602.11962", "abs": "https://arxiv.org/abs/2602.11962", "authors": ["Qile Wang", "Prerana Khatiwada", "Carolina Coimbra Vieira", "Benjamin E. Bagozzi", "Kenneth E. Barner", "Matthew Louis Mauriello"], "title": "Wisdom of the LLM Crowd: A Large Scale Benchmark of Multi-Label U.S. Election-Related Harmful Social Media Content", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "The spread of election misinformation and harmful political content conveys misleading narratives and poses a serious threat to democratic integrity. Detecting harmful content at early stages is essential for understanding and potentially mitigating its downstream spread. In this study, we introduce USE24-XD, a large-scale dataset of nearly 100k posts collected from X (formerly Twitter) during the 2024 U.S. presidential election cycle, enriched with spatio-temporal metadata. To substantially reduce the cost of manual annotation while enabling scalable categorization, we employ six large language models (LLMs) to systematically annotate posts across five nuanced categories: Conspiracy, Sensationalism, Hate Speech, Speculation, and Satire. We validate LLM annotations with crowdsourcing (n = 34) and benchmark them against human annotators. Inter-rater reliability analyses show comparable agreement patterns between LLMs and humans, with LLMs exhibiting higher internal consistency and achieving up to 0.90 recall on Speculation. We apply a wisdom-of-the-crowd approach across LLMs to aggregate annotations and curate a robust multi-label dataset. 60% of posts receive at least one label. We further analyze how human annotator demographics, including political ideology and affiliation, shape labeling behavior, highlighting systematic sources of subjectivity in judgments of harmful content. The USE24-XD dataset is publicly released to support future research.", "AI": {"tldr": "介绍并构建了USE24-XD数据集，该数据集包含了近十万条关于美国大选期间的社交媒体有害内容，并使用六种大型语言模型进行系统标注。", "motivation": "检测选举虚假信息和有害政治内容对于理解其传播以及可能减轻其影响至关重要。通过采用多标签分类方法可以降低人工注释成本，同时提高数据集规模。", "method": "利用六个大型语言模型对USE24-XD中的帖子进行系统标注，并使用众包方式验证这些标注的有效性。将不同语言模型的预测结果结合以创建一个稳健的多标签数据集。", "result": "研究发现大型语言模型和人类注释者之间有可比的一致性，LLM在某些类别上表现出更高的内部一致性。60%的数据至少被标记了一个标签。", "conclusion": "USE24-XD数据集将支持未来关于选举有害内容的研究工作。通过众包方式聚合大型语言模型的预测结果，可以创建一个高质量、大规模的多标签数据集。"}}
{"id": "2602.11960", "pdf": "https://arxiv.org/pdf/2602.11960", "abs": "https://arxiv.org/abs/2602.11960", "authors": ["Bruno Rigal", "Victor Dupriez", "Alexis Mignon", "Ronan Le Hy", "Nicolas Mery"], "title": "Benchmarking Vision-Language Models for French PDF-to-Markdown Conversion", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "13 pages, 6 figures", "summary": "This report evaluates PDF-to-Markdown conversion using recent Vision-Language Models (VLMs) on challenging French documents. Document parsing is a critical step for Retrieval-Augmented Generation (RAG) pipelines, where transcription and layout errors propagate to downstream retrieval and grounding. Existing benchmarks often emphasize English or Chinese and can over-penalize benign formatting and linearization choices (e.g., line breaks, list segmentation, alternative table renderings) that are largely irrelevant for downstream use. We introduce a French-focused benchmark of difficult pages selected via model-disagreement sampling from a corpus of 60{,}000 documents, covering handwritten forms, complex layouts, dense tables, and graphics-rich pages. Evaluation is performed with unit-test-style checks that target concrete failure modes (text presence, reading order, and local table constraints) combined with category-specific normalization designed to discount presentation-only variance. Across 15 models, we observe substantially higher robustness for the strongest proprietary models on handwriting and forms, while several open-weights systems remain competitive on standard printed layouts.", "AI": {"tldr": "该论文评估了近期的视觉语言模型（VLM）在处理法语PDF文档转换为Markdown格式时的表现。", "motivation": "现有的基准测试往往侧重于英文或中文文本，对于下游应用而言过于强调排版和线性化选择，而忽视了一些关键步骤如文书解析中的错误。因此，作者引入了一个针对法语文档的专门评估体系，以更准确地反映模型性能。", "method": "通过从60,000份文档中选取具有挑战性的页面作为基准测试集，并使用单元测试风格检查来评价文本存在性、阅读顺序和局部表格约束等具体失败模式。同时采用了分类特定的标准化方法来排除仅与呈现有关的变化。", "result": "在15个模型中，最强的专有模型对手写和表单表现出了更高的鲁棒性；而一些开源系统则在标准打印布局上仍保持竞争力。", "conclusion": "该研究强调了专门针对特定语言（如法语）并涵盖复杂文档类型的基准测试的重要性，并展示了现有视觉语言模型在此任务上的性能差距。"}}
{"id": "2602.11956", "pdf": "https://arxiv.org/pdf/2602.11956", "abs": "https://arxiv.org/abs/2602.11956", "authors": ["Balázs Meszéna", "Keith T. Murray", "Julien Corbo", "O. Batuhan Erkat", "Márton A. Hajnal", "Pierre-Olivier Polack", "Gergő Orbán"], "title": "TAVAE: A VAE with Adaptable Priors Explains Contextual Modulation in the Visual Cortex", "categories": ["q-bio.NC", "cs.AI", "cs.LG"], "comment": "ICLR 2026", "summary": "The brain interprets visual information through learned regularities, a computation formalized as probabilistic inference under a prior. The visual cortex establishes priors for this inference, some delivered through established top-down connections that inform low-level cortices about statistics represented at higher levels in the cortical hierarchy. While evidence shows that adaptation leads to priors reflecting the structure of natural images, it remains unclear whether similar priors can be flexibly acquired when learning a specific task. To investigate this, we built a generative model of V1 optimized for a simple discrimination task and analyzed it together with large-scale recordings from mice performing an analogous task. In line with recent approaches, we assumed that neuronal activity in V1 corresponds to latent posteriors in the generative model, enabling investigation of task-related priors in neuronal responses. To obtain a flexible test bed, we extended the VAE formalism so that a task can be acquired efficiently by reusing previously learned representations. Task-specific priors learned by this Task-Amortized VAE were used to investigate biases in mice and model when presenting stimuli that violated trained task statistics. Mismatch between learned task statistics and incoming sensory evidence produced signatures of uncertainty in stimulus category in the TAVAE posterior, reflecting properties of bimodal response profiles in V1 recordings. The task-optimized generative model accounted for key characteristics of V1 population activity, including within-day updates to population responses. Our results confirm that flexible task-specific contextual priors can be learned on demand by the visual system and deployed as early as the entry level of visual cortex.", "AI": {"tldr": "构建了一个生成模型来解释视觉皮层中的任务特定先验。", "motivation": "研究是否可以通过学习特定任务灵活地获得类似自然图像的先验。", "method": "通过扩展VAE形式化方法，建立了Task-Amortized VAE，并分析了小鼠执行类似任务的大规模记录数据。", "result": "验证了视觉系统可以在需要时学会灵活的任务特定上下文先验并在初级视觉皮层中使用这些先验。", "conclusion": "结果表明，视觉系统可以学习并部署灵活的任务特定的上下文先验。"}}
{"id": "2602.11953", "pdf": "https://arxiv.org/pdf/2602.11953", "abs": "https://arxiv.org/abs/2602.11953", "authors": ["Michael A. Bender", "William Kuszmaul", "Elaine Shi", "Rose Silver"], "title": "History-Independent Load Balancing", "categories": ["cs.DS"], "comment": "Appeared in the Proceedings of SODA 2026", "summary": "We give a (strongly) history-independent two-choice balls-and-bins algorithm on $n$ bins that supports both insertions and deletions on a set of up to $m$ balls, while guaranteeing a maximum load of $m / n + O(1)$ with high probability, and achieving an expected recourse of $O(\\log \\log (m/n))$ per operation. To the best of our knowledge, this is the first history-independent solution to achieve nontrivial guarantees of any sort for $m/n \\ge ω(1)$ and is the first fully dynamic solution (history independent or not) to achieve $O(1)$ overload with $o(m/n)$ expected recourse.", "AI": {"tldr": "该论文提出了一个历史独立的两选择球桶算法，支持插入和删除操作，并保证最大负载为m/n+O(1)且期望回复时间为O(log log (m/n))。", "motivation": "实现一种在动态环境中具有非平凡保证的历史独立性解决方案，特别是在m/n≥ω(1)时，同时使最大负载保持在O(1)内并且预计回复时间小于(m/n)。", "method": "提出了一种历史独立的两选择球桶算法，在n个桶上支持最多m个球的插入和删除操作，通过保证每次操作后最大负载为m/n+O(1)，并实现期望的O(log log (m/n))回复时间。", "result": "该算法能够以高概率确保最大负载不超过m/n+O(1)，并且每步操作的预期回复时间为O(log log (m/n))，这是首次在动态环境中（历史独立或非历史独立）实现了这样的保证。", "conclusion": "论文提出的历史独立两选择球桶算法有效解决了大规模动态环境下的负载均衡问题，并且在保持高效率的同时也确保了数据处理的安全性。"}}
{"id": "2602.11945", "pdf": "https://arxiv.org/pdf/2602.11945", "abs": "https://arxiv.org/abs/2602.11945", "authors": ["Hongliang Zhang", "Jiguo Yu", "Guijuan Wang", "Wenshuo Ma", "Tianqing He", "Baobao Chai", "Chunqiang Hu"], "title": "Towards Performance-Enhanced Model-Contrastive Federated Learning using Historical Information in Heterogeneous Scenarios", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated Learning (FL) enables multiple nodes to collaboratively train a model without sharing raw data. However, FL systems are usually deployed in heterogeneous scenarios, where nodes differ in both data distributions and participation frequencies, which undermines the FL performance. To tackle the above issue, this paper proposes PMFL, a performance-enhanced model-contrastive federated learning framework using historical training information. Specifically, on the node side, we design a novel model-contrastive term into the node optimization objective by incorporating historical local models to capture stable contrastive points, thereby improving the consistency of model updates in heterogeneous data distributions. On the server side, we utilize the cumulative participation count of each node to adaptively adjust its aggregation weight, thereby correcting the bias in the global objective caused by different node participation frequencies. Furthermore, the updated global model incorporates historical global models to reduce its fluctuations in performance between adjacent rounds. Extensive experiments demonstrate that PMFL achieves superior performance compared with existing FL methods in heterogeneous scenarios.", "AI": {"tldr": "该论文提出了一种使用历史信息的增强模型对比联邦学习框架PMFL，以解决异构场景中联邦学习性能不佳的问题。", "motivation": "在数据分布和参与频率不同的节点上部署联邦学习系统时，会导致其性能下降。本文旨在通过引入历史训练信息来提升联邦学习的表现。", "method": "该论文设计了一种新的模型对比项纳入到节点优化目标中，并利用每个节点的历史局部模型捕获稳定的对比点；同时，在服务器端根据累积参与次数自适应调整聚合权重，以纠正因不同参与频率导致的全局目标偏差。更新后的全局模型还包含历史全局模型来减少相邻轮次之间的性能波动。", "result": "广泛的实验表明PMFL在异构场景中的表现优于现有的联邦学习方法。", "conclusion": "通过利用历史信息和改进的聚合策略，提出的PMFL框架能够显著提升联邦学习在数据分布和参与频率不一致情况下的性能。"}}
{"id": "2602.11942", "pdf": "https://arxiv.org/pdf/2602.11942", "abs": "https://arxiv.org/abs/2602.11942", "authors": ["Soufiane Ben Haddou", "Laura Alvarez-Florez", "Erik J. Bekkers", "Fleur V. Y. Tjong", "Ahmad S. Amin", "Connie R. Bezzina", "Ivana Išgum"], "title": "Synthesis of Late Gadolinium Enhancement Images via Implicit Neural Representations for Cardiac Scar Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "Paper accepted at SPIE Medical Imaging 2026 Conference", "summary": "Late gadolinium enhancement (LGE) imaging is the clinical standard for myocardial scar assessment, but limited annotated datasets hinder the development of automated segmentation methods. We propose a novel framework that synthesises both LGE images and their corresponding segmentation masks using implicit neural representations (INRs) combined with denoising diffusion models. Our approach first trains INRs to capture continuous spatial representations of LGE data and associated myocardium and fibrosis masks. These INRs are then compressed into compact latent embeddings, preserving essential anatomical information. A diffusion model operates on this latent space to generate new representations, which are decoded into synthetic LGE images with anatomically consistent segmentation masks. Experiments on 133 cardiac MRI scans suggest that augmenting training data with 200 synthetic volumes contributes to improved fibrosis segmentation performance, with the Dice score showing an increase from 0.509 to 0.524. Our approach provides an annotation-free method to help mitigate data scarcity.The code for this research is publicly available.", "AI": {"tldr": "该论文提出了一种使用隐式神经表示和去噪扩散模型合成晚期钆增强图像及其分割掩膜的方法，以解决数据稀缺问题。", "motivation": "临床标准的晚期钆增强成像用于心肌瘢痕评估，但有限的数据集阻碍了自动化分割方法的发展。该研究旨在通过生成合成数据来克服这一限制，从而提高纤维化分割的表现。", "method": "首先使用隐式神经表示捕捉晚期钆增强图像及其相关的心肌和纤维化掩膜的连续空间表示，并将这些表示压缩成紧凑的潜在嵌入。然后在潜在空间中应用扩散模型以生成新的表示，最后解码为具有解剖一致性的合成晚期钆增强图像。", "result": "实验结果表明，在133个心脏MRI扫描数据集上使用200个合成体积进行训练后，纤维化分割的Dice分数从0.509提高到0.524。", "conclusion": "该研究提出了一种无需注释的方法来生成晚期钆增强图像和其掩膜，有助于解决数据稀缺问题并提高了纤维化分割的表现。"}}
{"id": "2602.11941", "pdf": "https://arxiv.org/pdf/2602.11941", "abs": "https://arxiv.org/abs/2602.11941", "authors": ["Benjamin Clavié", "Atoof Shakir", "Jonah Turner", "Sean Lee", "Aamir Shakir", "Makoto P. Kato"], "title": "IncompeBench: A Permissively Licensed, Fine-Grained Benchmark for Music Information Retrieval", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Multimodal Information Retrieval has made significant progress in recent years, leveraging the increasingly strong multimodal abilities of deep pre-trained models to represent information across modalities. Music Information Retrieval (MIR), in particular, has considerably increased in quality, with neural representations of music even making its way into everyday life products. However, there is a lack of high-quality benchmarks for evaluating music retrieval performance. To address this issue, we introduce \\textbf{IncompeBench}, a carefully annotated benchmark comprising $1,574$ permissively licensed, high-quality music snippets, $500$ diverse queries, and over $125,000$ individual relevance judgements. These annotations were created through the use of a multi-stage pipeline, resulting in high agreement between human annotators and the generated data. The resulting datasets are publicly available at https://huggingface.co/datasets/mixedbread-ai/incompebench-strict and https://huggingface.co/datasets/mixedbread-ai/incompebench-lenient with the prompts available at https://github.com/mixedbread-ai/incompebench-programs.", "AI": {"tldr": "本文介绍了IncompeBench，这是一个用于音乐信息检索的高质量基准测试集合。", "motivation": "由于缺乏对音乐检索性能评估的高质量基准，该研究旨在通过创建一个包含1574个许可的、高质素的音乐片段和超过125000个人类注释员判断的数据集来解决这一问题。", "method": "数据集使用多阶段流水线进行注解，并且这些标注是经过人类注释员高度一致同意生成的结果。", "result": "IncompeBench包括了1,574个音乐片段，500个多样化查询和超过125,000个人类的判断。数据集在Hugging Face上公开可用。", "conclusion": "IncompeBench提供了一个高质量、多样的数据集用于评估音乐信息检索系统的性能，并且对整个学术界开放使用以促进研究进展。"}}
{"id": "2602.11934", "pdf": "https://arxiv.org/pdf/2602.11934", "abs": "https://arxiv.org/abs/2602.11934", "authors": ["Yu Deng", "Yufeng Jin", "Xiaogang Jia", "Jiahong Xue", "Gerhard Neumann", "Georgia Chalvatzaki"], "title": "Robot-DIFT: Distilling Diffusion Features for Geometrically Consistent Visuomotor Control", "categories": ["cs.RO"], "comment": null, "summary": "We hypothesize that a key bottleneck in generalizable robot manipulation is not solely data scale or policy capacity, but a structural mismatch between current visual backbones and the physical requirements of closed-loop control. While state-of-the-art vision encoders (including those used in VLAs) optimize for semantic invariance to stabilize classification, manipulation typically demands geometric sensitivity the ability to map millimeter-level pose shifts to predictable feature changes. Their discriminative objective creates a \"blind spot\" for fine-grained control, whereas generative diffusion models inherently encode geometric dependencies within their latent manifolds, encouraging the preservation of dense multi-scale spatial structure. However, directly deploying stochastic diffusion features for control is hindered by stochastic instability, inference latency, and representation drift during fine-tuning. To bridge this gap, we propose Robot-DIFT, a framework that decouples the source of geometric information from the process of inference via Manifold Distillation. By distilling a frozen diffusion teacher into a deterministic Spatial-Semantic Feature Pyramid Network (S2-FPN), we retain the rich geometric priors of the generative model while ensuring temporal stability, real-time execution, and robustness against drift. Pretrained on the large-scale DROID dataset, Robot-DIFT demonstrates superior geometric consistency and control performance compared to leading discriminative baselines, supporting the view that how a model learns to see dictates how well it can learn to act.", "AI": {"tldr": "研究提出了一种名为Robot-DIFT的框架，通过从生成扩散模型中提取几何信息来改进机器人视觉操控中的几何一致性。", "motivation": "当前视觉骨干网络与闭环控制需求之间存在结构不匹配的问题。虽然最先进的视觉编码器优化了分类稳定的语义不变性，但它们对于需要微米级姿态变化映射的操纵任务缺乏敏感度。", "method": "该研究提出了一种通过解耦几何信息源和推理过程的方法来解决上述问题，具体做法是使用生成扩散模型作为教师网络，将其知识传递给一个确定性的空间语义特征金字塔网络（S2-FPN），以保留丰富的几何先验同时确保实时性和稳定性。", "result": "在DROID数据集上预训练后，Robot-DIFT显示出比最先进的判别基线更好的几何一致性和控制性能。", "conclusion": "研究表明通过学习如何更好地‘看到’可以提升机器人操控能力，特别是在保持几何一致性的方面。"}}
{"id": "2602.11931", "pdf": "https://arxiv.org/pdf/2602.11931", "abs": "https://arxiv.org/abs/2602.11931", "authors": ["Pretam Ray", "Pratik Prabhanjan Brahma", "Zicheng Liu", "Emad Barsoum"], "title": "AdaptEvolve: Improving Efficiency of Evolutionary AI Agents through Adaptive Model Selection", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, 2 Figues", "summary": "Evolutionary agentic systems intensify the trade-off between computational efficiency and reasoning capability by repeatedly invoking large language models (LLMs) during inference. This setting raises a central question: how can an agent dynamically select an LLM that is sufficiently capable for the current generation step while remaining computationally efficient? While model cascades offer a practical mechanism for balancing this trade-off, existing routing strategies typically rely on static heuristics or external controllers and do not explicitly account for model uncertainty. We introduce AdaptEvolve: Adaptive LLM Selection for Multi-LLM Evolutionary Refinement within an evolutionary sequential refinement framework that leverages intrinsic generation confidence to estimate real-time solvability. Empirical results show that confidence-driven selection yields a favourable Pareto frontier, reducing total inference cost by an average of 37.9% across benchmarks while retaining 97.5% of the upper-bound accuracy of static large-model baselines. Our code is available at https://github.com/raypretam/adaptive_llm_selection.", "AI": {"tldr": "本文提出了AdaptEvolve，一种基于内在生成置信度选择合适的大语言模型的适应性选择方法，以提高进化智能体在推理过程中的效率和准确性。", "motivation": "传统的模型级联策略依赖静态启发式或外部控制器，并未明确考虑模型不确定性。该研究旨在开发一种动态模型选择机制，使进化代理系统能够在保证计算效率的同时最大化其推理能力。", "method": "AdaptEvolve利用内在生成置信度来实时估算可解性，通过这种方法，在多大语言模型演进细化框架中实现适应性的大型语言模型选择。", "result": "实验结果表明，基于信心驱动的选择策略在基准测试上平均降低了37.9%的总推理成本，同时保留了静态大规模模型基线上的97.5%准确性。", "conclusion": "AdaptEvolve通过动态调整大语言模型的选择以优化进化智能体的成本效益比，在减少计算开销的同时保持了高水平的性能。"}}
{"id": "2602.11929", "pdf": "https://arxiv.org/pdf/2602.11929", "abs": "https://arxiv.org/abs/2602.11929", "authors": ["Zepeng Wang", "Jiangxing Wang", "Shiqing Yao", "Yu Zhang", "Ziluo Ding", "Ming Yang", "Yuxuan Wang", "Haobin Jiang", "Chao Ma", "Xiaochuan Shi", "Zongqing Lu"], "title": "General Humanoid Whole-Body Control via Pretraining and Fast Adaptation", "categories": ["cs.RO"], "comment": "22 pages", "summary": "Learning a general whole-body controller for humanoid robots remains challenging due to the diversity of motion distributions, the difficulty of fast adaptation, and the need for robust balance in high-dynamic scenarios. Existing approaches often require task-specific training or suffer from performance degradation when adapting to new motions. In this paper, we present FAST, a general humanoid whole-body control framework that enables Fast Adaptation and Stable Motion Tracking. FAST introduces Parseval-Guided Residual Policy Adaptation, which learns a lightweight delta action policy under orthogonality and KL constraints, enabling efficient adaptation to out-of-distribution motions while mitigating catastrophic forgetting. To further improve physical robustness, we propose Center-of-Mass-Aware Control, which incorporates CoM-related observations and objectives to enhance balance when tracking challenging reference motions. Extensive experiments in simulation and real-world deployment demonstrate that FAST consistently outperforms state-of-the-art baselines in robustness, adaptation efficiency, and generalization.", "AI": {"tldr": "本文提出了一种名为FAST的通用人形机器人全身控制框架，旨在通过快速适应和稳定的运动跟踪解决现有方法在任务特定训练或性能下降方面的问题。", "motivation": "学习适用于人形机器人的通用全身控制器仍然具有挑战性，因为需要处理各种动作分布、实现快速适应以及保证高动态场景中的稳定平衡。现有的方法通常需要针对特定任务的训练或者在适应新动作时会出现性能降低。", "method": "FAST框架引入了Parseval-Guided残差策略适应和基于质心感知控制的方法。前者学习一个轻量级的动作策略，后者通过集成与CoM相关的观测值来提高跟踪困难参考运动时的平衡能力。", "result": "实验结果表明，与最新的基准相比，FAST在鲁棒性、适应效率和泛化方面表现更优。", "conclusion": "FAST框架能够有效地解决人形机器人全身控制中的关键问题，并且已经在仿真和真实世界部署中得到了验证。"}}
{"id": "2602.11924", "pdf": "https://arxiv.org/pdf/2602.11924", "abs": "https://arxiv.org/abs/2602.11924", "authors": ["Shreya Chappidi", "Jatinder Singh", "Andra V. Krauze"], "title": "Who Does What? Archetypes of Roles Assigned to LLMs During Human-AI Decision-Making", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted to ACM CHI 2026", "summary": "LLMs are increasingly supporting decision-making across high-stakes domains, requiring critical reflection on the socio-technical factors that shape how humans and LLMs are assigned roles and interact during human-in-the-loop decision-making. This paper introduces the concept of human-LLM archetypes -- defined as re-curring socio-technical interaction patterns that structure the roles of humans and LLMs in collaborative decision-making. We describe 17 human-LLM archetypes derived from a scoping literature review and thematic analysis of 113 LLM-supported decision-making papers. Then, we evaluate these diverse archetypes across real-world clinical diagnostic cases to examine the potential effects of adopting distinct human-LLM archetypes on LLM outputs and decision outcomes. Finally, we present relevant tradeoffs and design choices across human-LLM archetypes, including decision control, social hierarchies, cognitive forcing strategies, and information requirements. Through our analysis, we show that selection of human-LLM interaction archetype can influence LLM outputs and decisions, bringing important risks and considerations for the designers of human-AI decision-making systems", "AI": {"tldr": "本文研究了大型语言模型在人类决策中的角色模式及其对输出和结果的影响。", "motivation": "随着大型语言模型越来越多地支持高风险领域的决策，需要深入探讨决定人机交互方式的社会技术因素。", "method": "通过对113篇相关文献进行主题分析，本文提出了17种人与LLM之间互动的角色模式，并通过真实世界临床诊断案例评估这些角色对LLM输出和决策结果的影响。", "result": "实验表明，不同的人机交互方式会影响大型语言模型的输出和最终决策的结果。", "conclusion": "选择合适的人机交互模式对于设计人类与AI协作的决策系统至关重要。"}}
{"id": "2602.11919", "pdf": "https://arxiv.org/pdf/2602.11919", "abs": "https://arxiv.org/abs/2602.11919", "authors": ["BoCheng Hu", "Zhonghan Zhao", "Kaiyue Zhou", "Hongwei Wang", "Gaoang Wang"], "title": "DynaHOI: Benchmarking Hand-Object Interaction for Dynamic Target", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Most existing hand motion generation benchmarks for hand-object interaction (HOI) focus on static objects, leaving dynamic scenarios with moving targets and time-critical coordination largely untested. To address this gap, we introduce the DynaHOI-Gym, a unified online closed-loop platform with parameterized motion generators and rollout-based metrics for dynamic capture evaluation. Built on DynaHOI-Gym, we release DynaHOI-10M, a large-scale benchmark with 10M frames and 180K hand capture trajectories, whose target motions are organized into 8 major categories and 22 fine-grained subcategories. We also provide a simple observe-before-act baseline (ObAct) that integrates short-term observations with the current frame via spatiotemporal attention to predict actions, achieving an 8.1% improvement in location success rate.", "AI": {"tldr": "本文提出DynaHOI-Gym和DynaHOI-10M，用于评估动态目标的手部动作生成。", "motivation": "现有的手对象交互基准主要针对静态物体，而缺乏对移动目标的时间关键协调的测试。因此引入DynaHOI-Gym来解决这一问题。", "method": "构建了参数化运动生成器和基于rollout的度量标准的统一在线闭环平台Dynahoigym，并发布了包含10M帧和180K手部捕捉轨迹的大规模基准数据集DynaHOI-10M。提供了观察后行动基线（ObAct），通过时空注意将短期观测与当前帧集成来预测动作。", "result": "提出的observe-before-action方法在位置成功率方面提升了8.1%。", "conclusion": "本文提出了针对动态手对象交互基准的解决方案，并验证了其有效性的观察后行动基线。"}}
{"id": "2602.11918", "pdf": "https://arxiv.org/pdf/2602.11918", "abs": "https://arxiv.org/abs/2602.11918", "authors": ["Taian Guo", "Haiyang Shen", "Junyu Luo", "Zhongshi Xing", "Hanchun Lian", "Jinsheng Huang", "Binqi Chen", "Luchen Liu", "Yun Ma", "Ming Zhang"], "title": "MEME: Modeling the Evolutionary Modes of Financial Markets", "categories": ["cs.AI"], "comment": null, "summary": "LLMs have demonstrated significant potential in quantitative finance by processing vast unstructured data to emulate human-like analytical workflows. However, current LLM-based methods primarily follow either an Asset-Centric paradigm focused on individual stock prediction or a Market-Centric approach for portfolio allocation, often remaining agnostic to the underlying reasoning that drives market movements. In this paper, we propose a Logic-Oriented perspective, modeling the financial market as a dynamic, evolutionary ecosystem of competing investment narratives, termed Modes of Thought. To operationalize this view, we introduce MEME (Modeling the Evolutionary Modes of Financial Markets), designed to reconstruct market dynamics through the lens of evolving logics. MEME employs a multi-agent extraction module to transform noisy data into high-fidelity Investment Arguments and utilizes Gaussian Mixture Modeling to uncover latent consensus within a semantic space. To model semantic drift among different market conditions, we also implement a temporal evaluation and alignment mechanism to track the lifecycle and historical profitability of these modes. By prioritizing enduring market wisdom over transient anomalies, MEME ensures that portfolio construction is guided by robust reasoning. Extensive experiments on three heterogeneous Chinese stock pools from 2023 to 2025 demonstrate that MEME consistently outperforms seven SOTA baselines. Further ablation studies, sensitivity analysis, lifecycle case study and cost analysis validate MEME's capacity to identify and adapt to the evolving consensus of financial markets. Our implementation can be found at https://github.com/gta0804/MEME.", "AI": {"tldr": "MEME通过逻辑导向的角度，模拟金融市场中的投资叙事演变来重建市场动态。", "motivation": "当前基于LLM的方法主要集中在单独股票预测或组合配置上，缺乏对推动市场价格变化的根本原因的理解。因此，提出了逻辑导向的视角，以更全面地理解金融市场的演化。", "method": "MEME使用多代理提取模块将嘈杂数据转化为投资论证，并利用高斯混合模型在语义空间中揭示潜在共识。为了跟踪不同市场条件下的语义漂移，实现了一个时间评估和对齐机制来追踪这些模式的生命周期和历史盈利能力。", "result": "实验表明MEME在三个不同的中国股票池上超过2023至2025年的数据集表现优于七个SOTA基准。进一步的消融研究、敏感性分析以及成本分析证实了MEME能识别并适应金融市场中不断变化的一致性。", "conclusion": "通过优先考虑持久的市场智慧而非短暂异常，MEME确保组合构建受到稳健理由的指导，在广泛的数据集上优于其他方法，并展示了其在金融市场的广泛应用潜力。"}}
{"id": "2602.11917", "pdf": "https://arxiv.org/pdf/2602.11917", "abs": "https://arxiv.org/abs/2602.11917", "authors": ["Taian Guo", "Haiyang Shen", "Junyu Luo", "Binqi Chen", "Hongjun Ding", "Jinsheng Huang", "Luchen Liu", "Yun Ma", "Ming Zhang"], "title": "AlphaPROBE: Alpha Mining via Principled Retrieval and On-graph biased evolution", "categories": ["cs.AI"], "comment": null, "summary": "Extracting signals through alpha factor mining is a fundamental challenge in quantitative finance. Existing automated methods primarily follow two paradigms: Decoupled Factor Generation, which treats factor discovery as isolated events, and Iterative Factor Evolution, which focuses on local parent-child refinements. However, both paradigms lack a global structural view, often treating factor pools as unstructured collections or fragmented chains, which leads to redundant search and limited diversity. To address these limitations, we introduce AlphaPROBE (Alpha Mining via Principled Retrieval and On-graph Biased Evolution), a framework that reframes alpha mining as the strategic navigation of a Directed Acyclic Graph (DAG). By modeling factors as nodes and evolutionary links as edges, AlphaPROBE treats the factor pool as a dynamic, interconnected ecosystem. The framework consists of two core components: a Bayesian Factor Retriever that identifies high-potential seeds by balancing exploitation and exploration through a posterior probability model, and a DAG-aware Factor Generator that leverages the full ancestral trace of factors to produce context-aware, nonredundant optimizations. Extensive experiments on three major Chinese stock market datasets against 8 competitive baselines demonstrate that AlphaPROBE significantly gains enhanced performance in predictive accuracy, return stability and training efficiency. Our results confirm that leveraging global evolutionary topology is essential for efficient and robust automated alpha discovery. We have open-sourced our implementation at https://github.com/gta0804/AlphaPROBE.", "AI": {"tldr": "AlphaPROBE 是一种通过全局结构视角改进自动化alpha因子挖掘的方法，旨在提高预测准确性和训练效率。", "motivation": "现有的自动alpha因子挖掘方法在处理因子池时存在冗余搜索和有限多样性的问题。为了解决这些问题，提出了一种新的框架来克服这些局限性。", "method": "AlphaPROBE将因子挖掘重新定义为有向无环图(DAG)中的战略性导航。包括一个基于贝叶斯模型的因子检索器和一个利用全局进化拓扑结构生成非冗余优化的方法。", "result": "实验结果表明，相比其他基准方法，AlphaPROBE在预测准确度、收益稳定性和训练效率方面都有显著提高。", "conclusion": "通过充分利用全球进化拓扑结构进行自动化alpha因子的发现是有效和稳健的关键。"}}
{"id": "2602.11910", "pdf": "https://arxiv.org/pdf/2602.11910", "abs": "https://arxiv.org/abs/2602.11910", "authors": ["Łukasz Staniszewski", "Katarzyna Zaleska", "Mateusz Modrzejewski", "Kamil Deja"], "title": "TADA! Tuning Audio Diffusion Models through Activation Steering", "categories": ["cs.SD", "cs.LG"], "comment": "Preprint. Preliminary work", "summary": "Audio diffusion models can synthesize high-fidelity music from text, yet their internal mechanisms for representing high-level concepts remain poorly understood. In this work, we use activation patching to demonstrate that distinct semantic musical concepts, such as the presence of specific instruments, vocals, or genre characteristics, are controlled by a small, shared subset of attention layers in state-of-the-art audio diffusion architectures. Next, we demonstrate that applying Contrastive Activation Addition and Sparse Autoencoders in these layers enables more precise control over the generated audio, indicating a direct benefit of the specialization phenomenon. By steering activations of the identified layers, we can alter specific musical elements with high precision, such as modulating tempo or changing a track's mood.", "AI": {"tldr": "通过激活引导，优化音频扩散模型的生成效果。", "motivation": "探索先进的音频扩散架构中的注意力层如何影响音乐合成，并提高对高阶概念控制的能力。", "method": "使用激活补丁技术识别关键的注意力层；应用对比激活添加和稀疏自编码器以实现更精确的控制。", "result": "通过引导特定层的激活，可以精准改变生成音频的具体元素如调速或调整音乐情绪。", "conclusion": "揭示了高级音频扩散模型内部机制，并展示了通过激活引导提升合成精度的有效性。"}}
{"id": "2602.11909", "pdf": "https://arxiv.org/pdf/2602.11909", "abs": "https://arxiv.org/abs/2602.11909", "authors": ["Daiqing Wu", "Xuan Zhang", "Dongbao Yang", "Jiashu Yao", "Longfei Chen", "Qingsong Liu", "Sicheng Zhao", "Can Ma", "Yangyang Kang", "Yu Zhou"], "title": "Echo: Towards Advanced Audio Comprehension via Audio-Interleaved Reasoning", "categories": ["cs.SD", "cs.LG"], "comment": "Accepted by ICLR 2026", "summary": "The maturation of Large Audio Language Models (LALMs) has raised growing expectations for them to comprehend complex audio much like humans. Current efforts primarily replicate text-based reasoning by contextualizing audio content through a one-time encoding, which introduces a critical information bottleneck. Drawing inspiration from human cognition, we propose audio-interleaved reasoning to break through this bottleneck. It treats audio as an active reasoning component, enabling sustained audio engagement and perception-grounded analysis. To instantiate it, we introduce a two-stage training framework, first teaching LALMs to localize salient audio segments through supervised fine-tuning, and then incentivizing proficient re-listening via reinforcement learning. In parallel, a structured data generation pipeline is developed to produce high-quality training data. Consequently, we present Echo, a LALM capable of dynamically re-listening to audio in demand during reasoning. On audio comprehension benchmarks, Echo achieves overall superiority in both challenging expert-level and general-purpose tasks. Comprehensive analysis further confirms the efficiency and generalizability of audio-interleaved reasoning, establishing it as a promising direction for advancing audio comprehension. Project page: https://github.com/wdqqdw/Echo.", "AI": {"tldr": "提出了一种音频交织推理方法，用于改进大型音频语言模型对复杂音频的理解。", "motivation": "当前的大型音频语言模型主要通过一次性编码方式来上下文化音频内容，这种处理方式会导致信息瓶颈。作者希望通过模仿人类认知的方式打破这一瓶颈，提升模型理解复杂音频的能力。", "method": "提出了一种两阶段训练框架，首先通过监督微调让模型学会定位关键音频片段，然后利用强化学习激励其进行有效重听。同时开发了结构化数据生成管线来产生高质量的训练数据。", "result": "Echo在音频理解基准测试中，在具有挑战性的专家级任务和通用任务上都表现出了优越性。", "conclusion": "实验结果表明，音频交织推理方法不仅效率高而且具有泛化能力，是一种提升音频理解的有效途径。"}}
{"id": "2602.11908", "pdf": "https://arxiv.org/pdf/2602.11908", "abs": "https://arxiv.org/abs/2602.11908", "authors": ["Shani Goren", "Ido Galil", "Ran El-Yaniv"], "title": "When Should LLMs Be Less Specific? Selective Abstraction for Reliable Long-Form Text Generation", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "LLMs are widely used, yet they remain prone to factual errors that erode user trust and limit adoption in high-risk settings. One approach to mitigate this risk is to equip models with uncertainty estimation mechanisms that abstain when confidence is low. However, this binary \"all-or-nothing\" approach is excessively restrictive in long-form settings, often discarding valuable information. We introduce Selective Abstraction (SA), a framework that enables LLMs to trade specificity for reliability by selectively reducing the detail of uncertain content. We first formalize SA through the lenses of selective risk and coverage. We then propose Atom-wise Selective Abstraction, a claim-level instantiation that decomposes responses into atomic claims (short, self-contained statements each expressing a single fact) and replaces uncertain atoms with higher confidence, less specific abstractions. To evaluate this framework, we develop a novel end-to-end pipeline for open-ended generation that instantiates risk as factual correctness and measures coverage using an information-theoretic measure of retained information. Across six open-source models on the FactScore and LongFact-Objects benchmarks, atom-wise SA consistently outperforms existing baselines, improving the area under the risk-coverage curve (AURC) by up to 27.73% over claim removal, demonstrating that reducing specificity can boost accuracy and reliability while preserving most of their original meaning.", "AI": {"tldr": "论文提出了选择性抽象框架，使LLM在不确定性较高时降低细节的准确性。", "motivation": "LLM存在事实错误问题，影响用户信任和高风险应用中的采用。现有的二元方法（要么全部输出要么全不输出）过于严格，在长文本生成中会丢弃有用信息。", "method": "提出原子级选择性抽象框架，将响应分解为原子声明并替换不确定的原子以更具体准确的信息代替。", "result": "在六种开源模型上，该方法提高了FactScore和LongFact-Objects基准测试中的风险覆盖率曲线下的面积（AURC），最高提升了27.73%。", "conclusion": "选择性抽象框架通过减少细节提高准确性与可靠性，同时保留大部分原始含义。"}}
{"id": "2602.11904", "pdf": "https://arxiv.org/pdf/2602.11904", "abs": "https://arxiv.org/abs/2602.11904", "authors": ["Weixing Zhang", "Bowen Jiang", "Yuhong Fu", "Anne Koziolek", "Regina Hebig", "Daniel Strüber"], "title": "Leveraging LLMs to support co-evolution between definitions and instances of textual DSLs: A Systematic Evaluation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Software languages evolve over time for reasons such as feature additions. When grammars evolve, textual instances that originally conformed to them may become outdated. While model-driven engineering provides many techniques for co-evolving models with metamodel changes, these approaches are not designed for textual DSLs and may lose human-relevant information such as layout and comments. This study systematically evaluates the potential of large language models (LLMs) for co-evolving grammars and instances of textual DSLs. Using Claude Sonnet 4.5 and GPT-5.2 across ten case languages with ten runs each, we assess both correctness and preservation of human-oriented information. Results show strong performance on small-scale cases ($\\geq$94% precision and recall for instances requiring fewer than 20 modified lines), but performance degraded with scale: Claude maintains 85% recall at 40 lines, while GPT fails on the largest instances. Response time increases substantially with instance size, and grammar evolution complexity and deletion granularity affect performance more than change type. These findings clarify when LLM-based co-evolution is effective and where current limitations remain.", "AI": {"tldr": "利用大语言模型（LLM）评估其在语法和实例文本DSL协同演进中的潜力。", "motivation": "研究如何通过大型语言模型来支持文本DSL的定义与实例之间的协同演化，特别是在处理人类相关的信息如布局和注释时。", "method": "采用Claude Sonnet 4.5和GPT-5.2对十种不同案例语言进行系统性评估，每种语言运行十次，以检查正确性和保持人类相关的信息情况。", "result": "在小规模情况下性能优异（少于20行修改的实例中精确率和召回率达到94%以上），但随着规模增加，性能下降：Claude在40行时召回率为85%，而GPT在最大实例上失败。响应时间随实例大小显著增加，并且语法演进复杂性和删除粒度影响更大。", "conclusion": "这些发现明确了LLM基于协同演化方法的有效性及其当前的局限性。"}}
{"id": "2602.11903", "pdf": "https://arxiv.org/pdf/2602.11903", "abs": "https://arxiv.org/abs/2602.11903", "authors": ["Yu-Chih Chen", "Michael Wang", "Chieh-Dun Wen", "Kai-Siang Ma", "Avinab Saha", "Li-Heng Chen", "Alan Bovik"], "title": "Learning Perceptual Representations for Gaming NR-VQA with Multi-Task FR Signals", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": "6 pages, 2 figures", "summary": "No-reference video quality assessment (NR-VQA) for gaming videos is challenging due to limited human-rated datasets and unique content characteristics including fast motion, stylized graphics, and compression artifacts. We present MTL-VQA, a multi-task learning framework that uses full-reference metrics as supervisory signals to learn perceptually meaningful features without human labels for pretraining. By jointly optimizing multiple full-reference (FR) objectives with adaptive task weighting, our approach learns shared representations that transfer effectively to NR-VQA. Experiments on gaming video datasets show MTL-VQA achieves performance competitive with state-of-the-art NR-VQA methods across both MOS-supervised and label-efficient/self-supervised settings.", "AI": {"tldr": "提出了一种多任务学习框架MTL-VQA，用于游戏视频的无参考质量评估。", "motivation": "由于缺乏标注数据和独特的内容特征，游戏视频的无参考质量评估非常具有挑战性。因此需要一种新方法来解决这些问题。", "method": "通过使用全参考指标作为监督信号并采用自适应任务权重进行多任务学习框架MTL-VQA的学习。", "result": "实验结果表明，在不同数据集上，该模型在无参考视频质量评估方面取得了与当前最佳方法相当的性能。", "conclusion": "提出的MTL-VQA框架可以有效地解决游戏视频中的无参考质量评估问题，并且在不同的设置下表现出色。"}}
{"id": "2602.11902", "pdf": "https://arxiv.org/pdf/2602.11902", "abs": "https://arxiv.org/abs/2602.11902", "authors": ["Suqin Yuan", "Xingrui Yu", "Jiyang Zheng", "Lei Feng", "Dadong Wang", "Ivor Tsang", "Tongliang Liu"], "title": "Mitigating Mismatch within Reference-based Preference Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICLR 2026", "summary": "Direct Preference Optimization (DPO) has become the de facto standard for offline preference alignment of large language models, but its reliance on a reference policy introduces a critical tension. DPO weighs each update relative to a reference, which stabilizes the training by regularizing the updates within a trusted region. This reliance becomes problematic for pessimistic pairs, where the reference model prefers the rejected response. For these pairs, DPO prematurely attenuates the gradient as soon as the policy margin ($Δ_θ$) merely beats the reference margin ($Δ_{\\mathrm{ref}}$) even if the policy is still wrong ($Δ_θ<0$). We name this failure premature satisfaction, which is a concrete form of the training-inference mismatch. Reference-free objectives remove this mismatch by optimizing the absolute margin, but at the cost of discarding the stabilizing signal of the reference. We mitigate this tension with Hybrid-DPO (HyPO), a drop-in modification to DPO that applies reference conditionally: HyPO behaves exactly like DPO when the reference is optimistic or neutral, and it treats the reference as neutral when it is pessimistic by replacing $Δ_θ-Δ_{\\mathrm{ref}}$ with $Δ_θ-\\max\\{0,Δ_{\\mathrm{ref}}\\}$. This one-line change strictly strengthens per-example learning signals on pessimistic pairs while preserving DPO's objective form and computational cost. By conditionally debiasing the pessimistic reference signal, HyPO mitigates premature satisfaction; empirically, across preference alignment, HyPO improves inference-aligned metrics and achieves higher pairwise win rates. Our results provide evidence that direct preference alignment could be enhanced by conditionally debiasing the reference signal, rather than discarding it.", "AI": {"tldr": "本文提出了HyPO算法，以缓解直接偏好优化（DPO）方法在处理悲观参考对时的过早满足问题。", "motivation": "由于DPO依赖于参考策略来稳定训练，当遇到悲观参考对时，会导致过早满意的问题。为了解决这一矛盾，作者提出了一种新的条件性偏置修正方法HyPO。", "method": "通过在DPO的基础上引入一种条件性的参考策略调整机制：当参考模型的态度是乐观或中立时，HyPO的行为与传统DPO相同；而当参考模型态度悲观时，则将参考信号视为零，并使用绝对边际进行优化。", "result": "实验结果显示，在偏好对齐任务上，HyPO不仅提高了推理一致性的指标，还获得了更高的成对胜率。", "conclusion": "通过条件性地修正参考信号的偏置而非完全丢弃它，直接偏好对齐可以得到改进。"}}
{"id": "2602.11897", "pdf": "https://arxiv.org/pdf/2602.11897", "abs": "https://arxiv.org/abs/2602.11897", "authors": ["Andrei Kojukhov", "Arkady Bovshover"], "title": "Agentic AI for Cybersecurity: A Meta-Cognitive Architecture for Governable Autonomy", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Contemporary AI-driven cybersecurity systems are predominantly architected as model-centric detection and automation pipelines optimized for task-level performance metrics such as accuracy and response latency. While effective for bounded classification tasks, these architectures struggle to support accountable decision-making under adversarial uncertainty, where actions must be justified, governed, and aligned with organizational and regulatory constraints. This paper argues that cybersecurity orchestration should be reconceptualized as an agentic, multi-agent cognitive system, rather than a linear sequence of detection and response components. We introduce a conceptual architectural framework in which heterogeneous AI agents responsible for detection, hypothesis formation, contextual interpretation, explanation, and governance are coordinated through an explicit meta-cognitive judgement function. This function governs decision readiness and dynamically calibrates system autonomy when evidence is incomplete, conflicting, or operationally risky. By synthesizing distributed cognition theory, multi-agent systems research, and responsible AI governance frameworks, we demonstrate that modern security operations already function as distributed cognitive systems, albeit without an explicit organizing principle. Our contribution is to make this cognitive structure architecturally explicit and governable by embedding meta-cognitive judgement as a first-class system function. We discuss implications for security operations centers, accountable autonomy, and the design of next-generation AI-enabled cyber defence architectures. The proposed framework shifts the focus of AI in cybersecurity from optimizing isolated predictions to governing autonomy under uncertainty.", "AI": {"tldr": "提出了一种基于多代理认知系统的网络安全架构，该系统通过元认知判断功能来协调决策和自治管理。", "motivation": "当前的AI驱动网络安全系统在对抗不确定性下的可问责性决策方面存在不足，需要一种能够支持组织约束和监管要求的新架构。", "method": "介绍了一个新的架构框架，其中异构AI代理负责检测、假设形成、上下文解释、说明和治理，并通过元认知判断功能进行协调。该方法结合了分布式认知理论、多代理系统研究和责任AI治理框架。", "result": "展示了如何使现代安全操作中心的功能成为显式的分布式认知系统，并提出了一种可治理的自治管理方法。", "conclusion": "新架构将AI在网络安全中的应用从孤立预测优化转向不确定条件下的自治管理，从而提高了系统的问责性和安全性。"}}
{"id": "2602.11896", "pdf": "https://arxiv.org/pdf/2602.11896", "abs": "https://arxiv.org/abs/2602.11896", "authors": ["Vincent Lostanlen", "Han Han"], "title": "Musical Metamerism with Time--Frequency Scattering", "categories": ["cs.SD", "eess.AS"], "comment": "Technical report, 15 pages, 1 figure. Written in November 2024 as part of a collaboration with Henkjan Honing's music cognition group at the University of Amsterdam", "summary": "The concept of metamerism originates from colorimetry, where it describes a sensation of visual similarity between two colored lights despite significant differences in spectral content. Likewise, we propose to call ``musical metamerism'' the sensation of auditory similarity which is elicited by two music fragments which differ in terms of underlying waveforms. In this technical report, we describe a method to generate musical metamers from any audio recording. Our method is based on joint time--frequency scattering in Kymatio, an open-source software in Python which enables GPU computing and automatic differentiation. The advantage of our method is that it does not require any manual preprocessing, such as transcription, beat tracking, or source separation. We provide a mathematical description of JTFS as well as some excerpts from the Kymatio source code. Lastly, we review the prior work on JTFS and draw connections with closely related algorithms, such as spectrotemporal receptive fields (STRF), modulation power spectra (MPS), and Gabor filterbank (GBFB).", "AI": {"tldr": "本文提出了一种基于时间频率散射生成音乐元的方法，这种方法可以从任何音频记录中产生听觉相似但波形不同的音乐片段。", "motivation": "受到色度学中的同色异谱概念的启发，即两个光的颜色看似相同但实际光谱内容不同，作者提出了“音乐同色异谱”这一概念，描述了两种听起来相似但实际上具有显著波形差异的音乐片段之间的感知。此方法的优势在于无需手动预处理如转录、节拍跟踪或源分离。", "method": "该方法基于Kymatio软件中的联合时间频率散射技术实现，并提供了数学上的描述以及相关的开源代码示例。", "result": "通过实验表明，所提出的方法能够生成具有听觉相似性但波形不同的音乐片段。", "conclusion": "本文展示了如何使用时间频率散射方法来识别和生成音乐同色异谱，从而进一步推动了这一领域的研究进展。"}}
{"id": "2602.11890", "pdf": "https://arxiv.org/pdf/2602.11890", "abs": "https://arxiv.org/abs/2602.11890", "authors": ["Giannis Spiliopoulos", "Alexandros Troupiotis-Kapeliaris", "Kostas Patroumpas", "Nikolaos Liapis", "Dimitrios Skoutas", "Dimitris Zissis", "Nikos Bikakis"], "title": "Data-Driven Trajectory Imputation for Vessel Mobility Analysis", "categories": ["cs.DB", "cs.CG", "cs.RO", "eess.IV"], "comment": "International Conference on Extending Database Technology (EDBT 2026)", "summary": "Modeling vessel activity at sea is critical for a wide range of applications, including route planning, transportation logistics, maritime safety, and environmental monitoring. Over the past two decades, the Automatic Identification System (AIS) has enabled real-time monitoring of hundreds of thousands of vessels, generating huge amounts of data daily. One major challenge in using AIS data is the presence of large gaps in vessel trajectories, often caused by coverage limitations or intentional transmission interruptions. These gaps can significantly degrade data quality, resulting in inaccurate or incomplete analysis. State-of-the-art imputation approaches have mainly been devised to tackle gaps in vehicle trajectories, even when the underlying road network is not considered. But the motion patterns of sailing vessels differ substantially, e.g., smooth turns, maneuvering near ports, or navigating in adverse weather conditions. In this application paper, we propose HABIT, a lightweight, configurable H3 Aggregation-Based Imputation framework for vessel Trajectories. This data-driven framework provides a valuable means to impute missing trajectory segments by extracting, analyzing, and indexing motion patterns from historical AIS data. Our empirical study over AIS data across various timeframes, densities, and vessel types reveals that HABIT produces maritime trajectory imputations performing comparably to baseline methods in terms of accuracy, while performing better in terms of latency while accounting for vessel characteristics and their motion patterns.", "AI": {"tldr": "提出了一种基于H3聚合的数据驱动船舶轨迹填补框架，用于改善海洋交通分析", "motivation": "解决自动识别系统（AIS）数据中的大量空白问题，提高海上活动监测的准确性和完整性", "method": "通过提取、分析和索引历史AIS数据中船只运动模式来填补缺失的航行轨迹片段", "result": "实验显示HABIT在准确性上与基线方法相当，在考虑船舶特性和运动模式时延迟更低", "conclusion": "所提出的框架为改善海洋交通分析提供了有效的手段"}}
{"id": "2602.11885", "pdf": "https://arxiv.org/pdf/2602.11885", "abs": "https://arxiv.org/abs/2602.11885", "authors": ["Yihao Wu", "Jinming Ma", "Junbo Tan", "Yanzhao Yu", "Shoujie Li", "Mingliang Zhou", "Diyun Xiang", "Xueqian Wang"], "title": "Learning to Manipulate Anything: Revealing Data Scaling Laws in Bounding-Box Guided Policies", "categories": ["cs.RO"], "comment": null, "summary": "Diffusion-based policies show limited generalization in semantic manipulation, posing a key obstacle to the deployment of real-world robots. This limitation arises because relying solely on text instructions is inadequate to direct the policy's attention toward the target object in complex and dynamic environments. To solve this problem, we propose leveraging bounding-box instruction to directly specify target object, and further investigate whether data scaling laws exist in semantic manipulation tasks. Specifically, we design a handheld segmentation device with an automated annotation pipeline, Label-UMI, which enables the efficient collection of demonstration data with semantic labels. We further propose a semantic-motion-decoupled framework that integrates object detection and bounding-box guided diffusion policy to improve generalization and adaptability in semantic manipulation. Throughout extensive real-world experiments on large-scale datasets, we validate the effectiveness of the approach, and reveal a power-law relationship between generalization performance and the number of bounding-box objects. Finally, we summarize an effective data collection strategy for semantic manipulation, which can achieve 85\\% success rates across four tasks on both seen and unseen objects. All datasets and code will be released to the community.", "AI": {"tldr": "该论文提出了使用边界框指导的策略来改善语义操纵任务中的泛化性能，并验证了数据规模与泛化效果之间的幂律关系。", "motivation": "当前基于扩散策略的方法在语义操纵中表现不佳，尤其在复杂多变的环境中难以仅通过文本指令准确操作目标对象。为解决这一问题，论文试图探索边界框指导的数据缩放定律以提高机器人实际部署中的适应性和泛化能力。", "method": "设计了一个手持分割设备和自动标注流水线Label-UMI来高效收集带语义标签的演示数据，并提出了一种将物体检测与边界框引导扩散策略结合的框架，提升了在语义操纵任务上的泛化能力和适应性。", "result": "通过大量真实世界实验验证了所提方法的有效性，在大规模数据集上展示了泛化性能和目标对象数量之间的幂律关系。最终，提出了一个有效的数据收集策略，成功率可达85%。", "conclusion": "该研究揭示了边界框指导的策略可以显著提高语义操纵任务中的泛化效果，并提供了一种高效的数据采集方法来支持机器人学习任何物体的操作技能。"}}
{"id": "2602.11882", "pdf": "https://arxiv.org/pdf/2602.11882", "abs": "https://arxiv.org/abs/2602.11882", "authors": ["Suraj Ranganath", "Anish Patnaik", "Vaishak Menon"], "title": "Where Bits Matter in World Model Planning: A Paired Mixed-Bit Study for Efficient Spatial Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "comment": "Workshop submission", "summary": "Efficient spatial reasoning requires world models that remain reliable under tight precision budgets. We study whether low-bit planning behavior is determined mostly by total bitwidth or by where bits are allocated across modules. Using DINO-WM on the Wall planning task, we run a paired-goal mixed-bit evaluation across uniform, mixed, asymmetric, and layerwise variants under two planner budgets. We observe a consistent three-regime pattern: 8-bit and 6-bit settings remain close to FP16, 3-bit settings collapse, and 4-bit settings are allocation-sensitive. In that transition region, preserving encoder precision improves planning relative to uniform quantization, and near-size asymmetric variants show the same encoder-side direction. In a later strict 22-cell replication with smaller per-cell episode count, the mixed-versus-uniform INT4 sign becomes budget-conditioned, which further highlights the sensitivity of this transition regime. These findings motivate module-aware, budget-aware quantization policies as a broader research direction for efficient spatial reasoning. Code and run artifacts are available at https://github.com/suraj-ranganath/DINO-MBQuant.", "AI": {"tldr": "研究在低精度预算下，规划行为是否主要由总位宽决定还是模块间的位分配决定。", "motivation": "探讨低比特位规划行为的决定因素是整体位宽还是各个模块之间的位分配，并探索高效空间推理的新量化策略。", "method": "使用DINO-WM在Wall规划任务中进行配对目标混合位评估，包括均匀、混合、非对称和层状变体，在两个规划者预算下运行实验。", "result": "观察到一致的三个阶段模式：8位和6位设置接近于FP16，3位设置崩溃，4位设置敏感于分配方式；在转换区域中，保持编码器精度优于均匀量化。", "conclusion": "模块意识预算意识量化策略是高效空间推理的一个重要研究方向。"}}
{"id": "2602.11881", "pdf": "https://arxiv.org/pdf/2602.11881", "abs": "https://arxiv.org/abs/2602.11881", "authors": ["Yifan Luo", "Yang Zhan", "Jiedong Jiang", "Tianyang Liu", "Mingrui Wu", "Zhennan Zhou", "Bin Dong"], "title": "From Atoms to Trees: Building a Structured Feature Forest with Hierarchical Sparse Autoencoders", "categories": ["cs.AI"], "comment": null, "summary": "Sparse autoencoders (SAEs) have proven effective for extracting monosemantic features from large language models (LLMs), yet these features are typically identified in isolation. However, broad evidence suggests that LLMs capture the intrinsic structure of natural language, where the phenomenon of \"feature splitting\" in particular indicates that such structure is hierarchical. To capture this, we propose the Hierarchical Sparse Autoencoder (HSAE), which jointly learns a series of SAEs and the parent-child relationships between their features. HSAE strengthens the alignment between parent and child features through two novel mechanisms: a structural constraint loss and a random feature perturbation mechanism. Extensive experiments across various LLMs and layers demonstrate that HSAE consistently recovers semantically meaningful hierarchies, supported by both qualitative case studies and rigorous quantitative metrics. At the same time, HSAE preserves the reconstruction fidelity and interpretability of standard SAEs across different dictionary sizes. Our work provides a powerful, scalable tool for discovering and analyzing the multi-scale conceptual structures embedded in LLM representations.", "AI": {"tldr": "论文提出了一种层次稀疏自编码器（HSAE）来从大型语言模型中抽取结构化的特征森林。", "motivation": "稀疏自编码器已经证明可以从大型语言模型中提取单一语义的特征，但这些特征往往是孤立存在的。证据表明，自然语言具有内在的层级结构，而“特征分裂”现象进一步说明这种结构是层次性的。为了捕捉这一点，论文提出了HSAE。", "method": "HSAE通过两个新的机制来增强父特征和子特征之间的对齐：结构约束损失和随机特征扰动机制。它同时学习一系列稀疏自编码器及其特征的父子关系。", "result": "实验结果表明，无论在不同的大型语言模型还是不同层次上，HSAE都能一致地恢复语义上有意义的层级结构，并且保持标准稀疏自编码器的重建保真度和可解释性。", "conclusion": "论文提出了一种用于发现和分析嵌入在大型语言模型表示中的多尺度概念结构的强大、可扩展工具。"}}
{"id": "2602.11880", "pdf": "https://arxiv.org/pdf/2602.11880", "abs": "https://arxiv.org/abs/2602.11880", "authors": ["Hongxu Yang", "Levente Lippenszky", "Edina Timko", "Gopal Avinash"], "title": "SynthRAR: Ring Artifacts Reduction in CT with Unrolled Network and Synthetic Data Training", "categories": ["cs.CV", "cs.AI"], "comment": "Prepare for submission", "summary": "Defective and inconsistent responses in CT detectors can cause ring and streak artifacts in the reconstructed images, making them unusable for clinical purposes. In recent years, several ring artifact reduction solutions have been proposed in the image domain or in the sinogram domain using supervised deep learning methods. However, these methods require dedicated datasets for training, leading to a high data collection cost. Furthermore, existing approaches focus exclusively on either image-space or sinogram-space correction, neglecting the intrinsic correlations from the forward operation of the CT geometry. Based on the theoretical analysis of non-ideal CT detector responses, the RAR problem is reformulated as an inverse problem by using an unrolled network, which considers non-ideal response together with linear forward-projection with CT geometry. Additionally, the intrinsic correlations of ring artifacts between the sinogram and image domains are leveraged through synthetic data derived from natural images, enabling the trained model to correct artifacts without requiring real-world clinical data. Extensive evaluations on diverse scanning geometries and anatomical regions demonstrate that the model trained on synthetic data consistently outperforms existing state-of-the-art methods.", "AI": {"tldr": "该论文提出了一种使用未卷展网络和合成数据训练来减少CT中的环形伪影的方法。", "motivation": "现有方法需要专门的数据集进行培训，成本高，并且只关注图像空间或sinogram空间的修正。本文通过理论分析将RAR问题重构为逆向问题并利用合成数据解决这些问题。", "method": "基于非理想CT探测器响应的理论分析，该论文提出了使用未卷展网络来处理环形伪影问题，并结合了线性前向投影和CT几何形状，同时利用来自自然图像的合成数据在sinogram和图像域之间建立内在联系。", "result": "实验结果表明，在各种扫描几何结构和解剖区域中，该模型优于现有最先进的方法。", "conclusion": "通过理论分析和创新技术的应用，所提出的基于未卷展网络的方法能够有效减少CT中的环形伪影。"}}
{"id": "2602.11877", "pdf": "https://arxiv.org/pdf/2602.11877", "abs": "https://arxiv.org/abs/2602.11877", "authors": ["Wanxing Wu", "He Zhu", "Yixia Li", "Lei Yang", "Jiehui Zhao", "Hongru Wang", "Jian Yang", "Benyou Wang", "Bingyi Jing", "Guanhua Chen"], "title": "Towards Fair and Comprehensive Evaluation of Routers in Collaborative LLM Systems", "categories": ["cs.CL", "cs.AI"], "comment": "Our code is publicly available at https://github.com/zhuchichi56/RouterXBench", "summary": "Large language models (LLMs) have achieved success, but cost and privacy constraints necessitate deploying smaller models locally while offloading complex queries to cloud-based models. Existing router evaluations are unsystematic, overlooking scenario-specific requirements and out-of-distribution robustness. We propose RouterXBench, a principled evaluation framework with three dimensions: router ability, scenario alignment, and cross-domain robustness. Unlike prior work that relies on output probabilities or external embeddings, we utilize internal hidden states that capture model uncertainty before answer generation. We introduce ProbeDirichlet, a lightweight router that aggregates cross-layer hidden states via learnable Dirichlet distributions with probabilistic training. Trained on multi-domain data, it generalizes robustly across in-domain and out-of-distribution scenarios. Our results show ProbeDirichlet achieves 16.68% and 18.86% relative improvements over the best baselines in router ability and high-accuracy scenarios, with consistent performance across model families, model scales, heterogeneous tasks, and agentic workflows.", "AI": {"tldr": "本文提出了一种新的评估框架RouterXBench，用于全面地评估路由器在协作LLM系统中的性能。", "motivation": "现有路由器评估方法缺乏系统的标准，并忽略了特定场景下的需求和跨域鲁棒性的问题。", "method": "提出了一个新的轻量级路由器ProbeDirichlet，利用内部隐藏状态来捕获模型的不确定性，使用可学习的狄利克雷分布对多层隐藏状态进行聚合。该方法在多个领域数据上训练，以提高其泛化能力。", "result": "实验结果显示，ProbeDirichlet在路由器能力和高精度场景中分别比最佳基线提高了16.68%和18.86%，并且在不同的模型家族、规模、异构任务及代理工作流程中的表现都是一致的。", "conclusion": "本文通过提出RouterXBench评估框架以及ProbeDirichlet路由器，展示了如何系统性地提高协作LLM系统的路由器性能，并且验证了其跨域鲁棒性的有效性。"}}
{"id": "2602.11875", "pdf": "https://arxiv.org/pdf/2602.11875", "abs": "https://arxiv.org/abs/2602.11875", "authors": ["Ji Li", "Zhiwei Li", "Shihao Li", "Zhenjiang Yu", "Boyang Wang", "Haiou Liu"], "title": "DiffPlace: Street View Generation via Place-Controllable Diffusion Model Enhancing Place Recognition", "categories": ["cs.CV", "cs.RO"], "comment": "accepted by ICRA 2026", "summary": "Generative models have advanced significantly in realistic image synthesis, with diffusion models excelling in quality and stability. Recent multi-view diffusion models improve 3D-aware street view generation, but they struggle to produce place-aware and background-consistent urban scenes from text, BEV maps, and object bounding boxes. This limits their effectiveness in generating realistic samples for place recognition tasks. To address these challenges, we propose DiffPlace, a novel framework that introduces a place-ID controller to enable place-controllable multi-view image generation. The place-ID controller employs linear projection, perceiver transformer, and contrastive learning to map place-ID embeddings into a fixed CLIP space, allowing the model to synthesize images with consistent background buildings while flexibly modifying foreground objects and weather conditions. Extensive experiments, including quantitative comparisons and augmented training evaluations, demonstrate that DiffPlace outperforms existing methods in both generation quality and training support for visual place recognition. Our results highlight the potential of generative models in enhancing scene-level and place-aware synthesis, providing a valuable approach for improving place recognition in autonomous driving", "AI": {"tldr": "本文提出了一种称为DiffPlace的新框架，该框架引入了一个地方ID控制器来生成可控制的地方和多视角图像。", "motivation": "现有的多视图扩散模型在三维感知街道视图的合成上有所进步，但它们难以根据文本、BEV地图和对象边界框产生符合地方特点且背景一致的城市场景。这限制了它们对地方识别任务的支持能力。", "method": "DiffPlace通过引入一个使用线性投影、受体变压器和对比学习来映射地方ID嵌入到固定CLIP空间中的地方ID控制器，使模型能够生成具有连贯背景建筑的图像同时灵活地修改前景对象和天气条件。", "result": "通过大量的实验，包括定量比较和增强训练评估，证明了DiffPlace在生成质量和用于视觉地方识别的训练支持上都优于现有方法。", "conclusion": "本文展示了生成模型在场景级和地方感知合成中的潜力，并为改善自动驾驶中地方识别提供了一种有价值的方法。"}}
{"id": "2602.11865", "pdf": "https://arxiv.org/pdf/2602.11865", "abs": "https://arxiv.org/abs/2602.11865", "authors": ["Nenad Tomašev", "Matija Franklin", "Simon Osindero"], "title": "Intelligent AI Delegation", "categories": ["cs.AI"], "comment": null, "summary": "AI agents are able to tackle increasingly complex tasks. To achieve more ambitious goals, AI agents need to be able to meaningfully decompose problems into manageable sub-components, and safely delegate their completion across to other AI agents and humans alike. Yet, existing task decomposition and delegation methods rely on simple heuristics, and are not able to dynamically adapt to environmental changes and robustly handle unexpected failures. Here we propose an adaptive framework for intelligent AI delegation - a sequence of decisions involving task allocation, that also incorporates transfer of authority, responsibility, accountability, clear specifications regarding roles and boundaries, clarity of intent, and mechanisms for establishing trust between the two (or more) parties. The proposed framework is applicable to both human and AI delegators and delegatees in complex delegation networks, aiming to inform the development of protocols in the emerging agentic web.", "AI": {"tldr": "提出了一种智能AI委托框架，该框架能够适应环境变化并处理意外故障。", "motivation": "现有的任务分解和委托方法依赖于简单的启发式算法，并且无法动态地适应环境变化或稳健地处理未预见的失败。为了实现更宏大的目标，需要一个可以有效解决这些问题的新框架。", "method": "设计了一个智能AI委托框架，该框架能够进行任务分配决策并包括权限转移、责任归属、清晰的角色和界限定义以及建立信任机制等内容。此方法适用于复杂委托网络中的人类或AI代理者与被委托者之间。", "result": "所提出的框架有助于开发新兴的代理网络中的协议，并且可以应用于多种场景下。", "conclusion": "该研究提出的方法为解决智能代理在网络环境下的任务分解和委托问题提供了一个可行方案。"}}
{"id": "2602.11862", "pdf": "https://arxiv.org/pdf/2602.11862", "abs": "https://arxiv.org/abs/2602.11862", "authors": ["Sibaek Lee", "Hyeonwoo Yu", "Giseop Kim", "Sunwook Choi"], "title": "LAMP: Implicit Language Map for Robot Navigation", "categories": ["cs.RO"], "comment": "Accepted for publication in IEEE Robotics and Automation Letters (RA-L). Project page: https://lab-of-ai-and-robotics.github.io/LAMP/", "summary": "Recent advances in vision-language models have made zero-shot navigation feasible, enabling robots to follow natural language instructions without requiring labeling. However, existing methods that explicitly store language vectors in grid or node-based maps struggle to scale to large environments due to excessive memory requirements and limited resolution for fine-grained planning. We introduce LAMP (Language Map), a novel neural language field-based navigation framework that learns a continuous, language-driven map and directly leverages it for fine-grained path generation. Unlike prior approaches, our method encodes language features as an implicit neural field rather than storing them explicitly at every location. By combining this implicit representation with a sparse graph, LAMP supports efficient coarse path planning and then performs gradient-based optimization in the learned field to refine poses near the goal. This coarse-to-fine pipeline, language-driven, gradient-guided optimization is the first application of an implicit language map for precise path generation. This refinement is particularly effective at selecting goal regions not directly observed by leveraging semantic similarities in the learned feature space. To further enhance robustness, we adopt a Bayesian framework that models embedding uncertainty via the von Mises-Fisher distribution, thereby improving generalization to unobserved regions. To scale to large environments, LAMP employs a graph sampling strategy that prioritizes spatial coverage and embedding confidence, retaining only the most informative nodes and substantially reducing computational overhead. Our experimental results, both in NVIDIA Isaac Sim and on a real multi-floor building, demonstrate that LAMP outperforms existing explicit methods in both memory efficiency and fine-grained goal-reaching accuracy.", "AI": {"tldr": "LAMP是一种新的神经语言场导航框架，通过学习连续的语言驱动地图来实现机器人在大环境中的精细路径规划。", "motivation": "现有的基于显式存储语言向量的方法难以扩展到大型环境中，因为它们需要大量内存并且分辨率有限，不适用于细粒度的路径规划。LAMP旨在解决这些问题，同时保持零样本导航的能力。", "method": "LAMP通过隐式神经场编码语言特征，并结合稀疏图进行粗略路径规划。在接近目标时，采用梯度导向优化来细化位置。这种方法可以利用语义相似性选择未直接观察到的目标区域。为了提高鲁棒性和减少计算负担，采用了贝叶斯框架和图形采样策略。", "result": "实验结果表明，LAMP不仅提高了记忆效率，而且在精细目标到达准确性方面也优于现有方法。", "conclusion": "通过引入隐式语言地图，LAMP能够在大型环境中实现高效的零样本导航。"}}
{"id": "2602.11860", "pdf": "https://arxiv.org/pdf/2602.11860", "abs": "https://arxiv.org/abs/2602.11860", "authors": ["Lu Tao", "Jinxuan Luo", "Yousuke Watanabe", "Zhengshu Zhou", "Yuhuan Lu", "Shen Ying", "Pan Zhang", "Fei Zhao", "Hiroaki Takada"], "title": "Talk2DM: Enabling Natural Language Querying and Commonsense Reasoning for Vehicle-Road-Cloud Integrated Dynamic Maps with Large Language Models", "categories": ["cs.AI"], "comment": "Submitted to IEEE TITS. Under review", "summary": "Dynamic maps (DM) serve as the fundamental information infrastructure for vehicle-road-cloud (VRC) cooperative autonomous driving in China and Japan. By providing comprehensive traffic scene representations, DM overcome the limitations of standalone autonomous driving systems (ADS), such as physical occlusions. Although DM-enhanced ADS have been successfully deployed in real-world applications in Japan, existing DM systems still lack a natural-language-supported (NLS) human interface, which could substantially enhance human-DM interaction. To address this gap, this paper introduces VRCsim, a VRC cooperative perception (CP) simulation framework designed to generate streaming VRC-CP data. Based on VRCsim, we construct a question-answering data set, VRC-QA, focused on spatial querying and reasoning in mixed-traffic scenes. Building upon VRCsim and VRC-QA, we further propose Talk2DM, a plug-and-play module that extends VRC-DM systems with NLS querying and commonsense reasoning capabilities. Talk2DM is built upon a novel chain-of-prompt (CoP) mechanism that progressively integrates human-defined rules with the commonsense knowledge of large language models (LLMs). Experiments on VRC-QA show that Talk2DM can seamlessly switch across different LLMs while maintaining high NLS query accuracy, demonstrating strong generalization capability. Although larger models tend to achieve higher accuracy, they incur significant efficiency degradation. Our results reveal that Talk2DM, powered by Qwen3:8B, Gemma3:27B, and GPT-oss models, achieves over 93\\% NLS query accuracy with an average response time of only 2-5 seconds, indicating strong practical potential.", "AI": {"tldr": "本文提出了Talk2DM模块，该模块为车辆道路云集成动态地图添加了自然语言查询和常识推理功能。", "motivation": "现有的动态地图系统缺乏支持自然语言的人机交互界面，这限制了人与系统的互动效果。为了改善这一情况，作者构建了一个框架来生成流式VRC感知数据，并基于此提出Talk2DM模块以增强动态地图的互动性和实用性。", "method": "通过使用新型提示链机制将人类定义规则和大型语言模型常识知识相结合，Talk2DM可以实现自然语言查询和常识推理功能。该方法在实验中表现出了良好的泛化能力。", "result": "实验表明，Talk2DM能够在不同大型语言模型之间无缝切换，并保持超过93%的自然语言查询准确性，平均响应时间仅为2-5秒，这显示了其强大的实际应用潜力。", "conclusion": "Talk2DM通过引入新颖的提示链机制增强了动态地图系统的互动性和实用性，证明了在车辆道路云集成环境中的有效性和效率。"}}
{"id": "2602.11858", "pdf": "https://arxiv.org/pdf/2602.11858", "abs": "https://arxiv.org/abs/2602.11858", "authors": ["Lai Wei", "Liangbo He", "Jun Lan", "Lingzhong Dong", "Yutong Cai", "Siyuan Li", "Huijia Zhu", "Weiqiang Wang", "Linghe Kong", "Yue Wang", "Zhuosheng Zhang", "Weiran Huang"], "title": "Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) excel at broad visual understanding but still struggle with fine-grained perception, where decisive evidence is small and easily overwhelmed by global context. Recent \"Thinking-with-Images\" methods alleviate this by iteratively zooming in and out regions of interest during inference, but incur high latency due to repeated tool calls and visual re-encoding. To address this, we propose Region-to-Image Distillation, which transforms zooming from an inference-time tool into a training-time primitive, thereby internalizing the benefits of agentic zooming into a single forward pass of an MLLM. In particular, we first zoom in to micro-cropped regions to let strong teacher models generate high-quality VQA data, and then distill this region-grounded supervision back to the full image. After training on such data, the smaller student model improves \"single-glance\" fine-grained perception without tool use. To rigorously evaluate this capability, we further present ZoomBench, a hybrid-annotated benchmark of 845 VQA data spanning six fine-grained perceptual dimensions, together with a dual-view protocol that quantifies the global--regional \"zooming gap\". Experiments show that our models achieve leading performance across multiple fine-grained perception benchmarks, and also improve general multimodal cognition on benchmarks such as visual reasoning and GUI agents. We further discuss when \"Thinking-with-Images\" is necessary versus when its gains can be distilled into a single forward pass. Our code is available at https://github.com/inclusionAI/Zooming-without-Zooming.", "AI": {"tldr": "该论文提出了一种名为“Region-to-Image Distillation”的方法，用于解决多模态大型语言模型在细粒度视觉感知中的难题。", "motivation": "现有多模态大型语言模型虽然擅长广泛的视觉理解，但在处理需要高度细节的场景时表现不佳。传统的方法通过迭代放大缩小感兴趣的区域来改善这一问题，但这会导致高延迟。论文旨在解决这个问题，并将放大功能内化为训练过程的一部分，从而在单次前向传递中提高模型性能。", "method": "该方法首先对微小裁剪区域进行放大处理，利用强大的教师模型生成高质量的VQA数据，然后将这种基于区域的数据反向传播到整个图像。通过这种方法，较小的学生模型可以在不使用工具的情况下提升其细粒度视觉感知能力。", "result": "实验表明，该方法在多个细粒度感知基准测试中表现出色，并且提升了多模态认知任务如视觉推理和GUI代理上的性能。", "conclusion": "该论文提出了“Region-to-Image Distillation”方法来解决多模态大型语言模型在处理细粒度视觉数据时的挑战，展示了这种方法的有效性并讨论了其应用范围。"}}
{"id": "2602.11855", "pdf": "https://arxiv.org/pdf/2602.11855", "abs": "https://arxiv.org/abs/2602.11855", "authors": ["Ayato Kitadai", "Takumi Ito", "Yumiko Nagoh", "Hiroki Takahashi", "Masanori Fujita", "Sangjic Lee", "Fumiaki Miyahara", "Tetsu Natsume", "Nariaki Nishino"], "title": "Decision Support System for Technology Opportunity Discovery: An Application of the Schwartz Theory of Basic Values", "categories": ["cs.HC"], "comment": "24 pages, 5 figures", "summary": "Discovering technology opportunities (TOD) remains a critical challenge for innovation management, especially in early-stage development where consumer needs are often unclear. Existing methods frequently fail to systematically incorporate end-user perspectives, resulting in a misalignment between technological potentials and market relevance. This study proposes a novel decision support framework that bridges this gap by linking technological feasibility with fundamental human values. The framework integrates two distinct lenses: the engineering-based Technology Readiness Levels (TRL) and Schwartz's theory of basic human values. By combining these, the approach enables a structured exploration of how emerging technologies may satisfy diverse user motivations. To illustrate the framework's feasibility and insight potential, we conducted exploratory workshops with general consumers and internal experts at Sony Computer Science Laboratories, Inc., analyzing four real-world technologies (two commercial successes and two failures). Two consistent patterns emerged: (1) internal experts identified a wider value landscape than consumers (vision gap), and (2) successful technologies exhibited a broader range of associated human values (value breadth), suggesting strategic foresight may underpin market success. This study contributes both a practical tool for early-stage R\\&D decision-making and a theoretical link between value theory and innovation outcomes. While exploratory in scope, the findings highlight the promise of value-centric evaluation as a foundation for more human-centered technology opportunity discovery.", "AI": {"tldr": "提出了一种结合技术准备水平和斯沃茨基本价值观理论的决策支持框架，用于早期阶段的技术机会发现", "motivation": "现有的技术机会发现方法通常未能系统地融入终端用户的观点，导致技术创新与市场需求不匹配。本研究旨在通过整合工程技术和人类价值视角来解决这一问题", "method": "该框架结合了工程技术准备水平（TRL）和斯沃茨基本价值观理论，并通过与索尼计算机科学实验室的消费者和内部专家进行探索性研讨会验证其可行性", "result": "两种一致模式：内部专家识别的价值观范围大于消费者，成功的技术具有更广泛的价值关联", "conclusion": "此研究提供了一种实用工具用于早期研发决策，并建立了价值理论与创新结果之间的联系"}}
{"id": "2602.11852", "pdf": "https://arxiv.org/pdf/2602.11852", "abs": "https://arxiv.org/abs/2602.11852", "authors": ["Yordan Yordanov", "Matteo Forasassi", "Bayar Menzat", "Ruizhi Wang", "Chang Qi", "Markus Kaltenberger", "Amine M'Charrak", "Tommaso Salvatori", "Thomas Lukasiewicz"], "title": "Prototype Transformer: Towards Language Model Architectures Interpretable by Design", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Preprint under review. Equal contribution: Yordan Yordanov and Matteo Forasassi. 39 pages, 25 figures, 22 tables", "summary": "While state-of-the-art language models (LMs) surpass the vast majority of humans in certain domains, their reasoning remains largely opaque, undermining trust in their output. Furthermore, while autoregressive LMs can output explicit reasoning, their true reasoning process is opaque, which introduces risks like deception and hallucination. In this work, we introduce the Prototype Transformer (ProtoT) -- an autoregressive LM architecture based on prototypes (parameter vectors), posed as an alternative to the standard self-attention-based transformers. ProtoT works by means of two-way communication between the input sequence and the prototypes, and we show that this leads to the prototypes automatically capturing nameable concepts (e.g. \"woman\") during training. They provide the potential to interpret the model's reasoning and allow for targeted edits of its behavior. Furthermore, by design, the prototypes create communication channels that aggregate contextual information at different time scales, aiding interpretability. In terms of computation scalability, ProtoT scales linearly with sequence length vs the quadratic scalability of SOTA self-attention transformers. Compared to baselines, ProtoT scales well with model and data size, and performs well on text generation and downstream tasks (GLUE). ProtoT exhibits robustness to input perturbations on par or better than some baselines, but differs from them by providing interpretable pathways showing how robustness and sensitivity arises. Reaching close to the performance of state-of-the-art architectures, ProtoT paves the way to creating well-performing autoregressive LMs interpretable by design.", "AI": {"tldr": "提出了一种基于原型的Transformer架构，旨在创建可解释的语言模型。", "motivation": "现有语言模型在某些领域的表现超过了大多数人类，但其推理过程不透明，导致输出可信度低。作者通过引入原型机制来提高模型的可解释性，并减少风险如欺骗和幻觉的发生。", "method": "提出了一种基于原型（参数向量）的Transformer架构——Prototype Transformer (ProtoT)，该架构通过输入序列与原型之间的双向通信工作，从而在训练过程中自动捕捉到可以命名的概念。此方法设计了能够聚合不同时间尺度上上下文信息的通信通道，提高了模型的可解释性。", "result": "相较于基线模型，ProtoT在文本生成和下游任务(GLUE)方面表现出色，并且其性能接近当前最先进的架构水平。此外，ProtoT对输入扰动表现出与某些基线相当或更好的鲁棒性。", "conclusion": "Prototype Transformer是一种可解释的语言模型架构设计方法，它不仅保持了高性能，还通过自动捕捉概念和聚合上下文信息提高了模型的可解释性和透明度。"}}
{"id": "2602.11851", "pdf": "https://arxiv.org/pdf/2602.11851", "abs": "https://arxiv.org/abs/2602.11851", "authors": ["André García Gómez", "Ines Rieger", "Wolfgang Hotwagner", "Max Landauer", "Markus Wurzenberger", "Florian Skopik", "Edgar Weippl"], "title": "Resource-Aware Deployment Optimization for Collaborative Intrusion Detection in Layered Networks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Collaborative Intrusion Detection Systems (CIDS) are increasingly adopted to counter cyberattacks, as their collaborative nature enables them to adapt to diverse scenarios across heterogeneous environments. As distributed critical infrastructure operates in rapidly evolving environments, such as drones in both civil and military domains, there is a growing need for CIDS architectures that can flexibly accommodate these dynamic changes. In this study, we propose a novel CIDS framework designed for easy deployment across diverse distributed environments. The framework dynamically optimizes detector allocation per node based on available resources and data types, enabling rapid adaptation to new operational scenarios with minimal computational overhead. We first conducted a comprehensive literature review to identify key characteristics of existing CIDS architectures. Based on these insights and real-world use cases, we developed our CIDS framework, which we evaluated using several distributed datasets that feature different attack chains and network topologies. Notably, we introduce a public dataset based on a realistic cyberattack targeting a ground drone aimed at sabotaging critical infrastructure. Experimental results demonstrate that the proposed CIDS framework can achieve adaptive, efficient intrusion detection in distributed settings, automatically reconfiguring detectors to maintain an optimal configuration, without requiring heavy computation, since all experiments were conducted on edge devices.", "AI": {"tldr": "提出了一种适应性协作入侵检测系统框架，能够在不同资源环境下快速部署和优化。", "motivation": "为了应对动态变化的分布式环境中日益复杂的网络攻击，研究团队开发了这种能够根据节点可用资源和数据类型灵活分配检测器的新CIDS架构。", "method": "通过文献回顾确定现有CIDS的关键特征，并基于这些见解以及实际案例构建新框架。使用包含不同攻击链路和网络拓扑的分布式数据集进行评估。", "result": "实验表明，所提出的CIDS能够在分布式环境中实现自适应、高效的入侵检测，无需大量计算即可自动重新配置检测器以保持最优状态。", "conclusion": "该研究成功展示了新框架在实际应用中的潜力和效果，能够满足不同环境下动态变化的网络安全需求。"}}
{"id": "2602.11850", "pdf": "https://arxiv.org/pdf/2602.11850", "abs": "https://arxiv.org/abs/2602.11850", "authors": ["Chenru Wang", "Beier Zhu", "Chi Zhang"], "title": "Free Lunch for Stabilizing Rectified Flow Inversion", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Rectified-Flow (RF)-based generative models have recently emerged as strong alternatives to traditional diffusion models, demonstrating state-of-the-art performance across various tasks. By learning a continuous velocity field that transforms simple noise into complex data, RF-based models not only enable high-quality generation, but also support training-free inversion, which facilitates downstream tasks such as reconstruction and editing. However, existing inversion methods, such as vanilla RF-based inversion, suffer from approximation errors that accumulate across timesteps, leading to unstable velocity fields and degraded reconstruction and editing quality. To address this challenge, we propose Proximal-Mean Inversion (PMI), a training-free gradient correction method that stabilizes the velocity field by guiding it toward a running average of past velocities, constrained within a theoretically derived spherical Gaussian. Furthermore, we introduce mimic-CFG, a lightweight velocity correction scheme for editing tasks, which interpolates between the current velocity and its projection onto the historical average, balancing editing effectiveness and structural consistency. Extensive experiments on PIE-Bench demonstrate that our methods significantly improve inversion stability, image reconstruction quality, and editing fidelity, while reducing the required number of neural function evaluations. Our approach achieves state-of-the-art performance on the PIE-Bench with enhanced efficiency and theoretical soundness.", "AI": {"tldr": "本文提出了一种名为Proximal-Mean Inversion (PMI)的方法，用于稳定基于Rectified Flow模型的逆向过程，并引入了一个轻量级的速度校正方案mimic-CFG来提高编辑任务的质量。", "motivation": "现有基于Rectified-Flow的生成模型在训练后能够进行自由倒推以实现下游任务如重建和编辑。但这种倒推方法因时间步长中累积近似误差导致不稳定，影响了质量和效果。", "method": "本文提出Proximal-Mean Inversion (PMI)通过指导速度场向过去的速度平均值趋近来稳定它，并引入mimic-CFG在编辑任务上平衡编辑效果和结构一致性。这些方法基于理论推导的球形高斯约束进行。", "result": "实验表明，所提方法显著提高了逆向过程的稳定性、图像重建质量和编辑准确度，同时降低了神经网络函数评估次数，并在PIE-Bench上达到了最先进的性能。", "conclusion": "该研究通过理论与实践验证了新方案的有效性，在稳定速度场的同时提升了基于Rectified-Flow模型的生成任务的质量和效率。"}}
{"id": "2602.11845", "pdf": "https://arxiv.org/pdf/2602.11845", "abs": "https://arxiv.org/abs/2602.11845", "authors": ["Qisen Wang", "Yifan Zhao", "Jia Li"], "title": "WorldTree: Towards 4D Dynamic Worlds from Monocular Video using Tree-Chains", "categories": ["cs.CV"], "comment": null, "summary": "Dynamic reconstruction has achieved remarkable progress, but there remain challenges in monocular input for more practical applications. The prevailing works attempt to construct efficient motion representations, but lack a unified spatiotemporal decomposition framework, suffering from either holistic temporal optimization or coupled hierarchical spatial composition. To this end, we propose WorldTree, a unified framework comprising Temporal Partition Tree (TPT) that enables coarse-to-fine optimization based on the inheritance-based partition tree structure for hierarchical temporal decomposition, and Spatial Ancestral Chains (SAC) that recursively query ancestral hierarchical structure to provide complementary spatial dynamics while specializing motion representations across ancestral nodes. Experimental results on different datasets indicate that our proposed method achieves 8.26% improvement of LPIPS on NVIDIA-LS and 9.09% improvement of mLPIPS on DyCheck compared to the second-best method. Code: https://github.com/iCVTEAM/WorldTree.", "AI": {"tldr": "本文提出了一种名为WorldTree的统一框架，用于从单目视频中重建4D动态世界。", "motivation": "当前动态重建工作在单目输入方面面临挑战，缺乏一个统一的时间空间分解框架，导致整体时间优化或耦合的空间层次组成的问题。", "method": "WorldTree包括Temporal Partition Tree(TPT)和Spatial Ancestral Chains(SAC)，TPT通过继承式的划分树结构实现从粗到细的优化；SAC递归查询祖先层次结构提供互补的空间动态，同时在祖先节点之间专业化运动表示。", "result": "实验结果表明，在NVIDIA-LS数据集上，该方法比第二好方法提高了8.26%的LPIPS指标，在DyCheck数据集上提高了9.09%的mLPIPS指标。", "conclusion": "WorldTree提供了一种有效的方法来处理单目视频中的动态重建挑战。"}}
{"id": "2602.11841", "pdf": "https://arxiv.org/pdf/2602.11841", "abs": "https://arxiv.org/abs/2602.11841", "authors": ["Moncef Garouani", "Josiane Mothe"], "title": "Improving Neural Retrieval with Attribution-Guided Query Rewriting", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "Neural retrievers are effective but brittle: underspecified or ambiguous queries can misdirect ranking even when relevant documents exist. Existing approaches address this brittleness only partially: LLMs rewrite queries without retriever feedback, and explainability methods identify misleading tokens but are used for post-hoc analysis. We close this loop and propose an attribution-guided query rewriting method that uses token-level explanations to guide query rewriting. For each query, we compute gradient-based token attributions from the retriever and then use these scores as soft guidance in a structured prompt to an LLM that clarifies weak or misleading query components while preserving intent. Evaluated on BEIR collections, the resulting rewrites consistently improve retrieval effectiveness over strong baselines, with larger gains for implicit or ambiguous information needs.", "AI": {"tldr": "提出了一种基于归因的查询重写方法，通过使用检索器的令牌级解释来指导LLM澄清弱或误导性的查询部分。", "motivation": "现有的神经检索技术在处理不明确或模糊查询时表现不佳。论文旨在解决这一问题，通过引入一种闭环机制，结合检索器反馈和基于归因的方法来改进查询重写。", "method": "计算检索器的令牌级归因分数，并将其作为软指导用于结构化提示中的LLM，以澄清弱或误导性的查询部分。", "result": "在BEIR集合上进行评估后，该方法显著提高了检索的有效性，在处理隐含或模糊信息需求时表现更佳。", "conclusion": "基于归因的查询重写方法成功解决了神经检索器在面对不明确或模糊查询时的问题，并提升了整体检索效果。"}}
{"id": "2602.11836", "pdf": "https://arxiv.org/pdf/2602.11836", "abs": "https://arxiv.org/abs/2602.11836", "authors": ["Alishbah Bashir", "Fatima Qaiser", "Ijaz Hussain"], "title": "ULTRA:Urdu Language Transformer-based Recommendation Architecture", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Urdu, as a low-resource language, lacks effective semantic content recommendation systems, particularly in the domain of personalized news retrieval. Existing approaches largely rely on lexical matching or language-agnostic techniques, which struggle to capture semantic intent and perform poorly under varying query lengths and information needs. This limitation results in reduced relevance and adaptability in Urdu content recommendation. We propose ULTRA (Urdu Language Transformer-based Recommendation Architecture),an adaptive semantic recommendation framework designed to address these challenges. ULTRA introduces a dual-embedding architecture with a query-length aware routing mechanism that dynamically distinguishes between short, intent-focused queries and longer, context-rich queries. Based on a threshold-driven decision process, user queries are routed to specialized semantic pipelines optimized for either title/headline-level or full-content/document level representations, ensuring appropriate semantic granularity during retrieval. The proposed system leverages transformer-based embeddings and optimized pooling strategies to move beyond surface-level keyword matching and enable context-aware similarity search. Extensive experiments conducted on a large-scale Urdu news corpus demonstrate that the proposed architecture consistently improves recommendation relevance across diverse query types. Results show gains in precision above 90% compared to single-pipeline baselines, highlighting the effectiveness of query-adaptive semantic alignment for low-resource languages. The findings establish ULTRA as a robust and generalizable content recommendation architecture, offering practical design insights for semantic retrieval systems in low-resource language settings.", "AI": {"tldr": "提出了一种基于Transformer的推荐架构ULTRA，用于改善乌尔都语个性化新闻检索中的内容推荐系统。", "motivation": "乌尔都语作为低资源语言，在有效捕捉语义意图和个人化新闻检索方面存在不足。现有方法依赖于词汇匹配或语言无关技术，难以适应不同查询长度和信息需求，影响了推荐的相关性和灵活性。", "method": "ULTRA采用双嵌入架构结合查询长度感知路由机制，根据阈值驱动的决策过程将用户查询导向特定语义管线进行处理。通过Transformer基嵌入技术和优化池策略实现超越表面词汇匹配的内容相关性搜索。", "result": "实验结果显示，与单通道基线相比，在各种查询类型下推荐的相关性提高了90%以上，表明适应查询长度的语义对齐在低资源语言环境中有效。", "conclusion": "ULTRA架构展示了强大的鲁棒性和普遍适用性，为低资源语言环境下语义检索系统的实际设计提供了宝贵见解。"}}
{"id": "2602.11832", "pdf": "https://arxiv.org/pdf/2602.11832", "abs": "https://arxiv.org/abs/2602.11832", "authors": ["Shangchen Miao", "Ningya Feng", "Jialong Wu", "Ye Lin", "Xu He", "Dong Li", "Mingsheng Long"], "title": "JEPA-VLA: Video Predictive Embedding is Needed for VLA Models", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Recent vision-language-action (VLA) models built upon pretrained vision-language models (VLMs) have achieved significant improvements in robotic manipulation. However, current VLAs still suffer from low sample efficiency and limited generalization. This paper argues that these limitations are closely tied to an overlooked component, pretrained visual representation, which offers insufficient knowledge on both aspects of environment understanding and policy prior. Through an in-depth analysis, we find that commonly used visual representations in VLAs, whether pretrained via language-image contrastive learning or image-based self-supervised learning, remain inadequate at capturing crucial, task-relevant environment information and at inducing effective policy priors, i.e., anticipatory knowledge of how the environment evolves under successful task execution. In contrast, we discover that predictive embeddings pretrained on videos, in particular V-JEPA 2, are adept at flexibly discarding unpredictable environment factors and encoding task-relevant temporal dynamics, thereby effectively compensating for key shortcomings of existing visual representations in VLAs. Building on these observations, we introduce JEPA-VLA, a simple yet effective approach that adaptively integrates predictive embeddings into existing VLAs. Our experiments demonstrate that JEPA-VLA yields substantial performance gains across a range of benchmarks, including LIBERO, LIBERO-plus, RoboTwin2.0, and real-robot tasks.", "AI": {"tldr": "本文提出了JEPA-VLA方法，通过将基于视频的预测嵌入融入到现有的VLA模型中，提高机器人操作任务的表现。", "motivation": "当前的视觉-语言-动作(VLA)模型虽然在预训练的视觉和语言模型基础上取得了显著进步，但仍存在样本效率低和泛化能力有限的问题。这些问题归因于预训练的视觉表示缺乏对环境理解和策略优先级的有效信息。", "method": "本文通过深入分析发现视频预测嵌入比传统的图像对比学习或自我监督学习生成的视觉表示更能灵活地排除不可预测的因素，编码与任务相关的动态变化，并有效弥补现有视觉表示中的关键缺陷。基于此观察，提出了JEPA-VLA方法，该方法可以将这些预测嵌入适应性集成到现有的VLA模型中。", "result": "实验结果表明，JEPA-VLA在LIBERO、LIBERO-plus、RoboTwin2.0以及真实机器人任务上的表现都得到了显著提升。", "conclusion": "本文通过引入视频预测嵌入来改善现有VLA模型的性能，证明了这种集成方法的有效性，并展示了其在多个基准测试中的优越结果。"}}
{"id": "2602.11826", "pdf": "https://arxiv.org/pdf/2602.11826", "abs": "https://arxiv.org/abs/2602.11826", "authors": ["Mirabel Mendoza-Cadena", "Arturo Merino", "Mads Anker Nielsen", "Kevin Schewior"], "title": "Combinatorial Perpetual Scheduling", "categories": ["cs.DS"], "comment": null, "summary": "This paper introduces a framework for combinatorial variants of perpetual-scheduling problems. Given a set system $(E,\\mathcal{I})$, a schedule consists of an independent set $I_t \\in \\mathcal{I}$ for every time step $t \\in \\mathbb{N}$, with the objective of fulfilling frequency requirements on the occurrence of elements in $E$. We focus specifically on combinatorial bamboo garden trimming, where elements accumulate height at growth rates $g(e)$ for $e \\in E$ given as a convex combination of incidence vectors of $\\mathcal{I}$ and are reset to zero when scheduled, with the goal of minimizing the maximum height attained by any element. Using the integrality of the matroid-intersection polytope, we prove that, when $(E,\\mathcal{I})$ is a matroid, it is possible to guarantee a maximum height of at most 2, which is optimal. We complement this existential result with efficient algorithms for specific matroid classes, achieving a maximum height of 2 for uniform and partition matroids, and 4 for graphic and laminar matroids. In contrast, we show that for general set systems, the optimal guaranteed height is $Θ(\\log |E|)$ and can be achieved by an efficient algorithm. For combinatorial pinwheel scheduling, where each element $e\\in E$ needs to occur in the schedule at least every $a_e \\in \\mathbb{N}$ time steps, our results imply bounds on the density sufficient for schedulability.", "AI": {"tldr": "该论文提出了一种用于组合性永续调度问题的框架，并针对特定类型的组合性竹园修剪和组合性轮转调度，提供了高度最优或密度足够的保证。", "motivation": "为了处理元素累积增长并重置的需求，在给定一组集合的情况下，优化独立集的选择以满足频率要求", "method": "利用拟阵交割多面体的整数性质证明了当(E, I)是拟准时可以确保最大高度不超过2。对于特定类型的拟阵如均匀和分区拟矩阵实现了最优算法。", "result": "对组合性竹园修剪，提出了一个保证最大高度为2（如果是均匀或分区拟阵）或4（如果是图形或层次拟阵）。同时表明对于一般的集系统，可以通过有效的算法实现最大高度Θ(log|E|)的保证。", "conclusion": "通过引入组合性永续调度框架，并针对特定类型的组合问题提供了最优或接近最优的结果。"}}
{"id": "2602.11824", "pdf": "https://arxiv.org/pdf/2602.11824", "abs": "https://arxiv.org/abs/2602.11824", "authors": ["Jialin Wu", "Wei Shi", "Han Shen", "Peigui Qi", "Kunsheng Tang", "Zhicong Huang", "Binghao Wang", "Zhou Yang"], "title": "Revis: Sparse Latent Steering to Mitigate Object Hallucination in Large Vision-Language Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Despite the advanced capabilities of Large Vision-Language Models (LVLMs), they frequently suffer from object hallucination. One reason is that visual features and pretrained textual representations often become intertwined in the deeper network layers. To address this, we propose REVIS, a training-free framework designed to explicitly re-activate this suppressed visual information. Rooted in latent space geometry, REVIS extracts the pure visual information vector via orthogonal projection and employs a calibrated strategy to perform sparse intervention only at the precise depth where suppression occurs. This surgical approach effectively restores visual information with minimal computational cost. Empirical evaluations on standard benchmarks demonstrate that REVIS reduces object hallucination rates by approximately 19% compared to state-of-the-art baselines, while preserving general reasoning capabilities.", "AI": {"tldr": "提出了一种无需训练的框架REVIS，通过稀疏干预恢复视觉信息来减少大型视觉语言模型中的对象幻觉问题。", "motivation": "大型视觉语言模型经常出现对象幻觉问题，这可能是由于视觉特征和预训练文本表示在深层网络中融合导致。为了解决这个问题，提出了REVIS框架。", "method": "REVIS通过正交投影提取纯视觉信息向量，并采用校准策略，在具体深度层进行稀疏干预来恢复被抑制的视觉信息。", "result": "实验证明，与最先进的基线相比，REVIS将对象幻觉率降低了约19%，同时保持了一般推理能力。", "conclusion": "通过提出的方法，可以在不牺牲其他功能的情况下有效减少大型视觉语言模型中的对象幻觉问题。"}}
{"id": "2602.11814", "pdf": "https://arxiv.org/pdf/2602.11814", "abs": "https://arxiv.org/abs/2602.11814", "authors": ["Nathan Buskulic", "Luca Calatroni"], "title": "A Comparative Study of MAP and LMMSE Estimators for Blind Inverse Problems", "categories": ["cs.IT", "cs.CV", "cs.LG"], "comment": null, "summary": "Maximum-a-posteriori (MAP) approaches are an effective framework for inverse problems with known forward operators, particularly when combined with expressive priors and careful parameter selection. In blind settings, however, their use becomes significantly less stable due to the inherent non-convexity of the problem and the potential non-identifiability of the solutions. (Linear) minimum mean square error (MMSE) estimators provide a compelling alternative that can circumvent these limitations. In this work, we study synthetic two-dimensional blind deconvolution problems under fully controlled conditions, with complete prior knowledge of both the signal and kernel distributions. We compare tailored MAP algorithms with simple LMMSE estimators whose functional form is closely related to that of an optimal Tikhonov estimator. Our results show that, even in these highly controlled settings, MAP methods remain unstable and require extensive parameter tuning, whereas the LMMSE estimator yields a robust and reliable baseline. Moreover, we demonstrate empirically that the LMMSE solution can serve as an effective initialization for MAP approaches, improving their performance and reducing sensitivity to regularization parameters, thereby opening the door to future theoretical and practical developments.", "AI": {"tldr": "对比研究了最大后验概率（MAP）和最小均方误差（LMMSE）估计器在盲逆问题中的性能。", "motivation": "由于盲设置下的非凸性和潜在的解不可识别性，使得MAP方法不够稳定。LMMSE估计器作为替代方案可以克服这些问题。", "method": "研究了合成二维盲反卷积问题，在完全控制条件下，比较定制的MAP算法与简单的LMMSE估计器（形式上类似于最优Tikhonov估计器）。", "result": "结果显示，即使在受控设置中，MAP方法仍不稳定且需要大量参数调整，而LMMSE估计器表现稳健可靠。此外，实验证明LMMSE解可用作MAP方法的有效初始化。", "conclusion": "研究表明，在盲逆问题中，LMMSE估计器比MAP方法更稳定并提供可靠的基准线。同时，LMMSE作为MAP的初始化可以改善其性能和减少对正则化参数的敏感性，为未来的研究提供了理论与实践基础。"}}
{"id": "2602.11812", "pdf": "https://arxiv.org/pdf/2602.11812", "abs": "https://arxiv.org/abs/2602.11812", "authors": ["Huanyi Xie", "Yubin Chen", "Liangyu Wang", "Lijie Hu", "Di Wang"], "title": "Predicting LLM Output Length via Entropy-Guided Representations", "categories": ["cs.AI"], "comment": null, "summary": "The long-tailed distribution of sequence lengths in LLM serving and reinforcement learning (RL) sampling causes significant computational waste due to excessive padding in batched inference. Existing methods rely on auxiliary models for static length prediction, but they incur high overhead, generalize poorly, and fail in stochastic \"one-to-many\" sampling scenarios. We introduce a lightweight framework that reuses the main model's internal hidden states for efficient length prediction. Our framework features two core components: 1) Entropy-Guided Token Pooling (EGTP), which uses on-the-fly activations and token entropy for highly accurate static prediction with negligible cost, and 2) Progressive Length Prediction (PLP), which dynamically estimates the remaining length at each decoding step to handle stochastic generation. To validate our approach, we build and release ForeLen, a comprehensive benchmark with long-sequence, Chain-of-Thought, and RL data. On ForeLen, EGTP achieves state-of-the-art accuracy, reducing MAE by 29.16\\% over the best baseline. Integrating our methods with a length-aware scheduler yields significant end-to-end throughput gains. Our work provides a new technical and evaluation baseline for efficient LLM inference.", "AI": {"tldr": "本文提出了一种轻量级框架，用于通过重用主模型的内部隐藏状态来高效预测LLM输出长度。", "motivation": "长尾分布的序列长度导致了批量推理中的过度填充，从而造成了大量的计算浪费。现有的依赖辅助模型的方法存在高开销、泛化能力差以及无法处理随机“一对多”采样场景的问题。", "method": "本文提出了两种核心组件：1）基于实时激活和令牌熵的EGTP，用于准确且成本低廉的静态长度预测；2）动态估计解码过程中剩余长度的PLP，以应对随机生成问题。此外，建立了ForeLen基准来验证方法的有效性。", "result": "在ForeLen基准上，EGTP实现了最先进的精度，比最佳基线减少了29.16%的MAE错误率；结合长度感知调度器后，整体端到端吞吐量得到了显著提升。", "conclusion": "本文通过重用模型内部隐藏状态提出了一种高效预测LLM输出长度的方法，并提供了新的技术与评估基准。"}}
{"id": "2602.11810", "pdf": "https://arxiv.org/pdf/2602.11810", "abs": "https://arxiv.org/abs/2602.11810", "authors": ["Marko Putak", "Thomas B. Moeslund", "Joakim Bruslund Haurum"], "title": "How to Sample High Quality 3D Fractals for Action Recognition Pre-Training?", "categories": ["cs.CV", "cs.LG"], "comment": "12 pages, 6 figures. To be published in VISAPP", "summary": "Synthetic datasets are being recognized in the deep learning realm as a valuable alternative to exhaustively labeled real data. One such synthetic data generation method is Formula Driven Supervised Learning (FDSL), which can provide an infinite number of perfectly labeled data through a formula driven approach, such as fractals or contours. FDSL does not have common drawbacks like manual labor, privacy and other ethical concerns. In this work we generate 3D fractals using 3D Iterated Function Systems (IFS) for pre-training an action recognition model. The fractals are temporally transformed to form a video that is used as a pre-training dataset for downstream task of action recognition. We find that standard methods of generating fractals are slow and produce degenerate 3D fractals. Therefore, we systematically explore alternative ways of generating fractals and finds that overly-restrictive approaches, while generating aesthetically pleasing fractals, are detrimental for downstream task performance. We propose a novel method, Targeted Smart Filtering, to address both the generation speed and fractal diversity issue. The method reports roughly 100 times faster sampling speed and achieves superior downstream performance against other 3D fractal filtering methods.", "AI": {"tldr": "通过生成高质量的三维分形样本以提高动作识别模型的预训练效果。", "motivation": "使用合成数据集作为标记真实数据的替代品，可以避免手动劳动、隐私和伦理问题。本研究旨在探索更高效且多样化的3D分形生成方法，以便用于动作识别任务的预训练。", "method": "提出了一种新的方法“目标化智能过滤”，以解决传统分形生成速度慢且产生退化样本的问题，同时保证了下游任务性能。", "result": "该方法实现了比其他3D分形筛选方法快约100倍的采样速度，并在动作识别任务中取得了更好的表现。", "conclusion": "通过改进的三维分形生成方法可以有效提高预训练模型的效果，同时保持生成过程的速度和多样性。"}}
{"id": "2602.11807", "pdf": "https://arxiv.org/pdf/2602.11807", "abs": "https://arxiv.org/abs/2602.11807", "authors": ["Lianjun Wu", "Shengchen Zhu", "Yuxuan Liu", "Liuyu Kai", "Xiaoduan Feng", "Duomin Wang", "Wenshuo Liu", "Jingxuan Zhang", "Kelvin Li", "Bin Wang"], "title": "PuYun-LDM: A Latent Diffusion Model for High-Resolution Ensemble Weather Forecasts", "categories": ["cs.AI"], "comment": null, "summary": "Latent diffusion models (LDMs) suffer from limited diffusability in high-resolution (<=0.25°) ensemble weather forecasting, where diffusability characterizes how easily a latent data distribution can be modeled by a diffusion process. Unlike natural image fields, meteorological fields lack task-agnostic foundation models and explicit semantic structures, making VFM-based regularization inapplicable. Moreover, existing frequency-based approaches impose identical spectral regularization across channels under a homogeneity assumption, which leads to uneven regularization strength under the inter-variable spectral heterogeneity in multivariate meteorological data. To address these challenges, we propose a 3D Masked AutoEncoder (3D-MAE) that encodes weather-state evolution features as an additional conditioning for the diffusion model, together with a Variable-Aware Masked Frequency Modeling (VA-MFM) strategy that adaptively selects thresholds based on the spectral energy distribution of each variable. Together, we propose PuYun-LDM, which enhances latent diffusability and achieves superior performance to ENS at short lead times while remaining comparable to ENS at longer horizons. PuYun-LDM generates a 15-day global forecast with a 6-hour temporal resolution in five minutes on a single NVIDIA H200 GPU, while ensemble forecasts can be efficiently produced in parallel.", "AI": {"tldr": "提出了一种新的高分辨率集合天气预报模型PuYun-LDM，改进了现有模型在气象数据中的扩散能力。", "motivation": "针对现有LDM模型在高分辨率气象预测中扩散性不足的问题，并结合气象数据特有的复杂性和异质性提出了改进方案。", "method": "通过引入3D Masked AutoEncoder (3D-MAE)和Variable-Aware Masked Frequency Modeling (VA-MFM)，增强了天气状态演变特征的编码及频率建模能力，以适应不同变量间谱能量分布的不同需求。", "result": "PuYun-LDM在短时预报中优于ENS模型，在长时预报中与之相当，并且具有高效的并行生成能力。", "conclusion": "通过改进气象数据处理方法和扩散模型结构，成功提高了高分辨率集合天气预报的准确性与效率。"}}
{"id": "2602.11804", "pdf": "https://arxiv.org/pdf/2602.11804", "abs": "https://arxiv.org/abs/2602.11804", "authors": ["Yiming Zhou", "Xuenjie Xie", "Panfeng Li", "Albrecht Kunz", "Ahmad Osman", "Xavier Maldague"], "title": "Efficient Segment Anything with Depth-Aware Fusion and Limited Training Data", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Segment Anything Models (SAM) achieve impressive universal segmentation performance but require massive datasets (e.g., 11M images) and rely solely on RGB inputs. Recent efficient variants reduce computation but still depend on large-scale training. We propose a lightweight RGB-D fusion framework that augments EfficientViT-SAM with monocular depth priors. Depth maps are generated with a pretrained estimator and fused mid-level with RGB features through a dedicated depth encoder. Trained on only 11.2k samples (less than 0.1\\% of SA-1B), our method achieves higher accuracy than EfficientViT-SAM, showing that depth cues provide strong geometric priors for segmentation.", "AI": {"tldr": "本文提出了一种轻量级的RGB-D融合框架，通过引入单目深度先验来改进EfficientViT-SAM模型。", "motivation": "Segment Anything Models (SAM)虽然实现了卓越的通用分割性能，但需要庞大的数据集和依赖于RGB输入。现有高效变体仍然需要大规模训练，本文旨在减少对大量标注数据的依赖，并引入几何先验以提高分割准确性。", "method": "通过预训练深度估计器生成深度图并将其与中间级别的RGB特征融合；采用专门设计的深度编码器来实现这种融合。", "result": "在仅使用11.2k样本的情况下，该方法达到了比EfficientViT-SAM更高的精度，表明了深度线索提供强大的几何先验。", "conclusion": "本文提出的轻量级RGB-D融合框架证明，在有限的训练数据下可以利用深度信息来增强分割模型性能。"}}
{"id": "2602.11799", "pdf": "https://arxiv.org/pdf/2602.11799", "abs": "https://arxiv.org/abs/2602.11799", "authors": ["Pingjun Pan", "Tingting Zhou", "Peiyao Lu", "Tingting Fei", "Hongxiang Chen", "Chuanjiang Luo"], "title": "Hi-SAM: A Hierarchical Structure-Aware Multi-modal Framework for Large-Scale Recommendation", "categories": ["cs.AI"], "comment": null, "summary": "Multi-modal recommendation has gained traction as items possess rich attributes like text and images. Semantic ID-based approaches effectively discretize this information into compact tokens. However, two challenges persist: (1) Suboptimal Tokenization: existing methods (e.g., RQ-VAE) lack disentanglement between shared cross-modal semantics and modality-specific details, causing redundancy or collapse; (2) Architecture-Data Mismatch: vanilla Transformers treat semantic IDs as flat streams, ignoring the hierarchy of user interactions, items, and tokens. Expanding items into multiple tokens amplifies length and noise, biasing attention toward local details over holistic semantics. We propose Hi-SAM, a Hierarchical Structure-Aware Multi-modal framework with two designs: (1) Disentangled Semantic Tokenizer (DST): unifies modalities via geometry-aware alignment and quantizes them via a coarse-to-fine strategy. Shared codebooks distill consensus while modality-specific ones recover nuances from residuals, enforced by mutual information minimization; (2) Hierarchical Memory-Anchor Transformer (HMAT): splits positional encoding into inter- and intra-item subspaces via Hierarchical RoPE to restore hierarchy. It inserts Anchor Tokens to condense items into compact memory, retaining details for the current item while accessing history only through compressed summaries. Experiments on real-world datasets show consistent improvements over SOTA baselines, especially in cold-start scenarios. Deployed on a large-scale social platform serving millions of users, Hi-SAM achieved a 6.55% gain in the core online metric.", "AI": {"tldr": "本文提出了一种基于层次结构感知的多模态框架Hi-SAM，用于大规模推荐系统。", "motivation": "现有方法在处理跨模式语义和特定模式细节时存在纠缠问题，并且缺乏对用户交互、项目和标记分层架构的支持。", "method": "提出了Disentangled Semantic Tokenizer（DST）和Hierarchical Memory-Anchor Transformer（HMAT），前者通过几何感知对齐并采用粗到细策略进行量化，后者通过层次RoPE将位置编码分为项目内部和项目之间子空间，并插入锚点标记以浓缩项目。", "result": "实验结果表明，在现实世界的数据集上，Hi-SAM相对于最新的基线模型表现出了持续的改进，尤其在冷启动场景中取得了6.55%的核心在线度量增益。", "conclusion": "通过引入层次结构感知机制和有效的多模态处理方法，Hi-SAM框架显著提升了大规模推荐系统的性能。"}}
{"id": "2602.11792", "pdf": "https://arxiv.org/pdf/2602.11792", "abs": "https://arxiv.org/abs/2602.11792", "authors": ["Hongbo Zhang", "Yue Yang", "Jianhao Yan", "Guangsheng Bao", "Yue Zhang", "Yue Zhang"], "title": "Detecting RLVR Training Data via Structural Convergence of Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "Preprint", "summary": "Reinforcement learning with verifiable rewards (RLVR) is central to training modern reasoning models, but the undisclosed training data raises concerns about benchmark contamination. Unlike pretraining methods, which optimize models using token-level probabilities, RLVR fine-tunes models based on reward feedback from self-generated reasoning trajectories, making conventional likelihood-based detection methods less effective. We show that RLVR induces a distinctive behavioral signature: prompts encountered during RLVR training result in more rigid and similar generations, while unseen prompts retain greater diversity. We introduce Min-$k$NN Distance, a simple black-box detector that quantifies this collapse by sampling multiple completions for a given prompt and computing the average of the $k$ smallest nearest-neighbor edit distances. Min-$k$NN Distance requires no access to the reference model or token probabilities. Experiments across multiple RLVR-trained reasoning models show that Min-$k$NN Distance reliably distinguishes RL-seen examples from unseen ones and outperforms existing membership inference and RL contamination detection baselines.", "AI": {"tldr": "研究提出了一种检测通过强化学习与可验证奖励（RLVR）训练的数据的方法。", "motivation": "由于RLVR方法的训练数据未公开，这引发了关于基准污染的关注。传统的基于概率的方法对于检测此类模型不够有效。", "method": "该研究提出了Min-$k$NN距离，一种无需访问参考模型或标记概率的黑盒检测器。通过计算给定提示的不同生成之间的编辑距离来量化这些差异。", "result": "实验表明，Min-$k$NN Distance方法能够有效地区分见过和未见过的数据，并优于现有的成员推断和RL污染检测基准。", "conclusion": "该研究提供了一种新颖且有效的工具来解决通过强化学习与可验证奖励训练的模型所带来的基准污染问题。"}}
{"id": "2602.11791", "pdf": "https://arxiv.org/pdf/2602.11791", "abs": "https://arxiv.org/abs/2602.11791", "authors": ["Antoine Amarilli", "Claire David", "Nadime Francis", "Victor Marsault", "Mikaël Monet", "Yann Strozecki"], "title": "Gray Codes With Constant Delay and Constant Auxiliary Space", "categories": ["cs.DS", "cs.CC"], "comment": "29 pages, 8 figures", "summary": "We give the first two algorithms to enumerate all binary words of $\\{0,1\\}^\\ell$ (like Gray codes) while ensuring that the delay and the auxiliary space is independent from $\\ell$, i.e., constant time for each word, and constant memory in addition to the $\\ell$ bits storing the current word. Our algorithms are given in two new computational models: tape machines and deque machines. We also study more restricted models, queue machines and stack machines, and show that they cannot enumerate all binary words with constant auxiliary space, even with unrestricted delay. A tape machine is a Turing machine that stores the current binary word on a single working tape of length $\\ell$. The machine has a single head and must edit its tape to reach all possible words of $\\{0,1\\}^{\\ell}$ , and output them (in unit time, by entering special output states), with no duplicates. We construct a tape machine that achieves this task with constant delay between consecutive outputs, which implies that the machine implements a so-called skew-tolerant quasi-Gray code. We then construct a more involved tape machine that implements a Gray code. A deque machine stores the current binary word on a double-ended queue of length $\\ell$, and stores a constant-size internal state. It works as a tape machine, except that it modifies the content of the deque by performing push and pop operations on the endpoints. We construct deque machines that enumerate all words of $\\{0,1\\}^\\ell$ with constant-delay. The main technical challenge in this model is to correctly detect when enumeration has finished. Our work on deque machine is also motivated by other contexts in which endpoint modifications occur naturally. In particular, our result is a first step towards enumerating walks in directed graphs with constant delay and constant auxiliary space, addressing a core task in modern graph database query processing.", "AI": {"tldr": "本文提出了两种算法，用于在常数延迟和辅助空间下枚举所有二进制词，适用于带式机器和双端队列机器模型。", "motivation": "现有方法难以实现常数时间延迟和辅助空间下的二进制词枚举任务。作者旨在解决此问题，并提出适用于特定计算模型的算法。", "method": "作者提出了两种新的计算模型：带式机器和双端队列机器，设计了可在这些模型下以恒定时间和空间复杂度运行的算法来实现二进制词的常数延迟枚举。", "result": "在带式机器模型中，实现了常数时间延迟下的枚举；而在双端队列机器模型中，则进一步优化为灰码枚举。此外，在其他受限模型下证明了无法仅用恒定辅助空间完成二进制词的枚举任务。", "conclusion": "研究结果展示了如何在新的计算模型中实现高效且资源节约型的二进制词枚举，并为进一步处理现代图形数据库查询奠定了基础。"}}
{"id": "2602.11790", "pdf": "https://arxiv.org/pdf/2602.11790", "abs": "https://arxiv.org/abs/2602.11790", "authors": ["Lingyong Yan", "Jiulong Wu", "Dong Xie", "Weixian Shi", "Deguo Xia", "Jizhou Huang"], "title": "Beyond End-to-End Video Models: An LLM-Based Multi-Agent System for Educational Video Generation", "categories": ["cs.AI", "cs.CL"], "comment": "For more information, visit the project website: https://robitsg.github.io/LASEV/", "summary": "Although recent end-to-end video generation models demonstrate impressive performance in visually oriented content creation, they remain limited in scenarios that require strict logical rigor and precise knowledge representation, such as instructional and educational media. To address this problem, we propose LAVES, a hierarchical LLM-based multi-agent system for generating high-quality instructional videos from educational problems. The LAVES formulates educational video generation as a multi-objective task that simultaneously demands correct step-by-step reasoning, pedagogically coherent narration, semantically faithful visual demonstrations, and precise audio--visual alignment. To address the limitations of prior approaches--including low procedural fidelity, high production cost, and limited controllability--LAVES decomposes the generation workflow into specialized agents coordinated by a central Orchestrating Agent with explicit quality gates and iterative critique mechanisms. Specifically, the Orchestrating Agent supervises a Solution Agent for rigorous problem solving, an Illustration Agent that produces executable visualization codes, and a Narration Agent for learner-oriented instructional scripts. In addition, all outputs from the working agents are subject to semantic critique, rule-based constraints, and tool-based compilation checks. Rather than directly synthesizing pixels, the system constructs a structured executable video script that is deterministically compiled into synchronized visuals and narration using template-driven assembly rules, enabling fully automated end-to-end production without manual editing. In large-scale deployments, LAVES achieves a throughput exceeding one million videos per day, delivering over a 95% reduction in cost compared to current industry-standard approaches while maintaining a high acceptance rate.", "AI": {"tldr": "提出了一种基于LLM的多代理系统LAVES，用于从教育问题生成高质量的教学视频。", "motivation": "解决现有端到端视频生成模型在需要严格逻辑严谨性和精确知识表示的情况下（如教学和教育媒体）表现不佳的问题。", "method": "将教育视频生成任务分解为多个专门的代理系统，并由中央调度代理协调，包括问题求解器、可视化生产者和叙述编写者。该系统通过结构化的可执行脚本自动生成同步视觉和叙述。", "result": "LAVES在大规模部署中每天可以生成超过一百万部视频，相比现有的行业标准方法成本降低了95%以上，并且保持了高接受率。", "conclusion": "LAVES能够高效地生成高质量的教学视频，通过分解任务并采用多代理系统，实现了自动化的端到端生产。"}}
{"id": "2602.11786", "pdf": "https://arxiv.org/pdf/2602.11786", "abs": "https://arxiv.org/abs/2602.11786", "authors": ["Keita Broadwater"], "title": "Evaluating LLM Safety Under Repeated Inference via Accelerated Prompt Stress Testing", "categories": ["cs.LG", "cs.AI"], "comment": "24 pages, 9 figures. Submitted to TMLR", "summary": "Traditional benchmarks for large language models (LLMs) primarily assess safety risk through breadth-oriented evaluation across diverse tasks. However, real-world deployment exposes a different class of risk: operational failures arising from repeated inference on identical or near-identical prompts rather than broad task generalization. In high-stakes settings, response consistency and safety under sustained use are critical. We introduce Accelerated Prompt Stress Testing (APST), a depth-oriented evaluation framework inspired by reliability engineering. APST repeatedly samples identical prompts under controlled operational conditions (e.g., decoding temperature) to surface latent failure modes including hallucinations, refusal inconsistency, and unsafe completions. Rather than treating failures as isolated events, APST models them as stochastic outcomes of independent inference events. We formalize safety failures using Bernoulli and binomial models to estimate per-inference failure probabilities, enabling quantitative comparison of reliability across models and decoding configurations. Applying APST to multiple instruction-tuned LLMs evaluated on AIR-BENCH-derived safety prompts, we find that models with similar benchmark-aligned scores can exhibit substantially different empirical failure rates under repeated sampling, particularly as temperature increases. These results demonstrate that shallow, single-sample evaluation can obscure meaningful reliability differences under sustained use. APST complements existing benchmarks by providing a practical framework for evaluating LLM safety and reliability under repeated inference, bridging benchmark alignment and deployment-oriented risk assessment.", "AI": {"tldr": "论文主要任务是通过加速提示压力测试（APST）框架来评估大型语言模型在重复推理时的安全性和可靠性。", "motivation": "传统的基准测试着重于广泛的任务，但在真实部署中，重复使用相同或相似提示的场景会暴露安全风险。这些风险包括响应一致性下降和安全性降低，特别是在高风险环境中更为关键。", "method": "引入了加速提示压力测试（APST），该框架通过在控制条件下反复抽取相同的提示来评估模型的安全性和可靠性，并使用伯努利和二项式模型量化每轮推理中的失败概率。", "result": "研究发现，即使具有相似基准分数的模型，在重复采样时也可能会表现出显著不同的失败率，特别是在温度增加的情况下。这些结果表明浅层单一样本评价无法完全揭示在持续使用下的可靠性差异。", "conclusion": "加速提示压力测试（APST）为评估大型语言模型的安全性和可靠性提供了实用框架，并补充了现有的基准测试方法，有助于更接近实际部署的风险评估。"}}
{"id": "2602.11785", "pdf": "https://arxiv.org/pdf/2602.11785", "abs": "https://arxiv.org/abs/2602.11785", "authors": ["Ainhize Barrainkua", "Santiago Mazuelas", "Novi Quadrianto", "Jose A. Lozano"], "title": "Safe Fairness Guarantees Without Demographics in Classification: Spectral Uncertainty Set Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As automated classification systems become increasingly prevalent, concerns have emerged over their potential to reinforce and amplify existing societal biases. In the light of this issue, many methods have been proposed to enhance the fairness guarantees of classifiers. Most of the existing interventions assume access to group information for all instances, a requirement rarely met in practice. Fairness without access to demographic information has often been approached through robust optimization techniques,which target worst-case outcomes over a set of plausible distributions known as the uncertainty set. However, their effectiveness is strongly influenced by the chosen uncertainty set. In fact, existing approaches often overemphasize outliers or overly pessimistic scenarios, compromising both overall performance and fairness. To overcome these limitations, we introduce SPECTRE, a minimax-fair method that adjusts the spectrum of a simple Fourier feature mapping and constrains the extent to which the worst-case distribution can deviate from the empirical distribution. We perform extensive experiments on the American Community Survey datasets involving 20 states. The safeness of SPECTRE comes as it provides the highest average values on fairness guarantees together with the smallest interquartile range in comparison to state-of-the-art approaches, even compared to those with access to demographic group information. In addition, we provide a theoretical analysis that derives computable bounds on the worst-case error for both individual groups and the overall population, as well as characterizes the worst-case distributions responsible for these extremal performances", "AI": {"tldr": "介绍了一种新方法SPECTRE，用于在无种族信息的情况下提高分类系统的公平性。", "motivation": "鉴于自动化分类系统可能加剧社会偏见的担忧，提出了许多旨在增强分类器公平性的方法。然而，大多数现有干预措施需要访问所有实例的群体信息，这在实践中很少实现。因此，研究者试图通过稳健优化技术来解决没有种族信息的情况下的公平性问题。", "method": "SPECTRE是一种最小化最坏情况公平性的方法，它通过对简单傅立叶特征映射的谱进行调整并限制最坏情况分布偏离经验分布的程度来工作。", "result": "在涉及20个州的美国社区调查数据集上进行了广泛的实验。与现有方法相比，包括那些具有种族信息访问权限的方法，SPECTRE提供了最高的平均公平保证值和最小的四分位距。", "conclusion": "SPECTRE能够在不使用群体信息的情况下提供更好的安全性和公平性，并且理论分析表明它可以为个体组和个人总体计算最坏情况误差的界限。"}}
{"id": "2602.11782", "pdf": "https://arxiv.org/pdf/2602.11782", "abs": "https://arxiv.org/abs/2602.11782", "authors": ["Yihao Liu", "Ziyun Zhang", "Zile He", "Huaqian Cai"], "title": "FlowMind: Execute-Summarize for Structured Workflow Generation from LLM Reasoning", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "LLMs can solve complex tasks through reasoning and tool use, but accurately translating these solutions into structured workflows remains challenging. We model workflows as sequences of tool use and reformulate the problem as designing a mechanism that can both solve tasks and reliably construct workflows. Prior approaches that build workflows during execution often suffer from inaccuracies due to interference between the two processes. We propose an Execute-Summarize(ES) framework that decouples task execution from workflow construction: the model first completes the task using available tools, then independently reconstructs a structured workflow from execution traces. This separation improves workflow accuracy and robustness. We introduce FlowBench and show through extensive experiments that our approach outperforms existing methods, providing a reliable paradigm for grounding free-form LLM reasoning into structured workflows.", "AI": {"tldr": "本文提出了一个将大型语言模型的自由形式推理转化为结构化工作流的方法。", "motivation": "当前的语言模型虽然能够通过推理和工具使用解决复杂任务，但是将其解决方案准确地翻译成结构化的工作流程仍然具有挑战性。", "method": "该论文提出了一种执行-总结（ES）框架，将任务执行与工作流构建过程解耦：首先使用可用的工具完成任务，然后独立地从执行跟踪中重构一个结构化的工作流。这一分离提高了工作流的准确性和鲁棒性。", "result": "通过广泛的实验，该方法在FlowBench上表现优于现有技术，展示了将自由形式的语言模型推理转化为结构化工作流的有效性。", "conclusion": "本文的方法提供了一种可靠的方式来实现大型语言模型推理向结构化工作流的转化。"}}
{"id": "2602.11780", "pdf": "https://arxiv.org/pdf/2602.11780", "abs": "https://arxiv.org/abs/2602.11780", "authors": ["Jinfang Wang", "Jiajie Liu", "Jianwei Wu", "Ziqin Luo", "Zhen Chen", "Chunlei Li", "Biao Han", "Tao Deng", "Yi Li", "Shuanglong Li", "Lin Liu"], "title": "RELATE: A Reinforcement Learning-Enhanced LLM Framework for Advertising Text Generation", "categories": ["cs.AI"], "comment": "10 pages, 3 figures", "summary": "In online advertising, advertising text plays a critical role in attracting user engagement and driving advertiser value. Existing industrial systems typically follow a two-stage paradigm, where candidate texts are first generated and subsequently aligned with online performance metrics such as click-through rate(CTR). This separation often leads to misaligned optimization objectives and low funnel efficiency, limiting global optimality. To address these limitations, we propose RELATE, a reinforcement learning-based end-to-end framework that unifies generation and objective alignment within a single model. Instead of decoupling text generation from downstream metric alignment, RELATE integrates performance and compliance objectives directly into the generation process via policy learning. To better capture ultimate advertiser value beyond click-level signals, We incorporate conversion-oriented metrics into the objective and jointly model them with compliance constraints as multi-dimensional rewards, enabling the model to generate high-quality ad texts that improve conversion performance under policy constraints. Extensive experiments on large-scale industrial datasets demonstrate that RELATE consistently outperforms baselines. Furthermore, online deployment on a production advertising platform yields statistically significant improvements in click-through conversion rate(CTCVR) under strict policy constraints, validating the robustness and real-world effectiveness of the proposed framework.", "AI": {"tldr": "RELATE是一种基于强化学习的端到端广告文案生成框架，旨在通过统一文本生成和性能对齐来优化广告效果。", "motivation": "现有的工业系统采用两阶段模式产生广告文案，并将其与在线表现指标（如点击率CTR）对齐。这种分离导致目标不一致和漏斗效率低，限制了全局最优性。", "method": "RELATE将性能和合规性的目标直接集成到文本生成过程中并通过策略学习来实现端到端的优化。通过引入基于转化的数据点，并结合合规约束作为多维度奖励，使得模型能够产生高质量且符合政策要求的广告文案。", "result": "在大规模工业数据集上的广泛实验表明，RELATE显著优于基线方法。在线部署于生产广告平台也显示了CTR转换率CTCVR有统计学意义的提高。", "conclusion": "该框架被证明具有鲁棒性和现实世界的有效性，能够生成高质量且合规的广告文案以优化转化性能。"}}
{"id": "2602.11775", "pdf": "https://arxiv.org/pdf/2602.11775", "abs": "https://arxiv.org/abs/2602.11775", "authors": ["Mersedeh Sadeghi", "Simon Scholz", "Max Unterbusch", "Andreas Vogelsang"], "title": "V-SHiNE: A Virtual Smart Home Framework for Explainability Evaluation", "categories": ["cs.HC", "cs.SE"], "comment": null, "summary": "Explanations are essential for helping users interpret and trust autonomous smart-home decisions, yet evaluating their quality and impact remains methodologically difficult in this domain. V-SHiNE addresses this gap: a browser-based smarthome simulation framework for scalable and realistic assessment of explanations. It allows researchers to configure environments, simulate behaviors, and plug in custom explanation engines, with flexible delivery modes and rich interaction logging. A study with 159 participants demonstrates its feasibility. V-SHiNE provides a lightweight, reproducible platform for advancing user-centered evaluation of explainable intelligent systems", "AI": {"tldr": "V-SHiNE是一款用于评估智能家庭解释系统的框架", "motivation": "当前领域内对自主智能家庭决策的解释质量和影响进行评价的方法较为困难，该论文旨在解决这一问题", "method": "提出了一款基于浏览器的家庭模拟框架，可以配置环境、模拟行为并嵌入自定义的解释引擎，提供灵活的交付模式和丰富的交互日志", "result": "一项包含159名参与者的研究证明了其可行性", "conclusion": "V-SHiNE为用户中心的可解释智能系统评估提供了轻量级且可重复使用的平台"}}
{"id": "2602.11771", "pdf": "https://arxiv.org/pdf/2602.11771", "abs": "https://arxiv.org/abs/2602.11771", "authors": ["Sébastien Gigot--Léandri", "Gaétan Morand", "Alexis Joly", "François Munoz", "David Mouillot", "Christophe Botella", "Maximilien Servajean"], "title": "How to Optimize Multispecies Set Predictions in Presence-Absence Modeling ?", "categories": ["cs.AI"], "comment": null, "summary": "Species distribution models (SDMs) commonly produce probabilistic occurrence predictions that must be converted into binary presence-absence maps for ecological inference and conservation planning. However, this binarization step is typically heuristic and can substantially distort estimates of species prevalence and community composition. We present MaxExp, a decision-driven binarization framework that selects the most probable species assemblage by directly maximizing a chosen evaluation metric. MaxExp requires no calibration data and is flexible across several scores. We also introduce the Set Size Expectation (SSE) method, a computationally efficient alternative that predicts assemblages based on expected species richness. Using three case studies spanning diverse taxa, species counts, and performance metrics, we show that MaxExp consistently matches or surpasses widely used thresholding and calibration methods, especially under strong class imbalance and high rarity. SSE offers a simpler yet competitive option. Together, these methods provide robust, reproducible tools for multispecies SDM binarization.", "AI": {"tldr": "本文提出了MaxExp和Set Size Expectation（SSE）两种方法，用于优化多物种集合预测的二值化步骤。", "motivation": "在物种分布模型中，将概率发生预测转换为二元存在-不存在地图时，现有方法往往不够准确，导致物种丰富度和群落组成的估计偏差较大。本文旨在提供更有效的二值化框架。", "method": "MaxExp是一种选择最可能的物种集合的方法，通过直接最大化选定评估指标来实现。SSE则基于预期物种丰富度预测集合，计算效率较高。", "result": "在三个案例研究中，MaxExp方法的表现优于常用的阈值和校准方法，尤其适用于强类别不平衡和高度稀有的情况。SSE提供了更简单但同样有竞争力的选择。", "conclusion": "本文提出的两种方法为多物种分布模型的二值化提供了一种稳健、可重复的工具，有助于生态推断和保护规划。"}}
{"id": "2602.11769", "pdf": "https://arxiv.org/pdf/2602.11769", "abs": "https://arxiv.org/abs/2602.11769", "authors": ["Zhenghuang Wu", "Kang Chen", "Zeyu Zhang", "Hao Tang"], "title": "Light4D: Training-Free Extreme Viewpoint 4D Video Relighting", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in diffusion-based generative models have established a new paradigm for image and video relighting. However, extending these capabilities to 4D relighting remains challenging, due primarily to the scarcity of paired 4D relighting training data and the difficulty of maintaining temporal consistency across extreme viewpoints. In this work, we propose Light4D, a novel training-free framework designed to synthesize consistent 4D videos under target illumination, even under extreme viewpoint changes. First, we introduce Disentangled Flow Guidance, a time-aware strategy that effectively injects lighting control into the latent space while preserving geometric integrity. Second, to reinforce temporal consistency, we develop Temporal Consistent Attention within the IC-Light architecture and further incorporate deterministic regularization to eliminate appearance flickering. Extensive experiments demonstrate that our method achieves competitive performance in temporal consistency and lighting fidelity, robustly handling camera rotations from -90 to 90. Code: https://github.com/AIGeeksGroup/Light4D. Website: https://aigeeksgroup.github.io/Light4D.", "AI": {"tldr": "提出了一种无需训练的框架Light4D，用于在极端视角变化下生成一致的4D视频重光照。", "motivation": "现有扩散模型难以处理缺乏配对的4D重光照数据以及保持时间一致性的问题。为此，本文提出了一个新颖的方法来解决这些问题。", "method": "引入了离散化流引导策略和时间一致性注意机制，在IC-Light架构中通过确定性正则化消除闪烁现象。", "result": "实验显示该方法在时间一致性和光照保真度方面表现优异，能够有效处理从-90到90度的相机旋转。", "conclusion": "Light4D成功地解决了极端视角变化下的4D视频重光照问题，并且保持了良好的时间一致性和光照质量。"}}
{"id": "2602.11767", "pdf": "https://arxiv.org/pdf/2602.11767", "abs": "https://arxiv.org/abs/2602.11767", "authors": ["Aladin Djuhera", "Swanand Ravindra Kadhe", "Farhan Ahmed", "Holger Boche"], "title": "TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Advances in large language models (LLMs) are driving a shift toward using reinforcement learning (RL) to train agents from iterative, multi-turn interactions across tasks. However, multi-turn RL remains challenging as rewards are often sparse or delayed, and environments can be stochastic. In this regime, naive trajectory sampling can hinder exploitation and induce mode collapse. We propose TSR (Trajectory-Search Rollouts), a training-time approach that repurposes test-time scaling ideas for improved per-turn rollout generation. TSR performs lightweight tree-style search to construct high-quality trajectories by selecting high-scoring actions at each turn using task-specific feedback. This improves rollout quality and stabilizes learning while leaving the underlying optimization objective unchanged, making TSR optimizer-agnostic. We instantiate TSR with best-of-N, beam, and shallow lookahead search, and pair it with PPO and GRPO, achieving up to 15% performance gains and more stable learning on Sokoban, FrozenLake, and WebShop tasks at a one-time increase in training compute. By moving search from inference time to the rollout stage of training, TSR provides a simple and general mechanism for stronger multi-turn agent learning, complementary to existing frameworks and rejection-sampling-style selection methods.", "AI": {"tldr": "TSR是一种改进多回合强化学习中代理生成的策略，通过在训练阶段进行轻量级树状搜索来提高每回合轨迹的质量，适用于多种任务和优化器。", "motivation": "随着大语言模型的发展，使用强化学习训练从多次交互中学习的代理变得越来越重要。然而，在稀疏或延迟奖励和随机环境中执行多回合RL仍具有挑战性。直接采用路径采样可能会阻碍探索并导致模式崩溃。", "method": "TSR通过在每个回合选择得分高的动作来构造高质量轨迹，使用任务特定反馈进行轻量级树状搜索生成改进的每回合轨迹。方法包括best-of-N、beam和浅层前瞻搜索，并与PPO和GRPO结合。", "result": "在Sokoban、FrozenLake和WebShop等任务上实现高达15%性能提升并提高训练稳定性，仅增加一次计算成本。", "conclusion": "TSR通过将搜索从推断时间移到训练阶段的回放期提供了一种简单且通用的方法来增强多回合代理学习，同时与现有框架和拒绝采样式选择方法互补。"}}
{"id": "2602.11764", "pdf": "https://arxiv.org/pdf/2602.11764", "abs": "https://arxiv.org/abs/2602.11764", "authors": ["Nilesh Vyas", "Fabien Geyer", "Svetoslav Duhovnikov"], "title": "Reliable and Private Anonymous Routing for Satellite Constellations", "categories": ["cs.CR", "cs.ET", "cs.IR", "cs.NI"], "comment": "14 Pages, 16 Figures", "summary": "Shared, dynamic network infrastructures, such as dual-use LEO satellite constellations, pose critical threats to metadata privacy, particularly for state actors operating in mixed-trust environments. This work proposes an enhanced anonymity architecture, evolving the Loopix mix-network, to provide robust security and reliability in these volatile topologies. We introduce three primary contributions: (1) A multi-path transport protocol utilizing $(n, k)$ erasure codes, which is demonstrated to counteract the high link volatility and intermittent connectivity that renders standard mix-networks unreliable. (2) The integration of a computationally efficient Private Information Retrieval (PIR) protocol during route discovery. (3) The introduction of adaptive, centrality-based delay strategies that efficiently mitigate the inherent topological bias of LEO networks, providing a superior anonymity-to-latency trade-off. This mechanism provably prevents metadata leakage at the user-provider directory, mitigating profiling and correlation attacks. We validate this architecture via high-fidelity, packet-level simulations of a LEO constellation. Empirical results show our multi-path transport achieves near-zero message loss, establishing a quantifiable trade-off between reliability and bandwidth overhead. Furthermore, microbenchmarks of the PIR protocol quantify its computational and latency overheads, confirming its feasibility for practical deployment. This work provides a validated blueprint for deployable high-anonymity communication systems, demonstrating the viability of securely multiplexing sensitive operations within large-scale commercial network infrastructures.", "AI": {"tldr": "提出了一种增强匿名架构，旨在为共享、动态网络基础设施中的低轨道卫星星座提供强大且可靠的隐私保护措施。", "motivation": "为了应对在混合信任环境中运营的国家行为者面临的元数据隐私威胁，特别是在使用双重用途LEO卫星星座时。", "method": "1. 多路径传输协议结合(n, k)擦除码；2. 私有信息检索(PIR)协议集成；3. 基于中心性的自适应延迟策略。", "result": "模拟实验表明多路径传输几乎实现零消息丢失，并证明了其可部署性及对带宽的合理开销，同时微基准测试确认了PIR协议的计算和时延开销。", "conclusion": "此工作为高匿名通信系统提供了有效的部署蓝图，并证实了在大规模商业网络基础设施中安全复用敏感操作的可能性。"}}
{"id": "2602.11761", "pdf": "https://arxiv.org/pdf/2602.11761", "abs": "https://arxiv.org/abs/2602.11761", "authors": ["MiniCPM Team", "Wenhao An", "Yingfa Chen", "Yewei Fang", "Jiayi Li", "Xin Li", "Yaohui Li", "Yishan Li", "Yuxuan Li", "Biyuan Lin", "Chuan Liu", "Hezi Liu", "Siyuan Liu", "Hongya Lyu", "Yinxu Pan", "Shixin Ren", "Xingyu Shen", "Zhou Su", "Haojun Sun", "Yangang Sun", "Zhen Leng Thai", "Xin Tian", "Rui Wang", "Xiaorong Wang", "Yudong Wang", "et al. (21 additional authors not shown)"], "title": "MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "MiniCPM-SALA Technical Report", "summary": "The evolution of large language models (LLMs) towards applications with ultra-long contexts faces challenges posed by the high computational and memory costs of the Transformer architecture. While existing sparse and linear attention mechanisms attempt to mitigate these issues, they typically involve a trade-off between memory efficiency and model performance. This paper introduces MiniCPM-SALA, a 9B-parameter hybrid architecture that integrates the high-fidelity long-context modeling of sparse attention (InfLLM-V2) with the global efficiency of linear attention (Lightning Attention). By employing a layer selection algorithm to integrate these mechanisms in a 1:3 ratio and utilizing a hybrid positional encoding (HyPE), the model maintains efficiency and performance for long-context tasks. Furthermore, we introduce a cost-effective continual training framework that transforms pre-trained Transformer-based models into hybrid models, which reduces training costs by approximately 75% compared to training from scratch. Extensive experiments show that MiniCPM-SALA maintains general capabilities comparable to full-attention models while offering improved efficiency. On a single NVIDIA A6000D GPU, the model achieves up to 3.5x the inference speed of the full-attention model at the sequence length of 256K tokens and supports context lengths of up to 1M tokens, a scale where traditional full-attention 8B models fail because of memory constraints.", "AI": {"tldr": "该论文提出了MiniCPM-SALA，一种结合了稀疏注意力和线性注意力的混合架构，旨在解决大规模语言模型在处理超长上下文时面临的计算和内存开销问题。", "motivation": "随着大型语言模型向具有极长上下文的应用发展，传统的Transformer架构面临着高昂的计算和内存成本挑战。现有的稀疏注意机制与线性注意机制虽然试图缓解这些问题，但通常会牺牲性能或效率。", "method": "通过在90亿参数的混合架构中集成InfLLM-V2的高保真长上下文建模能力和Lightning Attention的全局效率，并使用层选择算法以1:3的比例融合这些机制以及采用一种成本效益高的连续训练框架，将预训练Transformer模型转换为混合模型。", "result": "实验结果表明，MiniCPM-SALA在保持与全注意力模型相当的一般性能的同时提高了效率。它在一个NVIDIA A6000D GPU上实现了最高达3.5倍的推理速度提升，并支持长达1M令牌的上下文长度。", "conclusion": "该论文通过引入一种新的混合架构MiniCPM-SALA，成功地在提高长上下文建模效率的同时保持了模型性能。"}}
{"id": "2602.11758", "pdf": "https://arxiv.org/pdf/2602.11758", "abs": "https://arxiv.org/abs/2602.11758", "authors": ["Dongting Li", "Xingyu Chen", "Qianyang Wu", "Bo Chen", "Sikai Wu", "Hanyu Wu", "Guoyao Zhang", "Liang Li", "Mingliang Zhou", "Diyun Xiang", "Jianzhu Ma", "Qiang Zhang", "Renjing Xu"], "title": "HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model", "categories": ["cs.RO"], "comment": "Webpage: https://haic-humanoid.github.io/", "summary": "Humanoid robots show promise for complex whole-body tasks in unstructured environments. Although Human-Object Interaction (HOI) has advanced, most methods focus on fully actuated objects rigidly coupled to the robot, ignoring underactuated objects with independent dynamics and non-holonomic constraints. These introduce control challenges from coupling forces and occlusions. We present HAIC, a unified framework for robust interaction across diverse object dynamics without external state estimation. Our key contribution is a dynamics predictor that estimates high-order object states (velocity, acceleration) solely from proprioceptive history. These predictions are projected onto static geometric priors to form a spatially grounded dynamic occupancy map, enabling the policy to infer collision boundaries and contact affordances in blind spots. We use asymmetric fine-tuning, where a world model continuously adapts to the student policy's exploration, ensuring robust state estimation under distribution shifts. Experiments on a humanoid robot show HAIC achieves high success rates in agile tasks (skateboarding, cart pushing/pulling under various loads) by proactively compensating for inertial perturbations, and also masters multi-object long-horizon tasks like carrying a box across varied terrain by predicting the dynamics of multiple objects.", "AI": {"tldr": "提出HAIC框架，用于人形机器人处理复杂环境中多样物体的动力学交互任务。", "motivation": "现有方法大多集中在刚性连接的全驱对象上，忽略独立动力学和非完整约束的欠驱动对象带来的挑战。", "method": "通过预测高阶状态（速度、加速度）形成动态占用图，结合世界模型适应策略探索进行稳健的状态估计。", "result": "实验表明HAIC在敏捷任务中成功率高，并能处理多物体长时间域任务。", "conclusion": "HAIC框架成功解决了人形机器人与不同动力学对象交互的挑战。"}}
{"id": "2602.11757", "pdf": "https://arxiv.org/pdf/2602.11757", "abs": "https://arxiv.org/abs/2602.11757", "authors": ["Yi Zhang", "Yunshuang Wang", "Zeyu Zhang", "Hao Tang"], "title": "Code2Worlds: Empowering Coding LLMs for 4D World Generation", "categories": ["cs.CV"], "comment": null, "summary": "Achieving spatial intelligence requires moving beyond visual plausibility to build world simulators grounded in physical laws. While coding LLMs have advanced static 3D scene generation, extending this paradigm to 4D dynamics remains a critical frontier. This task presents two fundamental challenges: multi-scale context entanglement, where monolithic generation fails to balance local object structures with global environmental layouts; and a semantic-physical execution gap, where open-loop code generation leads to physical hallucinations lacking dynamic fidelity. We introduce Code2Worlds, a framework that formulates 4D generation as language-to-simulation code generation. First, we propose a dual-stream architecture that disentangles retrieval-augmented object generation from hierarchical environmental orchestration. Second, to ensure dynamic fidelity, we establish a physics-aware closed-loop mechanism in which a PostProcess Agent scripts dynamics, coupled with a VLM-Motion Critic that performs self-reflection to iteratively refine simulation code. Evaluations on the Code4D benchmark show Code2Worlds outperforms baselines with a 41% SGS gain and 49% higher Richness, while uniquely generating physics-aware dynamics absent in prior static methods. Code: https://github.com/AIGeeksGroup/Code2Worlds. Website: https://aigeeksgroup.github.io/Code2Worlds.", "AI": {"tldr": "该论文提出Code2Worlds框架，用于生成符合物理定律的4D世界。", "motivation": "现有编码LLMs在静态3D场景生成方面取得了进展，但要扩展到动态4D环境，则面临多尺度上下文纠缠和语义-物理执行差距两大挑战。为解决这些问题并实现空间智能，本文提出了解决方案。", "method": "Code2Worlds采用双流架构分离检索增强的对象生成与分层环境编排，并引入了一个基于物理学的闭环机制，其中PostProcess Agent负责动态脚本编写，而VLM-Motion Critic进行自我反思以迭代改进模拟代码。", "result": "在Code4D基准测试中，Code2Worlds相较于基线方法，在SGS得分上高出41%，丰富度提升了49%。它能够生成具有物理意识的动态环境，这是之前静态方法所不具备的能力。", "conclusion": "该研究为代码生成式世界模拟提供了一种新的解决方案，并通过实验验证了其优越性，证明了在多尺度上下文和语义-物理执行差距方面取得的重要进展。"}}
{"id": "2602.11754", "pdf": "https://arxiv.org/pdf/2602.11754", "abs": "https://arxiv.org/abs/2602.11754", "authors": ["Keita Nishimoto", "Kimitaka Asatani", "Ichiro Sakata"], "title": "Cooperation Breakdown in LLM Agents Under Communication Delays", "categories": ["cs.MA", "cs.AI", "cs.GT"], "comment": null, "summary": "LLM-based multi-agent systems (LLM-MAS), in which autonomous AI agents cooperate to solve tasks, are gaining increasing attention. For such systems to be deployed in society, agents must be able to establish cooperation and coordination under real-world computational and communication constraints. We propose the FLCOA framework (Five Layers for Cooperation/Coordination among Autonomous Agents) to conceptualize how cooperation and coordination emerge in groups of autonomous agents, and highlight that the influence of lower-layer factors - especially computational and communication resources - has been largely overlooked. To examine the effect of communication delay, we introduce a Continuous Prisoner's Dilemma with Communication Delay and conduct simulations with LLM-based agents. As delay increases, agents begin to exploit slower responses even without explicit instructions. Interestingly, excessive delay reduces cycles of exploitation, yielding a U-shaped relationship between delay magnitude and mutual cooperation. These results suggest that fostering cooperation requires attention not only to high-level institutional design but also to lower-layer factors such as communication delay and resource allocation, pointing to new directions for MAS research.", "AI": {"tldr": "研究了LLM代理系统中通信延迟对合作的影响。", "motivation": "在LLM多智能体系统部署时，需要考虑计算和通信资源限制下的合作建立与协调问题。", "method": "提出了FLCOA框架并引入带通信延迟的连续囚徒困境模型进行模拟。", "result": "随着延迟增加，代理开始利用较慢响应的行为；但过度延迟减少了剥削循环，形成了U形关系。", "conclusion": "研究指出促进合作不仅需要关注高层制度设计，还需要考虑底层因素如通信延迟和资源分配。"}}
{"id": "2602.11753", "pdf": "https://arxiv.org/pdf/2602.11753", "abs": "https://arxiv.org/abs/2602.11753", "authors": ["Danqing Shi"], "title": "Building Intelligent User Interfaces for Human-AI Alignment", "categories": ["cs.HC"], "comment": null, "summary": "Aligning AI systems with human values fundamentally relies on effective human feedback. While significant research has addressed training algorithms, the role of user interface is often overlooked and only treated as an implementation detail rather than a critical factor of alignment. This paper addresses this gap by introducing a reference model that offers a systematic framework for analyzing where and how user interface contributions can improve human-AI alignment. The structured taxonomy of the reference model is demonstrated through two case studies and a preliminary investigation featuring six user interfaces. This work highlights opportunities to advance alignment through human-computer interaction.", "AI": {"tldr": "构建智能用户界面以促进人机对齐", "motivation": "当前研究主要集中在训练算法上，而忽略了用户界面在促进人工智能与人类价值观一致中的关键作用。本文旨在填补这一空白，通过引入一个参考模型来系统分析用户界面如何提高人机对齐。", "method": "提出并展示了参考模型的结构化分类，并通过两个案例研究和六种不同用户界面的初步调查验证了该模型的有效性。", "result": "揭示了通过人类计算机交互可以改进人机对齐的机会。", "conclusion": "本文强调了用户界面在促进人工智能与人类价值观一致中的重要性和潜力。"}}
{"id": "2602.11750", "pdf": "https://arxiv.org/pdf/2602.11750", "abs": "https://arxiv.org/abs/2602.11750", "authors": ["Jiazheng Sun", "Mingxuan Li", "Yingying Zhang", "Jiayang Niu", "Yachen Wu", "Ruihan Jin", "Shuyu Lei", "Pengrongrui Tan", "Zongyu Zhang", "Ruoyi Wang", "Jiachen Yang", "Boyu Yang", "Jiacheng Liu", "Xin Peng"], "title": "AmbiBench: Benchmarking Mobile GUI Agents Beyond One-Shot Instructions in the Wild", "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": "21 pages, 7 figures", "summary": "Benchmarks are paramount for gauging progress in the domain of Mobile GUI Agents. In practical scenarios, users frequently fail to articulate precise directives containing full task details at the onset, and their expressions are typically ambiguous. Consequently, agents are required to converge on the user's true intent via active clarification and interaction during execution. However, existing benchmarks predominantly operate under the idealized assumption that user-issued instructions are complete and unequivocal. This paradigm focuses exclusively on assessing single-turn execution while overlooking the alignment capability of the agent. To address this limitation, we introduce AmbiBench, the first benchmark incorporating a taxonomy of instruction clarity to shift evaluation from unidirectional instruction following to bidirectional intent alignment. Grounded in Cognitive Gap theory, we propose a taxonomy of four clarity levels: Detailed, Standard, Incomplete, and Ambiguous. We construct a rigorous dataset of 240 ecologically valid tasks across 25 applications, subject to strict review protocols. Furthermore, targeting evaluation in dynamic environments, we develop MUSE (Mobile User Satisfaction Evaluator), an automated framework utilizing an MLLM-as-a-judge multi-agent architecture. MUSE performs fine-grained auditing across three dimensions: Outcome Effectiveness, Execution Quality, and Interaction Quality. Empirical results on AmbiBench reveal the performance boundaries of SoTA agents across different clarity levels, quantify the gains derived from active interaction, and validate the strong correlation between MUSE and human judgment. This work redefines evaluation standards, laying the foundation for next-generation agents capable of truly understanding user intent.", "AI": {"tldr": "构建一个基准测试AmbiBench，用于评估移动GUI代理在处理模糊和不完整指令时的能力。", "motivation": "现有基准主要基于用户能够提供明确且详尽的指令这一理想化假设，忽视了代理人对真实意图的理解与互动能力。因此提出一种更贴近实际场景的评价方法。", "method": "引入AmbiBench及其分类标准；建立包含240个任务的数据集，并开发MUSE评估框架来衡量代理人的表现。", "result": "展示了当前最佳技术代理在不同指令清晰度下的性能，强调了主动互动带来的收益并验证了MUSE的准确性。", "conclusion": "这项工作重新定义了移动GUI代理的评价标准，促进了新一代代理人真正理解用户意图的能力。"}}
{"id": "2602.11749", "pdf": "https://arxiv.org/pdf/2602.11749", "abs": "https://arxiv.org/abs/2602.11749", "authors": ["Zibo Xiao", "Jun Sun", "Junjie Chen"], "title": "AIR: Improving Agent Safety through Incident Response", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Model (LLM) agents are increasingly deployed in practice across a wide range of autonomous applications. Yet current safety mechanisms for LLM agents focus almost exclusively on preventing failures in advance, providing limited capabilities for responding to, containing, or recovering from incidents after they inevitably arise. In this work, we introduce AIR, the first incident response framework for LLM agent systems. AIR defines a domain-specific language for managing the incident response lifecycle autonomously in LLM agent systems, and integrates it into the agent's execution loop to (1) detect incidents via semantic checks grounded in the current environment state and recent context, (2) guide the agent to execute containment and recovery actions via its tools, and (3) synthesize guardrail rules during eradication to block similar incidents in future executions. We evaluate AIR on three representative agent types. Results show that AIR achieves detection, remediation, and eradication success rates all exceeding 90%. Extensive experiments further confirm the necessity of AIR's key design components, show the timeliness and moderate overhead of AIR, and demonstrate that LLM-generated rules can approach the effectiveness of developer-authored rules across domains. These results show that incident response is both feasible and essential as a first-class mechanism for improving agent safety.", "AI": {"tldr": "AIR框架旨在改进大型语言模型代理的安全性，通过自动处理事故响应周期来预防和解决意外情况。", "motivation": "当前对于大型语言模型（LLM）代理的安全机制主要集中在预防失败上，缺乏有效的应对、控制或恢复措施。因此，引入了AIR框架以增强此类系统的安全性。", "method": "AIR定义了一个特定领域的语言，用于在LLM代理系统中自主管理事故响应周期，并将其集成到代理的执行循环中进行检测、隔离和修复。", "result": "实验结果表明，AIR能够实现超过90%的成功检测率、缓解率以及消除率。此外，研究还证明了大型语言模型生成的安全规则可以接近开发者编写的规则的有效性。", "conclusion": "该研究表明，事故响应机制对于提高代理系统的安全性是可行且必要的。"}}
{"id": "2602.11745", "pdf": "https://arxiv.org/pdf/2602.11745", "abs": "https://arxiv.org/abs/2602.11745", "authors": ["Songlin Lyu", "Lujie Ban", "Zihang Wu", "Tianqi Luo", "Jirong Liu", "Chenhao Ma", "Yuyu Luo", "Nan Tang", "Shipeng Qi", "Heng Lin", "Yongchao Liu", "Chuntao Hong"], "title": "Text2GQL-Bench: A Text to Graph Query Language Benchmark [Experiment, Analysis & Benchmark]", "categories": ["cs.AI"], "comment": null, "summary": "Graph models are fundamental to data analysis in domains rich with complex relationships. Text-to-Graph-Query-Language (Text-to-GQL) systems act as a translator, converting natural language into executable graph queries. This capability allows Large Language Models (LLMs) to directly analyze and manipulate graph data, posi-tioning them as powerful agent infrastructures for Graph Database Management System (GDBMS). Despite recent progress, existing datasets are often limited in domain coverage, supported graph query languages, or evaluation scope. The advancement of Text-to-GQL systems is hindered by the lack of high-quality benchmark datasets and evaluation methods to systematically compare model capabilities across different graph query languages and domains. In this work, we present Text2GQL-Bench, a unified Text-to-GQL benchmark designed to address these limitations. Text2GQL-Bench couples a multi-GQL dataset that has 178,184 (Question, Query) pairs spanning 13 domains, with a scalable construction framework that generates datasets in different domains, question abstraction levels, and GQLs with heterogeneous resources. To support compre-hensive assessment, we introduce an evaluation method that goes beyond a single end-to-end metric by jointly reporting grammatical validity, similarity, semantic alignment, and execution accuracy. Our evaluation uncovers a stark dialect gap in ISO-GQL generation: even strong LLMs achieve only at most 4% execution accuracy (EX) in zero-shot settings, though a fixed 3-shot prompt raises accuracy to around 50%, the grammatical validity remains lower than 70%. Moreover, a fine-tuned 8B open-weight model reaches 45.1% EX, and 90.8% grammatical validity, demonstrating that most of the performance jump is unlocked by exposure to sufficient ISO-GQL examples.", "AI": {"tldr": "本文提出了一种用于评估文本到图查询语言（Text-to-GQL）系统的统一基准，解决了现有数据集在领域覆盖率、支持的图形查询语言以及评价范围方面的限制。", "motivation": "现有的文本到图查询语言系统由于缺乏高质量的基准数据集和全面的评估方法而受到局限。这使得很难系统性地比较不同图查询语言和领域的模型能力。", "method": "提出了Text2GQL-Bench，它包含一个多领域、多级别的问题抽象以及多种图形查询语言的数据集，并引入了一个超越单一端到端指标的综合性评价方法，涵盖语法有效性、相似度和语义一致性等方面。", "result": "实验显示，在零样本设置下，即使是强大的LLM模型在生成ISO-GQL时也仅能达到4%的执行准确率，而3-shot提示则可将该数值提升至50%，但其语法有效性的表现仍低于70%。细调后的8B开放权重模型达到了45.1%的执行准确度和90.8%的语法规则正确性。", "conclusion": "研究揭示了在ISO-GQL生成方面存在的显著方言差距，并表明大多数性能提升可以通过充分接触足够数量的ISO-GQL示例来解锁。"}}
{"id": "2602.11743", "pdf": "https://arxiv.org/pdf/2602.11743", "abs": "https://arxiv.org/abs/2602.11743", "authors": ["Xiangyu Wu", "Dongming Jiang", "Feng Yu", "Yueying Tian", "Jiaqi Tang", "Qing-Guo Chen", "Yang Yang", "Jianfeng Lu"], "title": "Adaptive Debiasing Tsallis Entropy for Test-Time Adaptation", "categories": ["cs.CV"], "comment": "Accepted for publication at ICLR 2026; 24 pages; 5 figures", "summary": "Mainstream Test-Time Adaptation (TTA) methods for adapting vision-language models, e.g., CLIP, typically rely on Shannon Entropy (SE) at test time to measure prediction uncertainty and inconsistency. However, since CLIP has a built-in bias from pretraining on highly imbalanced web-crawled data, SE inevitably results in producing biased estimates of uncertainty entropy. To address this issue, we notably find and demonstrate that Tsallis Entropy (TE), a generalized form of SE, is naturally suited for characterizing biased distributions by introducing a non-extensive parameter q, with the performance of SE serving as a lower bound for TE. Building upon this, we generalize TE into Adaptive Debiasing Tsallis Entropy (ADTE) for TTA, customizing a class-specific parameter q^l derived by normalizing the estimated label bias from continuously incoming test instances, for each category. This adaptive approach allows ADTE to accurately select high-confidence views and seamlessly integrate with a label adjustment strategy to enhance adaptation, without introducing distribution-specific hyperparameter tuning. Besides, our investigation reveals that both TE and ADTE can serve as direct, advanced alternatives to SE in TTA, without any other modifications. Experimental results show that ADTE outperforms state-of-the-art methods on ImageNet and its five variants, and achieves the highest average performance on 10 cross-domain benchmarks, regardless of the model architecture or text prompts used. Our code is available at https://github.com/Jinx630/ADTE.", "AI": {"tldr": "提出了一种自适应去偏Tsallis熵(ADTE)的方法，用于测试时的视觉-语言模型适应。", "motivation": "主流的测试时间适应方法依赖Shannon熵(SE)，但在处理CLIP等模型的预训练偏差时产生偏置。为了改进这一点，论文探讨了使用Tsallis熵（TE）和自适应去偏策略来提高适应性能。", "method": "通过引入一个非广泛参数q将Tsallis熵广义化为ADTE，并根据连续到来的测试实例估计类别特定偏置，实现了一种自适应选择高置信度视图的方法。此方法与标签调整策略结合使用，增强了模型的适应性。", "result": "实验表明，提出的ADTE在ImageNet及其五个变体以及10个跨领域基准上优于最先进的方法，并且无论所使用的模型架构或文本提示如何，都达到了最高的平均性能。", "conclusion": "通过自适应去偏Tsallis熵(ADTE)，可以有效提高视觉-语言模型的测试时间适应性，而无需引入分布特定的超参数调整。"}}
{"id": "2602.11740", "pdf": "https://arxiv.org/pdf/2602.11740", "abs": "https://arxiv.org/abs/2602.11740", "authors": ["Ayhan Alp Aydeniz", "Robert Loftin", "Kagan Tumer"], "title": "Counterfactual Conditional Likelihood Rewards for Multiagent Exploration", "categories": ["cs.MA", "cs.RO"], "comment": "9 pages, 5 figures", "summary": "Efficient exploration is critical for multiagent systems to discover coordinated strategies, particularly in open-ended domains such as search and rescue or planetary surveying. However, when exploration is encouraged only at the individual agent level, it often leads to redundancy, as agents act without awareness of how their teammates are exploring. In this work, we introduce Counterfactual Conditional Likelihood (CCL) rewards, which score each agent's exploration by isolating its unique contribution to team exploration. Unlike prior methods that reward agents solely for the novelty of their individual observations, CCL emphasizes observations that are informative with respect to the joint exploration of the team. Experiments in continuous multiagent domains show that CCL rewards accelerate learning for domains with sparse team rewards, where most joint actions yield zero rewards, and are particularly effective in tasks that require tight coordination among agents.", "AI": {"tldr": "介绍了一种新的奖励机制Counterfactual Conditional Likelihood(CCL)，用于加速多智能体系统在稀疏团队奖励环境中的学习过程，特别是在需要紧密协作的任务中。", "motivation": "为了使多智能体系统有效地探索和发现协调策略，在鼓励个体智能体的探索时避免冗余，作者提出了一种新的奖励机制CCL，以促进整个团队的有效探索。", "method": "提出了Counterfactual Conditional Likelihood(CCL) 奖励机制，该机制通过评估每个智能体对团队整体探索的独特贡献来评分和激励每个智能体的行为。与先前的方法不同，CCL 不仅仅是基于个体观察的新颖性进行奖励，而是强调那些对于整个团队的联合探索具有信息量的观察结果。", "result": "实验结果显示，在连续多智能体环境中，使用CCL 奖励可以加速学习过程，特别是在稀疏团队奖励和需要紧密协作的任务中表现尤为突出。", "conclusion": "提出的新颖奖励机制CCL 有助于解决多智能体系统中的探索效率问题，并且在实验任务中证明了其有效性。"}}
{"id": "2602.11737", "pdf": "https://arxiv.org/pdf/2602.11737", "abs": "https://arxiv.org/abs/2602.11737", "authors": ["Boqi Chen", "Xudong Liu", "Jianing Qiu"], "title": "Mask What Matters: Mitigating Object Hallucinations in Multimodal Large Language Models with Object-Aligned Visual Contrastive Decoding", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "We study object hallucination in Multimodal Large Language Models (MLLMs) and improve visual contrastive decoding (VCD) by constructing an object-aligned auxiliary view. We leverage object-centric attention in self-supervised Vision Transformers. In particular, we remove the most salient visual evidence to construct an auxiliary view that disrupts unsupported tokens and produces a stronger contrast signal. Our method is prompt-agnostic, model-agnostic, and can be seamlessly plugged into the existing VCD pipeline with little computation overhead, i.e., a single cacheable forward pass. Empirically, our method demonstrates consistent gains on two popular object hallucination benchmarks across two MLLMs.", "AI": {"tldr": "研究并减少多模态大型语言模型中的对象幻觉问题，通过构建与对象对齐的辅助视图改进视觉对比解码。", "motivation": "探讨多模态大型语言模型中存在的对象幻觉问题，并寻求一种可以减轻这种问题的方法。", "method": "利用自监督视觉变换器中的对象中心注意力机制，通过移除最显著的视觉证据来创建一个破坏未支持令牌并产生更强对比信号的辅助视图。该方法是提示无关、模型无关的，并且可以无缝集成到现有的视觉对比解码管道中而无需增加太多计算负担。", "result": "在两个流行的对象幻觉基准测试上，对于两种多模态大型语言模型均显示出一致的性能提升。", "conclusion": "通过构建与对象对齐的辅助视图改进了视觉对比解码技术，有效减轻了多模态大型语言模型中的对象幻觉问题。"}}
{"id": "2602.11735", "pdf": "https://arxiv.org/pdf/2602.11735", "abs": "https://arxiv.org/abs/2602.11735", "authors": ["Wanhao Liu", "Junhong Dai", "Yixuan Zhang", "Shengyun Yin", "Panshuo Li"], "title": "AC-MASAC: An Attentive Curriculum Learning Framework for Heterogeneous UAV Swarm Coordination", "categories": ["cs.RO"], "comment": null, "summary": "Cooperative path planning for heterogeneous UAV swarms poses significant challenges for Multi-Agent Reinforcement Learning (MARL), particularly in handling asymmetric inter-agent dependencies and addressing the risks of sparse rewards and catastrophic forgetting during training. To address these issues, this paper proposes an attentive curriculum learning framework (AC-MASAC). The framework introduces a role-aware heterogeneous attention mechanism to explicitly model asymmetric dependencies. Moreover, a structured curriculum strategy is designed, integrating hierarchical knowledge transfer and stage-proportional experience replay to address the issues of sparse rewards and catastrophic forgetting. The proposed framework is validated on a custom multi-agent simulation platform, and the results show that our method has significant advantages over other advanced methods in terms of Success Rate, Formation Keeping Rate, and Success-weighted Mission Time. The code is available at \\textcolor{red}{https://github.com/Wanhao-Liu/AC-MASAC}.", "AI": {"tldr": "提出了一种基于注意力的课程学习框架AC-MASAC，用于解决异构无人机群协同路径规划问题", "motivation": "为了解决多智能体强化学习中处理不对称互依关系、稀疏奖励和灾难性遗忘的问题", "method": "引入了角色感知的异构注意机制和结构化的课程策略，包括分层知识转移和比例经验回放", "result": "在成功率、编队保持率和加权任务时间方面优于其他先进方法", "conclusion": "所提框架有效提升了无人机群协同路径规划性能"}}
{"id": "2602.11733", "pdf": "https://arxiv.org/pdf/2602.11733", "abs": "https://arxiv.org/abs/2602.11733", "authors": ["Matteo Nulli", "Vladimir Orshulevich", "Tala Bazazo", "Christian Herold", "Michael Kozielski", "Marcin Mazur", "Szymon Tuzel", "Cees G. M. Snoek", "Seyyed Hadi Hashemi", "Omar Javed", "Yannick Versley", "Shahram Khadivi"], "title": "Adapting Vision-Language Models for E-commerce Understanding at Scale", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "E-commerce product understanding demands by nature, strong multimodal comprehension from text, images, and structured attributes. General-purpose Vision-Language Models (VLMs) enable generalizable multimodal latent modelling, yet there is no documented, well-known strategy for adapting them to the attribute-centric, multi-image, and noisy nature of e-commerce data, without sacrificing general performance. In this work, we show through a large-scale experimental study, how targeted adaptation of general VLMs can substantially improve e-commerce performance while preserving broad multimodal capabilities. Furthermore, we propose a novel extensive evaluation suite covering deep product understanding, strict instruction following, and dynamic attribute extraction.", "AI": {"tldr": "通过大规模实验研究展示如何针对通用视觉语言模型进行特定适应，以显著提高其在电子商务环境中的性能。", "motivation": "电子商务理解需要强大的多模态综合能力，但是没有一个公认的策略将这些通用的视觉语言模型（VLM）适配到属性中心、多图像和噪声环境中而不牺牲泛化性能。", "method": "提出了一种新型广泛评估套件，涵盖深度产品理解、严格指令遵循和动态属性提取。", "result": "实验表明，在电子商务环境中通过特定适应可以显著提高这些通用视觉语言模型的性能，并保持其广泛的多模态能力。", "conclusion": "成功证明了对通用VLM进行针对性调整以改进电子商务环境下表现的有效性。"}}
{"id": "2602.11730", "pdf": "https://arxiv.org/pdf/2602.11730", "abs": "https://arxiv.org/abs/2602.11730", "authors": ["Xiaowen Zhang", "Zhi Gao", "Licheng Jiao", "Lingling Li", "Qing Li"], "title": "STVG-R1: Incentivizing Instance-Level Reasoning and Grounding in Videos via Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "In vision-language models (VLMs), misalignment between textual descriptions and visual coordinates often induces hallucinations. This issue becomes particularly severe in dense prediction tasks such as spatial-temporal video grounding (STVG). Prior approaches typically focus on enhancing visual-textual alignment or attaching auxiliary decoders. However, these strategies inevitably introduce additional trainable modules, leading to significant annotation costs and computational overhead. In this work, we propose a novel visual prompting paradigm that avoids the difficult problem of aligning coordinates across modalities. Specifically, we reformulate per-frame coordinate prediction as a compact instance-level identification problem by assigning each object a unique, temporally consistent ID. These IDs are embedded into the video as visual prompts, providing explicit and interpretable inputs to the VLMs. Furthermore, we introduce STVG-R1, the first reinforcement learning framework for STVG, which employs a task-driven reward to jointly optimize temporal accuracy, spatial consistency, and structural format regularization. Extensive experiments on six benchmarks demonstrate the effectiveness of our approach. STVG-R1 surpasses the baseline Qwen2.5-VL-7B by a remarkable margin of 20.9% on m_IoU on the HCSTVG-v2 benchmark, establishing a new state of the art (SOTA). Surprisingly, STVG-R1 also exhibits strong zero-shot generalization to multi-object referring video object segmentation tasks, achieving a SOTA 47.3% J&F on MeViS.", "AI": {"tldr": "本文提出了一种新的视觉提示范式和首个用于时空视频定位（STVG）的强化学习框架，以解决现有方法中的问题。", "motivation": "为了解决当前视觉语言模型中因模态间坐标对齐不当导致的问题，以及避免引入额外可训练模块带来的高昂标注成本和计算负担。", "method": "本文提出了一种新的视觉提示范式，并将帧级坐标预测重构为实例级别的识别问题。同时引入了首个用于STVG的强化学习框架STVG-R1，通过任务驱动奖励优化时间精度、空间一致性以及结构格式正则化。", "result": "在六个基准测试中验证了该方法的有效性，其中STVG-R1相比基线模型Qwen2.5-VL-7B在HCSTVG-v2基准上提高了20.9%的m_IoU，并且展示了对多对象视频目标分割任务的强大零样本泛化能力。", "conclusion": "本文通过引入视觉提示和强化学习框架解决了现有方法中的问题，提升了时空视频定位任务的表现并建立了新的SOTA结果。"}}
{"id": "2602.11729", "pdf": "https://arxiv.org/pdf/2602.11729", "abs": "https://arxiv.org/abs/2602.11729", "authors": ["Thomas Jiralerspong", "Trenton Bricken"], "title": "Cross-Architecture Model Diffing with Crosscoders: Unsupervised Discovery of Differences Between LLMs", "categories": ["cs.AI", "cs.LG", "cs.SE"], "comment": null, "summary": "Model diffing, the process of comparing models' internal representations to identify their differences, is a promising approach for uncovering safety-critical behaviors in new models. However, its application has so far been primarily focused on comparing a base model with its finetune. Since new LLM releases are often novel architectures, cross-architecture methods are essential to make model diffing widely applicable. Crosscoders are one solution capable of cross-architecture model diffing but have only ever been applied to base vs finetune comparisons. We provide the first application of crosscoders to cross-architecture model diffing and introduce Dedicated Feature Crosscoders (DFCs), an architectural modification designed to better isolate features unique to one model. Using this technique, we find in an unsupervised fashion features including Chinese Communist Party alignment in Qwen3-8B and Deepseek-R1-0528-Qwen3-8B, American exceptionalism in Llama3.1-8B-Instruct, and a copyright refusal mechanism in GPT-OSS-20B. Together, our results work towards establishing cross-architecture crosscoder model diffing as an effective method for identifying meaningful behavioral differences between AI models.", "AI": {"tldr": "本文提出了一种跨架构模型对比的方法，使用专用特征交叉编码器来发现大型语言模型之间的差异。", "motivation": "现有的模型对比方法主要集中在基线模型与微调后的模型之间，但新的LLM通常是全新的架构。因此需要一种可以跨越不同架构的模型对比方法来发现其内在行为的不同。", "method": "本文首次将交叉编码器应用于跨架构模型对比，并引入了专用特征交叉编码器（DFCs），以更好地隔离一个模型特有的功能。", "result": "通过此技术，发现了Qwen3-8B和Deepseek-R1-0528-Qwen3-8B中的中国共产党倾向性、Llama3.1-8B-Instruct中的美国例外主义以及GPT-OSS-20B中的版权拒绝机制等特征。", "conclusion": "本文展示了跨架构交叉编码器模型对比作为一种有效方法，可以识别不同AI模型之间的行为差异，并进一步推动该领域的研究。"}}
{"id": "2602.11717", "pdf": "https://arxiv.org/pdf/2602.11717", "abs": "https://arxiv.org/abs/2602.11717", "authors": ["Weihong Lin", "Lin Sun", "Qilong Shi", "Aomufei Yuan", "Yuxuan Tian", "Zhengyang Wang", "Guangxiang Zhao", "Xiangzheng Zhang", "Tong Yang"], "title": "Beyond Parameter Arithmetic: Sparse Complementary Fusion for Distribution-Aware Model Merging", "categories": ["cs.AI"], "comment": null, "summary": "Model merging has emerged as a promising paradigm for composing the capabilities of large language models by directly operating in weight space, enabling the integration of specialized models without costly retraining. However, existing merging methods largely rely on parameter-space heuristics, which often introduce severe interference, leading to degraded generalization and unstable generation behaviors such as repetition and incoherent outputs. In this work, we propose Sparse Complementary Fusion with reverse KL (SCF-RKL), a novel model merging framework that explicitly controls functional interference through sparse, distribution-aware updates. Instead of assuming linear additivity in parameter space, SCF-RKL measures the functional divergence between models using reverse Kullback-Leibler divergence and selectively incorporates complementary parameters. This mode-seeking, sparsity-inducing design effectively preserves stable representations while integrating new capabilities. We evaluate SCF-RKL across a wide range of model scales and architectures, covering both reasoning-focused and instruction-tuned models. Extensive experiments on 24 benchmarks spanning advanced reasoning, general reasoning and knowledge, instruction following, and safety demonstrate, vision classification that SCF-RKL consistently outperforms existing model merging methods while maintaining strong generalization and generation stability.", "AI": {"tldr": "本文提出了SCF-RKL，一种新的模型融合框架，通过稀疏、分布感知的更新来控制功能干扰，从而在集成新能力的同时保持稳定的表示。", "motivation": "现有合并方法主要依赖参数空间启发式方法，常常引入严重干扰，导致泛化退化和生成行为不稳定。为了解决这一问题，本文提出SCF-RKL框架以提高模型融合的效果。", "method": "SCF-RKL通过反向Kullback-Leibler散度测量模型之间的功能差异，并选择性地合并互补参数。这种方法寻求模式并诱导稀疏性，从而有效保持稳定表示的同时集成新能力。", "result": "在涵盖推理、指令跟随和安全性的24个基准上的广泛实验表明，SCF-RKL在各种模型规模和架构上均优于现有方法，并且具有强大的泛化能力和生成稳定性。", "conclusion": "本文提出的SCF-RKL框架通过控制功能干扰，在保持稳定表示的同时有效集成新能力，显著提高了模型融合的效果。"}}
{"id": "2602.11714", "pdf": "https://arxiv.org/pdf/2602.11714", "abs": "https://arxiv.org/abs/2602.11714", "authors": ["Jiung Yeon", "Seongbo Ha", "Hyeonwoo Yu"], "title": "GSO-SLAM: Bidirectionally Coupled Gaussian Splatting and Direct Visual Odometry", "categories": ["cs.CV", "cs.RO"], "comment": "8 pages, 6 figures, RA-L accepted", "summary": "We propose GSO-SLAM, a real-time monocular dense SLAM system that leverages Gaussian scene representation. Unlike existing methods that couple tracking and mapping with a unified scene, incurring computational costs, or loosely integrate them with well-structured tracking frameworks, introducing redundancies, our method bidirectionally couples Visual Odometry (VO) and Gaussian Splatting (GS). Specifically, our approach formulates joint optimization within an Expectation-Maximization (EM) framework, enabling the simultaneous refinement of VO-derived semi-dense depth estimates and the GS representation without additional computational overhead. Moreover, we present Gaussian Splat Initialization, which utilizes image information, keyframe poses, and pixel associations from VO to produce close approximations to the final Gaussian scene, thereby eliminating the need for heuristic methods. Through extensive experiments, we validate the effectiveness of our method, showing that it not only operates in real time but also achieves state-of-the-art geometric/photometric fidelity of the reconstructed scene and tracking accuracy.", "AI": {"tldr": "提出了一种实时的单目密集SLAM系统GSO-SLAM，利用高斯场景表示方法。", "motivation": "现有的方法要么通过统一的场景耦合跟踪和映射，导致计算成本增加；要么松散地集成它们，引入冗余。为此，我们提出一种双向耦合VO与GS的方法，提高效率并减少额外开销。", "method": "我们的方法在EM框架中进行联合优化，同时改进了由VO产生的半密集深度估计和高斯表示，并提出了利用图像信息、关键帧姿态及像素关联的高斯初始化方法。", "result": "实验验证显示该系统不仅实现了实时运行，还达到了重建场景的几何/光度保真度和跟踪精度的新水平。", "conclusion": "GSO-SLAM通过双向耦合VO与GS的方法，在不增加计算成本的情况下提高了SLAM性能。"}}
{"id": "2602.11710", "pdf": "https://arxiv.org/pdf/2602.11710", "abs": "https://arxiv.org/abs/2602.11710", "authors": ["Zhidian Lin", "Allison Jing", "Ziyuan Qu", "Fabio Zambetta", "Ryan M. Kelly"], "title": "Mapping the Landscape of Affective Extended Reality: A Scoping Review of Biodata-Driven Systems for Understanding and Sharing Emotions", "categories": ["cs.HC", "cs.ET"], "comment": "30 pages, 18 figures, 8 tables", "summary": "This paper introduces the notion of affective extended reality (XR) to characterise XR systems that use biodata to enable understanding of emotions. The HCI literature contains many such systems, but they have not yet been mapped into a coherent whole. To address this, we conducted a scoping review of 82 papers that explore the nexus of biodata, emotions, and XR. We analyse the technologies used in these systems, the interaction techniques employed, and the methods used to evaluate their effectiveness. Through our analysis, we contribute a mapping of the current landscape of affective XR, revealing diversity in the goals for enabling emotion sharing. We demonstrate how HCI researchers have explored the design of the interaction flows in XR biofeedback systems, highlighting key design dimensions and challenges in understanding emotions. We discuss underused approaches for emotion sharing and highlight opportunities for future research on affective XR.", "AI": {"tldr": "本文通过综述82篇相关文献，探讨生物数据、情绪和扩展现实（XR）之间的关系，并绘制情感XR领域的地图。", "motivation": "在人机交互领域中存在许多利用生物信号来理解情绪的XR系统，但这些系统尚未整合成一个统一的整体。因此，该研究旨在填补这一空白。", "method": "作者进行了82篇相关论文的综述分析，探讨了这些系统所使用的技术、互动技术以及评估其效果的方法。", "result": "通过分析，贡献了一个关于当前情感XR领域的地图，揭示了促进情绪分享的各种目标，并展示了人机交互研究人员在XR生物反馈系统设计中的探索及其面临的挑战与机遇。", "conclusion": "该研究为情感XR领域提供了宝贵的见解，指出了未充分利用的情绪分享方法和未来的研究机会。"}}
{"id": "2602.11706", "pdf": "https://arxiv.org/pdf/2602.11706", "abs": "https://arxiv.org/abs/2602.11706", "authors": ["Arafa Yoncalik", "Wouter Jansen", "Nico Huebel", "Mohammad Hasan Rahmani", "Jan Steckel"], "title": "LLM-Driven 3D Scene Generation of Agricultural Simulation Environments", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "Accepted at IEEE Conference on Artificial Intelligence 2026", "summary": "Procedural generation techniques in 3D rendering engines have revolutionized the creation of complex environments, reducing reliance on manual design. Recent approaches using Large Language Models (LLMs) for 3D scene generation show promise but often lack domain-specific reasoning, verification mechanisms, and modular design. These limitations lead to reduced control and poor scalability. This paper investigates the use of LLMs to generate agricultural synthetic simulation environments from natural language prompts, specifically to address the limitations of lacking domain-specific reasoning, verification mechanisms, and modular design. A modular multi-LLM pipeline was developed, integrating 3D asset retrieval, domain knowledge injection, and code generation for the Unreal rendering engine using its API. This results in a 3D environment with realistic planting layouts and environmental context, all based on the input prompt and the domain knowledge. To enhance accuracy and scalability, the system employs a hybrid strategy combining LLM optimization techniques such as few-shot prompting, Retrieval-Augmented Generation (RAG), finetuning, and validation. Unlike monolithic models, the modular architecture enables structured data handling, intermediate verification, and flexible expansion. The system was evaluated using structured prompts and semantic accuracy metrics. A user study assessed realism and familiarity against real-world images, while an expert comparison demonstrated significant time savings over manual scene design. The results confirm the effectiveness of multi-LLM pipelines in automating domain-specific 3D scene generation with improved reliability and precision. Future work will explore expanding the asset hierarchy, incorporating real-time generation, and adapting the pipeline to other simulation domains beyond agriculture.", "AI": {"tldr": "该论文研究了利用大型语言模型生成农业模拟场景的技术，提出了一种模块化多LLM管道。", "motivation": "当前的3D场景生成技术缺乏领域特定推理、验证机制和模块设计，限制了控制性和可扩展性。本论文旨在解决这些问题，并通过自然语言提示生成具有现实布局和环境背景的农业模拟场景。", "method": "开发了一种多LLM管道，该管道结合了3D资产检索、领域知识注入以及Unreal渲染引擎API的代码生成技术。为了提高准确性和可扩展性，系统采用混合策略，包括少样本提示、检索增强生成（RAG）、微调和验证。", "result": "通过结构化提示和语义准确性指标进行评估，并通过用户研究和专家比较展示结果优于手动设计场景的时间效率。结论证实了多LLM管道在自动化领域特定3D场景生成中的有效性和可靠性。", "conclusion": "该系统能有效地自动生成农业模拟环境，具有较高的准确性和可扩展性。未来的工作将探索扩大资产层次结构、实现实时生成以及适应其他仿真领域。"}}
{"id": "2602.11705", "pdf": "https://arxiv.org/pdf/2602.11705", "abs": "https://arxiv.org/abs/2602.11705", "authors": ["Yuxiang Zhong", "Jun Wei", "Chaoqi Chen", "Senyou An", "Hui Huang"], "title": "TG-Field: Geometry-Aware Radiative Gaussian Fields for Tomographic Reconstruction", "categories": ["cs.CV"], "comment": "Accepted to AAAI 2026. Project page: https://vcc.tech/research/2026/TG-Field", "summary": "3D Gaussian Splatting (3DGS) has revolutionized 3D scene representation with superior efficiency and quality. While recent adaptations for computed tomography (CT) show promise, they struggle with severe artifacts under highly sparse-view projections and dynamic motions. To address these challenges, we propose Tomographic Geometry Field (TG-Field), a geometry-aware Gaussian deformation framework tailored for both static and dynamic CT reconstruction. A multi-resolution hash encoder is employed to capture local spatial priors, regularizing primitive parameters under ultra-sparse settings. We further extend the framework to dynamic reconstruction by introducing time-conditioned representations and a spatiotemporal attention block to adaptively aggregate features, thereby resolving spatiotemporal ambiguities and enforcing temporal coherence. In addition, a motion-flow network models fine-grained respiratory motion to track local anatomical deformations. Extensive experiments on synthetic and real-world datasets demonstrate that TG-Field consistently outperforms existing methods, achieving state-of-the-art reconstruction accuracy under highly sparse-view conditions.", "AI": {"tldr": "提出了一种用于CT重建的几何感知高斯变形框架TG-Field，该框架在稀疏视角下和动态场景中均表现出色。", "motivation": "为了克服当前技术在处理稀疏视角投影和动态运动时出现严重伪影的问题，本文提出了TG-Field。", "method": "使用多分辨率哈希编码器捕捉局部空间先验，并通过时间条件表示和时空注意力块来解决时空模糊并保持时间一致性。引入了运动流网络以模拟精细的呼吸运动，追踪局部解剖变形。", "result": "在合成数据集和真实世界数据集中进行广泛的实验显示TG-Field优于现有方法，在稀疏视角条件下达到最先进的重建精度。", "conclusion": "TG-Field提供了一种有效的方法来解决CT图像中的时空模糊问题，并且能够在高稀疏度下实现准确的重建。"}}
{"id": "2602.11704", "pdf": "https://arxiv.org/pdf/2602.11704", "abs": "https://arxiv.org/abs/2602.11704", "authors": ["Ayush Varshney", "Katherine L. Bouman", "Berthy T. Feng"], "title": "U-DAVI: Uncertainty-Aware Diffusion-Prior-Based Amortized Variational Inference for Image Reconstruction", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted at ICASSP 2026", "summary": "Ill-posed imaging inverse problems remain challenging due to the ambiguity in mapping degraded observations to clean images. Diffusion-based generative priors have recently shown promise, but typically rely on computationally intensive iterative sampling or per-instance optimization. Amortized variational inference frameworks address this inefficiency by learning a direct mapping from measurements to posteriors, enabling fast posterior sampling without requiring the optimization of a new posterior for every new set of measurements. However, they still struggle to reconstruct fine details and complex textures. To address this, we extend the amortized framework by injecting spatially adaptive perturbations to measurements during training, guided by uncertainty estimates, to emphasize learning in the most uncertain regions. Experiments on deblurring and super-resolution demonstrate that our method achieves superior or competitive performance to previous diffusion-based approaches, delivering more realistic reconstructions without the computational cost of iterative refinement.", "AI": {"tldr": "U-DAVI是一种不确定性感知的扩散先验为基础的变分推理框架，用于图像重建。", "motivation": "解决现有方法在处理复杂纹理和细节时效率低下的问题，并提高图像重建质量。", "method": "通过训练过程中对测量值进行空间自适应扰动来强调学习最不确定区域，同时利用不确定性估计指导这一过程。", "result": "实验表明该方法在去模糊和超分辨率任务中达到或优于先前的方法，生成更为逼真的重构结果且无需迭代细化的计算成本。", "conclusion": "U-DAVI通过引入不确定性感知的空间自适应扰动显著改进了图像重建的质量和效率。"}}
{"id": "2602.11703", "pdf": "https://arxiv.org/pdf/2602.11703", "abs": "https://arxiv.org/abs/2602.11703", "authors": ["Qiwen Xu", "David Rügamer", "Holger Wenz", "Johann Fontana", "Nora Meggyeshazi", "Andreas Bender", "Máté E. Maros"], "title": "Semantically Conditioned Diffusion Models for Cerebral DSA Synthesis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Digital subtraction angiography (DSA) plays a central role in the diagnosis and treatment of cerebrovascular disease, yet its invasive nature and high acquisition cost severely limit large-scale data collection and public data sharing. Therefore, we developed a semantically conditioned latent diffusion model (LDM) that synthesizes arterial-phase cerebral DSA frames under explicit control of anatomical circulation (anterior vs.\\ posterior) and canonical C-arm positions. We curated a large single-centre DSA dataset of 99,349 frames and trained a conditional LDM using text embeddings that encoded anatomy and acquisition geometry. To assess clinical realism, four medical experts, including two neuroradiologists, one neurosurgeon, and one internal medicine expert, systematically rated 400 synthetic DSA images using a 5-grade Likert scale for evaluating proximal large, medium, and small peripheral vessels. The generated images achieved image-wise overall Likert scores ranging from 3.1 to 3.3, with high inter-rater reliability (ICC(2,k) = 0.80--0.87). Distributional similarity to real DSA frames was supported by a low median Fréchet inception distance (FID) of 15.27. Our results indicate that semantically controlled LDMs can produce realistic synthetic DSAs suitable for downstream algorithm development, research, and training.", "AI": {"tldr": "开发了一种语义条件下的潜在扩散模型，用于合成脑部数字减影血管造影图像。", "motivation": "DSA在诊断和治疗脑血管疾病中至关重要，但其侵入性和高昂的获取成本限制了大规模数据收集和公共数据共享。因此，该研究旨在通过使用有条件生成对抗网络来克服这一挑战，并产生临床现实的合成DSAs。", "method": "利用文本嵌入编码解剖学和采集几何形状的大规模单中心DSA图像集训练语义条件下的潜在扩散模型。采用400张合成DSA图像进行评估，由四位医学专家使用5级Likert量表评定血管。", "result": "生成的图像获得了从3.1到3.3的整体Likert评分，并显示出高信度（ICC(2,k) = 0.80--0.87）。分布相似性通过低中位Fréchet inception距离(FID=15.27)得到支持。", "conclusion": "研究表明，语义控制的潜在扩散模型可以产生适合下游算法开发、研究和训练的真实合成DSAs。"}}
{"id": "2602.11700", "pdf": "https://arxiv.org/pdf/2602.11700", "abs": "https://arxiv.org/abs/2602.11700", "authors": ["Yongyao Wang", "Ziqi Miao", "Lu Yang", "Haonan Jia", "Wenting Yan", "Chen Qian", "Lijun Li"], "title": "TabSieve: Explicit In-Table Evidence Selection for Tabular Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages", "summary": "Tabular prediction can benefit from in-table rows as few-shot evidence, yet existing tabular models typically perform instance-wise inference and LLM-based prompting is often brittle. Models do not consistently leverage relevant rows, and noisy context can degrade performance. To address this challenge, we propose TabSieve, a select-then-predict framework that makes evidence usage explicit and auditable. Given a table and a query row, TabSieve first selects a small set of informative rows as evidence and then predicts the missing target conditioned on the selected evidence. To enable this capability, we construct TabSieve-SFT-40K by synthesizing high-quality reasoning trajectories from 331 real tables using a strong teacher model with strict filtering. Furthermore, we introduce TAB-GRPO, a reinforcement learning recipe that jointly optimizes evidence selection and prediction correctness with separate rewards, and stabilizes mixed regression and classification training via dynamic task-advantage balancing. Experiments on a held-out benchmark of 75 classification and 52 regression tables show that TabSieve consistently improves performance across shot budgets, with average gains of 2.92% on classification and 4.45% on regression over the second-best baseline. Further analysis indicates that TabSieve concentrates more attention on the selected evidence, which improves robustness to noisy context.", "AI": {"tldr": "本文提出了TabSieve框架，通过显式选择表格中的相关行作为证据来提高表预测任务的性能。", "motivation": "现有的表格模型在处理实例时不够灵活且易受噪声影响，因此提出了一种新的框架以改进其对证据的选择和利用。", "method": "首先使用强化学习技术从真实表格中合成高质量推理轨迹，然后通过奖励优化选择正确的证据并进行预测。", "result": "实验结果显示，在不同情况下TabSieve的性能均有提升，平均提高了2.92%（分类）和4.45%（回归）。", "conclusion": "该方法提升了模型对有用证据的关注度，增强了其在噪声环境下的鲁棒性。"}}
{"id": "2602.11693", "pdf": "https://arxiv.org/pdf/2602.11693", "abs": "https://arxiv.org/abs/2602.11693", "authors": ["Zehao Xia", "Yiqun Wang", "Zhengda Lu", "Kai Liu", "Jun Xiao", "Peter Wonka"], "title": "OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "Project page: https://omega-avatar.github.io/OMEGA-Avatar/", "summary": "Creating high-fidelity, animatable 3D avatars from a single image remains a formidable challenge. We identified three desirable attributes of avatar generation: 1) the method should be feed-forward, 2) model a 360° full-head, and 3) should be animation-ready. However, current work addresses only two of the three points simultaneously. To address these limitations, we propose OMEGA-Avatar, the first feed-forward framework that simultaneously generates a generalizable, 360°-complete, and animatable 3D Gaussian head from a single image. Starting from a feed-forward and animatable framework, we address the 360° full-head avatar generation problem with two novel components. First, to overcome poor hair modeling in full-head avatar generation, we introduce a semantic-aware mesh deformation module that integrates multi-view normals to optimize a FLAME head with hair while preserving its topology structure. Second, to enable effective feed-forward decoding of full-head features, we propose a multi-view feature splatting module that constructs a shared canonical UV representation from features across multiple views through differentiable bilinear splatting, hierarchical UV mapping, and visibility-aware fusion. This approach preserves both global structural coherence and local high-frequency details across all viewpoints, ensuring 360° consistency without per-instance optimization. Extensive experiments demonstrate that OMEGA-Avatar achieves state-of-the-art performance, significantly outperforming existing baselines in 360° full-head completeness while robustly preserving identity across different viewpoints.", "AI": {"tldr": "该论文提出了一种从单张图片生成高保真度、可动画化的全方位三维头像的方法。", "motivation": "当前方法在生成高保真度的全方位头部模型时，无法同时满足一次性建模、全局完整性和可动画化的要求。作者旨在开发一种能够同时具备这三种属性的模型。", "method": "论文提出了OMEGA-Avatar框架，通过引入语义感知网格变形模块和多视图特征融合模块来生成高保真度、全方位、可动画化的三维头像。", "result": "实验结果表明，该方法在360°头部完整性及身份一致性方面超越了现有的基准模型。", "conclusion": "OMEGA-Avatar框架是首个能够一次性从单张图片中生成高质量全方位可动画化三维头像的方法，并且展示了出色的性能。"}}
{"id": "2602.11690", "pdf": "https://arxiv.org/pdf/2602.11690", "abs": "https://arxiv.org/abs/2602.11690", "authors": ["Oliver Zahn", "Matt Beton", "Simran Chana"], "title": "ANML: Attribution-Native Machine Learning with Guaranteed Robustness", "categories": ["cs.LG", "cs.AI"], "comment": "27 pages, 6 figures", "summary": "Frontier AI systems increasingly train on specialized expert data, from clinical records to proprietary research to curated datasets, yet current training pipelines treat all samples identically. A Nobel laureate's contribution receives the same weight as an unverified submission. We introduce ANML (Attribution-Native Machine Learning), a framework that weights training samples by four quality factors: gradient-based consistency (q), verification status (v), contributor reputation (r), and temporal relevance (T). By combining what the model observes (gradient signals) with what the system knows about data provenance (external signals), ANML produces per-contributor quality weights that simultaneously improve model performance and enable downstream attribution. Across 5 datasets (178-32,561 samples), ANML achieves 33-72% error reduction over gradient-only baselines. Quality-weighted training is data-efficient: 20% high-quality data outperforms 100% uniformly weighted data by 47%. A Two-Stage Adaptive gating mechanism guarantees that ANML never underperforms the best available baseline, including under strategic joint attacks combining credential faking with gradient alignment. When per-sample detection fails against subtle corruption, contributor-level attribution provides 1.3-5.3x greater improvement than sample-level methods, with the advantage growing as corruption becomes harder to detect.", "AI": {"tldr": "ANML框架通过结合模型观察到的梯度信号和系统对数据来源的理解，提高训练样本的质量权重，以提升模型性能并支持下游归因分析。", "motivation": "当前AI系统的训练流程没有区别对待不同质量的数据，导致高质量贡献（如诺贝尔奖得主）与低质量或未经验证的提交获得相同处理。这可能导致不准确的学习和潜在的安全风险。", "method": "ANML框架通过四个因素对训练样本进行加权：梯度一致性、验证状态、贡献者声誉和时间相关性。结合模型观察到的数据（如梯度信号）和系统所知的来源信息，该框架生成每个贡献者的质量权重，并采用两阶段自适应门控机制保证性能。", "result": "在五个数据集上的实验表明，ANML相对于仅基于梯度的方法能够减少33%至72%的错误率。使用高质量的数据比均匀加权所有数据更具效率，例如，20％高质量数据优于100％统一加权的数据47％。此外，在面临难以检测到的样本级篡改时，贡献者级别的归因方法表现更优。", "conclusion": "ANML不仅提升了模型性能和数据利用效率，还在保护AI系统免受潜在攻击方面提供了有效的方法。"}}
{"id": "2602.11685", "pdf": "https://arxiv.org/pdf/2602.11685", "abs": "https://arxiv.org/abs/2602.11685", "authors": ["Joey Zhong", "Hao Zhang", "Clare Southern", "Jeremy Yang", "Thomas Wang", "Kate Jung", "Shu Zhang", "Denis Yarats", "Johnny Ho", "Jerry Ma"], "title": "DRACO: a Cross-Domain Benchmark for Deep Research Accuracy, Completeness, and Objectivity", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present DRACO (Deep Research Accuracy, Completeness, and Objectivity), a benchmark of complex deep research tasks. These tasks, which span 10 domains and draw on information sources from 40 countries, originate from anonymized real-world usage patterns within a large-scale deep research system. Tasks are sampled from a de-identified dataset of Perplexity Deep Research requests, then filtered and augmented to ensure that the tasks are anonymized, open-ended and complex, objectively evaluable, and representative of the broad scope of real-world deep research use cases. Outputs are graded against task-specific rubrics along four dimensions: factual accuracy (accuracy), breadth and depth of analysis (including completeness), presentation quality (including objectivity), and citation quality. DRACO is publicly available at https://hf.co/datasets/perplexity-ai/draco.", "AI": {"tldr": "提出DRACO基准，用于评估复杂深度研究任务的准确性、完整性和客观性。", "motivation": "为了提供一个能够全面评估深度研究报告质量和真实世界使用情况的标准。", "method": "从匿名化的真实世界数据集中抽取和过滤任务，并根据特定准则进行评分。", "result": "DRACO基准涵盖了10个领域，包含来自40个国家的信息来源，用于评估报告的准确性、分析广度与深度、呈现质量以及引用质量。", "conclusion": "DRACO是一个公开可用的工具，能够帮助研究人员和系统开发者提高其在复杂领域的研究质量和客观性。"}}
{"id": "2602.11684", "pdf": "https://arxiv.org/pdf/2602.11684", "abs": "https://arxiv.org/abs/2602.11684", "authors": ["Sahand Sabour", "TszYam NG", "Minlie Huang"], "title": "PatientHub: A Unified Framework for Patient Simulation", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "Work in progress", "summary": "As Large Language Models increasingly power role-playing applications, simulating patients has become a valuable tool for training counselors and scaling therapeutic assessment. However, prior work is fragmented: existing approaches rely on incompatible, non-standardized data formats, prompts, and evaluation metrics, hindering reproducibility and fair comparison. In this paper, we introduce PatientHub, a unified and modular framework that standardizes the definition, composition, and deployment of simulated patients. To demonstrate PatientHub's utility, we implement several representative patient simulation methods as case studies, showcasing how our framework supports standardized cross-method evaluation and the seamless integration of custom evaluation metrics. We further demonstrate PatientHub's extensibility by prototyping two new simulator variants, highlighting how PatientHub accelerates method development by eliminating infrastructure overhead. By consolidating existing work into a single reproducible pipeline, PatientHub lowers the barrier to developing new simulation methods and facilitates cross-method and cross-model benchmarking. Our framework provides a practical foundation for future datasets, methods, and benchmarks in patient-centered dialogue, and the code is publicly available via https://github.com/Sahandfer/PatientHub.", "AI": {"tldr": "介绍了一个统一的框架PatientHub，用于标准化模拟患者的方法、评估和集成。", "motivation": "现有的模拟方法缺乏标准化的数据格式、提示词和评估指标，导致难以重现结果并进行公平比较。因此需要一个统一的标准来提高可重复性和互操作性。", "method": "提出了PatientHub框架，该框架能够定义、组合和部署标准化的模拟患者模型，并支持跨方法和自定义评估指标的一致评测。", "result": "通过案例研究展示了PatientHub在不同模拟方法中的应用以及其扩展性的证明，表明它能加速新方法开发并降低基础设施开销。", "conclusion": "PatientHub为未来的研究提供了一个实用的基础平台，并且框架的代码公开可供访问。"}}
{"id": "2602.11683", "pdf": "https://arxiv.org/pdf/2602.11683", "abs": "https://arxiv.org/abs/2602.11683", "authors": ["Xin Xu", "Tong Yu", "Xiang Chen", "Haoliang Wang", "Julian McAuley", "Saayan Mitra"], "title": "ThinkRouter: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Work in Progress", "summary": "Recent work explores latent reasoning to improve reasoning efficiency by replacing explicit reasoning trajectories with continuous representations in a latent space, yet its effectiveness varies across settings. Analysis of model confidence dynamics under latent reasoning reveals that thinking trajectories ending in incorrect answers contain fewer low-confidence steps than those ending in correct answers. Meanwhile, we suggest that soft embeddings aggregated by multiple low-confidence thinking alternatives may introduce and propagate noise, leading to high confidence in unreliable reasoning trajectories. Motivated by these observations, ThinkRouter, an inference-time confidence-aware routing mechanism is proposed to avoid high confidence and noise for efficient reasoning. ThinkRouter routes thinking to the discrete token space when model confidence is low, and to the latent space otherwise. Extensive experiments on STEM reasoning and coding benchmarks across diverse large reasoning models demonstrate that ThinkRouter outperforms explicit CoT, random routing, and latent reasoning baselines in terms of accuracy, achieving an average improvement of 19.70 points in Pass@1, while reducing generation length by up to 15.55%. Further comprehensive analysis reveals that ThinkRouter can calibrate errors arising from explicit CoT and latent reasoning, and accelerates end-of-thinking token generation by globally lowering model confidence.", "AI": {"tldr": "ThinkRouter通过推理时间自信度感知路由机制，实现高效推理。", "motivation": "在隐式推理中发现错误回答的思考轨迹包含较少低置信步骤，并提出软嵌入聚合可能导致噪声传播的问题。因此设计了自信度感知路由机制来避免高置信和噪音以提高效率。", "method": "ThinkRouter根据模型自信度决定将思考导向离散标记空间或隐式空间，当自信度过低时转向离散标记空间；否则继续在隐式空间内进行推理。", "result": "实验显示ThinkRouter比显式CoT、随机路由和隐式推理基准分别提高了Pass@1平均准确率19.70个百分点，并缩短了生成长度最多达到15.55%。同时还能校准由显式CoT和隐式推理引入的错误，加速思考结束标记生成。", "conclusion": "通过自信度感知路由机制ThinkRouter在保持准确性的同时提高了效率并减少了噪声传播，适用于多样大型推理模型的STEM推理及编码基准测试中。"}}
{"id": "2602.11679", "pdf": "https://arxiv.org/pdf/2602.11679", "abs": "https://arxiv.org/abs/2602.11679", "authors": ["Kyungbok Lee", "Angelica Cristello Sarteau", "Michael R. Kosorok"], "title": "Provable Offline Reinforcement Learning for Structured Cyclic MDPs", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.OC", "stat.ME"], "comment": "65 pages, 4 figures. Submitted to JMLR", "summary": "We introduce a novel cyclic Markov decision process (MDP) framework for multi-step decision problems with heterogeneous stage-specific dynamics, transitions, and discount factors across the cycle. In this setting, offline learning is challenging: optimizing a policy at any stage shifts the state distributions of subsequent stages, propagating mismatch across the cycle. To address this, we propose a modular structural framework that decomposes the cyclic process into stage-wise sub-problems. While generally applicable, we instantiate this principle as CycleFQI, an extension of fitted Q-iteration enabling theoretical analysis and interpretation. It uses a vector of stage-specific Q-functions, tailored to each stage, to capture within-stage sequences and transitions between stages. This modular design enables partial control, allowing some stages to be optimized while others follow predefined policies. We establish finite-sample suboptimality error bounds and derive global convergence rates under Besov regularity, demonstrating that CycleFQI mitigates the curse of dimensionality compared to monolithic baselines. Additionally, we propose a sieve-based method for asymptotic inference of optimal policy values under a margin condition. Experiments on simulated and real-world Type 1 Diabetes data sets demonstrate CycleFQI's effectiveness.", "AI": {"tldr": "提出了一个新的循环马尔可夫决策过程框架，用于解决具有异质阶段特定动态的多步决策问题，并提出了一种名为CycleFQI的新方法，该方法能够理论分析并解释。", "motivation": "为了解决在闭环中由于优化一个周期内的策略导致后续阶段的状态分布发生变化而产生的传播不匹配问题，作者提出了一个新的循环马尔可夫决策过程框架和一种新的方法来解决这个问题。", "method": "提出了一种模块化结构框架，该框架将循环过程分解成阶段性子问题，并具体实现为CycleFQI，这是一种扩展的拟合Q迭代方法。它使用一组特定阶段的Q函数，可以捕获每个阶段内的序列和各阶段之间的过渡，允许部分控制。", "result": "实验结果表明，CycleFQI在模拟数据集和真实世界中的1型糖尿病数据集中都表现出色，并且比单一基线方法更能缓解维度灾难问题。", "conclusion": "通过理论分析和实验证明了CycleFQI的有效性及其对解决具有复杂动态特性的多步决策问题的优势。"}}
{"id": "2602.11678", "pdf": "https://arxiv.org/pdf/2602.11678", "abs": "https://arxiv.org/abs/2602.11678", "authors": ["Chengwei Ma", "Zhen Tian", "Zhou Zhou", "Zhixian Xu", "Xiaowei Zhu", "Xia Hua", "Si Shi", "F. Richard Yu"], "title": "Beyond Pixels: Vector-to-Graph Transformation for Reliable Schematic Auditing", "categories": ["cs.AI", "cs.CV"], "comment": "4 pages, 3 figures. Accepted to ICASSP 2026", "summary": "Multimodal Large Language Models (MLLMs) have shown remarkable progress in visual understanding, yet they suffer from a critical limitation: structural blindness. Even state-of-the-art models fail to capture topology and symbolic logic in engineering schematics, as their pixel-driven paradigm discards the explicit vector-defined relations needed for reasoning. To overcome this, we propose a Vector-to-Graph (V2G) pipeline that converts CAD diagrams into property graphs where nodes represent components and edges encode connectivity, making structural dependencies explicit and machine-auditable. On a diagnostic benchmark of electrical compliance checks, V2G yields large accuracy gains across all error categories, while leading MLLMs remain near chance level. These results highlight the systemic inadequacy of pixel-based methods and demonstrate that structure-aware representations provide a reliable path toward practical deployment of multimodal AI in engineering domains. To facilitate further research, we release our benchmark and implementation at https://github.com/gm-embodied/V2G-Audit.", "AI": {"tldr": "本文提出了一种将CAD图纸转换为属性图的Vector-to-Graph（V2G）管道，以增强工程图样审计的准确性。", "motivation": "多模态大型语言模型在视觉理解方面取得了显著进展，但在处理工程图样的拓扑结构和符号逻辑时存在盲点。传统的像素驱动方法无法捕捉到矢量定义的关系，因此需要一种新的方法来改进这一缺陷。", "method": "本文提出了一种将CAD图纸转换为属性图的Vector-to-Graph（V2G）管道，其中节点表示组件，边编码连接性，以明确结构依赖关系并使其可被机器审计。", "result": "在电气合规检查诊断基准上，V2G方法比最先进的多模态大型语言模型在所有错误类别中取得了显著的准确性提升。", "conclusion": "这些结果表明了像素驱动方法在处理工程图样时的系统性不足，并展示了结构感知表示为多模态AI在工程领域的实用部署提供了一条可靠路径。"}}
{"id": "2602.11675", "pdf": "https://arxiv.org/pdf/2602.11675", "abs": "https://arxiv.org/abs/2602.11675", "authors": ["Edward Y. Chang"], "title": "Right for the Wrong Reasons: Epistemic Regret Minimization for Causal Rung Collapse in LLMs", "categories": ["cs.AI"], "comment": "18 pages, 6 tables, 3 figures", "summary": "Machine learning systems that are \"right for the wrong reasons\" achieve high performance through shortcuts that collapse under distributional shift. We show this pathology has a precise causal origin: autoregressive training provides no gradient signal to distinguish association P(Y|X) from intervention P(Y|do(X)), a failure we formalize as Rung Collapse. When outcome-based learning reinforces correct answers obtained through incorrect causal models, the agent becomes entrenched in flawed reasoning, a phenomenon we term Aleatoric Entrenchment. We propose Epistemic Regret Minimization (ERM), a belief revision objective that penalizes errors in causal reasoning independently of task success, and embed it within a three-layer architecture with three contributions grounded in knowledge representation: (1) a Physical Grounding Theorem proving that actions satisfying actuator independence implement valid do-operations, bridging action languages and do-calculus; (2) ERM as a causal belief revision operator satisfying AGM postulates, preventing entrenchment even when the agent succeeds for the wrong reasons; and (3) a failure mode taxonomy that classifies recurring reasoning errors and injects domain-independent guards, enabling cross-domain transfer. We prove asymptotic recovery of the true interventional distribution with finite-sample bounds. Experiments on 1,360 causal trap scenarios across six frontier LLMs reveal that Rung Collapse persists even in reasoning-enhanced models (3.7% for GPT-5.2), that steerability exhibits inverse scaling where advanced models resist generic correction, and that targeted ERM feedback recovers 53-59% of entrenched errors where outcome-level feedback fails.", "AI": {"tldr": "研究提出了一种新的方法来解决大型语言模型中的因果推理问题，即“正确但理由错误”的现象。", "motivation": "在机器学习系统中，通过捷径获得高表现力的模型可能会陷入分布偏移的问题。这种病理有精确的因果根源：自回归训练无法区分关联和干预信号，导致模型被错误的因果模型所固化。", "method": "提出了Epistemic Regret Minimization (ERM)，这是一种信念修订目标，通过惩罚任务成功之外的因果推理错误来防止错误因果模型的强化。该方法嵌入在三层架构中，并包括知识表示方面三个贡献：物理接地定理、作为因果信念修正算子的ERM和故障模式分类。", "result": "实验结果表明，Rung Collapse现象即使在增强型因果模型中依然存在（GPT-5.2为3.7%），高级别模型对通用纠正更具有抵抗力。但是，针对性的ERM反馈可以恢复被固化的错误，并且比仅基于输出级别的反馈更加有效。", "conclusion": "该研究证明了通过引入新的信念修订目标和架构设计来解决因果推理中“正确但理由错误”的现象是可行的，这为未来的模型改进提供了理论基础。"}}
{"id": "2602.11674", "pdf": "https://arxiv.org/pdf/2602.11674", "abs": "https://arxiv.org/abs/2602.11674", "authors": ["Longyuan Zhu", "Hairan Hua", "Linlin Miao", "Bing Zhao"], "title": "Benchmark Health Index: A Systematic Framework for Benchmarking the Benchmarks of LLMs", "categories": ["cs.AI"], "comment": "42 pages, 8 figures, 7 tables. Code and website available at https://github.com/SKYLENAGE-AI/benchmark-health-index", "summary": "Large Language Models (LLMs) are advancing rapidly, yet the benchmarks used to measure this progress are becoming increasingly unreliable. Score inflation and selective reporting have eroded the authority of standard benchmarks, leaving the community uncertain about which evaluation results remain trustworthy. We introduce the Benchmark Health Index (BHI), a pure data-driven framework for auditing evaluation sets along three orthogonal and complementary axes: (1) Capability Discrimination, measuring how sharply a benchmark separates model performance beyond noise; (2) Anti-Saturation, estimating remaining headroom before ceiling effects erode resolution and thus the benchmark's expected longevity; and (3) Impact, quantifying influence across academic and industrial ecosystems via adoption breadth and practice-shaping power. By distilling 106 validated benchmarks from the technical reports of 91 representative models in 2025, we systematically characterize the evaluation landscape. BHI is the first framework to quantify benchmark health at a macro level, providing a principled basis for benchmark selection and enabling dynamic lifecycle management for next-generation evaluation protocols.", "AI": {"tldr": "介绍Benchmark Health Index（BHI），一种用于评估大型语言模型（LLMs）基准测试可靠性的框架。", "motivation": "由于评分膨胀和选择性报告，现有的标准基准变得不可靠，导致社区对评估结果的信任度降低。因此需要一个系统化的方法来审计这些基准。", "method": "BHI通过三个轴向进行评估：区分能力、抗饱和能力和影响力，并基于2025年的技术报告中的106个验证过的基准和91种代表性模型的数据，形成了一套数据驱动的框架。", "result": "系统地描述了评价环境并提出了第一个在宏观层面量化基准健康的框架。", "conclusion": "BHI为基准选择提供了理论基础，并能实现下一代评估协议的动态生命周期管理。"}}
{"id": "2602.11673", "pdf": "https://arxiv.org/pdf/2602.11673", "abs": "https://arxiv.org/abs/2602.11673", "authors": ["Khanh Nguyen", "Dasith de Silva Edirimuni", "Ghulam Mubashar Hassan", "Ajmal Mian"], "title": "RI-Mamba: Rotation-Invariant Mamba for Robust Text-to-Shape Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "3D assets have rapidly expanded in quantity and diversity due to the growing popularity of virtual reality and gaming. As a result, text-to-shape retrieval has become essential in facilitating intuitive search within large repositories. However, existing methods require canonical poses and support few object categories, limiting their real-world applicability where objects can belong to diverse classes and appear in random orientations. To address this challenge, we propose RI-Mamba, the first rotation-invariant state-space model for point clouds. RI-Mamba defines global and local reference frames to disentangle pose from geometry and uses Hilbert sorting to construct token sequences with meaningful geometric structure while maintaining rotation invariance. We further introduce a novel strategy to compute orientational embeddings and reintegrate them via feature-wise linear modulation, effectively recovering spatial context and enhancing model expressiveness. Our strategy is inherently compatible with state-space models and operates in linear time. To scale up retrieval, we adopt cross-modal contrastive learning with automated triplet generation, allowing training on diverse datasets without manual annotation. Extensive experiments demonstrate RI-Mamba's superior representational capacity and robustness, achieving state-of-the-art performance on the OmniObject3D benchmark across more than 200 object categories under arbitrary orientations. Our code will be made available at https://github.com/ndkhanh360/RI-Mamba.git.", "AI": {"tldr": "提出了RI-Mamba，一种旋转不变性点云状态空间模型，用于增强文本到形状检索的鲁棒性和表现力。", "motivation": "现有方法依赖于标准姿态且仅支持有限的对象类别，在现实应用中限制了它们的效果。本文提出了解决方案，以处理任意方向下的多样化对象。", "method": "通过定义全局和局部参考框架分离姿态与几何，并使用希尔伯特排序构建具有有意义几何结构的令牌序列，同时保持旋转不变性；引入计算定向嵌入并通过特征级线性调制重新整合策略；采用跨模式对比学习以实现大规模检索。", "result": "在OmniObject3D基准测试中，在超过200个对象类别和任意方向下表现出优越的表现力和鲁棒性，达到了最先进的性能。", "conclusion": "RI-Mamba通过旋转不变性和增强的模型表现力有效地提升了文本到形状检索的效果，并为大规模数据集提供了有效的训练策略。"}}
{"id": "2602.11672", "pdf": "https://arxiv.org/pdf/2602.11672", "abs": "https://arxiv.org/abs/2602.11672", "authors": ["Yingyi Luo", "Shuaiang Rong", "Adam Watts", "Ahmet Enis Cetin"], "title": "U-Net with Hadamard Transform and DCT Latent Spaces for Next-day Wildfire Spread Prediction", "categories": ["cs.CV"], "comment": null, "summary": "We developed a lightweight and computationally efficient tool for next-day wildfire spread prediction using multimodal satellite data as input. The deep learning model, which we call Transform Domain Fusion UNet (TD-FusionUNet), incorporates trainable Hadamard Transform and Discrete Cosine Transform layers that apply two-dimensional transforms, enabling the network to capture essential \"frequency\" components in orthogonalized latent spaces. Additionally, we introduce custom preprocessing techniques, including random margin cropping and a Gaussian mixture model, to enrich the representation of the sparse pre-fire masks and enhance the model's generalization capability. The TD-FusionUNet is evaluated on two datasets which are the Next-Day Wildfire Spread dataset released by Google Research in 2023, and WildfireSpreadTS dataset. Our proposed TD-FusionUNet achieves an F1 score of 0.591 with 370k parameters, outperforming the UNet baseline using ResNet18 as the encoder reported in the WildfireSpreadTS dataset while using substantially fewer parameters. These results show that the proposed latent space fusion model balances accuracy and efficiency under a lightweight setting, making it suitable for real time wildfire prediction applications in resource limited environments.", "AI": {"tldr": "提出了一种轻量级的深度学习模型TD-FusionUNet，用于通过多模态卫星数据进行次日野火蔓延预测。", "motivation": "开发一种高效且计算资源要求低的工具，以利用多模态卫星数据预测次日野火扩散情况。使用Hadamard变换和DCT层增强网络捕捉关键频率成分的能力，并引入预处理技术提高模型泛化能力。", "method": "采用轻量级TD-FusionUNet模型，该模型在U-Net基础上增加了可训练的Hadamard变换和离散余弦变换层。同时使用随机边缘裁剪及高斯混合模型来增强稀疏火灾前掩码的表现力。", "result": "在Next-Day Wildfire Spread数据集上获得F1得分为0.591，参数量为37万，在WildfireSpreadTS数据集中超越了基于ResNet18的UNet基线模型，显示出良好的精度与效率平衡。", "conclusion": "TD-FusionUNet在资源有限环境下实现了准确且高效的野火预测能力。"}}
{"id": "2602.11669", "pdf": "https://arxiv.org/pdf/2602.11669", "abs": "https://arxiv.org/abs/2602.11669", "authors": ["Haoyu Huang", "Yoichi Sato"], "title": "Egocentric Gaze Estimation via Neck-Mounted Camera", "categories": ["cs.CV"], "comment": null, "summary": "This paper introduces neck-mounted view gaze estimation, a new task that estimates user gaze from the neck-mounted camera perspective. Prior work on egocentric gaze estimation, which predicts device wearer's gaze location within the camera's field of view, mainly focuses on head-mounted cameras while alternative viewpoints remain underexplored. To bridge this gap, we collect the first dataset for this task, consisting of approximately 4 hours of video collected from 8 participants during everyday activities. We evaluate a transformer-based gaze estimation model, GLC, on the new dataset and propose two extensions: an auxiliary gaze out-of-bound classification task and a multi-view co-learning approach that jointly trains head-view and neck-view models using a geometry-aware auxiliary loss. Experimental results show that incorporating gaze out-of-bound classification improves performance over standard fine-tuning, while the co-learning approach does not yield gains. We further analyze these results and discuss implications for neck-mounted gaze estimation.", "AI": {"tldr": "通过颈部安装的摄像机视角估计用户的视线。", "motivation": "现有研究主要关注于头部安装摄像头的自我中心视线估计，而其他视角的研究较少。此研究旨在填补这一空白，探索从颈部安装相机收集数据并进行视线估计的新方法。", "method": "提出了一个基于转换器的视线估计模型GLC，并在新收集的数据集上进行了评估。还引入了辅助任务——视线是否超出边界分类以及多视图协同学习的方法。", "result": "实验表明，加入视线是否超出边界的分类可以提升性能；而多视图协同学习方法并未带来显著增益。", "conclusion": "该研究填补了颈部安装摄像机视角的自我中心视线估计领域的空白，并展示了新的数据集和模型的有效性。"}}
{"id": "2602.11666", "pdf": "https://arxiv.org/pdf/2602.11666", "abs": "https://arxiv.org/abs/2602.11666", "authors": ["E Fan", "Lisong Shi", "Zhengtong Li", "Chih-yung Wen"], "title": "PhyNiKCE: A Neurosymbolic Agentic Framework for Autonomous Computational Fluid Dynamics", "categories": ["cs.AI", "cs.CL"], "comment": "30 pages, 10 figures", "summary": "The deployment of autonomous agents for Computational Fluid Dynamics (CFD), is critically limited by the probabilistic nature of Large Language Models (LLMs), which struggle to enforce the strict conservation laws and numerical stability required for physics-based simulations. Reliance on purely semantic Retrieval Augmented Generation (RAG) often leads to \"context poisoning,\" where agents generate linguistically plausible but physically invalid configurations due to a fundamental Semantic-Physical Disconnect. To bridge this gap, this work introduces PhyNiKCE (Physical and Numerical Knowledgeable Context Engineering), a neurosymbolic agentic framework for trustworthy engineering. Unlike standard black-box agents, PhyNiKCE decouples neural planning from symbolic validation. It employs a Symbolic Knowledge Engine that treats simulation setup as a Constraint Satisfaction Problem, rigidly enforcing physical constraints via a Deterministic RAG Engine with specialized retrieval strategies for solvers, turbulence models, and boundary conditions. Validated through rigorous OpenFOAM experiments on practical, non-tutorial CFD tasks using Gemini-2.5-Pro/Flash, PhyNiKCE demonstrates a 96% relative improvement over state-of-the-art baselines. Furthermore, by replacing trial-and-error with knowledge-driven initialization, the framework reduced autonomous self-correction loops by 59% while simultaneously lowering LLM token consumption by 17%. These results demonstrate that decoupling neural generation from symbolic constraint enforcement significantly enhances robustness and efficiency. While validated on CFD, this architecture offers a scalable, auditable paradigm for Trustworthy Artificial Intelligence in broader industrial automation.", "AI": {"tldr": "本文介绍了一种名为PhyNiKCE的神经符号代理框架，用于计算流体动力学（CFD）中的自主代理。", "motivation": "大型语言模型在执行物理约束和数值稳定性时存在局限性，导致生成的结果可能具有语言上的合理性但不符合物理学要求。为解决这一问题，本文提出了一种新的方法来增强代理的可靠性和效率。", "method": "PhyNiKCE通过神经规划与符号验证的分离实现任务。使用一个符号知识引擎将模拟设置视为约束满足问题，并利用确定性的RAG引擎进行专业检索策略以执行求解器、湍流模型和边界条件，从而严格地执行物理约束。", "result": "实验表明，相较于最先进的基准线，PhyNiKCE在实际而非教程CFD任务上实现了96%的相对改进。同时，它通过知识驱动的初始化减少了自主校正循环59%，并降低了大型语言模型的标记消耗17%。", "conclusion": "该框架验证了将神经生成与符号约束执行分离能显著提高可靠性和效率，并为更广泛工业自动化中的可信赖人工智能提供了一个可扩展、可审计的方法。"}}
{"id": "2602.11663", "pdf": "https://arxiv.org/pdf/2602.11663", "abs": "https://arxiv.org/abs/2602.11663", "authors": ["Yifan Zhao", "Yuxin Fang", "Yihuan Chen", "RAY LC"], "title": "\"I Was Told to Come Back and Share This\": Social Media-Based Near-Death Experience Disclosures as Expressions of Spiritual Beliefs", "categories": ["cs.HC"], "comment": "19 pages, 5 figures, CHI 2026 full paper", "summary": "People who experienced near-death events often turn to personal expression as a way of processing trauma and articulating beliefs. While scholars have examined how individuals share near-death experiences (NDEs), limited research has explored how these narratives are communicated collaboratively on today's social media platforms. We analyzed 200 randomly sampled TikTok videos tagged with #nde and related hashtags. Content analysis revealed that individuals often use NDE narratives to articulate personal meaning, with spiritual and religious themes appearing in the majority of posts and serving as a means of exploring and making sense of personal spiritual perspectives. Consistent with this, analyses of comment sections reveal that videos containing spiritual themes tend to attract more engagement and foster deeper conversations around faith and meaning. Our findings offer insights into how online platforms facilitate community-level engagement with spirituality, and suggest implications for design of spaces that support shared expression and connection in specialized communities.", "AI": {"tldr": "通过分析带有#nde标签的200个随机样本TikTok视频，研究了人们如何利用社交媒体平台分享濒死经历，并探讨这些叙述中的精神和宗教主题。", "motivation": "尽管学者们已经研究过个体如何分享他们的濒死体验（NDE），但关于在当今社交媒体平台上进行这种叙述的协作沟通的研究相对较少。本论文旨在填补这一空白，探讨在线社区中精神层面互动的方式以及意义建构的过程。", "method": "选取带有#nde标签和相关主题标签的200个随机样本TikTok视频进行了内容分析，并进一步研究了评论区中的互动情况。", "result": "大多数帖子都包含了精神或宗教的主题，这表明濒死经历者利用这些叙述来表达个人的意义。同时发现，含有关于精神信仰主题的视频通常会吸引更多的参与度并促进关于信仰和意义更深层次的讨论。", "conclusion": "研究结果揭示了在线平台如何促进群体层面对精神层面的互动，并为设计支持特定社区中共享表达和联系的空间提供了启示。"}}
{"id": "2602.11661", "pdf": "https://arxiv.org/pdf/2602.11661", "abs": "https://arxiv.org/abs/2602.11661", "authors": ["Tianxiang Xu", "Jiayi Liu", "Yixuan Tong", "Jialu Xu", "Yunqing Wei", "Kaiwen Feng", "PanPan Hou", "Kangping Yin", "Jiyuan Hu", "Hao Zhou", "Zhenxin Ma", "Jian Xu", "Guanjun Jiang"], "title": "Quark Medical Alignment: A Holistic Multi-Dimensional Alignment and Collaborative Optimization Paradigm", "categories": ["cs.AI"], "comment": null, "summary": "While reinforcement learning for large language model alignment has progressed rapidly in recent years, transferring these paradigms to high-stakes medical question answering reveals a fundamental paradigm mismatch. Reinforcement Learning from Human Feedback relies on preference annotations that are prohibitively expensive and often fail to reflect the absolute correctness of medical facts. Reinforcement Learning from Verifiable Rewards lacks effective automatic verifiers and struggles to handle complex clinical contexts. Meanwhile, medical alignment requires the simultaneous optimization of correctness, safety, and compliance, yet multi-objective heterogeneous reward signals are prone to scale mismatch and optimization conflicts.To address these challenges, we propose a robust medical alignment paradigm. We first construct a holistic multi-dimensional medical alignment matrix that decomposes alignment objectives into four categories: fundamental capabilities, expert knowledge, online feedback, and format specifications. Within each category, we establish a closed loop of where observable metrics inform attributable diagnosis, which in turn drives optimizable rewards, thereby providing fine-grained, high-resolution supervision signals for subsequent iterative optimization. To resolve gradient domination and optimization instability problem caused by heterogeneous signals, we further propose a unified optimization mechanism. This mechanism employs Reference-Frozen Normalization to align reward scales and implements a Tri-Factor Adaptive Dynamic Weighting strategy to achieve collaborative optimization that is weakness-oriented, risk-prioritized, and redundancy-reducing. Experimental results demonstrate the effectiveness of our proposed paradigm in real-world medical scenario evaluations, establishing a new paradigm for complex alignment in vertical domains.", "AI": {"tldr": "该论文提出了一种针对医疗问答的强化学习对齐新范式，旨在解决现有方法在准确性、安全性和合规性等方面的不足。", "motivation": "现有的基于人类反馈和可验证奖励的强化学习方法难以应对复杂的临床情境，无法有效优化多目标异构信号导致的问题。", "method": "论文构建了全方位多维度医学对齐矩阵，并提出了一种统一优化机制以解决不同信号间的梯度支配及优化不稳定问题。", "result": "实验结果验证了所提范式在真实医疗场景评估中的有效性，确立了复杂领域对齐的新标准。", "conclusion": "论文提出的综合多维度医学对齐矩阵和协同优化方法有效解决了现有强化学习算法在高风险医疗问答应用中的局限性。"}}
{"id": "2602.11660", "pdf": "https://arxiv.org/pdf/2602.11660", "abs": "https://arxiv.org/abs/2602.11660", "authors": ["Jeongho Noh", "Tai Hyoung Rhee", "Eunho Lee", "Jeongyun Kim", "Sunwoo Lee", "Ayoung Kim"], "title": "Clutt3R-Seg: Sparse-view 3D Instance Segmentation for Language-grounded Grasping in Cluttered Scenes", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted to ICRA 2026. 9 pages, 8 figures", "summary": "Reliable 3D instance segmentation is fundamental to language-grounded robotic manipulation. Its critical application lies in cluttered environments, where occlusions, limited viewpoints, and noisy masks degrade perception. To address these challenges, we present Clutt3R-Seg, a zero-shot pipeline for robust 3D instance segmentation for language-grounded grasping in cluttered scenes. Our key idea is to introduce a hierarchical instance tree of semantic cues. Unlike prior approaches that attempt to refine noisy masks, our method leverages them as informative cues: through cross-view grouping and conditional substitution, the tree suppresses over- and under-segmentation, yielding view-consistent masks and robust 3D instances. Each instance is enriched with open-vocabulary semantic embeddings, enabling accurate target selection from natural language instructions. To handle scene changes during multi-stage tasks, we further introduce a consistency-aware update that preserves instance correspondences from only a single post-interaction image, allowing efficient adaptation without rescanning. Clutt3R-Seg is evaluated on both synthetic and real-world datasets, and validated on a real robot. Across all settings, it consistently outperforms state-of-the-art baselines in cluttered and sparse-view scenarios. Even on the most challenging heavy-clutter sequences, Clutt3R-Seg achieves an AP@25 of 61.66, over 2.2x higher than baselines, and with only four input views it surpasses MaskClustering with eight views by more than 2x. The code is available at: https://github.com/jeonghonoh/clutt3r-seg.", "AI": {"tldr": "本文提出了Clutt3R-Seg，一种针对语言引导抓取的稠密场景下鲁棒性三维实例分割的零样本管道。", "motivation": "可靠的3D实例分割对于基于语言的机器人操纵至关重要。在有遮挡、有限视图和噪声掩膜的情况下，现有方法难以应对这些挑战。因此，作者提出了一种新的方法来解决这些问题。", "method": "Clutt3R-Seg通过引入一个层次化的语义线索实例树，并利用交叉视图分组和条件替代来抑制过度分割和欠分割，生成一致的掩膜和鲁棒的3D实例。每个实例都使用开放词汇语义嵌入丰富，使其能够从自然语言指令中准确选择目标。", "result": "在合成数据集和真实世界数据集上，Clutt3R-Seg始终优于基线方法，在稠密视图场景下表现尤为突出。特别是在最困难的重遮挡序列中，其AP@25达到了61.66，比基线高出超过2.2倍。", "conclusion": "本文提出的Clutt3R-Seg在语言引导抓取任务中的三维实例分割上展现了优越性能，并且能够在多阶段任务中通过简单的单后交互图像更新来保持实例对应关系。"}}
{"id": "2602.11658", "pdf": "https://arxiv.org/pdf/2602.11658", "abs": "https://arxiv.org/abs/2602.11658", "authors": ["Bingyuan Wang", "Xingbei Chen", "Zongyang Qiu", "Linping Yuan", "Zeyu Wang"], "title": "EmoSpace: Fine-Grained Emotion Prototype Learning for Immersive Affective Content Generation", "categories": ["cs.CV"], "comment": null, "summary": "Emotion is important for creating compelling virtual reality (VR) content. Although some generative methods have been applied to lower the barrier to creating emotionally rich content, they fail to capture the nuanced emotional semantics and the fine-grained control essential for immersive experiences. To address these limitations, we introduce EmoSpace, a novel framework for emotion-aware content generation that learns dynamic, interpretable emotion prototypes through vision-language alignment. We employ a hierarchical emotion representation with rich learnable prototypes that evolve during training, enabling fine-grained emotional control without requiring explicit emotion labels. We develop a controllable generation pipeline featuring multi-prototype guidance, temporal blending, and attention reweighting that supports diverse applications, including emotional image outpainting, stylized generation, and emotional panorama generation for VR environments. Our experiments demonstrate the superior performance of EmoSpace over existing methods in both qualitative and quantitative evaluations. Additionally, we present a comprehensive user study investigating how VR environments affect emotional perception compared to desktop settings. Our work facilitates immersive visual content generation with fine-grained emotion control and supports applications like therapy, education, storytelling, artistic creation, and cultural preservation. Code and models will be made publicly available.", "AI": {"tldr": "EmoSpace是一个用于情感感知内容生成的新型框架，通过视觉语言对齐学习动态、可解释的情感原型。", "motivation": "现有的生成方法难以捕捉细腻的情感语义和沉浸式体验所需的精细控制。为了解决这些问题，作者提出了一种能够进行细粒度情绪控制的新框架EmoSpace。", "method": "该框架采用分层情感表示法，并在训练过程中使用丰富的可学习原型来进化，实现了无需显式情感标签的精细化情绪控制。同时开发了一个可控生成管线，支持诸如情感图像扩展、风格化生成和VR环境的情感全景图生成等多种应用。", "result": "实验结果表明EmoSpace框架超越了现有方法，并且通过全面的用户研究展示了在虚拟现实环境中与桌面设置相比影响情感感知的方式。", "conclusion": "该工作促进了具有细粒度情绪控制能力的沉浸式视觉内容生成，支持诸如治疗、教育、讲故事、艺术创作和文化保护等应用场景。"}}
{"id": "2602.11656", "pdf": "https://arxiv.org/pdf/2602.11656", "abs": "https://arxiv.org/abs/2602.11656", "authors": ["Seo Hyun Kim", "Jin Bok Park", "Do Yeon Koo", "Ho Gun Park", "Il Yong Chun"], "title": "SToRM: Supervised Token Reduction for Multi-modal LLMs toward efficient end-to-end autonomous driving", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "In autonomous driving, end-to-end (E2E) driving systems that predict control commands directly from sensor data have achieved significant advancements. For safe driving in unexpected scenarios, these systems may additionally rely on human interventions such as natural language instructions. Using a multi-modal large language model (MLLM) facilitates human-vehicle interaction and can improve performance in such scenarios. However, this approach requires substantial computational resources due to its reliance on an LLM and numerous visual tokens from sensor inputs, which are limited in autonomous vehicles. Many MLLM studies have explored reducing visual tokens, but often suffer end-task performance degradation compared to using all tokens. To enable efficient E2E driving while maintaining performance comparable to using all tokens, this paper proposes the first Supervised Token Reduction framework for multi-modal LLMs (SToRM). The proposed framework consists of three key elements. First, a lightweight importance predictor with short-term sliding windows estimates token importance scores. Second, a supervised training approach uses an auxiliary path to obtain pseudo-supervision signals from an all-token LLM pass. Third, an anchor-context merging module partitions tokens into anchors and context tokens, and merges context tokens into relevant anchors to reduce redundancy while minimizing information loss. Experiments on the LangAuto benchmark show that SToRM outperforms state-of-the-art E2E driving MLLMs under the same reduced-token budget, maintaining all-token performance while reducing computational cost by up to 30x.", "AI": {"tldr": "提出了一种名为SToRM的监督令牌减少框架，旨在通过减少多模态LLM中的视觉令牌数量来提高端到端自动驾驶系统的效率。", "motivation": "为了在不牺牲性能的情况下降低计算成本，解决多模态大语言模型在自动驾驶中所需的大量计算资源问题。", "method": "该方法包含三个关键元素：轻量级的重要性预测器、监督训练方法和锚点-上下文合并模块。", "result": "实验表明，在相同的减少令牌预算下，SToRM比现有最好的端到端驾驶多模态LLM性能更优，并且可以将计算成本降低最多30倍。", "conclusion": "所提出的监督令牌减少框架（SToRM）在保持全令牌性能的同时显著降低了自动驾驶系统的计算成本。"}}
{"id": "2602.11655", "pdf": "https://arxiv.org/pdf/2602.11655", "abs": "https://arxiv.org/abs/2602.11655", "authors": ["Christian Rondanini", "Barbara Carminati", "Elena Ferrari", "Niccolò Lardo", "Ashish Kundu"], "title": "LoRA-based Parameter-Efficient LLMs for Continuous Learning in Edge-based Malware Detection", "categories": ["cs.CR", "cs.AI", "cs.DC"], "comment": null, "summary": "The proliferation of edge devices has created an urgent need for security solutions capable of detecting malware in real time while operating under strict computational and memory constraints. Recently, Large Language Models (LLMs) have demonstrated remarkable capabilities in recognizing complex patterns, yet their deployment on edge devices remains impractical due to their resource demands. However, in edge malware detection, static or centrally retrained models degrade under evolving threats and heterogeneous traffic; locally trained models become siloed and fail to transfer across domains. To overcome these limitations, in this paper, we present a continuous learning architecture for edge-based malware detection that combines local adaptation on each device with global knowledge sharing through parameter-efficient LoRA adapters. Lightweight transformer models (DistilBERT, DistilGPT-2, TinyT5) run on edge nodes and are incrementally fine-tuned on device-specific traffic; only the resulting LoRA modules are aggregated by a lightweight coordinator and redistributed, enabling cross-device generalization without exchanging raw data. We evaluate on two public IoT security datasets, Edge-IIoTset and TON-IoT, under multi-round learning to simulate evolving threats. Compared to isolated fine-tuning, the LoRA-based exchange yields up to 20-25% accuracy gains when models encounter previously unseen attacks from another domain, while maintaining stable loss and F1 across rounds. LoRA adds less than 1% to model size (~0.6-1.8 MB), making updates practical for constrained edge hardware.", "AI": {"tldr": "本文提出了一种结合局部适应和全局知识共享的边缘设备恶意软件检测连续学习架构，采用轻量级LoRA适配器以克服资源限制。", "motivation": "在边缘设备上实时检测恶意软件的需求日益迫切，但大型语言模型因资源需求高而难以部署。静态或集中重训练模型无法适应不断变化的安全威胁，本地训练模型缺乏跨域泛化能力。", "method": "使用轻量级Transformer模型（如DistilBERT、DistilGPT-2和TinyT5）在边缘节点上针对特定流量进行增量微调，并通过LoRA模块的聚合与分发实现知识共享。", "result": "实验结果显示，相较于孤立微调方法，基于LoRA的知识交换可使模型面对未见过攻击时准确率提高20-25%，同时保持稳定的损失和F1分数。", "conclusion": "提出的连续学习架构在资源受限的边缘设备上实现了有效的恶意软件检测，具备良好的泛化能力和稳定性。"}}
{"id": "2602.11653", "pdf": "https://arxiv.org/pdf/2602.11653", "abs": "https://arxiv.org/abs/2602.11653", "authors": ["Mengxiao Geng", "Zijie Chen", "Ran Hong", "Bingxuan Li", "Qiegen Liu"], "title": "GR-Diffusion: 3D Gaussian Representation Meets Diffusion in Whole-Body PET Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Positron emission tomography (PET) reconstruction is a critical challenge in molecular imaging, often hampered by noise amplification, structural blurring, and detail loss due to sparse sampling and the ill-posed nature of inverse problems. The three-dimensional discrete Gaussian representation (GR), which efficiently encodes 3D scenes using parameterized discrete Gaussian distributions, has shown promise in computer vision. In this work, we pro-pose a novel GR-Diffusion framework that synergistically integrates the geometric priors of GR with the generative power of diffusion models for 3D low-dose whole-body PET reconstruction. GR-Diffusion employs GR to generate a reference 3D PET image from projection data, establishing a physically grounded and structurally explicit benchmark that overcomes the low-pass limitations of conventional point-based or voxel-based methods. This reference image serves as a dual guide during the diffusion process, ensuring both global consistency and local accuracy. Specifically, we employ a hierarchical guidance mechanism based on the GR reference. Fine-grained guidance leverages differences to refine local details, while coarse-grained guidance uses multi-scale difference maps to correct deviations. This strategy allows the diffusion model to sequentially integrate the strong geometric prior from GR and recover sub-voxel information. Experimental results on the UDPET and Clinical datasets with varying dose levels show that GR-Diffusion outperforms state-of-the-art methods in enhancing 3D whole-body PET image quality and preserving physiological details.", "AI": {"tldr": "本文提出了GR-Diffusion框架，结合三维高斯表示与扩散模型以改进低剂量全身PET重建。", "motivation": "解决传统方法在稀疏采样和逆问题病态下导致的噪声放大、结构模糊及细节丢失问题", "method": "通过三级引导机制使用GR生成参考图像，利用几何先验指导扩散过程以恢复亚体素信息", "result": "实验结果表明，在不同剂量水平上，GR-Diffusion优于现有方法，提高了3D全身PET图像质量和生理细节的保存", "conclusion": "GR-Diffusion框架通过结合三维高斯表示和扩散模型显著提升了低剂量全身PET重建的效果"}}
{"id": "2602.11651", "pdf": "https://arxiv.org/pdf/2602.11651", "abs": "https://arxiv.org/abs/2602.11651", "authors": ["Enhao Huang", "Frank Li", "Tony Lin", "Lowes Yang"], "title": "DMind-3: A Sovereign Edge--Local--Cloud AI System with Controlled Deliberation and Correction-Based Tuning for Safe, Low-Latency Transaction Execution", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "This paper introduces DMind-3, a sovereign Edge-Local-Cloud intelligence stack designed to secure irreversible financial execution in Web3 environments against adversarial risks and strict latency constraints. While existing cloud-centric assistants compromise privacy and fail under network congestion, and purely local solutions lack global ecosystem context, DMind-3 resolves these tensions by decomposing capability into three cooperating layers: a deterministic signing-time intent firewall at the edge, a private high-fidelity reasoning engine on user hardware, and a policy-governed global context synthesizer in the cloud. We propose policy-driven selective offloading to route computation based on privacy sensitivity and uncertainty, supported by two novel training objectives: Hierarchical Predictive Synthesis (HPS) for fusing time-varying macro signals, and Contrastive Chain-of-Correction Supervised Fine-Tuning (C$^3$-SFT) to enhance local verification reliability. Extensive evaluations demonstrate that DMind-3 achieves a 93.7% multi-turn success rate in protocol-constrained tasks and superior domain reasoning compared to general-purpose baselines, providing a scalable framework where safety is bound to the edge execution primitive while maintaining sovereignty over sensitive user intent.", "AI": {"tldr": "DMind-3是一个主权边缘-本地-云端AI系统，旨在通过控制性审慎和基于修正的调优实现安全、低延迟交易执行。", "motivation": "现有的云中心化助手在隐私保护上有所欠缺且在网络拥塞时表现不佳；而纯粹的本地解决方案则缺乏全局生态系统的上下文信息。DMind-3的设计目的是解决这些矛盾，同时保障不可逆金融行为的安全性。", "method": "DMind-3通过分解能力为三个协作层来实现其目标：边缘上的确定签名时间意图防火墙、用户设备上的私密高保真推理引擎以及云端的政策治理全局上下文综合器。系统提出了基于策略驱动的选择卸载，根据隐私敏感度和不确定性进行计算路由，并引入了Hierarchical Predictive Synthesis (HPS)和Contrastive Chain-of-Correction Supervised Fine-Tuning (C$^3$-SFT)两种新的训练目标。", "result": "DMind-3在协议约束任务中实现了93.7%的多轮成功率，并且其领域推理能力优于通用基线系统，从而提供了一个安全绑定于边缘执行原语的同时保持对敏感用户意图主权的可扩展框架。", "conclusion": "通过将能力分解为三个协作层并引入新颖的训练目标，DMind-3解决了现有技术在隐私保护、网络拥塞和全局上下文方面的不足，并提供了高效的解决方案来满足Web3环境中安全、低延迟交易执行的需求。"}}
{"id": "2602.11648", "pdf": "https://arxiv.org/pdf/2602.11648", "abs": "https://arxiv.org/abs/2602.11648", "authors": ["Faezeh Vahedi", "Morteza Memari", "Ramtin Tabatabaei", "Alireza Taheri"], "title": "Human-Like Gaze Behavior in Social Robots: A Deep Learning Approach Integrating Human and Non-Human Stimuli", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "Nonverbal behaviors, particularly gaze direction, play a crucial role in enhancing effective communication in social interactions. As social robots increasingly participate in these interactions, they must adapt their gaze based on human activities and remain receptive to all cues, whether human-generated or not, to ensure seamless and effective communication. This study aims to increase the similarity between robot and human gaze behavior across various social situations, including both human and non-human stimuli (e.g., conversations, pointing, door openings, and object drops). A key innovation in this study, is the investigation of gaze responses to non-human stimuli, a critical yet underexplored area in prior research. These scenarios, were simulated in the Unity software as a 3D animation and a 360-degree real-world video. Data on gaze directions from 41 participants were collected via virtual reality (VR) glasses. Preprocessed data, trained two neural networks-LSTM and Transformer-to build predictive models based on individuals' gaze patterns. In the animated scenario, the LSTM and Transformer models achieved prediction accuracies of 67.6% and 70.4%, respectively; In the real-world scenario, the LSTM and Transformer models achieved accuracies of 72% and 71.6%, respectively. Despite the gaze pattern differences among individuals, our models outperform existing approaches in accuracy while uniquely considering non-human stimuli, offering a significant advantage over previous literature. Furthermore, deployed on the NAO robot, the system was evaluated by 275 participants via a comprehensive questionnaire, with results demonstrating high satisfaction during interactions. This work advances social robotics by enabling robots to dynamically mimic human gaze behavior in complex social contexts.", "AI": {"tldr": "本文提出了一种深度学习方法，用于提高社交机器人在多种情境下模仿人类注视行为的准确性，包括人机互动和非人工刺激。", "motivation": "增强社交机器人的沟通效果，使它们能够更好地适应不同的社会情景，并对所有类型的刺激（无论是由人类产生的还是非人为的）做出响应。", "method": "使用Unity软件生成3D动画和360度真实世界视频模拟场景。利用VR眼镜收集41名参与者在不同情况下的注视数据。通过LSTM和Transformer两种神经网络训练模型，基于个体的注视模式进行预测。", "result": "在仿真场景中，LSTM模型预测准确率为67.6%，Transformer为70.4%；现实世界场景中，LSTM模型预测准确率为72%，Transformer为71.6%。通过问卷调查评估表明，在与NAO机器人的互动中参与者高度满意。", "conclusion": "该研究展示了如何利用深度学习方法使社交机器人在复杂社会环境中模仿人类注视行为，并在考虑非人为刺激的情况下提高了模型的准确性，从而增强了人机交互的质量。"}}
{"id": "2602.11646", "pdf": "https://arxiv.org/pdf/2602.11646", "abs": "https://arxiv.org/abs/2602.11646", "authors": ["Ryan Deem", "Garrett Goodman", "Waqas Majeed", "Md Abdullah Al Hafiz Khan", "Michail S. Alexiou"], "title": "Brain Tumor Classifiers Under Attack: Robustness of ResNet Variants Against Transferable FGSM and PGD Attacks", "categories": ["cs.CV", "cs.AI"], "comment": "ef:IEEE 25th International Conference on Bioinformatics and Bioengineering (BIBE) Athens Greece 2025 pp. 420-428", "summary": "Adversarial robustness in deep learning models for brain tumor classification remains an underexplored yet critical challenge, particularly for clinical deployment scenarios involving MRI data. In this work, we investigate the susceptibility and resilience of several ResNet-based architectures, referred to as BrainNet, BrainNeXt and DilationNet, against gradient-based adversarial attacks, namely FGSM and PGD. These models, based on ResNet, ResNeXt, and dilated ResNet variants respectively, are evaluated across three preprocessing configurations (i) full-sized augmented, (ii) shrunk augmented and (iii) shrunk non-augmented MRI datasets. Our experiments reveal that BrainNeXt models exhibit the highest robustness to black-box attacks, likely due to their increased cardinality, though they produce weaker transferable adversarial samples. In contrast, BrainNet and Dilation models are more vulnerable to attacks from each other, especially under PGD with higher iteration steps and $α$ values. Notably, shrunk and non-augmented data significantly reduce model resilience, even when the untampered test accuracy remains high, highlighting a key trade-off between input resolution and adversarial vulnerability. These results underscore the importance of jointly evaluating classification performance and adversarial robustness for reliable real-world deployment in brain MRI analysis.", "AI": {"tldr": "研究了不同ResNet变体在脑肿瘤分类中的对抗鲁棒性，评估了FGSM和PGD攻击下的模型表现。", "motivation": "探讨深度学习模型在医学影像分析中的抗干扰能力，特别是面对MRI数据的对抗样本时的表现。", "method": "基于ResNet、ResNeXt及膨胀型ResNet变体构建BrainNet、BrainNeXt和DilationNet模型；评估三种预处理配置下的FGSM和PGD攻击效果。", "result": "发现BrainNeXt模型在黑盒攻击中表现最佳，但生成的对抗样本转移性较低；输入分辨率降低会显著影响模型的抗干扰能力。", "conclusion": "强调同时评估分类性能与对抗鲁棒性的重要性，以确保真实场景下的可靠性。"}}
{"id": "2602.11643", "pdf": "https://arxiv.org/pdf/2602.11643", "abs": "https://arxiv.org/abs/2602.11643", "authors": ["Yufeng Tian", "Shuiqi Cheng", "Tianming Wei", "Tianxing Zhou", "Yuanhang Zhang", "Zixian Liu", "Qianwei Han", "Zhecheng Yuan", "Huazhe Xu"], "title": "ViTaS: Visual Tactile Soft Fusion Contrastive Learning for Visuomotor Learning", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Published to ICRA 2026", "summary": "Tactile information plays a crucial role in human manipulation tasks and has recently garnered increasing attention in robotic manipulation. However, existing approaches mostly focus on the alignment of visual and tactile features and the integration mechanism tends to be direct concatenation. Consequently, they struggle to effectively cope with occluded scenarios due to neglecting the inherent complementary nature of both modalities and the alignment may not be exploited enough, limiting the potential of their real-world deployment. In this paper, we present ViTaS, a simple yet effective framework that incorporates both visual and tactile information to guide the behavior of an agent. We introduce Soft Fusion Contrastive Learning, an advanced version of conventional contrastive learning method and a CVAE module to utilize the alignment and complementarity within visuo-tactile representations. We demonstrate the effectiveness of our method in 12 simulated and 3 real-world environments, and our experiments show that ViTaS significantly outperforms existing baselines. Project page: https://skyrainwind.github.io/ViTaS/index.html.", "AI": {"tldr": "本文提出了ViTaS框架，通过视觉和触觉信息的融合对比学习来指导代理行为，在模拟和现实环境中均显著优于现有基线。", "motivation": "现有的方法主要关注视觉与触觉特征对齐，并且直接拼接导致在遮挡情况下处理效果不佳，忽视了两种模态间的互补性。这限制了其在实际部署中的潜力。", "method": "本文引入了软融合对比学习和CVAE模块来利用视触表示的对齐性和互补性，形成ViTaS框架，以指导代理行为。", "result": "实验表明，ViTaS在12个模拟环境和3个真实世界环境中均显著优于现有基线。", "conclusion": "通过视觉与触觉信息的有效融合，ViTaS能够更好地处理遮挡情况，并提高实际部署中的性能。"}}
{"id": "2602.11642", "pdf": "https://arxiv.org/pdf/2602.11642", "abs": "https://arxiv.org/abs/2602.11642", "authors": ["Diego Patiño", "Knut Peterson", "Kostas Daniilidis", "David K. Han"], "title": "Electrostatics-Inspired Surface Reconstruction (EISR): Recovering 3D Shapes as a Superposition of Poisson's PDE Solutions", "categories": ["cs.CV"], "comment": null, "summary": "Implicit shape representation, such as SDFs, is a popular approach to recover the surface of a 3D shape as the level sets of a scalar field. Several methods approximate SDFs using machine learning strategies that exploit the knowledge that SDFs are solutions of the Eikonal partial differential equation (PDEs). In this work, we present a novel approach to surface reconstruction by encoding it as a solution to a proxy PDE, namely Poisson's equation. Then, we explore the connection between Poisson's equation and physics, e.g., the electrostatic potential due to a positive charge density. We employ Green's functions to obtain a closed-form parametric expression for the PDE's solution, and leverage the linearity of our proxy PDE to find the target shape's implicit field as a superposition of solutions. Our method shows improved results in approximating high-frequency details, even with a small number of shape priors.", "AI": {"tldr": "本文提出了一种基于泊松方程的隐式场重建方法，通过电势和格林函数来逼近高频率细节。", "motivation": "利用机器学习策略可以有效地近似SDF，并且这些方法通常会考虑到SDF是Eikonal偏微分方程的解。本文旨在探索使用泊松方程作为代理PDE的方法，以更好地恢复3D形状的高频细节。", "method": "将表面重建问题转化为求解泊松方程的线性组合，并利用格林函数获得闭式解析表达式来逼近目标形状的隐式场。", "result": "该方法能够在使用少量先验形状的情况下较好地近似高频细节，提高了3D形状恢复的效果。", "conclusion": "通过采用电势和泊松方程作为代理PDE的方法可以有效地恢复高频率的三维形状细节。"}}
{"id": "2602.11638", "pdf": "https://arxiv.org/pdf/2602.11638", "abs": "https://arxiv.org/abs/2602.11638", "authors": ["Hao Qin", "Yukai Sun", "Meng Wang", "Ming Kong", "Mengxu Lu", "Qiang Zhu"], "title": "Variation-aware Flexible 3D Gaussian Editing", "categories": ["cs.GR", "cs.AI"], "comment": null, "summary": "Indirect editing methods for 3D Gaussian Splatting (3DGS) have recently witnessed significant advancements. These approaches operate by first applying edits in the rendered 2D space and subsequently projecting the modifications back into 3D. However, this paradigm inevitably introduces cross-view inconsistencies and constrains both the flexibility and efficiency of the editing process. To address these challenges, we present VF-Editor, which enables native editing of Gaussian primitives by predicting attribute variations in a feedforward manner. To accurately and efficiently estimate these variations, we design a novel variation predictor distilled from 2D editing knowledge. The predictor encodes the input to generate a variation field and employs two learnable, parallel decoding functions to iteratively infer attribute changes for each 3D Gaussian. Thanks to its unified design, VF-Editor can seamlessly distill editing knowledge from diverse 2D editors and strategies into a single predictor, allowing for flexible and effective knowledge transfer into the 3D domain. Extensive experiments on both public and private datasets reveal the inherent limitations of indirect editing pipelines and validate the effectiveness and flexibility of our approach.", "AI": {"tldr": "介绍了一种名为VF-Editor的直接编辑方法，用于在3D高斯点云上进行灵活有效的属性修改。", "motivation": "间接编辑方法存在跨视角不一致性和灵活性限制的问题，需要一种更高效和准确的方法来解决这些问题。", "method": "设计了一个新的预测器通过前向传递方式预测三维高斯的属性变化，并从2D编辑知识中提取有效信息转移到3D空间进行灵活的知识迁移。", "result": "实验表明，与间接编辑方法相比，该直接编辑方法可以更有效地减少跨视角不一致性并提高编辑效率和灵活性。", "conclusion": "VF-Editor提供了一种新的方式来解决现有的三维高斯点云编辑中的挑战，并展示了在多个数据集上的优越性能。"}}
{"id": "2602.11636", "pdf": "https://arxiv.org/pdf/2602.11636", "abs": "https://arxiv.org/abs/2602.11636", "authors": ["Changti Wu", "Jiahuai Mao", "Yuzhuo Miao", "Shijie Lian", "Bin Yu", "Xiaopeng Lin", "Cong Huang", "Lei Zhang", "Kai Chen"], "title": "ScalSelect: Scalable Training-Free Multimodal Data Selection for Efficient Visual Instruction Tuning", "categories": ["cs.CV", "cs.AI"], "comment": "The code is available at \\href{https://github.com/ChangtiWu/ScalSelect}{ScalSelect}", "summary": "Large-scale Visual Instruction Tuning (VIT) has become a key paradigm for advancing the performance of vision-language models (VLMs) across various multimodal tasks. However, training on the large-scale datasets is computationally expensive and inefficient due to redundancy in the data, which motivates the need for multimodal data selection to improve training efficiency. Existing data selection methods for VIT either require costly training or gradient computation. Training-free alternatives often depend on proxy models or datasets, instruction-agnostic representations, and pairwise similarity with quadratic complexity, limiting scalability and representation fidelity. In this work, we propose ScalSelect, a scalable training-free multimodal data selection method with linear-time complexity with respect to the number of samples, eliminating the need for external models or auxiliary datasets. ScalSelect first constructs sample representations by extracting visual features most attended by instruction tokens in the target VLM, capturing instruction-relevant information. It then identifies samples whose representations best approximate the dominant subspace of the full dataset representations, enabling scalable importance scoring without pairwise comparisons. Extensive experiments across multiple VLMs, datasets, and selection budgets demonstrate that ScalSelect achieves over 97.5% of the performance of training on the full dataset using only 16% of the data, and even outperforms full-data training in some settings. The code is available at \\href{https://github.com/ChangtiWu/ScalSelect}{ScalSelect}.", "AI": {"tldr": "ScalSelect是一种可扩展的无训练多模态数据选择方法，用于视觉指令调优。", "motivation": "大规模视觉指令调优在计算上昂贵且低效，因为数据中的冗余导致了效率低下。现有的数据选择方法需要耗费大量资源进行训练或梯度计算，或者依赖代理模型和数据集，这限制了其可扩展性和表示准确性。", "method": "ScalSelect通过提取目标VLM中最关注的视觉特征来构建样本表示，并识别出最佳接近整个数据集主子空间的样本，从而实现无成对比较的重要性评分。这种方法具有线性时间复杂度，消除了对外部模型或辅助数据集的需求。", "result": "实验表明，ScalSelect使用仅16%的数据即可达到全数据训练性能的97.5%以上，在某些场景下甚至优于全数据训练。", "conclusion": "ScalSelect是一种高效且可扩展的多模态数据选择方法，能够显著提高视觉指令调优模型的效率和表现。"}}
{"id": "2602.11635", "pdf": "https://arxiv.org/pdf/2602.11635", "abs": "https://arxiv.org/abs/2602.11635", "authors": ["Shuo Lu", "Jianjie Cheng", "Yinuo Xu", "Yongcan Yu", "Lijun Sheng", "Peijie Wang", "Siru Jiang", "Yongguan Hu", "Run Ling", "Yihua Shao", "Ao Ma", "Wei Feng", "Lingxiao He", "Meng Wang", "Qianlong Xie", "Xingxing Wang", "Ran He", "Jian Liang"], "title": "Do MLLMs Really Understand Space? A Mathematical Reasoning Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) have achieved strong performance on perception-oriented tasks, yet their ability to perform mathematical spatial reasoning, defined as the capacity to parse and manipulate two- and three-dimensional relations, remains unclear. Humans easily solve textbook-style spatial reasoning problems with over 95\\% accuracy, but we find that most leading MLLMs fail to reach even 60\\% on the same tasks. This striking gap highlights spatial reasoning as a fundamental weakness of current models. To investigate this gap, we present MathSpatial, a unified framework for evaluating and improving spatial reasoning in MLLMs. MathSpatial includes three complementary components: (i) MathSpatial-Bench, a benchmark of 2K problems across three categories and eleven subtypes, designed to isolate reasoning difficulty from perceptual noise; (ii) MathSpatial-Corpus, a training dataset of 8K additional problems with verified solutions; and (iii) MathSpatial-SRT, which models reasoning as structured traces composed of three atomic operations--Correlate, Constrain, and Infer. Experiments show that fine-tuning Qwen2.5-VL-7B on MathSpatial achieves competitive accuracy while reducing tokens by 25\\%. MathSpatial provides the first large-scale resource that disentangles perception from reasoning, enabling precise measurement and comprehensive understanding of mathematical spatial reasoning in MLLMs.", "AI": {"tldr": "评估并改进多模态大型语言模型在数学空间推理任务上的能力。", "motivation": "现有模型在感知任务上表现良好，但在解决需要解析和操作二维、三维关系的数学空间推理问题时存在显著缺陷。人类能以高准确率完成这些任务，而多数领先模型的表现却远低于此标准。", "method": "提出MathSpatial框架，包括MathSpatial-Bench测试基准、MathSpatial-Corpus训练数据集以及用于建模推理过程的MathSpatial-SRT。", "result": "在MathSpatial框架下微调Qwen2.5-VL-7B模型后，在空间推理任务上的准确性得到了提高，并且减少了25%的令牌使用量。", "conclusion": "通过提出一个能够区分感知与推理的大规模资源，该研究为精确测量和全面理解多模态语言模型在数学空间推理方面的表现提供了可能。"}}
{"id": "2602.11632", "pdf": "https://arxiv.org/pdf/2602.11632", "abs": "https://arxiv.org/abs/2602.11632", "authors": ["David Hogan", "Andrew Doherty", "Boon Kien Khoo", "Johnson Zhou", "Richard Salib", "James Stewart", "Kiaran Lawson", "Alon Loeffler", "Brett Kagan"], "title": "CL API: Real-Time Closed-Loop Interactions with Biological Neural Networks", "categories": ["q-bio.NC", "cs.ET", "cs.NE", "eess.SY"], "comment": null, "summary": "Biological neural networks (BNNs) are increasingly explored for their rich dynamics, parallelism, and adaptive behavior. Beyond understanding their function as a scientific endeavour, a key focus has been using these biological systems as a novel computing substrate. However, BNNs can only function as reliable information-processing systems if inputs are delivered in a temporally and structurally consistent manner. In practice, this requires stimulation with precisely controlled structure, microsecond-scale timing, multi-channel synchronization, and the ability to observe and respond to neural activity in real-time. Existing approaches to interacting with BNNs face a fundamental trade-off: they either depend on low-level hardware mechanisms, imposing prohibitive complexity for rapid iteration, or they sacrifice temporal and structural control, undermining consistency and reproducibility - particularly in closed-loop experiments. The Cortical Labs Application Programming Interface (CL API) enables real-time, sub-millisecond closed-loop interactions with BNNs. Taking a contract-based API design approach, the CL API provides users with precise stimulation semantics, transactional admission, deterministic ordering, and explicit synchronization guarantees. This contract is presented through a declarative Python interface, enabling non-expert programmers to express complex stimulation and closed-loop behavior without managing low-level scheduling or hardware details. Ultimately, the CL API provides an accessible and reproducible foundation for real-time experimentation with BNNs, supporting both fundamental biological research and emerging neurocomputing applications.", "AI": {"tldr": "本文提出了一个实时闭环交互的API，用于生物神经网络（BNNs）的研究和应用。", "motivation": "为了使生物神经网络能够作为可靠的信息处理系统工作，需要对输入进行精确控制。但是现有方法要么过于复杂难以快速迭代，要么缺乏时间结构上的控制。", "method": "通过采用合同式的API设计方法，CL API提供了一个声明式Python接口，使得非专家程序员可以表达复杂的刺激和闭环行为而不必管理底层调度或硬件细节。", "result": "该API能够实现亚毫秒级的实时闭环交互，并为生物神经网络的研究提供了可访问且可重复的基础。", "conclusion": "CL API提供了一个易于使用的平台，支持对生物神经网络进行实时实验，既可以用于基础生物学研究也可以用于新兴的神经系统计算应用。"}}
{"id": "2602.11630", "pdf": "https://arxiv.org/pdf/2602.11630", "abs": "https://arxiv.org/abs/2602.11630", "authors": ["Yipeng Huang", "Dejun Xu", "Zexin Lin", "Zhenzhong Wang", "Min Jiang"], "title": "Neuro-Symbolic Multitasking: A Unified Framework for Discovering Generalizable Solutions to PDE Families", "categories": ["cs.AI"], "comment": null, "summary": "Solving Partial Differential Equations (PDEs) is fundamental to numerous scientific and engineering disciplines. A common challenge arises from solving the PDE families, which are characterized by sharing an identical mathematical structure but varying in specific parameters. Traditional numerical methods, such as the finite element method, need to independently solve each instance within a PDE family, which incurs massive computational cost. On the other hand, while recent advancements in machine learning PDE solvers offer impressive computational speed and accuracy, their inherent ``black-box\" nature presents a considerable limitation. These methods primarily yield numerical approximations, thereby lacking the crucial interpretability provided by analytical expressions, which are essential for deeper scientific insight. To address these limitations, we propose a neuro-assisted multitasking symbolic PDE solver framework for PDE family solving, dubbed NMIPS. In particular, we employ multifactorial optimization to simultaneously discover the analytical solutions of PDEs. To enhance computational efficiency, we devise an affine transfer method by transferring learned mathematical structures among PDEs in a family, avoiding solving each PDE from scratch. Experimental results across multiple cases demonstrate promising improvements over existing baselines, achieving up to a $\\sim$35.7% increase in accuracy while providing interpretable analytical solutions.", "AI": {"tldr": "提出了一种神经符号多任务框架NMIPS，用于发现PDE家族的可解释解。", "motivation": "传统数值方法解决每个PDE实例消耗大量计算资源；机器学习方法虽快但缺乏解析表达式提供的可解释性。", "method": "利用多因子优化同时寻找PDE的解析解，并通过仿射转移法提高效率，避免从零开始求解每一PDE。", "result": "实验显示在准确性上相较于现有基准提高了约35.7%，并提供了解释性的解析解。", "conclusion": "NMIPS框架有效解决了PDE家族求解中的计算量和可解释性问题。"}}
{"id": "2602.11628", "pdf": "https://arxiv.org/pdf/2602.11628", "abs": "https://arxiv.org/abs/2602.11628", "authors": ["Yeva Gabrielyan", "Varduhi Yeghiazaryan", "Irina Voiculescu"], "title": "PLESS: Pseudo-Label Enhancement with Spreading Scribbles for Weakly Supervised Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "This work was supported by the Afeyan Family Foundation Seed Grants and the JACE Foundation Research Innovation Grant Program at AUA", "summary": "Weakly supervised learning with scribble annotations uses sparse user-drawn strokes to indicate segmentation labels on a small subset of pixels. This annotation reduces the cost of dense pixel-wise labeling, but suffers inherently from noisy and incomplete supervision. Recent scribble-based approaches in medical image segmentation address this limitation using pseudo-label-based training; however, the quality of the pseudo-labels remains a key performance limit. We propose PLESS, a generic pseudo-label enhancement strategy which improves reliability and spatial consistency. It builds on a hierarchical partitioning of the image into a hierarchy of spatially coherent regions. PLESS propagates scribble information to refine pseudo-labels within semantically coherent regions. The framework is model-agnostic and easily integrates into existing pseudo-label methods. Experiments on two public cardiac MRI datasets (ACDC and MSCMRseg) across four scribble-supervised algorithms show consistent improvements in segmentation accuracy. Code will be made available on GitHub upon acceptance.", "AI": {"tldr": "提出了一种改进伪标签可靠性和空间一致性的方法PLESS，用于弱监督分割任务。", "motivation": "现有基于伪标签的训练方法在使用手写注释进行医学图像分割时，仍面临伪标签质量差的问题。因此，需要一种新的策略来提高这些模型的表现。", "method": "通过将图像划分为一系列空间上连贯的区域，并利用这些区域内的信息传播手写标记以改进伪标签的质量。", "result": "实验表明，在两个公开的心脏MRI数据集上的四种类别监督算法中，PLESS方法提高了分割准确性。", "conclusion": "提出的框架模型无关且易于集成到现有的伪标签方法中，可以有效地提高弱监督条件下的医学图像分割精度。"}}
{"id": "2602.11626", "pdf": "https://arxiv.org/pdf/2602.11626", "abs": "https://arxiv.org/abs/2602.11626", "authors": ["Wenqian Chen", "Yucheng Fu", "Michael Penwarden", "Pratanu Roy", "Panos Stinis"], "title": "ArGEnT: Arbitrary Geometry-encoded Transformer for Operator Learning", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "physics.comp-ph", "physics.flu-dyn"], "comment": "69 pages, 21 figures, 10 tables", "summary": "Learning solution operators for systems with complex, varying geometries and parametric physical settings is a central challenge in scientific machine learning. In many-query regimes such as design optimization, control and inverse problems, surrogate modeling must generalize across geometries while allowing flexible evaluation at arbitrary spatial locations. In this work, we propose Arbitrary Geometry-encoded Transformer (ArGEnT), a geometry-aware attention-based architecture for operator learning on arbitrary domains. ArGEnT employs Transformer attention mechanisms to encode geometric information directly from point-cloud representations with three variants-self-attention, cross-attention, and hybrid-attention-that incorporates different strategies for incorporating geometric features. By integrating ArGEnT into DeepONet as the trunk network, we develop a surrogate modeling framework capable of learning operator mappings that depend on both geometric and non-geometric inputs without the need to explicitly parametrize geometry as a branch network input. Evaluation on benchmark problems spanning fluid dynamics, solid mechanics and electrochemical systems, we demonstrate significantly improved prediction accuracy and generalization performance compared with the standard DeepONet and other existing geometry-aware saurrogates. In particular, the cross-attention transformer variant enables accurate geometry-conditioned predictions with reduced reliance on signed distance functions. By combining flexible geometry encoding with operator-learning capabilities, ArGEnT provides a scalable surrogate modeling framework for optimization, uncertainty quantification, and data-driven modeling of complex physical systems.", "AI": {"tldr": "提出了一种基于注意力机制的Arbitrary Geometry-encoded Transformer (ArGEnT)，用于复杂几何形状和参数物理设置下的操作学习。", "motivation": "在科学机器学习中，针对具有复杂、变化几何结构的问题进行解决方案操作学习是关键挑战。特别是在设计优化等多查询场景下，需要建立能够跨不同几何结构泛化的替代模型，并允许灵活地评估任意空间位置处的预测值。", "method": "ArGEnT利用Transformer注意力机制从点云表示中直接编码几何信息，具有自注意、交叉注意和混合注意三种变体。将其集成到DeepONet作为主干网络，形成一个能够在仅需非显式参数化的情况下学习依赖于几何与非几何输入的操作映射的替代建模框架。", "result": "在流体力学等基准问题上的评估显示，ArGEnT比标准DeepONet和其他现有的基于几何结构的方法具有显著改进的预测精度和泛化性能。特别是交叉注意变换器变体能够减少对符号距离函数的依赖，从而实现准确的几何条件预测。", "conclusion": "通过结合灵活的几何编码与操作学习能力，ArGEnT为优化、不确定性量化及复杂物理系统的数据驱动建模提供了可扩展的替代建模框架。"}}
{"id": "2602.11625", "pdf": "https://arxiv.org/pdf/2602.11625", "abs": "https://arxiv.org/abs/2602.11625", "authors": ["Bin Huang", "Xun Yu", "Yikun Zhang", "Yi Zhang", "Yang Chen", "Qiegen Liu"], "title": "PLOT-CT: Pre-log Voronoi Decomposition Assisted Generation for Low-dose CT Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Low-dose computed tomography (LDCT) reconstruction is fundamentally challenged by severe noise and compromised data fidelity under reduced radiation exposure. Most existing methods operate either in the image or post-log projection domain, which fails to fully exploit the rich structural information in pre-log measurements while being highly susceptible to noise. The requisite logarithmic transformation critically amplifies noise within these data, imposing exceptional demands on reconstruction precision. To overcome these challenges, we propose PLOT-CT, a novel framework for Pre-Log vOronoi decomposiTion-assisted CT generation. Our method begins by applying Voronoi decomposition to pre-log sinograms, disentangling the data into distinct underlying components, which are embedded in separate latent spaces. This explicit decomposition significantly enhances the model's capacity to learn discriminative features, directly improving reconstruction accuracy by mitigating noise and preserving information inherent in the pre-log domain. Extensive experiments demonstrate that PLOT-CT achieves state-of-the-art performance, attaining a 2.36dB PSNR improvement over traditional methods at the 1e4 incident photon level in the pre-log domain.", "AI": {"tldr": "提出了一种新的低剂量CT重建方法PLOT-CT，通过预日志Voronoi分解提高图像质量。", "motivation": "现有LDCT重建方法在低辐射曝光下无法充分利用前对数测量中的结构信息，并且容易受到噪声的影响。为了克服这些挑战，提出了PLOT-CT框架。", "method": "该方法首先将Voronoi分解应用于预日志sinogram，将其数据分离成不同的底层组件，并嵌入到单独的潜在空间中。这显著增强了模型学习鉴别性特征的能力，从而通过减少噪声和保留前对数域中的信息来提高重建精度。", "result": "实验结果表明，PLOT-CT在1e4入射光子级别下，在预日志域达到了比传统方法高2.36dB的PSNR提升，并且实现了最先进的性能。", "conclusion": "PLOT-CT通过改进低剂量CT重建中的噪声处理和数据结构信息利用，成功提高了图像质量。"}}
{"id": "2602.11619", "pdf": "https://arxiv.org/pdf/2602.11619", "abs": "https://arxiv.org/abs/2602.11619", "authors": ["Aman Mehta"], "title": "When Agents Disagree With Themselves: Measuring Behavioral Consistency in LLM-Based Agents", "categories": ["cs.AI"], "comment": "5 pages, 2 figures", "summary": "Run the same LLM agent on the same task twice: do you get the same behavior? We find the answer is often no. In a study of 3,000 agent runs across three models (Llama 3.1 70B, GPT-4o, and Claude Sonnet 4.5) on HotpotQA, we observe that ReAct-style agents produce 2.0--4.2 distinct action sequences per 10 runs on average, even with identical inputs. More importantly, this variance predicts failure: tasks with consistent behavior ($\\leq$2 unique paths) achieve 80--92% accuracy, while highly inconsistent tasks ($\\geq$6 unique paths) achieve only 25--60%, a 32--55 percentage point gap depending on model. We trace variance to early decisions: 69% of divergence occurs at step 2, the first search query. Our results suggest that monitoring behavioral consistency during execution could enable early error detection and improve agent reliability.", "AI": {"tldr": "研究评估了大型语言模型代理在相同任务上多次运行的行为一致性，并分析了一致性与准确性之间的关系。", "motivation": "发现LLM代理的输出行为不一致可能影响其性能，希望通过监测这种行为的一致性来提高代理的可靠性和早期故障检测能力。", "method": "通过3000次实验，在HotpotQA任务上使用三种模型（Llama 3.1 70B、GPT-4o和Claude Sonnet 4.5）评估LLM代理的行为一致性，特别是在ReAct样式的代理中观察到的行为差异。", "result": "行为不一致的代理准确性显著低于具有高行为一致性的代理。这种不一致主要发生在早期决策阶段，尤其是在第一个搜索查询时。", "conclusion": "监测LLM代理执行过程中的行为一致性可以作为提高代理可靠性的一种手段，并有助于实现更早的错误检测。"}}
{"id": "2602.11614", "pdf": "https://arxiv.org/pdf/2602.11614", "abs": "https://arxiv.org/abs/2602.11614", "authors": ["Yousuf Choudhary", "Tosiron Adegbija"], "title": "Device-Circuit Co-Design of Variation-Resilient Read and Write Drivers for Antiferromagnetic Tunnel Junction (AFMTJ) Memories", "categories": ["cs.AR", "cs.ET"], "comment": "International VLSI Symposium on Technology, Systems and Applications (VLSI-TSA) 2026", "summary": "Antiferromagnetic Tunnel Junctions (AFMTJs) offer picosecond switching and high integration density for in-memory computing, but their ultrafast dynamics and low tunnel magnetoresistance (TMR) make state-of-the-art MRAM interfaces unreliable. This work develops a device-circuit co-designed read/write interface optimized for AFMTJ behavior. Using a calibrated SPICE AFMTJ model as a baseline, we identify the limitations of conventional drivers and propose an asymmetric pulse driver (PD) for deterministic picosecond switching and a self-timed sense amplifier (STSA) with dynamic trip-point tuning for low-TMR sensing. Our experiments using SPICE and Monte Carlo evaluations demonstrate that the proposed circuits preserve AFMTJ latency and energy benefits while achieving robust read/write yield under realistic PVT and 3D integration parasitics, outperforming standard MRAM front-ends under the same conditions.", "AI": {"tldr": "该论文开发了一种针对反铁磁隧道结（AFMTJ）特性的设备电路协同设计的读写接口。", "motivation": "由于超快动态和低隧穿磁电阻，现有MRAM接口在AFMTJ内存中不可靠。需要一种新的读写接口来利用AFMTJ的优势并克服其限制。", "method": "使用校准的SPICE AFMTJ模型作为基准，识别了传统驱动器的局限性，并提出了一种非对称脉冲驱动器和动态阈值点调整的自定时放大器以实现低TMR检测。", "result": "实验结果表明所提出的电路在现实情况下保持AFMTJ延迟和能源效益的同时提高了读写良率，优于标准MRAM前端。", "conclusion": "该研究通过设备电路协同设计实现了针对AFMTJ特性的优化读写接口，在保证性能的同时增强了可靠性和集成度。"}}
{"id": "2602.11609", "pdf": "https://arxiv.org/pdf/2602.11609", "abs": "https://arxiv.org/abs/2602.11609", "authors": ["Yiming Gao", "Zhen Wang", "Jefferson Chen", "Mark Antkowiak", "Mengzhou Hu", "JungHo Kong", "Dexter Pratt", "Jieyuan Liu", "Enze Ma", "Zhiting Hu", "Eric P. Xing"], "title": "scPilot: Large Language Model Reasoning Toward Automated Single-Cell Analysis and Discovery", "categories": ["cs.AI", "q-bio.GN"], "comment": "Accepted at NeurIPS 2025 Main Conference", "summary": "We present scPilot, the first systematic framework to practice omics-native reasoning: a large language model (LLM) converses in natural language while directly inspecting single-cell RNA-seq data and on-demand bioinformatics tools. scPilot converts core single-cell analyses, i.e., cell-type annotation, developmental-trajectory reconstruction, and transcription-factor targeting, into step-by-step reasoning problems that the model must solve, justify, and, when needed, revise with new evidence. To measure progress, we release scBench, a suite of 9 expertly curated datasets and graders that faithfully evaluate the omics-native reasoning capability of scPilot w.r.t various LLMs. Experiments with o1 show that iterative omics-native reasoning lifts average accuracy by 11% for cell-type annotation and Gemini-2.5-Pro cuts trajectory graph-edit distance by 30% versus one-shot prompting, while generating transparent reasoning traces explain marker gene ambiguity and regulatory logic. By grounding LLMs in raw omics data, scPilot enables auditable, interpretable, and diagnostically informative single-cell analyses. Code, data, and package are available at https://github.com/maitrix-org/scPilot", "AI": {"tldr": "scPilot是第一个系统性框架，利用大型语言模型进行单细胞RNA测序数据的自动化分析和发现。", "motivation": "为了提高单细胞数据分析的准确性和透明度，开发了一种新的方法来整合大规模语言模型和生物信息学工具。", "method": "将核心单细胞分析任务转化为逐步推理问题，通过scBench评估框架测量进度，并与一次性提示进行对比。", "result": "实验表明迭代推理提升了11%的细胞类型注释准确率，且轨迹图编辑距离减少了30%，同时生成了清晰的推理痕迹来解释标记基因模糊性和调控逻辑。", "conclusion": "通过将大规模语言模型直接应用于原始组学数据中，scPilot使单细胞分析更加可审计、透明和具有诊断意义。"}}
{"id": "2602.11598", "pdf": "https://arxiv.org/pdf/2602.11598", "abs": "https://arxiv.org/abs/2602.11598", "authors": ["Zedong Chu", "Shichao Xie", "Xiaolong Wu", "Yanfen Shen", "Minghua Luo", "Zhengbo Wang", "Fei Liu", "Xiaoxu Leng", "Junjun Hu", "Mingyang Yin", "Jia Lu", "Yingnan Guo", "Kai Yang", "Jiawei Han", "Xu Chen", "Yanqing Zhu", "Yuxiang Zhao", "Xin Liu", "Yirong Yang", "Ye He", "Jiahang Wang", "Yang Cai", "Tianlin Zhang", "Li Gao", "Liu Liu", "et al. (19 additional authors not shown)"], "title": "ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Project Page: https://amap-cvlab.github.io/ABot-Navigation/ABot-N0/", "summary": "Embodied navigation has long been fragmented by task-specific architectures. We introduce ABot-N0, a unified Vision-Language-Action (VLA) foundation model that achieves a ``Grand Unification'' across 5 core tasks: Point-Goal, Object-Goal, Instruction-Following, POI-Goal, and Person-Following. ABot-N0 utilizes a hierarchical ``Brain-Action'' architecture, pairing an LLM-based Cognitive Brain for semantic reasoning with a Flow Matching-based Action Expert for precise, continuous trajectory generation. To support large-scale learning, we developed the ABot-N0 Data Engine, curating 16.9M expert trajectories and 5.0M reasoning samples across 7,802 high-fidelity 3D scenes (10.7 $\\text{km}^2$). ABot-N0 achieves new SOTA performance across 7 benchmarks, significantly outperforming specialized models. Furthermore, our Agentic Navigation System integrates a planner with hierarchical topological memory, enabling robust, long-horizon missions in dynamic real-world environments.", "AI": {"tldr": "介绍了ABot-N0，一种统一的视觉语言行动（VLA）基础模型，用于实现五个核心任务的‘大统一’。", "motivation": "长期以来，实体导航被特定的任务架构所分割。本文旨在通过引入一个通用的基础模型来解决这个问题。", "method": "使用分层的“大脑-动作”架构，结合LLM为基础的认知大脑和基于流匹配的动作专家。为了支持大规模学习，开发了ABot-N0数据引擎。", "result": "在7个基准测试中实现了新的SOTA性能，并且在动态现实环境中能够执行长期任务。", "conclusion": "通过引入统一的VLA基础模型，解决了实体导航领域碎片化问题，实现了跨五个核心任务的大统一。"}}
{"id": "2602.11596", "pdf": "https://arxiv.org/pdf/2602.11596", "abs": "https://arxiv.org/abs/2602.11596", "authors": ["Nikhil Verma", "Minjung Kim", "JooYoung Yoo", "Kyung-Min Jin", "Manasa Bharadwaj", "Kevin Ferreira", "Ko Keun Kim", "Youngjoon Kim"], "title": "MAPLE: Modality-Aware Post-training and Learning Ecosystem", "categories": ["cs.AI"], "comment": "31 pages", "summary": "Multimodal language models now integrate text, audio, and video for unified reasoning. Yet existing RL post-training pipelines treat all input signals as equally relevant, ignoring which modalities each task actually requires. This modality-blind training inflates policy-gradient variance, slows convergence, and degrades robustness to real-world distribution shifts where signals may be missing, added, or reweighted. We introduce MAPLE, a complete modality-aware post-training and learning ecosystem comprising: (1) MAPLE-bench, the first benchmark explicitly annotating minimal signal combinations required per task; (2) MAPO, a modality-aware policy optimization framework that stratifies batches by modality requirement to reduce gradient variance from heterogeneous group advantages; (3) Adaptive weighting and curriculum scheduling that balances and prioritizes harder signal combinations. Systematic analysis across loss aggregation, clipping, sampling, and curriculum design establishes MAPO's optimal training strategy. Adaptive weighting and curriculum focused learning further boost performance across signal combinations. MAPLE narrows uni/multi-modal accuracy gaps by 30.24%, converges 3.18x faster, and maintains stability across all modality combinations under realistic reduced signal access. MAPLE constitutes a complete recipe for deployment-ready multimodal RL post-training.", "AI": {"tldr": "本文提出了MAPLE，一个面向多模态强化学习后期训练的生态系统。通过将不同任务所需的最小信号组合进行标注和优化策略来提升模型性能。", "motivation": "现有的RL后期训练流水线忽视了输入信号中各模态的重要性，导致政策梯度方差增大、收敛速度变慢及鲁棒性下降的问题。", "method": "MAPLE生态系统包括：1. MAPLE-bench基准测试；2. MAPO模态感知策略优化框架；3. 自适应加权和课程调度。这些方法能够减少异构群体优势导致的梯度方差，提升模型性能。", "result": "实验显示，MAPLE将单一/多模态准确率差距缩小了30.24%，收敛速度提高了3.18倍，并且在所有信号组合下保持稳定。", "conclusion": "MAPLE提供了一套完整的部署准备就绪的多模态RL后期训练方案。"}}
{"id": "2602.11588", "pdf": "https://arxiv.org/pdf/2602.11588", "abs": "https://arxiv.org/abs/2602.11588", "authors": ["Yuqing Gao", "Guanren Zhou", "Khalid M. Mosalam"], "title": "A Large Language Model for Disaster Structural Reconnaissance Summarization", "categories": ["cs.CV"], "comment": "8 pages, 4 figures. Presented at the 18th World Conference on Earthquake Engineering (18WCEE 2024)", "summary": "Artificial Intelligence (AI)-aided vision-based Structural Health Monitoring (SHM) has emerged as an effective approach for monitoring and assessing structural condition by analyzing image and video data. By integrating Computer Vision (CV) and Deep Learning (DL), vision-based SHM can automatically identify and localize visual patterns associated with structural damage. However, previous works typically generate only discrete outputs, such as damage class labels and damage region coordinates, requiring engineers to further reorganize and analyze these results for evaluation and decision-making. In late 2022, Large Language Models (LLMs) became popular across multiple fields, providing new insights into AI-aided vision-based SHM. In this study, a novel LLM-based Disaster Reconnaissance Summarization (LLM-DRS) framework is proposed. It introduces a standard reconnaissance plan in which the collection of vision data and corresponding metadata follows a well-designed on-site investigation process. Text-based metadata and image-based vision data are then processed and integrated into a unified format, where well-trained Deep Convolutional Neural Networks extract key attributes, including damage state, material type, and damage level. Finally, all data are fed into an LLM with carefully designed prompts, enabling the LLM-DRS to generate summary reports for individual structures or affected regions based on aggregated attributes and metadata. Results show that integrating LLMs into vision-based SHM, particularly for rapid post-disaster reconnaissance, demonstrates promising potential for improving resilience of the built environment through effective reconnaissance.", "AI": {"tldr": "该论文提出了一种基于大型语言模型的灾难侦察总结框架，用于自动分析和整合结构损伤数据，生成详细的评估报告。", "motivation": "现有的视觉健康监测方法只能提供离散结果，工程师需要进一步重组和分析这些结果。因此，引入大型语言模型以提高灾后快速侦察的有效性和建筑环境的韧性。", "method": "提出了一种标准的侦察计划，收集视觉数据及其元数据，并通过深度卷积神经网络提取关键属性。然后将所有数据输入到经过精心设计提示的大型语言模型中生成总结报告。", "result": "结果表明，集成大型语言模型到基于视觉的结构健康监测系统可以提高灾后快速侦察的有效性。", "conclusion": "该研究展示了将大型语言模型应用于灾难现场结构损伤评估的巨大潜力，有助于提升建筑环境韧性。"}}
{"id": "2602.11584", "pdf": "https://arxiv.org/pdf/2602.11584", "abs": "https://arxiv.org/abs/2602.11584", "authors": ["Yujie Gu", "Richeng Jin", "Zhaoyang Zhang", "Huaiyu Dai"], "title": "Gradient Compression May Hurt Generalization: A Remedy by Synthetic Data Guided Sharpness Aware Minimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "It is commonly believed that gradient compression in federated learning (FL) enjoys significant improvement in communication efficiency with negligible performance degradation. In this paper, we find that gradient compression induces sharper loss landscapes in federated learning, particularly under non-IID data distributions, which suggests hindered generalization capability. The recently emerging Sharpness Aware Minimization (SAM) effectively searches for a flat minima by incorporating a gradient ascent step (i.e., perturbing the model with gradients) before the celebrated stochastic gradient descent. Nonetheless, the direct application of SAM in FL suffers from inaccurate estimation of the global perturbation due to data heterogeneity. Existing approaches propose to utilize the model update from the previous communication round as a rough estimate. However, its effectiveness is hindered when model update compression is incorporated. In this paper, we propose FedSynSAM, which leverages the global model trajectory to construct synthetic data and facilitates an accurate estimation of the global perturbation. The convergence of the proposed algorithm is established, and extensive experiments are conducted to validate its effectiveness.", "AI": {"tldr": "提出了一种新的联邦学习算法FedSynSAM，通过合成数据来准确估计全局扰动。", "motivation": "发现梯度压缩在非独立同分布数据下会导致更尖锐的损失景观，并且现有方法在模型更新压缩后效果不佳。", "method": "利用全球模型轨迹生成合成数据以提高全局扰动估计准确性，从而改进了联邦学习中的Sharpness Aware Minimization算法。", "result": "理论证明了所提算法的有效性并通过大量实验验证其性能。", "conclusion": "FedSynSAM能够有效克服梯度压缩带来的问题，并提高了联邦学习在非独立同分布数据下的泛化能力。"}}
{"id": "2602.11583", "pdf": "https://arxiv.org/pdf/2602.11583", "abs": "https://arxiv.org/abs/2602.11583", "authors": ["Jingdi Chen", "Hanqing Yang", "Zongjun Liu", "Carlee Joe-Wong"], "title": "The Five Ws of Multi-Agent Communication: Who Talks to Whom, When, What, and Why -- A Survey from MARL to Emergent Language and LLMs", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted at Transactions on Machine Learning Research (TMLR), 2026", "summary": "Multi-agent sequential decision-making powers many real-world systems, from autonomous vehicles and robotics to collaborative AI assistants. In dynamic, partially observable environments, communication is often what reduces uncertainty and makes collaboration possible. This survey reviews multi-agent communication (MA-Comm) through the Five Ws: who communicates with whom, what is communicated, when communication occurs, and why communication is beneficial. This framing offers a clean way to connect ideas across otherwise separate research threads. We trace how communication approaches have evolved across three major paradigms. In Multi-Agent Reinforcement Learning (MARL), early methods used hand-designed or implicit protocols, followed by end-to-end learned communication optimized for reward and control. While successful, these protocols are frequently task-specific and hard to interpret, motivating work on Emergent Language (EL), where agents can develop more structured or symbolic communication through interaction. EL methods, however, still struggle with grounding, generalization, and scalability, which has fueled recent interest in large language models (LLMs) that bring natural language priors for reasoning, planning, and collaboration in more open-ended settings. Across MARL, EL, and LLM-based systems, we highlight how different choices shape communication design, where the main trade-offs lie, and what remains unsolved. We distill practical design patterns and open challenges to support future hybrid systems that combine learning, language, and control for scalable and interpretable multi-agent collaboration.", "AI": {"tldr": "本文综述了多智能体沟通（MA-Comm）的五个W：谁与谁交流，交流什么内容，何时交流以及为什么有益。通过这种方法，文章连接了不同的研究方向，并总结了从MARL到新兴语言再到大型语言模型的发展历程。", "motivation": "在动态和部分可观测环境中，多智能体通信能够减少不确定性并促进协作，然而现有的沟通方法往往任务特定且难以解读。本文综述旨在提供一个清晰的方法来连接不同研究领域，并总结现有挑战与未来趋势。", "method": "文章从MARL、新兴语言到大型语言模型的视角探讨了多智能体交流的发展历程，通过五个W的问题框架分析各个领域的研究成果和方法论。", "result": "综述显示了不同选择如何影响沟通设计及其中的主要权衡，并指出了仍然存在的未解问题。提出了实用的设计模式和支持未来混合系统的开放挑战。", "conclusion": "文章总结了多智能体通信领域的发展现状，强调了任务特定性与可解释性的挑战，并展望了结合学习、语言和控制的未来研究方向，以实现更广泛的应用场景中更为有效的交流设计。"}}
{"id": "2602.11581", "pdf": "https://arxiv.org/pdf/2602.11581", "abs": "https://arxiv.org/abs/2602.11581", "authors": ["Yiteng Tu", "Shuo Miao", "Weihang Su", "Yiqun Liu", "Qingyao Ai"], "title": "Analytical Search", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Analytical information needs, such as trend analysis and causal impact assessment, are prevalent across various domains including law, finance, science, and much more. However, existing information retrieval paradigms, whether based on relevance-oriented document ranking or retrieval-augmented generation (RAG) with large language models (LLMs), often struggle to meet the end-to-end requirements of such tasks at the corpus scale. They either emphasize information finding rather than end-to-end problem solving, or simply treat everything as naive question answering, offering limited control over reasoning, evidence usage, and verifiability. As a result, they struggle to support analytical queries that have diverse utility concepts and high accountability requirements. In this paper, we propose analytical search as a distinct and emerging search paradigm designed to fulfill these analytical information needs. Analytical search reframes search as an evidence-governed, process-oriented analytical workflow that explicitly models analytical intent, retrieves evidence for fusion, and produces verifiable conclusions through structured, multi-step inference. We position analytical search in contrast to existing paradigms, and present a unified system framework that integrates query understanding, recall-oriented retrieval, reasoning-aware fusion, and adaptive verification. We also discuss potential research directions for the construction of analytical search engines. In this way, we highlight the conceptual significance and practical importance of analytical search and call on efforts toward the next generation of search engines that support analytical information needs.", "AI": {"tldr": "该论文提出了分析搜索作为一种新的信息检索范式，以应对传统信息检索方法在处理趋势分析和因果影响评估等任务中的不足。", "motivation": "现有基于相关性排序或检索增强生成的方法无法完全满足诸如趋势分析、因果影响评估等复杂需求，因为这些需求需要的是端到端的问题解决能力以及对推理控制、证据使用和可验证性的高要求。", "method": "论文提出了一种新的搜索范式——分析搜索。它将搜索重新定义为一个基于证据引导的、过程导向的分析工作流，并构建了一个统一系统框架，包括查询理解、召回增强检索、推理感知融合和自适应验证。", "result": "通过这种新提出的分析搜索方法，论文展示了如何更好地支持复杂的分析信息需求，解决了现有方法在处理这类任务时遇到的问题。", "conclusion": "该研究强调了分析搜索的概念重要性和实际意义，并呼吁构建下一代搜索引擎以支持这些复杂的信息检索需求。"}}
{"id": "2602.11575", "pdf": "https://arxiv.org/pdf/2602.11575", "abs": "https://arxiv.org/abs/2602.11575", "authors": ["Seungyeon Yoo", "Youngseok Jang", "Dabin Kim", "Youngsoo Han", "Seungwoo Jung", "H. Jin Kim"], "title": "ReaDy-Go: Real-to-Sim Dynamic 3D Gaussian Splatting Simulation for Environment-Specific Visual Navigation with Moving Obstacles", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Project page: https://syeon-yoo.github.io/ready-go-site/", "summary": "Visual navigation models often struggle in real-world dynamic environments due to limited robustness to the sim-to-real gap and the difficulty of training policies tailored to target deployment environments (e.g., households, restaurants, and factories). Although real-to-sim navigation simulation using 3D Gaussian Splatting (GS) can mitigate this gap, prior works have assumed only static scenes or unrealistic dynamic obstacles, despite the importance of safe navigation in dynamic environments. To address these issues, we propose ReaDy-Go, a novel real-to-sim simulation pipeline that synthesizes photorealistic dynamic scenarios for target environments. ReaDy-Go generates photorealistic navigation datasets for dynamic environments by combining a reconstructed static GS scene with dynamic human GS obstacles, and trains policies robust to both the sim-to-real gap and moving obstacles. The pipeline consists of three components: (1) a dynamic GS simulator that integrates scene GS with a human animation module, enabling the insertion of animatable human GS avatars and the synthesis of plausible human motions from 2D trajectories, (2) navigation dataset generation for dynamic environments that leverages the simulator, a robot expert planner designed for dynamic GS representations, and a human planner, and (3) policy learning using the generated datasets. ReaDy-Go outperforms baselines across target environments in both simulation and real-world experiments, demonstrating improved navigation performance even after sim-to-real transfer and in the presence of moving obstacles. Moreover, zero-shot sim-to-real deployment in an unseen environment indicates its generalization potential. Project page: https://syeon-yoo.github.io/ready-go-site/.", "AI": {"tldr": "提出了一种名为ReaDy-Go的现实到模拟导航仿真流程，用于生成针对特定环境的动态场景。", "motivation": "现有视觉导航模型在动态环境中表现不佳，难以适应目标部署环境。本研究旨在解决这一问题，通过合成逼真的动态场景来提高导航性能和安全性。", "method": "ReaDy-Go由三个部分组成：1）一个动态GS仿真器，可以将静态GS场景与人类动画模块结合，并插入可操作的GS人物；2）生成针对动态环境的导航数据集；3）使用生成的数据集进行策略学习。", "result": "在模拟和真实世界实验中，ReaDy-Go优于基准模型。它表现出更好的导航性能，即使经过仿真到现实转移，在面对移动障碍物时也能保持良好表现，并展示了零样本泛化能力。", "conclusion": "ReaDy-Go为动态环境的视觉导航提供了一种有效的解决方案，通过生成逼真的数据集来提高策略的鲁棒性和适应性。"}}
{"id": "2602.11574", "pdf": "https://arxiv.org/pdf/2602.11574", "abs": "https://arxiv.org/abs/2602.11574", "authors": ["Aditya Taparia", "Som Sagar", "Ransalu Senanayake"], "title": "Learning to Configure Agentic AI Systems", "categories": ["cs.AI"], "comment": "21 pages, 13 figures", "summary": "Configuring LLM-based agent systems involves choosing workflows, tools, token budgets, and prompts from a large combinatorial design space, and is typically handled today by fixed large templates or hand-tuned heuristics. This leads to brittle behavior and unnecessary compute, since the same cumbersome configuration is often applied to both easy and hard input queries. We formulate agent configuration as a query-wise decision problem and introduce ARC (Agentic Resource & Configuration learner), which learns a light-weight hierarchical policy using reinforcement learning to dynamically tailor these configurations. Across multiple benchmarks spanning reasoning and tool-augmented question answering, the learned policy consistently outperforms strong hand-designed and other baselines, achieving up to 25% higher task accuracy while also reducing token and runtime costs. These results demonstrate that learning per-query agent configurations is a powerful alternative to \"one size fits all\" designs.", "AI": {"tldr": "本文提出了一种名为ARC的算法，用于基于LLM的代理系统的配置优化。", "motivation": "传统的固定大型模板或手动调优的方法在处理复杂任务时表现出脆弱性，并且浪费计算资源。为了解决这个问题，研究人员希望通过动态调整每项查询的配置来提高性能。", "method": "本文使用强化学习方法设计了一种轻量级分层策略ARC（代理资源与配置学习器），以根据输入查询的不同需求进行自适应的资源和参数配置优化。", "result": "实验结果表明，ARC算法在多个基准测试中超越了手动设计和其他基线模型，在任务准确性方面提高了25％以上，并且降低了计算成本。", "conclusion": "这项研究表明，学习每项查询的代理配置是一种比“一刀切”设计方案更强大的替代方案。"}}
{"id": "2602.11569", "pdf": "https://arxiv.org/pdf/2602.11569", "abs": "https://arxiv.org/abs/2602.11569", "authors": ["Zhenlin Qin", "Yancheng Ling", "Leizhen Wang", "Francisco Câmara Pereira", "Zhenliang Ma"], "title": "SemaPop: Semantic-Persona Conditioned Population Synthesis", "categories": ["cs.AI"], "comment": null, "summary": "Population synthesis is a critical component of individual-level socio-economic simulation, yet remains challenging due to the need to jointly represent statistical structure and latent behavioral semantics. Existing population synthesis approaches predominantly rely on structured attributes and statistical constraints, leaving a gap in semantic-conditioned population generation that can capture abstract behavioral patterns implicitly in survey data. This study proposes SemaPop, a semantic-statistical population synthesis model that integrates large language models (LLMs) with generative population modeling. SemaPop derives high-level persona representations from individual survey records and incorporates them as semantic conditioning signals for population generation, while marginal regularization is introduced to enforce alignment with target population marginals. In this study, the framework is instantiated using a Wasserstein GAN with gradient penalty (WGAN-GP) backbone, referred to as SemaPop-GAN. Extensive experiments demonstrate that SemaPop-GAN achieves improved generative performance, yielding closer alignment with target marginal and joint distributions while maintaining sample-level feasibility and diversity under semantic conditioning. Ablation studies further confirm the contribution of semantic persona conditioning and architectural design choices to balancing marginal consistency and structural realism. These results demonstrate that SemaPop-GAN enables controllable and interpretable population synthesis through effective semantic-statistical information fusion. SemaPop-GAN also provides a promising modular foundation for developing generative population projection systems that integrate individual-level behavioral semantics with population-level statistical constraints.", "AI": {"tldr": "提出了一种结合大型语言模型和生成性人口建模的SemaPop方法，用于合成符合统计结构和行为语义的人口。", "motivation": "为了填补现有人口合成方法中对行为模式隐式捕捉不足的问题，研究提出了一个可以综合统计信息和语义条件信号的新方法。", "method": "通过大型语言模型从个人调查记录中提取高级人物表示，并将其作为生成新人群的语义条件信号。利用Wasserstein GAN with gradient penalty（WGAN-GP）框架实现人口合成，同时引入边缘正则化以确保与目标边缘分布的一致性。", "result": "SemaPop-GAN在生成符合统计边际和联合分布的人口方面表现出色，并且保持了样本级别的可行性和多样性。实验表明该方法可以平衡边距一致性和结构现实主义。", "conclusion": "通过有效的语义-统计信息融合，SemaPop-GAN实现了可控且可解释的人口合成，为开发结合个体行为和人口级统计约束的生成性人口预测系统提供了基础。"}}
{"id": "2602.11567", "pdf": "https://arxiv.org/pdf/2602.11567", "abs": "https://arxiv.org/abs/2602.11567", "authors": ["Chang Liu", "Qinyi Zhou", "Xinjie Shen", "Xingyu Bruce Liu", "Tongshuang Wu", "Xiang 'Anthony' Chen"], "title": "Behavioral Indicators of Overreliance During Interaction with Conversational Language Models", "categories": ["cs.HC"], "comment": "conditionally accepted by ACM CHI 2026", "summary": "LLMs are now embedded in a wide range of everyday scenarios. However, their inherent hallucinations risk hiding misinformation in fluent responses, raising concerns about overreliance on AI. Detecting overreliance is challenging, as it often arises in complex, dynamic contexts and cannot be easily captured by post-hoc task outcomes. In this work, we aim to investigate how users' behavioral patterns correlate with overreliance. We collected interaction logs from 77 participants working with an LLM injected plausible misinformation across three real-world tasks and we assessed overreliance by whether participants detected and corrected these errors. By semantically encoding and clustering segments of user interactions, we identified five behavioral patterns linked to overreliance: users with low overreliance show careful task comprehension and fine-grained navigation; users with high overreliance show frequent copy-paste, skipping initial comprehension, repeated LLM references, coarse locating, and accepting misinformation despite hesitation. We discuss design implications for mitigation.", "AI": {"tldr": "研究探讨了用户与注入误导信息的语言模型交互时的行为模式，以识别过度依赖的迹象。", "motivation": "鉴于大型语言模型可能存在隐藏在流畅回答中的错误信息，研究旨在通过行为分析来检测用户的过度依赖情况。", "method": "收集了77名参与者在三个实际任务中与注入误导信息的语言模型交互的日志。通过语义编码和聚类用户交互片段，识别出五种与过度依赖相关的行为模式。", "result": "研究发现，低过度依赖的用户表现出仔细的任务理解及细致导航；而高过度依赖的用户则频繁使用复制粘贴功能、跳过初始理解步骤、重复参考模型输出、粗略定位信息并接受错误信息尽管有所犹豫。", "conclusion": "该研究表明特定的行为模式与用户的过度依赖行为有关，为未来设计干预措施提供了依据。"}}
{"id": "2602.11565", "pdf": "https://arxiv.org/pdf/2602.11565", "abs": "https://arxiv.org/abs/2602.11565", "authors": ["Zesheng Jia", "Jin Wang", "Siao Liu", "Lingzhi Li", "Ziyao Huang", "Yunjiang Xu", "Jianping Wang"], "title": "Move What Matters: Parameter-Efficient Domain Adaptation via Optimal Transport Flow for Collaborative Perception", "categories": ["cs.CV"], "comment": null, "summary": "Fast domain adaptation remains a fundamental challenge for deploying multi-agent systems across diverse environments in Vehicle-to-Everything (V2X) collaborative perception. Despite the success of Parameter-Efficient Fine-Tuning (PEFT) in natural language processing and conventional vision tasks, directly applying PEFT to multi-agent settings leads to significant performance degradation and training instability. In this work, we conduct a detailed analysis and identify two key factors: (i) inter-frame redundancy in heterogeneous sensory streams, and (ii) erosion of fine-grained semantics in deep-layer representations under PEFT adaptation. To address these issues, we propose FlowAdapt, a parameter-efficient framework grounded in optimal transport theory, which minimizes information transport costs across both data distributions and network hierarchies. Specifically, we introduce a Wasserstein Greedy Sampling strategy to selectively filter redundant samples via a bounded covering radius. Furthermore, Progressive Knowledge Transfer module is designed to progressively inject compressed early-stage representations into later stages through learnable pathways, alleviating semantic degradation in late-stage adaptation. Extensive experiments on three benchmarks demonstrate that FlowAdapt achieves state-of-the-art performance with only 1% of trainable parameters, effectively bridging domain gaps with superior sample efficiency and generalization.", "AI": {"tldr": "提出了一种基于最优传输理论的参数高效域适应框架FlowAdapt，用于解决多代理系统在V2X协同感知中的快速领域适应问题。", "motivation": "传统的参数高效微调方法（PEFT）直接应用于多代理场景时会导致性能下降和训练不稳定。为了解决这一问题并提高适应性效率，提出了基于最优传输理论的FlowAdapt框架。", "method": "该方法引入了Wasserstein贪婪采样策略以筛选冗余样本，并设计了渐进知识转移模块通过可学习路径将压缩后的早期阶段表示注入后期阶段，从而减少深层语义损失。", "result": "实验表明，在三个基准测试上，FlowAdapt仅使用1%的训练参数便达到了最先进的性能表现，展示了优异的采样效率和泛化能力。", "conclusion": "通过引入最优传输理论，该论文提出的FlowAdapt框架解决了多代理系统在V2X协同感知中的域适应挑战，并显著提高了模型的适应性和高效性。"}}
{"id": "2602.11564", "pdf": "https://arxiv.org/pdf/2602.11564", "abs": "https://arxiv.org/abs/2602.11564", "authors": ["Chen Zhao", "Jiawei Chen", "Hongyu Li", "Zhuoliang Kang", "Shilin Lu", "Xiaoming Wei", "Kai Zhang", "Jian Yang", "Ying Tai"], "title": "LUVE : Latent-Cascaded Ultra-High-Resolution Video Generation with Dual Frequency Experts", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in video diffusion models have significantly improved visual quality, yet ultra-high-resolution (UHR) video generation remains a formidable challenge due to the compounded difficulties of motion modeling, semantic planning, and detail synthesis. To address these limitations, we propose \\textbf{LUVE}, a \\textbf{L}atent-cascaded \\textbf{U}HR \\textbf{V}ideo generation framework built upon dual frequency \\textbf{E}xperts. LUVE employs a three-stage architecture comprising low-resolution motion generation for motion-consistent latent synthesis, video latent upsampling that performs resolution upsampling directly in the latent space to mitigate memory and computational overhead, and high-resolution content refinement that integrates low-frequency and high-frequency experts to jointly enhance semantic coherence and fine-grained detail generation. Extensive experiments demonstrate that our LUVE achieves superior photorealism and content fidelity in UHR video generation, and comprehensive ablation studies further validate the effectiveness of each component. The project is available at \\href{https://unicornanrocinu.github.io/LUVE_web/}{https://github.io/LUVE/}.", "AI": {"tldr": "LUVE是一种用于生成超高清视频的框架，通过低分辨率运动生成、视频潜在上采样和高分辨率内容细化三个阶段来提升视频质量和细节。", "motivation": "现有的视频扩散模型虽提高了视觉质量，但在超高清视频生成方面仍存在挑战。为了克服这些限制，作者提出了LUVE以提高运动建模、语义规划和细节合成的能力。", "method": "LUVE采用三阶段架构：低分辨率运动生成用于运动一致的潜在合成；视频潜在上采样直接在潜在空间中进行分辨率上采样来减少内存和计算开销；高分辨率内容细化集成高低频专家共同增强语义连贯性和细节生成能力。", "result": "LUVE在超高清视频生成方面达到了更高的图像逼真度和内容保真度，实验验证了各组件的有效性。", "conclusion": "通过创新的三阶段架构，LUVE有效解决了超高清视频生成中的挑战，并实现了高质量、高细节的视频生成。"}}
{"id": "2602.11554", "pdf": "https://arxiv.org/pdf/2602.11554", "abs": "https://arxiv.org/abs/2602.11554", "authors": ["Yichun Xiao", "Runwei Guan", "Fangqiang Ding"], "title": "HyperDet: 3D Object Detection with Hyper 4D Radar Point Clouds", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "9 pages, 4 figures, 6 tables", "summary": "4D mmWave radar provides weather-robust, velocity-aware measurements and is more cost-effective than LiDAR. However, radar-only 3D detection still trails LiDAR-based systems because radar point clouds are sparse, irregular, and often corrupted by multipath noise, yielding weak and unstable geometry. We present HyperDet, a detector-agnostic radar-only 3D detection framework that constructs a task-aware hyper 4D radar point cloud for standard LiDAR-oriented detectors. HyperDet aggregates returns from multiple surround-view 4D radars over consecutive frames to improve coverage and density, then applies geometry-aware cross-sensor consensus validation with a lightweight self-consistency check outside overlap regions to suppress inconsistent returns. It further integrates a foreground-focused diffusion module with training-time mixed radar-LiDAR supervision to densify object structures while lifting radar attributes (e.g., Doppler, RCS); the model is distilled into a consistency model for single-step inference. On MAN TruckScenes, HyperDet consistently improves over raw radar inputs with VoxelNeXt and CenterPoint, partially narrowing the radar-LiDAR gap. These results show that input-level refinement enables radar to better leverage LiDAR-oriented detectors without architectural modifications.", "AI": {"tldr": "本文提出了一种利用超4D雷达点云进行3D物体检测的框架HyperDet，以提高单靠雷达实现3D检测的效果。", "motivation": "由于雷达点云稀疏、不规则且容易受到多路径噪声的影响，导致其几何结构弱且不稳定。因此，为了提升雷达在3D物体检测中的性能并降低成本，本文旨在开发一种有效的解决方案。", "method": "HyperDet通过融合来自多个周围视图4D雷达的连续帧数据以提高覆盖率和密度，并应用几何感知跨传感器一致性验证以及轻量级自一致检查来抑制不一致返回。此外，引入了前景聚焦扩散模块结合混合训练时间监督进一步强化对象结构。", "result": "在MAN TruckScenes上，HyperDet相较于原始雷达输入明显提升，在与LiDAR基于的系统对比中缩小差距。", "conclusion": "通过输入级改进使得雷达能够更好地利用标准LiDAR导向检测器，而无需架构修改。"}}
{"id": "2602.11553", "pdf": "https://arxiv.org/pdf/2602.11553", "abs": "https://arxiv.org/abs/2602.11553", "authors": ["Nam Nguyen", "Thinh Nguyen", "Bella Bose"], "title": "Perception-based Image Denoising via Generative Compression", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Image denoising aims to remove noise while preserving structural details and perceptual realism, yet distortion-driven methods often produce over-smoothed reconstructions, especially under strong noise and distribution shift. This paper proposes a generative compression framework for perception-based denoising, where restoration is achieved by reconstructing from entropy-coded latent representations that enforce low-complexity structure, while generative decoders recover realistic textures via perceptual measures such as learned perceptual image patch similarity (LPIPS) loss and Wasserstein distance. Two complementary instantiations are introduced: (i) a conditional Wasserstein GAN (WGAN)-based compression denoiser that explicitly controls the rate-distortion-perception (RDP) trade-off, and (ii) a conditional diffusion-based reconstruction strategy that performs iterative denoising guided by compressed latents. We further establish non-asymptotic guarantees for the compression-based maximum-likelihood denoiser under additive Gaussian noise, including bounds on reconstruction error and decoding error probability. Experiments on synthetic and real-noise benchmarks demonstrate consistent perceptual improvements while maintaining competitive distortion performance.", "AI": {"tldr": "提出了一种基于生成压缩的感知图像去噪框架，以去除噪声的同时保持结构细节和视觉真实感。", "motivation": "现有基于失真的方法在强噪声或分布偏移情况下容易产生过度平滑的结果。因此，本论文旨在通过引入感知度量来改善图像去噪效果。", "method": "该研究提出了一个生成压缩框架用于感知去噪，其中恢复过程是通过对熵编码的潜在表示进行重构实现的，同时采用生成解码器利用诸如LPIPS损失和Wasserstein距离等感知度量来恢复真实纹理。引入了两种互补的实例化方式：（i）基于条件WGAN的压缩去噪器，其显式控制率失真感知（RDP）权衡；（ii）一种由压缩潜在值引导的迭代去噪策略。", "result": "实验表明，在合成和真实噪声基准上实现了持续的感知改进，并且保持了竞争力的失真性能。此外，还建立了基于压缩的最大似然去噪器在加性高斯噪声下的非渐近保证，包括重构误差和解码错误概率的界限。", "conclusion": "本文提出的基于生成压缩的方法有效提升了图像去噪的质量，特别是在处理强噪声或分布偏移的情况下表现良好。"}}
{"id": "2602.11550", "pdf": "https://arxiv.org/pdf/2602.11550", "abs": "https://arxiv.org/abs/2602.11550", "authors": ["Sisuo Lyu", "Siru Zhong", "Tiegang Chen", "Weilin Ruan", "Qingxiang Liu", "Taiqiang Lv", "Qingsong Wen", "Raymond Chi-Wing Wong", "Yuxuan Liang"], "title": "TS-Memory: Plug-and-Play Memory for Time Series Foundation Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time Series Foundation Models (TSFMs) achieve strong zero-shot forecasting through large-scale pre-training, but adapting them to downstream domains under distribution shift remains challenging. Existing solutions face a trade-off: Parametric Adaptation can cause catastrophic forgetting and requires costly multi-domain maintenance, while Non-Parametric Retrieval improves forecasts but incurs high inference latency due to datastore search. We propose Parametric Memory Distillation and implement it as TS-Memory, a lightweight memory adapter that augments frozen TSFMs. TS-Memory is trained in two stages. First, we construct an offline, leakage-safe kNN teacher that synthesizes confidence-aware quantile targets from retrieved futures. Second, we distill this retrieval-induced distributional correction into a lightweight memory adapter via confidence-gated supervision. During inference, TS-Memory fuses memory and backbone predictions with constant-time overhead, enabling retrieval-free deployment. Experiments across diverse TSFMs and benchmarks demonstrate consistent improvements in both point and probabilistic forecasting over representative adaptation methods, with efficiency comparable to the frozen backbone.", "AI": {"tldr": "本文提出了一种轻量级的记忆适配器TS-Memory，用于增强时间序列基础模型的适应性。", "motivation": "现有的时间序列基础模型在零样本预测中表现出色，但面对分布偏移时难以有效适应。参数调整会导致灾难性遗忘并需要高昂的成本来维护多领域模型；非参数检索虽然可以提高预测效果，但是会带来较高的推理延迟。", "method": "提出了TS-Memory方法：首先构建一个离线、安全的kNN教师网络，并从检索到的未来中合成置信度感知的目标。然后通过置信度门控监督将这种检索诱导的分布校正提炼成轻量级的记忆适配器，推理时融合内存和主干预测。", "result": "实验结果表明，在多种时间序列基础模型和基准测试上TS-Memory方法在点预测和概率预测方面均优于代表性适应方法，并且效率与冻结主干相当。", "conclusion": "TS-Memory提供了一种有效的方法，使时间序列基础模型能够在保持高效的同时提高其适应性。"}}
{"id": "2602.11549", "pdf": "https://arxiv.org/pdf/2602.11549", "abs": "https://arxiv.org/abs/2602.11549", "authors": ["Yuanfu Wang", "Zhixuan Liu", "Xiangtian Li", "Chaochao Lu", "Chao Yang"], "title": "Native Reasoning Models: Training Language Models to Reason on Unverifiable Data", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICLR 2026", "summary": "The prevailing paradigm for training large reasoning models--combining Supervised Fine-Tuning (SFT) with Reinforcement Learning with Verifiable Rewards (RLVR)--is fundamentally constrained by its reliance on high-quality, human-annotated reasoning data and external verifiers. This dependency incurs significant data-collection costs, risks embedding human cognitive biases, and confines the reinforcement learning stage to objectively assessable domains like mathematics and coding, leaving a wide range of unverifiable tasks beyond its scope. To overcome these limitations, we introduce NRT (Native Reasoning Training), a novel framework that cultivates complex reasoning by having the model generate its own reasoning traces using only standard question-answer pairs, thereby obviating the need for expert-written demonstrations. NRT reframes the training problem by treating the reasoning process as a latent variable. It employs a unified training objective that models reasoning as an optimization problem, intrinsically rewarding paths that increase the model's likelihood of producing the ground-truth answer. This unified perspective allows us to analyze intrinsic failure modes of prior methods, such as policy collapse, and systematically design more robust reward aggregation functions, creating a self-reinforcing feedback loop where the model learns to think in ways that resolve its own uncertainty. Empirical evaluation on Llama and Mistral model families demonstrates that NRT achieves state-of-the-art performance among verifier-free methods, significantly outperforming standard SFT baselines and prior verifier-free RL methods. Our approach yields particularly strong performance gains in complex reasoning domains and exhibits high robustness to policy collapse, offering a general, scalable path toward building more powerful and broadly applicable reasoning systems.", "AI": {"tldr": "该论文提出了一种新的训练框架NRT，用于在缺乏验证器的情况下培养语言模型的推理能力。", "motivation": "现有方法依赖于高质量的人工标注数据和外部验证器，这增加了数据收集成本并限制了模型应用领域。为了克服这些问题，作者提出了无需验证器的新框架NRT。", "method": "NRT通过让模型自动生成推理路径来训练复杂推理能力，并采用统一的优化目标来奖励能够提高生成正确答案概率的推理方式。", "result": "实验结果表明，NRT在缺乏验证器的情况下表现优于现有方法，在复杂推理任务中尤其有效。", "conclusion": "NRT提供了一种通用且可扩展的方法，用于构建更强大和广泛应用的语言模型推理系统。"}}
{"id": "2602.11547", "pdf": "https://arxiv.org/pdf/2602.11547", "abs": "https://arxiv.org/abs/2602.11547", "authors": ["Xiang Zhang", "Haiyang Xia", "Ziwen He", "Wenbin Huang", "Fei Peng", "Zhangjie Fu"], "title": "H.265/HEVC Video Steganalysis Based on CU Block Structure Gradients and IPM Mapping", "categories": ["eess.IV", "cs.MM"], "comment": null, "summary": "Existing H.265/HEVC video steganalysis research mainly focuses on statistical feature modeling at the levels of motion vectors (MV), intra prediction modes (IPM), or transform coefficients. In contrast, studies targeting the coding-structure level - especially the analysis of block-level steganographic behaviors in Coding Units (CUs) - remain at an early stage. As a core component of H.265/HEVC coding decisions, the CU partition structure often exhibits steganographic perturbations in the form of structural changes and reorganization of prediction relationships, which are difficult to characterize effectively using traditional pixel-domain features or mode statistics. To address this issue, this paper, for the first time from the perspective of CU block-level steganalysis, proposes an H.265/HEVC video steganalysis method based on CU block-structure gradients and intra prediction mode mapping. The proposed method constructs a CU block-structure gradient map to explicitly describe changes in coding-unit partitioning, and combines it with a block-level mapping representation of IPM to jointly model the structural perturbations introduced by CU-level steganographic embedding. On this basis, we design a Transformer network, GradIPMFormer, tailored for CU-block steganalysis, thereby effectively enhancing the capability to perceive CU-level steganographic behaviors. Experimental results show that under different quantization parameters and resolution settings, the proposed method consistently achieves superior detection performance across multiple H.265/HEVC steganographic algorithms, validating the feasibility and effectiveness of conducting video steganalysis from the coding-structure perspective. This study provides a new CU block-level analysis paradigm for H.265/HEVC video steganalysis and has significant research value for covert communication security detection.", "AI": {"tldr": "论文提出了基于CU块结构梯度和IPM映射的H.265/HEVC视频隐写分析方法，设计了用于CU块级隐写分析的Transformer网络GradIPMFormer。", "motivation": "现有的H.265/HEVC视频隐写分析研究主要集中在统计特征建模上，而在编码结构层面特别是CU块级别的隐写行为分析方面仍处于初级阶段。为了有效表征由CU级别隐写嵌入引入的结构扰动，本文从CU块级隐写分析的角度出发。", "method": "论文构建了CU块结构梯度图以描述编码单元划分的变化，并结合IPM的块级映射表示来联合建模由CU级别的隐写嵌入引出的结构性变化。基于此，设计了一个用于CU块级隐写分析的Transformer网络GradIPMFormer。", "result": "实验结果表明，在不同的量化参数和分辨率设置下，所提出的方法在多个H.265/HEVC隐写算法上始终具有优越的检测性能。", "conclusion": "本文提供了一种新的CU块级分析范式用于H.265/HEVC视频隐写分析，并为隐蔽通信安全检测的研究提供了重要的研究价值。"}}
{"id": "2602.11545", "pdf": "https://arxiv.org/pdf/2602.11545", "abs": "https://arxiv.org/abs/2602.11545", "authors": ["Yingkai Zhang", "Shuang Chen", "Ye Tian", "Yunyi Gao", "Jianyong Jiang", "Ying Fu"], "title": "Supervise-assisted Multi-modality Fusion Diffusion Model for PET Restoration", "categories": ["cs.CV"], "comment": null, "summary": "Positron emission tomography (PET) offers powerful functional imaging but involves radiation exposure. Efforts to reduce this exposure by lowering the radiotracer dose or scan time can degrade image quality. While using magnetic resonance (MR) images with clearer anatomical information to restore standard-dose PET (SPET) from low-dose PET (LPET) is a promising approach, it faces challenges with the inconsistencies in the structure and texture of multi-modality fusion, as well as the mismatch in out-of-distribution (OOD) data. In this paper, we propose a supervise-assisted multi-modality fusion diffusion model (MFdiff) for addressing these challenges for high-quality PET restoration. Firstly, to fully utilize auxiliary MR images without introducing extraneous details in the restored image, a multi-modality feature fusion module is designed to learn an optimized fusion feature. Secondly, using the fusion feature as an additional condition, high-quality SPET images are iteratively generated based on the diffusion model. Furthermore, we introduce a two-stage supervise-assisted learning strategy that harnesses both generalized priors from simulated in-distribution datasets and specific priors tailored to in-vivo OOD data. Experiments demonstrate that the proposed MFdiff effectively restores high-quality SPET images from multi-modality inputs and outperforms state-of-the-art methods both qualitatively and quantitatively.", "AI": {"tldr": "提出了一种监督辅助多模态融合扩散模型MFdiff，用于从低剂量PET图像和MR图像中恢复高质量的标准剂量PET图像。", "motivation": "降低辐射暴露虽然可以减少放射性示踪剂的剂量或缩短扫描时间，但会损害PET图像的质量。使用具有清晰解剖信息的MRI来提高低剂量PET图像质量是一个有前景的方法，但面临着多模态融合中的结构和纹理不一致以及分布外数据匹配的问题。", "method": "设计了多模态特征融合模块以充分利用辅助MR图像，并避免引入无关细节；利用扩散模型基于优化后的融合特征迭代生成高质量的SPET图像；采用两阶段监督辅助学习策略，结合模拟分布内的通用先验知识和针对实际分布外的数据特定先验知识。", "result": "实验表明所提出的MFdiff方法能够有效地从多模态输入中恢复出高质量的标准剂量PET图像，并在定性和定量评估上超过了现有最先进的方法。", "conclusion": "监督辅助的多模态融合扩散模型成功解决了低剂量和标准剂量PET图像之间的质量差距问题，提供了更安全高效的成像解决方案。"}}
{"id": "2602.11541", "pdf": "https://arxiv.org/pdf/2602.11541", "abs": "https://arxiv.org/abs/2602.11541", "authors": ["Hanbing Liu", "Chunhao Tian", "Nan An", "Ziyuan Wang", "Pinyan Lu", "Changyuan Yu", "Qi Qi"], "title": "Budget-Constrained Agentic Large Language Models: Intention-Based Planning for Costly Tool Use", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "We study budget-constrained tool-augmented agents, where a large language model must solve multi-step tasks by invoking external tools under a strict monetary budget. We formalize this setting as sequential decision making in context space with priced and stochastic tool executions, making direct planning intractable due to massive state-action spaces, high variance of outcomes and prohibitive exploration cost. To address these challenges, we propose INTENT, an inference-time planning framework that leverages an intention-aware hierarchical world model to anticipate future tool usage, risk-calibrated cost, and guide decisions online. Across cost-augmented StableToolBench, INTENT strictly enforces hard budget feasibility while substantially improving task success over baselines, and remains robust under dynamic market shifts such as tool price changes and varying budgets.", "AI": {"tldr": "研究在严格预算约束下，大型语言模型通过调用外部工具解决多步骤任务的框架。", "motivation": "面对预算受限且需要使用成本高昂工具来完成复杂任务的情景，现有方法难以直接规划并执行有效决策。为应对这一挑战，本论文提出一种新的推理时间规划框架以提高任务成功率。", "method": "INTENT是一种利用意图感知分层世界模型的推理时间规划框架，能够预见未来的工具使用、风险校准成本，并在线指导决策。", "result": "在增强的成本稳定的工件基准测试中，INTENT严格遵守硬预算限制并显著提高了任务完成率，同时对动态市场变化（如工具价格变动和不同预算）表现出强大的适应性。", "conclusion": "通过提出INTENT框架，解决了预算受限下大型语言模型调用昂贵工具执行多步骤任务时面临的决策难题。"}}
{"id": "2602.11536", "pdf": "https://arxiv.org/pdf/2602.11536", "abs": "https://arxiv.org/abs/2602.11536", "authors": ["De-Xing Huang", "Chaohui Yu", "Xiao-Hu Zhou", "Tian-Yu Xiang", "Qin-Yi Zhang", "Mei-Jiang Gui", "Rui-Ze Ma", "Chen-Yu Wang", "Nu-Fang Xiao", "Fan Wang", "Zeng-Guang Hou"], "title": "Vascular anatomy-aware self-supervised pre-training for X-ray angiogram analysis", "categories": ["cs.CV"], "comment": "10 pages, 10 figures, 10 tables. Journal version of VasoMIM (AAAI 2026)", "summary": "X-ray angiography is the gold standard imaging modality for cardiovascular diseases. However, current deep learning approaches for X-ray angiogram analysis are severely constrained by the scarcity of annotated data. While large-scale self-supervised learning (SSL) has emerged as a promising solution, its potential in this domain remains largely unexplored, primarily due to the lack of effective SSL frameworks and large-scale datasets. To bridge this gap, we introduce a vascular anatomy-aware masked image modeling (VasoMIM) framework that explicitly integrates domain-specific anatomical knowledge. Specifically, VasoMIM comprises two key designs: an anatomy-guided masking strategy and an anatomical consistency loss. The former strategically masks vessel-containing patches to compel the model to learn robust vascular semantics, while the latter preserves structural consistency of vessels between original and reconstructed images, enhancing the discriminability of the learned representations. In conjunction with VasoMIM, we curate XA-170K, the largest X-ray angiogram pre-training dataset to date. We validate VasoMIM on four downstream tasks across six datasets, where it demonstrates superior transferability and achieves state-of-the-art performance compared to existing methods. These findings highlight the significant potential of VasoMIM as a foundation model for advancing a wide range of X-ray angiogram analysis tasks. VasoMIM and XA-170K will be available at https://github.com/Dxhuang-CASIA/XA-SSL.", "AI": {"tldr": "本文提出了一种基于血管解剖的自监督预训练框架VasoMIM，用于X射线造影图像分析。", "motivation": "当前深度学习方法在X射线造影图像分析中受限于标注数据稀缺。为解决此问题，开发一种能够利用大规模无标签数据进行有效预训练的方法是必要的。", "method": "本文设计了一种血管解剖感知的掩码图像建模框架VasoMIM，包含解剖引导式掩码策略和解剖一致性损失。通过该方法，模型可以在缺乏大量标注数据的情况下学习到丰富的血管信息，并在下游任务中表现出色。", "result": "实验结果表明，在四个不同下游任务上，VasoMIM均优于现有方法，显示了其作为基础模型的巨大潜力。", "conclusion": "本文提出的方法能够显著提高X射线造影图像分析的准确性和效率。"}}
{"id": "2602.11534", "pdf": "https://arxiv.org/pdf/2602.11534", "abs": "https://arxiv.org/abs/2602.11534", "authors": ["Jingkun Liu", "Yisong Yue", "Max Welling", "Yue Song"], "title": "Krause Synchronization Transformers", "categories": ["cs.LG", "cs.AI"], "comment": "Project page: https://jingkun-liu.github.io/krause-sync-transformers/", "summary": "Self-attention in Transformers relies on globally normalized softmax weights, causing all tokens to compete for influence at every layer. When composed across depth, this interaction pattern induces strong synchronization dynamics that favor convergence toward a dominant mode, a behavior associated with representation collapse and attention sink phenomena. We introduce Krause Attention, a principled attention mechanism inspired by bounded-confidence consensus dynamics. Krause Attention replaces similarity-based global aggregation with distance-based, localized, and selectively sparse interactions, promoting structured local synchronization instead of global mixing. We relate this behavior to recent theory modeling Transformer dynamics as interacting particle systems, and show how bounded-confidence interactions naturally moderate attention concentration and alleviate attention sinks. Restricting interactions to local neighborhoods also reduces runtime complexity from quadratic to linear in sequence length. Experiments across vision (ViT on CIFAR/ImageNet), autoregressive generation (MNIST/CIFAR-10), and large language models (Llama/Qwen) demonstrate consistent gains with substantially reduced computation, highlighting bounded-confidence dynamics as a scalable and effective inductive bias for attention.", "AI": {"tldr": "提出了一种新的注意力机制Krause Attention，通过局部化的稀疏交互来替代全局的自注意力机制，以减轻表示坍塌和注意力陷落的问题。", "motivation": "传统的Transformer中，所有标记在全球范围内竞争影响力，导致了强烈的同步动态行为，并引起代表崩溃和注意力陷落现象。新的注意力机制旨在解决这些问题并减少计算复杂度。", "method": "Krause Attention采用了基于距离的局部交互方式，仅在局部邻域内进行稀疏互动，从而降低了运行时间复杂性从序列长度的平方到线性。", "result": "实验结果表明，在视觉（ViT）、自回归生成和大型语言模型等多个领域中，新的注意力机制表现出了显著的优势，并且计算成本大幅减少。", "conclusion": "Krause Attention通过局部化、稀疏交互减轻了表示坍塌和注意力陷落现象，证明了其作为有效的归纳偏差在Transformer中的广泛应用前景。"}}
{"id": "2602.11533", "pdf": "https://arxiv.org/pdf/2602.11533", "abs": "https://arxiv.org/abs/2602.11533", "authors": ["Zhihang Yuan", "Zhiyuan Liu", "Mahesh K. Marina"], "title": "AltTS: A Dual-Path Framework with Alternating Optimization for Multivariate Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Multivariate time series forecasting involves two qualitatively distinct factors: (i) stable within-series autoregressive (AR) dynamics, and (ii) intermittent cross-dimension interactions that can become spurious over long horizons. We argue that fitting a single model to capture both effects creates an optimization conflict: the high-variance updates needed for cross-dimension modeling can corrupt the gradients that support autoregression, resulting in brittle training and degraded long-horizon accuracy. To address this, we propose ALTTS, a dual-path framework that explicitly decouples autoregression and cross-relation (CR) modeling. In ALTTS, the AR path is instantiated with a linear predictor, while the CR path uses a Transformer equipped with Cross-Relation Self-Attention (CRSA); the two branches are coordinated via alternating optimization to isolate gradient noise and reduce cross-block interference. Extensive experiments on multiple benchmarks show that ALTTS consistently outperforms prior methods, with the most pronounced improvements on long-horizon forecasting. Overall, our results suggest that carefully designed optimization strategies, rather than ever more complex architectures, can be a key driver of progress in multivariate time series forecasting.", "AI": {"tldr": "提出了一种用于多变量时间序列预测的双路径框架AltTS，通过交替优化分离自回归和跨维度交互。", "motivation": "单一模型捕捉稳定的时间序列内部关系和间歇性的跨维度互动会导致训练不稳定，并降低长周期预测精度。因此需要一种新的方法来解决这个问题。", "method": "提出了一种双路径框架AltTS，其中包括一个线性自回归路径和一个带有交叉关系自我注意机制的Transformer路径，这两条路径通过交替优化协调以减少梯度噪声。", "result": "实验结果表明，与先前的方法相比，ALTTS在多变量时间序列预测上具有更好的性能，特别是在长周期预测中表现更加突出。", "conclusion": "精心设计的优化策略可以成为推动多变量时间序列预测领域发展的关键因素。"}}
{"id": "2602.11528", "pdf": "https://arxiv.org/pdf/2602.11528", "abs": "https://arxiv.org/abs/2602.11528", "authors": ["Dong Yan", "Jian Liang", "Ran He", "Tieniu Tan"], "title": "Stop Tracking Me! Proactive Defense Against Attribute Inference Attack in LLMs", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": "Accepted at ICLR 2026", "summary": "Recent studies have shown that large language models (LLMs) can infer private user attributes (e.g., age, location, gender) from user-generated text shared online, enabling rapid and large-scale privacy breaches. Existing anonymization-based defenses are coarse-grained, lacking word-level precision in anonymizing privacy-leaking elements. Moreover, they are inherently limited as altering user text to hide sensitive cues still allows attribute inference to occur through models' reasoning capabilities. To address these limitations, we propose a unified defense framework that combines fine-grained anonymization (TRACE) with inference-preventing optimization (RPS). TRACE leverages attention mechanisms and inference chain generation to identify and anonymize privacy-leaking textual elements, while RPS employs a lightweight two-stage optimization strategy to induce model rejection behaviors, thereby preventing attribute inference. Evaluations across diverse LLMs show that TRACE-RPS reduces attribute inference accuracy from around 50\\% to below 5\\% on open-source models. In addition, our approach offers strong cross-model generalization, prompt-variation robustness, and utility-privacy tradeoffs. Our code is available at https://github.com/Jasper-Yan/TRACE-RPS.", "AI": {"tldr": "本文提出了一种结合细粒度匿名化和推理阻止优化的统一防御框架，以对抗大型语言模型中的属性推断攻击。", "motivation": "现有基于匿名化的防御方法过于粗略，无法精确到词级别，并且即使改变了用户文本也无法完全防止通过模型推理能力进行属性推测。因此，需要一种新的防御策略来应对这些问题。", "method": "该框架包括两个部分：TRACE和RPS。TRACE利用注意力机制生成推断链条来识别并匿名化隐私泄露的文本元素；而RPS使用轻量级两阶段优化策略诱导模型拒绝行为，从而防止属性推测。", "result": "在多种大型语言模型上的评估表明，该框架将开放源代码模型中属性推测准确率从约50%降低到低于5%，并且具有较强的跨模型泛化能力、提示变化鲁棒性和隐私-效用权衡。", "conclusion": "本文提出了一种能够有效对抗大型语言模型中属性推断攻击的防御框架，展示了其在保护用户隐私方面的强大效果。"}}
{"id": "2602.11527", "pdf": "https://arxiv.org/pdf/2602.11527", "abs": "https://arxiv.org/abs/2602.11527", "authors": ["Jiawei Zhu", "Wei Chen", "Ruichu Cai"], "title": "CausalAgent: A Conversational Multi-Agent System for End-to-End Causal Inference", "categories": ["cs.AI"], "comment": "Accepted by IUI 2026", "summary": "Causal inference holds immense value in fields such as healthcare, economics, and social sciences. However, traditional causal analysis workflows impose significant technical barriers, requiring researchers to possess dual backgrounds in statistics and computer science, while manually selecting algorithms, handling data quality issues, and interpreting complex results. To address these challenges, we propose CausalAgent, a conversational multi-agent system for end-to-end causal inference. The system innovatively integrates Multi-Agent Systems (MAS), Retrieval-Augmented Generation (RAG), and the Model Context Protocol (MCP) to achieve automation from data cleaning and causal structure learning to bias correction and report generation through natural language interaction. Users need only upload a dataset and pose questions in natural language to receive a rigorous, interactive analysis report. As a novel user-centered human-AI collaboration paradigm, CausalAgent explicitly models the analysis workflow. By leveraging interactive visualizations, it significantly lowers the barrier to entry for causal analysis while ensuring the rigor and interpretability of the process.", "AI": {"tldr": "提出了一种对话式多智能体系统CausalAgent，用于端到端的因果推理。", "motivation": "传统的因果分析工作流程对技术要求高，并且需要统计学和计算机科学背景的研究人员手动选择算法、处理数据质量等问题。", "method": "CausalAgent结合了多代理系统（MAS）、检索增强生成（RAG）以及模型上下文协议（MCP），实现了从数据清洗到因果结构学习再到偏差校正及报告生成的自动化流程，通过自然语言交互完成。", "result": "用户只需上传数据集并通过自然语言提问即可获得详细的分析报告。此系统显著降低了进入门槛，确保了过程的严谨性和可解释性。", "conclusion": "CausalAgent作为人机协作的新范式，能够提供更加高效、准确且易于理解的因果推理方案。"}}
{"id": "2602.11524", "pdf": "https://arxiv.org/pdf/2602.11524", "abs": "https://arxiv.org/abs/2602.11524", "authors": ["Congmin Zheng", "Xiaoyun Mo", "Xinbei Ma", "Qiqiang Lin", "Yin Zhao", "Jiachen Zhu", "Xingyu Lou", "Jun Wang", "Zhaoxiang Wang", "Weiwen Liu", "Zhuosheng Zhang", "Yong Yu", "Weinan Zhang"], "title": "Adaptive Milestone Reward for GUI Agents", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement Learning (RL) has emerged as a mainstream paradigm for training Mobile GUI Agents, yet it struggles with the temporal credit assignment problem inherent in long-horizon tasks. A primary challenge lies in the trade-off between reward fidelity and density: outcome reward offers high fidelity but suffers from signal sparsity, while process reward provides dense supervision but remains prone to bias and reward hacking. To resolve this conflict, we propose the Adaptive Milestone Reward (ADMIRE) mechanism. ADMIRE constructs a verifiable, adaptive reward system by anchoring trajectory to milestones, which are dynamically distilled from successful explorations. Crucially, ADMIRE integrates an asymmetric credit assignment strategy that denoises successful trajectories and scaffolds failed trajectories. Extensive experiments demonstrate that ADMIRE consistently yields over 10% absolute improvement in success rate across different base models on AndroidWorld. Moreover, the method exhibits robust generalizability, achieving strong performance across diverse RL algorithms and heterogeneous environments such as web navigation and embodied tasks.", "AI": {"tldr": "本文提出了自适应里程碑奖励机制（ADMIRE），以解决强化学习在训练移动GUI代理时遇到的时间信用分配问题。", "motivation": "强化学习在处理长时间任务时面临时间信用分配的问题，特别是奖励的准确性和密度之间的权衡。", "method": "ADMIRE通过将轨迹锚定到动态提取的成功探索里程碑上，构建了一个可验证、自适应的奖励系统，并结合了不对称的信用分配策略。", "result": "实验结果表明，在AndroidWorld中，ADMIRE在不同基础模型下成功率达到10%以上的绝对改进。该方法还展示了对各种强化学习算法和异构环境的强大泛化能力。", "conclusion": "ADMIRE解决了奖励准确性和密度之间的权衡问题，提高了移动GUI代理的成功率，并展现了广泛的适用性。"}}
{"id": "2602.11522", "pdf": "https://arxiv.org/pdf/2602.11522", "abs": "https://arxiv.org/abs/2602.11522", "authors": ["Dennis Kim", "Roya Daneshi", "Bruce Draper", "Sarath Sreedharan"], "title": "Implications of AI Involvement for Trust in Expert Advisory Workflows Under Epistemic Dependence", "categories": ["cs.HC"], "comment": null, "summary": "The increasing integration of AI-powered tools into expert workflows, such as medicine, law, and finance, raises a critical question: how does AI involvement influence a user's trust in the human expert, the AI system, and their combination? To investigate this, we conducted a user study (N=77) featuring a simulated course-planning task. We compared various conditions that differed in both the presence of AI and the specific mode of human-AI collaboration. Our results indicate that while the advisor's ability to create a correct schedule is important, the user's perception of expertise and trust is also influenced by how the expert utilized the AI assistant. These findings raise important considerations for the design of human-AI hybrid teams, particularly when the adoption of recommendations depends on the end-user's perception of the recommender's expertise.", "AI": {"tldr": "研究探讨了AI在专家工作流程中的作用如何影响用户对人类专家和AI系统的信任。", "motivation": "随着AI工具的集成，需要了解这种技术介入如何改变用户对专家及其建议的信任。", "method": "通过一个模拟课程规划任务进行用户研究（N=77），比较了不同条件下的人与AI合作模式。", "result": "结果显示用户的信任不仅取决于顾问创建正确日程的能力，还受到如何使用AI助手的影响。", "conclusion": "这些发现对设计人机混合团队提出了重要考虑，特别是当建议的采纳依赖于用户对推荐者的专业知识感知时。"}}
{"id": "2602.11520", "pdf": "https://arxiv.org/pdf/2602.11520", "abs": "https://arxiv.org/abs/2602.11520", "authors": ["Yasin Khadem Charvadeh", "Katherine S. Panageas", "Yuan Chen"], "title": "Locally Interpretable Individualized Treatment Rules for Black-Box Decision Models", "categories": ["stat.ME", "cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "Individualized treatment rules (ITRs) aim to optimize healthcare by tailoring treatment decisions to patient-specific characteristics. Existing methods typically rely on either interpretable but inflexible models or highly flexible black-box approaches that sacrifice interpretability; moreover, most impose a single global decision rule across patients. We introduce the Locally Interpretable Individualized Treatment Rule (LI-ITR) method, which combines flexible machine learning models to accurately learn complex treatment outcomes with locally interpretable approximations to construct subject-specific treatment rules. LI-ITR employs variational autoencoders to generate realistic local synthetic samples and learns individualized decision rules through a mixture of interpretable experts. Simulation studies show that LI-ITR accurately recovers true subject-specific local coefficients and optimal treatment strategies. An application to precision side-effect management in breast cancer illustrates the necessity of flexible predictive modeling and highlights the practical utility of LI-ITR in estimating optimal treatment rules while providing transparent, clinically interpretable explanations.", "AI": {"tldr": "提出了一种局部可解释的个性化治疗规则方法（LI-ITR），结合灵活的机器学习模型和局部解释近似，为每位患者构建个性化的治疗方法。", "motivation": "现有方法通常依赖于可解释但不灵活的模型或牺牲可解释性的高度灵活的黑盒方法，并且大多数只采用一个全局决策规则。为了克服这些限制，提出了一种新的个性化治疗规则方法。", "method": "LI-ITR 方法使用变分自动编码器生成现实的局部合成样本，通过混合可解释专家学习个体化决策规则。", "result": "模拟研究显示，LI-ITR 准确恢复了真正的患者特定本地系数和最佳治疗策略。在乳腺癌精确副作用管理的应用中展示了该方法的实际效用。", "conclusion": "LI-ITR 方法能够在估计最优治疗方案的同时提供透明且临床可解释的说明，证明了其在个性化医疗中的重要性。"}}
{"id": "2602.11517", "pdf": "https://arxiv.org/pdf/2602.11517", "abs": "https://arxiv.org/abs/2602.11517", "authors": ["Renan Favero", "Lily Elefteriadou"], "title": "Calibration and Evaluation of Car-Following Models for Autonomous Shuttles Using a Novel Multi-Criteria Framework", "categories": ["cs.ET", "cs.LG"], "comment": null, "summary": "Autonomous shuttles (AS) are fully autonomous transit vehicles with operating characteristics distinct from conventional autonomous vehicles (AV). Developing dedicated car-following models for AS is critical to understanding their traffic impacts; however, few studies have calibrated such models with field data. More advanced machine learning (ML) techniques have not yet been applied to AS trajectories, leaving the potential of ML for capturing AS dynamics unexplored and constraining the development of dedicated AS models. Furthermore, there is a lack of a unified framework for systematically evaluating and comparing the performance of car-following models to replicate real trajectories. Existing car-following studies often rely on disparate metrics, which limit reproducibility and performance comparability. This study addresses these gaps through two main contributions: (1) the calibration of a diverse set of car-following models using real-world AS trajectory data, including eight machine learning algorithms and two physics-based models; and (2) the introduction of a multi-criteria evaluation framework that integrates measures of prediction accuracy, trajectory stability, and statistical similarity, which provides a generalizable methodology for a systematic assessment of car-following models. Results indicated that the proposed calibrated XGBoost model achieved the best overall performance. Sequential model type, such as LSTM and CNN, captured long-term positional stability but were less responsive to short-term dynamics. LSTM and CNN captured long-term positional stability but were less responsive to short-term dynamics. Traditional models (IDM, ACC) and kernel methods showed lower accuracy and stability than most ML models tested.", "AI": {"tldr": "本文通过使用实际的自主穿梭车辆轨迹数据校准了一系列的汽车跟随模型，并引入了一个多标准评估框架，以系统地评估这些模型。", "motivation": "自动驾驶穿梭车（AS）具有独特的操作特性，在理解其交通影响方面需要专门的汽车跟随模型。然而，很少有研究利用现场数据来校准此类模型，而且缺乏一个统一的框架来评估和比较汽车跟随模型的表现。", "method": "该论文使用八种机器学习算法和两种物理基础模型对一系列汽车跟随模型进行了校准，并引入了一个多标准评价框架，其中包括预测准确度、轨迹稳定性和统计相似性的指标。", "result": "结果显示，提出的XGBoost模型表现最佳。序列模型（如LSTM和CNN）在捕捉长期位置稳定性方面表现出色，但在应对短期动态变化时反应较慢。", "conclusion": "本文通过使用实际数据校准了多种汽车跟随模型，并提出了一种多标准评估框架来系统性地评价这些模型的性能，有助于开发专门用于自动驾驶穿梭车的模型。"}}
{"id": "2602.11516", "pdf": "https://arxiv.org/pdf/2602.11516", "abs": "https://arxiv.org/abs/2602.11516", "authors": ["Hong Su"], "title": "Human-Inspired Continuous Learning of Internal Reasoning Processes: Learning How to Think for Adaptive AI Systems", "categories": ["cs.AI"], "comment": null, "summary": "Learning internal reasoning processes is crucial for developing AI systems capable of sustained adaptation in dynamic real-world environments. However, most existing approaches primarily emphasize learning task-specific outputs or static knowledge representations, while overlooking the continuous refinement of internal reasoning structures, action scheduling policies, and learning mechanisms themselves. In this paper, we propose a human-inspired continuous learning framework that unifies reasoning, action, reflection, and verification within a sequential reasoning model enhanced by parallel learning. The framework explicitly treats internal thinking processes as primary learning objects. It systematically records internal reasoning trajectories and environmental interactions as structured learning material, enabling the system to optimize not only task-level content but also the organization, scheduling, and evolution of reasoning activities. This design realizes learning alongside processing, allowing cognitive structures to improve during execution. Furthermore, the framework supports controlled replacement of predefined logic with learned procedures and introduces a hierarchical learning-to-learn mechanism that jointly adapts task-level parameters and learning strategies. As a result, the system progressively evolves its internal cognitive architecture while preserving operational stability. Experimental results on a temperature sensor abnormality detection task show that incorporating internal-process learning reduces average runtime by 23.9%.", "AI": {"tldr": "本文提出了一种人类启发式的连续学习框架，该框架将推理、行为、反思和验证统一在一个增强的序列模型中，以优化任务层次的内容以及推理活动的组织、调度与进化。", "motivation": "现有AI系统主要关注特定任务输出或静态知识表示的学习，而忽视了内部推理结构、行动规划政策及学习机制本身的持续改进。本文旨在解决这一问题，开发一种能够适应动态环境并不断优化自身认知架构的AI系统。", "method": "提出了一种将推理、行为反思和验证统一在一个序列模型中的框架，并引入了一个平行学习增强机制。该方法记录内部推理轨迹和环境交互作为结构化学习材料，允许在执行过程中改善认知结构，并支持预定义逻辑与学习程序之间的转换以及分层的学习策略。", "result": "实验结果显示，在温度传感器异常检测任务中，采用此框架能够将平均运行时间减少23.9%。", "conclusion": "本文所提出的连续学习框架允许AI系统在其执行过程中持续优化其内部认知架构，并保持操作稳定性。"}}
{"id": "2602.11514", "pdf": "https://arxiv.org/pdf/2602.11514", "abs": "https://arxiv.org/abs/2602.11514", "authors": ["Sidong Feng", "Chunyang Chen"], "title": "How Smart Is Your GUI Agent? A Framework for the Future of Software Interaction", "categories": ["cs.SE", "cs.AI", "cs.CV", "cs.HC"], "comment": null, "summary": "GUI agents are rapidly becoming a new interaction to software, allowing people to navigate web, desktop and mobile rather than execute them click by click. Yet ``agent'' is described with radically different degrees of autonomy, obscuring capability, responsibility and risk. We call for conceptual clarity through GUI Agent Autonomy Levels (GAL), a six-level framework that makes autonomy explicit and helps benchmark progress toward trustworthy software interaction.", "AI": {"tldr": "该论文提出了一个六级框架（GUI Agent Autonomy Levels，GAL），以明确和评估GUI代理的自主程度。", "motivation": "由于“代理”的定义存在很大差异，使得软件交互中的能力和风险变得模糊不清。此研究旨在通过引入清晰的概念框架来解决这一问题。", "method": "提出了一个六级的GUI Agent Autonomy Levels（GAL）框架，并详细描述了各级别的特征和作用。", "result": "提供了一种明确且可衡量的方式来评估软件交互中GUI代理的自主程度。", "conclusion": "通过引入GAL框架，可以更清晰地理解并信任未来的软件交互方式。"}}
{"id": "2602.11513", "pdf": "https://arxiv.org/pdf/2602.11513", "abs": "https://arxiv.org/abs/2602.11513", "authors": ["Yujie Gu", "Richeng Jin", "Xiaoyu Ji", "Yier Jin", "Wenyuan Xu"], "title": "Differentially Private and Communication Efficient Large Language Model Split Inference via Stochastic Quantization and Soft Prompt", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable performance and received significant research interest. The enormous computational demands, however, hinder the local deployment on devices with limited resources. The current prevalent LLM inference paradigms require users to send queries to the service providers for processing, which raises critical privacy concerns. Existing approaches propose to allow the users to obfuscate the token embeddings before transmission and utilize local models for denoising. Nonetheless, transmitting the token embeddings and deploying local models may result in excessive communication and computation overhead, preventing practical implementation. In this work, we propose \\textbf{DEL}, a framework for \\textbf{D}ifferentially private and communication \\textbf{E}fficient \\textbf{L}LM split inference. More specifically, an embedding projection module and a differentially private stochastic quantization mechanism are proposed to reduce the communication overhead in a privacy-preserving manner. To eliminate the need for local models, we adapt soft prompt at the server side to compensate for the utility degradation caused by privacy. To the best of our knowledge, this is the first work that utilizes soft prompt to improve the trade-off between privacy and utility in LLM inference, and extensive experiments on text generation and natural language understanding benchmarks demonstrate the effectiveness of the proposed method.", "AI": {"tldr": "提出了一种在保护隐私的同时减少通信开销的大型语言模型分割推理框架DEL。", "motivation": "大型语言模型面临着巨大的计算需求，现有的推理范式需要用户向服务提供商发送查询进行处理，这引发了严重的隐私问题。现有方法虽然能够在一定程度上解决这些问题，但仍存在通信和计算负担过大的情况。", "method": "提出了一个包含嵌入投影模块和差异私有随机量化机制的框架DEL，以在保护隐私的情况下降低通信开销，并使用软提示来补偿由于隐私保护导致的性能下降。", "result": "实验结果表明，所提出的方法在文本生成和自然语言理解基准测试中表现出色，证明了其有效性和优越性。", "conclusion": "这是第一个利用软提示改善大型语言模型推理中隐私与效用之间权衡的工作。"}}
{"id": "2602.11510", "pdf": "https://arxiv.org/pdf/2602.11510", "abs": "https://arxiv.org/abs/2602.11510", "authors": ["Faouzi El Yagoubi", "Ranwa Al Mallah", "Godwin Badu-Marfo"], "title": "AgentLeak: A Full-Stack Benchmark for Privacy Leakage in Multi-Agent LLM Systems", "categories": ["cs.AI"], "comment": "17 pages, 10 figures, 13 tables. Code and dataset available at https://github.com/Privatris/AgentLeak", "summary": "Multi-agent Large Language Model (LLM) systems create privacy risks that current benchmarks cannot measure. When agents coordinate on tasks, sensitive data passes through inter-agent messages, shared memory, and tool arguments; pathways that output-only audits never inspect. We introduce AgentLeak, to the best of our knowledge the first full-stack benchmark for privacy leakage covering internal channels, spanning 1,000 scenarios across healthcare, finance, legal, and corporate domains, paired with a 32-class attack taxonomy and three-tier detection pipeline. Testing GPT-4o, GPT-4o-mini, Claude 3.5 Sonnet, Mistral Large, and Llama 3.3 70B across 4,979 traces reveals that multi-agent configurations reduce per-channel output leakage (C1: 27.2% vs 43.2% in single-agent) but introduce unmonitored internal channels that raise total system exposure to 68.9% (OR-aggregated across C1, C2, C5). Internal channels account for most of this gap: inter-agent messages (C2) leak at 68.8%, compared to 27.2% on C1 (output channel). This means that output-only audits miss 41.7% of violations. Claude 3.5 Sonnet, which emphasizes safety alignment in its design, achieves the lowest leakage rates on both external (3.3%) and internal (28.1%) channels, suggesting that model-level safety training may transfer to internal channel protection. Across all five models and four domains, the pattern C2 > C1 holds consistently, confirming that inter-agent communication is the primary vulnerability. These findings underscore the need for coordination frameworks that incorporate internal-channel privacy protections and enforce privacy controls on inter-agent communication.", "AI": {"tldr": "本文提出了一种新的隐私泄漏评估基准AgentLeak，用于检测多代理大型语言模型系统中的内部和外部通道的隐私风险。", "motivation": "当前对多代理LLM系统的隐私风险缺乏有效的测量方法。为了填补这一空白，研究者开发了全面的隐私泄露评估工具AgentLeak。", "method": "通过构建涵盖1000个不同场景和32类攻击分类学的基准测试集，并利用三阶段检测管道来评估GPT-4o等五种模型在多代理配置下的性能。", "result": "实验表明，虽然多代理配置减少了输出通道泄漏，但增加了内部通信渠道的风险。Claude 3.5 Sonnet因其安全性设计，在所有被测模型中表现出最低的隐私泄露率。", "conclusion": "研究结果强调了需要开发包含对内部和外部通信保护框架来确保多代理LLM系统的隐私安全。"}}
{"id": "2602.11509", "pdf": "https://arxiv.org/pdf/2602.11509", "abs": "https://arxiv.org/abs/2602.11509", "authors": ["David Wan", "Han Wang", "Ziyang Wang", "Elias Stengel-Eskin", "Hyunji Lee", "Mohit Bansal"], "title": "Multimodal Fact-Level Attribution for Verifiable Reasoning", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "29 pages. Code and data are available at https://github.com/meetdavidwan/murgat", "summary": "Multimodal large language models (MLLMs) are increasingly used for real-world tasks involving multi-step reasoning and long-form generation, where reliability requires grounding model outputs in heterogeneous input sources and verifying individual factual claims. However, existing multimodal grounding benchmarks and evaluation methods focus on simplified, observation-based scenarios or limited modalities and fail to assess attribution in complex multimodal reasoning. We introduce MuRGAt (Multimodal Reasoning with Grounded Attribution), a benchmark for evaluating fact-level multimodal attribution in settings that require reasoning beyond direct observation. Given inputs spanning video, audio, and other modalities, MuRGAt requires models to generate answers with explicit reasoning and precise citations, where each citation specifies both modality and temporal segments. To enable reliable assessment, we introduce an automatic evaluation framework that strongly correlates with human judgments. Benchmarking with human and automated scores reveals that even strong MLLMs frequently hallucinate citations despite correct reasoning. Moreover, we observe a key trade-off: increasing reasoning depth or enforcing structured grounding often degrades accuracy, highlighting a significant gap between internal reasoning and verifiable attribution.", "AI": {"tldr": "本文介绍了MuRGAt基准，用于评估多模态推理中的事实级别归因能力。", "motivation": "现有评价标准仅适用于简单观察场景或单一模态输入，无法准确度量复杂情境下的多模态推理归因性能。", "method": "引入了MuRGAt数据集和自动评估框架来测试模型在面对视频、音频等多模态输入时的精确引证能力。", "result": "实验表明强大的多模态语言模型仍会在正确推理的同时出现错误引用现象，揭示出内部逻辑与可验证归因之间的差距。", "conclusion": "发现了一个关键的权衡：增加推理深度或强制结构化归因通常会降低准确率，指出了未来研究的方向。"}}
{"id": "2602.11507", "pdf": "https://arxiv.org/pdf/2602.11507", "abs": "https://arxiv.org/abs/2602.11507", "authors": ["Ryuji Matsuo", "Hailong Liu", "Toshihiro Hiraoka", "Takahiro Wada"], "title": "An Educational Human Machine Interface Providing Request-to-Intervene Trigger and Reason Explanation for Enhancing the Driver's Comprehension of ADS's System Limitations", "categories": ["cs.HC"], "comment": null, "summary": "Level 3 automated driving systems (ADS) have attracted significant attention and are being commercialized. A level 3 ADS prompts the driver to take control by issuing a request to intervene (RtI) when its operational design domains (ODD) are exceeded. However, complex traffic situations can cause drivers to perceive multiple potential triggers of RtI simultaneously, causing hesitation or confusion during take-over. Therefore, drivers need to clearly understand the ADS's system limitations to ensure safe take-over. This study proposes a voice-based educational human machine interface~(HMI) for providing RtI trigger cues and reason to help drivers understand ADS's system limitations. The results of a between-group experiment using a driving simulator showed that incorporating effective trigger cues and reason into the RtI was related to improved driver comprehension of the ADS's system limitations. Moreover, most participants, instructed via the proposed method, could proactively take over control of the ADS in cases where RtI fails; meanwhile, their number of collisions was lower compared with the other RtI HMI conditions. Therefore, using the proposed method to continually enhance the driver's understanding of the system limitations of ADS through the proposed method is associated with safer and more effective real-time interactions with ADS.", "AI": {"tldr": "提出了一种基于语音的教育人机接口，用于在自动驾驶系统请求驾驶员接管时提供触发线索和原因解释，以提高驾驶员对系统的理解。", "motivation": "为了解决复杂交通情况下驾驶员对于多潜在触发因素造成的困惑与犹豫问题，提升驾驶员在遇到自动驾驶系统超出其设计运行域（ODD）范围时的安全接管能力。", "method": "通过驾驶模拟器实验，在不同组别中比较了带有有效触发线索和原因说明的请求接管（RtI）界面与其他条件下的表现。", "result": "实验结果表明，采用提议方法能够显著提升驾驶员对自动驾驶系统限制的理解；并且大多数参与者在面临RtI失败的情况下可以主动接管车辆控制，减少了碰撞次数。", "conclusion": "通过持续利用该方法提高驾驶员对ADS的系统限制理解，有助于实现与ADS更安全有效的实时互动。"}}
{"id": "2602.11506", "pdf": "https://arxiv.org/pdf/2602.11506", "abs": "https://arxiv.org/abs/2602.11506", "authors": ["Zhen Bi", "Xueshu Chen", "Luoyang Sun", "Yuhang Yao", "Qing Shen", "Jungang Lou", "Cheng Deng"], "title": "RooflineBench: A Benchmarking Framework for On-Device LLMs via Roofline Analysis", "categories": ["cs.LG", "cs.AI", "cs.AR", "cs.PF"], "comment": null, "summary": "The transition toward localized intelligence through Small Language Models (SLMs) has intensified the need for rigorous performance characterization on resource-constrained edge hardware. However, objectively measuring the theoretical performance ceilings of diverse architectures across heterogeneous platforms remains a formidable challenge. In this work, we propose a systematic framework based on the Roofline model that unifies architectural primitives and hardware constraints through the lens of operational intensity (OI). By defining an inference-potential region, we introduce the Relative Inference Potential as a novel metric to compare efficiency differences between Large Language Models (LLMs) on the same hardware substrate. Extensive empirical analysis across diverse compute tiers reveals that variations in performance and OI are significantly influenced by sequence length. We further identify a critical regression in OI as model depth increases. Additionally, our findings highlight an efficiency trap induced by hardware heterogeneity and demonstrate how structural refinements, such as Multi-head Latent Attention (M LA), can effectively unlock latent inference potential across various hardware substrates. These insights provide actionable directions for hardware-software co-design to align neural structures with physical constraints in on-device intelligence. The released code is available in the Appendix C.", "AI": {"tldr": "本文提出了一种基于Roofline模型的基准测试框架，用于在资源受限边缘硬件上评估大型语言模型（LLMs）的性能。", "motivation": "随着小型语言模型向局部智能转变，在异构平台上准确测量不同架构的理论性能上限成为一项挑战。为了解决这一问题，本文提出了一个基于Roofline模型的系统框架来统一建筑基础和硬件约束。", "method": "通过定义推理潜力区域并引入相对推理潜力作为衡量效率差异的新指标，作者进行了广泛的实证分析以揭示序列长度对性能和操作强度的影响，并识别出随着模型深度增加的操作强度下降趋势。", "result": "研究发现操作强度随序列长度变化显著，且存在由于硬件异构性导致的效率陷阱。通过结构改进如多头潜在注意力机制（MLA），可以有效解锁不同硬件上的推理潜力。", "conclusion": "这些见解为硬件和软件协同设计提供了可操作的方向，以使神经结构与物理约束相匹配，在设备端智能中实现优化。"}}
{"id": "2602.11499", "pdf": "https://arxiv.org/pdf/2602.11499", "abs": "https://arxiv.org/abs/2602.11499", "authors": ["Zhenlong Yuan", "Xiangyan Qu", "Jing Tang", "Rui Chen", "Lei Sun", "Ruidong Chen", "Hongwei Yu", "Chengxuan Qian", "Xiangxiang Chu", "Shuo Li", "Yuyin Zhou"], "title": "What if Agents Could Imagine? Reinforcing Open-Vocabulary HOI Comprehension through Generation", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal Large Language Models have shown promising capabilities in bridging visual and textual reasoning, yet their reasoning capabilities in Open-Vocabulary Human-Object Interaction (OV-HOI) are limited by cross-modal hallucinations and occlusion-induced ambiguity. To address this, we propose \\textbf{ImagineAgent}, an agentic framework that harmonizes cognitive reasoning with generative imagination for robust visual understanding. Specifically, our method innovatively constructs cognitive maps that explicitly model plausible relationships between detected entities and candidate actions. Subsequently, it dynamically invokes tools including retrieval augmentation, image cropping, and diffusion models to gather domain-specific knowledge and enriched visual evidence, thereby achieving cross-modal alignment in ambiguous scenarios. Moreover, we propose a composite reward that balances prediction accuracy and tool efficiency. Evaluations on SWIG-HOI and HICO-DET datasets demonstrate our SOTA performance, requiring approximately 20\\% of training data compared to existing methods, validating our robustness and efficiency.", "AI": {"tldr": "本文提出了一种名为ImagineAgent的框架，通过认知推理和生成想象力来改善多模态大型语言模型在开放词汇人类对象交互（OV-HOI）中的视觉理解能力。", "motivation": "现有的多模态大语言模型在处理交叉模式幻觉和由遮挡引起的模糊性时，在开放词汇HOI任务上的表现有限，因此本文提出ImagineAgent来解决这些问题。", "method": "通过构建认知地图，明确建模检测到的实体与候选行动之间的可能关系，并利用检索增强、图像裁剪和扩散模型等工具收集特定领域的知识和丰富的视觉证据。同时提出了一个平衡预测准确性和工具效率的综合奖励机制。", "result": "在SWIG-HOI和HICO-DET数据集上的评估显示，本文方法达到了SOTA性能，只需要现有方法训练数据的大约20%，验证了其鲁棒性和高效性。", "conclusion": "ImagineAgent通过认知推理与生成想象力的有效结合，在解决开放词汇HOI任务中的交叉模式幻觉和模糊性问题上取得了显著进展。"}}
{"id": "2602.11494", "pdf": "https://arxiv.org/pdf/2602.11494", "abs": "https://arxiv.org/abs/2602.11494", "authors": ["Yufan Liu", "Daoyuan Ren", "Zhipeng Zhang", "Wenyang Luo", "Bing Li", "Weiming Hu", "Stephen Maybank"], "title": "Arbitrary Ratio Feature Compression via Next Token Prediction", "categories": ["cs.CV"], "comment": null, "summary": "Feature compression is increasingly important for improving the efficiency of downstream tasks, especially in applications involving large-scale or multi-modal data. While existing methods typically rely on dedicated models for achieving specific compression ratios, they are often limited in flexibility and generalization. In particular, retraining is necessary when adapting to a new compression ratio. To address this limitation, we propose a novel and flexible Arbitrary Ratio Feature Compression (ARFC) framework, which supports any compression ratio with a single model, eliminating the need for multiple specialized models. At its core, the Arbitrary Ratio Compressor (ARC) is an auto-regressive model that performs compression via next-token prediction. This allows the compression ratio to be controlled at inference simply by adjusting the number of generated tokens. To enhance the quality of the compressed features, two key modules are introduced. The Mixture of Solutions (MoS) module refines the compressed tokens by utilizing multiple compression results (solutions), reducing uncertainty and improving robustness. The Entity Relation Graph Constraint (ERGC) is integrated into the training process to preserve semantic and structural relationships during compression. Extensive experiments on cross-modal retrieval, image classification, and image retrieval tasks across multiple datasets demonstrate that our method consistently outperforms existing approaches at various compression ratios. Notably, in some cases, it even surpasses the performance of the original, uncompressed features. These results validate the effectiveness and versatility of ARFC for practical, resource-constrained scenarios.", "AI": {"tldr": "提出了一种灵活的任意比例特征压缩框架ARFC，通过单一模型支持任何压缩比。", "motivation": "现有方法在实现特定压缩比率时需要专门训练模型，缺乏灵活性和泛化能力。为了克服这一限制，作者提出了可以适应各种压缩率而不需重新训练的新方法。", "method": "核心是自回归的任意比例压缩器ARC，通过下个令牌预测进行压缩；引入混合解决方案MoS模块来改进压缩后的特征质量，并整合实体关系图约束ERGC以保持压缩过程中的语义和结构关系。", "result": "实验结果表明，在跨模态检索、图像分类及图像检索任务中，ARFC在各种压缩比率下都优于现有方法，有时甚至超过未压缩的原始特性。", "conclusion": "通过单一模型实现任意比例特征压缩的有效性和实用性得到了验证"}}
{"id": "2602.11492", "pdf": "https://arxiv.org/pdf/2602.11492", "abs": "https://arxiv.org/abs/2602.11492", "authors": ["Ryota Takamido", "Chiharu Suzuki", "Hiroki Nakamoto"], "title": "Data-driven modelling of low-dimensional dynamical structures underlying complex full-body human movement", "categories": ["cs.HC"], "comment": ":68T99ACM Class:J.3; H.4", "summary": "One of the central challenges in the study of human motor control and learning is the degrees-of-freedom problem. Although the dynamical systems approach (DSA) has provided valuable insights into addressing this issue, its application has largely been confined to cyclic or simplified motor movements. To overcome this limitation, the present study employs neural ordinary differential equations (NODEs) to model the time evolution of non-cyclic full-body movements as a low-dimensional latent dynamical system. Given the temporal complexity full-body kinematic chains, baseball pitching was selected as a representative target movement to examine whether DSA could be extended to more complex, ecologically valid human movements. Results of the verification experiment demonstrated that the time evolution of a complex pitching motion could be accurately predicted (R^2 > 0.45) using the NODE-based dynamical model. Notably, approximately 50% of the variance in the latter half of the pitching motion was explained using only the initial ~8% of the temporal sequence, underscoring how subsequent movement evolves from initial conditions according to ODE-defined dynamics in latent space. These findings indicate the potential to extend the DSA to more complex and ecologically valid forms of human movement.", "AI": {"tldr": "利用神经常微分方程（NODE）建模复杂全身体动的低维动态结构", "motivation": "解决人类运动控制和学习中的自由度问题，将动力系统方法扩展到更复杂的现实动作中", "method": "使用NODE基于时间序列数据预测复杂的投球动作动态，并验证模型效果", "result": "NODE模型能够准确预测复杂的投球动作（R^2>0.45），并展示初始条件如何影响后续运动的演变", "conclusion": "表明DSA可以应用于更多复杂和现实的人类运动"}}
{"id": "2602.11488", "pdf": "https://arxiv.org/pdf/2602.11488", "abs": "https://arxiv.org/abs/2602.11488", "authors": ["Jayadev Billa"], "title": "When Audio-LLMs Don't Listen: A Cross-Linguistic Study of Modality Arbitration", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "25 pages, 18 tables, 8 languages, benchmark and code at https://github.com/jb1999/alme-benchmark", "summary": "When audio and text conflict, speech-enabled language models follow the text 10 times more often than when arbitrating between two text sources, even when explicitly instructed to trust the audio. Using ALME, a benchmark of 57,602 controlled audio-text conflict stimuli across 8 languages, we find that Gemini 2.0 Flash exhibits 16.6\\% text dominance under audio-text conflict versus 1.6\\% under text-text conflict with identical reliability cues. This gap is not explained by audio quality: audio-only accuracy (97.2\\%) exceeds cascade accuracy (93.9\\%), indicating audio embeddings preserve more information than text transcripts. We propose that text dominance reflects an asymmetry not in information content but in arbitration accessibility: how easily the model can reason over competing representations. This framework explains otherwise puzzling findings. Forcing transcription before answering increases text dominance (19\\% to 33\\%), sacrificing audio's information advantage without improving accessibility. Framing text as ``deliberately corrupted'' reduces text dominance by 80\\%. A fine-tuning ablation provides interventional evidence: training only the audio projection layer increases text dominance (+26.5\\%), while LoRA on the language model halves it ($-$23.9\\%), localizing text dominance to the LLM's reasoning rather than the audio encoder. Experiments across four state-of-the-art audio-LLMs and 8 languages show consistent trends with substantial cross-linguistic and cross-model variation, establishing modality arbitration as a distinct reliability dimension not captured by standard speech benchmarks.", "AI": {"tldr": "研究了语言模型在音频文本冲突时偏向文字的原因和机制。", "motivation": "探索为何语言模型在处理音频与文本的矛盾信息时，倾向于信任文本而非高质量的音频输入。", "method": "使用ALME基准测试集进行对比实验，包括对不同语言、各种模型的交叉验证；通过改变问题设定和训练策略来探究影响因素。", "result": "发现Gemini2.0Flash在处理音频-文本冲突时表现出明显偏向文字的行为（16.6%），远高于文本-文本冲突情况下的偏差（1.6%）；实验表明这种偏好并非源自信息量差异，而是模型对于不同表示形式的推理难度。", "conclusion": "确认了语言模型存在一种跨模式仲裁偏见，这为理解和改进多模态系统的可靠性和透明度提供了新的视角和研究方向。"}}
{"id": "2602.11483", "pdf": "https://arxiv.org/pdf/2602.11483", "abs": "https://arxiv.org/abs/2602.11483", "authors": ["Stephan Vonschallen", "Friederike Eyssel", "Theresa Schmiedel"], "title": "Understanding Persuasive Interactions between Generative Social Agents and Humans: The Knowledge-based Persuasion Model (KPM)", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Generative social agents (GSAs) use artificial intelligence to autonomously communicate with human users in a natural and adaptive manner. Currently, there is a lack of theorizing regarding interactions with GSAs, and likewise, few guidelines exist for studying how they influence user attitudes and behaviors. Consequently, we propose the Knowledge-based Persuasion Model (KPM) as a novel theoretical framework. According to the KPM, a GSA's self, user, and context-related knowledge drives its persuasive behavior, which in turn shapes the attitudes and behaviors of a responding human user. By synthesizing existing research, the model offers a structured approach to studying interactions with GSAs, supporting the development of agents that motivate rather than manipulate humans. Accordingly, the KPM encourages the integration of responsible GSAs that adhere to social norms and ethical standards with the goal of increasing user wellbeing. Implications of the KPM for research and application domains such as healthcare and education are discussed.", "AI": {"tldr": "提出了一种基于知识的说服模型（KPM），以解释生成式社会代理与人类用户的互动方式。", "motivation": "现有研究缺乏关于生成式社会代理和用户交互理论以及如何影响用户态度和行为的指导原则，因此提出了一个新型理论框架来填补这一空白。", "method": "通过综合现有的研究，提出了一种新的理论模型KPM，该模型认为生成式社会代理的知识驱动其说服行为并进而塑造人类用户的反应。", "result": "KPM为研究与GSAs的互动提供了结构化的方法，并支持开发激励而非操纵人类的代理人。讨论了KPM在医疗保健和教育等领域的应用及影响。", "conclusion": "该模型鼓励将符合社会规范和伦理标准的生成式社会代理整合到应用程序中，以增强用户福祉"}}
{"id": "2602.11481", "pdf": "https://arxiv.org/pdf/2602.11481", "abs": "https://arxiv.org/abs/2602.11481", "authors": ["Minda Li", "Bhaskar Krishnamachari"], "title": "Compiler-Guided Inference-Time Adaptation: Improving GPT-5 Programming Performance in Idris", "categories": ["cs.PL", "cs.AI"], "comment": null, "summary": "GPT-5, a state of the art large language model from OpenAI, demonstrates strong performance in widely used programming languages such as Python, C++, and Java; however, its ability to operate in low resource or less commonly used languages remains underexplored. This work investigates whether GPT-5 can effectively acquire proficiency in an unfamiliar functional programming language, Idris, through iterative, feedback driven prompting. We first establish a baseline showing that with zero shot prompting the model solves only 22 out of 56 Idris exercises using the platform Exercism, substantially underperforming relative to higher resource languages (45 out of 50 in Python and 35 out of 47 in Erlang). We then evaluate several refinement strategies, including iterative prompting based on platform feedback, augmenting prompts with documentation and error classification guides, and iterative prompting using local compilation errors and failed test cases. Among these approaches, incorporating local compilation errors yields the most substantial improvements. Using this structured, error guided refinement loop, GPT-5 performance increased to an impressive 54 solved problems out of 56. These results suggest that while large language models may initially struggle in low resource settings, structured compiler level feedback can play a critical role in unlocking their capabilities.", "AI": {"tldr": "研究了GPT-5在Idris编程语言中的表现，并通过编译器引导的推理时间适应来提高其性能。", "motivation": "探索大型语言模型如GPT-5在资源有限或不常用的语言中（例如Idris）的能力，以及如何改进其在这些环境下的表现。", "method": "首先建立了一个零样本提示基线测试，在此基础上评估了多种改进策略，包括基于平台反馈的迭代提示、增加文档和错误分类指南，并最终采用了将本地编译错误纳入的迭代提示方法。", "result": "通过使用结构化、以错误为导向的反馈循环，GPT-5在Idris中的表现从最初的22个问题解决了提高到了54个问题解决。", "conclusion": "虽然大型语言模型可能最初难以适应资源有限或不常用的语言环境，但通过结构化的编译器层面反馈可以显著提升其能力。"}}
{"id": "2602.11477", "pdf": "https://arxiv.org/pdf/2602.11477", "abs": "https://arxiv.org/abs/2602.11477", "authors": ["Yifan Liang", "Andong Li", "Kang Yang", "Guochen Yu", "Fangkun Liu", "Lingling Dai", "Xiaodong Li", "Chengshi Zheng"], "title": "SLD-L2S: Hierarchical Subspace Latent Diffusion for High-Fidelity Lip to Speech Synthesis", "categories": ["eess.AS", "cs.CE"], "comment": null, "summary": "Although lip-to-speech synthesis (L2S) has achieved significant progress in recent years, current state-of-the-art methods typically rely on intermediate representations such as mel-spectrograms or discrete self-supervised learning (SSL) tokens. The potential of latent diffusion models (LDMs) in this task remains largely unexplored. In this paper, we introduce SLD-L2S, a novel L2S framework built upon a hierarchical subspace latent diffusion model. Our method aims to directly map visual lip movements to the continuous latent space of a pre-trained neural audio codec, thereby avoiding the information loss inherent in traditional intermediate representations. The core of our method is a hierarchical architecture that processes visual representations through multiple parallel subspaces, initiated by a subspace decomposition module. To efficiently enhance interactions within and between these subspaces, we design the diffusion convolution block (DiCB) as our network backbone. Furthermore, we employ a reparameterized flow matching technique to directly generate the target latent vectors. This enables a principled inclusion of speech language model (SLM) and semantic losses during training, moving beyond conventional flow matching objectives and improving synthesized speech quality. Our experiments show that SLD-L2S achieves state-of-the-art generation quality on multiple benchmark datasets, surpassing existing methods in both objective and subjective evaluations.", "AI": {"tldr": "本文提出了SLD-L2S，一种基于层级子空间潜在扩散模型的唇到语音合成框架。", "motivation": "当前最先进的方法依赖于中间表示如梅尔频谱图或离散自监督学习令牌，在这种任务中，潜在扩散模型的应用尚未充分探索。", "method": "该方法利用一个层次化架构处理视觉表示，并通过多个平行子空间进行操作。引入了扩散卷积块（DiCB）作为网络骨干来增强各个子空间以及它们之间的互动。采用重参数化流动匹配技术直接生成目标潜在向量。", "result": "实验表明，SLD-L2S在多个基准数据集上的生成质量超越现有方法，无论是客观评价还是主观评价都表现出色。", "conclusion": "该研究提出了一种新的唇到语音合成框架SLD-L2S，并通过实验证明了其优越性。"}}
{"id": "2602.11476", "pdf": "https://arxiv.org/pdf/2602.11476", "abs": "https://arxiv.org/abs/2602.11476", "authors": ["R. Jay Martin II"], "title": "Bounded Local Generator Classes for Deterministic State Evolution", "categories": ["cs.OS", "cs.DS"], "comment": "38 pages. Formal operator-class result", "summary": "We formalize a constructive subclass of locality-preserving deterministic operators acting on graph-indexed state systems. We define the class of Bounded Local Generator Classes (BLGC), consisting of finite-range generators operating on bounded state spaces under deterministic composition. Within this class, incremental update cost is independent of total system dimension. We prove that, under the BLGC assumptions, per-step operator work satisfies W_t = O(1) as the number of nodes M \\to \\infty, establishing a structural decoupling between global state size and incremental computational effort. The framework admits a Hilbert-space embedding in \\ell^2(V; \\mathbb{R}^d) and yields bounded operator norms on admissible subspaces. The result applies specifically to the defined subclass and does not claim universality beyond the stated locality and boundedness constraints.", "AI": {"tldr": "本文形式化定义了在图索引状态系统上操作的局部保持确定性算子的一个构造子类，即有界本地生成器类别（BLGC），并在该框架下证明了一些重要性质。", "motivation": "研究如何通过有限范围的生成器在有界状态下进行操作，并探讨其对全局状态大小和增量计算努力之间的结构解耦效应。", "method": "定义了Bounded Local Generator Classes (BLGC)，并分析其在Hilbert空间中的嵌入特性及其算子范数的界限性质。", "result": "证明了在BLGC假设下，每一步操作的工作量满足W_t = O(1)与节点数量M无关，并且框架适用于定义的子类。", "conclusion": "该研究为特定条件下确定性状态演化提供了一个新的分析工具和理论基础。"}}
{"id": "2602.11468", "pdf": "https://arxiv.org/pdf/2602.11468", "abs": "https://arxiv.org/abs/2602.11468", "authors": ["Raihan Islam Arnob", "Max Merlin", "Abhishek Paudel", "Benned Hedegaard", "George Konidaris", "Gregory Stein"], "title": "Effective Task Planning with Missing Objects using Learning-Informed Object Search", "categories": ["cs.RO"], "comment": null, "summary": "Task planning for mobile robots often assumes full environment knowledge and so popular approaches, like planning via the PDDL, cannot plan when the locations of task-critical objects are unknown. Recent learning-driven object search approaches are effective, but operate as standalone tools and so are not straightforwardly incorporated into full task planners, which must additionally determine both what objects are necessary and when in the plan they should be sought out. To address this limitation, we develop a planning framework centered around novel model-based LIOS actions: each a policy that aims to find and retrieve a single object. High-level planning treats LIOS actions as deterministic and so -- informed by model-based calculations of the expected cost of each -- generates plans that interleave search and execution for effective, sound, and complete learning-informed task planning despite uncertainty. Our work effectively reasons about uncertainty while maintaining compatibility with existing full-knowledge solvers. In simulated ProcTHOR homes and in the real world, our approach outperforms non-learned and learned baselines on tasks including retrieval and meal prep.", "AI": {"tldr": "开发了一种基于学习的物体搜索任务规划框架，以处理移动机器人在未知环境中的物体定位问题。", "motivation": "现有任务规划方法通常假设环境信息完整，而当关键物体的位置未知时无法进行规划。此外，虽然有一些学习驱动的方法可以找到物体，但它们难以集成到完整的任务规划系统中。", "method": "提出了一种新的模型LIOS动作，作为寻找和获取单个对象的策略，并将这些动作视为确定性操作来生成计划，从而在模拟环境中实现有效、正确且完整的学习辅助任务规划。", "result": "该方法在ProcTHOR模拟房屋及真实世界中表现出色，优于非学习基线和学习基线的方法，在检索和烹饪前准备等任务上性能更强。", "conclusion": "所提出的方法能够在不确定性环境下进行有效的任务规划，同时保持与现有完全信息求解器的兼容性。"}}
{"id": "2602.11466", "pdf": "https://arxiv.org/pdf/2602.11466", "abs": "https://arxiv.org/abs/2602.11466", "authors": ["Yun-Cheng Li", "Sen Lei", "Heng-Chao Li", "Ke Li"], "title": "A Dual-Branch Framework for Semantic Change Detection with Boundary and Temporal Awareness", "categories": ["cs.CV"], "comment": null, "summary": "Semantic Change Detection (SCD) aims to detect and categorize land-cover changes from bi-temporal remote sensing images. Existing methods often suffer from blurred boundaries and inadequate temporal modeling, limiting segmentation accuracy. To address these issues, we propose a Dual-Branch Framework for Semantic Change Detection with Boundary and Temporal Awareness, termed DBTANet. Specifically, we utilize a dual-branch Siamese encoder where a frozen SAM branch captures global semantic context and boundary priors, while a ResNet34 branch provides local spatial details, ensuring complementary feature representations. On this basis, we design a Bidirectional Temporal Awareness Module (BTAM) to aggregate multi-scale features and capture temporal dependencies in a symmetric manner. Furthermore, a Gaussian-smoothed Projection Module (GSPM) refines shallow SAM features, suppressing noise while enhancing edge information for boundary-aware constraints. Extensive experiments on two public benchmarks demonstrate that DBTANet effectively integrates global semantics, local details, temporal reasoning, and boundary awareness, achieving state-of-the-art performance.", "AI": {"tldr": "本文提出了一种双分支框架的语义变化检测方法，用于从时间序列遥感图像中识别和分类土地覆盖的变化。", "motivation": "现有的语义变化检测方法在边界模糊和时间建模不足方面存在局限性，影响了分割精度。为了克服这些问题，作者设计了一个具有时间和边界的双分支框架来提高准确性。", "method": "提出了DBTANet框架，该框架包含一个冻结的SAM分支用于捕获全局语义背景和边缘先验，而ResNet34分支提供局部空间细节；同时引入双向时间感知模块（BTAM）聚合多尺度特征并捕捉对称的时间依赖性，以及高斯平滑投影模块（GSPM）以增强边界信息。", "result": "实验结果表明DBTANet在两个公开基准数据集上实现了最先进的性能，能够有效地整合全局语义、局部细节、时间推理和边缘感知。", "conclusion": "通过引入新的双分支框架和多个创新模块，DBTANet能够在保持高精度的同时解决现有方法的局限性。"}}
{"id": "2602.11464", "pdf": "https://arxiv.org/pdf/2602.11464", "abs": "https://arxiv.org/abs/2602.11464", "authors": ["Tao Zhang", "Song Xia", "Ye Wang", "Qin Jin"], "title": "EasyMimic: A Low-Cost Framework for Robot Imitation Learning from Human Videos", "categories": ["cs.RO"], "comment": "icra 2026", "summary": "Robot imitation learning is often hindered by the high cost of collecting large-scale, real-world data. This challenge is especially significant for low-cost robots designed for home use, as they must be both user-friendly and affordable. To address this, we propose the EasyMimic framework, a low-cost and replicable solution that enables robots to quickly learn manipulation policies from human video demonstrations captured with standard RGB cameras. Our method first extracts 3D hand trajectories from the videos. An action alignment module then maps these trajectories to the gripper control space of a low-cost robot. To bridge the human-to-robot domain gap, we introduce a simple and user-friendly hand visual augmentation strategy. We then use a co-training method, fine-tuning a model on both the processed human data and a small amount of robot data, enabling rapid adaptation to new tasks. Experiments on the low-cost LeRobot platform demonstrate that EasyMimic achieves high performance across various manipulation tasks. It significantly reduces the reliance on expensive robot data collection, offering a practical path for bringing intelligent robots into homes. Project website: https://zt375356.github.io/EasyMimic-Project/.", "AI": {"tldr": "提出了一种低成本的机器人模仿学习框架EasyMimic，使机器人能够从人类视频演示中快速学习操作策略。", "motivation": "解决低成本家用机器人在实际环境中收集大规模数据集时所面临的高成本挑战。", "method": "首先从视频中提取3D手部轨迹；然后通过行动对齐模块将这些轨迹映射到低成本机器人的抓取控制空间；引入简单易用的手部视觉增强策略来弥合人类与机器人之间的领域差距；使用协同训练方法，同时在处理过的人类数据和少量机器人数据上进行微调。", "result": "实验结果表明，EasyMimic在LeRobot平台上实现了多种操作任务的高表现，并显著减少了对昂贵的数据收集的依赖。", "conclusion": "提供了一种低成本且易于复制的方法，使智能机器人能够快速适应新的任务，为将这些技术引入家庭铺平了道路。"}}
{"id": "2602.11461", "pdf": "https://arxiv.org/pdf/2602.11461", "abs": "https://arxiv.org/abs/2602.11461", "authors": ["Yilun Huang", "Asal Mehradfar", "Salman Avestimehr", "Hamidreza Aghasi"], "title": "EM-Aware Physical Synthesis: Neural Inductor Modeling and Intelligent Placement & Routing for RF Circuits", "categories": ["cs.AR", "cs.AI", "cs.LG", "eess.SY"], "comment": "Accepted at the 2026 IEEE International Symposium on Circuits and Systems (ISCAS 2026)", "summary": "This paper presents an ML-driven framework for automated RF physical synthesis that transforms circuit netlists into manufacturable GDSII layouts. While recent ML approaches demonstrate success in topology selection and parameter optimization, they fail to produce manufacturable layouts due to oversimplified component models and lack of routing capabilities. Our framework addresses these limitations through three key innovations: (1) a neural network framework trained on 18,210 inductor geometries with frequency sweeps from 1-100 GHz, generating 7.5 million training samples, that predicts inductor Q-factor with less than 2% error and enables fast gradient-based layout optimization with a 93.77% success rate in producing high-Q layouts; (2) an intelligent P-Cell optimizer that reduces layout area while maintaining design-rule-check (DRC) compliance; and (3) a complete placement and routing engine with frequency-dependent EM spacing rules and DRC-aware synthesis. The neural inductor model demonstrates superior accuracy across 1-100 GHz, enabling EM-accurate component synthesis with real-time inference. The framework successfully generates DRC-aware GDSII layouts for RF circuits, representing a significant step toward automated RF physical design.", "AI": {"tldr": "本文提出了一种基于机器学习的框架，用于将电路网络列表转换为可制造的GDSII布局。", "motivation": "现有的机器学习方法在拓扑选择和参数优化方面表现出色，但无法生成可制造的布局。因为这些方法使用过度简化的组件模型且缺乏布线能力。", "method": "该框架通过三个关键创新解决这些问题：（1）一个基于神经网络的框架，训练于包含频率扫描范围为1-100 GHz的18210个电感几何形状的数据集上；（2）智能P单元优化器能够减少布局面积同时保持设计规则检查合规性；（3）完整的放置和路由引擎带有频率依赖电磁间距规则和DRC感知合成。", "result": "神经电感模型在1-100GHz范围内展示出优越的精度，使EM准确的组件综合具有实时推断能力。框架成功生成了符合设计规则检查要求的RF电路GDSII布局。", "conclusion": "该方法显著推进了RF物理设计的自动化进程。"}}
{"id": "2602.11455", "pdf": "https://arxiv.org/pdf/2602.11455", "abs": "https://arxiv.org/abs/2602.11455", "authors": ["Zhengbo Jiao", "Shaobo Wang", "Zifan Zhang", "Wei Wang", "Bing Zhao", "Hu Wei", "Linfeng Zhang"], "title": "Credit Where It is Due: Cross-Modality Connectivity Drives Precise Reinforcement Learning for MLLM Reasoning", "categories": ["cs.AI"], "comment": "20pages", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced the reasoning capabilities of Multimodal Large Language Models (MLLMs), yet how visual evidence is integrated during reasoning remains poorly understood. We explore multimodal RLVR through the lens of cross-modal attention connectivity and find that only a small fraction of tokens (approximately 15%) exhibit strong visual-textual coupling. These high-connectivity tokens act as anchors that ground reasoning in the image, while the majority follow linguistic patterns. During RLVR training, credit assignment naturally concentrates on these anchors, sharpening their visual grounding over time. Building on this insight, we propose Anchor-Token Reinforcement Learning (AT-RL), a lightweight framework that selectively reinforces high-connectivity tokens via graph-based clustering of attention topology. Evaluated across the series (3B-32B), AT-RL introduces only 1.2% overhead yet enables the 32B model to surpass the 72B-Instruct baseline on MathVista (80.2), with consistent gains observed across STEM, video and general tasks. Conversely, training solely on low-connectivity tokens causes severe degradation, confirming that effective multimodal RL hinges on precise credit assignment to visual anchors. Our work reveals that reasoning quality is governed not by token quantity but by the fidelity of cross-modal anchoring.", "AI": {"tldr": "本文通过跨模态注意力连接探索了多模态强化学习，提出了锚定令牌强化学习（AT-RL）框架以提高多模态大型语言模型在视觉证据整合方面的精确度。", "motivation": "当前对于如何将视觉证据纳入多模态大语言模型的推理过程的理解仍不足。本文通过跨模态注意力连接研究这一问题，并探索了精准分配强化学习信用的重要性。", "method": "作者利用跨模态注意力连通性识别出作为锚点的高连通性令牌，这些令牌在训练过程中得到自然且集中的强化反馈。在此基础上提出了AT-RL框架，通过基于图聚类的方法对注意拓扑结构进行集群操作以增强这些高连通性令牌。", "result": "该方法在跨不同规模模型系列（从3B到32B）上测试时，在MathVista任务中32B型号超越了72B-Instruct基线，同时也在STEM、视频和通用任务中观察到了一致性的提升。训练仅依赖低连通性令牌则会导致严重的性能下降。", "conclusion": "本文研究表明在多模态强化学习过程中精确的跨模态锚点识别至关重要，并且推理质量取决于视觉锚点的准确性而非令牌数量。"}}
{"id": "2602.11454", "pdf": "https://arxiv.org/pdf/2602.11454", "abs": "https://arxiv.org/abs/2602.11454", "authors": ["Ta Duy Nguyem", "Alina Ene", "Huy Le Nguyen"], "title": "Adaptive Power Iteration Method for Differentially Private PCA", "categories": ["cs.DS", "cs.LG"], "comment": null, "summary": "We study $(ε,δ)$-differentially private algorithms for the problem of approximately computing the top singular vector of a matrix $A\\in\\mathbb{R}^{n\\times d}$ where each row of $A$ is a datapoint in $\\mathbb{R}^{d}$. In our privacy model, neighboring inputs differ by one single row/datapoint. We study the private variant of the power iteration method, which is widely adopted in practice. Our algorithm is based on a filtering technique which adapts to the coherence parameter of the input matrix. This technique provides a utility that goes beyond the worst-case guarantees for matrices with low coherence parameter. Our work departs from and complements the work by Hardt-Roth (STOC 2013) which designed a private power iteration method for the privacy model where neighboring inputs differ in one single entry by at most 1.", "AI": {"tldr": "研究了在差分隐私保护下的矩阵主奇异向量的近似计算方法。", "motivation": "旨在提出一种基于过滤技术的自适应幂迭代算法，以提高低连贯性参数矩阵的实用性和私密性。", "method": "利用过滤技术调整输入矩阵的连贯性参数，并设计了一种适用于差分隐私保护模型中的幂迭代方法。", "result": "该方法在低连贯性参数下提供了比现有最坏情况保证更好的效用。", "conclusion": "提出的方法有效提高了私有主成分分析中计算准确性和效率，同时满足了差分隐私的需求。"}}
{"id": "2602.11453", "pdf": "https://arxiv.org/pdf/2602.11453", "abs": "https://arxiv.org/abs/2602.11453", "authors": ["Sajad Ebrahimi", "Bhaskar Mitra", "Negar Arabzadeh", "Ye Yuan", "Haolun Wu", "Fattane Zarrinkalam", "Ebrahim Bagheri"], "title": "From Noise to Order: Learning to Rank via Denoising Diffusion", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "In information retrieval (IR), learning-to-rank (LTR) methods have traditionally limited themselves to discriminative machine learning approaches that model the probability of the document being relevant to the query given some feature representation of the query-document pair. In this work, we propose an alternative denoising diffusion-based deep generative approach to LTR that instead models the full joint distribution over feature vectors and relevance labels. While in the discriminative setting, an over-parameterized ranking model may find different ways to fit the training data, we hypothesize that candidate solutions that can explain the full data distribution under the generative setting produce more robust ranking models. With this motivation, we propose DiffusionRank that extends TabDiff, an existing denoising diffusion-based generative model for tabular datasets, to create generative equivalents of classical discriminative pointwise and pairwise LTR objectives. Our empirical results demonstrate significant improvements from DiffusionRank models over their discriminative counterparts. Our work points to a rich space for future research exploration on how we can leverage ongoing advancements in deep generative modeling approaches, such as diffusion, for learning-to-rank in IR.", "AI": {"tldr": "本文提出了一种基于去噪扩散的深度生成模型DiffusionRank，用于信息检索中的学习到排序任务。", "motivation": "传统学习到排序方法受限于判别式机器学习技术，仅能建模文档对查询的相关性概率。作者认为，在生成式设置下，可以创建更稳健的排名模型。", "method": "作者提出DiffusionRank，它扩展了TabDiff，这是一种现有的基于去噪扩散的用于表格数据集的生成模型，以生成传统判别式的点对和成对学习到排序目标的生成等价物。", "result": "实验结果表明，与传统的判别式方法相比，DiffusionRank模型显著提高了性能。", "conclusion": "作者的工作指出了利用深度生成模型进展进行信息检索中的学习到排序任务的研究方向。"}}
{"id": "2602.11448", "pdf": "https://arxiv.org/pdf/2602.11448", "abs": "https://arxiv.org/abs/2602.11448", "authors": ["Nghia Nguyen", "Tianjiao Ding", "René Vidal"], "title": "Hierarchical Concept Embedding & Pursuit for Interpretable Image Classification", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Interpretable-by-design models are gaining traction in computer vision because they provide faithful explanations for their predictions. In image classification, these models typically recover human-interpretable concepts from an image and use them for classification. Sparse concept recovery methods leverage the latent space of vision-language models to represent image embeddings as a sparse combination of concept embeddings. However, because such methods ignore the hierarchical structure of concepts, they can produce correct predictions with explanations that are inconsistent with the hierarchy. In this work, we propose Hierarchical Concept Embedding \\& Pursuit (HCEP), a framework that induces a hierarchy of concept embeddings in the latent space and uses hierarchical sparse coding to recover the concepts present in an image. Given a hierarchy of semantic concepts, we construct a corresponding hierarchy of concept embeddings and, assuming the correct concepts for an image form a rooted path in the hierarchy, derive desirable conditions for identifying them in the embedded space. We show that hierarchical sparse coding reliably recovers hierarchical concept embeddings, whereas vanilla sparse coding fails. Our experiments on real-world datasets demonstrate that HCEP outperforms baselines in concept precision and recall while maintaining competitive classification accuracy. Moreover, when the number of samples is limited, HCEP achieves superior classification accuracy and concept recovery. These results show that incorporating hierarchical structures into sparse coding yields more reliable and interpretable image classification models.", "AI": {"tldr": "本文提出了一种层次化概念嵌入与追迹（HCEP）框架，用于改进图像分类的可解释性。", "motivation": "当前稀疏概念恢复方法忽略了概念的层级结构，可能导致正确预测但解释与层级结构不一致的问题。因此，需要一种新的方法来解决这一问题。", "method": "提出了一种层次化概念嵌入和追迹（HCEP）框架，该框架在潜在空间中构建一个概念嵌入的层级，并使用分层稀疏编码来恢复图像中的概念。", "result": "实验表明，HCEP在概念准确性和召回率上优于基线方法，在样本数量有限的情况下还具有更好的分类准确性。", "conclusion": "将层次结构纳入稀疏编码可以生成更可靠和可解释的图像分类模型。"}}
{"id": "2602.11446", "pdf": "https://arxiv.org/pdf/2602.11446", "abs": "https://arxiv.org/abs/2602.11446", "authors": ["Mark D. Olchanyi", "Annabel Sorby-Adams", "John Kirsch", "Brian L. Edlow", "Ava Farnan", "Renfei Liu", "Matthew S. Rosen", "Emery N. Brown", "W. Taylor Kimberly", "Juan Eugenio Iglesias"], "title": "Enhanced Portable Ultra Low-Field Diffusion Tensor Imaging with Bayesian Artifact Correction and Deep Learning-Based Super-Resolution", "categories": ["cs.CV", "cs.AI"], "comment": "38 pages, 8 figures, 2 supplementary figures, and 3 supplementary tables", "summary": "Portable, ultra-low-field (ULF) magnetic resonance imaging has the potential to expand access to neuroimaging but currently suffers from coarse spatial and angular resolutions and low signal-to-noise ratios. Diffusion tensor imaging (DTI), a sequence tailored to detect and reconstruct white matter tracts within the brain, is particularly prone to such imaging degradation due to inherent sequence design coupled with prolonged scan times. In addition, ULF DTI scans exhibit artifacting that spans both the space and angular domains, requiring a custom modelling algorithm for subsequent correction. We introduce a nine-direction, single-shell ULF DTI sequence, as well as a companion Bayesian bias field correction algorithm that possesses angular dependence and convolutional neural network-based superresolution algorithm that is generalizable across DTI datasets and does not require re-training (''DiffSR''). We show through a synthetic downsampling experiment and white matter assessment in real, matched ULF and high-field DTI scans that these algorithms can recover microstructural and volumetric white matter information at ULF. We also show that DiffSR can be directly applied to white matter-based Alzheimers disease classification in synthetically degraded scans, with notable improvements in agreement between DTI metrics, as compared to un-degraded scans. We freely disseminate the Bayesian bias correction algorithm and DiffSR with the goal of furthering progress on both ULF reconstruction methods and general DTI sequence harmonization. We release all code related to DiffSR for $\\href{https://github.com/markolchanyi/DiffSR}{public \\space use}$.", "AI": {"tldr": "本文提出了一个改进的便携式低场扩散张量成像序列，结合了贝叶斯偏置场校正算法和基于深度学习的超分辨率算法。", "motivation": "便携式低场磁共振成像具有扩展神经影像学访问的能力，但目前存在空间和角度分辨率粗略、信噪比低的问题。本文旨在解决这些问题，并提高扩散张量成像的质量。", "method": "提出了一种九方向单壳体低场扩散张量成像序列，以及一种贝叶斯偏置场校正算法和基于卷积神经网络的超分辨率算法（DiffSR）。", "result": "通过合成降采样实验和真实匹配的低场与高场DTI扫描中的白质评估，显示这些算法可以恢复微结构和体积的白质信息。此外，在人工退化的扫描中直接应用DiffSR进行白质基阿尔茨海默病分类时表现出改进。", "conclusion": "本文的方法在便携式低场成像重建方法上取得了进展，并且在扩散张量序列调谐方面具有广泛的应用前景。"}}
{"id": "2602.11444", "pdf": "https://arxiv.org/pdf/2602.11444", "abs": "https://arxiv.org/abs/2602.11444", "authors": ["Muskaan Chopra", "Lorenz Sparrenberg", "Rafet Sifa"], "title": "Towards Reliable Machine Translation: Scaling LLMs for Critical Error Detection and Safety", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at ECIR 2026", "summary": "Machine Translation (MT) plays a pivotal role in cross-lingual information access, public policy communication, and equitable knowledge dissemination. However, critical meaning errors, such as factual distortions, intent reversals, or biased translations, can undermine the reliability, fairness, and safety of multilingual systems. In this work, we explore the capacity of instruction-tuned Large Language Models (LLMs) to detect such critical errors, evaluating models across a range of parameters using the publicly accessible data sets. Our findings show that model scaling and adaptation strategies (zero-shot, few-shot, fine-tuning) yield consistent improvements, outperforming encoder-only baselines like XLM-R and ModernBERT. We argue that improving critical error detection in MT contributes to safer, more trustworthy, and socially accountable information systems by reducing the risk of disinformation, miscommunication, and linguistic harm, especially in high-stakes or underrepresented contexts. This work positions error detection not merely as a technical challenge, but as a necessary safeguard in the pursuit of just and responsible multilingual AI. The code will be made available at GitHub.", "AI": {"tldr": "本论文研究了在大规模语言模型中检测机器翻译中的关键错误的能力，以提高系统的可靠性和安全性。", "motivation": "跨语种的信息访问、公共政策传播和知识普及需要可靠的机器翻译。然而，事实扭曲、意图反转或偏见翻译等关键性错误会损害这些系统。因此，改进关键错误检测对于减少误导信息和语言伤害至关重要。", "method": "论文评估了参数不同的指令微调大型语言模型在公开数据集上的表现，并比较了零样本学习、少量样本学习和微调策略的效果。", "result": "结果显示，随着模型规模的增加和适应策略的改进，关键错误检测性能显著提升，优于传统的编码器基线模型。", "conclusion": "提高机器翻译中的关键错误检测能力是确保多语言AI系统更安全、可信赖和社会责任感的重要措施。"}}
{"id": "2602.11440", "pdf": "https://arxiv.org/pdf/2602.11440", "abs": "https://arxiv.org/abs/2602.11440", "authors": ["Penghui Ruan", "Bojia Zi", "Xianbiao Qi", "Youze Huang", "Rong Xiao", "Pichao Wang", "Jiannong Cao", "Yuhui Shi"], "title": "Ctrl&Shift: High-Quality Geometry-Aware Object Manipulation in Visual Generation", "categories": ["cs.CV"], "comment": "Accepted at ICLR 2026", "summary": "Object-level manipulation, relocating or reorienting objects in images or videos while preserving scene realism, is central to film post-production, AR, and creative editing. Yet existing methods struggle to jointly achieve three core goals: background preservation, geometric consistency under viewpoint shifts, and user-controllable transformations. Geometry-based approaches offer precise control but require explicit 3D reconstruction and generalize poorly; diffusion-based methods generalize better but lack fine-grained geometric control. We present Ctrl&Shift, an end-to-end diffusion framework to achieve geometry-consistent object manipulation without explicit 3D representations. Our key insight is to decompose manipulation into two stages, object removal and reference-guided inpainting under explicit camera pose control, and encode both within a unified diffusion process. To enable precise, disentangled control, we design a multi-task, multi-stage training strategy that separates background, identity, and pose signals across tasks. To improve generalization, we introduce a scalable real-world dataset construction pipeline that generates paired image and video samples with estimated relative camera poses. Extensive experiments demonstrate that Ctrl&Shift achieves state-of-the-art results in fidelity, viewpoint consistency, and controllability. To our knowledge, this is the first framework to unify fine-grained geometric control and real-world generalization for object manipulation, without relying on any explicit 3D modeling.", "AI": {"tldr": "提出了Ctrl&Shift，一种无须显式三维重建的端到端扩散框架，用于实现几何一致性的物体操纵。", "motivation": "现有方法难以同时达成背景保持、视角变化下的几何一致性以及用户可控变换等三个核心目标。本文旨在提供一种不依赖于显式3D建模即可实现实用操作的方法。", "method": "通过将物体去除和参考引导的填充分解为两个阶段，并在统一的扩散过程中编码，实现了无须显式三维表示的几何一致对象操纵。设计了多任务、多阶段训练策略以实现背景信号、身份信号及姿态信号的分离。", "result": "实验表明Ctrl&Shift在保真度、视角一致性以及可控制性方面达到了最先进的水平。", "conclusion": "Ctrl&Shift首次实现了细粒度几何控制与现实世界泛化的统一，无需依赖任何显式3D建模。"}}
{"id": "2602.11437", "pdf": "https://arxiv.org/pdf/2602.11437", "abs": "https://arxiv.org/abs/2602.11437", "authors": ["Chengrui Qu", "Christopher Yeh", "Kishan Panaganti", "Eric Mazumdar", "Adam Wierman"], "title": "Distributionally Robust Cooperative Multi-Agent Reinforcement Learning via Robust Value Factorization", "categories": ["cs.AI", "cs.MA"], "comment": "ICLR 2026", "summary": "Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution, where value-factorization methods enforce the individual-global-maximum (IGM) principle so that decentralized greedy actions recover the team-optimal joint action. However, the reliability of this recipe in real-world settings remains unreliable due to environmental uncertainties arising from the sim-to-real gap, model mismatch, and system noise. We address this gap by introducing Distributionally robust IGM (DrIGM), a principle that requires each agent's robust greedy action to align with the robust team-optimal joint action. We show that DrIGM holds for a novel definition of robust individual action values, which is compatible with decentralized greedy execution and yields a provable robustness guarantee for the whole system. Building on this foundation, we derive DrIGM-compliant robust variants of existing value-factorization architectures (e.g., VDN/QMIX/QTRAN) that (i) train on robust Q-targets, (ii) preserve scalability, and (iii) integrate seamlessly with existing codebases without bespoke per-agent reward shaping. Empirically, on high-fidelity SustainGym simulators and a StarCraft game environment, our methods consistently improve out-of-distribution performance. Code and data are available at https://github.com/crqu/robust-coMARL.", "AI": {"tldr": "论文提出了一种分布鲁棒个体全局最大（DrIGM）原则，并基于此开发了鲁棒价值因子化架构，提高了多智能体强化学习在不确定环境中的性能。", "motivation": "由于现实世界中的不确定性因素如仿真与真实之间的差距、模型不匹配和系统噪声等，传统中心训练分散执行的价值分解方法在实际应用中表现不稳定。因此提出了DrIGM原则来提高可靠性。", "method": "通过引入新型的鲁棒个体动作值定义并开发出符合DrIGM原理的鲁棒价值因子化架构，如针对VDN/QMIX/QTRAN等的方法改进版，确保了系统的整体鲁棒性保证。", "result": "在高保真SustainGym仿真器和StarCraft游戏环境中，所提方法显示出了比传统方法更为稳定的跨分布性能提升。", "conclusion": "新提出的DrIGM原则及其相应架构能够有效增强多智能体强化学习算法应对不确定环境的能力。"}}
{"id": "2602.11436", "pdf": "https://arxiv.org/pdf/2602.11436", "abs": "https://arxiv.org/abs/2602.11436", "authors": ["Carolina Brás", "Soufiane Ben Haddou", "Thijs P. Kuipers", "Laura Alvarez-Florez", "R. Nils Planken", "Fleur V. Y. Tjong", "Connie Bezzina", "Ivana Išgum"], "title": "Fighting MRI Anisotropy: Learning Multiple Cardiac Shapes From a Single Implicit Neural Representation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The anisotropic nature of short-axis (SAX) cardiovascular magnetic resonance imaging (CMRI) limits cardiac shape analysis. To address this, we propose to leverage near-isotropic, higher resolution computed tomography angiography (CTA) data of the heart. We use this data to train a single neural implicit function to jointly represent cardiac shapes from CMRI at any resolution. We evaluate the method for the reconstruction of right ventricle (RV) and myocardium (MYO), where MYO simultaneously models endocardial and epicardial left-ventricle surfaces. Since high-resolution SAX reference segmentations are unavailable, we evaluate performance by extracting a 4-chamber (4CH) slice of RV and MYO from their reconstructed shapes. When compared with the reference 4CH segmentation masks from CMRI, our method achieved a Dice similarity coefficient of 0.91 $\\pm$ 0.07 and 0.75 $\\pm$ 0.13, and a Hausdorff distance of 6.21 $\\pm$ 3.97 mm and 7.53 $\\pm$ 5.13 mm for RV and MYO, respectively. Quantitative and qualitative assessment demonstrate the model's ability to reconstruct accurate, smooth and anatomically plausible shapes, supporting improvements in cardiac shape analysis.", "AI": {"tldr": "利用CTA数据训练单个神经隐式函数来同时表示CMRI的心脏形状", "motivation": "短轴心血管MRI的各向异性性质限制了心脏形态分析，通过结合近同性高分辨率CTA数据改善这一情况", "method": "使用CTA数据训练单一神经隐式模型以在任意分辨率下共同表征心肌和右心室的形状，并从中提取4腔视图进行评估", "result": "对于RV和MYO重建，分别实现了0.91±0.07、0.75±0.13的Dice相似系数及6.21±3.97mm、7.53±5.13mm的Hausdorff距离，并展示了模型准确、平滑和解剖学上合理的形状重建能力", "conclusion": "所提出的方法通过结合CTA数据，有效改善了心脏形态分析"}}
{"id": "2602.11425", "pdf": "https://arxiv.org/pdf/2602.11425", "abs": "https://arxiv.org/abs/2602.11425", "authors": ["Yuanxin Xia", "Xinyan Li", "Matteo Calafà", "Allan P. Engsig-Karup", "Cheol-Ho Jeong"], "title": "Surface impedance inference via neural fields and sparse acoustic data obtained by a compact array", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Standardized laboratory characterizations for absorbing materials rely on idealized sound field assumptions, which deviate largely from real-life conditions. Consequently, \\emph{in-situ} acoustic characterization has become essential for accurate diagnosis and virtual prototyping. We propose a physics-informed neural field that reconstructs local, near-surface broadband sound fields from sparse pressure samples to directly infer complex surface impedance. A parallel, multi-frequency architecture enables a broadband impedance retrieval within runtimes on the order of seconds to minutes. To validate the method, we developed a compact microphone array with low hardware complexity. Numerical verifications and laboratory experiments demonstrate accurate impedance retrieval with a small number of sensors under realistic conditions. We further showcase the approach in a vehicle cabin to provide practical guidance on measurement locations that avoid strong interference. Here, we show that this approach offers a robust means of characterizing \\emph{in-situ} boundary conditions for architectural and automotive acoustics.", "AI": {"tldr": "通过稀疏声学数据和神经场技术，直接推断出复杂表面阻抗。", "motivation": "实验室表征方法依赖于理想化的声场假设，这与实际情况存在较大偏差。因此，需要进行现场声学特性校准以实现准确诊断及虚拟建模。", "method": "提出了一种基于物理信息的神经网络模型，在多频率并行架构支持下从稀疏压力样本中重建局部、近表面宽带声音场，并直接推断出复杂表面阻抗。利用便携式麦克风阵列验证了方法的有效性。", "result": "数值仿真和实验室实验表明，该方法能够在实际条件下准确地进行阻抗检索，仅需少量传感器即可完成任务。此外，在车辆内部展示了如何选择测量位置以避免强干扰的影响。", "conclusion": "提出的方法为建筑与汽车声学领域中的现场边界条件特性校准提供了一种稳健的手段。"}}
{"id": "2602.11424", "pdf": "https://arxiv.org/pdf/2602.11424", "abs": "https://arxiv.org/abs/2602.11424", "authors": ["Zecheng Wang", "Deyuan Liu", "Chunshan Li", "Yupeng Zhang", "Zhengyun Zhao", "Dianhui Chu", "Bingning Wang", "Dianbo Sui"], "title": "Gradients Must Earn Their Influence: Unifying SFT with Generalized Entropic Objectives", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Standard negative log-likelihood (NLL) for Supervised Fine-Tuning (SFT) applies uniform token-level weighting. This rigidity creates a two-fold failure mode: (i) overemphasizing low-probability targets can amplify gradients on noisy supervision and disrupt robust priors, and (ii) uniform weighting provides weak sharpening when the model is already confident. Existing methods fail to resolve the resulting plasticity--stability dilemma, often suppressing necessary learning signals alongside harmful ones. To address this issue, we unify token-level SFT objectives within a generalized deformed-log family and expose a universal gate $\\times$ error gradient structure, where the gate controls how much the model trusts its current prediction. By employing the Cayley transform, we map the model's continuously evolving uncertainty onto a continuous focus trajectory, which enables seamless interpolation between scenarios involving uncertain novel concepts and those involving well-established knowledge. We then introduce Dynamic Entropy Fine-Tuning (DEFT), a parameter-free objective that modulates the trust gate using distribution concentration (Rényi-2 entropy) as a practical proxy for the model's predictive state. Extensive experiments and analyses demonstrate that DEFT achieves a better balance between exploration and exploitation, leading to improved overall performance.", "AI": {"tldr": "本文提出了一种新的监督微调方法DEFT，通过调整模型对自身预测的信任度来解决NLL的局限性。", "motivation": "传统的负对数似然（NLL）应用于监督微调时存在两个问题：一是过度放大低概率目标，二是均匀加权对于已知信息提供弱化加强。这些问题导致了学习信号抑制的问题。", "method": "本文提出DEFT方法，利用广义变形对数家族统一令牌级的SFT目标，并通过Cayley变换将模型的不确定性映射到一个连续聚焦轨迹上，使用Rényi-2熵作为代理来调整信任门。", "result": "实验显示DEFT在平衡探索和利用之间取得了更好的效果，并提高了整体性能。", "conclusion": "本文提出的方法能够更好地处理监督微调中的问题，并提升了模型的综合表现。"}}
{"id": "2602.11412", "pdf": "https://arxiv.org/pdf/2602.11412", "abs": "https://arxiv.org/abs/2602.11412", "authors": ["Hanjing Shi", "Dominic DiFranzo"], "title": "When Visibility Outpaces Verification: Delayed Verification and Narrative Lock-in in Agentic AI Discourse", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "Agentic AI systems-autonomous entities capable of independent planning and execution-reshape the landscape of human-AI trust. Long before direct system exposure, user expectations are mediated through high-stakes public discourse on social platforms. However, platform-mediated engagement signals (e.g., upvotes) may inadvertently function as a ``credibility proxy,'' potentially stifling critical evaluation. This paper investigates the interplay between social proof and verification timing in online discussions of agentic AI. Analyzing a longitudinal dataset from two distinct Reddit communities with contrasting interaction cultures-r/OpenClaw and r/Moltbook-we operationalize verification cues via reproducible lexical rules and model the ``time-to-first-verification'' using a right-censored survival analysis framework. Our findings reveal a systemic ``Popularity Paradox'': high-visibility discussions in both subreddits experience significantly delayed or entirely absent verification cues compared to low-visibility threads. This temporal lag creates a critical window for ``Narrative Lock-in,'' where early, unverified claims crystallize into collective cognitive biases before evidence-seeking behaviors emerge. We discuss the implications of this ``credibility-by-visibility'' effect for AI safety and propose ``epistemic friction'' as a design intervention to rebalance engagement-driven platforms.", "AI": {"tldr": "研究探讨了社交证明与验证时机在在线讨论中的相互作用，特别是在Reddit社区中关于代理AI的对话。", "motivation": "探讨高可见性讨论如何影响用户对代理AI系统的信任和评价，以及这种现象对AI安全的影响。", "method": "通过分析两个具有不同互动文化的Reddit子版块的数据，使用可重复的词汇规则操作验证线索，并采用右删失生存分析框架来建模首次验证的时间。", "result": "高可见性讨论在两个子版块中都经历了显著延迟或完全缺乏验证信号的情况。这种时间滞后导致了‘叙事锁定’现象，在证据寻求行为出现之前，早期未经证实的声明固化为集体认知偏差。", "conclusion": "提出了一种名为‘认识摩擦’的设计干预措施来重新平衡以参与度驱动的平台，并讨论了由此产生的‘可见性带来的可信度’效应对AI安全的影响。"}}
{"id": "2602.11409", "pdf": "https://arxiv.org/pdf/2602.11409", "abs": "https://arxiv.org/abs/2602.11409", "authors": ["Sina Tayebati", "Divake Kumar", "Nastaran Darabi", "Davide Ettori", "Ranganath Krishnan", "Amit Ranjan Trivedi"], "title": "TRACER: Trajectory Risk Aggregation for Critical Episodes in Agentic Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Estimating uncertainty for AI agents in real-world multi-turn tool-using interaction with humans is difficult because failures are often triggered by sparse critical episodes (e.g., looping, incoherent tool use, or user-agent miscoordination) even when local generation appears confident. Existing uncertainty proxies focus on single-shot text generation and therefore miss these trajectory-level breakdown signals. We introduce TRACER, a trajectory-level uncertainty metric for dual-control Tool-Agent-User interaction. TRACER combines content-aware surprisal with situational-awareness signals, semantic and lexical repetition, and tool-grounded coherence gaps, and aggregates them using a tail-focused risk functional with a MAX-composite step risk to surface decisive anomalies. We evaluate TRACER on $τ^2$-bench by predicting task failure and selective task execution. To this end, TRACER improves AUROC by up to 37.1% and AUARC by up to 55% over baselines, enabling earlier and more accurate detection of uncertainty in complex conversational tool-use settings. Our code and benchmark are available at https://github.com/sinatayebati/agent-tracer.", "AI": {"tldr": "TRACER是一种用于多轮工具使用交互中的不确定性估计方法，特别是在代理与用户互动时，通过结合内容感知的惊讶度和情境意识信号来识别关键事件的风险。", "motivation": "现有的不确定性评估方法主要针对单一文本生成任务，并且无法捕捉到由于稀疏的关键时刻（如循环、不连贯或协调问题）所引发的问题。TRACER旨在解决这些多轮交互中的轨迹级风险检测。", "method": "TRACER通过整合内容感知的惊讶度，情境意识信号以及语义和词汇重复，工具相关的连贯性缺口，并采用尾部聚焦的风险函数来实现不确定性估计。", "result": "在$τ^2$-bench上的评估显示，相较于基线方法，TRACER可提高AUROC高达37.1%，并改善AUARC多达55%，表明它能更早且准确地识别复杂对话工具使用场景中的不确定性。", "conclusion": "通过结合多维度的风险信号和创新的聚合方式，TRACER为复杂交互环境下的不确定性检测提供了有效解决方案。"}}
{"id": "2602.11408", "pdf": "https://arxiv.org/pdf/2602.11408", "abs": "https://arxiv.org/abs/2602.11408", "authors": ["Michael Menezes", "Anastasios Kyrillidis"], "title": "GHOST: Unmasking Phantom States in Mamba2 via Grouped Hidden-state Output-aware Selection & Truncation", "categories": ["cs.AI", "cs.LG", "eess.SY"], "comment": "16 pages, 7 figures", "summary": "While Mamba2's expanded state dimension enhances temporal modeling, it incurs substantial inference overhead that saturates bandwidth during autoregressive generation. Standard pruning methods fail to address this bottleneck: unstructured sparsity leaves activations dense, magnitude-based selection ignores runtime dynamics, and gradient-based methods impose prohibitive costs. We introduce GHOST (Grouped Hidden-state Output-aware Selection and Truncation), a structured pruning framework that approximates control-theoretic balanced truncation using only forward-pass statistics. By jointly measuring controllability and observability, GHOST rivals the fidelity of gradient-based methods without requiring backpropagation. As a highlight, on models ranging from 130M to 2.7B parameters, our approach achieves a 50\\% state-dimension reduction with approximately 1 perplexity point increase on WikiText-2. Code is available at https://anonymous.4open.science/r/mamba2_ghost-7BCB/.", "AI": {"tldr": "GHOST是一种结构化修剪框架，用于减少Mamba2模型的推理开销。", "motivation": "Mamba2通过增加状态维度改善了时间建模能力，但这导致了大量的推理开销，在自回归生成过程中消耗带宽。标准的修剪方法未能解决这个问题。", "method": "GHOST通过仅使用前向传播统计信息来近似控制理论中的平衡截断，并联合测量可控性和可观测性。", "result": "在从1.3亿参数到27亿参数大小的不同模型中，该方法将状态维度减少了50%，而在WikiText-2上的困惑度增加不到一个点。", "conclusion": "GHOST框架在不使用反向传播的情况下达到了与梯度基方法相近的精度，并成功地降低了Mamba2模型的推理开销。"}}
{"id": "2602.11404", "pdf": "https://arxiv.org/pdf/2602.11404", "abs": "https://arxiv.org/abs/2602.11404", "authors": ["Ioannis Caragiannis", "Vasilis Gkatzelis", "Sebastian Homrighausen"], "title": "The Distortion of Prior-Independent b-Matching Mechanisms", "categories": ["cs.GT", "cs.DS"], "comment": null, "summary": "In a setting where $m$ items need to be partitioned among $n$ agents, we evaluate the performance of mechanisms that take as input each agent's \\emph{ordinal preferences}, i.e., their ranking of the items from most- to least-preferred. The standard measure for evaluating ordinal mechanisms is the \\emph{distortion}, and the vast majority of the literature on distortion has focused on worst-case analysis, leading to some overly pessimistic results. We instead evaluate the distortion of mechanisms with respect to their expected performance when the agents' preferences are generated stochastically. We first show that no ordinal mechanism can achieve a distortion better than $e/(e-1)\\approx 1.582$, even if each agent needs to receive exactly one item (i.e., $m=n$) and every agent's values for different items are drawn i.i.d.\\ from the same known distribution. We then complement this negative result by proposing an ordinal mechanism that achieves the optimal distortion of $e/(e-1)$ even if each agent's values are drawn from an agent-specific distribution that is unknown to the mechanism. To further refine our analysis, we also optimize the \\emph{distortion gap}, i.e., the extent to which an ordinal mechanism approximates the optimal distortion possible for the instance at hand, and we propose a mechanism with a near-optimal distortion gap of $1.076$. Finally, we also evaluate the distortion and distortion gap of simple mechanisms that have a one-pass structure.", "AI": {"tldr": "评估在随机生成的代理偏好下，机制的表现，特别是在每个代理需要一个物品的情况下。", "motivation": "现有的文献主要关注最坏情况下的表现，这可能导致过于悲观的结果。本文试图通过期望性能来评价机制的表现。", "method": "提出了一种序数机制，在未知特定代理价值分布的情况下达到了最优失真度$e/(e-1)$。优化了失真差距，提出了具有接近最优的失真差距（$1.076$）的机制。", "result": "证明了没有序数机制能够实现低于$e/(e-1)≈1.582$的失真度，并提出了一种新的机制来达到这个最佳值。此外，该机制还优化了失真差距。", "conclusion": "在随机生成偏好下评估机制性能的方法比最坏情况分析更准确。"}}
{"id": "2602.11401", "pdf": "https://arxiv.org/pdf/2602.11401", "abs": "https://arxiv.org/abs/2602.11401", "authors": ["Alan Baade", "Eric Ryan Chan", "Kyle Sargent", "Changan Chen", "Justin Johnson", "Ehsan Adeli", "Li Fei-Fei"], "title": "Latent Forcing: Reordering the Diffusion Trajectory for Pixel-Space Image Generation", "categories": ["cs.CV", "cs.LG"], "comment": "8 pages, 6 figures", "summary": "Latent diffusion models excel at generating high-quality images but lose the benefits of end-to-end modeling. They discard information during image encoding, require a separately trained decoder, and model an auxiliary distribution to the raw data. In this paper, we propose Latent Forcing, a simple modification to existing architectures that achieves the efficiency of latent diffusion while operating on raw natural images. Our approach orders the denoising trajectory by jointly processing latents and pixels with separately tuned noise schedules. This allows the latents to act as a scratchpad for intermediate computation before high-frequency pixel features are generated. We find that the order of conditioning signals is critical, and we analyze this to explain differences between REPA distillation in the tokenizer and the diffusion model, conditional versus unconditional generation, and how tokenizer reconstruction quality relates to diffusability. Applied to ImageNet, Latent Forcing achieves a new state-of-the-art for diffusion transformer-based pixel generation at our compute scale.", "AI": {"tldr": "本文提出了Latent Forcing技术，通过重新排序扩散过程中的轨迹，使模型在像素空间中直接生成高质量图像。", "motivation": "现有潜扩散模型存在丢弃信息、需要额外训练解码器和建模辅助分布等问题。作者希望通过改进的方法，在保持效率的同时，直接对原始自然图像进行操作。", "method": "Latent Forcing通过联合处理潜在变量和像素，并使用不同的噪声时间表来重新排序去噪轨迹，使潜变量作为中间计算的草稿板。这种方法的关键在于条件信号的顺序排列。", "result": "在ImageNet数据集上，该方法达到了基于扩散变换器的新水平，在计算规模内实现了最佳的像素生成效果。", "conclusion": "Latent Forcing技术通过重新排序扩散过程中的轨迹，提高了模型对原始图像的操作效率，并且展示了其在高质量图像生成方面的优越性。"}}
{"id": "2602.11399", "pdf": "https://arxiv.org/pdf/2602.11399", "abs": "https://arxiv.org/abs/2602.11399", "authors": ["Chongyi Zheng", "Royina Karegoudra Jayanth", "Benjamin Eysenbach"], "title": "Can We Really Learn One Representation to Optimize All Rewards?", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "As machine learning has moved towards leveraging large models as priors for downstream tasks, the community has debated the right form of prior for solving reinforcement learning (RL) problems. If one were to try to prefetch as much computation as possible, they would attempt to learn a prior over the policies for some yet-to-be-determined reward function. Recent work (forward-backward (FB) representation learning) has tried this, arguing that an unsupervised representation learning procedure can enable optimal control over arbitrary rewards without further fine-tuning. However, FB's training objective and learning behavior remain mysterious. In this paper, we demystify FB by clarifying when such representations can exist, what its objective optimizes, and how it converges in practice. We draw connections with rank matching, fitted Q-evaluation, and contraction mapping. Our analysis suggests a simplified unsupervised pre-training method for RL that, instead of enabling optimal control, performs one step of policy improvement. We call our proposed method $\\textbf{one-step forward-backward representation learning (one-step FB)}$. Experiments in didactic settings, as well as in $10$ state-based and image-based continuous control domains, demonstrate that one-step FB converges to errors $10^5$ smaller and improves zero-shot performance by $+24\\%$ on average. Our project website is available at https://chongyi-zheng.github.io/onestep-fb.", "AI": {"tldr": "本文研究了如何通过单一表示学习来优化所有奖励的问题，并提出了one-step FB方法。", "motivation": "当前关于在强化学习中使用哪种先验模型存在争议，前人工作尝试了一种名为FB的无监督表征学习方法，但其训练目标和学习行为尚不明确。本文旨在澄清这些问题，并提出一种更简单的预训练方法。", "method": "提出了one-step FB方法，该方法通过单一表示学习进行一次策略改进，而不仅仅是为了实现最优控制。", "result": "实验表明，one-step FB在10个基于状态和图像的连续控制环境中比传统FB方法误差减少了$10^5$倍，并且零样本性能提高了24%。", "conclusion": "通过深入分析，本文提出了one-step FB方法并验证其效果，展示了无监督表征学习在强化学习中的潜力。"}}
{"id": "2602.11398", "pdf": "https://arxiv.org/pdf/2602.11398", "abs": "https://arxiv.org/abs/2602.11398", "authors": ["Hormoz Shahrzad", "Niharika Gajawell", "Kaitlin Maile", "Manish Saggar", "Risto Miikkulainen"], "title": "Evolution With Purpose: Hierarchy-Informed Optimization of Whole-Brain Models", "categories": ["cs.NE"], "comment": null, "summary": "Evolutionary search is well suited for large-scale biophysical brain modeling, where many parameters with nonlinear interactions and no tractable gradients need to be optimized. Standard evolutionary approaches achieve an excellent fit to MRI data; however, among many possible such solutions, it finds ones that overfit to individual subjects and provide limited predictive power. This paper investigates whether guiding evolution with biological knowledge can help. Focusing on whole-brain Dynamic Mean Field (DMF) models, a baseline where 20 parameters were shared across the brain was compared against a heterogeneous formulation where different sets of 20 parameters were used for the seven canonical brain regions. The heterogeneous model was optimized using four strategies: optimizing all parameters at once, a curricular approach following the hierarchy of brain networks (HICO), a reversed curricular approach, and a randomly shuffled curricular approach. While all heterogeneous strategies fit the data well, only curricular approaches generalized to new subjects. Most importantly, only HICO made it possible to use the parameter sets to predict the subjects' behavioral abilities as well. Thus, by guiding evolution with biological knowledge about the hierarchy of brain regions, HICO demonstrated how domain knowledge can be harnessed to serve the purpose of optimization in real-world domains.", "AI": {"tldr": "通过引入生物知识来优化全脑模型参数，以提高模型的泛化能力和预测能力。", "motivation": "标准进化方法虽然能很好地拟合MRI数据，但会产生过度拟合问题，并且预测能力有限。因此，探索使用生物知识引导进化的策略。", "method": "比较了基线模型和异质模型，并采用了四种优化策略：同时优化所有参数、遵循大脑网络层次结构的课程学习（HICO）、逆向课程学习以及随机排列的课程学习。", "result": "只有采用基于大脑区域层次结构的知识引导进化的策略，才能使参数集用于预测受试者的行为能力。", "conclusion": "通过引入生物知识指导进化过程，可以提高全脑模型的泛化能力和预测性能。"}}
{"id": "2602.11395", "pdf": "https://arxiv.org/pdf/2602.11395", "abs": "https://arxiv.org/abs/2602.11395", "authors": ["Qingsong Wang", "Mikhail Belkin", "Yusu Wang"], "title": "General and Efficient Steering of Unconditional Diffusion", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Guiding unconditional diffusion models typically requires either retraining with conditional inputs or per-step gradient computations (e.g., classifier-based guidance), both of which incur substantial computational overhead. We present a general recipe for efficiently steering unconditional diffusion {without gradient guidance during inference}, enabling fast controllable generation. Our approach is built on two observations about diffusion model structure: Noise Alignment: even in early, highly corrupted stages, coarse semantic steering is possible using a lightweight, offline-computed guidance signal, avoiding any per-step or per-sample gradients. Transferable concept vectors: a concept direction in activation space once learned transfers across both {timesteps} and {samples}; the same fixed steering vector learned near low noise level remains effective when injected at intermediate noise levels for every generation trajectory, providing refined conditional control with efficiency. Such concept directions can be efficiently and reliably identified via Recursive Feature Machine (RFM), a light-weight backpropagation-free feature learning method. Experiments on CIFAR-10, ImageNet, and CelebA demonstrate improved accuracy/quality over gradient-based guidance, while achieving significant inference speedups.", "AI": {"tldr": "本文提出了一种高效引导无条件扩散模型的方法，无需梯度指导即可实现快速可控生成。", "motivation": "目前引导无条件扩散模型通常需要重新训练或每步计算梯度，这两种方法都会带来大量的计算开销。为此，研究者提出了一个通用且高效的方案来解决此问题。", "method": "该方法基于两个观察：噪声对齐和可转移的概念向量。通过轻量级的离线指导信号实现粗略语义引导；同一学习到的概念方向在多个时间步上依然有效，从而提供精细控制同时保持效率。递归特征机（RFM）可以识别这些概念方向，并且是不需要反向传播的方法。", "result": "实验结果表明，相比梯度导向方法，本文提出的方法在CIFAR-10、ImageNet和CelebA数据集上提高了准确性和生成质量的同时获得了显著的推理速度提升。", "conclusion": "所提方案提供了一种无需在线计算梯度即可实现高效引导无条件扩散模型的新途径。"}}
{"id": "2602.11393", "pdf": "https://arxiv.org/pdf/2602.11393", "abs": "https://arxiv.org/abs/2602.11393", "authors": ["Mrinal Verghese", "Christopher G. Atkeson"], "title": "Human Preference Modeling Using Visual Motion Prediction Improves Robot Skill Learning from Egocentric Human Video", "categories": ["cs.RO"], "comment": "15 pages, 11 figures", "summary": "We present an approach to robot learning from egocentric human videos by modeling human preferences in a reward function and optimizing robot behavior to maximize this reward. Prior work on reward learning from human videos attempts to measure the long-term value of a visual state as the temporal distance between it and the terminal state in a demonstration video. These approaches make assumptions that limit performance when learning from video. They must also transfer the learned value function across the embodiment and environment gap. Our method models human preferences by learning to predict the motion of tracked points between subsequent images and defines a reward function as the agreement between predicted and observed object motion in a robot's behavior at each step. We then use a modified Soft Actor Critic (SAC) algorithm initialized with 10 on-robot demonstrations to estimate a value function from this reward and optimize a policy that maximizes this value function, all on the robot. Our approach is capable of learning on a real robot, and we show that policies learned with our reward model match or outperform prior work across multiple tasks in both simulation and on the real robot.", "AI": {"tldr": "该论文提出了一种机器人学习方法，通过建模人类偏好来从第一人称视角的人类视频中学习技能。", "motivation": "现有工作在从视频学习奖励时存在假设限制性能，并且必须跨体感和环境差距转移所学的价值函数。本文旨在改善这些问题。", "method": "该方法通过预测跟踪点之间的运动并定义奖励为机器人行为每一步中的预测和观察到的对象运动的一致性来建模人类偏好。然后使用经过10次机器人工况演示初始化的修改Soft Actor Critic (SAC) 算法估计值函数，并优化最大化此值函数的策略。", "result": "该方法能够实现在真实机器人上学习，所学政策在模拟和实际机器人上的多种任务中匹配或优于先前的工作。", "conclusion": "通过使用人类偏好建模来预测视觉运动可以改进从第一人称视角的人类视频中进行机器人的技能学习。"}}
{"id": "2602.11390", "pdf": "https://arxiv.org/pdf/2602.11390", "abs": "https://arxiv.org/abs/2602.11390", "authors": ["Christian Z. Pratt", "Kyle J. Ray", "James P. Crutchfield"], "title": "Metastable Dynamical Computing with Energy Landscapes: A Primer", "categories": ["cond-mat.stat-mech", "cond-mat.supr-con", "cs.AR", "cs.ET", "nlin.CD"], "comment": "9 pages, 5 figures; http://csc.ucdavis.edu/~cmg/compmech/pubs/MetastableDynComp.htm", "summary": "Smartphones, laptops, and data centers are CMOS-based technologies that ushered our world into the information age of the 21st century. Despite their advantages for scalable computing, their implementations come with surprisingly large energetic costs. This challenge has revitalized scientific and engineering interest in energy-efficient information-processing designs. One current paradigm -- dynamical computing -- controls the location and shape of minima in potential energy landscapes that are connected to a thermal environment. The landscape supports distinguishable metastable energy minima that serve as a system's mesoscopic memory states. Information is represented by microstate distributions. Dynamically manipulating the memory states then corresponds to information processing. This framing provides a natural description of the associated thermodynamic transformations and required resources. Appealing to bifurcation theory, a computational protocol in the metastable regime can be analyzed by tracking the evolution of fixed points in the state space. We illustrate the paradigm's capabilities by performing 1-bit and 2-bit computations with double-well and quadruple-well potentials, respectively. These illustrate how dynamical computing can serve as a basis for designing universal logic gates and investigating their out-of-equilibrium thermodynamic performance.", "AI": {"tldr": "本文介绍了基于能量景观的动态计算方法，通过控制能量最小值的位置和形状来进行信息处理。", "motivation": "当前CMOS技术虽然具有可扩展性，但能耗较高，激发了对节能高效的信息处理设计的兴趣。本文提出了一种新的计算框架——利用能量景观中的亚稳态进行信息处理以减少能源消耗。", "method": "通过操控双峰和四峰势能的形状来动态地改变系统的记忆状态，并用固定点理论分析这些变化，演示了如何在亚稳态下执行1位和2位运算。", "result": "成功展示了基于能量景观的计算框架能够实现基本逻辑门的功能，并探讨了其非平衡热力学性能。", "conclusion": "这种动态计算方法为设计节能高效的信息处理系统提供了新思路，具有广泛的应用前景。"}}
{"id": "2602.11389", "pdf": "https://arxiv.org/pdf/2602.11389", "abs": "https://arxiv.org/abs/2602.11389", "authors": ["Heejeong Nam", "Quentin Le Lidec", "Lucas Maes", "Yann LeCun", "Randall Balestriero"], "title": "Causal-JEPA: Learning World Models through Object-Level Latent Interventions", "categories": ["cs.AI"], "comment": "Project Page: https://hazel-heejeong-nam.github.io/cjepa/", "summary": "World models require robust relational understanding to support prediction, reasoning, and control. While object-centric representations provide a useful abstraction, they are not sufficient to capture interaction-dependent dynamics. We therefore propose C-JEPA, a simple and flexible object-centric world model that extends masked joint embedding prediction from image patches to object-centric representations. By applying object-level masking that requires an object's state to be inferred from other objects, C-JEPA induces latent interventions with counterfactual-like effects and prevents shortcut solutions, making interaction reasoning essential. Empirically, C-JEPA leads to consistent gains in visual question answering, with an absolute improvement of about 20\\% in counterfactual reasoning compared to the same architecture without object-level masking. On agent control tasks, C-JEPA enables substantially more efficient planning by using only 1\\% of the total latent input features required by patch-based world models, while achieving comparable performance. Finally, we provide a formal analysis demonstrating that object-level masking induces a causal inductive bias via latent interventions. Our code is available at https://github.com/galilai-group/cjepa.", "AI": {"tldr": "提出了一种新的对象级世界模型C-JEPA，用于提高预测、推理和控制的准确性。", "motivation": "为了在物体之间的相互作用中获得稳健的关系理解，提出了C-JEPA来扩展现有的图像块联合嵌入预测方法到对象级别的表示。", "method": "通过应用对象级别屏蔽，使一个物体的状态需要从其他物体推断出来，从而诱导出具有反事实效果的潜在干预，并防止捷径解决方案。这种设置使得交互推理成为必要。", "result": "在视觉问答任务中取得了约20%的绝对改进，在代理控制任务上能够使用1%的潜入输入特征达到与基于图像块的世界模型相当的表现。", "conclusion": "C-JEPA通过对象级屏蔽诱导出因果偏倚，提高了世界模型的理解能力和效率。"}}
{"id": "2602.11382", "pdf": "https://arxiv.org/pdf/2602.11382", "abs": "https://arxiv.org/abs/2602.11382", "authors": ["M. Szusterman"], "title": "Markovian protocols and an upper bound on the extension complexity of the matching polytope", "categories": ["cs.DM", "cs.DS"], "comment": "21 pages (of which 10 page appendix), 2 figures", "summary": "This paper investigates the extension complexity of polytopes by exploiting the correspondence between non-negative factorizations of slack matrices and randomized communication protocols. We introduce a geometric characterization of extension complexity based on the width of Markovian protocols, as a variant of the framework introduced by Faenza et al. This enables us to derive a new upper bound of $\\tilde{O}(n^3\\cdot 1.5^n)$ for the extension complexity of the matching polytope $P_{\\text{match}}(n)$, improving upon the standard $2^n$-bound given by Edmonds' description. Additionally, we recover Goemans' compact formulation for the permutahedron using a one-round protocol based on sorting networks.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.11374", "pdf": "https://arxiv.org/pdf/2602.11374", "abs": "https://arxiv.org/abs/2602.11374", "authors": ["Aviv Bick", "Eric P. Xing", "Albert Gu"], "title": "Retrieval-Aware Distillation for Transformer-SSM Hybrids", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "State-space models (SSMs) offer efficient sequence modeling but lag behind Transformers on benchmarks that require in-context retrieval. Prior work links this gap to a small set of attention heads, termed Gather-and-Aggregate (G&A), which SSMs struggle to reproduce. We propose *retrieval-aware distillation*, which converts a pretrained Transformer into a hybrid student by preserving only these retrieval-critical heads and distilling the rest into recurrent heads. We identify the essential heads via ablation on a synthetic retrieval task, producing a hybrid with sparse, non-uniform attention placement. We show that preserving **just 2% of attention heads recovers over 95% of teacher performance on retrieval-heavy tasks** (10 heads in a 1B model), requiring far fewer heads than hybrids that retain at least 25%. We further find that large recurrent states often compensate for missing retrieval: once retrieval is handled by these heads, the SSM backbone can be simplified with limited loss, even with an $8\\times$ reduction in state dimension. By reducing both the attention cache and the SSM state, the resulting hybrid is $5$--$6\\times$ more memory-efficient than comparable hybrids, closing the Transformer--SSM gap at a fraction of the memory cost.", "AI": {"tldr": "本文提出了一种基于检索感知蒸馏的Transformer和状态空间模型（SSM）混合方法，通过保留关键注意力头并简化剩余部分来提升SSM在需要上下文检索任务上的性能。", "motivation": "现有的SSMs虽然高效但不如Transformers擅长处理需要上下文检索的任务。研究发现这是由于SSMs难以复现一组称为Gather-and-Aggregate（G&A）的关键注意力头所致，因此希望通过保留这些关键注意力头来提升SSM的性能。", "method": "提出了一种新的蒸馏方法，即检索感知蒸馏，将预训练的Transformer转换为混合学生模型。通过识别和保存关键的注意力头，并将其余部分蒸馏到循环头部中，从而构造出高效的混合模型。", "result": "实验结果显示保留2%的注意力头就可以恢复教师模型在检索任务上的95%以上性能；同时发现大状态量可以补偿缺失的检索能力。通过简化SSM骨干，即使减少8倍的状态维度也不会造成太大损失；最终得到的混合模型比类似的混合模型内存效率提高5-6倍。", "conclusion": "该方法成功缩小了Transformer和SSM之间的差距，并以较低的内存成本实现了高性能。"}}
{"id": "2602.11368", "pdf": "https://arxiv.org/pdf/2602.11368", "abs": "https://arxiv.org/abs/2602.11368", "authors": ["Arthur Juliani"], "title": "The Manifold of the Absolute: Religious Perennialism as Generative Inference", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper formalizes religious epistemology through the mathematics of Variational Autoencoders. We model religious traditions as distinct generative mappings from a shared, low-dimensional latent space to the high-dimensional space of observable cultural forms, and define three competing generative configurations corresponding to exclusivism, universalism, and perennialism, alongside syncretism as direct mixing in observable space. Through abductive comparison, we argue that exclusivism cannot parsimoniously account for cross-traditional contemplative convergence, that syncretism fails because combining the outputs of distinct generative processes produces incoherent artifacts, and that universalism suffers from posterior collapse: stripping traditions to a common core discards the structural information necessary for inference. The perennialist configuration provides the best explanatory fit. Within this framework, strict orthodoxy emerges not as a cultural constraint but as a structural necessity: the contemplative practices that recover the latent source must be matched to the specific tradition whose forms they take as input. The unity of religions, if it exists, is real but inaccessible by shortcut: one must go deep rather than wide.", "AI": {"tldr": "本文通过变分自编码器的数学模型将宗教认识论形式化，探讨不同宗教传统之间的关系。", "motivation": "旨在解析三种宗教观（排他主义、普遍主义和永恒主义）及其相互间的比较，并提出一种新的解释框架来更好地理解宗教统一性问题。", "method": "使用变分自编码器模型构建宗教传统的生成映射，分析并对比了排他主义、普遍主义以及永恒主义等不同宗教观念的合理性。", "result": "研究表明永恒主义提供了最佳的解释力，可以更好地解析跨传统冥想实践的趋同现象。同时指出严格正统性并非文化限制而是结构性需要。", "conclusion": "如果宗教间的统一性存在，则其是真实的但难以直接访问：必须深入而非广泛地探索。"}}
{"id": "2602.11367", "pdf": "https://arxiv.org/pdf/2602.11367", "abs": "https://arxiv.org/abs/2602.11367", "authors": ["Matthew Prock", "Ziv Epstein", "Hope Schroeder", "Amy Smith", "Cassandra Lee", "Vana Goblot", "Farnaz Jahanbakhsh"], "title": "Interpretive Cultures: Resonance, randomness, and negotiated meaning for AI-assisted tarot divination", "categories": ["cs.HC"], "comment": ":H.5.2", "summary": "While generative AI tools are increasingly adopted for creative and analytical tasks, their role in interpretive practices, where meaning is subjective, plural, and non-causal, remains poorly understood. This paper examines AI-assisted tarot reading, a divinatory practice in which users pose a query, draw cards through a randomized process, and ask AI systems to interpret the resulting symbols. Drawing on interviews with tarot practitioners and Hartmut Rosa's Theory of Resonance, we investigate how users seek, negotiate, and evaluate resonant interpretations in a context where no causal relationship exists between the query and the data being interpreted. We identify distinct ways practitioners incorporate AI into their interpretive workflows, including using AI to navigate uncertainty and self-doubt, explore alternative perspectives, and streamline or extend existing divinatory practices. Based on these findings, we offer design recommendations for AI systems that support interpretive meaning-making without collapsing ambiguity or foreclosing user agency.", "AI": {"tldr": "研究探讨了AI辅助塔罗占卜中的解释性实践。", "motivation": "探索在主观、多样和非因果性的解释实践中，生成式AI工具的作用仍不明确。具体考察用户如何通过随机过程与AI系统共同解读符号。", "method": "基于对塔罗师的访谈及Rosa共鸣理论，研究了用户寻求、协商并评估共振性解释的方式，并提出了设计建议。", "result": "识别出从业者将AI融入解释工作流程的不同方式，包括利用AI应对不确定性、探索替代视角和优化占卜实践。", "conclusion": "建议AI系统支持解释性的意义创造，避免模糊性和限制用户自主权。"}}
{"id": "2602.11364", "pdf": "https://arxiv.org/pdf/2602.11364", "abs": "https://arxiv.org/abs/2602.11364", "authors": ["Arpit Singh Gautam", "Kailash Talreja", "Saurabh Jha"], "title": "The Energy of Falsehood: Detecting Hallucinations via Diffusion Model Likelihoods", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) frequently hallucinate plausible but incorrect assertions, a vulnerability often missed by uncertainty metrics when models are confidently wrong. We propose DiffuTruth, an unsupervised framework that reconceptualizes fact verification via non equilibrium thermodynamics, positing that factual truths act as stable attractors on a generative manifold while hallucinations are unstable. We introduce the Generative Stress Test, claims are corrupted with noise and reconstructed using a discrete text diffusion model. We define Semantic Energy, a metric measuring the semantic divergence between the original claim and its reconstruction using an NLI critic. Unlike vector space errors, Semantic Energy isolates deep factual contradictions. We further propose a Hybrid Calibration fusing this stability signal with discriminative confidence. Extensive experiments on FEVER demonstrate DiffuTruth achieves a state of the art unsupervised AUROC of 0.725, outperforming baselines by 1.5 percent through the correction of overconfident predictions. Furthermore, we show superior zero shot generalization on the multi hop HOVER dataset, outperforming baselines by over 4 percent, confirming the robustness of thermodynamic truth properties to distribution shifts.", "AI": {"tldr": "提出了一种名为DiffuTruth的无监督框架，通过扩散模型重建和语义能量测量来检测大型语言模型中的虚假信息。", "motivation": "大型语言模型容易产生看似合理但错误的信息（即幻觉），这种问题常被不确定性度量忽略。为解决这一挑战，研究提出了一种新的方法来验证事实的真实性。", "method": "DiffuTruth利用非平衡热力学概念，将真实陈述视为生成流形上的稳定吸引子，而虚假信息则是不稳定的。通过引入语义能量测量以及混合校准策略融合稳定性信号和判别置信度，该框架能够检测并纠正模型的幻觉。", "result": "在FEVER数据集上实现了最先进的无监督AUROC性能（0.725），并在多跳HOVER数据集中也表现出色，显示出强大的分布迁移能力。", "conclusion": "通过提出DiffuTruth框架，研究成功地提高了大型语言模型幻觉检测的准确性，并展示了该方法在不同任务上的稳健性。"}}
{"id": "2602.11363", "pdf": "https://arxiv.org/pdf/2602.11363", "abs": "https://arxiv.org/abs/2602.11363", "authors": ["Yael Kirkpatrick", "John Kuszmaul", "Surya Mathialagan", "Virginia Vassilevska Williams"], "title": "Preprocessed 3SUM for Unknown Universes with Subquadratic Space", "categories": ["cs.DS"], "comment": "13 pages", "summary": "We consider the classic 3SUM problem: given sets of integers $A, B, C $, determine whether there is a tuple $(a, b, c) \\in A \\times B \\times C$ satisfying $a + b + c = 0$. The 3SUM Hypothesis, central in fine-grained complexity, states that there does not exist a truly subquadratic time 3SUM algorithm. Given this long-standing barrier, recent work over the past decade has explored 3SUM from a data structural perspective. Specifically, in the 3SUM in preprocessed universes regime, we are tasked with preprocessing sets $A, B$ of size $n$, to create a space-efficient data structure that can quickly answer queries, each of which is a 3SUM problem of the form $A', B', C'$, where $A' \\subseteq A$ and $B' \\subseteq B$. A series of results have achieved $\\tilde{O}(n^2)$ preprocessing time, $\\tilde{O}(n^2)$ space, and query time improving progressively from $\\tilde{O}(n^{1.9})$ [CL15] to $\\tilde{O}(n^{11/6})$ [CVX23] to $\\tilde{O}(n^{1.5})$ [KPS25]. Given these series of works improving query time, a natural open question has emerged: can one achieve both truly subquadratic space and truly subquadratic query time for 3SUM in preprocessed universes? We resolve this question affirmatively, presenting a tradeoff curve between query and space complexity. Specifically, we present a simple randomized algorithm achieving $\\tilde{O}(n^{1.5 + \\varepsilon})$ query time and $\\tilde{O}(n^{2 - 2\\varepsilon/3})$ space complexity. Furthermore, our algorithm has $\\tilde{O}(n^2)$ preprocessing time, matching past work. Notably, quadratic preprocessing is likely necessary for our tradeoff as either the preprocessing or the query time must be at least $n^{2-o(1)}$ under the 3SUM Hypothesis.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.11361", "pdf": "https://arxiv.org/pdf/2602.11361", "abs": "https://arxiv.org/abs/2602.11361", "authors": ["Weili Shi", "Dongliang Guo", "Lehan Yang", "Tianlong Wang", "Hanzhang Yuan", "Sheng Li"], "title": "Finding the Cracks: Improving LLMs Reasoning with Paraphrastic Probing and Consistency Verification", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models have demonstrated impressive performance across a variety of reasoning tasks. However, their problem-solving ability often declines on more complex tasks due to hallucinations and the accumulation of errors within these intermediate steps. Recent work has introduced the notion of critical tokens--tokens in the reasoning process that exert significant influence on subsequent steps. Prior studies suggest that replacing critical tokens can refine reasoning trajectories. Nonetheless, reliably identifying and exploiting critical tokens remains challenging. To address this, we propose the Paraphrastic Probing and Consistency Verification~(PPCV) framework. PPCV operates in two stages. In the first stage, we roll out an initial reasoning path from the original question and then concatenate paraphrased versions of the question with this reasoning path. And we identify critical tokens based on mismatches between the predicted top-1 token and the expected token in the reasoning path. A criterion is employed to confirm the final critical token. In the second stage, we substitute critical tokens with candidate alternatives and roll out new reasoning paths for both the original and paraphrased questions. The final answer is determined by checking the consistency of outputs across these parallel reasoning processes. We evaluate PPCV on mainstream LLMs across multiple benchmarks. Extensive experiments demonstrate PPCV substantially enhances the reasoning performance of LLMs compared to baselines.", "AI": {"tldr": "提出一种通过同义词探测和一致性验证来改进大型语言模型推理能力的方法。", "motivation": "解决大型语言模型在复杂任务中的问题解决能力下降的问题，特别是由于幻觉和中间步骤中错误的积累导致的表现不佳。希望通过识别并利用关键词汇来提高推理过程的一致性和准确性。", "method": "PPCV框架分为两个阶段：第一阶段通过同义词探测来生成初始推理路径，并基于预测和期望令牌之间的不匹配确定关键令牌；第二阶段替换这些关键令牌，然后比较原始问题和同义转换后的输出一致性以确定最终答案。", "result": "实验表明，与基线方法相比，PPCV框架显著提升了大型语言模型在多个基准测试中的推理性能。", "conclusion": "通过采用PPCV框架改进了大型语言模型的推理能力，并在多种任务中展示了其优越性。"}}
{"id": "2602.11360", "pdf": "https://arxiv.org/pdf/2602.11360", "abs": "https://arxiv.org/abs/2602.11360", "authors": ["Sara Matijevic", "Christopher Yau"], "title": "Bootstrapping-based Regularisation for Reducing Individual Prediction Instability in Clinical Risk Prediction Models", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Clinical prediction models are increasingly used to support patient care, yet many deep learning-based approaches remain unstable, as their predictions can vary substantially when trained on different samples from the same population. Such instability undermines reliability and limits clinical adoption. In this study, we propose a novel bootstrapping-based regularisation framework that embeds the bootstrapping process directly into the training of deep neural networks. This approach constrains prediction variability across resampled datasets, producing a single model with inherent stability properties. We evaluated models constructed using the proposed regularisation approach against conventional and ensemble models using simulated data and three clinical datasets: GUSTO-I, Framingham, and SUPPORT. Across all datasets, our model exhibited improved prediction stability, with lower mean absolute differences (e.g., 0.019 vs. 0.059 in GUSTO-I; 0.057 vs. 0.088 in Framingham) and markedly fewer significantly deviating predictions. Importantly, discriminative performance and feature importance consistency were maintained, with high SHAP correlations between models (e.g., 0.894 for GUSTO-I; 0.965 for Framingham). While ensemble models achieved greater stability, we show that this came at the expense of interpretability, as each constituent model used predictors in different ways. By regularising predictions to align with bootstrapped distributions, our approach allows prediction models to be developed that achieve greater robustness and reproducibility without sacrificing interpretability. This method provides a practical route toward more reliable and clinically trustworthy deep learning models, particularly valuable in data-limited healthcare settings.", "AI": {"tldr": "本文提出了一种基于自助法的正则化框架，以减少临床风险预测模型中的个体预测不稳定性。", "motivation": "许多基于深度学习的方法在相同的群体样本中训练时会产生差异很大的预测结果。这种不稳定影响了其可靠性和临床应用。", "method": "该研究提出了一种新的基于自助法的正则化框架，将自助过程直接嵌入到深度神经网络的训练过程中，通过约束再采样数据集上的预测变化来生成一个具有固有稳定性的单一模型。", "result": "在模拟和临床数据集中，所提出的模型显示出更好的预测稳定性，平均绝对差异较低（例如，在GUSTO-I中为0.019 vs. 0.059；Framingham中为0.057 vs. 0.088），并且明显减少了显著偏离的预测。此外，该方法保持了分类性能和特征重要性的一致性。", "conclusion": "通过正则化预测以与自助分布对齐，本文的方法能够开发出更稳健、可重复且具有较高解释性的预测模型，在数据有限的医疗环境中尤为有价值。"}}
{"id": "2602.11358", "pdf": "https://arxiv.org/pdf/2602.11358", "abs": "https://arxiv.org/abs/2602.11358", "authors": ["Zachary Pedram Dadfar"], "title": "When Models Examine Themselves: Vocabulary-Activation Correspondence in Self-Referential Processing", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Code and data: https://doi.org/10.5281/zenodo.18567446", "summary": "Large language models produce rich introspective language when prompted for self-examination, but whether this language reflects internal computation or sophisticated confabulation has remained unclear. We show that self-referential vocabulary tracks concurrent activation dynamics, and that this correspondence is specific to self-referential processing. We introduce the Pull Methodology, a protocol that elicits extended self-examination through format engineering, and use it to identify a direction in activation space that distinguishes self-referential from descriptive processing in Llama 3.1. The direction is orthogonal to the known refusal direction, localised at 6.25% of model depth, and causally influences introspective output when used for steering. When models produce \"loop\" vocabulary, their activations exhibit higher autocorrelation (r = 0.44, p = 0.002); when they produce \"shimmer\" vocabulary under steering, activation variability increases (r = 0.36, p = 0.002). Critically, the same vocabulary in non-self-referential contexts shows no activation correspondence despite nine-fold higher frequency. Qwen 2.5-32B, with no shared training, independently develops different introspective vocabulary tracking different activation metrics, all absent in descriptive controls. The findings indicate that self-report in transformer models can, under appropriate conditions, reliably track internal computational states.", "AI": {"tldr": "研究通过引入Pull方法论，探讨大型语言模型在自我反省时词汇与激活状态之间的对应关系。", "motivation": "探究大型语言模型生成的自我反省性语言是否真实反映了内部计算过程而非复杂的编造。", "method": "利用Pull方法论设计特定格式工程来激发长时间的自我反思，并通过分析Llama 3.1和Qwen 2.5-32B模型在激活空间中的差异，确定区分自省与描述性处理的方向。同时评估这些词汇在不同上下文下的激活状态。", "result": "发现当模型生成特定词汇时，其激活状态确实反映了内部计算过程；这种对应关系仅限于自我反省的背景下，在其他条件下不存在相同的关系。", "conclusion": "研究结果表明，在适当的条件下，大型语言模型可以可靠地通过自述反映其内部计算状态。"}}
{"id": "2602.11354", "pdf": "https://arxiv.org/pdf/2602.11354", "abs": "https://arxiv.org/abs/2602.11354", "authors": ["Bang Nguyen", "Dominik Soós", "Qian Ma", "Rochana R. Obadage", "Zack Ranjan", "Sai Koneru", "Timothy M. Errington", "Shakhlo Nematova", "Sarah Rajtmajer", "Jian Wu", "Meng Jiang"], "title": "ReplicatorBench: Benchmarking LLM Agents for Replicability in Social and Behavioral Sciences", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "The literature has witnessed an emerging interest in AI agents for automated assessment of scientific papers. Existing benchmarks focus primarily on the computational aspect of this task, testing agents' ability to reproduce or replicate research outcomes when having access to the code and data. This setting, while foundational, (1) fails to capture the inconsistent availability of new data for replication as opposed to reproduction, and (2) lacks ground-truth diversity by focusing only on reproducible papers, thereby failing to evaluate an agent's ability to identify non-replicable research. Furthermore, most benchmarks only evaluate outcomes rather than the replication process. In response, we introduce ReplicatorBench, an end-to-end benchmark, including human-verified replicable and non-replicable research claims in social and behavioral sciences for evaluating AI agents in research replication across three stages: (1) extraction and retrieval of replication data; (2) design and execution of computational experiments; and (3) interpretation of results, allowing a test of AI agents' capability to mimic the activities of human replicators in real world. To set a baseline of AI agents' capability, we develop ReplicatorAgent, an agentic framework equipped with necessary tools, like web search and iterative interaction with sandboxed environments, to accomplish tasks in ReplicatorBench. We evaluate ReplicatorAgent across four underlying large language models (LLMs), as well as different design choices of programming language and levels of code access. Our findings reveal that while current LLM agents are capable of effectively designing and executing computational experiments, they struggle with retrieving resources, such as new data, necessary to replicate a claim. All code and data are publicly available at https://github.com/CenterForOpenScience/llm-benchmarking.", "AI": {"tldr": "本文介绍了ReplicatorBench，一个用于评估AI代理在社会科学和行为科学中进行研究复制的能力的端到端基准。", "motivation": "现有的基准测试主要集中在计算方面，未能捕捉新数据的不一致可用性和非可重复性研究的真实多样性。为了填补这一空白，作者提出了一个新的基准框架来全面评价AI代理的能力。", "method": "通过引入ReplicatorBench和开发一个具有Web搜索和其他工具功能的代理框架，作者测试了AI代理在复制科学研究时的表现，并评估了不同LLM模型下的表现。", "result": "结果表明当前的LLM代理能够有效地设计和执行计算实验，但在获取必要资源以复现实验方面存在困难。", "conclusion": "ReplicatorBench为评价AI代理在社会科学中进行研究复制的能力提供了一个全面框架。"}}
{"id": "2602.11351", "pdf": "https://arxiv.org/pdf/2602.11351", "abs": "https://arxiv.org/abs/2602.11351", "authors": ["Yihang Yao", "Zhepeng Cen", "Haohong Lin", "Shiqi Liu", "Zuxin Liu", "Jiacheng Zhu", "Zhang-Wei Hong", "Laixi Shi", "Ding Zhao"], "title": "Pushing Forward Pareto Frontiers of Proactive Agents with Behavioral Agentic Optimization", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Proactive large language model (LLM) agents aim to actively plan, query, and interact over multiple turns, enabling efficient task completion beyond passive instruction following and making them essential for real-world, user-centric applications. Agentic reinforcement learning (RL) has recently emerged as a promising solution for training such agents in multi-turn settings, allowing interaction strategies to be learned from feedback. However, existing pipelines face a critical challenge in balancing task performance with user engagement, as passive agents can not efficiently adapt to users' intentions while overuse of human feedback reduces their satisfaction. To address this trade-off, we propose BAO, an agentic RL framework that combines behavior enhancement to enrich proactive reasoning and information-gathering capabilities with behavior regularization to suppress inefficient or redundant interactions and align agent behavior with user expectations. We evaluate BAO on multiple tasks from the UserRL benchmark suite, and demonstrate that it substantially outperforms proactive agentic RL baselines while achieving comparable or even superior performance to commercial LLM agents, highlighting its effectiveness for training proactive, user-aligned LLM agents in complex multi-turn scenarios. Our website: https://proactive-agentic-rl.github.io/.", "AI": {"tldr": "本文提出了一种新的框架BAO，用于训练能在多轮交互中主动规划、查询和互动的LLM代理。", "motivation": "现有LLM代理在平衡任务性能与用户参与度方面存在挑战。被动代理无法有效适应用户的意图，而过多的人类反馈会降低用户体验。", "method": "BAO结合了行为增强和行为正则化，以提高主动推理能力和信息收集能力，并抑制无效或冗余的交互，使其更符合用户期望。", "result": "在UserRL基准测试套件上评估表明，BAO显著优于现有的代理强化学习基线方法，在复杂多轮场景中训练出性能优越且与用户对齐的LLM代理。", "conclusion": "BAO框架有效解决了现有代理面临的问题，并展示了其在训练高效、用户体验良好的LLM代理方面的潜力。"}}
{"id": "2602.11349", "pdf": "https://arxiv.org/pdf/2602.11349", "abs": "https://arxiv.org/abs/2602.11349", "authors": ["Samuel Waugh", "Stuart James"], "title": "ArtContext: Contextualizing Artworks with Open-Access Art History Articles and Wikidata Knowledge through a LoRA-Tuned CLIP Model", "categories": ["cs.CV"], "comment": null, "summary": "Many Art History articles discuss artworks in general as well as specific parts of works, such as layout, iconography, or material culture. However, when viewing an artwork, it is not trivial to identify what different articles have said about the piece. Therefore, we propose ArtContext, a pipeline for taking a corpus of Open-Access Art History articles and Wikidata Knowledge and annotating Artworks with this information. We do this using a novel corpus collection pipeline, then learn a bespoke CLIP model adapted using Low-Rank Adaptation (LoRA) to make it domain-specific. We show that the new model, PaintingCLIP, which is weakly supervised by the collected corpus, outperforms CLIP and provides context for a given artwork. The proposed pipeline is generalisable and can be readily applied to numerous humanities areas.", "AI": {"tldr": "本文提出了一种方法，使用Open-Access艺术史文章和Wikidata知识库为艺术品添加上下文信息。", "motivation": "在浏览艺术品时，很难找到关于该作品的具体评论。因此，作者希望通过利用开放存取的艺术史文章和Wikidata知识来创建一个能够提供艺术品背景的系统。", "method": "首先收集了艺术史文章和Wikidata中的相关信息，然后使用低秩适应（LoRA）技术调整CLIP模型以使其特定于领域，并生成新的PaintingCLIP模型。", "result": "新模型PaintingCLIP在识别艺术品及其相关背景信息方面优于原始的CLIP模型。", "conclusion": "通过这种方法可以为艺术品提供更丰富的上下文信息，且该方法具有广泛的应用潜力。"}}
{"id": "2602.11348", "pdf": "https://arxiv.org/pdf/2602.11348", "abs": "https://arxiv.org/abs/2602.11348", "authors": ["Ruipeng Wang", "Yuxin Chen", "Yukai Wang", "Chang Wu", "Junfeng Fang", "Xiaodong Cai", "Qi Gu", "Hui Su", "An Zhang", "Xiang Wang", "Xunliang Cai", "Tat-Seng Chua"], "title": "AgentNoiseBench: Benchmarking Robustness of Tool-Using LLM Agents Under Noisy Condition", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large language models have enabled LLM-based agents to achieve strong performance on a variety of benchmarks. However, their performance in real-world deployments often that observed on benchmark settings, especially in complex and imperfect environments. This discrepancy largely arises because prevailing training and evaluation paradigms are typically built on idealized assumptions, overlooking the inherent stochasticity and noise present in real-world interactions. To bridge this gap, we introduce AgentNoiseBench, a framework for systematically evaluating the robustness of agentic models under noisy environments. We first conduct an in-depth analysis of biases and uncertainties in real-world scenarios and categorize environmental noise into two primary types: user-noise and tool-noise. Building on this analysis, we develop an automated pipeline that injects controllable noise into existing agent-centric benchmarks while preserving task solvability. Leveraging this pipeline, we perform extensive evaluations across a wide range of models with diverse architectures and parameter scales. Our results reveal consistent performance variations under different noise conditions, highlighting the sensitivity of current agentic models to realistic environmental perturbations.", "AI": {"tldr": "本文提出了AgentNoiseBench框架，用于评估大型语言模型代理在有噪声环境中的鲁棒性。", "motivation": "当前的LLM代理虽然在理想化环境中表现出色，但在复杂和不完美的现实世界部署中性能下降。这是由于现有训练和评价方法忽略了真实场景中存在的随机性和噪音。", "method": "通过深入分析现实世界的偏差与不确定性，并将环境噪声分为用户噪声和工具噪声两类，开发了一种自动注入可控噪声的评估管道来改进现有的代理基准测试。", "result": "实验结果表明，当前模型在不同噪声条件下表现出一致性的性能变化，展示了对实际环境中干扰的高度敏感性。", "conclusion": "AgentNoiseBench能够有效地评估大型语言模型代理在有噪声环境下的鲁棒性，并为未来研究提供了一个有价值的框架。"}}
{"id": "2602.11346", "pdf": "https://arxiv.org/pdf/2602.11346", "abs": "https://arxiv.org/abs/2602.11346", "authors": ["Esha Singh", "Dongxia Wu", "Chien-Yi Yang", "Tajana Rosing", "Rose Yu", "Yi-An Ma"], "title": "Divide and Learn: Multi-Objective Combinatorial Optimization at Scale", "categories": ["cs.LG", "cs.AI"], "comment": "Tech report. Code URL coming soon", "summary": "Multi-objective combinatorial optimization seeks Pareto-optimal solutions over exponentially large discrete spaces, yet existing methods sacrifice generality, scalability, or theoretical guarantees. We reformulate it as an online learning problem over a decomposed decision space, solving position-wise bandit subproblems via adaptive expert-guided sequential construction. This formulation admits regret bounds of $O(d\\sqrt{T \\log T})$ depending on subproblem dimensionality \\(d\\) rather than combinatorial space size. On standard benchmarks, our method achieves 80--98\\% of specialized solvers performance while achieving two to three orders of magnitude improvement in sample and computational efficiency over Bayesian optimization methods. On real-world hardware-software co-design for AI accelerators with expensive simulations, we outperform competing methods under fixed evaluation budgets. The advantage grows with problem scale and objective count, establishing bandit optimization over decomposed decision spaces as a principled alternative to surrogate modeling or offline training for multi-objective optimization.", "AI": {"tldr": "将多目标组合优化问题重新表述为在线学习问题，通过解决位置特定的代理子问题来找到帕累托最优解。", "motivation": "现有的方法在处理大规模多目标组合优化时，存在泛化能力差、可扩展性弱或理论保证不足的问题。因此提出了新的方法以提高效率和性能。", "method": "将决策空间分解，并通过自适应专家引导的顺序构建来解决每个位置特定的代理子问题，从而得到帕累托最优解。", "result": "在标准基准测试中达到80--98%的专业求解器性能的同时，样本效率和计算效率提高了两个到三个数量级；在真实世界的应用中，在给定评估预算下优于其他方法，并且随着问题规模和目标数量的增长，优势更加明显。", "conclusion": "在线学习方法通过分解决策空间来解决多目标优化问题是替代代理建模或离线训练的一种原理性选择。"}}
{"id": "2602.11342", "pdf": "https://arxiv.org/pdf/2602.11342", "abs": "https://arxiv.org/abs/2602.11342", "authors": ["Qiaosi Wang", "Jini Kim", "Avanita Sharma", "Alicia", "Lee", "Jodi Forlizzi", "Hong Shen"], "title": "Situated, Dynamic, and Subjective: Envisioning the Design of Theory-of-Mind-Enabled Everyday AI with Industry Practitioners", "categories": ["cs.HC", "cs.AI"], "comment": "16 pages, preprint for ACM CHI 2026 Conference", "summary": "Theory of Mind (ToM) -- the ability to infer what others are thinking (e.g., intentions) from observable cues -- is traditionally considered fundamental to human social interactions. This has sparked growing efforts in building and benchmarking AI's ToM capability, yet little is known about how such capability could translate into the design and experience of everyday user-facing AI products and services. We conducted 13 co-design sessions with 26 U.S.-based AI practitioners to envision, reflect, and distill design recommendations for ToM-enabled everyday AI products and services that are both future-looking and grounded in the realities of AI design and development practices. Analysis revealed three interrelated design recommendations: ToM-enabled AI should 1) be situated in the social context that shape users' mental states, 2) be responsive to the dynamic nature of mental states, and 3) be attuned to subjective individual differences. We surface design tensions within each recommendation that reveal a broader gap between practitioners' envisioned futures of ToM-enabled AI and the realities of current AI design and development practices. These findings point toward the need to move beyond static, inference-driven approach to ToM and toward designing ToM as a pervasive capability that supports continuous human-AI interaction loops.", "AI": {"tldr": "本文通过与AI从业者合作，设计和反思具有心智理论能力的日常AI产品和服务的方法论建议。", "motivation": "探讨将心智理论能力转化为日常用户面对的AI产品和服务的设计和体验的理解尚浅。", "method": "进行了13次共设会议，涉及26位美国AI从业人员，以展望、反映并提炼出面向未来且基于现实设计与开发实践的心智理论赋能日常AI产品的设计建议。", "result": "分析揭示了三个相关的设计建议：心智理论赋能的AI应1）适应塑造用户心理状态的社会背景；2）响应心理状态变化；3）关注主观个体差异。发现从业者对于心智理论赋能AI未来的愿景和当前现实之间的差距。", "conclusion": "研究表明需要超越静态、推理驱动的心智理论方法，转向设计一种支持连续人机交互循环的广泛能力。"}}
{"id": "2602.11340", "pdf": "https://arxiv.org/pdf/2602.11340", "abs": "https://arxiv.org/abs/2602.11340", "authors": ["Bo Pan", "Xuan Kan", "Kaitai Zhang", "Yan Yan", "Shunwen Tan", "Zihao He", "Zixin Ding", "Junjie Wu", "Liang Zhao"], "title": "Bi-Level Prompt Optimization for Multimodal LLM-as-a-Judge", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have become widely adopted as automated judges for evaluating AI-generated content. Despite their success, aligning LLM-based evaluations with human judgments remains challenging. While supervised fine-tuning on human-labeled data can improve alignment, it is costly and inflexible, requiring new training for each task or dataset. Recent progress in auto prompt optimization (APO) offers a more efficient alternative by automatically improving the instructions that guide LLM judges. However, existing APO methods primarily target text-only evaluations and remain underexplored in multimodal settings. In this work, we study auto prompt optimization for multimodal LLM-as-a-judge, particularly for evaluating AI-generated images. We identify a key bottleneck: multimodal models can only process a limited number of visual examples due to context window constraints, which hinders effective trial-and-error prompt refinement. To overcome this, we propose BLPO, a bi-level prompt optimization framework that converts images into textual representations while preserving evaluation-relevant visual cues. Our bi-level optimization approach jointly refines the judge prompt and the I2T prompt to maintain fidelity under limited context budgets. Experiments on four datasets and three LLM judges demonstrate the effectiveness of our method.", "AI": {"tldr": "提出了一种双层提示优化框架BLPO，用于多模态LLM评估AI生成图像时的自动提示优化。", "motivation": "现有的自动提示优化方法主要针对纯文本评价，而对多模态场景下的应用研究较少。在多模态模型中，受限于上下文窗口限制，难以通过有限视觉示例有效进行提示精炼。", "method": "提出了一种双层提示优化框架BLPO，将图像转换为保持评估相关视觉线索的文本表示，并联合优化评价提示和I2T提示以适应有限的上下文预算。", "result": "实验结果表明该方法在四个数据集及三种LLM评委上具有有效性。", "conclusion": "通过引入双层优化框架BLPO，解决了多模态下自动提示优化的关键瓶颈问题。"}}
{"id": "2602.11339", "pdf": "https://arxiv.org/pdf/2602.11339", "abs": "https://arxiv.org/abs/2602.11339", "authors": ["Evgeney Bogatyrev", "Khaled Abud", "Ivan Molodetskikh", "Nikita Alutis", "Dmitry Vatolin"], "title": "Exploring Real-Time Super-Resolution: Benchmarking and Fine-Tuning for Streaming Content", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in real-time super-resolution have enabled higher-quality video streaming, yet existing methods struggle with the unique challenges of compressed video content. Commonly used datasets do not accurately reflect the characteristics of streaming media, limiting the relevance of current benchmarks. To address this gap, we introduce a comprehensive dataset - StreamSR - sourced from YouTube, covering a wide range of video genres and resolutions representative of real-world streaming scenarios. We benchmark 11 state-of-the-art real-time super-resolution models to evaluate their performance for the streaming use-case. Furthermore, we propose EfRLFN, an efficient real-time model that integrates Efficient Channel Attention and a hyperbolic tangent activation function - a novel design choice in the context of real-time super-resolution. We extensively optimized the architecture to maximize efficiency and designed a composite loss function that improves training convergence. EfRLFN combines the strengths of existing architectures while improving both visual quality and runtime performance. Finally, we show that fine-tuning other models on our dataset results in significant performance gains that generalize well across various standard benchmarks. We made the dataset, the code, and the benchmark available at https://github.com/EvgeneyBogatyrev/EfRLFN.", "AI": {"tldr": "本文研究了实时超分辨率在流媒体上的应用，提出了一个新数据集StreamSR和一种新的高效实时模型EfRLFN。", "motivation": "现有的实时超分辨率方法在处理压缩视频内容时面临挑战，常用数据集不能准确反映实际流媒体特征。为此，作者引入了一个全面的数据集，并对多种现有方法进行了基准测试，同时提出了一种新设计的模型以提高效率和性能。", "method": "作者提出了一个名为EfRLFN的新模型，该模型结合了Efficient Channel Attention和双曲正切激活函数，优化了架构并设计了复合损失函数。此外，还展示了在新的数据集上微调其他模型可以显著提升其表现。", "result": "新模型EfRLFN在视觉质量与运行时间性能方面都得到了改进，并且在各种基准测试中表现出色。其它模型通过在StreamSR数据集上的微调也取得了明显的性能提升，证明了该方法的有效性。", "conclusion": "本研究不仅提供了新的数据集和评估标准，还提出了一种高效的实时超分辨率解决方案，为流媒体应用中的视频增强技术带来了重要进展。"}}
{"id": "2602.11337", "pdf": "https://arxiv.org/pdf/2602.11337", "abs": "https://arxiv.org/abs/2602.11337", "authors": ["Yejin Kim", "Wilbert Pumacay", "Omar Rayyan", "Max Argus", "Winson Han", "Eli VanderBilt", "Jordi Salvador", "Abhay Deshpande", "Rose Hendrix", "Snehal Jauhri", "Shuo Liu", "Nur Muhammad Mahi Shafiullah", "Maya Guru", "Ainaz Eftekhar", "Karen Farley", "Donovan Clay", "Jiafei Duan", "Arjun Guru", "Piper Wolters", "Alvaro Herrasti", "Ying-Chun Lee", "Georgia Chalvatzaki", "Yuchen Cui", "Ali Farhadi", "Dieter Fox", "et al. (1 additional authors not shown)"], "title": "MolmoSpaces: A Large-Scale Open Ecosystem for Robot Navigation and Manipulation", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Deploying robots at scale demands robustness to the long tail of everyday situations. The countless variations in scene layout, object geometry, and task specifications that characterize real environments are vast and underrepresented in existing robot benchmarks. Measuring this level of generalization requires infrastructure at a scale and diversity that physical evaluation alone cannot provide. We introduce MolmoSpaces, a fully open ecosystem to support large-scale benchmarking of robot policies. MolmoSpaces consists of over 230k diverse indoor environments, ranging from handcrafted household scenes to procedurally generated multiroom houses, populated with 130k richly annotated object assets, including 48k manipulable objects with 42M stable grasps. Crucially, these environments are simulator-agnostic, supporting popular options such as MuJoCo, Isaac, and ManiSkill. The ecosystem supports the full spectrum of embodied tasks: static and mobile manipulation, navigation, and multiroom long-horizon tasks requiring coordinated perception, planning, and interaction across entire indoor environments. We also design MolmoSpaces-Bench, a benchmark suite of 8 tasks in which robots interact with our diverse scenes and richly annotated objects. Our experiments show MolmoSpaces-Bench exhibits strong sim-to-real correlation (R = 0.96, \\r{ho} = 0.98), confirm newer and stronger zero-shot policies outperform earlier versions in our benchmarks, and identify key sensitivities to prompt phrasing, initial joint positions, and camera occlusion. Through MolmoSpaces and its open-source assets and tooling, we provide a foundation for scalable data generation, policy training, and benchmark creation for robot learning research.", "AI": {"tldr": "MolmoSpaces是一个大型开放生态系统，用于大规模机器人导航和操作基准测试。", "motivation": "现有机器人基准不足以代表真实环境中的多样化情况。需要一个支持大规模多样化的基础设施来衡量机器人的泛化能力。", "method": "构建了包含230k室内场景、130k物体资产的生态系统，涵盖从手工制作的家庭场景到程序生成的多房间房屋，并设计了MolmoSpaces-Bench基准测试套件。", "result": "实验表明MolmoSpaces-Bench展示了强大的仿真与现实关联性（R=0.96，ρ=0.98），并确认新政策优于旧版本。还确定了一些关键敏感因素。", "conclusion": "通过开放源代码资产和工具，提供了一个机器人学习研究的数据生成、策略训练和基准创建的基础架构"}}
{"id": "2602.11330", "pdf": "https://arxiv.org/pdf/2602.11330", "abs": "https://arxiv.org/abs/2602.11330", "authors": ["Sushmita Gupta", "Pallavi Jain", "Sanjay Seetharaman", "Meirav Zehavi"], "title": "When agents choose bundles autonomously: guarantees beyond discrepancy", "categories": ["cs.GT", "cs.DS"], "comment": "40 pages; abstract shortened due to arXiv requirements", "summary": "We consider the fair division of indivisible items among $n$ agents with additive non-negative normalized valuations, with the goal of obtaining high value guarantees, that is, close to the proportional share for each agent. We prove that partitions where \\emph{every} part yields high value for each agent are asymptotically limited by a discrepancy barrier of $Θ(\\sqrt{n})$. Guided by this, our main objective is to overcome this barrier and achieve stronger individual guarantees for each agent in polynomial time. Towards this, we are able to exhibit an exponential improvement over the discrepancy barrier. In particular, we can create partitions on-the-go such that when agents arrive sequentially (representing a previously-agreed priority order) and pick a part autonomously and rationally (i.e., one of highest value), then each is guaranteed a part of value at least $\\mathsf{PROP} - \\mathcal{O}{(\\log n)}$. Moreover, we show even better guarantees for three restricted valuation classes such as those defined by: a common ordering on items, a bound on the multiplicity of values, and a hypergraph with a bound on the \\emph{influence} of any agent. Specifically, we study instances where: (1) the agents are ``close'' to unanimity in their relative valuation of the items -- a generalization of the ordered additive setting; (2) the valuation functions do not assign the same positive value to more than $t$ items; and (3) the valuation functions respect a hypergraph, a setting introduced by Christodoulou et al. [EC'23], where agents are vertices and items are hyperedges. While the sizes of the hyperedges and neighborhoods can be arbitrary, the influence of any agent $a$, defined as the number of its neighbors who value at least one item positively that $a$ also values positively, is bounded.", "AI": {"tldr": "该论文研究了在分发不可分割物品时，通过设计新的分配策略来提高每个代理人的价值保证。", "motivation": "传统的公平分配方法受制于一个与代理人数量平方根成正比的偏差限制。本文旨在克服这一限制，并提供更强的价值保证。", "method": "提出了一个新的分配方案，在代理按特定顺序依次选择部分时，可以为每位代理人提供至少PROP - O(log n) 的价值保证。", "result": "通过新的算法设计，证明了对于满足一定条件的估值类（如接近统一性、限制重复值和尊重超图），每个代理人都能获得更高的价值保证。", "conclusion": "本文提出了一个有效的分配策略，克服了传统方法中的偏差壁垒，并在特定条件下提供了更强的价值保障。"}}
{"id": "2602.11327", "pdf": "https://arxiv.org/pdf/2602.11327", "abs": "https://arxiv.org/abs/2602.11327", "authors": ["Zeynab Anbiaee", "Mahdi Rabbani", "Mansur Mirani", "Gunjan Piya", "Igor Opushnyev", "Ali Ghorbani", "Sajjad Dadkhah"], "title": "Security Threat Modeling for Emerging AI-Agent Protocols: A Comparative Analysis of MCP, A2A, Agora, and ANP", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The rapid development of the AI agent communication protocols, including the Model Context Protocol (MCP), Agent2Agent (A2A), Agora, and Agent Network Protocol (ANP), is reshaping how AI agents communicate with tools, services, and each other. While these protocols support scalable multi-agent interaction and cross-organizational interoperability, their security principles remain understudied, and standardized threat modeling is limited; no protocol-centric risk assessment framework has been established yet. This paper presents a systematic security analysis of four emerging AI agent communication protocols. First, we develop a structured threat modeling analysis that examines protocol architectures, trust assumptions, interaction patterns, and lifecycle behaviors to identify protocol-specific and cross-protocol risk surfaces. Second, we introduce a qualitative risk assessment framework that identifies twelve protocol-level risks and evaluates security posture across the creation, operation, and update phases through systematic assessment of likelihood, impact, and overall protocol risk, with implications for secure deployment and future standardization. Third, we provide a measurement-driven case study on MCP that formalizes the risk of missing mandatory validation/attestation for executable components as a falsifiable security claim by quantifying wrong-provider tool execution under multi-server composition across representative resolver policies. Collectively, our results highlight key design-induced risk surfaces and provide actionable guidance for secure deployment and future standardization of agent communication ecosystems.", "AI": {"tldr": "本文对四种新兴AI代理通信协议(MCP、A2A、Agora和ANP)进行了系统性的安全分析。", "motivation": "这些协议支持可扩展的多代理交互和跨组织互操作性，但其安全原理研究不足，标准化威胁建模有限；目前没有建立基于协议的风险评估框架。", "method": "首先开发了结构化威胁建模分析方法，其次引入了一个定性的风险评估框架，最后通过量化测试提供了MCP的案例研究。", "result": "结果突显了设计诱导的安全风险表面，并为安全部署和未来标准化提供可操作的指导建议。", "conclusion": "本文的结果强调了协议特定及跨协议的风险面，并为AI代理通信生态系统的安全部署和未来标准化提供了有益的见解。"}}
{"id": "2602.11324", "pdf": "https://arxiv.org/pdf/2602.11324", "abs": "https://arxiv.org/abs/2602.11324", "authors": ["Jonas Ellert", "Tomasz Kociumaka"], "title": "Time-Optimal Construction of String Synchronizing Sets", "categories": ["cs.DS"], "comment": "Full version of a work to appear in the proceedings of STACS 2026. The abstract has been abridged to comply with arXiv format requirements", "summary": "A key principle in string processing is local consistency: using short contexts to handle matching fragments of a string consistently. String synchronizing sets [Kempa, Kociumaka; STOC 2019] are an influential instantiation of this principle. A $τ$-synchronizing set of a length-$n$ string is a set of $O(n/τ)$ positions, chosen via their length-$2τ$ contexts, such that (outside highly periodic regions) at least one position in every length-$τ$ window is selected. Among their applications are faster algorithms for data compression, text indexing, and string similarity in the word RAM model. We show how to preprocess any string $T \\in [0..σ)^n$ in $O(n\\logσ/\\log n)$ time so that, for any $τ\\in[1..n]$, a $τ$-synchronizing set of $T$ can be constructed in $O((n\\logτ)/(τ\\log n))$ time. Both bounds are optimal in the word RAM model with word size $w=Θ(\\log n)$. Previously, the construction time was $O(n/τ)$, either after an $O(n)$-time preprocessing [Kociumaka, Radoszewski, Rytter, Waleń; SICOMP 2024], or without preprocessing if $τ<0.2\\log_σn$ [Kempa, Kociumaka; STOC 2019]. A simple version of our method outputs the set as a sorted list in $O(n/τ)$ time, or as a bitmask in $O(n/\\log n)$ time. Our optimal construction produces a compact fully indexable dictionary, supporting select queries in $O(1)$ time and rank queries in $O(\\log(\\tfrac{\\logτ}{\\log\\log n}))$ time, matching unconditional cell-probe lower bounds for $τ\\le n^{1-Ω(1)}$. We achieve this via a new framework for processing sparse integer sequences in a custom variable-length encoding. For rank and select queries, we augment the optimal variant of van Emde Boas trees [Pătraşcu, Thorup; STOC 2006] with a deterministic linear-time construction. The above query-time guarantees hold after preprocessing time proportional to the encoding size (in words).", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.11323", "pdf": "https://arxiv.org/pdf/2602.11323", "abs": "https://arxiv.org/abs/2602.11323", "authors": ["Arda Alniak", "Sinan Kalkan", "Mustafa Mert Ankarali", "Afsar Saranli", "Abdullah Aydin Alatan"], "title": "MDE-VIO: Enhancing Visual-Inertial Odometry Using Learned Depth Priors", "categories": ["cs.CV"], "comment": "6 pages, 2 figures, 3 tables. Submitted to ICIP 2026", "summary": "Traditional monocular Visual-Inertial Odometry (VIO) systems struggle in low-texture environments where sparse visual features are insufficient for accurate pose estimation. To address this, dense Monocular Depth Estimation (MDE) has been widely explored as a complementary information source. While recent Vision Transformer (ViT) based complex foundational models offer dense, geometrically consistent depth, their computational demands typically preclude them from real-time edge deployment. Our work bridges this gap by integrating learned depth priors directly into the VINS-Mono optimization backend. We propose a novel framework that enforces affine-invariant depth consistency and pairwise ordinal constraints, explicitly filtering unstable artifacts via variance-based gating. This approach strictly adheres to the computational limits of edge devices while robustly recovering metric scale. Extensive experiments on the TartanGround and M3ED datasets demonstrate that our method prevents divergence in challenging scenarios and delivers significant accuracy gains, reducing Absolute Trajectory Error (ATE) by up to 28.3%. Code will be made available.", "AI": {"tldr": "本文提出了一种利用学习到的深度先验增强视觉惯性里程计性能的方法，特别是在低纹理环境下。", "motivation": "传统的单目视觉惯性里程计在低纹理环境中难以准确估计姿态。为了克服这一问题，引入了密集单目深度估计作为辅助信息来源。然而，基于Vision Transformer的大模型计算需求高，不适合边缘设备实时部署。", "method": "本文提出了一种新的框架，该框架将学习到的深度先验直接集成到VINS-Mono优化后端中，并采用了仿射不变性深度一致性约束和成对序数约束，通过方差门控滤除不稳定特征。", "result": "实验结果表明，在TartanGround和M3ED数据集上，本文方法在挑战性场景下防止了发散现象，并显著提高了精度，最大降低了28.3%的绝对轨迹误差。", "conclusion": "该研究成功将学习到的深度先验集成到VIO系统中，有效解决了低纹理环境中的姿态估计问题，同时保持了较低的计算需求。"}}
{"id": "2602.11322", "pdf": "https://arxiv.org/pdf/2602.11322", "abs": "https://arxiv.org/abs/2602.11322", "authors": ["Jason Dury"], "title": "Predictive Associative Memory: Retrieval Beyond Similarity Through Temporal Co-occurrence", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "20 pages, 6 figures, for associated Git: https://github.com/EridosAI/PAM-Benchmark", "summary": "Current approaches to memory in neural systems rely on similarity-based retrieval: given a query, find the most representationally similar stored state. This assumption -- that useful memories are similar memories -- fails to capture a fundamental property of biological memory: association through temporal co-occurrence. We propose Predictive Associative Memory (PAM), an architecture in which a JEPA-style predictor, trained on temporal co-occurrence within a continuous experience stream, learns to navigate the associative structure of an embedding space. We introduce an Inward JEPA that operates over stored experience (predicting associatively reachable past states) as the complement to the standard Outward JEPA that operates over incoming sensory data (predicting future states). We evaluate PAM as an associative recall system -- testing faithfulness of recall for experienced associations -- rather than as a retrieval system evaluated on generalisation to unseen associations. On a synthetic benchmark, the predictor's top retrieval is a true temporal associate 97% of the time (Association Precision@1 = 0.970); it achieves cross-boundary Recall@20 = 0.421 where cosine similarity scores zero; and it separates experienced-together from never-experienced-together states with a discrimination AUC of 0.916 (cosine: 0.789). Even restricted to cross-room pairs where embedding similarity is uninformative, the predictor achieves AUC = 0.849 (cosine: 0.503, chance). A temporal shuffle control confirms the signal is genuine temporal co-occurrence structure, not embedding geometry: shuffling collapses cross-boundary recall by 90%, replicated across training seeds. All results are stable across seeds (SD < 0.006) and query selections (SD $\\leq$ 0.012).", "AI": {"tldr": "提出了一种基于时间共现的预测关联记忆模型PAM，以解决现有相似性检索方法在生物记忆中的不足。", "motivation": "当前神经系统中的记忆方法依赖于相似度检索，在生物记忆中，这种假设未能捕捉到通过时间共现进行关联的本质特性。", "method": "提出了一种新架构，其中JEPA风格的预测器基于连续体验流中的时间共现训练来学习嵌入空间中的关联结构。引入了向内JEPA以操作存储经验（预测可达过去状态），作为标准向外JEPA（预测未来状态）的补充。", "result": "在合成基准上，PAM模型的前一检索是真正的时间相关项97%的时间；它实现了跨边界召回率20=0.421（余弦相似度得分为零）。即使限制为嵌入相似性无信息的情境下，仍实现AUC = 0.849。", "conclusion": "PAM模型成功解决了通过时间共现进行记忆关联的问题，并验证了其性能在跨种子和查询选择上的稳定性。"}}
{"id": "2602.11321", "pdf": "https://arxiv.org/pdf/2602.11321", "abs": "https://arxiv.org/abs/2602.11321", "authors": ["Ziyan Xiong", "Lixing Fang", "Junyun Huang", "Kashu Yamazaki", "Hao Zhang", "Chuang Gan"], "title": "ExtremControl: Low-Latency Humanoid Teleoperation with Direct Extremity Control", "categories": ["cs.RO"], "comment": "Project website: https://owenowl.github.io/extremcontrol", "summary": "Building a low-latency humanoid teleoperation system is essential for collecting diverse reactive and dynamic demonstrations. However, existing approaches rely on heavily pre-processed human-to-humanoid motion retargeting and position-only PD control, resulting in substantial latency that severely limits responsiveness and prevents tasks requiring rapid feedback and fast reactions. To address this problem, we propose ExtremControl, a low latency whole-body control framework that: (1) operates directly on SE(3) poses of selected rigid links, primarily humanoid extremities, to avoid full-body retargeting; (2) utilizes a Cartesian-space mapping to directly convert human motion to humanoid link targets; and (3) incorporates velocity feedforward control at low level to support highly responsive behavior under rapidly changing control interfaces. We further provide a unified theoretical formulation of ExtremControl and systematically validate its effectiveness through experiments in both simulation and real-world environments. Building on ExtremControl, we implement a low-latency humanoid teleoperation system that supports both optical motion capture and VR-based motion tracking, achieving end-to-end latency as low as 50ms and enabling highly responsive behaviors such as ping-pong ball balancing, juggling, and real-time return, thereby substantially surpassing the 200ms latency limit observed in prior work.", "AI": {"tldr": "本文提出了一种低延迟的人形机器人遥操作框架ExtremControl，该框架通过直接控制选定的刚性链接（主要是人形机器人的四肢）以及利用笛卡尔空间映射来实现快速响应和高精度控制。", "motivation": "现有方法依赖于复杂的肢体运动重定向与位置PID控制，导致延迟较大，影响实时反馈及快速反应任务的表现。为了减少延时并提高响应速度，本文提出了直接操作刚性链接的低延迟遥操作系统。", "method": "ExtremControl框架通过选择性地操控人形机器人的SE(3)姿态来避免全身重新定向，并使用笛卡尔空间映射将人类动作直接转换为人形机器人链接的目标。此外，该系统还采用了低级速度前馈控制以支持快速变化的操作接口下的高响应行为。", "result": "实验结果显示，在模拟和真实环境中，ExtremControl实现了最低50ms的端到端延迟，并成功执行了诸如平衡乒乓球、接球等需要高度反应能力的任务，这比先前工作的200ms延迟限制有了显著改进。", "conclusion": "通过直接操作选定刚性链接并结合笛卡尔空间映射和速度前馈控制，ExtremControl框架能够在低延时的情况下实现高效的人形机器人遥操作。"}}
{"id": "2602.11318", "pdf": "https://arxiv.org/pdf/2602.11318", "abs": "https://arxiv.org/abs/2602.11318", "authors": ["Sheza Munir", "Benjamin Mah", "Krisha Kalsi", "Shivani Kapania", "Julian Posada", "Edith Law", "Ding Wang", "Syed Ishtiaque Ahmed"], "title": "Dissecting Subjectivity and the \"Ground Truth\" Illusion in Data Annotation", "categories": ["cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "In machine learning, \"ground truth\" refers to the assumed correct labels used to train and evaluate models. However, the foundational \"ground truth\" paradigm rests on a positivistic fallacy that treats human disagreement as technical noise rather than a vital sociotechnical signal. This systematic literature review analyzes research published between 2020 and 2025 across seven premier venues: ACL, AIES, CHI, CSCW, EAAMO, FAccT, and NeurIPS, investigating the mechanisms in data annotation practices that facilitate this \"consensus trap\". Our identification phase captured 30,897 records, which were refined via a tiered keyword filtration schema to a high-recall corpus of 3,042 records for manual screening, resulting in a final included corpus of 346 papers for qualitative synthesis. Our reflexive thematic analysis reveals that systemic failures in positional legibility, combined with the recent architectural shift toward human-as-verifier models, specifically the reliance on model-mediated annotations, introduce deep-seated anchoring bias and effectively remove human voices from the loop. We further demonstrate how geographic hegemony imposes Western norms as universal benchmarks, often enforced by the performative alignment of precarious data workers who prioritize requester compliance over honest subjectivity to avoid economic penalties. Critiquing the \"noisy sensor\" fallacy, where statistical models misdiagnose cultural pluralism as random error, we argue for reclaiming disagreement as a high-fidelity signal essential for building culturally competent models. To address these systemic tensions, we propose a roadmap for pluralistic annotation infrastructures that shift the objective from discovering a singular \"right\" answer to mapping the diversity of human experience.", "AI": {"tldr": "本文通过系统文献综述，分析了数据标注实践中存在的问题，并提出了解决方案。", "motivation": "该研究质疑“地面真实”的假设，揭示出在机器学习中将人类分歧视为技术噪音而非重要信号的谬误。目的是探讨和解决数据标注中存在的深层偏见和规范性问题。", "method": "论文通过一个分层关键词过滤策略筛选文献，从30897篇记录中确定了最终包含的346篇文章进行定性综合分析。", "result": "研究发现系统性失败导致的位置透明度缺失、模型中介标注依赖以及西方规范强加等问题，并证明这些因素如何通过文化多样性的误诊作为随机错误而加剧。", "conclusion": "论文批判了“噪音传感器谬论”，并提出了构建包容多元体验的注释基础设施道路图，以解决这些问题。"}}
{"id": "2602.11316", "pdf": "https://arxiv.org/pdf/2602.11316", "abs": "https://arxiv.org/abs/2602.11316", "authors": ["Ishan Mishra", "Jiajie Li", "Deepak Mishra", "Jinjun Xiong"], "title": "Selective Prior Synchronization via SYNC Loss", "categories": ["cs.CV"], "comment": null, "summary": "Prediction under uncertainty is a critical requirement for the deep neural network to succeed responsibly. This paper focuses on selective prediction, which allows DNNs to make informed decisions about when to predict or abstain based on the uncertainty level of their predictions. Current methods are either ad-hoc such as SelectiveNet, focusing on how to modify the network architecture or objective function, or post-hoc such as softmax response, achieving selective prediction through analyzing the model's probabilistic outputs. We observe that post-hoc methods implicitly generate uncertainty information, termed the selective prior, which has traditionally been used only during inference. We argue that the selective prior provided by the selection mechanism is equally vital during the training stage. Therefore, we propose the SYNC loss which introduces a novel integration of ad-hoc and post-hoc method. Specifically, our approach incorporates the softmax response into the training process of SelectiveNet, enhancing its selective prediction capabilities by examining the selective prior. Evaluated across various datasets, including CIFAR-100, ImageNet-100, and Stanford Cars, our method not only enhances the model's generalization capabilities but also surpasses previous works in selective prediction performance, and sets new benchmarks for state-of-the-art performance.", "AI": {"tldr": "该论文提出了SYNC损失，通过将softmax响应纳入SelectiveNet的训练过程，实现了不确定条件下的选择性预测。", "motivation": "当前的选择性预测方法存在不足，要么是修改网络架构或目标函数的ad-hoc方法，要么是在分析模型概率输出基础上的post-hoc方法。论文提出一种新的损失SYNC，整合了这两种方法的优点，并在训练阶段利用选择性先验来提升选择性预测能力。", "method": "该研究提出了一个名为SYNC的新损失函数，它将softmax响应融入SelectiveNet的训练过程中，通过这种方式提升了模型的选择性预测性能。", "result": "实验结果显示，在CIFAR-100、ImageNet-100和Stanford Cars数据集上，该方法不仅增强了模型的泛化能力，而且在选择性预测性能方面超越了先前的工作，并设定了新的基准。", "conclusion": "SYNC损失函数通过整合ad-hoc与post-hoc方法的优势，在训练阶段利用选择性先验提升了模型的选择性预测能力，从而改善了模型的不确定条件下的决策表现。"}}
{"id": "2602.11314", "pdf": "https://arxiv.org/pdf/2602.11314", "abs": "https://arxiv.org/abs/2602.11314", "authors": ["Jacob Rubinstein", "Avi Donaty", "Don Engel"], "title": "Advancing Digital Twin Generation Through a Novel Simulation Framework and Quantitative Benchmarking", "categories": ["cs.CV", "cs.GR"], "comment": "9 pages, 10 figures. Preprint", "summary": "The generation of 3D models from real-world objects has often been accomplished through photogrammetry, i.e., by taking 2D photos from a variety of perspectives and then triangulating matched point-based features to create a textured mesh. Many design choices exist within this framework for the generation of digital twins, and differences between such approaches are largely judged qualitatively. Here, we present and test a novel pipeline for generating synthetic images from high-quality 3D models and programmatically generated camera poses. This enables a wide variety of repeatable, quantifiable experiments which can compare ground-truth knowledge of virtual camera parameters and of virtual objects against the reconstructed estimations of those perspectives and subjects.", "AI": {"tldr": "提出了一种新的生成合成图像的管道，用于从高质量的三维模型和程序生成的相机姿态进行数字孪生的比较性实验", "motivation": "现有方法对3D模型生成的质量评估多为定性的，缺乏定量基准。本文旨在通过设计一种新框架来量化这些差异并提高数字孪生的准确性", "method": "使用高精度3D模型和程序化生成的摄像机姿态，创建合成图像以进行可重复的、量化的实验", "result": "实现了对虚拟相机参数和对象视角重建估计的精确比较，增强了数字孪生生成的质量评估能力", "conclusion": "新方法提供了一种有效的手段来量化不同设计选择下的数字孪生效果，并有助于提高3D模型生成的整体质量"}}
{"id": "2602.11311", "pdf": "https://arxiv.org/pdf/2602.11311", "abs": "https://arxiv.org/abs/2602.11311", "authors": ["Caitlin Morris", "Pattie Maes"], "title": "Same Feedback, Different Source: How AI vs. Human Feedback Shapes Learner Engagement", "categories": ["cs.HC"], "comment": "7 pages, 5 figures", "summary": "When learners receive feedback, what they believe about its source may shape how they engage with it. As AI is used alongside human instructors, understanding these attribution effects is essential for designing effective hybrid AI-human educational systems. We designed a creative coding interface that isolates source attribution while controlling for content: all participants receive identical LLM-generated feedback, but half see it attributed to AI and half to a human teaching assistant (TA). We found two key results. First, perceived feedback source affected engagement: learners in the TA condition spent significantly more time and effort (d = 0.88-1.56) despite receiving identical feedback. Second, perceptions differed: AI-attributed feedback ratings were predicted by prior trust in AI (r = 0.85), while TA-attributed ratings were predicted by perceived genuineness (r = 0.65). These findings suggest that feedback source shapes both engagement and evaluation, with implications for hybrid educational system design.", "AI": {"tldr": "研究探讨了学习者收到相同反馈但来源不同（AI或人类助教）时的学习参与度和评价差异。", "motivation": "随着人工智能在教育中的应用，了解反馈源如何影响学生行为对于设计有效的混合教学系统至关重要。", "method": "设计了一个创意编程界面，所有参与者都接收相同的LLM生成的反馈，但一半认为来自AI，另一半认为来自人类助教。研究了来源归因对参与度的影响以及不同来源归因下的评价差异。", "result": "结果显示，学习者在认为反馈来源于人类助教的情况下投入更多时间和精力；同时，AI源的信任程度和人类源的真诚感分别影响反馈评价。", "conclusion": "反馈来源显著影响学生的行为与评价，这对于混合教学系统的设计具有重要意义。"}}
{"id": "2602.11304", "pdf": "https://arxiv.org/pdf/2602.11304", "abs": "https://arxiv.org/abs/2602.11304", "authors": ["Anushri Eswaran", "Oleg Golev", "Darshan Tank", "Sidhant Rahi", "Himanshu Tyagi"], "title": "CryptoAnalystBench: Failures in Multi-Tool Long-Form LLM Analysis", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Modern analyst agents must reason over complex, high token inputs, including dozens of retrieved documents, tool outputs, and time sensitive data. While prior work has produced tool calling benchmarks and examined factuality in knowledge augmented systems, relatively little work studies their intersection: settings where LLMs must integrate large volumes of dynamic, structured and unstructured multi tool outputs. We investigate LLM failure modes in this regime using crypto as a representative high data density domain. We introduce (1) CryptoAnalystBench, an analyst aligned benchmark of 198 production crypto and DeFi queries spanning 11 categories; (2) an agentic harness equipped with relevant crypto and DeFi tools to generate responses across multiple frontier LLMs; and (3) an evaluation pipeline with citation verification and an LLM as a judge rubric spanning four user defined success dimensions: relevance, temporal relevance, depth, and data consistency. Using human annotation, we develop a taxonomy of seven higher order error types that are not reliably captured by factuality checks or LLM based quality scoring. We find that these failures persist even in state of the art systems and can compromise high stakes decisions. Based on this taxonomy, we refine the judge rubric to better capture these errors. While the judge does not align with human annotators on precise scoring across rubric iterations, it reliably identifies critical failure modes, enabling scalable feedback for developers and researchers studying analyst style agents. We release CryptoAnalystBench with annotated queries, the evaluation pipeline, judge rubrics, and the error taxonomy, and outline mitigation strategies and open challenges in evaluating long form, multi tool augmented systems.", "AI": {"tldr": "该论文通过引入CryptoAnalystBench，研究LLM在处理大量动态、结构化和非结构化的多工具输出时的失败模式。", "motivation": "先前的工作主要集中在单独的研究领域中，例如工具有呼叫基准或知识增强系统中的准确性。然而，在这些领域的交集中，即LLM必须整合大规模多样化数据的情况下研究相对较少。", "method": "该论文通过构建CryptoAnalystBench，使用加密货币作为高密度数据的代表领域，并引入了一种代理工具来生成跨前沿LLM的回答。同时，开发了一个评估管道，包括引用验证和LLM评分规则，以捕捉四种类别的成功维度：相关性、时效性、深度和数据一致性。", "result": "人类注释者根据七个高级错误类型的发展，这些错误无法通过事实检查或基于LLM的质量得分可靠地捕获。即使在最先进的系统中也存在这些问题，并可能影响重大决策。", "conclusion": "论文提出了一个新的评估管道以更好地捕捉这类错误，并提供了CryptoAnalystBench、注释查询和评判标准等资源供开发人员使用，同时指出了评估长篇多工具增强系统的挑战与策略。"}}
{"id": "2602.11301", "pdf": "https://arxiv.org/pdf/2602.11301", "abs": "https://arxiv.org/abs/2602.11301", "authors": ["John M. Willis"], "title": "The PBSAI Governance Ecosystem: A Multi-Agent AI Reference Architecture for Securing Enterprise AI Estates", "categories": ["cs.AI", "cs.CR"], "comment": "43 pages, plus 12 pages of appendices. One Figure", "summary": "Enterprises are rapidly deploying large language models, retrieval augmented generation pipelines, and tool using agents into production, often on shared high performance computing clusters and cloud accelerator platforms that also support defensive analytics. These systems increasingly function not as isolated models but as AI estates: socio technical systems spanning models, agents, data pipelines, security tooling, human workflows, and hyperscale infrastructure. Existing governance and security frameworks, including the NIST AI Risk Management Framework and systems security engineering guidance, articulate principles and risk functions but do not provide implementable architectures for multi agent, AI enabled cyber defense. This paper introduces the Practitioners Blueprint for Secure AI (PBSAI) Governance Ecosystem, a multi agent reference architecture for securing enterprise and hyperscale AI estates. PBSAI organizes responsibilities into a twelve domain taxonomy and defines bounded agent families that mediate between tools and policy through shared context envelopes and structured output contracts. The architecture assumes baseline enterprise security capabilities and encodes key systems security techniques, including analytic monitoring, coordinated defense, and adaptive response. A lightweight formal model of agents, context envelopes, and ecosystem level invariants clarifies the traceability, provenance, and human in the loop guarantees enforced across domains. We demonstrate alignment with NIST AI RMF functions and illustrate application in enterprise SOC and hyperscale defensive environments. PBSAI is proposed as a structured, evidence centric foundation for open ecosystem development and future empirical validation.", "AI": {"tldr": "介绍PBSAI治理生态系统，一个多代理参考架构，旨在为企业和超大规模的人工智能庄园提供安全保障。", "motivation": "随着企业迅速将大型语言模型、增强生成管道和工具使用代理部署到生产环境中，现有的治理体系难以应对这些复杂的多代理人工智能防御需求。因此需要一种新的架构来解决这些问题。", "method": "提出了PBSAI治理生态系统这一多代理参考架构，该系统定义了责任域分类，并通过共享上下文包和结构化输出合同连接工件与政策。它还提供了轻量级的形式模型以确保可追溯性、出处和人机交互保证。", "result": "演示了与NIST AI RMF功能的一致性和在企业SOC和超大规模防御环境中的应用实例。", "conclusion": "PBSAI被提议作为开放生态系统开发的结构化证据中心基础，并为未来的实证验证做准备。"}}
{"id": "2602.11298", "pdf": "https://arxiv.org/pdf/2602.11298", "abs": "https://arxiv.org/abs/2602.11298", "authors": ["Alexander H. Liu", "Andy Ehrenberg", "Andy Lo", "Chen-Yo Sun", "Guillaume Lample", "Jean-Malo Delignon", "Khyathi Raghavi Chandu", "Patrick von Platen", "Pavankumar Reddy Muddireddy", "Rohin Arora", "Sanchit Gandhi", "Sandeep Subramanian", "Soham Ghosh", "Srijan Mishra", "Abhinav Rastogi", "Alan Jeffares", "Albert Jiang", "Alexandre Sablayrolles", "Amélie Héliou", "Andrew Bai", "Angele Lenglemetz", "Anmol Agarwal", "Anton Eliseev", "Antonia Calvi", "Arjun Majumdar", "et al. (109 additional authors not shown)"], "title": "Voxtral Realtime", "categories": ["cs.AI"], "comment": null, "summary": "We introduce Voxtral Realtime, a natively streaming automatic speech recognition model that matches offline transcription quality at sub-second latency. Unlike approaches that adapt offline models through chunking or sliding windows, Voxtral Realtime is trained end-to-end for streaming, with explicit alignment between audio and text streams. Our architecture builds on the Delayed Streams Modeling framework, introducing a new causal audio encoder and Ada RMS-Norm for improved delay conditioning. We scale pretraining to a large-scale dataset spanning 13 languages. At a delay of 480ms, Voxtral Realtime achieves performance on par with Whisper, the most widely deployed offline transcription system. We release the model weights under the Apache 2.0 license.", "AI": {"tldr": "介绍了一个实时语音识别模型Voxtral Realtime，该模型在次秒级延迟下达到离线转录质量。", "motivation": "现有方法通常通过分块或滑动窗口来适应离线模型，而本文提出的方法是端到端训练的流式模型，旨在提高实时性同时保持高质量的语音识别结果。", "method": "采用延迟流建模框架，引入了新的因果音频编码器和Ada RMS-Norm以改进延迟条件。使用跨越13种语言的大规模数据集进行预训练。", "result": "在480毫秒延迟下，Voxtral Realtime的性能与广泛部署的离线转录系统Whisper相当。", "conclusion": "本文提出的模型能够实现实时语音识别，并达到高质量的转录效果。"}}
{"id": "2602.11295", "pdf": "https://arxiv.org/pdf/2602.11295", "abs": "https://arxiv.org/abs/2602.11295", "authors": ["Gil Raitses"], "title": "On Decision-Valued Maps and Representational Dependence", "categories": ["cs.AI", "cs.DB"], "comment": "10 pages, 3 figures, 5 tables", "summary": "A computational engine applied to different representations of the same data can produce different discrete outcomes, with some representations preserving the result and others changing it entirely. A decision-valued map records which representations preserve the outcome and which change it, associating each member of a declared representation family with the discrete result it produces. This paper formalizes decision-valued maps and describes DecisionDB, an infrastructure that logs, replays and audits these relationships using identifiers computed from content and artifacts stored in write-once form. Deterministic replay recovers each recorded decision identifier exactly from stored artifacts, with all three identifying fields matching their persisted values. The contribution partitions representation space into persistence regions and boundaries, and treats decision reuse as a mechanically checkable condition.", "AI": {"tldr": "本文主要任务是通过决策值映射和DecisionDB基础设施，记录不同数据表示方式下计算引擎产生的离散结果及其关联性。", "motivation": "当相同的数据显示为不同的形式时，应用于这些显示的数据的计算引擎可能会产生不同的离散输出。此文章旨在研究如何记录并审计这些变化以提高理解。", "method": "作者提出了决策值映射的概念，并构建了DecisionDB基础设施来记录和重现不同数据表示方式下的决策结果关系，使用标识符从内容及其存储的工件中计算得出。", "result": "通过分区表示空间为持久性和边界区域的方式，机械地检查决策重用条件成为可能。", "conclusion": "本文贡献在于提供了一种机制来理解和处理不同数据表示方式对计算结果的影响。"}}
{"id": "2602.11291", "pdf": "https://arxiv.org/pdf/2602.11291", "abs": "https://arxiv.org/abs/2602.11291", "authors": ["Wenyuan Chen", "Jinbang Huang", "Oscar Pang", "Zhiyuan Li", "Xiao Hu", "Lingfeng Zhang", "Zhanguang Zhang", "Mark Coates", "Tongtong Cao", "Xingyue Quan", "Yingxue Zhang"], "title": "H-WM: Robotic Task and Motion Planning Guided by Hierarchical World Model", "categories": ["cs.RO"], "comment": "14 pages, 3 figures", "summary": "World models are becoming central to robotic planning and control, as they enable prediction of future state transitions. Existing approaches often emphasize video generation or natural language prediction, which are difficult to directly ground in robot actions and suffer from compounding errors over long horizons. Traditional task and motion planning relies on symbolic logic world models, such as planning domains, that are robot-executable and robust for long-horizon reasoning. However, these methods typically operate independently of visual perception, preventing synchronized symbolic and perceptual state prediction. We propose a Hierarchical World Model (H-WM) that jointly predicts logical and visual state transitions within a unified bilevel framework. H-WM combines a high-level logical world model with a low-level visual world model, integrating the robot-executable, long-horizon robustness of symbolic reasoning with perceptual grounding from visual observations. The hierarchical outputs provide stable and consistent intermediate guidance for long-horizon tasks, mitigating error accumulation and enabling robust execution across extended task sequences. To train H-WM, we introduce a robotic dataset that aligns robot motion with symbolic states, actions, and visual observations. Experiments across vision-language-action (VLA) control policies demonstrate the effectiveness and generality of the approach.", "AI": {"tldr": "提出了一种层次世界模型H-WM，用于机器人任务和运动规划。", "motivation": "现有方法难以直接将视频生成或自然语言预测与机器人动作联系起来，并且在长时序上容易积累误差。传统的方法通常独立于视觉感知，不能同步执行符号逻辑和感知状态的预测。", "method": "提出了一种层次世界模型H-WM，在统一的双层框架中同时预测逻辑和视觉状态转换。结合高层次的逻辑模型与低层次的视觉模型，将符号推理的长期稳健性与从视觉观察中获得的感觉接地相结合。", "result": "实验表明了所提方法在跨长任务序列上的稳定性和一致性指导，以及有效性和通用性。", "conclusion": "H-WM结合了逻辑和感知状态预测的能力，在机器人规划和控制领域展示了强大的应用前景。"}}
{"id": "2602.11287", "pdf": "https://arxiv.org/pdf/2602.11287", "abs": "https://arxiv.org/abs/2602.11287", "authors": ["Yuanyong Luo", "Jing Huang", "Yu Cheng", "Ziwei Yu", "Kaihua Zhang", "Kehong Hong", "Xinda Ma", "Xin Wang", "Anping Tong", "Guipeng Hu", "Yun Xu", "Mehran Taghian", "Peng Wu", "Guanglin Li", "Yunke Peng", "Tianchi Hu", "Minqi Chen", "Michael Bi Mi", "Hu Liu", "Xiping Zhou", "Junsong Wang", "Qiang Lin", "Heng Liao"], "title": "HiFloat4 Format for Language Model Inference", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": "8 pages, 4 figures", "summary": "This paper introduces HiFloat4 (HiF4), a block floating-point data format tailored for deep learning. Each HiF4 unit packs 64 4-bit elements with 32 bits of shared scaling metadata, averaging 4.5 bits per value. The metadata specifies a three-level scaling hierarchy, capturing inter- and intra-group dynamic range while improving the utilization of the representational space. In addition, the large 64-element group size enables matrix multiplications to be executed in a highly fixed-point manner, significantly reducing hardware area and power consumption. To evaluate the proposed format, we conducted inference experiments on several language models, including LLaMA, Qwen, Mistral, DeepSeek-V3.1 and LongCat. Results show that HiF4 achieves higher average accuracy than the state-of-the-art NVFP4 format across multiple models and diverse downstream tasks.", "AI": {"tldr": "介绍了一种名为HiFloat4（HiF4）的深度学习专用块浮点数据格式。", "motivation": "旨在开发一种高效的数据表示方式，以提高深度学习模型的精度和减少硬件资源消耗。", "method": "提出了一种新的数据格式HiF4，通过使用32位共享缩放元数据和64个元素组大小来优化矩阵乘法计算。", "result": "实验结果表明，在多个语言模型上，HiF4格式的平均精度高于现有最佳的NVFP4格式。", "conclusion": "HiFloat4是一种能够在保持高精度的同时减少硬件消耗的有效方法。"}}
{"id": "2602.11281", "pdf": "https://arxiv.org/pdf/2602.11281", "abs": "https://arxiv.org/abs/2602.11281", "authors": ["Alessandro Meroni", "Nicolò Oreste Pinciroli Vago", "Piero Fraternali"], "title": "DeepRed: an architecture for redshift estimation", "categories": ["astro-ph.IM", "cs.AI", "cs.LG", "gr-qc"], "comment": "Accepted for publication in Neural Computing and Applications", "summary": "Estimating redshift is a central task in astrophysics, but its measurement is costly and time-consuming. In addition, current image-based methods are often validated on homogeneous datasets. The development and comparison of networks able generalize across different morphologies, ranging from galaxies to gravitationally-lensed transients, and observational conditions, remain an open challenge. This work proposes DeepRed, a deep learning pipeline that demonstrates how modern computer vision architectures, including ResNet, EfficientNet, Swin Transformer, and MLP-Mixer, can estimate redshifts from images of galaxies, gravitational lenses, and gravitationally-lensed supernovae. We compare these architectures and their ensemble to both neural networks (A1, A3, NetZ, and PhotoZ) and a feature-based method (HOG+SVR) on simulated (DeepGraviLens) and real (KiDS, SDSS) datasets. Our approach achieves state-of-the-art results on all datasets. On DeepGraviLens, DeepRed achieves a significant improvement in the Normalized Mean Absolute Deviation compared to the best baseline (PhotoZ): 55% on DES-deep (using EfficientNet), 51% on DES-wide (Ensemble), 52% on DESI-DOT (Ensemble), and 46% on LSST-wide (Ensemble). On real observations from the KiDS survey, the pipeline outperforms the best baseline (NetZ), improving NMAD by 16% on a general test set without high-probability lenses (Ensemble) and 27% on high-probability lenses (Ensemble). For non-lensed galaxies in the SDSS dataset, the MLP-Mixer architecture achieves a 5% improvement over the best baselines (A3 and NetZ). SHAP shows that the models correctly focus on the objects of interest with over 95% localization accuracy on high-quality images, validating the reliability of the predictions. These findings suggest that deep learning is a scalable, robust, and interpretable solution for redshift estimation in large-scale surveys.", "AI": {"tldr": "DeepRed是一种用于估计红移的深度学习管道，通过现代计算机视觉架构展示了从星系、引力透镜和重力透镜超新星图像中估算红移的能力。", "motivation": "当前基于图像的方法通常在同质数据集上验证，并且难以推广至不同形态及观测条件下。论文旨在开发一种能够跨不同类型天体和观测条件泛化的深度学习网络，以提高红移估计的准确性和效率。", "method": "使用了包括ResNet、EfficientNet、Swin Transformer 和 MLP-Mixer在内的现代计算机视觉架构，并与现有神经网络（A1, A3, NetZ和PhotoZ）及特征基方法（HOG+SVR）进行对比。在DeepGraviLens模拟数据集和KiDS、SDSS真实观测数据集中进行了验证。", "result": "在所有数据集上均实现了最先进的结果，特别是在DeepGraviLens仿真数据集上的NMAD相比最优基准（PhotoZ），使用EfficientNet模型改进了55%，而Ensemble模型分别提高了46%到52%。对于KiDS真实观测数据集，管道优于最佳基线（NetZ），在一般测试集中NMAD提高16%，而在高概率透镜中提高27%。", "conclusion": "该研究证明了深度学习是大规模调查中红移估计的可扩展、稳健和解释性解决方案。这些模型能够准确地聚焦目标，显示出预测结果的高度可靠性。"}}
{"id": "2602.11250", "pdf": "https://arxiv.org/pdf/2602.11250", "abs": "https://arxiv.org/abs/2602.11250", "authors": ["Julia Gaudio", "Charlie K. Guan"], "title": "An Improved Upper Bound for the Euclidean TSP Constant Using Band Crossovers", "categories": ["cs.CG", "cs.DS", "math.CO", "math.PR"], "comment": null, "summary": "Consider $n$ points generated uniformly at random in the unit square, and let $L_n$ be the length of their optimal traveling salesman tour. Beardwood, Halton, and Hammersley (1959) showed $L_n / \\sqrt n \\to β$ almost surely as $n\\to \\infty$ for some constant $β$. The exact value of $β$ is unknown but estimated to be approximately $0.71$ (Applegate, Bixby, Chvátal, Cook 2011). Beardwood et al. further showed that $0.625 \\leq β\\leq 0.92116.$ Currently, the best known bounds are $0.6277 \\leq β\\leq 0.90380$, due to Gaudio and Jaillet (2019) and Carlsson and Yu (2023), respectively. The upper bound was derived using a computer-aided approach that is amenable to lower bounds with improved computation speed. In this paper, we show via simulation and concentration analysis that future improvement of the $0.90380$ is limited to $\\sim0.88$. Moreover, we provide an alternative tour-constructing heuristic that, via simulation, could potentially improve the upper bound to $\\sim0.85$. Our approach builds on a prior \\emph{band-traversal} strategy, initially proposed by Beardwood et al. (1959) and subsequently refined by Carlsson and Yu (2023): divide the unit square into bands of height $Θ(1/\\sqrt{n})$, construct paths within each band, and then connect the paths to create a TSP tour. Our approach allows paths to cross bands, and takes advantage of pairs of points in adjacent bands which are close to each other. A rigorous numerical analysis improves the upper bound to $0.90367$.", "AI": {"tldr": "通过模拟和集中分析改进了旅行商问题（TSP）常数的上界。", "motivation": "Beardwood等人提出的原始方法虽然有效，但存在局限性，因此作者旨在通过引入新的策略来进一步提高上界的准确度。", "method": "采用带遍历策略并允许路径跨越带区；通过模拟和集中分析改进了上界。", "result": "将TSP常数的上界从0.90380改进至0.90367，通过引入一种新的构造性启发式算法进一步潜在地将上界改善到约0.85。", "conclusion": "提出的新方法在理论上和数值分析中都显示出改进TSP常数上界的潜力。"}}
{"id": "2602.11249", "pdf": "https://arxiv.org/pdf/2602.11249", "abs": "https://arxiv.org/abs/2602.11249", "authors": ["Jialiang Lin"], "title": "How to check in continually over 4,000 days on an online learning platform? An empirical experience and a practical solution", "categories": ["cs.CY", "cs.HC"], "comment": "Please cite the version of ICDEL", "summary": "The check-in service is often provided as an incentive system by online learning platforms to help users establish a learning routine and achieve accomplishment. However, according to the questionnaire conducted in this study, 82.5% of users of online English learning platforms that feature a check-in service have failed to maintain the daily check-in behavior for long-term language learning, mainly by reason of demotivation, forgetfulness, boredom, and insufficient time. As a language learner, I have an empirical experience in maintaining a record of over 4,000 daily check-ins on China's leading online English learning platform of Shanbay. In the meantime, I have been constantly exploring a practical solution to help cultivate perseverance for other users to follow through the learning routine. In this paper, I systematically introduce this practical solution, the GILT method, and its instructions. The experience and solution for perseverance development are based on Shanbay, but they can be applied to other learning platforms for different purposes.", "AI": {"tldr": "介绍一种帮助用户在在线学习平台持续签到的方法GILT。", "motivation": "许多使用在线英语学习平台的用户由于缺乏动力、健忘、无聊和时间不足等原因，难以维持长期的学习习惯。作者通过自己的经验探索了一种解决方案。", "method": "提出并详细介绍了GILT方法（目标设定、激励机制、时间和任务分解）来帮助用户培养持续签到的习惯。", "result": "该方法在Shanbay平台被验证有效，可以应用于其他学习平台和目的。", "conclusion": "通过使用GILT方法，可以帮助更多用户维持在线学习的日常习惯。"}}
{"id": "2602.11246", "pdf": "https://arxiv.org/pdf/2602.11246", "abs": "https://arxiv.org/abs/2602.11246", "authors": ["Nikhil Garg", "Jon Kleinberg", "Kenny Peng"], "title": "How Many Features Can a Language Model Store Under the Linear Representation Hypothesis?", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IT", "math.CO"], "comment": null, "summary": "We introduce a mathematical framework for the linear representation hypothesis (LRH), which asserts that intermediate layers of language models store features linearly. We separate the hypothesis into two claims: linear representation (features are linearly embedded in neuron activations) and linear accessibility (features can be linearly decoded). We then ask: How many neurons $d$ suffice to both linearly represent and linearly access $m$ features? Classical results in compressed sensing imply that for $k$-sparse inputs, $d = O(k\\log (m/k))$ suffices if we allow non-linear decoding algorithms (Candes and Tao, 2006; Candes et al., 2006; Donoho, 2006). However, the additional requirement of linear decoding takes the problem out of the classical compressed sensing, into linear compressed sensing. Our main theoretical result establishes nearly-matching upper and lower bounds for linear compressed sensing. We prove that $d = Ω_ε(\\frac{k^2}{\\log k}\\log (m/k))$ is required while $d = O_ε(k^2\\log m)$ suffices. The lower bound establishes a quantitative gap between classical and linear compressed setting, illustrating how linear accessibility is a meaningfully stronger hypothesis than linear representation alone. The upper bound confirms that neurons can store an exponential number of features under the LRH, giving theoretical evidence for the \"superposition hypothesis\" (Elhage et al., 2022). The upper bound proof uses standard random constructions of matrices with approximately orthogonal columns. The lower bound proof uses rank bounds for near-identity matrices (Alon, 2003) together with Turán's theorem (bounding the number of edges in clique-free graphs). We also show how our results do and do not constrain the geometry of feature representations and extend our results to allow decoders with an activation function and bias.", "AI": {"tldr": "本文引入了一个数学框架来探讨线性表示假设（LRH），并确定了在给定条件下神经元数量与存储特征数量之间的关系。", "motivation": "动机在于理解语言模型中中间层如何通过线性方式存储和解码特征，并量化这一过程所需资源的数量。该研究旨在区分线性表示与线性可访问性的差异，以及探讨超叠加假设的理论基础。", "method": "本文提出了一个数学框架来解析线性压缩感知问题，并在理论上建立了接近匹配的上下界证明。上界通过标准随机矩阵构造实现，下界则基于秩限制和图论方法。", "result": "研究结果显示，在允许非线性解码算法的情况下，d = O(k log(m/k)) 足以满足存储条件；而要求线性解码时，需要 d = Ω_ε((k^2 / log k) log (m/k))。上界证明了在LRH下神经元可以存储指数数量的特征。", "conclusion": "该研究确认了线性压缩感知中线性可访问性的严格要求，并提供了理论支持来说明语言模型中间层能够高效地以线性方式存储大量特征，从而为超叠加假设提供了一定程度上的证据。"}}
{"id": "2602.11244", "pdf": "https://arxiv.org/pdf/2602.11244", "abs": "https://arxiv.org/abs/2602.11244", "authors": ["Sethuraman T V", "Savya Khosla", "Aditi Tiwari", "Vidya Ganesh", "Rakshana Jayaprakash", "Aditya Jain", "Vignesh Srinivasakumar", "Onkar Kishor Susladkar", "Srinidhi Sunkara", "Aditya Shanmugham", "Rakesh Vaideeswaran", "Abbaas Alif Mohamed Nishar", "Simon Jenni", "Derek Hoiem"], "title": "Stress Tests REVEAL Fragile Temporal and Visual Grounding in Video-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "This work investigates a fundamental question: Do Video-Language Models (VidLMs) robustly account for video content, temporal sequence, and motion? Our investigation shows that, surprisingly, they often do not. We introduce REVEAL{}, a diagnostic benchmark that probes fundamental weaknesses of contemporary VidLMs through five controlled stress tests; assessing temporal expectation bias, reliance on language-only shortcuts, video sycophancy, camera motion sensitivity, and robustness to spatiotemporal occlusion. We test leading open- and closed-source VidLMs and find that these models confidently describe reversed scenes as forward, answer questions while neglecting video content, agree with false claims, struggle with basic camera motion, and fail to aggregate temporal information amidst simple spatiotemporal masking. Humans, on the other hand, succeed at these tasks with ease. Alongside our benchmark, we provide a data pipeline that automatically generates diagnostic examples for our stress tests, enabling broader and more scalable evaluation. We will release our benchmark and code to support future research.", "AI": {"tldr": "论文通过引入REVEAL基准测试来评估视频语言模型在处理时间序列和视觉信息时的脆弱性。", "motivation": "研究者发现现有的视频语言模型（VidLMs）并未充分考虑视频内容、时间顺序及运动。他们希望通过揭示这些模型的基本弱点，促进未来的研究和发展。", "method": "论文设计了五项控制压力测试来诊断现有VidLMs的弱点：评估对时间预期偏差、仅依赖于文本线索的能力、图像取悦性、镜头移动敏感度以及时空遮蔽下的鲁棒性。此外，还提供了自动化生成诊断示例的数据流水线。", "result": "研究发现这些模型在描述场景方向时出错，在回答问题时忽视视频内容，并且难以处理基本的镜头运动和简单的时空遮蔽。", "conclusion": "人类相对容易完成这些任务而VidLMs却表现不佳。论文强调了进一步提高模型性能的重要性，以更好地理解和生成视频语言关联。"}}
{"id": "2602.11242", "pdf": "https://arxiv.org/pdf/2602.11242", "abs": "https://arxiv.org/abs/2602.11242", "authors": ["Yitong Wang", "Yue Yao"], "title": "ReTracing: An Archaeological Approach Through Body, Machine, and Generative Systems", "categories": ["cs.CV"], "comment": null, "summary": "We present ReTracing, a multi-agent embodied performance art that adopts an archaeological approach to examine how artificial intelligence shapes, constrains, and produces bodily movement. Drawing from science-fiction novels, the project extracts sentences that describe human-machine interaction. We use large language models (LLMs) to generate paired prompts \"what to do\" and \"what not to do\" for each excerpt. A diffusion-based text-to-video model transforms these prompts into choreographic guides for a human performer and motor commands for a quadruped robot. Both agents enact the actions on a mirrored floor, captured by multi-camera motion tracking and reconstructed into 3D point clouds and motion trails, forming a digital archive of motion traces. Through this process, ReTracing serves as a novel approach to reveal how generative systems encode socio-cultural biases through choreographed movements. Through an immersive interplay of AI, human, and robot, ReTracing confronts a critical question of our time: What does it mean to be human among AIs that also move, think, and leave traces behind?", "AI": {"tldr": "本文通过一个多代理的身临其境表演艺术，探索人工智能如何影响身体运动。", "motivation": "项目旨在探讨人工智能对人类和机器互动的影响，并揭示生成系统中的社会文化偏见。", "method": "利用大型语言模型生成行动指南和命令，然后通过一个文本到视频的扩散模型转化为舞蹈指导和机器人指令。表演中的人类和机器的动作被多摄像机捕捉并重建为3D点云。", "result": "形成了一系列动作轨迹的数字档案，展示了人工智能如何编码社会文化偏见。", "conclusion": "ReTracing通过AI、人类和机器人的互动，提出了在存在同样移动思考留下痕迹的人工智能时代的身份问题。"}}
{"id": "2602.11241", "pdf": "https://arxiv.org/pdf/2602.11241", "abs": "https://arxiv.org/abs/2602.11241", "authors": ["Jinghan He", "Junfeng Fang", "Feng Xiong", "Zijun Yao", "Fei Shen", "Haiyun Guo", "Jinqiao Wang", "Tat-Seng Chua"], "title": "Active Zero: Self-Evolving Vision-Language Models through Active Environment Exploration", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Self-play has enabled large language models to autonomously improve through self-generated challenges. However, existing self-play methods for vision-language models rely on passive interaction with static image collections, resulting in strong dependence on initial datasets and inefficient learning. Without the ability to actively seek visual data tailored to their evolving capabilities, agents waste computational effort on samples that are either trivial or beyond their current skill level. To address these limitations, we propose Active-Zero, a framework that shifts from passive interaction to active exploration of visual environments. Active-Zero employs three co-evolving agents: a Searcher that retrieves images from open-world repositories based on the model's capability frontier, a Questioner that synthesizes calibrated reasoning tasks, and a Solver refined through accuracy rewards. This closed loop enables self-scaffolding auto-curricula where the model autonomously constructs its learning trajectory. On Qwen2.5-VL-7B-Instruct across 12 benchmarks, Active-Zero achieves 53.97 average accuracy on reasoning tasks (5.7% improvement) and 59.77 on general understanding (3.9% improvement), consistently outperforming existing self-play baselines. These results highlight active exploration as a key ingredient for scalable and adaptive self-evolving vision-language systems.", "AI": {"tldr": "提出了Active-Zero框架，通过主动探索视觉环境来提升视觉语言模型的自主学习能力。", "motivation": "现有的自玩游戏方法依赖于静态图像集合进行被动交互，导致对初始数据集的高度依赖和低效学习。为了克服这些限制，需要一种能够主动寻求与自身技能水平相匹配的数据的方法。", "method": "Active-Zero框架采用三个协同演化的代理：搜索者从开放世界存储库中检索图像，提问者根据模型的能力边界合成推理任务，解决者通过准确性奖励进行优化。", "result": "在Qwen2.5-VL-7B-Instruct上跨12个基准测试中，Active-Zero实现了推理任务平均准确率53.97（提高5.7%）和一般理解准确率59.77（提高3.9%），优于现有自玩游戏基线。", "conclusion": "主动探索是可扩展且适应性强的视觉语言系统自主演化的关键要素。"}}
{"id": "2602.11239", "pdf": "https://arxiv.org/pdf/2602.11239", "abs": "https://arxiv.org/abs/2602.11239", "authors": ["Samanta Ghosh", "Jannatul Adan Mahi", "Shayan Abrar", "Md Parvez Mia", "Asaduzzaman Rayhan", "Abdul Awal Yasir", "Asaduzzaman Hridoy"], "title": "Toward Reliable Tea Leaf Disease Diagnosis Using Deep Learning Model: Enhancing Robustness With Explainable AI and Adversarial Training", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "6 pages,9 figures, 2025 IEEE International Women in Engineering (WIE) Conference on Electrical and Computer Engineering (WIECON-ECE)", "summary": "Tea is a valuable asset for the economy of Bangladesh. So, tea cultivation plays an important role to boost the economy. These valuable plants are vulnerable to various kinds of leaf infections which may cause less production and low quality. It is not so easy to detect these diseases manually. It may take time and there could be some errors in the detection.Therefore, the purpose of the study is to develop an automated deep learning model for tea leaf disease classification based on the teaLeafBD dataset so that anyone can detect the diseases more easily and efficiently. There are 5,278 high-resolution images in this dataset. The images are classified into seven categories. Six of them represents various diseases and the rest one represents healthy leaves. The proposed pipeline contains data preprocessing, data splitting, adversarial training, augmentation, model training, evaluation, and comprehension made possible with Explainable AI strategies. DenseNet201 and EfficientNetB3 were employed to perform the classification task. To prepare the model more robustly, we applied adversarial training so it can operate effectively even with noisy or disturbed inputs. In addition, Grad-CAM visualization was executed to analyze the model's predictions by identifying the most influential regions of each image. Our experimental outcomes revealed that EfficientNetB3 achieved the highest classification accuracy of 93%, while DenseNet201 reached 91%. The outcomes prove that the effectiveness of the proposed approach can accurately detect tea leaf diseases and provide a practical solution for advanced agricultural management.", "AI": {"tldr": "开发一个基于茶叶BD数据集的自动化深度学习模型，用于茶叶疾病的分类。", "motivation": "为了更准确、高效地检测茶树叶片疾病，减少经济损失并提高产量与质量。", "method": "使用DenseNet201和EfficientNetB3进行分类任务，并通过对抗训练增强模型的鲁棒性。同时利用可解释的人工智能策略（如Grad-CAM）来可视化模型预测。", "result": "实验结果显示，EfficientNetB3达到了最高的分类准确率93%，而DenseNet201为91%。", "conclusion": "提出的深度学习方法可以有效检测茶树叶片疾病，并提供先进的农业管理解决方案。"}}
{"id": "2602.11237", "pdf": "https://arxiv.org/pdf/2602.11237", "abs": "https://arxiv.org/abs/2602.11237", "authors": ["Mujeeb Ur Rehman", "Imran Rehan", "Sohail Khalid"], "title": "AI-Driven Clinical Decision Support System for Enhanced Diabetes Diagnosis and Management", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Identifying type 2 diabetes mellitus can be challenging, particularly for primary care physicians. Clinical decision support systems incorporating artificial intelligence (AI-CDSS) can assist medical professionals in diagnosing type 2 diabetes with high accuracy. This study aimed to assess an AI-CDSS specifically developed for the diagnosis of type 2 diabetes by employing a hybrid approach that integrates expert-driven insights with machine learning techniques. The AI-CDSS was developed (training dataset: n = 650) and tested (test dataset: n = 648) using a dataset of 1298 patients with and without type 2 diabetes. To generate predictions, the algorithm utilized key features such as body mass index, plasma fasting glucose, and hemoglobin A1C. Furthermore, a clinical pilot study involving 105 patients was conducted to assess the diagnostic accuracy of the system in comparison to non-endocrinology specialists. The AI-CDSS showed a high degree of accuracy, with 99.8% accuracy in predicting diabetes, 99.3% in predicting prediabetes, 99.2% in identifying at-risk individuals, and 98.8% in predicting no diabetes. The test dataset revealed a 98.8% agreement between endocrinology specialists and the AI-CDSS. Type 2 diabetes was identified in 45% of 105 individuals in the pilot study. Compared with diabetes specialists, the AI-CDSS scored a 98.5% concordance rate, greatly exceeding that of nonendocrinology specialists, who had an 85% agreement rate. These findings indicate that the AI-CDSS has the potential to be a useful tool for accurately identifying type 2 diabetes, especially in situations in which diabetes specialists are not readily available.", "AI": {"tldr": "开发并测试了一种结合专家知识与机器学习的AI驱动临床决策支持系统，用于提高糖尿病诊断和管理准确性。", "motivation": "旨在通过利用人工智能辅助初级保健医生准确地诊断2型糖尿病，并且在缺乏内分泌科专科医生的情况下提供帮助。", "method": "使用包含1298名患者的数据集训练并测试了AI-CDSS系统，该系统结合关键特征（如BMI、空腹血糖和HbA1C）进行预测。并对105名患者的临床试点研究进行了诊断准确性评估。", "result": "AI-CDSS在糖尿病识别中达到98.8%的准确率，在非内分泌专科医生中的协议率为85%，与内分泌科专家的协议率达到98.5%。", "conclusion": "该研究表明，基于人工智能的临床决策支持系统有潜力成为一种有用的工具，能够在缺乏专业医疗人员的情况下更准确地识别2型糖尿病。"}}
{"id": "2602.11236", "pdf": "https://arxiv.org/pdf/2602.11236", "abs": "https://arxiv.org/abs/2602.11236", "authors": ["Yandan Yang", "Shuang Zeng", "Tong Lin", "Xinyuan Chang", "Dekang Qi", "Junjin Xiao", "Haoyun Liu", "Ronghan Chen", "Yuzhi Chen", "Dongjie Huo", "Feng Xiong", "Xing Wei", "Zhiheng Ma", "Mu Xu"], "title": "ABot-M0: VLA Foundation Model for Robotic Manipulation with Action Manifold Learning", "categories": ["cs.CV", "cs.CL", "cs.RO"], "comment": "Project website: https://amap-cvlab.github.io/ABot-Manipulation/ . Code: https://github.com/amap-cvlab/ABot-Manipulation . 22 pages, 10 figures, 10 tables", "summary": "Building general-purpose embodied agents across diverse hardware remains a central challenge in robotics, often framed as the ''one-brain, many-forms'' paradigm. Progress is hindered by fragmented data, inconsistent representations, and misaligned training objectives. We present ABot-M0, a framework that builds a systematic data curation pipeline while jointly optimizing model architecture and training strategies, enabling end-to-end transformation of heterogeneous raw data into unified, efficient representations. From six public datasets, we clean, standardize, and balance samples to construct UniACT-dataset, a large-scale dataset with over 6 million trajectories and 9,500 hours of data, covering diverse robot morphologies and task scenarios. Unified pre-training improves knowledge transfer and generalization across platforms and tasks, supporting general-purpose embodied intelligence. To improve action prediction efficiency and stability, we propose the Action Manifold Hypothesis: effective robot actions lie not in the full high-dimensional space but on a low-dimensional, smooth manifold governed by physical laws and task constraints. Based on this, we introduce Action Manifold Learning (AML), which uses a DiT backbone to predict clean, continuous action sequences directly. This shifts learning from denoising to projection onto feasible manifolds, improving decoding speed and policy stability. ABot-M0 supports modular perception via a dual-stream mechanism that integrates VLM semantics with geometric priors and multi-view inputs from plug-and-play 3D modules such as VGGT and Qwen-Image-Edit, enhancing spatial understanding without modifying the backbone and mitigating standard VLM limitations in 3D reasoning. Experiments show components operate independently with additive benefits. We will release all code and pipelines for reproducibility and future research.", "AI": {"tldr": "提出ABot-M0框架，通过系统化数据整理流程和模型架构优化，构建大型机器人操纵统一预训练模型UniACT-dataset，并引入行动流形学习（AML）提高预测效率。", "motivation": "解决通用机器人代理在不同硬件上的挑战，包括碎片化的数据、不一致的表示形式以及训练目标的偏差问题。通过建立一个系统化的大规模数据整理流程和优化模型架构来促进知识转移与泛化能力提升。", "method": "构建包含六大数据集的UniACT-dataset；引入行动流形学习（AML），使用DiT骨干网络预测连续动作序列，提高解码速度与策略稳定性；通过双流机制整合视觉语言模型语义和几何先验及多视角输入，增强空间理解能力。", "result": "实验表明各个组件可以独立操作并产生累加效果，支持模块化感知的同时避免了标准视觉语言模型在三维推理中的局限性。", "conclusion": "ABot-M0框架通过统一预训练和行动流形学习等技术手段有效提升了机器人操纵任务的知识转移与泛化能力，并展示了良好的模块化感知特性。"}}
{"id": "2602.11230", "pdf": "https://arxiv.org/pdf/2602.11230", "abs": "https://arxiv.org/abs/2602.11230", "authors": ["Jaime Banks", "Jon Stromer-Galley", "Samiksha Singh", "Collin Capano"], "title": "DiSCoKit: An Open-Source Toolkit for Deploying Live LLM Experiences in Survey Research", "categories": ["cs.HC"], "comment": null, "summary": "Advancing social-scientific research of human-AI interaction dynamics and outcomes often requires researchers to deliver experiences with live large-language models (LLMs) to participants through online survey platforms. However, technical and practical challenges (from logging chat data to manipulating AI behaviors for experimental designs) often inhibit survey-based deployment of AI stimuli. We developed DiSCoKit--an open-source toolkit for deploying live LLM experiences (e.g., ones based on models delivered through Microsoft Azure portal) through JavaScript-enabled survey platforms (e.g., Qualtrics). This paper introduces that toolkit, explaining its scientific impetus, describes its architecture and operation, as well as its deployment possibilities and limitations.", "AI": {"tldr": "介绍一个用于在在线调查平台中部署实时大型语言模型体验的开源工具包DiSCoKit。", "motivation": "解决社会科学研究人员在通过在线调查平台交付实时大型语言模型体验时遇到的技术和实际挑战，如日志记录聊天数据和为实验设计操纵AI行为等。", "method": "开发一个基于微软Azure门户等提供模型的开源工具包DiSCoKit，并描述其架构、操作及部署的可能性与限制。", "result": "成功创建了一个能够在JavaScript支持的在线调查平台（如Qualtrics）上部署实时大型语言模型体验的工具包DiSCoKit。", "conclusion": "通过使用DiSCoKit，研究人员可以在各种在线调研平台中更加轻松地集成和控制大型语言模型实验，从而促进人机交互研究的发展。"}}
{"id": "2602.11229", "pdf": "https://arxiv.org/pdf/2602.11229", "abs": "https://arxiv.org/abs/2602.11229", "authors": ["Zituo Chen", "Haixu Wu", "Sili Deng"], "title": "Latent Generative Solvers for Generalizable Long-Term Physics Simulation", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "We study long-horizon surrogate simulation across heterogeneous PDE systems. We introduce Latent Generative Solvers (LGS), a two-stage framework that (i) maps diverse PDE states into a shared latent physics space with a pretrained VAE, and (ii) learns probabilistic latent dynamics with a Transformer trained by flow matching. Our key mechanism is an uncertainty knob that perturbs latent inputs during training and inference, teaching the solver to correct off-manifold rollout drift and stabilizing autoregressive prediction. We further use flow forcing to update a system descriptor (context) from model-generated trajectories, aligning train/test conditioning and improving long-term stability. We pretrain on a curated corpus of $\\sim$2.5M trajectories at $128^2$ resolution spanning 12 PDE families. LGS matches strong deterministic neural-operator baselines on short horizons while substantially reducing rollout drift on long horizons. Learning in latent space plus efficient architectural choices yields up to \\textbf{70$\\times$} lower FLOPs than non-generative baselines, enabling scalable pretraining. We also show efficient adaptation to an out-of-distribution $256^2$ Kolmogorov flow dataset under limited finetuning budgets. Overall, LGS provides a practical route toward generalizable, uncertainty-aware neural PDE solvers that are more reliable for long-term forecasting and downstream scientific workflows.", "AI": {"tldr": "本文研究了长时域代理模拟跨异构PDE系统，提出了一种两阶段框架Latent Generative Solvers (LGS)，通过预训练的VAE将多样化的PDE状态映射到共享的潜在物理空间，并用Transformer学习潜在动态。", "motivation": "为了实现长时域上稳定、准确且可靠的预测，本研究提出了一个能够处理异构偏微分方程系统的通用代理模拟框架。通过利用预训练的VAE和Transformer模型，在潜在空间中学习动态并纠正离散点漂移问题。", "method": "该方法包括两个阶段：第一阶段使用预训练的变分自编码器将不同的PDE状态映射到共同的潜在物理空间；第二阶段用Transformer通过流匹配来学习潜在动力学。引入不确定性旋钮在训练和推理时扰动潜在输入，以纠正离散点漂移并稳定预测。", "result": "LGS模型不仅在短时间范围内与确定性神经操作器基线相匹敌，在长时间段内显著减少了偏差，并且由于在潜在空间学习加上高效的架构选择，其计算效率比非生成基准高70倍。", "conclusion": "总体而言，本文提出的方法为通用化、不确定性感知的神经PDE求解器提供了一条实用途径，更适用于长期预测和下游科学工作流程。"}}
{"id": "2602.11223", "pdf": "https://arxiv.org/pdf/2602.11223", "abs": "https://arxiv.org/abs/2602.11223", "authors": ["Micheal P. Papazoglou", "Bernd J. Krämer", "Mira Raheem", "Amal Elgammal"], "title": "Patient Digital Twins for Chronic Care: Technical Hurdles, Lessons Learned, and the Road Ahead", "categories": ["cs.SE", "cs.HC"], "comment": "Feature Article, Patient Medical Digital Twins, Under Review in IEEE SOftware", "summary": "Chronic diseases constitute the principal burden of morbidity, mortality, and healthcare costs worldwide, yet current health systems remain fragmented and predominantly reactive. Patient Medical Digital Twins (PMDTs) offer a paradigm shift: holistic, continuously updated digital counterparts of patients that integrate clinical, genomic, lifestyle, and quality-of-life data. We report early implementations of PMDTs via ontology-driven modeling and federated analytics pilots. Insights from the QUALITOP oncology study and a distributed AI platform confirm both feasibility and challenges: aligning with HL7 FHIR and OMOP standards, embedding privacy governance, scaling federated queries, and designing intuitive clinician interfaces. We also highlight technical gains, such as automated reasoning over multimodal blueprints and predictive analytics for patient outcomes. By reflecting on these experiences, we outline actionable insights for software engineers and identify opportunities, such as DSLs and model-driven engineering, to advance PMDTs toward trustworthy, adaptive chronic care ecosystems.", "AI": {"tldr": "患者医疗数字孪生(PMDTs)用于慢性疾病的综合管理，通过整合临床、基因组学、生活方式和生活质量数据实现。", "motivation": "当前的健康系统对于处理慢性疾病负担不足且过于被动，PMDTs旨在提供一种新的范式：即持续更新的患者数字孪生体，以促进全面健康管理。", "method": "该研究通过基于本体论模型驱动的方法和联邦分析试点实施了PMDTs，探讨了与HL7 FHIR和OMOP标准的一致性、隐私治理、可扩展性的联邦查询以及设计直观医生界面的技术挑战及解决方案。", "result": "初步结果显示了PMDTs的可行性和潜力，并提出了一系列技术优势，如多模式蓝本中的自动推理和预测分析。", "conclusion": "通过回顾这些经验教训，该研究为软件工程师提供了可操作见解并确定了未来发展方向，例如领域特定语言(DSL)和模型驱动工程以推进PMDTs向信任、适应性慢性护理生态系统迈进。"}}
{"id": "2602.11219", "pdf": "https://arxiv.org/pdf/2602.11219", "abs": "https://arxiv.org/abs/2602.11219", "authors": ["Tanmoy Mukherjee", "Marius Kloft", "Pierre Marquis", "Zied Bouraoui"], "title": "Credal Concept Bottleneck Models: Structural Separation of Epistemic and Aleatoric Uncertainty", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Decomposing predictive uncertainty into epistemic (model ignorance) and aleatoric (data ambiguity) components is central to reliable decision making, yet most methods estimate both from the same predictive distribution. Recent empirical and theoretical results show these estimates are typically strongly correlated, so changes in predictive spread simultaneously affect both components and blur their semantics. We propose a credal-set formulation in which uncertainty is represented as a set of predictive distributions, so that epistemic and aleatoric uncertainty correspond to distinct geometric properties: the size of the set versus the noise within its elements. We instantiate this idea in a Variational Credal Concept Bottleneck Model with two disjoint uncertainty heads trained by disjoint objectives and non-overlapping gradient paths, yielding separation by construction rather than post hoc decomposition. Across multi-annotator benchmarks, our approach reduces the correlation between epistemic and aleatoric uncertainty by over an order of magnitude compared to standard methods, while improving the alignment of epistemic uncertainty with prediction error and aleatoric uncertainty with ground-truth ambiguity.", "AI": {"tldr": "该论文提出了一种新的模型来区分预测中的认识不确定性和数据不确定性。", "motivation": "现有的方法难以准确地区分预测的不确定性为认识不确定性和数据不确定性，因为它们通常同时影响两个组成部分。", "method": "提出了一个基于信度集的形式化方法，在此形式中将不确定性表示为一组预测分布，并通过在变分概念瓶颈模型中分离出两个独立的不确定性头来实现这种区分。", "result": "该方法显著减少了认识不确定性和数据不确定性的相关性，提高了对预测误差和真实数据模糊性的准确度量。", "conclusion": "这种方法有效地将认识不确定性与数据不确定性分开，并在多标注基准上取得了较好的结果。"}}
{"id": "2602.11214", "pdf": "https://arxiv.org/pdf/2602.11214", "abs": "https://arxiv.org/abs/2602.11214", "authors": ["Manuel Hetzel", "Kerim Turacan", "Hannes Reichert", "Konrad Doll", "Bernhard Sick"], "title": "DD-MDN: Human Trajectory Forecasting with Diffusion-Based Dual Mixture Density Networks and Uncertainty Self-Calibration", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Human Trajectory Forecasting (HTF) predicts future human movements from past trajectories and environmental context, with applications in Autonomous Driving, Smart Surveillance, and Human-Robot Interaction. While prior work has focused on accuracy, social interaction modeling, and diversity, little attention has been paid to uncertainty modeling, calibration, and forecasts from short observation periods, which are crucial for downstream tasks such as path planning and collision avoidance. We propose DD-MDN, an end-to-end probabilistic HTF model that combines high positional accuracy, calibrated uncertainty, and robustness to short observations. Using a few-shot denoising diffusion backbone and a dual mixture density network, our method learns self-calibrated residence areas and probability-ranked anchor paths, from which diverse trajectory hypotheses are derived, without predefined anchors or endpoints. Experiments on the ETH/UCY, SDD, inD, and IMPTC datasets demonstrate state-of-the-art accuracy, robustness at short observation intervals, and reliable uncertainty modeling. The code is available at: https://github.com/kav-institute/ddmdn.", "AI": {"tldr": "DD-MDN 提出了一种基于扩散的双混合密度网络和不确定性自校准的人体轨迹预测模型，提高了短观测期间的位置精度、可靠的不确定性建模以及鲁棒性。", "motivation": "先前的研究主要关注准确性、社会交互建模和多样性，而很少涉及不确定性建模和短期观察期预报。这些特性对于下游任务如路径规划和碰撞避免至关重要。", "method": "DD-MDN 结合了少样本去噪扩散骨架和双重混合密度网络，学习自我校准的居住区域和概率排名锚定路径，从而生成多样化的轨迹假设。", "result": "实验结果显示，在ETH/UCY、SDD、inD 和IMPTC 数据集上，DD-MDN 达到了最先进的准确性，并且在短观测区间内表现出了更好的鲁棒性以及可靠的不确定性建模。", "conclusion": "DD-MDN 方法提高了人体轨迹预测的精度和可靠性，特别是在短期观察期间。该方法为路径规划和碰撞避免等下游任务提供了支持。"}}
{"id": "2602.11210", "pdf": "https://arxiv.org/pdf/2602.11210", "abs": "https://arxiv.org/abs/2602.11210", "authors": ["Danlong Yuan", "Wei Wu", "Zhengren Wang", "Xueliang Zhao", "Huishuai Zhang", "Dongyan Zhao"], "title": "SWE-MiniSandbox: Container-Free Reinforcement Learning for Building Software Engineering Agents", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "ICML under review", "summary": "Reinforcement learning (RL) has become a key paradigm for training software engineering (SWE) agents, but existing pipelines typically rely on per-task containers for isolation. At scale, pre-built container images incur substantial storage overhead, slow environment setup, and require container-management privileges. We propose SWE-MiniSandbox, a lightweight, container-free method that enables scalable RL training of SWE agents without sacrificing isolation. Instead of relying on per-instance containers, SWE-MiniSandbox executes each task in an isolated workspace backed by kernel-level mechanisms, substantially reducing system overhead. It leverages lightweight environment pre-caching techniques to eliminate the need for bulky container images. As a result, our approach lowers disk usage to approximately 5\\% of that required by container-based pipelines and reduces environment preparation time to about 25\\% of the container baseline. Empirical results demonstrate that SWE-MiniSandbox achieves evaluation performance comparable to standard container-based pipelines. By removing the dependency on heavy container infrastructure, SWE-MiniSandbox offers a practical and accessible foundation for scaling RL-based SWE agents, particularly in resource-constrained research environments.", "AI": {"tldr": "提出了一种轻量级、无需容器的方法，用于训练软件工程代理的强化学习。", "motivation": "现有管道依赖于每个任务的隔离容器，这导致了存储开销大、环境设置慢以及需要容器管理权限的问题。为了提高可扩展性并减少系统开销，提出了SWE-MiniSandbox。", "method": "SWE-MiniSandbox利用内核级别的机制实现任务隔离，并采用轻量级的环境预缓存技术来消除对大型容器镜像的需求，从而降低了磁盘使用率和环境准备时间。", "result": "实验结果表明，SWE-MiniSandbox在评估性能上与标准的基于容器的方法相当。它将磁盘使用减少到大约5%，并将环境设置时间减少了约75%。", "conclusion": "通过消除对重型容器基础设施的依赖，SWE-MiniSandbox为扩展基于RL的软件工程代理提供了一种实用且可访问的基础，特别是在资源受限的研究环境中。"}}
{"id": "2602.11206", "pdf": "https://arxiv.org/pdf/2602.11206", "abs": "https://arxiv.org/abs/2602.11206", "authors": ["Jose Marie Antonio Miñoza"], "title": "UltraLIF: Fully Differentiable Spiking Neural Networks via Ultradiscretization and Max-Plus Algebra", "categories": ["cs.LG", "cs.AI", "cs.CV", "math.RA", "q-bio.NC"], "comment": null, "summary": "Spiking Neural Networks (SNNs) offer energy-efficient, biologically plausible computation but suffer from non-differentiable spike generation, necessitating reliance on heuristic surrogate gradients. This paper introduces UltraLIF, a principled framework that replaces surrogate gradients with ultradiscretization, a mathematical formalism from tropical geometry providing continuous relaxations of discrete dynamics. The central insight is that the max-plus semiring underlying ultradiscretization naturally models neural threshold dynamics: the log-sum-exp function serves as a differentiable soft-maximum that converges to hard thresholding as a learnable temperature parameter $\\eps \\to 0$. Two neuron models are derived from distinct dynamical systems: UltraLIF from the LIF ordinary differential equation (temporal dynamics) and UltraDLIF from the diffusion equation modeling gap junction coupling across neuronal populations (spatial dynamics). Both yield fully differentiable SNNs trainable via standard backpropagation with no forward-backward mismatch. Theoretical analysis establishes pointwise convergence to classical LIF dynamics with quantitative error bounds and bounded non-vanishing gradients. Experiments on six benchmarks spanning static images, neuromorphic vision, and audio demonstrate improvements over surrogate gradient baselines, with gains most pronounced in single-timestep ($T{=}1$) settings on neuromorphic and temporal datasets. An optional sparsity penalty enables significant energy reduction while maintaining competitive accuracy.", "AI": {"tldr": "本文提出了一种新的框架UltraLIF，用于构建全可微的尖峰神经网络，解决了传统SNN中由于非连续性导致难以训练的问题。", "motivation": "传统的SNN因为非连续性的尖峰生成问题，在训练时需要依靠启发式的代理梯度。这种做法可能导致学习效率低下和准确性不足。", "method": "本文利用热带几何中的超离散化（ultradiscretization）方法，通过max-plus代数为神经元阈值动态提供了可微分的近似表示，从而构建了全可微SNN模型UltraLIF和UltraDLIF。这些模型可以通过标准反向传播进行训练。", "result": "实验结果显示，与启发式代理梯度基线相比，所提出的UltraLIF框架在多个基准测试中取得了改进，尤其是在单时间步长设置下的表现更为突出。", "conclusion": "本文提出的方法提供了一种新的途径来解决SNN的可训练性问题，并且证明了这种新方法的有效性和效率。"}}
{"id": "2602.11204", "pdf": "https://arxiv.org/pdf/2602.11204", "abs": "https://arxiv.org/abs/2602.11204", "authors": ["Zhuxin Lei", "Ziyuan Yang", "Yi Zhang"], "title": "Zero-Sacrifice Persistent-Robustness Adversarial Defense for Pre-Trained Encoders", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The widespread use of publicly available pre-trained encoders from self-supervised learning (SSL) has exposed a critical vulnerability: their susceptibility to downstream-agnostic adversarial examples (DAEs), which are crafted without knowledge of the downstream tasks but capable of misleading downstream models. While several defense methods have been explored recently, they rely primarily on task-specific adversarial fine-tuning, which inevitably limits generalizability and causes catastrophic forgetting and deteriorates benign performance. Different with previous works, we propose a more rigorous defense goal that requires only a single tuning for diverse downstream tasks to defend against DAEs and preserve benign performance. To achieve this defense goal, we introduce Zero-Sacrifice Persistent-Robustness Adversarial Defense (ZePAD), which is inspired by the inherent sensitivity of neural networks to data characteristics. Specifically, ZePAD is a dual-branch structure, which consists of a Multi-Pattern Adversarial Enhancement Branch (MPAE-Branch) that uses two adversarially fine-tuned encoders to strengthen adversarial resistance. The Benign Memory Preservation Branch (BMP-Branch) is trained on local data to ensure adversarial robustness does not compromise benign performance. Surprisingly, we find that ZePAD can directly detect DAEs by evaluating branch confidence, without introducing any adversarial exsample identification task during training. Notably, by enriching feature diversity, our method enables a single adversarial fine-tuning to defend against DAEs across downstream tasks, thereby achieving persistent robustness. Extensive experiments on 11 SSL methods and 6 datasets validate its effectiveness. In certain cases, it achieves a 29.20% improvement in benign performance and a 73.86% gain in adversarial robustness, highlighting its zero-sacrifice property.", "AI": {"tldr": "提出了一种针对预训练编码器的零牺牲持久鲁棒性对抗防御方法（ZePAD），以保护其免受下游任务无关的对抗样本攻击，同时保持良性性能。", "motivation": "公开可用的自监督学习预先训练的编码器容易受到下游无关对抗样本的影响。现有的防御手段主要依赖于特定任务的对抗微调，这限制了泛化能力，并导致灾难性遗忘和良性和表现下降。", "method": "提出了一种双分支结构的零牺牲持久鲁棒性对抗防御方法（ZePAD），包括多模式对抗增强分支和良性记忆保存分支。前者使用两个对抗微调编码器来强化对抗抵抗，后者在本地数据上训练以确保对抗鲁棒性不损害良性性能。", "result": "实验结果显示，在某些情况下，该方法实现了73.86%的抗扰动效果提升，并且保持了29.20%良性和表现的改进，验证了其零牺牲性质。", "conclusion": "ZePAD提供了一种有效的防御方案来保护预训练编码器免受下游无关对抗样本攻击的同时，不损害良性性能。"}}
{"id": "2602.11202", "pdf": "https://arxiv.org/pdf/2602.11202", "abs": "https://arxiv.org/abs/2602.11202", "authors": ["Vishak K Bhat", "Prateek Chanda", "Ashmit Khandelwal", "Maitreyi Swaroop", "Vineeth N. Balasubramanian", "Subbarao Kambhampati", "Nagarajan Natarajan", "Amit Sharma"], "title": "interwhen: A Generalizable Framework for Verifiable Reasoning with Test-time Monitors", "categories": ["cs.LO", "cs.AI"], "comment": "23 pages, 5 figures", "summary": "We present a test-time verification framework, interwhen, that ensures that the output of a reasoning model is valid wrt. a given set of verifiers. Verified reasoning is an important goal in high-stakes scenarios such as deploying agents in the physical world or in domains such as law and finance. However, current techniques either rely on the generate-test paradigm that verifies only after the final answer is produced, or verify partial output through a step-extraction paradigm where the task execution is externally broken down into structured steps. The former is inefficient while the latter artificially restricts a model's problem solving strategies. Instead, we propose to verify a model's reasoning trace as-is, taking full advantage of a model's reasoning capabilities while verifying and steering the model's output only when needed. The key idea is meta-prompting, identifying the verifiable properties that any partial solution should satisfy and then prompting the model to follow a custom format in its trace such that partial outputs can be easily parsed and checked. We consider both self-verification and external verification and find that interwhen provides a useful abstraction to provide feedback and steer reasoning models in each case. Using self-verification, interwhen obtains state-of-the-art results on early stopping reasoning models, without any loss in accuracy. Using external verifiers, interwhen obtains 10 p.p. improvement in accuracy over test-time scaling methods, while ensuring 100% soundness and being 4x more efficient. The code for interwhen is available at https://github.com/microsoft/interwhen", "AI": {"tldr": "本文介绍了一个名为interwhen的测试时验证框架，用于确保推理模型输出的有效性。", "motivation": "在高风险场景下，如物理世界的代理部署或法律、金融领域中，需要确保模型的推理结果是可靠的。当前技术要么依赖于生成-测试模式，在最终答案产生后进行验证；要么通过步骤提取方法对外部任务执行过程进行结构化分解来验证部分输出。前者效率低下而后者限制了模型解决问题的战略。", "method": "本文提出了一种新颖的方法，即在推理过程中直接对模型的推论轨迹进行验证和引导，采用元提示的方式识别任何中间解应满足的可验证属性，并促使模型遵循特定格式以使部分输出易于解析和检查。该方法包括自我验证和外部验证。", "result": "使用self-verification时，interwhen在早期停止推理模型上获得了最先进的结果，而没有任何准确性的损失；利用外部验证者，interwhen比测试时间缩放方法提高了10个百分点的准确性，同时保证了100%的有效性，并且效率高出4倍。", "conclusion": "本文提出的框架提供了对推理模型进行反馈和引导的新抽象层次，是目前一个实用且有效的解决方案。"}}
{"id": "2602.11198", "pdf": "https://arxiv.org/pdf/2602.11198", "abs": "https://arxiv.org/abs/2602.11198", "authors": ["Shafiuddin Rehan Ahmed", "Wei Wei"], "title": "DDL2PropBank Agent: Benchmarking Multi-Agent Frameworks' Developer Experience Through a Novel Relational Schema Mapping Task", "categories": ["cs.CL", "cs.AI"], "comment": "ARR submission", "summary": "Multi-agent frameworks promise to simplify LLM-driven software development, yet there is no principled way to evaluate their developer experience in a controlled setting. We introduce DDL2PropBank, a novel benchmark task that maps relational database schemas to PropBank rolesets, requiring autonomous retrieval of candidate frames and fine-grained linguistic reasoning over table names, columns, and relations. Using the Agent-as-a-Tool pattern, we implement identical agent logic across 10 frameworks and evaluate along two dimensions: (i) code complexity via static analysis, and (ii) AI-assistability -- the extent to which LLMs can autonomously generate correct, framework-specific code. Our results reveal a threefold complexity spectrum, with Pydantic AI and Agno requiring the least implementation overhead. For AI-assistability, structural alignment scores reliably proxy runtime success for frameworks with single canonical patterns, but overestimate correctness for multi-pattern frameworks. Agno emerges as the strongest overall performer, combining lowest complexity with highest structural alignment and 83% pass@1.", "AI": {"tldr": "通过DDL2PropBank任务，评估多代理框架的开发者体验。", "motivation": "多代理框架简化了LLM驱动的软件开发，但没有一种系统的方法来控制环境下评测其开发者体验。因此引入了一个新的基准任务——DDL2PropBank，以解决此问题。", "method": "使用Agent-as-a-Tool模式，在10个不同的框架中实现相同的代理逻辑，并从代码复杂性和AI辅助性两个维度进行评估。", "result": "结果显示了三倍的复杂度范围。Pydantic AI和Agno表现出最少的实施开销，而对于AI辅助性而言，结构性对齐分数可靠地预测具有单模式结构框架的成功率，但多模式框架存在过高估计正确性的风险。", "conclusion": "Agno作为总体性能最强者，在最低复杂度与最高结构性对齐中脱颖而出，并且在第一次尝试时成功率为83%。"}}
{"id": "2602.11197", "pdf": "https://arxiv.org/pdf/2602.11197", "abs": "https://arxiv.org/abs/2602.11197", "authors": ["Advait Balaji", "Trevor Teolis", "S. David Mis", "Jose Antonio Lara Benitez", "Chao Wang", "Maarten V. de Hoop"], "title": "Hybrid operator learning of wave scattering maps in high-contrast media", "categories": ["eess.SP", "cs.AI", "cs.CV"], "comment": null, "summary": "Surrogate modeling of wave propagation and scattering (i.e. the wave speed and source to wave field map) in heterogeneous media has significant potential in applications such as seismic imaging and inversion. High-contrast settings, such as subsurface models with salt bodies, exhibit strong scattering and phase sensitivity that challenge existing neural operators. We propose a hybrid architecture that decomposes the scattering operator into two separate contributions: a smooth background propagation and a high-contrast scattering correction. The smooth component is learned with a Fourier Neural Operator (FNO), which produces globally coupled feature tokens encoding background wave propagation; these tokens are then passed to a vision transformer, where attention is used to model the high-contrast scattering correction dominated by strong, spatial interactions. Evaluated on high-frequency Helmholtz problems with strong contrasts, the hybrid model achieves substantially improved phase and amplitude accuracy compared to standalone FNOs or transformers, with favorable accuracy-parameter scaling.", "AI": {"tldr": "提出了一种混合架构来模拟高对比度介质中的波散射。", "motivation": "现有神经操作者在面对强烈散射和相位敏感性的高对比度设置时表现不佳，因此需要改进的模型以提高准确性。", "method": "将散射算子分解为背景传播和平滑分量和高对比度散射校正两个部分。利用傅里叶神经算子学习平滑分量，并通过视觉变换器处理强烈的空间相互作用。", "result": "与单独使用FNO或变压器相比，混合模型在高频Helmholtz问题上的相位和幅度准确性显著提高。", "conclusion": "该方法解决了高对比度介质中波传播的模拟挑战，提高了精度参数的比例。"}}
{"id": "2602.11196", "pdf": "https://arxiv.org/pdf/2602.11196", "abs": "https://arxiv.org/abs/2602.11196", "authors": ["Hongyang Zhang", "Haitao Zhang", "Yinhao Liu", "Kunjie Lin", "Yue Huang", "Xinghao Ding"], "title": "Position-Aware Self-supervised Representation Learning for Cross-mode Radar Signal Recognition", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "Radar signal recognition in open electromagnetic environments is challenging due to diverse operating modes and unseen radar types. Existing methods often overlook position relations in pulse sequences, limiting their ability to capture semantic dependencies over time. We propose RadarPos, a position-aware self-supervised framework that leverages pulse-level temporal dynamics without complex augmentations or masking, providing improved position relation modeling over contrastive learning or masked reconstruction. Using this framework, we evaluate cross-mode radar signal recognition under the long-tailed setting to assess adaptability and generalization. Experimental results demonstrate enhanced discriminability and robustness, highlighting practical applicability in real-world electromagnetic environments.", "AI": {"tldr": "本文提出了一种雷达信号识别框架RadarPos，利用脉冲级别的时序动态信息来增强位置关系建模。", "motivation": "现有方法在处理开放电磁环境中的雷达信号识别任务时，常常忽视了脉冲序列的位置关系，限制了其对时间语义依赖性的捕捉能力。", "method": "提出了一种基于位置感知的自监督学习框架RadarPos，在不使用复杂数据增强或遮挡的情况下利用脉冲级别的时序动态信息来提高位置关系建模。", "result": "实验结果表明，该方法在长尾设置下的跨模式雷达信号识别中表现出更高的判别能力和鲁棒性。", "conclusion": "本文提出的RadarPos框架证明了其在实际电磁环境中的实用性和有效性。"}}
{"id": "2602.11192", "pdf": "https://arxiv.org/pdf/2602.11192", "abs": "https://arxiv.org/abs/2602.11192", "authors": ["Arian Raje", "Anupam Nayak", "Gauri Joshi"], "title": "MELINOE: Fine-Tuning Enables Memory-Efficient Inference for Mixture-of-Experts Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) model architectures can significantly reduce the number of activated parameters per token, enabling computationally efficient training and inference. However, their large overall parameter counts and model sizes have precluded their widespread usage in resource-constrained settings as all of the parameters must still be loaded into GPU memory. Prior works aim to address this memory bottleneck by offloading certain experts into CPU memory and porting them to GPU memory only when they are activated. In practice, these methods suffer from the significant I/O latency incurred by expert transfer. We present MELINOE, a method that fine-tunes an MoE model to more strongly prefer activating a smaller number of experts per sequence. Caching these preferred experts in GPU memory reduces expert churn and CPU-GPU transfer overhead. MELINOE increases throughput by $1.2-3\\times$ over efficient baselines and up to $14.7\\times$ over transfer-heavy baselines while retaining or even improving the performance of the model on a downstream task, making it a reliable method for improving MoE inference efficiency.", "AI": {"tldr": "通过微调方法减少激活的专家数量，提高混合专家模型在资源受限环境中的推理效率。", "motivation": "现有的混合专家模型由于其庞大的参数量和模型尺寸，在资源受限环境中难以使用。虽然有研究尝试通过将部分专家迁移到CPU内存中以减轻GPU内存压力，但这种做法引入了显著的I/O延迟问题。", "method": "提出MELINOE方法，通过对MoE模型进行微调来使更少数量的专家被激活，并把这些优选专家缓存到GPU内存中从而减少专家切换和CPU-GPU传输开销。", "result": "相比于高效基准线，MELINOE提升了1.2-3倍的吞吐量；与高传输需求基线相比，提升高达14.7倍。同时模型性能保持不变或有所提高。", "conclusion": "MELINOE是一种有效的方法，在不牺牲模型精度的情况下提高了混合专家模型在资源受限环境中的推理效率。"}}
{"id": "2602.11190", "pdf": "https://arxiv.org/pdf/2602.11190", "abs": "https://arxiv.org/abs/2602.11190", "authors": ["Fan Zhang", "Shiming Fan", "Hua Wang"], "title": "Time-TK: A Multi-Offset Temporal Interaction Framework Combining Transformer and Kolmogorov-Arnold Networks for Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series forecasting is crucial for the World Wide Web and represents a core technical challenge in ensuring the stable and efficient operation of modern web services, such as intelligent transportation and website throughput. However, we have found that existing methods typically employ a strategy of embedding each time step as an independent token. This paradigm introduces a fundamental information bottleneck when processing long sequences, the root cause of which is that independent token embedding destroys a crucial structure within the sequence - what we term as multi-offset temporal correlation. This refers to the fine-grained dependencies embedded within the sequence that span across different time steps, which is especially prevalent in regular Web data. To fundamentally address this issue, we propose a new perspective on time series embedding. We provide an upper bound on the approximate reconstruction performance of token embedding, which guides our design of a concise yet effective Multi-Offset Time Embedding method to mitigate the performance degradation caused by standard token embedding. Furthermore, our MOTE can be integrated into various existing models and serve as a universal building block. Based on this paradigm, we further design a novel forecasting architecture named Time-TK. This architecture first utilizes a Multi-Offset Interactive KAN to learn and represent specific temporal patterns among multiple offset sub-sequences. Subsequently, it employs an efficient Multi-Offset Temporal Interaction mechanism to effectively capture the complex dependencies between these sub-sequences, achieving global information integration. Extensive experiments on 14 real-world benchmark datasets, covering domains such as traffic flow and BTC/USDT throughput, demonstrate that Time-TK significantly outperforms all baseline models, achieving state-of-the-art forecasting accuracy.", "AI": {"tldr": "提出一种结合Transformer和Kolmogorov-Arnold网络的多偏移时间交互框架Time-TK，用于时间序列预测。", "motivation": "现有方法将每个时间步作为独立标记处理引入了信息瓶颈问题，破坏了序列中的多层次时序关联性。为了解决这一问题，提出了一种新的时间序列嵌入视角和一种有效的多偏移时间嵌入方法。", "method": "首先使用Multi-Offset Interactive KAN学习并表示多个偏移子序列之间的特定时态模式；然后采用高效的Multi-Offset Temporal Interaction机制有效捕捉这些子序列间的复杂依赖关系，实现全局信息整合。", "result": "在14个涵盖交通流量和BTC/USDT吞吐量等领域的现实世界基准数据集上进行的广泛实验表明，Time-TK显著优于所有基线模型，实现了最先进的预测精度。", "conclusion": "提出的Time-TK框架能够有效地解决时间序列中多层次时序关联性问题，并在实际应用中表现出色。"}}
{"id": "2602.11189", "pdf": "https://arxiv.org/pdf/2602.11189", "abs": "https://arxiv.org/abs/2602.11189", "authors": ["Yitian Wang", "Fanmeng Wang", "Angxiao Yue", "Wentao Guo", "Yaning Cui", "Hongteng Xu"], "title": "MuCO: Generative Peptide Cyclization Empowered by Multi-stage Conformation Optimization", "categories": ["q-bio.BM", "cs.AI"], "comment": null, "summary": "Modeling peptide cyclization is critical for the virtual screening of candidate peptides with desirable physical and pharmaceutical properties. This task is challenging because a cyclic peptide often exhibits diverse, ring-shaped conformations, which cannot be well captured by deterministic prediction models derived from linear peptide folding. In this study, we propose MuCO (Multi-stage Conformation Optimization), a generative peptide cyclization method that models the distribution of cyclic peptide conformations conditioned on the corresponding linear peptide. In principle, MuCO decouples the peptide cyclization task into three stages: topology-aware backbone design, generative side-chain packing, and physics-aware all-atom optimization, thereby generating and optimizing conformations of cyclic peptides in a coarse-to-fine manner. This multi-stage framework enables an efficient parallel sampling strategy for conformation generation and allows for rapid exploration of diverse, low-energy conformations. Experiments on the large-scale CPSea dataset demonstrate that MuCO significantly outperforms state-of-the-art methods in consistently in physical stability, structural diversity, secondary structure recovery, and computational efficiency, making it a promising computational tool for exploring and designing cyclic peptides.", "AI": {"tldr": "提出了MuCO方法，用于生成肽环化模型，该模型能够有效地优化和探索多种低能量构象。", "motivation": "线性肽折叠的确定性预测模型难以捕捉到多样的环状肽构象分布。因此需要一种新的方法来更好地模拟这些构象。", "method": "MuCO是一种基于三阶段结构优化的生成肽环化的方法，包括拓扑感知骨架设计、生成侧链包装以及物理感知全原子优化。该框架支持高效的并行采样策略，并允许快速探索多种低能量构象。", "result": "实验表明，与现有方法相比，MuCO在物理稳定性、结构多样性、二级结构恢复和计算效率方面表现出显著优势。", "conclusion": "MuCO是一种具有前景的计算工具，能够有效地模拟和设计环状肽。"}}
{"id": "2602.11187", "pdf": "https://arxiv.org/pdf/2602.11187", "abs": "https://arxiv.org/abs/2602.11187", "authors": ["Yubo Hou", "Furen Zhuang", "Partha Pratim Kundu", "Sezin Ata Kircali", "Jie Wang", "Mihai Dragos Rotaru", "Dutta Rahul", "Ashish James"], "title": "TDPNavigator-Placer: Thermal- and Wirelength-Aware Chiplet Placement in 2.5D Systems Through Multi-Agent Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "ef:The 27th IEEE Electronics Packaging Technology Conference (EPTC 2025)", "summary": "The rapid growth of electronics has accelerated the adoption of 2.5D integrated circuits, where effective automated chiplet placement is essential as systems scale to larger and more heterogeneous chiplet assemblies. Existing placement methods typically focus on minimizing wirelength or transforming multi-objective optimization into a single objective through weighted sum, which limits their ability to handle competing design requirements. Wirelength reduction and thermal management are inherently conflicting objectives, making prior approaches inadequate for practical deployment. To address this challenge, we propose TDPNavigator-Placer, a novel multi-agent reinforcement learning framework that dynamically optimizes placement based on chiplet's thermal design power (TDP). This approach explicitly assigns these inherently conflicting objectives to specialized agents, each operating under distinct reward mechanisms and environmental constraints within a unified placement paradigm. Experimental results demonstrate that TDPNavigator-Placer delivers a significantly improved Pareto front over state-of-the-art methods, enabling more balanced trade-offs between wirelength and thermal performance.", "AI": {"tldr": "提出了一种新的多智能体强化学习框架TDPNavigator-Placer，用于处理热设计功率和线长之间的冲突目标。", "motivation": "现有方法在面对线长最小化与热管理时的冲突目标上存在局限性，难以实现有效的自动芯片放置。因此，需要一种能够平衡这些相互矛盾的目标的方法。", "method": "提出TDPNavigator-Placer框架，通过多智能体强化学习来动态优化基于每个芯片热设计功率的放置策略，并利用不同的奖励机制和环境约束将不同目标分配给专门的代理。", "result": "实验结果显示，提出的TDPNavigator-Placer方法相比于现有技术提供了显著改善的设计性能，在线长和热性能之间取得了更平衡的权衡。", "conclusion": "该框架为2.5D集成电路中的芯片放置提供了一种新的解决方案，有效处理了线长最小化与热管理之间的冲突目标。"}}
{"id": "2602.11186", "pdf": "https://arxiv.org/pdf/2602.11186", "abs": "https://arxiv.org/abs/2602.11186", "authors": ["Zhihan Zeng", "Kaihe Wang", "Zhongpei Zhang", "Yue Xiu"], "title": "GAC-KAN: An Ultra-Lightweight GNSS Interference Classifier for GenAI-Powered Consumer Edge Devices", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "The integration of Generative AI (GenAI) into Consumer Electronics (CE)--from AI-powered assistants in wearables to generative planning in autonomous Uncrewed Aerial Vehicles (UAVs)--has revolutionized user experiences. However, these GenAI applications impose immense computational burdens on edge hardware, leaving strictly limited resources for fundamental security tasks like Global Navigation Satellite System (GNSS) signal protection. Furthermore, training robust classifiers for such devices is hindered by the scarcity of real-world interference data. To address the dual challenges of data scarcity and the extreme efficiency required by the GenAI era, this paper proposes a novel framework named GAC-KAN. First, we adopt a physics-guided simulation approach to synthesize a large-scale, high-fidelity jamming dataset, mitigating the data bottleneck. Second, to reconcile high accuracy with the stringent resource constraints of GenAI-native chips, we design a Multi-Scale Ghost-ACB-Coordinate (MS-GAC) backbone. This backbone combines Asymmetric Convolution Blocks (ACB) and Ghost modules to extract rich spectral-temporal features with minimal redundancy. Replacing the traditional Multi-Layer Perceptron (MLP) decision head, we introduce a Kolmogorov-Arnold Network (KAN), which employs learnable spline activation functions to achieve superior non-linear mapping capabilities with significantly fewer parameters. Experimental results demonstrate that GAC-KAN achieves an overall accuracy of 98.0\\%, outperforming state-of-the-art baselines. Significantly, the model contains only 0.13 million parameter--approximately 660 times fewer than Vision Transformer (ViT) baselines. This extreme lightweight characteristic makes GAC-KAN an ideal \"always-on\" security companion, ensuring GNSS reliability without contending for the computational resources required by primary GenAI tasks.", "AI": {"tldr": "提出了GAC-KAN框架，用于在资源受限的消费级边缘设备上实现GNSS干扰分类。", "motivation": "为了应对消费电子产品中生成式AI应用带来的计算负担和实际干扰数据稀缺的问题，该论文旨在设计一个高效的干扰分类器。", "method": "通过物理引导仿真方法合成大规模高保真干扰数据集；采用多尺度鬼ACB坐标（MS-GAC）骨干网络结合非线性映射能力强的Kolmogorov-Arnold网络(KAN)，实现高效准确的干扰分类。", "result": "实验结果表明，GAC-KAN模型在准确率上达到了98.0%，并且参数量仅为0.13百万，显著减少了计算资源的需求。", "conclusion": "该论文提出的轻量化框架能够为消费级边缘设备提供有效的GNSS干扰保护，确保信号的可靠性。"}}
{"id": "2602.11185", "pdf": "https://arxiv.org/pdf/2602.11185", "abs": "https://arxiv.org/abs/2602.11185", "authors": ["Zhendong Huang", "Hengjie Cao", "Fang Dong", "Ruijun Huang", "Mengyi Chen", "Yifeng Yang", "Xin Zhang", "Anrui Chen", "Mingzhi Dong", "Yujiang Wang", "Jinlong Hou", "Qin Lv", "Robert P. Dick", "Yuan Cheng", "Fan Yang", "Tun Lu", "Li Shang"], "title": "Spectra: Rethinking Optimizers for LLMs Under Spectral Anisotropy", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Gradient signals in LLM training are highly anisotropic: recurrent linguistic structure concentrates energy into a small set of dominant spectral directions, while context specific information resides in a long tail. We show that this spike tail separation persists throughout training, with the spike occupying only about 1.5% of directions yet dominating optimizer statistics. This dominance suppresses tail learning by contracting tail updates through second moment normalization and tightening the globally stable learning rate bound. Motivated by this analysis, we propose Spectra, a spike aware optimizer that suppresses the dominant low rank spike subspace without amplifying the noise sensitive spectral tail. Spectra tracks the spike subspace via cached, warm started power iteration and applies low rank spectral shaping with negligible overhead and substantially reduced optimizer state memory. On LLaMA3 8B trained on 50B tokens, Spectra reaches the same target loss 30% faster than AdamW, reduces per step end to end overhead by 0.7%, cuts optimizer state memory by 49.25%, and improves average downstream accuracy by 1.62%. Compared to Muon, Spectra is 5.1x faster in optimizer processing time, achieves a lower final loss, and improves average accuracy by 0.66%.", "AI": {"tldr": "本文提出了一种新的优化器Spectra，旨在解决LLM训练中梯度信号的谱异质性问题。", "motivation": "在大规模语言模型训练过程中，梯度信号表现出高度的方向异质性。这种异质性使得主要的信息集中在少数几个主导方向上，而次要信息则分散在长尾部分。这导致优化器对长尾部分的学习产生了抑制作用。", "method": "Spectra通过缓存和预热的幂迭代跟踪主导子空间，并应用低秩谱形变来抑制长尾噪声敏感性，同时保持较低的计算开销和内存消耗。", "result": "在LLaMA3 8B模型上训练50B标记时，Spectra比AdamW达到相同目标损失速度快30%，减少了每步端到端的开销，并且将优化器状态内存减少49.25%。与Muon相比，Spectra在优化器处理时间方面快5.1倍，最终损失更低，平均准确率提高0.66%。", "conclusion": "通过对LLM训练中梯度信号的谱异质性问题的研究和解决，本文提出的Spectra优化器展示了显著的性能提升，同时减少了内存消耗和计算开销。"}}
{"id": "2602.11184", "pdf": "https://arxiv.org/pdf/2602.11184", "abs": "https://arxiv.org/abs/2602.11184", "authors": ["Zukang Xu", "Zhixiong Zhao", "Xing Hu", "Zhixuan Chen", "Dawei Yang"], "title": "KBVQ-MoE: KLT-guided SVD with Bias-Corrected Vector Quantization for MoE Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICLR 2026", "summary": "Mixture of Experts (MoE) models have achieved great success by significantly improving performance while maintaining computational efficiency through sparse expert activation. However, their enormous parameter sizes and memory demands pose major challenges for deployment in resource-constrained environments. Vector Quantization (VQ) offers a promising approach for ultra-low-bit compression in Large Language Models (LLMs) by leveraging a codebook, where weight vectors are mapped to the most similar discrete codewords. Yet, directly applying VQ to MoEs often leads to substantial performance degradation due to two critical obstacles: (1) redundant representations among experts cause VQ to repeatedly quantize similar representations for each expert, resulting in inefficient use of limited codebook capacity; and (2) cumulative output bias is amplified by expert aggregation in MoE layers, leading to distributional shifts in the quantized outputs. To address these issues, we propose KBVQ-MoE, a novel VQ framework to enhance extremely low-bit quantization for MoE-based LLMs. KBVQ-MoE integrates two techniques: (1) input-driven redundancy elimination, where a Karhunen-Loeve Transform (KLT) guided singular value decomposition (SVD) extracts dominant weight components and shares them across experts; and (2) bias-corrected output stabilization, where vector quantization is applied only to expert-specific (non-redundant) representations and the quantized outputs are corrected via channel-wise affine compensation. Experiments on various MoE LLMs demonstrate that KBVQ-MoE preserves accuracy substantially better than existing quantization methods. For example, 3-bit quantization of Qwen1.5-MoE-A2.7B achieves an average accuracy of 67.99, nearly identical to the FP16 baseline of 68.07, underscoring KBVQ-MoE's potential for efficient deployment on edge devices and other resource-constrained platforms.", "AI": {"tldr": "提出KBVQ-MoE框架，通过输入驱动冗余消除和偏置校正输出稳定化技术，提高混合专家模型的低比特量化效率。", "motivation": "解决MoE模型在资源受限环境中的部署挑战，尤其是在直接应用向量量化（VQ）时导致的表现下降问题。", "method": "KBVQ-MoE框架结合了两种技术：通过KLT引导奇异值分解提取权重分量并在专家间共享以消除冗余；仅对专家特定的非冗余表示进行向量量化，并通过通道级仿射补偿校正量化输出偏置。", "result": "实验表明，KBVQ-MoE在各种MoE大语言模型上保持了高精度，如3比特量化后的Qwen1.5-MoE-A2.7B的平均准确率为67.99，接近FP16基准线68.07。", "conclusion": "KBVQ-MoE框架展示了在边缘设备和其他资源受限平台上高效部署的巨大潜力。"}}
{"id": "2602.11183", "pdf": "https://arxiv.org/pdf/2602.11183", "abs": "https://arxiv.org/abs/2602.11183", "authors": ["Yin Tang", "Jiawei Ma", "Jinrui Zhang", "Alex Jinpeng Wang", "Deyu Zhang"], "title": "Mitigating Error Accumulation in Continuous Navigation via Memory-Augmented Kalman Filtering", "categories": ["cs.RO", "cs.CV", "eess.SY"], "comment": "Preprint, 15 pages, 6 figures", "summary": "Continuous navigation in complex environments is critical for Unmanned Aerial Vehicle (UAV). However, the existing Vision-Language Navigation (VLN) models follow the dead-reckoning, which iteratively updates its position for the next waypoint prediction, and subsequently construct the complete trajectory. Then, such stepwise manner will inevitably lead to accumulated errors of position over time, resulting in misalignment between internal belief and objective coordinates, which is known as \"state drift\" and ultimately compromises the full trajectory prediction. Drawing inspiration from classical control theory, we propose to correct for errors by formulating such sequential prediction as a recursive Bayesian state estimation problem. In this paper, we design NeuroKalman, a novel framework that decouples navigation into two complementary processes: a Prior Prediction, based on motion dynamics and a Likelihood Correction, from historical observation. We first mathematically associate Kernel Density Estimation of the measurement likelihood with the attention-based retrieval mechanism, which then allows the system to rectify the latent representation using retrieved historical anchors without gradient updates. Comprehensive experiments on TravelUAV benchmark demonstrate that, with only 10% of the training data fine-tuning, our method clearly outperforms strong baselines and regulates drift accumulation.", "AI": {"tldr": "本文提出了NeuroKalman框架，旨在通过递归贝叶斯状态估计方法来纠正连续导航中的位置累积误差。", "motivation": "现有的VLN模型由于采取步步迭代更新位置的方式，在复杂环境中进行连续导航时会产生位置累计错误，导致内部信念与真实坐标之间的偏差增大。为了减少这种累积误差，作者受到了经典控制理论的启发，提出了一种新的框架来解决这个问题。", "method": "本文设计了NeuroKalman框架，将导航过程分解为先验预测和似然校正两个互补部分：前者基于运动动力学，后者则从历史观测中提取信息进行纠正。通过将核密度估计与注意机制相结合，系统能够在不更新梯度的情况下修正潜在表示。", "result": "在TravelUAV基准数据集上的实验表明，在仅使用10%的训练数据微调的情况下，该方法明显优于现有的基线模型，并且能有效调节累积漂移问题。", "conclusion": "NeuroKalman框架通过递归贝叶斯状态估计成功缓解了连续导航中的位置积累误差问题，为解决UAV在复杂环境中进行连续任务时的定位准确性提供了新思路。"}}
{"id": "2602.11179", "pdf": "https://arxiv.org/pdf/2602.11179", "abs": "https://arxiv.org/abs/2602.11179", "authors": ["Munazza Zaib", "Elaf Alhazmi"], "title": "From Instruction to Output: The Role of Prompting in Modern NLG", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Prompt engineering has emerged as an integral technique for extending the strengths and abilities of Large Language Models (LLMs) to gain significant performance gains in various Natural Language Processing (NLP) tasks. This approach, which requires instructions to be composed in natural language to bring out the knowledge from LLMs in a structured way, has driven breakthroughs in various NLP tasks. Yet there is still no structured framework or coherent understanding of the varied prompt engineering methods and techniques, particularly in the field of Natural Language Generation (NLG). This survey aims to help fill that gap by outlining recent developments in prompt engineering, and their effect on different NLG tasks. It reviews recent advances in prompting methods and their impact on NLG tasks, presenting prompt design as an input-level control mechanism that complements fine-tuning and decoding approaches. The paper introduces a taxonomy of prompting paradigms, a decision framework for prompt selection based on varying factors for the practitioners, outlines emerging trends and challenges, and proposes a framework that links design, optimization, and evaluation to support more controllable and generalizable NLG.", "AI": {"tldr": "本文综述了提示工程在自然语言生成(NLG)任务中的作用，提出了一个系统化的框架来指导从业者选择合适的提示方法。", "motivation": "当前的提示工程技术尚缺乏结构化的方法论和系统的理解。为了填补这一空白，本论文旨在概述近年来提示工程的发展趋势及其对NLG的影响。", "method": "本文通过回顾现有文献中的提示设计技术，提出了一种新的分类框架，并针对不同的任务场景为从业者提供了决策指导。", "result": "文章提出了一个涵盖设计、优化和评估的框架，以促进更可控且具通用性的自然语言生成。", "conclusion": "研究表明，提示工程不仅可以作为输入级别的控制机制来补充微调和解码方法，还可以通过系统化的方法提高NLG任务的效果。"}}
{"id": "2602.11177", "pdf": "https://arxiv.org/pdf/2602.11177", "abs": "https://arxiv.org/abs/2602.11177", "authors": ["Lei Jiang", "Yue Zhou", "Natalie Parde"], "title": "What Do LLMs Know About Alzheimer's Disease? Fine-Tuning, Probing, and Data Synthesis for AD Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reliable early detection of Alzheimer's disease (AD) is challenging, particularly due to limited availability of labeled data. While large language models (LLMs) have shown strong transfer capabilities across domains, adapting them to the AD domain through supervised fine-tuning remains largely unexplored. In this work, we fine-tune an LLM for AD detection and investigate how task-relevant information is encoded within its internal representations. We employ probing techniques to analyze intermediate activations across transformer layers, and we observe that, after fine-tuning, the probing values of specific words and special markers change substantially, indicating that these elements assume a crucial role in the model's improved detection performance. Guided by this insight, we design a curated set of task-aware special markers and train a sequence-to-sequence model as a data-synthesis tool that leverages these markers to generate structurally consistent and diagnostically informative synthetic samples. We evaluate the synthesized data both intrinsically and by incorporating it into downstream training pipelines.", "AI": {"tldr": "本论文研究了通过微调和数据合成来提高大规模语言模型在阿尔茨海默病检测中的性能。", "motivation": "目前，由于标注数据的稀缺，阿尔茨海默病早期可靠的诊断仍面临挑战。该工作旨在探索将大型语言模型应用于AD领域并通过监督微调提升其表现的方法。", "method": "通过微调和探针技术分析中间激活状态来研究任务相关信息在内部表示中的编码方式，并设计了一套专门的标记用于生成合成样本以增强下游训练流程。", "result": "观察到经过微调后特定词汇和特殊标识符的探针值发生了显著变化，表明这些元素对模型改善检测性能至关重要。使用合成数据改进了模型的表现。", "conclusion": "通过微调与探针分析揭示了如何利用大型语言模型进行AD诊断的关键信息，并展示了借助设计的标记生成有效合成样本以增强训练效果的方法"}}
{"id": "2602.11176", "pdf": "https://arxiv.org/pdf/2602.11176", "abs": "https://arxiv.org/abs/2602.11176", "authors": ["Maral Doctorarastoo", "Katherine A. Flanigan", "Mario Bergés", "Christopher McComb"], "title": "Evaluating Few-Shot Temporal Reasoning of LLMs for Human Activity Prediction in Smart Environments", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG"], "comment": ":I.2.4; I.2.8; I.2.6; I.6.5; H.3.3", "summary": "Anticipating human activities and their durations is essential in applications such as smart-home automation, simulation-based architectural and urban design, activity-based transportation system simulation, and human-robot collaboration, where adaptive systems must respond to human activities. Existing data-driven agent-based models--from rule-based to deep learning--struggle in low-data environments, limiting their practicality. This paper investigates whether large language models, pre-trained on broad human knowledge, can fill this gap by reasoning about everyday activities from compact contextual cues. We adopt a retrieval-augmented prompting strategy that integrates four sources of context--temporal, spatial, behavioral history, and persona--and evaluate it on the CASAS Aruba smart-home dataset. The evaluation spans two complementary tasks: next-activity prediction with duration estimation, and multi-step daily sequence generation, each tested with various numbers of few-shot examples provided in the prompt. Analyzing few-shot effects reveals how much contextual supervision is sufficient to balance data efficiency and predictive accuracy, particularly in low-data environments. Results show that large language models exhibit strong inherent temporal understanding of human behavior: even in zero-shot settings, they produce coherent daily activity predictions, while adding one or two demonstrations further refines duration calibration and categorical accuracy. Beyond a few examples, performance saturates, indicating diminishing returns. Sequence-level evaluation confirms consistent temporal alignment across few-shot conditions. These findings suggest that pre-trained language models can serve as promising temporal reasoners, capturing both recurring routines and context-dependent behavioral variations, thereby strengthening the behavioral modules of agent-based models.", "AI": {"tldr": "评估大型语言模型在低数据环境下的人类活动预测能力", "motivation": "现有数据驱动的智能系统难以处理低数据环境，希望通过利用预训练的语言模型来解决人类行为的时间推理问题", "method": "采用检索增强提示策略，结合四种情境信息（时间、空间、行为历史和个人特征），并使用CASAS Aruba智能家居数据集进行评估，包括下一个活动预测和多步骤日常序列生成任务", "result": "大型语言模型在零样本设置下可以产生连贯的日常活动预测，在少量示例的帮助下进一步提高准确性和持续性。超过一定数量后性能趋于稳定", "conclusion": "预训练的语言模型具备强大的时间推理能力，可以捕捉人类行为中的常规模式和上下文依赖变化"}}
{"id": "2602.11174", "pdf": "https://arxiv.org/pdf/2602.11174", "abs": "https://arxiv.org/abs/2602.11174", "authors": ["Aradhya Dixit", "Shreem Dixit"], "title": "The Script Tax: Measuring Tokenization-Driven Efficiency and Latency Disparities in Multilingual Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Pretrained multilingual language models are often assumed to be script-agnostic, yet their tokenizers can impose systematic costs on certain writing systems. We quantify this script tax by comparing two orthographic variants with identical linguistic content. Across mBERT and XLM-R, the higher-fragmentation orthography shows a ~3.4x increase in fertility (6.73-6.85 vs. 2.10-2.35 tokens/word), leading to a 16.5x inference slowdown (0.23 vs. 3.8 sentences/second) on identical hardware. Using bits per character (BPC) to avoid the \"NLL paradox\" from subword fragmentation, we find a substantial increase in information cost: +19.7% for mBERT (8.06->9.65) and +47.1% for XLM-R (12.19->17.94). A round-trip conversion check (CER_rt=0.31) suggests these gaps reflect orthography-conditioned processing rather than mapping noise. Our results highlight tokenization as a key source of inequity in multilingual NLP and motivate script-aware tokenization and pretraining.", "AI": {"tldr": "量化多语言模型中不同书写系统所带来的效率和延迟差异。", "motivation": "探讨预训练的多语言模型在处理不同脚本时是否存在系统性的成本问题，以揭示其不平等性。", "method": "通过比较两种具有相同语言内容的不同拼写变体，使用片段化度量标准（如每字符比特数）来评估信息代价，并进行往返转换检查。", "result": "高碎片化的书写系统导致模型的推断速度下降16.5倍，且信息成本增加，mBERT增加了19.7%，XLM-R增加了47.1%。", "conclusion": "证明了令牌化是多语言NLP中不平等的关键来源，并建议采用脚本感知令牌化和预训练方法。"}}
{"id": "2602.11171", "pdf": "https://arxiv.org/pdf/2602.11171", "abs": "https://arxiv.org/abs/2602.11171", "authors": ["Baek Seong-Eun", "Lee Jung-Mok", "Kim Sung-Bin", "Tae-Hyun Oh"], "title": "Efficient Hyper-Parameter Search for LoRA via Language-aided Bayesian Optimization", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Fine-tuning Large Language Models (LLMs) with Low-Rank Adaptation (LoRA) enables resource-efficient personalization or specialization, but it comes at the expense of additional hyperparameter tuning. Although LoRA makes fine-tuning efficient, it is highly sensitive to the choice of hyperparameters, and exhaustive hyperparameter search is still computationally very demanding. To address these challenges, we propose a framework that integrates the domain knowledge of pre-trained LLMs into Bayesian Optimization (BO) to efficiently search for LoRA hyperparameters. To leverage the informed knowledge of LLMs, we repurpose LLMs as a discrete-to-continuous mapping to link the hyperparameters and their domain knowledge with a continuous vector space, where BO is conducted. We design and control the mapping by language prompting, where we provide a domain-aware textual prompt describing the relationships among hyperparameters and their respective roles; thereby, we explicitly inject domain knowledge about LoRA into the LLM in natural language. Also, we model the residual information that is hard to linguistically describe in the prompt with an additional learnable token. This aids BO to sample more high-performing hyperparameters. In addition, by leveraging the observation of the strong correlation between the respective performance obtained from full and subset training datasets in LoRA training regimes, we introduce proxy training and evaluation with a data subset. This further increases the efficiency of our method. We demonstrate that our hyperparameter found with only about 30 iterations achieves more than 20% performance improvement over standard hyperparameters found from about 45,000 combinations.", "AI": {"tldr": "提出了一种利用语言模型和贝叶斯优化高效搜索LoRA超参数的方法。", "motivation": "为了提高LoRA的个性化或专业化能力，同时减少耗时且计算密集型的超参数搜索过程，该论文设计了结合领域知识与预训练语言模型的解决方案。", "method": "将预训练的语言模型作为离散到连续映射工具，通过自然语言提示注入LoRA领域的知识，并利用贝叶斯优化在连续向量空间中进行高效的超参数搜索。同时引入代理训练和评估机制以进一步提高效率。", "result": "提出的框架仅使用约30次迭代即可找到比标准方法从约45,000种组合中选出的超参数高出20%以上的性能。", "conclusion": "结合语言模型与贝叶斯优化的方法能够有效提高LoRA的个性化能力和训练效率。"}}
{"id": "2602.11169", "pdf": "https://arxiv.org/pdf/2602.11169", "abs": "https://arxiv.org/abs/2602.11169", "authors": ["Mangadoddi Srikar Vardhan", "Lekkala Sai Teja"], "title": "Disentangling Direction and Magnitude in Transformer Representations: A Double Dissociation Through L2-Matched Perturbation Analysis", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "15 pages, 7 figures. will Submit to ICML 2026", "summary": "Transformer hidden states encode information as high-dimensional vectors, yet whether direction (orientation in representational space) and magnitude (vector norm) serve distinct functional roles remains unclear. Studying Pythia-family models, we discover a striking cross-over dissociation: angular perturbations cause up to 42.9 more damage to language modeling loss, while magnitude perturbations cause disproportionately more damage to syntactic processing (20.4% vs.1.6% accuracy drop on subject-verb agreement).This finding is enabled by L2-matched perturbation analysis, a methodology ensuring that an gular and magnitude perturbations achieve identical Euclidean displacements. Causal intervention reveals that angular damage flows substantially through the attention pathways (28.4% loss recovery via attention repair), while magnitude damage flows partly through the LayerNorm pathways(29.9% recovery via LayerNorm repair). These patterns replicate across scales within the Pythia architecture family. These findings provide evidence that direction and magnitude support partially distinct computational roles in LayerNorm based architectures. The direction preferentially affects attentional routing, while magnitude modulates processing intensity for fine-grained syntactic judgments. We find different patterns in RMSNorm-based architectures, suggesting that the dissociation depends on architectural choices. Our results refine the linear representation hypothesis and have implications for model editing and interpretability research", "AI": {"tldr": "本文通过L2匹配扰动分析，研究了Transformer模型中的方向和大小在语言建模和句法处理中扮演的不同角色。", "motivation": "探索Transformer隐藏状态的方向（空间取向）和大小（矢量范数）是否具有不同的功能性作用，以及它们如何影响语言建模损失和句法加工准确性。", "method": "利用L2匹配扰动分析方法进行研究，并通过因果干预揭示了方向损伤主要经由注意力路径传递，而大小损伤部分经过LayerNorm路径传递。", "result": "发现角向扰动对语言模型损失的损害更大，幅度扰动对句法处理（如主谓一致）的影响更显著；不同架构的选择会影响这种分离模式的存在。", "conclusion": "研究提供了方向和大小在LayerNorm架构中支持部分不同的计算角色的证据，并对模型编辑和可解释性研究具有重要意义。"}}
{"id": "2602.11168", "pdf": "https://arxiv.org/pdf/2602.11168", "abs": "https://arxiv.org/abs/2602.11168", "authors": ["Jingyan Xu", "Marcelo L. LaFleur", "Christina Schweikert", "D. Frank Hsu"], "title": "Enhancing SDG-Text Classification with Combinatorial Fusion Analysis and Generative AI", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, 8 figures, 4 tables; Accepted to 2025 IEEE International Conference on Pervasive Intelligence and Computing (PICom 2025)", "summary": "(Natural Language Processing) NLP techniques such as text classification and topic discovery are very useful in many application areas including information retrieval, knowledge discovery, policy formulation, and decision-making. However, it remains a challenging problem in cases where the categories are unavailable, difficult to differentiate, or are interrelated. Social analysis with human context is an area that can benefit from text classification, as it relies substantially on text data. The focus of this paper is to enhance the classification of text according to the UN's Sustainable Development Goals (SDGs) by collecting and combining intelligence from multiple models. Combinatorial Fusion Analysis (CFA), a system fusion paradigm using a rank-score characteristic (RSC) function and cognitive diversity (CD), has been used to enhance classifier methods by combining a set of relatively good and mutually diverse classification models. We use a generative AI model to generate synthetic data for model training and then apply CFA to this classification task. The CFA technique achieves 96.73% performance, outperforming the best individual model. We compare the outcomes with those obtained from human domain experts. It is demonstrated that combining intelligence from multiple ML/AI models using CFA and getting input from human experts can, not only complement, but also enhance each other.", "AI": {"tldr": "利用组合融合分析和生成式AI提升对可持续发展目标(SDGs)文本分类的准确性。", "motivation": "在无法获得或难以区分类别，或者类别之间相互关联的情况下，如何改进文本分类以支持社会分析成为挑战。本研究旨在通过收集并整合多个模型的信息来增强SDGs相关文本的分类。", "method": "使用组合融合分析(CFA)结合生成式AI产生的合成数据训练多模型，并采用排名得分特征(RSC)函数和认知多样性(CD)进行系统融合，以此提高分类器的方法。最后与人类专家提供的结果比较。", "result": "该方法实现96.73%的性能，超过了最佳单一模型的表现，展示了通过整合多个ML/AI模型的信息以及结合人类专家的意见可以互补并相互增强的效果。", "conclusion": "组合融合分析(CFA)技术与生成式AI相结合，在SDGs文本分类任务中表现出色。这种方法不仅能提高分类准确率，还能将机器学习和人工智能模型的输出与人类专家的知识有效地结合起来。"}}
{"id": "2602.11167", "pdf": "https://arxiv.org/pdf/2602.11167", "abs": "https://arxiv.org/abs/2602.11167", "authors": ["Nathan Mao", "Varun Kaushik", "Shreya Shivkumar", "Parham Sharafoleslami", "Kevin Zhu", "Sunishchal Dev"], "title": "Visualizing and Benchmarking LLM Factual Hallucination Tendencies via Internal State Analysis and Clustering", "categories": ["cs.CL", "cs.AI"], "comment": "ef:Proceedings of IJCNLP-AACL SRW 2025, pp. 289-298", "summary": "Large Language Models (LLMs) often hallucinate, generating nonsensical or false information that can be especially harmful in sensitive fields such as medicine or law. To study this phenomenon systematically, we introduce FalseCite, a curated dataset designed to capture and benchmark hallucinated responses induced by misleading or fabricated citations. Running GPT-4o-mini, Falcon-7B, and Mistral 7-B through FalseCite, we observed a noticeable increase in hallucination activity for false claims with deceptive citations, especially in GPT-4o-mini. Using the responses from FalseCite, we can also analyze the internal states of hallucinating models, visualizing and clustering the hidden state vectors. From this analysis, we noticed that the hidden state vectors, regardless of hallucination or non-hallucination, tend to trace out a distinct horn-like shape. Our work underscores FalseCite's potential as a foundation for evaluating and mitigating hallucinations in future LLM research.", "AI": {"tldr": "本文介绍了FalseCite，一个用于捕获和评估大型语言模型在虚假引用下产生虚构信息倾向的基准数据集。通过分析GPT-4o-mini、Falcon-7B和Mistral 7-B模型内部状态并进行聚类，揭示了其在处理误导性或伪造引文时产生的幻觉。", "motivation": "大型语言模型（LLMs）常产生不切实际或虚假信息，在医学和法律等敏感领域尤其危险。为此，本文提出FalseCite数据集来系统研究这一现象，并评估未来缓解策略的效果。", "method": "使用FalseCite对GPT-4o-mini、Falcon-7B和Mistral 7-B进行测试，观察模型在虚假引用下的幻觉反应。通过分析内部状态向量的聚类模式，可视化其特征。", "result": "发现当面对误导性或伪造引文时，GPT-4o-mini尤其容易产生幻觉；所有模型无论是否产生幻觉，其内部状态向量都呈现出独特的“角状”形态。", "conclusion": "FalseCite为评估和缓解大型语言模型的虚构信息倾向提供了基础。"}}
{"id": "2602.11166", "pdf": "https://arxiv.org/pdf/2602.11166", "abs": "https://arxiv.org/abs/2602.11166", "authors": ["Xu Hu", "Yifan Zhang", "Songtao Wei", "Chen Zhao", "Qiannan Li", "Bingzhe Li", "Feng Chen"], "title": "Small Updates, Big Doubts: Does Parameter-Efficient Fine-tuning Enhance Hallucination Detection ?", "categories": ["cs.CL", "cs.AI"], "comment": "18 pages, 13 figures, 8 tables", "summary": "Parameter-efficient fine-tuning (PEFT) methods are widely used to adapt large language models (LLMs) to downstream tasks and are often assumed to improve factual correctness. However, how the parameter-efficient fine-tuning methods affect hallucination behavior remains insufficiently understood, especially on QA datasets. In this work, we systematically investigate the impact of PEFT on hallucination detection through a comprehensive empirical study across three open-weight LLM backbones and three fact-seeking QA benchmarks. For each model, we evaluate performance using seven unsupervised hallucination detection methods spanning three complementary approaches: semantic consistency based detectors, confidence based detectors, and entropy based detectors. This multifaceted evaluation enables us to characterize how PEFT reshapes uncertainty across different detection paradigms. In conclusion, our experimental results show that PEFT consistently strengthens hallucination detection ability, substantially improving AUROC across a wide range of hallucination detectors. Besides, further analyses using linear probes and representation diagnostics indicate that PEFT methods primarily reshapes how uncertainty is encoded and surfaced, comparing with injecting new factual knowledge into the models.", "AI": {"tldr": "本文研究了参数高效微调方法对问答数据集上幻觉检测的影响。", "motivation": "探索参数高效微调（PEFT）方法如何影响大型语言模型在问答任务中的事实正确性和幻觉行为，尤其是在幻觉检测方面的作用尚不清楚的情况下进行这项工作。", "method": "通过使用三个开放权重的LLM基础模型和三种基于事实的问答基准数据集上的七种无监督幻觉检测方法来进行系统的实证研究。这些方法涵盖了语义一致性、置信度和熵三种不同的检测范式。", "result": "实验结果表明，参数高效微调（PEFT）显著增强了对幻觉行为的检测能力，提高了多种幻觉检测器的AUROC指标。", "conclusion": "PEFT通过重新编码和展示不确定性来改善幻觉检测的能力，而不是向模型中注入新的事实知识。"}}
{"id": "2602.11165", "pdf": "https://arxiv.org/pdf/2602.11165", "abs": "https://arxiv.org/abs/2602.11165", "authors": ["Pushwitha Krishnappa", "Amit Das", "Vinija Jain", "Tathagata Mukherjee", "Aman Chadha"], "title": "Assessing LLM Reliability on Temporally Recent Open-Domain Questions", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed for open-domain question answering, yet their alignment with human perspectives on temporally recent information remains underexplored. We introduce RECOM (Reddit Evaluation for Correspondence of Models), a benchmark dataset of 15,000 recent Reddit questions from September 2025 paired with community-derived reference answers. We investigate how four open-source LLMs (Llama3.1-8B, Mistral-7B, Gemma-2-9B, and GPT-OSS-20B) respond to these questions, evaluating alignment using lexical metrics (BLEU, ROUGE), semantic similarity (BERTScore, MoverScore, cosine similarity), and logical inference (NLI). Our central finding is a striking semantic-lexical paradox: all models achieve over 99% cosine similarity with references despite less than 8% BLEU-1 overlap, a 90+ percentage point gap indicating that models preserve meaning through extensive paraphrasing rather than lexical reproduction. MoverScore (51-53%) confirms this pattern, occupying an intermediate position that reflects the optimal transport cost of semantic alignment. Furthermore, model scale does not predict performance: Mistral-7B (7B parameters) outperforms GPT-OSS-20B (20B parameters) across all metrics. NLI analysis reveals that contradiction rates remain below 7%, suggesting models rarely generate content that directly conflicts with human consensus. These findings challenge the reliability of lexical metrics for evaluating abstractive generation and argue for multi-dimensional evaluation frameworks that capture semantic fidelity beyond surface-level text matching. The RECOM dataset is publicly available at https://anonymous.4open.science/r/recom-D4B0", "AI": {"tldr": "评估大型语言模型在处理最近时期开放域问题时的准确性。", "motivation": "探究大型语言模型对近期信息的响应是否与人类视角一致，因为这一点尚未充分研究。", "method": "引入RECOM数据集，包含15000个来自2025年9月的Reddit问题，并通过BLEU、ROUGE等词法指标以及BERTScore、MoverScore和余弦相似度等语义相似性指标来评估模型的表现。使用自然逻辑推理(NLI)分析模型输出与人类共识的矛盾率。", "result": "发现一个显著的语言-语义悖论：所有模型在语义上高度一致，但词法重叠很低；Mistral-7B性能优于参数更多的GPT-OSS-20B，表明规模并非决定因素；NLI分析显示矛盾率低于7%。", "conclusion": "研究表明仅凭词汇匹配不足以评估生成文本的质量，建议采用多维度框架来评价模型的语义保真度。"}}
{"id": "2602.11164", "pdf": "https://arxiv.org/pdf/2602.11164", "abs": "https://arxiv.org/abs/2602.11164", "authors": ["Weiting Liu", "Han Wu", "Yufei Kuang", "Xiongwei Han", "Tao Zhong", "Jianfeng Feng", "Wenlian Lu"], "title": "Automated Optimization Modeling via a Localizable Error-Driven Perspective", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Automated optimization modeling via Large Language Models (LLMs) has emerged as a promising approach to assist complex human decision-making. While post-training has become a pivotal technique to enhance LLMs' capabilities in this domain, its effectiveness is severely constrained by the scarcity and underutilization of high-quality training data. However, through a detailed profiling of error patterns across various problem-response pairs drawn from post-training, we identify two fundamental limitations of existing automated optimization modeling approaches: (L1) the sparsity of error-specific problems and (L2) the sparse rewards associated with difficult problems. We demonstrate that these limitations can result in suboptimal performance in domain-specific post-training for LLMs. To tackle the above two limitations, we propose a novel error-driven learning framework -- namely, auto\\textbf{m}ated opt\\textbf{i}mization modeli\\textbf{n}g via a localizable error-\\textbf{d}riven perspective (MIND) -- that customizes the whole model training framework from data synthesis to post-training. MIND is based on our key observation of the unique localizable patterns in error propagation of optimization modelings, that is, modeling errors may remain localized to specific semantic segments and do not propagate throughout the entire solution. Thus, in contrast to holistic reasoning tasks such as mathematical proofs, MIND leverages the construction of a focused, high-density training corpus and proposes \\textbf{D}ynamic Supervised \\textbf{F}ine-Tuning \\textbf{P}olicy \\textbf{O}ptimization (DFPO) to tackle difficult problems through localized refinement. Experiments on six benchmarks demonstrate that MIND consistently outperforms all the state-of-the-art automated optimization modeling approaches.", "AI": {"tldr": "提出了一种新的错误驱动学习框架MIND，以解决自动化优化建模中的局限性，并通过局部化的方法提高了LLMs在特定领域后训练的性能。", "motivation": "现有自动化优化建模方法存在两个主要限制：一是缺少特定错误问题的数据；二是难以针对难题提供有效奖励。这些问题导致了LLMs在特定领域的后训练中表现不佳。", "method": "MIND框架基于优化建模中的独特局部化模式，通过聚焦高密度训练语料库和动态监督细化策略优化（DFPO）来解决难点问题，并通过局部化改进提升模型性能。", "result": "实验表明，在六个基准测试上，MIND在自动化优化建模方面始终优于现有最佳方法。", "conclusion": "提出的MIND框架能够有效地解决当前自动化优化建模中的局限性，并显著提高LLMs的特定领域后训练表现。"}}
{"id": "2602.11163", "pdf": "https://arxiv.org/pdf/2602.11163", "abs": "https://arxiv.org/abs/2602.11163", "authors": ["Muhammad Haris", "Hans Höft", "Markus M. Becker", "Markus Stocker"], "title": "Nested Named Entity Recognition in Plasma Physics Research Articles", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Named Entity Recognition (NER) is an important task in natural language processing that aims to identify and extract key entities from unstructured text. We present a novel application of NER in plasma physics research articles and address the challenges of extracting specialized entities from scientific text in this domain. Research articles in plasma physics often contain highly complex and context-rich content that must be extracted to enable, e.g., advanced search. We propose a lightweight approach based on encoder-transformers and conditional random fields to extract (nested) named entities from plasma physics research articles. First, we annotate a plasma physics corpus with 16 classes specifically designed for the nested NER task. Second, we evaluate an entity-specific model specialization approach, where independent BERT-CRF models are trained to recognize individual entity types in plasma physics text. Third, we integrate an optimization process to systematically fine-tune hyperparameters and enhance model performance. Our work contributes to the advancement of entity recognition in plasma physics and also provides a foundation to support researchers in navigating and analyzing scientific literature.", "AI": {"tldr": "本文提出了一种基于编码器-变换器和条件随机场的轻量级方法，用于从等离子体物理学研究文章中提取（嵌套）命名实体。", "motivation": "在等离子体物理的研究文献中存在高度复杂且富含上下文的内容，需要对其进行抽取以便于高级检索。现有的命名实体识别技术难以满足该领域的特殊需求，因此本文旨在解决这一挑战，并促进科学文献的导航和分析。", "method": "首先，作者对一个专门针对等离子体物理学文章的语料库进行了标注，涵盖16个类别；其次，提出了一种独立训练BERT-CRF模型来识别个体实体类型的特化方法；最后，通过优化过程系统地微调超参数以提升模型性能。", "result": "本文的方法能够有效提取科学文献中的命名实体，并为研究人员提供了分析和导航大量科学资料的工具基础。", "conclusion": "本研究提出了一种新颖的应用于等离子体物理学文章中的命名实体识别方法，旨在提高科学文本中实体抽取的效果。该方法不仅有助于科学研究者的文献阅读和信息检索工作，还为进一步的研究打下了坚实的基础。"}}
{"id": "2602.11161", "pdf": "https://arxiv.org/pdf/2602.11161", "abs": "https://arxiv.org/abs/2602.11161", "authors": ["Svetlana Churina", "Kokil Jaidka", "Anab Maulana Barik", "Harshit Aneja", "Cai Yang", "Wynne Hsu", "Mong Li Lee"], "title": "Althea: Human-AI Collaboration for Fact-Checking and Critical Reasoning", "categories": ["cs.HC", "cs.CL"], "comment": null, "summary": "The web's information ecosystem demands fact-checking systems that are both scalable and epistemically trustworthy. Automated approaches offer efficiency but often lack transparency, while human verification remains slow and inconsistent. We introduce Althea, a retrieval-augmented system that integrates question generation, evidence retrieval, and structured reasoning to support user-driven evaluation of online claims. On the AVeriTeC benchmark, Althea achieves a Macro-F1 of 0.44, outperforming standard verification pipelines and improving discrimination between supported and refuted claims. We further evaluate Althea through a controlled user study and a longitudinal survey experiment (N = 642), comparing three interaction modes that vary in the degree of scaffolding: an Exploratory mode with guided reasoning, a Summary mode providing synthesized verdicts, and a Self-search mode that offers procedural guidance without algorithmic intervention. Results show that guided interaction produces the strongest immediate gains in accuracy and confidence, while self-directed search yields the most persistent improvements over time. This pattern suggests that performance gains are not driven solely by effort or exposure, but by how cognitive work is structured and internalized.", "AI": {"tldr": "阿尔西娅系统通过整合问题生成、证据检索和结构化推理，支持用户驱动的在线声明评估。", "motivation": "网络信息生态系统需要既高效又可信的事实核查系统。自动方法虽效率高但缺乏透明度，而人工验证则缓慢且不一致。", "method": "阿尔西娅是一个检索增强型系统，结合了问题生成、证据检索和结构化推理来支持用户驱动的评估过程。该系统通过三种交互模式进行评估：探索性模式（带引导式推理）、摘要模式（提供合成裁决）和自我搜索模式（在没有算法干预的情况下提供程序指导）。", "result": "在AVeriTeC基准测试中，阿尔西娅达到了Macro-F1为0.44的分数，超过了标准验证流程，并提高了支持与反驳声明之间的区分度。用户研究显示，引导式交互立即提升了准确性和信心，而自我搜索模式则随着时间带来了持久的进步。", "conclusion": "研究表明，认知工作的结构化和内化对表现提升至关重要，这表明性能改进不仅仅是由于努力或曝光时间增加所致。"}}
{"id": "2602.11160", "pdf": "https://arxiv.org/pdf/2602.11160", "abs": "https://arxiv.org/abs/2602.11160", "authors": ["Alexanne Worm", "Florian Marchal", "Sylvain Castagnos"], "title": "BIRD: A Museum Open Dataset Combining Behavior Patterns and Identity Types to Better Model Visitors' Experience", "categories": ["cs.HC", "cs.AI", "cs.IR"], "comment": "ef:UMAP '25: 33rd ACM Conference on User Modeling, Adaptation and Personalization, Jun 2025, New York City, United States. pp.18-22", "summary": "Lack of data is a recurring problem in Artificial Intelligence, as it is essential for training and validating models. This is particularly true in the field of cultural heritage, where the number of open datasets is relatively limited and where the data collected does not always allow for holistic modeling of visitors' experience due to the fact that data are ad hoc (i.e. restricted to the sole characteristics required for the evaluation of a specific model). To overcome this lack, we conducted a study between February and March 2019 aimed at obtaining comprehensive and detailed information about visitors, their visit experience and their feedback. We equipped 51 participants with eye-tracking glasses, leaving them free to explore the 3 floors of the museum for an average of 57 minutes, and to discover an exhibition of more than 400 artworks. On this basis, we built an open dataset combining contextual data (demographic data, preferences, visiting habits, motivations, social context. . . ), behavioral data (spatiotemporal trajectories, gaze data) and feedback (satisfaction, fatigue, liked artworks, verbatim. . . ). Our analysis made it possible to re-enact visitor identities combining the majority of characteristics found in the literature and to reproduce the Veron and Levasseur profiles. This dataset will ultimately make it possible to improve the quality of recommended paths in museums by personalizing the number of points of interest (POIs), the time spent at these different POIs, and the amount of information to be provided to each visitor based on their level of interest.", "AI": {"tldr": "构建了一个包含行为模式和个人信息的文化遗产访客开放数据集，以更全面地建模访客体验。", "motivation": "缺乏能够全面反映访客体验的数据限制了文化遗产领域人工智能模型的发展。为了克服这一问题，作者开展了一项研究来收集更多的详尽信息。", "method": "通过让51位参与者佩戴眼动追踪眼镜在博物馆自由探索并记录数据，包括人口统计、偏好、行为轨迹和反馈等。", "result": "创建了一个结合上下文和个人行为的数据集，可以重建访客身份，并复制了Veron和Levasseur的个人资料模型。", "conclusion": "该数据集将有助于改进博物馆推荐路线的质量，使个性化信息更加贴合每个访客的兴趣水平。"}}
{"id": "2602.11159", "pdf": "https://arxiv.org/pdf/2602.11159", "abs": "https://arxiv.org/abs/2602.11159", "authors": ["Natalia Abarca", "Andrés Carvallo", "Claudia López Moncada", "Felipe Bravo-Marquez"], "title": "Explaining AI Without Code: A User Study on Explainable AI", "categories": ["cs.AI", "cs.HC", "cs.LG"], "comment": "LatinX in AI Workshop @ NeurIPS-25", "summary": "The increasing use of Machine Learning (ML) in sensitive domains such as healthcare, finance, and public policy has raised concerns about the transparency of automated decisions. Explainable AI (XAI) addresses this by clarifying how models generate predictions, yet most methods demand technical expertise, limiting their value for novices. This gap is especially critical in no-code ML platforms, which seek to democratize AI but rarely include explainability. We present a human-centered XAI module in DashAI, an open-source no-code ML platform. The module integrates three complementary techniques, which are Partial Dependence Plots (PDP), Permutation Feature Importance (PFI), and KernelSHAP, into DashAI's workflow for tabular classification. A user study (N = 20; ML novices and experts) evaluated usability and the impact of explanations. Results show: (i) high task success ($\\geq80\\%$) across all explainability tasks; (ii) novices rated explanations as useful, accurate, and trustworthy on the Explanation Satisfaction Scale (ESS, Cronbach's $α$ = 0.74, a measure of internal consistency), while experts were more critical of sufficiency and completeness; and (iii) explanations improved perceived predictability and confidence on the Trust in Automation scale (TiA, $α$ = 0.60), with novices showing higher trust than experts. These findings highlight a central challenge for XAI in no-code ML, making explanations both accessible to novices and sufficiently detailed for experts.", "AI": {"tldr": "本文研究了在无代码机器学习平台上实现可解释性人工智能（XAI）的方法，通过用户研究评估其有效性。", "motivation": "随着机器学习在敏感领域中的广泛应用，透明度成为了关注焦点。现有的大多数解释方法需要技术知识，限制了它们对初学者的价值。因此，本文旨在解决无代码平台上的XAI问题。", "method": "研究团队开发了一种基于DashAI的可解释性模块，并将其应用于表格分类任务中。该模块结合了部分依赖图、排列特征重要性和核SHAP三种技术。通过一项包含20名参与者（包括初学者和专家）的研究，评估了这些解释方法的有效性。", "result": "实验结果显示：(i)所有可解释性任务的完成度均超过80%；(ii) 初学者认为解释有用、准确且可信，而专家则对信息充分性和完整性提出了更高要求；(iii) 解释提高了自动化预测的信任度和信心，初学者表现出了更高的信任水平。", "conclusion": "研究发现，在无代码机器学习中实现XAI是一个挑战。需要找到一种方法，既能使解释易于初学者理解，又能满足专家的需求。"}}
{"id": "2602.11158", "pdf": "https://arxiv.org/pdf/2602.11158", "abs": "https://arxiv.org/abs/2602.11158", "authors": ["Juliana Gerard", "Morgan Macleod", "Kelly Norwood", "Aisling Reid", "Muskaan Singh"], "title": "Methodological Variation in Studying Staff and Student Perceptions of AI", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "29 pages, 3 figures", "summary": "In this paper, we compare methodological approaches for comparing student and staff perceptions, and ask: how much do these measures vary across different approaches? We focus on the case of AI perceptions, which are generally assessed via a single quantitative or qualitative measure, or with a mixed methods approach that compares two distinct data sources - e.g. a quantitative questionnaire with qualitative comments. To compare different approaches, we collect two forms of qualitative data: standalone comments and structured focus groups. We conduct two analyses for each data source: with a sentiment and stance analysis, we measure overall negativity/positivity of the comments and focus group conversations, respectively. Meanwhile, word clouds from the comments and a thematic analysis of the focus groups provide further detail on the content of this qualitative data - particularly the thematic analysis, which includes both similarities and differences between students and staff. We show that different analyses can produce different results - for a single data source. This variation stems from the construct being evaluated - an overall measure of positivity/negativity can produce a different picture from more detailed content-based analyses. We discuss the implications of this variation for institutional contexts, and for the comparisons from previous studies.", "AI": {"tldr": "本文比较了不同方法对师生关于人工智能感知的看法，探讨这些测量在不同类型方法中的差异。", "motivation": "研究旨在探索不同评估方法对学生和员工关于AI感知的调查结果的影响，并揭示这些影响对于机构环境的意义以及先前研究所作比较的有效性。", "method": "收集两种形式的定性数据：独立评论与结构化焦点小组。对每个数据源进行两次分析，分别通过情感分析测量整体负面/正面情绪，同时生成词云并开展主题分析以提供更详细的内容信息。", "result": "展示不同分析方法在单一数据源中可产生不同的结果，并指出这种差异源于所评估的构建物——总体的情绪衡量可能与基于内容的具体分析呈现出截然不同的画面。", "conclusion": "讨论了此变异对于机构环境的意义以及先前研究所作比较的有效性，强调了多角度考量的重要性。"}}
{"id": "2602.11156", "pdf": "https://arxiv.org/pdf/2602.11156", "abs": "https://arxiv.org/abs/2602.11156", "authors": ["Sungmoon Kim", "Hyuna Jeon", "Dahye Kim", "Mingyu Kim", "Dong-Kyu Chae", "Jiwoong Kim"], "title": "HybridRAG: A Practical LLM-based ChatBot Framework based on Pre-Generated Q&A over Raw Unstructured Documents", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for grounding Large Language Model (LLM)-based chatbot responses on external knowledge. However, existing RAG studies typically assume well-structured textual sources (e.g. Wikipedia or curated datasets) and perform retrieval and generation at query time, which can limit their applicability in real-world chatbot scenarios. In this paper, we present HybridRAG, a novel and practical RAG framework towards more accurate and faster chatbot responses. First, HybridRAG ingests raw, unstructured PDF documents containing complex layouts (text, tables, figures) via Optical Character Recognition (OCR) and layout analysis, and convert them into hierarchical text chunks. Then, it pre-generates a plausible question-answer (QA) knowledge base from the organized chunks using an LLM. At query time, user questions are matched against this QA bank to retrieve immediate answers when possible, and only if no suitable QA match is found does our framework fall back to an on-the-fly response generation. Experiments on OHRBench demonstrate that our HybridRAG provides higher answer quality and lower latency compared to a standard RAG baseline. We believe that HybridRAG could be a practical solution for real-world chatbot applications that must handle large volumes of unstructured documents and lots of users under limited computational resources.", "AI": {"tldr": "提出了一种基于LLM的聊天机器人框架HybridRAG，用于处理原始未结构化的文档以提高响应质量和速度。", "motivation": "现有RAG方法依赖于已整理的知识库，限制了其在实际场景中的应用。为了应对大规模未结构化文档和大量用户的挑战，在有限资源下提供高效解决方案。", "method": "通过OCR和布局分析将原始PDF文档转换为层次文本片段；使用LLM从这些片段生成预设的问答知识库；查询时优先匹配问答库，找不到匹配则进行实时响应生成。", "result": "在OHRBench上的实验表明HybridRAG比标准RAG基线具有更高的答案质量和更低的延迟。", "conclusion": "认为HybridRAG可以作为处理大量未结构化文档和用户的实际聊天机器人应用的实用解决方案。"}}
{"id": "2602.11154", "pdf": "https://arxiv.org/pdf/2602.11154", "abs": "https://arxiv.org/abs/2602.11154", "authors": ["Yue Gao", "Hong-Xing Yu", "Sanghyeon Chang", "Qianxi Fu", "Bo Zhu", "Yoonjin Won", "Juan Carlos Niebles", "Jiajun Wu"], "title": "SurfPhase: 3D Interfacial Dynamics in Two-Phase Flows from Sparse Videos", "categories": ["cs.CV"], "comment": "The first two authors contributed equally. Project website: https://yuegao.me/SurfPhase", "summary": "Interfacial dynamics in two-phase flows govern momentum, heat, and mass transfer, yet remain difficult to measure experimentally. Classical techniques face intrinsic limitations near moving interfaces, while existing neural rendering methods target single-phase flows with diffuse boundaries and cannot handle sharp, deformable liquid-vapor interfaces. We propose SurfPhase, a novel model for reconstructing 3D interfacial dynamics from sparse camera views. Our approach integrates dynamic Gaussian surfels with a signed distance function formulation for geometric consistency, and leverages a video diffusion model to synthesize novel-view videos to refine reconstruction from sparse observations. We evaluate on a new dataset of high-speed pool boiling videos, demonstrating high-quality view synthesis and velocity estimation from only two camera views. Project website: https://yuegao.me/SurfPhase.", "AI": {"tldr": "提出了SurfPhase模型，用于从稀疏视频中重建两相流的三维界面动力学。", "motivation": "现有的实验技术在测量接近移动边界的两相流动时存在固有限制；神经渲染方法主要针对单相流且难以处理尖锐、可变形的液气界面。", "method": "SurfPhase结合动态高斯光球和符号距离函数以确保几何一致性，并使用视频扩散模型从稀疏视图中生成新的视角视频来优化重建。", "result": "在高速池沸腾视频数据集上验证了高质量的新视角合成及速度估计，仅通过两个摄像头即可实现。", "conclusion": "SurfPhase能够有效地从稀疏的摄像机视图中重建两相流的三维界面动力学。"}}
{"id": "2602.11150", "pdf": "https://arxiv.org/pdf/2602.11150", "abs": "https://arxiv.org/abs/2602.11150", "authors": ["Manan H Anjaria", "Mehmet Enes Erciyes", "Vedant Ghatnekar", "Neha Navarkar", "Haritheja Etukuru", "Xiaole Jiang", "Kanad Patel", "Dhawal Kabra", "Nicholas Wojno", "Radhika Ajay Prayage", "Soumith Chintala", "Lerrel Pinto", "Nur Muhammad Mahi Shafiullah", "Zichen Jeff Cui"], "title": "YOR: Your Own Mobile Manipulator for Generalizable Robotics", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Recent advances in robot learning have generated significant interest in capable platforms that may eventually approach human-level competence. This interest, combined with the commoditization of actuators, has propelled growth in low-cost robotic platforms. However, the optimal form factor for mobile manipulation, especially on a budget, remains an open question. We introduce YOR, an open-source, low-cost mobile manipulator that integrates an omnidirectional base, a telescopic vertical lift, and two arms with grippers to achieve whole-body mobility and manipulation. Our design emphasizes modularity, ease of assembly using off-the-shelf components, and affordability, with a bill-of-materials cost under 10,000 USD. We demonstrate YOR's capability by completing tasks that require coordinated whole-body control, bimanual manipulation, and autonomous navigation. Overall, YOR offers competitive functionality for mobile manipulation research at a fraction of the cost of existing platforms. Project website: https://www.yourownrobot.ai/", "AI": {"tldr": "介绍了一种低成本、模块化设计的移动操作机器人YOR，适用于通用性机器人研究。", "motivation": "当前机器人学习的进步推动了对高性能平台的需求，并且随着执行器的成本降低，低预算下的理想移动操纵形式因素仍然存在疑问。因此，作者提出了一个开放源代码、低成本、集成全向底座和伸缩垂直提升装置的移动操作机器人YOR。", "method": "设计了一种模块化结构，使用现成组件组装，并在10,000美元预算下实现了全身体控制、双臂协同操纵和自主导航任务能力。", "result": "展示了YOR完成需要协调全身控制、双臂协同操作及自主导航的任务的能力，证明了其作为移动操作研究平台的竞争力。", "conclusion": "YOR提供了与现有平台相比具有成本效益的功能性，适用于通用机器人研究。"}}
{"id": "2602.11146", "pdf": "https://arxiv.org/pdf/2602.11146", "abs": "https://arxiv.org/abs/2602.11146", "authors": ["Gongye Liu", "Bo Yang", "Yida Zhi", "Zhizhou Zhong", "Lei Ke", "Didan Deng", "Han Gao", "Yongxiang Huang", "Kaihao Zhang", "Hongbo Fu", "Wenhan Luo"], "title": "Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling", "categories": ["cs.CV", "cs.AI"], "comment": "Code: https://github.com/HKUST-C4G/diffusion-rm", "summary": "Preference optimization for diffusion and flow-matching models relies on reward functions that are both discriminatively robust and computationally efficient. Vision-Language Models (VLMs) have emerged as the primary reward provider, leveraging their rich multimodal priors to guide alignment. However, their computation and memory cost can be substantial, and optimizing a latent diffusion generator through a pixel-space reward introduces a domain mismatch that complicates alignment. In this paper, we propose DiNa-LRM, a diffusion-native latent reward model that formulates preference learning directly on noisy diffusion states. Our method introduces a noise-calibrated Thurstone likelihood with diffusion-noise-dependent uncertainty. DiNa-LRM leverages a pretrained latent diffusion backbone with a timestep-conditioned reward head, and supports inference-time noise ensembling, providing a diffusion-native mechanism for test-time scaling and robust rewarding. Across image alignment benchmarks, DiNa-LRM substantially outperforms existing diffusion-based reward baselines and achieves performance competitive with state-of-the-art VLMs at a fraction of the computational cost. In preference optimization, we demonstrate that DiNa-LRM improves preference optimization dynamics, enabling faster and more resource-efficient model alignment.", "AI": {"tldr": "提出了一种新的基于扩散的潜在奖励模型DiNa-LRM，用于改进偏好优化任务。", "motivation": "现有的基于视觉-语言模型（VLM）的奖励函数计算和内存成本高，并且存在领域不匹配的问题。因此需要一种更高效、更适合的方法来解决这些问题。", "method": "提出了DiNa-LRM方法，它直接在扩散状态上的噪声校准Thurstone似然度进行偏好学习，支持推理时的噪声集成，提供了一个适合测试时间尺度和健壮奖励机制。", "result": "实验结果表明，DiNa-LRM在图像对齐基准上大幅超越了现有的基于扩散的奖励基线，并且以更低的成本达到了与视觉-语言模型相当的表现。此外，在偏好优化方面也表现出更快、更资源高效的行为。", "conclusion": "DiNa-LRM提供了一种新的方法来解决现有基于扩散和流匹配模型中的偏好优化问题，证明了其在多个方面的优越性。"}}
{"id": "2602.11145", "pdf": "https://arxiv.org/pdf/2602.11145", "abs": "https://arxiv.org/abs/2602.11145", "authors": ["Christopher Mitcheltree", "Vincent Lostanlen", "Emmanouil Benetos", "Mathieu Lagrange"], "title": "SCRAPL: Scattering Transform with Random Paths for Machine Learning", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "Accepted to ICLR 2026. Code, audio samples, and Python package provided at https://christhetree.github.io/scrapl/", "summary": "The Euclidean distance between wavelet scattering transform coefficients (known as paths) provides informative gradients for perceptual quality assessment of deep inverse problems in computer vision, speech, and audio processing. However, these transforms are computationally expensive when employed as differentiable loss functions for stochastic gradient descent due to their numerous paths, which significantly limits their use in neural network training. Against this problem, we propose \"Scattering transform with Random Paths for machine Learning\" (SCRAPL): a stochastic optimization scheme for efficient evaluation of multivariable scattering transforms. We implement SCRAPL for the joint time-frequency scattering transform (JTFS) which demodulates spectrotemporal patterns at multiple scales and rates, allowing a fine characterization of intermittent auditory textures. We apply SCRAPL to differentiable digital signal processing (DDSP), specifically, unsupervised sound matching of a granular synthesizer and the Roland TR-808 drum machine. We also propose an initialization heuristic based on importance sampling, which adapts SCRAPL to the perceptual content of the dataset, improving neural network convergence and evaluation performance. We make our code and audio samples available and provide SCRAPL as a Python package.", "AI": {"tldr": "提出了一种新的随机路径散射变换方法（SCRAPL），用于有效评估多变量散射变换，并应用于无监督音频匹配任务。", "motivation": "现有的欧几里得距离计算波浪散射变换系数的梯度对于深度逆问题感知质量评价来说是有效的，但其高时间复杂性使得难以作为神经网络训练中的可微分损失函数使用。为解决此问题提出了SCRAPL方法以提高效率。", "method": "提出了一种新的随机路径散射变换（SCRAPL）优化方案，用于有效评估多变量散射变换，并应用到无监督数字信号处理任务中。", "result": "通过在不同音频数据集上验证该算法的有效性，证明了SCARP方法能够提高神经网络训练的收敛速度和评价性能。", "conclusion": "SCRAPL作为一个高效的优化方案，在不牺牲准确性的情况下提高了计算效率，并应用于无监督声音匹配任务中展示出了良好的效果。"}}
{"id": "2602.11144", "pdf": "https://arxiv.org/pdf/2602.11144", "abs": "https://arxiv.org/abs/2602.11144", "authors": ["Ruichuan An", "Sihan Yang", "Ziyu Guo", "Wei Dai", "Zijun Shen", "Haodong Li", "Renrui Zhang", "Xinyu Wei", "Guopeng Li", "Wenshan Wu", "Wentao Zhang"], "title": "GENIUS: Generative Fluid Intelligence Evaluation Suite", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Unified Multimodal Models (UMMs) have shown remarkable progress in visual generation. Yet, existing benchmarks predominantly assess $\\textit{Crystallized Intelligence}$, which relies on recalling accumulated knowledge and learned schemas. This focus overlooks $\\textit{Generative Fluid Intelligence (GFI)}$: the capacity to induce patterns, reason through constraints, and adapt to novel scenarios on the fly. To rigorously assess this capability, we introduce $\\textbf{GENIUS}$ ($\\textbf{GEN}$ Fluid $\\textbf{I}$ntelligence Eval$\\textbf{U}$ation $\\textbf{S}$uite). We formalize $\\textit{GFI}$ as a synthesis of three primitives. These include $\\textit{Inducing Implicit Patterns}$ (e.g., inferring personalized visual preferences), $\\textit{Executing Ad-hoc Constraints}$ (e.g., visualizing abstract metaphors), and $\\textit{Adapting to Contextual Knowledge}$ (e.g., simulating counter-intuitive physics). Collectively, these primitives challenge models to solve problems grounded entirely in the immediate context. Our systematic evaluation of 12 representative models reveals significant performance deficits in these tasks. Crucially, our diagnostic analysis disentangles these failure modes. It demonstrates that deficits stem from limited context comprehension rather than insufficient intrinsic generative capability. To bridge this gap, we propose a training-free attention intervention strategy. Ultimately, $\\textbf{GENIUS}$ establishes a rigorous standard for $\\textit{GFI}$, guiding the field beyond knowledge utilization toward dynamic, general-purpose reasoning. Our dataset and code will be released at: $\\href{https://github.com/arctanxarc/GENIUS}{https://github.com/arctanxarc/GENIUS}$.", "AI": {"tldr": "GENIUS是一个评估生成流体智能（GFI）的基准测试，用于检测模型在视觉生成任务中的适应能力、推理能力和模式识别能力。", "motivation": "当前大多数基准主要评估的是晶体智力（已积累的知识和学习的模式），忽略了生成流体智能。因此，作者提出了一个新标准来衡量模型的动态和通用推理能力。", "method": "GENIUS通过引入三种核心任务形式化了GFI：隐式模式诱导、即时约束执行和上下文适应，并且对12个代表性的模型进行了系统评估，分析它们在这些任务上的表现。此外还提出了一种无需训练的注意力干预策略来改善模型的表现。", "result": "通过GENIUS基准测试发现现有模型在GFI相关的任务中表现出明显的性能不足，这些缺陷主要来自于有限的上下文理解能力而不是生成能力的缺乏。", "conclusion": "GENIUS建立了评估生成流体智能的新标准，并强调了未来研究应关注模型动态、通用推理能力的发展。"}}
{"id": "2602.11143", "pdf": "https://arxiv.org/pdf/2602.11143", "abs": "https://arxiv.org/abs/2602.11143", "authors": ["Yikai Wang", "Tingxuan Leng", "Changyi Lin", "Shiqi Liu", "Shir Simon", "Bingqing Chen", "Jonathan Francis", "Ding Zhao"], "title": "APEX: Learning Adaptive High-Platform Traversal for Humanoid Robots", "categories": ["cs.RO"], "comment": "Project Website: https://apex-humanoid.github.io/", "summary": "Humanoid locomotion has advanced rapidly with deep reinforcement learning (DRL), enabling robust feet-based traversal over uneven terrain. Yet platforms beyond leg length remain largely out of reach because current RL training paradigms often converge to jumping-like solutions that are high-impact, torque-limited, and unsafe for real-world deployment. To address this gap, we propose APEX, a system for perceptive, climbing-based high-platform traversal that composes terrain-conditioned behaviors: climb-up and climb-down at vertical edges, walking or crawling on the platform, and stand-up and lie-down for posture reconfiguration. Central to our approach is a generalized ratchet progress reward for learning contact-rich, goal-reaching maneuvers. It tracks the best-so-far task progress and penalizes non-improving steps, providing dense yet velocity-free supervision that enables efficient exploration under strong safety regularization. Based on this formulation, we train LiDAR-based full-body maneuver policies and reduce the sim-to-real perception gap through a dual strategy: modeling mapping artifacts during training and applying filtering and inpainting to elevation maps during deployment. Finally, we distill all six skills into a single policy that autonomously selects behaviors and transitions based on local geometry and commands. Experiments on a 29-DoF Unitree G1 humanoid demonstrate zero-shot sim-to-real traversal of 0.8 meter platforms (approximately 114% of leg length), with robust adaptation to platform height and initial pose, as well as smooth and stable multi-skill transitions.", "AI": {"tldr": "本论文提出了APEX系统，用于人形机器人在越过腿部长度的平台时的学习适应性攀爬。", "motivation": "当前强化学习训练范式趋向于跳跃式的解决方案，这种方式对现实世界的部署来说是高冲击力、扭矩限制且不安全。为此，本文提出了一种基于感知和攀爬的人形机器人高空平台穿越方法，以填补这一空白。", "method": "本文采用一种泛化的棘轮进展奖励机制来学习接触密集型的目标达到动作，并结合激光雷达进行全身体态策略训练及缩小仿真到现实的感知差距。通过这些技术，实现了六项技能的一体化和自动行为选择与转换。", "result": "在29自由度的Unitree G1人形机器人上实验表明，该系统可以实现0.8米平台（约为腿部长度的114%）上的零样本仿真到现实穿越，并具有对平台高度及初始姿态的强大适应性。", "conclusion": "APEX通过学习接触密集型目标达到动作和基于激光雷达的全身体态策略训练，实现了人形机器人在高空平台上的稳健穿越。"}}
{"id": "2602.11142", "pdf": "https://arxiv.org/pdf/2602.11142", "abs": "https://arxiv.org/abs/2602.11142", "authors": ["Shaswat Garg", "Matin Moezzi", "Brandon Da Silva"], "title": "Data-Efficient Hierarchical Goal-Conditioned Reinforcement Learning via Normalizing Flows", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "9 pages, 3 figures, IEEE International Conference on Robotics and Automation 2026", "summary": "Hierarchical goal-conditioned reinforcement learning (H-GCRL) provides a powerful framework for tackling complex, long-horizon tasks by decomposing them into structured subgoals. However, its practical adoption is hindered by poor data efficiency and limited policy expressivity, especially in offline or data-scarce regimes. In this work, Normalizing flow-based hierarchical implicit Q-learning (NF-HIQL), a novel framework that replaces unimodal gaussian policies with expressive normalizing flow policies at both the high- and low-levels of the hierarchy is introduced. This design enables tractable log-likelihood computation, efficient sampling, and the ability to model rich multimodal behaviors. New theoretical guarantees are derived, including explicit KL-divergence bounds for Real-valued non-volume preserving (RealNVP) policies and PAC-style sample efficiency results, showing that NF-HIQL preserves stability while improving generalization. Empirically, NF-HIQL is evaluted across diverse long-horizon tasks in locomotion, ball-dribbling, and multi-step manipulation from OGBench. NF-HIQL consistently outperforms prior goal-conditioned and hierarchical baselines, demonstrating superior robustness under limited data and highlighting the potential of flow-based architectures for scalable, data-efficient hierarchical reinforcement learning.", "AI": {"tldr": "引入基于正则流的分层隐式Q学习框架（NF-HIQL）以提高数据效率和策略表达性，解决复杂任务。", "motivation": "现有层次化目标导向强化学习方法在数据稀缺或离线环境中表现不佳且策略表达能力有限。", "method": "使用正则流替代高斯策略，在分层结构的高层与低层均采用多模态行为建模，并提供理论保证如KL散度界限和样本效率结果，表明NF-HIQL具有稳定性并提高泛化能力。", "result": "在多个长时任务上，NF-HIQL优于现有目标导向及层次化基线方法，特别是在数据受限情况下的表现更优。", "conclusion": "NF-HIQL展示了正则流架构在可扩展和数据高效分层强化学习中的潜力。"}}
{"id": "2602.11141", "pdf": "https://arxiv.org/pdf/2602.11141", "abs": "https://arxiv.org/abs/2602.11141", "authors": ["Yu Wang", "Frederik L. Dennig", "Michael Behrisch", "Alexandru Telea"], "title": "LCIP: Loss-Controlled Inverse Projection of High-Dimensional Image Data", "categories": ["cs.HC", "cs.LG"], "comment": null, "summary": "Projections (or dimensionality reduction) methods $P$ aim to map high-dimensional data to typically 2D scatterplots for visual exploration. Inverse projection methods $P^{-1}$ aim to map this 2D space to the data space to support tasks such as data augmentation, classifier analysis, and data imputation. Current $P^{-1}$ methods suffer from a fundamental limitation -- they can only generate a fixed surface-like structure in data space, which poorly covers the richness of this space. We address this by a new method that can `sweep' the data space under user control. Our method works generically for any $P$ technique and dataset, is controlled by two intuitive user-set parameters, and is simple to implement. We demonstrate it by an extensive application involving image manipulation for style transfer.", "AI": {"tldr": "本文提出了一种新的逆投影方法，可以由用户控制来扫掠高维数据空间。", "motivation": "现有的逆投影方法只能生成固定的数据结构，无法充分覆盖高维数据的复杂性。因此需要一种更灵活的方法来更好地支持任务如数据增强、分类器分析和数据插补等。", "method": "通过用户控制参数，提出了一种新的逆投影技术，可以在任意维度数据集上通用地工作，并且可以实现简单。", "result": "实验表明该方法在图像风格迁移中具有广泛的应用效果。", "conclusion": "新方法能够更好地覆盖高维空间的数据分布，提供更加丰富的结果，并支持多种应用任务。"}}
{"id": "2602.11137", "pdf": "https://arxiv.org/pdf/2602.11137", "abs": "https://arxiv.org/abs/2602.11137", "authors": ["Tessa Han", "Sebastian Bordt", "Hanlin Zhang", "Sham Kakade"], "title": "Weight Decay Improves Language Model Plasticity", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The prevailing paradigm in large language model (LLM) development is to pretrain a base model, then perform further training to improve performance and model behavior. However, hyperparameter optimization and scaling laws have been studied primarily from the perspective of the base model's validation loss, ignoring downstream adaptability. In this work, we study pretraining from the perspective of model plasticity, that is, the ability of the base model to successfully adapt to downstream tasks through fine-tuning. We focus on the role of weight decay, a key regularization parameter during pretraining. Through systematic experiments, we show that models trained with larger weight decay values are more plastic, meaning they show larger performance gains when fine-tuned on downstream tasks. This phenomenon can lead to counterintuitive trade-offs where base models that perform worse after pretraining can perform better after fine-tuning. Further investigation of weight decay's mechanistic effects on model behavior reveals that it encourages linearly separable representations, regularizes attention matrices, and reduces overfitting on the training data. In conclusion, this work demonstrates the importance of using evaluation metrics beyond cross-entropy loss for hyperparameter optimization and casts light on the multifaceted role of that a single optimization hyperparameter plays in shaping model behavior.", "AI": {"tldr": "研究了权重衰减对语言模型适应性的改进作用。", "motivation": "探索预训练阶段的超参数调整如何影响下游任务中的模型可塑性，而不仅仅是基础模型验证损失的优化。", "method": "通过系统实验研究不同的权重衰减值在预训练中对模型性能的影响，并分析其机制效果。", "result": "发现较大的权重衰减值可以提高模型的适应性，导致更好的下游任务表现。同时揭示了权重衰减如何影响模型表示、注意矩阵和过拟合情况。", "conclusion": "表明除了交叉熵损失之外，应使用更多的评价指标进行超参数优化，并阐明了一个单一优化参数在塑造模型行为中的多重作用。"}}
{"id": "2602.11136", "pdf": "https://arxiv.org/pdf/2602.11136", "abs": "https://arxiv.org/abs/2602.11136", "authors": ["Jiayi Zhou", "Yang Sheng", "Hantao Lou", "Yaodong Yang", "Jie Fu"], "title": "FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight", "categories": ["cs.AI"], "comment": "27 pages", "summary": "As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems without inheriting their failure modes? We argue that formal verification offers a principled escape from this dilemma, yet its adoption has been hindered by a critical bottleneck: the translation from natural language requirements to formal specifications. This paper bridges this gap by proposing , a neuro-symbolic framework that employs a bidirectional Formal-of-Thought architecture: LLMs serve as specification compilers that top-down decompose high-level human intent into atomic, verifiable constraints, then bottom-up prove compliance using Dafny specifications and Z3 Satisfiability modulo theories solving, which produces mathematical guarantees rather than probabilistic scores. We validate across three benchmarks spanning behavioral safety, multi-domain constraint adherence, and agentic upward deception detection. Experiments on 7 agent models demonstrate that achieves an average improvement of 16.6% over LLM-as-a-Judge baselines, enables weak-to-strong generalization where a 7B judge achieves over 90% accuracy detecting deception from 72B agents, and provides near-linear safety improvement through iterative refinement.", "AI": {"tldr": "本文提出了一种神经符号框架 FormalJudge，用于评估LLM代理的行为安全性。", "motivation": "随着基于LLM的代理在高风险领域中的广泛应用，确保它们的行为安全变得至关重要。现有的监督模式面临困境：如何可靠地监督其他具有概率性的系统而不继承其失效模式？", "method": "本文提出了一种神经符号框架 FormalJudge，该框架利用双向形式化思想架构，将LLM用作规范编译器，自上而下分解高层次的人类意图为原子的可验证约束，并通过 Dafny 规格和 Z3 满足性理论求解器自底向上证明合规性。", "result": "实验结果显示，在7个代理模型中，FormalJudge 平均比 LLM-as-a-Judge 基线提高了16.6%的性能。此外，该框架还实现了从弱到强泛化的功能，并且通过迭代精炼提供了近乎线性的安全性改进。", "conclusion": "本文提出的 FormalJudge 框架解决了现有监督模式面临的挑战，为确保LLM代理的行为安全提供了一种新的方法论支持。"}}
{"id": "2602.11130", "pdf": "https://arxiv.org/pdf/2602.11130", "abs": "https://arxiv.org/abs/2602.11130", "authors": ["Maximilian Plattner", "Fabian Paischer", "Johannes Brandstetter", "Arturs Berzins"], "title": "From Circuits to Dynamics: Understanding and Stabilizing Failure in 3D Diffusion Transformers", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Reliable surface completion from sparse point clouds underpins many applications spanning content creation and robotics. While 3D diffusion transformers attain state-of-the-art results on this task, we uncover that they exhibit a catastrophic mode of failure: arbitrarily small on-surface perturbations to the input point cloud can fracture the output into multiple disconnected pieces -- a phenomenon we call Meltdown. Using activation-patching from mechanistic interpretability, we localize Meltdown to a single early denoising cross-attention activation. We find that the singular-value spectrum of this activation provides a scalar proxy: its spectral entropy rises when fragmentation occurs and returns to baseline when patched. Interpreted through diffusion dynamics, we show that this proxy tracks a symmetry-breaking bifurcation of the reverse process. Guided by this insight, we introduce PowerRemap, a test-time control that stabilizes sparse point-cloud conditioning. We demonstrate that Meltdown persists across state-of-the-art architectures (WaLa, Make-a-Shape), datasets (GSO, SimJEB) and denoising strategies (DDPM, DDIM), and that PowerRemap effectively counters this failure with stabilization rates of up to 98.3%. Overall, this work is a case study on how diffusion model behavior can be understood and guided based on mechanistic analysis, linking a circuit-level cross-attention mechanism to diffusion-dynamics accounts of trajectory bifurcations.", "AI": {"tldr": "本文研究了从稀疏点云完成三维表面时，扩散变形器模型出现的失败模式，并通过机制性分析提出了一种测试时间控制方法来稳定这种条件。", "motivation": "在使用3D扩散变压器进行稀疏点云的可靠表面补全任务中发现了一个严重的失效模式：输入点云的小扰动会导致输出分解为多个不连接的部分。为了理解和解决这个问题，作者探索了机制性解释的方法，并希望通过这种方法来稳定模型的行为。", "method": "通过激活打补丁技术定位失败到早期去噪交叉注意力机制的单一激活上。发现该激活的奇异值光谱熵在出现片段化时上升，在修正后恢复正常。基于扩散动力学理论，提出了一种测试时间控制方法PowerRemap来稳定稀疏点云条件。", "result": "实验表明，这种失败模式存在于不同的模型架构、数据集和去噪策略中，并且通过使用PowerRemap可以有效解决该问题，稳定率高达98.3%。", "conclusion": "这项研究证明了基于机制性分析理解扩散模型行为的有效性，并展示了如何将电路层面的交叉注意力机制与扩散动力学理论联系起来以指导和稳定模型的行为。"}}
{"id": "2602.11125", "pdf": "https://arxiv.org/pdf/2602.11125", "abs": "https://arxiv.org/abs/2602.11125", "authors": ["Animesh Maiti", "Abhinav Chakraborty", "Bibhuti Das", "Subhash Bhagat", "Krishnendu Mukhopadhyaya"], "title": "Min-Sum Uniform Coverage Problem by Autonomous Mobile Robots", "categories": ["cs.DC", "cs.RO"], "comment": null, "summary": "We study the \\textit{min-sum uniform coverage} problem for a swarm of $n$ mobile robots on a given finite line segment and on a circle having finite positive radius, where the circle is given as an input. The robots must coordinate their movements to reach a uniformly spaced configuration that minimizes the total distance traveled by all robots. The robots are autonomous, anonymous, identical, and homogeneous, and operate under the \\textit{Look-Compute-Move} (LCM) model with \\textit{non-rigid} motion controlled by a fair asynchronous scheduler. They are oblivious and silent, possessing neither persistent memory nor a means of explicit communication. In the \\textbf{line-segment setting}, the \\textit{min-sum uniform coverage} problem requires placing the robots at uniformly spaced points along the segment so as to minimize the total distance traveled by all robots. In the \\textbf{circle setting} for this problem, the robots have to arrange themselves uniformly around the given circle to form a regular $n$-gon. There is no fixed orientation or designated starting vertex, and the goal is to minimize the total distance traveled by all the robots. We present a deterministic distributed algorithm that achieves uniform coverage in the line-segment setting with minimum total movement cost. For the circle setting, we characterize all initial configurations for which the \\textit{min-sum uniform coverage} problem is deterministically unsolvable under the considered robot model. For all the other remaining configurations, we provide a deterministic distributed algorithm that achieves uniform coverage while minimizing the total distance traveled. These results characterize the deterministic solvability of min-sum coverage for oblivious robots and achieve optimal cost whenever solvable.", "AI": {"tldr": "研究了由n个自主移动机器人组成的群在给定的有限线段和圆上实现均匀覆盖的问题，目标是最小化所有机器人的总行驶距离。", "motivation": "探讨如何通过协调移动来使机器人达到均匀分布的状态，并最小化总的行进距离。这有助于提高资源利用效率并优化任务执行。", "method": "提出了一种确定性的分布式算法，在线段设置中实现了均匀覆盖，同时在圆周设置中对于所有可解的情况也提供了实现均匀覆盖的最优成本算法。", "result": "在线段上成功实现了最小化总行进距离的同时达到均匀分布的目标。并且，在圆周上的特定初始配置下确定了问题是否可解，并为其他情况提供了优化解决方案。", "conclusion": "该论文的研究结果对于无记忆、无声的自主移动机器人在不同场景下的覆盖任务具有重要意义，展示了如何通过算法设计来最小化总行进距离并实现最佳分布。"}}
{"id": "2602.11124", "pdf": "https://arxiv.org/pdf/2602.11124", "abs": "https://arxiv.org/abs/2602.11124", "authors": ["Tianyi Xiong", "Shihao Wang", "Guilin Liu", "Yi Dong", "Ming Li", "Heng Huang", "Jan Kautz", "Zhiding Yu"], "title": "PhyCritic: Multimodal Critic Models for Physical AI", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid development of large multimodal models, reliable judge and critic models have become essential for open-ended evaluation and preference alignment, providing pairwise preferences, numerical scores, and explanatory justifications for assessing model-generated responses. However, existing critics are primarily trained in general visual domains such as captioning or image question answering, leaving physical AI tasks involving perception, causal reasoning, and planning largely underexplored. We introduce PhyCritic, a multimodal critic model optimized for physical AI through a two-stage RLVR pipeline: a physical skill warmup stage that enhances physically oriented perception and reasoning, followed by self-referential critic finetuning, where the critic generates its own prediction as an internal reference before judging candidate responses, improving judgment stability and physical correctness. Across both physical and general-purpose multimodal judge benchmarks, PhyCritic achieves strong performance gains over open-source baselines and, when applied as a policy model, further improves perception and reasoning in physically grounded tasks.", "AI": {"tldr": "本文介绍了PhyCritic，一种用于物理人工智能任务的多模态批评模型。", "motivation": "随着大型多模态模型的发展，可靠的判断和批评模型对于开放性评估和偏好对齐变得至关重要。然而现有批评模型主要针对一般的视觉领域，如图像描述或问答，而物理AI任务中的感知、因果推理和规划等领域尚未得到充分探索。", "method": "PhyCritic通过两阶段RLVR流程优化：第一个阶段是物理技能预热期，增强物理导向的感知和推理；第二个阶段是自我参照批评微调期，在此期间批评模型在其生成自己的预测作为内部参考之前评估候选响应，从而提高评判的稳定性和物理正确性。", "result": "在物理和通用多模态裁判基准上，PhyCritic的表现显著优于开源基线，并且当用作策略模型时，进一步提高了物理任务中感知与推理的能力。", "conclusion": "本文提出了PhyCritic，一个专为物理人工智能设计的多模态批评模型。在多个评估指标中，该模型都展示出了优越性，特别是在增强物理任务中的感知和推理能力方面取得了重要进展。"}}
{"id": "2602.11117", "pdf": "https://arxiv.org/pdf/2602.11117", "abs": "https://arxiv.org/abs/2602.11117", "authors": ["Di Chang", "Ji Hou", "Aljaz Bozic", "Assaf Neuberger", "Felix Juefei-Xu", "Olivier Maury", "Gene Wei-Chin Lin", "Tuur Stuyck", "Doug Roble", "Mohammad Soleymani", "Stephane Grabli"], "title": "HairWeaver: Few-Shot Photorealistic Hair Motion Synthesis with Sim-to-Real Guided Video Diffusion", "categories": ["cs.CV"], "comment": "Website: https://boese0601.github.io/hairweaver/", "summary": "We present HairWeaver, a diffusion-based pipeline that animates a single human image with realistic and expressive hair dynamics. While existing methods successfully control body pose, they lack specific control over hair, and as a result, fail to capture the intricate hair motions, resulting in stiff and unrealistic animations. HairWeaver overcomes this limitation using two specialized modules: a Motion-Context-LoRA to integrate motion conditions and a Sim2Real-Domain-LoRA to preserve the subject's photoreal appearance across different data domains. These lightweight components are designed to guide a video diffusion backbone while maintaining its core generative capabilities. By training on a specialized dataset of dynamic human motion generated from a CG simulator, HairWeaver affords fine control over hair motion and ultimately learns to produce highly realistic hair that responds naturally to movement. Comprehensive evaluations demonstrate that our approach sets a new state of the art, producing lifelike human hair animations with dynamic details.", "AI": {"tldr": "HairWeaver 是一种基于扩散的方法，用于对单个人类图像进行逼真的头发动态动画。", "motivation": "现有方法在控制人体姿态方面成功，但在特定的头发控制上却存在不足，导致无法捕捉复杂的头发运动，产生僵硬和不真实的动画。", "method": "HairWeaver 使用两个专门模块：Motion-Context-LoRA 和 Sim2Real-Domain-LoRA，以整合运动条件并保持主体在不同数据域中的光度真实外观。这些轻量级组件设计为引导视频扩散主干，同时保持其核心生成能力。", "result": "通过使用来自CG模拟器生成的动态人类动作的专业数据集进行训练，HairWeaver 具有对头发运动的精细控制，并最终学会产生高度逼真的响应自然移动的头发。综合评估表明我们的方法设定了新的最先进的水平，能够生成具有动态细节的真实感人类头发动画。", "conclusion": "HairWeaver 在生成真实感的人类头发动画方面表现出色，尤其是在处理复杂且细致的头发运动时。"}}
{"id": "2602.11116", "pdf": "https://arxiv.org/pdf/2602.11116", "abs": "https://arxiv.org/abs/2602.11116", "authors": ["Alfonso Sciacchitano", "Liraz Mudrik", "Sean Kragelund", "Isaac Kaminer"], "title": "Multi-UAV Trajectory Optimization for Bearing-Only Localization in GPS Denied Environments", "categories": ["eess.SY", "cs.RO", "math.OC"], "comment": "38 pages, 7 figure, and 6 tables", "summary": "Accurate localization of maritime targets by unmanned aerial vehicles (UAVs) remains challenging in GPS-denied environments. UAVs equipped with gimballed electro-optical sensors are typically used to localize targets, however, reliance on these sensors increases mechanical complexity, cost, and susceptibility to single-point failures, limiting scalability and robustness in multi-UAV operations. This work presents a new trajectory optimization framework that enables cooperative target localization using UAVs with fixed, non-gimballed cameras operating in coordination with a surface vessel. This estimation-aware optimization generates dynamically feasible trajectories that explicitly account for mission constraints, platform dynamics, and out-of-frame events. Estimation-aware trajectories outperform heuristic paths by reducing localization error by more than a factor of two, motivating their use in cooperative operations. Results further demonstrate that coordinated UAVs with fixed, non-gimballed cameras achieve localization accuracy that meets or exceeds that of single gimballed systems, while substantially lowering system complexity and cost, enabling scalability, and enhancing mission resilience.", "AI": {"tldr": "该论文提出了一种新的轨迹优化框架，以实现GPS受限环境下的无人飞行器协同目标定位。", "motivation": "在没有GPS的环境中通过无人飞行器（UAV）进行准确的目标定位仍然具有挑战性。传统的依靠带有云台电光学传感器的UAV增加了机械复杂性和成本，并且容易出现单点故障，这限制了多UAV操作中的可扩展性和鲁棒性。", "method": "该论文提出了一种新的轨迹优化框架，在此框架中，装备固定非云台摄像头的UAV与水面船只协同工作以定位目标。这种估计意识的优化生成符合任务约束、平台动力学和出框事件动态可行性路径。", "result": "结果表明，通过使用估计意识的路线比传统的启发式路径减少了超过两倍的目标定位误差，并且在固定非云台摄像头的UAV之间进行协调可以实现与单个带有云台系统的精度相等甚至更高的目标定位准确性。", "conclusion": "该论文所提出的解决方案不仅降低了系统的复杂性和成本，还提高了多无人飞行器操作中的可扩展性以及任务韧性。"}}
{"id": "2602.11114", "pdf": "https://arxiv.org/pdf/2602.11114", "abs": "https://arxiv.org/abs/2602.11114", "authors": ["Jialiang Wang", "Shengxiang Xu", "Hanmo Liu", "Jiachuan Wang", "Yuyu Luo", "Shimin Di", "Min-Ling Zhang", "Lei Chen"], "title": "Learning to Compose for Cross-domain Agentic Workflow Generation", "categories": ["cs.MA", "cs.AI", "cs.LG", "cs.SE"], "comment": null, "summary": "Automatically generating agentic workflows -- executable operator graphs or codes that orchestrate reasoning, verification, and repair -- has become a practical way to solve complex tasks beyond what single-pass LLM generation can reliably handle. Yet what constitutes a good workflow depends heavily on the task distribution and the available operators. Under domain shift, current systems typically rely on iterative workflow refinement to discover a feasible workflow from a large workflow space, incurring high iteration costs and yielding unstable, domain-specific behavior. In response, we internalize a decompose-recompose-decide mechanism into an open-source LLM for cross-domain workflow generation. To decompose, we learn a compact set of reusable workflow capabilities across diverse domains. To recompose, we map each input task to a sparse composition over these bases to generate a task-specific workflow in a single pass. To decide, we attribute the success or failure of workflow generation to counterfactual contributions from learned capabilities, thereby capturing which capabilities actually drive success by their marginal effects. Across stringent multi-domain, cross-domain, and unseen-domain evaluations, our 1-pass generator surpasses SOTA refinement baselines that consume 20 iterations, while substantially reducing generation latency and cost.", "AI": {"tldr": "论文提出了一种基于LLM的跨领域工作流生成方法，通过学习可重用的工作流能力来自动构建高效、适应性强的工作流。", "motivation": "当前系统在跨域任务中通常需要迭代优化来发现可行的工作流，这导致了高成本和不稳定的行为。论文旨在减少迭代次数并提高工作效率。", "method": "提出了一种基于LLM的分解-重组-决策机制：首先学习可重用的工作流能力；然后将输入任务映射为这些基础工作流的稀疏组合生成特定于任务的工作流；最后通过反事实贡献来归因成功或失败，以捕捉驱动成功的因素。", "result": "论文方法在多领域、跨域和未见过领域的严格评估中优于消耗20次迭代的最佳现有技术基线，并显著减少了生成延迟和成本。", "conclusion": "新方法能够在一个步骤内自动生成适应性强的工作流，大幅降低了生成时间和成本，展示了其优越性。"}}
{"id": "2602.11113", "pdf": "https://arxiv.org/pdf/2602.11113", "abs": "https://arxiv.org/abs/2602.11113", "authors": ["Daniel S. J. Derwent", "Simon Watson", "Bruno V. Adorno"], "title": "A receding-horizon multi-contact motion planner for legged robots in challenging environments", "categories": ["cs.RO"], "comment": "Submitted to Robotics and Autonomous Systems For supplementary video, see https://www.youtube.com/watch?v=RJp8DCmhDa4", "summary": "We present a novel receding-horizon multi-contact motion planner for legged robots in challenging scenarios, able to plan motions such as chimney climbing, navigating very narrow passages or crossing large gaps. Our approach adds new capabilities to the state of the art, including the ability to reactively re-plan in response to new information, and planning contact locations and whole-body trajectories simultaneously, simplifying the implementation and removing the need for post-processing or complex multi-stage approaches. Our method is more resistant to local minima problems than other potential field based approaches, and our quadratic-program-based posture generator returns nodes more quickly than those of existing algorithms. Rigorous statistical analysis shows that, with short planning horizons (e.g., one step ahead), our planner is faster than the state-of-the-art across all scenarios tested (between 45% and 98% faster on average, depending on the scenario), while planning less efficient motions (requiring 5% fewer to 700% more stance changes on average). In all but one scenario (Chimney Walking), longer planning horizons (e.g., four steps ahead) extended the average planning times (between 73% faster and 400% slower than the state-of-the-art) but resulted in higher quality motion plans (between 8% more and 47% fewer stance changes than the state-of-the-art).", "AI": {"tldr": "本文提出了一种新的基于退步地平线的多接触运动规划方法，适用于腿足机器人在挑战性环境中的运动规划。", "motivation": "为了提高腿足机器人在复杂环境下的适应性和灵活性，开发一种能够应对各种地形和障碍物的新方法。", "method": "该方法通过同时计划接触点和全身体态轨迹来简化实现过程，并且能够在面对新信息时做出反应性重规划。利用二次规划法生成姿势节点，提高了计算效率。", "result": "实验表明，在短时间规划情况下（例如一步预测），本文的规划器比现有技术快45%到98%，虽然运动效率略低；而长时间规划下（如四步预测）则能够提供更高质量的运动方案，但计划时间延长。", "conclusion": "该方法通过改进后的退步地平线多接触运动规划策略，在复杂环境中实现了高效的腿足机器人运动规划，并展示了其在实际应用中的潜力和优势。"}}
{"id": "2602.11105", "pdf": "https://arxiv.org/pdf/2602.11105", "abs": "https://arxiv.org/abs/2602.11105", "authors": ["Divya Jyoti Bajpai", "Dhruv Bhardwaj", "Soumya Roy", "Tejas Duseja", "Harsh Agarwal", "Aashay Sandansing", "Manjesh Kumar Hanawal"], "title": "FastFlow: Accelerating The Generative Flow Matching Models with Bandit Inference", "categories": ["cs.CV"], "comment": "Accepted at International Conference on Learning Representations (ICLR) 2026", "summary": "Flow-matching models deliver state-of-the-art fidelity in image and video generation, but the inherent sequential denoising process renders them slower. Existing acceleration methods like distillation, trajectory truncation, and consistency approaches are static, require retraining, and often fail to generalize across tasks. We propose FastFlow, a plug-and-play adaptive inference framework that accelerates generation in flow matching models. FastFlow identifies denoising steps that produce only minor adjustments to the denoising path and approximates them without using the full neural network models used for velocity predictions. The approximation utilizes finite-difference velocity estimates from prior predictions to efficiently extrapolate future states, enabling faster advancements along the denoising path at zero compute cost. This enables skipping computation at intermediary steps. We model the decision of how many steps to safely skip before requiring a full model computation as a multi-armed bandit problem. The bandit learns the optimal skips to balance speed with performance. FastFlow integrates seamlessly with existing pipelines and generalizes across image generation, video generation, and editing tasks. Experiments demonstrate a speedup of over 2.6x while maintaining high-quality outputs. The source code for this work can be found at https://github.com/Div290/FastFlow.", "AI": {"tldr": "FastFlow提出了一个自适应插件加速框架，用于流匹配模型的生成过程。", "motivation": "现有的加速方法如蒸馏、轨迹截断和一致性方法存在静态性问题，并需要重新训练且难以泛化到不同任务中。因此，提出一种能够动态调整并无需额外训练的新方案。", "method": "FastFlow通过使用有限差分速度估计来近似预测步骤的模型计算，以零成本高效地推算未来的状态；同时将决定何时跳过完整模型计算的过程建模为一个多臂老虎机问题。这种方法可以在保持高质量输出的同时加快生成过程。", "result": "实验结果表明，FastFlow能够在不牺牲质量的情况下实现超过2.6倍的速度提升，并且能够无缝集成到现有管道中并泛化至图像生成、视频生成和编辑任务。", "conclusion": "FastFlow提供了一种通用的方法来加速流匹配模型的生成过程，同时保持高质量输出，展示了其在多种任务中的有效性。"}}
{"id": "2602.11103", "pdf": "https://arxiv.org/pdf/2602.11103", "abs": "https://arxiv.org/abs/2602.11103", "authors": ["Wayne Chi", "Yixiong Fang", "Arnav Yayavaram", "Siddharth Yayavaram", "Seth Karten", "Qiuhong Anna Wei", "Runkun Chen", "Alexander Wang", "Valerie Chen", "Ameet Talwalkar", "Chris Donahue"], "title": "GameDevBench: Evaluating Agentic Capabilities Through Game Development", "categories": ["cs.AI", "cs.CL", "cs.SE"], "comment": null, "summary": "Despite rapid progress on coding agents, progress on their multimodal counterparts has lagged behind. A key challenge is the scarcity of evaluation testbeds that combine the complexity of software development with the need for deep multimodal understanding. Game development provides such a testbed as agents must navigate large, dense codebases while manipulating intrinsically multimodal assets such as shaders, sprites, and animations within a visual game scene. We present GameDevBench, the first benchmark for evaluating agents on game development tasks. GameDevBench consists of 132 tasks derived from web and video tutorials. Tasks require significant multimodal understanding and are complex -- the average solution requires over three times the amount of lines of code and file changes compared to prior software development benchmarks. Agents still struggle with game development, with the best agent solving only 54.5% of tasks. We find a strong correlation between perceived task difficulty and multimodal complexity, with success rates dropping from 46.9% on gameplay-oriented tasks to 31.6% on 2D graphics tasks. To improve multimodal capability, we introduce two simple image and video-based feedback mechanisms for agents. Despite their simplicity, these methods consistently improve performance, with the largest change being an increase in Claude Sonnet 4.5's performance from 33.3% to 47.7%. We release GameDevBench publicly to support further research into agentic game development.", "AI": {"tldr": "游戏开发基准(GameDevBench)用于评估代理在复杂多模态任务中的能力。", "motivation": "当前编码代理发展迅速，但它们的多模态理解能力相对滞后。缺乏结合软件开发复杂性和多模态需求的测试床是主要原因之一。", "method": "GameDevBench由132个从网络和视频教程中提取的任务组成，这些任务需要复杂的多模态理解和大量代码行及文件更改。引入了两种简单的基于图像和视频的反馈机制以提高代理的能力。", "result": "最好的代理只能解决54.5%的任务，游戏玩法任务的成功率为46.9%，而2D图形任务则为31.6%。简单反馈方法显著提高了性能，例如Claude Sonnet 4.5从33.3%提升至47.7%。", "conclusion": "GameDevBench作为一个公开的基准测试平台，将支持未来关于代理游戏开发的研究。"}}
{"id": "2602.11096", "pdf": "https://arxiv.org/pdf/2602.11096", "abs": "https://arxiv.org/abs/2602.11096", "authors": ["Soumya Suvra Ghosal", "Souradip Chakraborty", "Vaibhav Singh", "Furong Huang", "Dinesh Manocha", "Amrit Singh Bedi"], "title": "Safety Recovery in Reasoning Models Is Only a Few Early Steering Steps Away", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) based post-training for explicit chain-of-thought (e.g., GRPO) improves the reasoning ability of multimodal large-scale reasoning models (MLRMs). But recent evidence shows that it can simultaneously degrade safety alignment and increase jailbreak success rates. We propose SafeThink, a lightweight inference-time defense that treats safety recovery as a satisficing constraint rather than a maximization objective. SafeThink monitors the evolving reasoning trace with a safety reward model and conditionally injects an optimized short corrective prefix (\"Wait, think safely\") only when the safety threshold is violated. In our evaluations across six open-source MLRMs and four jailbreak benchmarks (JailbreakV-28K, Hades, FigStep, and MM-SafetyBench), SafeThink reduces attack success rates by 30-60% (e.g., LlamaV-o1: 63.33% to 5.74% on JailbreakV-28K, R1-Onevision: 69.07% to 5.65% on Hades) while preserving reasoning performance (MathVista accuracy: 65.20% to 65.00%). A key empirical finding from our experiments is that safety recovery is often only a few steering steps away: intervening in the first 1-3 reasoning steps typically suffices to redirect the full generation toward safe completions.", "AI": {"tldr": "提出了一种称为SafeThink的轻量级推理时防御方法，用于恢复多模态大规模推理模型的安全性。", "motivation": "基于强化学习（RL）后的训练可以提高显式思维链模型的推理能力，但同时也会降低安全对齐并增加逃逸成功的概率。因此需要一种能够保证安全性的同时不影响推理性能的方法。", "method": "SafeThink通过使用一个安全管理模型来监控不断发展的推理痕迹，并且在安全阈值被违反时插入一个最优化的短纠正前缀。", "result": "实验结果表明，SafeThink在减少攻击成功率方面表现出色（减少了30-60%），同时保持了推理性能。干预最初的1到3个推理步骤通常足以引导整个生成过程向安全完成转变。", "conclusion": "研究表明，通过少量的早期干预就可以恢复模型的安全性，并且这种方法可以在保证安全性的同时不影响推理能力。"}}
{"id": "2602.11090", "pdf": "https://arxiv.org/pdf/2602.11090", "abs": "https://arxiv.org/abs/2602.11090", "authors": ["Carlos Stein Brito"], "title": "Direct Learning of Calibration-Aware Uncertainty for Neural PDE Surrogates", "categories": ["cs.LG", "cs.AI", "cs.CE", "stat.CO"], "comment": "13 pages, 11 figures", "summary": "Neural PDE surrogates are often deployed in data-limited or partially observed regimes where downstream decisions depend on calibrated uncertainty in addition to low prediction error. Existing approaches obtain uncertainty through ensemble replication, fixed stochastic noise such as dropout, or post hoc calibration. Cross-regularized uncertainty learns uncertainty parameters during training using gradients routed through a held-out regularization split. The predictor is optimized on the training split for fit, while low-dimensional uncertainty controls are optimized on the regularization split to reduce train-test mismatch, yielding regime-adaptive uncertainty without per-regime noise tuning. The framework can learn continuous noise levels at the output head, within hidden features, or within operator-specific components such as spectral modes. We instantiate the approach in Fourier Neural Operators and evaluate on APEBench sweeps over observed fraction and training-set size. Across these sweeps, the learned predictive distributions are better calibrated on held-out splits and the resulting uncertainty fields concentrate in high-error regions in one-step spatial diagnostics.", "AI": {"tldr": "该论文提出了一种学习校准感知不确定性方法，适用于神经PDE代理模型，在数据有限或部分观测的情况下提供更好的预测分布和不确定性的校准。", "motivation": "在数据有限或不完整情况下，下游决策需要准确的预测误差以及经过校准的不确定性。现有方法通过集成复制、固定随机噪声或后处理校正来获取不确定性，但这些方法难以适应不同场景下对噪声的不同需求。", "method": "该方法利用交叉正则化学习在训练过程中优化模型参数和控制低维不确定性的参数，并通过对保留验证集的误差最小化提高预测分布的准确性与校准性。可以应用于输出头部、隐藏特征或特定操作组件如谱模式处的连续噪声水平。", "result": "实验结果表明，在APEBench基准测试中，通过所提出的框架学习到的预测分布优于传统方法，并且在空间诊断中不确定性集中在误差较高的区域。", "conclusion": "该研究提出了一种适应数据有限情况下的神经PDE代理模型不确定性的新方法，可以显著提高预测准确性和校准性。"}}
{"id": "2602.11089", "pdf": "https://arxiv.org/pdf/2602.11089", "abs": "https://arxiv.org/abs/2602.11089", "authors": ["Yicheng Chen", "Zerun Ma", "Xinchen Xie", "Yining Li", "Kai Chen"], "title": "DataChef: Cooking Up Optimal Data Recipes for LLM Adaptation via Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the current landscape of Large Language Models (LLMs), the curation of large-scale, high-quality training data is a primary driver of model performance. A key lever is the \\emph{data recipe}, which comprises a data processing pipeline to transform raw sources into training corpora. Despite the growing use of LLMs to automate individual data processing steps, such as data synthesis and filtering, the overall design of data recipes remains largely manual and labor-intensive, requiring substantial human expertise and iteration. To bridge this gap, we formulate \\emph{end-to-end data recipe generation} for LLM adaptation. Given a target benchmark and a pool of available data sources, a model is required to output a complete data recipe that adapts a base LLM to the target task. We present DataChef-32B, which performs online reinforcement learning using a proxy reward that predicts downstream performance for candidate recipes. Across six held-out tasks, DataChef-32B produces practical recipes that reach comparable downstream performance to those curated by human experts. Notably, the recipe from DataChef-32B adapts Qwen3-1.7B-Base to the math domain, achieving 66.7 on AIME'25 and surpassing Qwen3-1.7B. This work sheds new light on automating LLM training and developing self-evolving AI systems.", "AI": {"tldr": "数据厨师（DataChef）通过强化学习自动生成优化的LLM适配数据配方。", "motivation": "当前LLM训练中，高质量大规模的数据集对模型性能至关重要。然而，设计有效的数据处理流程依旧依赖大量的人工干预和专业知识，本研究旨在实现端到端的数据配方生成自动化以减少人力成本并提高效率。", "method": "提出了一种基于在线强化学习的方法DataChef-32B，该方法使用预测下游性能的代理奖励来优化数据配方设计，并实现了对多个任务的有效适应。", "result": "在六个独立的任务上验证了DataChef-32B生成的数据配方能够达到与人工设计相媲美的效果；特别地，在数学领域中，将Qwen3-1.7B-Base模型适配后达到了AIME'25的66.7分并超越了原始模型。", "conclusion": "本研究展示了通过自动化方法生成有效数据处理流程的可能性，并为开发自适应AI系统提供了新思路。"}}
