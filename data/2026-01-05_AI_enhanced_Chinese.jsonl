{"id": "2601.00796", "pdf": "https://arxiv.org/pdf/2601.00796", "abs": "https://arxiv.org/abs/2601.00796", "authors": ["Jiewen Chan", "Zhenjun Zhao", "Yu-Lun Liu"], "title": "AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction", "categories": ["cs.CV"], "comment": "Project page: https://jiewenchan.github.io/AdaGaR/", "summary": "Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/", "AI": {"tldr": "本文提出了一种用于动态场景重建的自适应Gabor表示法（AdaGaR），该方法结合了频率自适应和时间连续性。", "motivation": "现有使用单高斯原语的方法无法捕获高频细节，而标准Gabor函数则引入能量不稳定。此外，缺乏时间连续约束会导致插值期间出现运动伪影。", "method": "提出了一个统一框架AdaGaR，该框架通过可学习频率权重和自适应能补偿平衡了细节捕捉与稳定性，并采用三次Hermite样条结合时间曲率正则化以确保平滑的运动演化。引入了一个自适应初始化机制，将深度估计、点跟踪以及前景掩码相结合。", "result": "实验显示在Tap-Vid DAVIS数据集上的性能（PSNR 35.49, SSIM 0.9433, LPIPS 0.0723）优于现有方法，并且在帧插值、深度一致性等方面具有很好的泛化能力。", "conclusion": "AdaGaR框架能够有效解决动态场景重建中的挑战，提供高质量的结果。"}}
{"id": "2601.00794", "pdf": "https://arxiv.org/pdf/2601.00794", "abs": "https://arxiv.org/abs/2601.00794", "authors": ["Wenhui Chu", "Nikolaos V. Tsekos"], "title": "Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI", "categories": ["cs.CV", "cs.LG"], "comment": "7 pages, 5 figures, published in ICBBB 2022", "summary": "Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.", "AI": {"tldr": "提出两种用于心肌MRI图像中左心室自动分割的深度学习方法LNU-Net和IBU-Net", "motivation": "改善心脏影像分析中的左心室分割以支持临床量化与诊断", "method": "基于U-Net架构，加入层归一化或实例批次归一化的变体，并通过仿射变换及弹性形变处理图像数据；实验中比较了LNU-Net和IBU-Net的性能", "result": "在805张MRI影像上验证，所提方法优于现有技术，特别是在Dice系数与平均垂直距离方面表现更优", "conclusion": "LNU-Net和IBU-Net能有效提升左心室自动分割精度"}}
{"id": "2601.00791", "pdf": "https://arxiv.org/pdf/2601.00791", "abs": "https://arxiv.org/abs/2601.00791", "authors": ["Valentin Noël"], "title": "Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.LO"], "comment": "58 pages, 19 figures, Under Review", "summary": "We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen's $d = 3.30$ ($p < 10^{-116}$), enabling 85.0--95.6\\% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93--95\\% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B's Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness ($d = 2.09$, $p_{\\text{MW}} = 1.16 \\times 10^{-48}$), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.", "AI": {"tldr": "通过谱分析注意力模式，提出了一种无需训练的方法来检测大型语言模型中的有效数学推理。", "motivation": "动机是开发一种无须依赖训练数据或微调的验证方法，以识别大型语言模型中有效的数学证明。", "method": "将注意力矩阵视为动态图上的邻接矩阵，并从中提取四个谱诊断指标：Fiedler值（代数连接性）、高频能量比（HFER）、图形信号平滑度和谱熵。这些指标在有效和无效的数学证明之间表现出统计显着差异。", "result": "实验表明，所提出的谱签名法能够以高达Cohen's d = 3.30 (p < 10^-116) 的效应大小实现85.0%到95.6%的分类准确率。此外，该方法还能检测逻辑连贯性而非编译器接受度。", "conclusion": "研究表明谱图分析是一个原则性的框架，可用于验证推理并立即应用于幻觉检测和AI安全性监控。"}}
{"id": "2601.00789", "pdf": "https://arxiv.org/pdf/2601.00789", "abs": "https://arxiv.org/abs/2601.00789", "authors": ["Shukesh Reddy", "Srijan Das", "Abhijit Das"], "title": "Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection", "categories": ["cs.CV"], "comment": null, "summary": "In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.", "AI": {"tldr": "本文旨在通过特征融合的方式，利用自监督辅助任务来优化深度伪造检测的主任务。", "motivation": "为了释放自监督学习在泛化深度伪造检测中的潜力，作者试图探索不同训练方案组合的有效性。", "method": "研究者实验了不同的训练模式，并发现将自监督辅助任务和主要任务的特征进行融合可以显著提升性能。", "result": "通过大量数据集验证，所提出的方法在跨数据集中显示出了更好的泛化能力。", "conclusion": "最终结果表明，使用特征融合的自监督辅助任务能够有效提升深度伪造检测系统的整体表现。"}}
{"id": "2601.00785", "pdf": "https://arxiv.org/pdf/2601.00785", "abs": "https://arxiv.org/abs/2601.00785", "authors": ["Sunny Gupta", "Amit Sethi"], "title": "FedHypeVAE: Federated Learning with Hypernetwork Generated Conditional VAEs for Differentially Private Embedding Sharing", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "10 pages, 1 figures, Accepted at AAI'26", "summary": "Federated data sharing promises utility without centralizing raw data, yet existing embedding-level generators struggle under non-IID client heterogeneity and provide limited formal protection against gradient leakage. We propose FedHypeVAE, a differentially private, hypernetwork-driven framework for synthesizing embedding-level data across decentralized clients. Building on a conditional VAE backbone, we replace the single global decoder and fixed latent prior with client-aware decoders and class-conditional priors generated by a shared hypernetwork from private, trainable client codes. This bi-level design personalizes the generative layerrather than the downstream modelwhile decoupling local data from communicated parameters. The shared hypernetwork is optimized under differential privacy, ensuring that only noise-perturbed, clipped gradients are aggregated across clients. A local MMD alignment between real and synthetic embeddings and a Lipschitz regularizer on hypernetwork outputs further enhance stability and distributional coherence under non-IID conditions. After training, a neutral meta-code enables domain agnostic synthesis, while mixtures of meta-codes provide controllable multi-domain coverage. FedHypeVAE unifies personalization, privacy, and distribution alignment at the generator level, establishing a principled foundation for privacy-preserving data synthesis in federated settings. Code: github.com/sunnyinAI/FedHypeVAE", "AI": {"tldr": "提出了一种新的联邦学习框架FedHypeVAE，利用超网络生成条件变分自编码器来在分散式客户端之间合成嵌入级数据，同时保持差分隐私。", "motivation": "现有嵌入级生成器难以处理客户端异质性，并且对梯度泄漏提供的正式保护有限。因此，需要一种能够在非IID条件下工作的框架，既保证隐私又能提供高质量的嵌入合成。", "method": "基于条件变分自编码器（VAE）架构，通过引入由超网络生成的客户特定解码器和类条件先验来个性化生成过程。共享超网络在差分隐私约束下优化，确保聚合参数仅包含噪声扰动、裁剪梯度。", "result": "FedHypeVAE能够在非IID条件下合成稳定的嵌入级数据，并且通过混合元代码提供可控多领域覆盖。实验结果表明该方法在联邦学习环境中实现了个人化和隐私保护的统一。", "conclusion": "FedHypeVAE为隐私保护下的生成式数据合成建立了一个坚实的理论基础，在保持客户本地数据私密性的同时，提供了高质量的数据合成能力。"}}
{"id": "2601.00777", "pdf": "https://arxiv.org/pdf/2601.00777", "abs": "https://arxiv.org/abs/2601.00777", "authors": ["Akanksha Chuchra", "Shukesh Reddy", "Sudeepta Mishra", "Abhijit Das", "Abhinav Dhall"], "title": "Investigating the Viability of Employing Multi-modal Large Language Models in the Context of Audio Deepfake Detection", "categories": ["cs.SD", "cs.CV"], "comment": "Accepted at IJCB 2025", "summary": "While Vision-Language Models (VLMs) and Multimodal Large Language Models (MLLMs) have shown strong generalisation in detecting image and video deepfakes, their use for audio deepfake detection remains largely unexplored. In this work, we aim to explore the potential of MLLMs for audio deepfake detection. Combining audio inputs with a range of text prompts as queries to find out the viability of MLLMs to learn robust representations across modalities for audio deepfake detection. Therefore, we attempt to explore text-aware and context-rich, question-answer based prompts with binary decisions. We hypothesise that such a feature-guided reasoning will help in facilitating deeper multimodal understanding and enable robust feature learning for audio deepfake detection. We evaluate the performance of two MLLMs, Qwen2-Audio-7B-Instruct and SALMONN, in two evaluation modes: (a) zero-shot and (b) fine-tuned. Our experiments demonstrate that combining audio with a multi-prompt approach could be a viable way forward for audio deepfake detection. Our experiments show that the models perform poorly without task-specific training and struggle to generalise to out-of-domain data. However, they achieve good performance on in-domain data with minimal supervision, indicating promising potential for audio deepfake detection.", "AI": {"tldr": "研究在音频深度伪造检测中使用多模态大型语言模型的可行性。", "motivation": "目前，视觉-语言模型（VLM）和多模态大型语言模型（MLLM）在图像和视频深伪检测方面表现出色，但应用于音频深伪检测的研究较少。本文旨在探索MLLM在音频深伪检测中的应用潜力。", "method": "结合音频输入和文本提示作为查询，使用两个MLLM（Qwen2-Audio-7B-Instruct和SALMONN），通过零样本和微调两种模式进行实验。", "result": "研究结果显示，在没有特定任务训练的情况下模型性能较差且难以泛化到域外数据。但对内域数据而言，即使是在最小监督下也取得了较好的效果。", "conclusion": "结合音频输入与多提示方法在音频深伪检测中显示出潜在的可行性，但仍需进一步优化以提高其在外域数据上的表现能力。"}}
{"id": "2601.00770", "pdf": "https://arxiv.org/pdf/2601.00770", "abs": "https://arxiv.org/abs/2601.00770", "authors": ["Simon Paquette-Greenbaum", "Jiangbo Yu"], "title": "LLM Agents for Combinatorial Efficient Frontiers: Investment Portfolio Optimization", "categories": ["cs.CE", "cs.AI", "econ.GN"], "comment": null, "summary": "Investment portfolio optimization is a task conducted in all major financial institutions. The Cardinality Constrained Mean-Variance Portfolio Optimization (CCPO) problem formulation is ubiquitous for portfolio optimization. The challenge of this type of portfolio optimization, a mixed-integer quadratic programming (MIQP) problem, arises from the intractability of solutions from exact solvers, where heuristic algorithms are used to find approximate portfolio solutions. CCPO entails many laborious and complex workflows and also requires extensive effort pertaining to heuristic algorithm development, where the combination of pooled heuristic solutions results in improved efficient frontiers. Hence, common approaches are to develop many heuristic algorithms. Agentic frameworks emerge as a promising candidate for many problems within combinatorial optimization, as they have been shown to be equally efficient with regard to automating large workflows and have been shown to be excellent in terms of algorithm development, sometimes surpassing human-level performance. This study implements a novel agentic framework for the CCPO and explores several concrete architectures. In benchmark problems, the implemented agentic framework matches state-of-the-art algorithms. Furthermore, complex workflows and algorithm development efforts are alleviated, while in the worst case, lower but acceptable error is reported.", "AI": {"tldr": "该论文提出了一种新的代理框架来解决卡方约束均值-方差投资组合优化问题，并在基准测试中证明了其与现有最佳算法相当的性能。", "motivation": "传统的投资组合优化问题是计算密集型和复杂的，需要大量的人工开发启发式算法。代理框架可以自动执行大规模工作流程并降低复杂性。", "method": "提出了一种新的代理框架来解决CCPO问题，并测试了几种具体架构的有效性。", "result": "该代理框架在基准问题上与现有最佳算法相匹配，且降低了复杂的工作流和算法开发的努力，在最坏情况下也报告了可接受的误差水平。", "conclusion": "研究表明，基于代理的方法为解决CCPO问题提供了一种高效且有效的解决方案。"}}
{"id": "2601.00768", "pdf": "https://arxiv.org/pdf/2601.00768", "abs": "https://arxiv.org/abs/2601.00768", "authors": ["Mihail Stoian"], "title": "Mind the Gap. Doubling Constant Parametrization of Weighted Problems: TSP, Max-Cut, and More", "categories": ["cs.DS"], "comment": "To appear at STACS 2026", "summary": "Despite much research, hard weighted problems still resist super-polynomial improvements over their textbook solution. On the other hand, the unweighted versions of these problems have recently witnessed the sought-after speedups. Currently, the only way to repurpose the algorithm of the unweighted version for the weighted version is to employ a polynomial embedding of the input weights. This, however, introduces a pseudo-polynomial factor into the running time, which becomes impractical for arbitrarily weighted instances. In this paper, we introduce a new way to repurpose the algorithm of the unweighted problem. Specifically, we show that the time complexity of several well-known NP-hard problems operating over the $(\\min, +)$ and $(\\max, +)$ semirings, such as TSP, Weighted Max-Cut, and Edge-Weighted $k$-Clique, is proportional to that of their unweighted versions when the set of input weights has small doubling. We achieve this by a meta-algorithm that converts the input weights into polynomially bounded integers using the recent constructive Freiman's theorem by Randolph and Węgrzycki [ESA 2024] before applying the polynomial embedding.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00765", "pdf": "https://arxiv.org/pdf/2601.00765", "abs": "https://arxiv.org/abs/2601.00765", "authors": ["Joslyn Orgill", "Andra Rice", "Max Fowler", "Seth Poulsen"], "title": "The Effect of Transparency on Students' Perceptions of AI Graders", "categories": ["cs.HC"], "comment": null, "summary": "The development of effective autograders is key for scaling assessment and feedback. While NLP based autograding systems for open-ended response questions have been found to be beneficial for providing immediate feedback, autograders are not always liked, understood, or trusted by students. Our research tested the effect of transparency on students' attitudes towards autograders. Transparent autograders increased students' perceptions of autograder accuracy and willingness to discuss autograders in survey comments, but did not improve other related attitudes -- such as willingness to be graded by them on a test -- relative to the control without transparency. However, this lack of impact may be due to higher measured student trust towards autograders in this study than in prior work in the field. We briefly discuss possible reasons for this trend.", "AI": {"tldr": "研究探讨了透明度对AI评分系统学生感知的影响", "motivation": "提高学生对基于NLP的开放性问题自动评分系统的信任和接受度，以促进评估反馈的规模化。", "method": "通过比较透明与不透明的自动评分系统对学生态度的影响来测试效果。", "result": "透明的自动评分系统提高了学生的准确性和讨论意愿，但并未改善其他相关态度如考试中的使用意愿。可能由于本研究中学生对自动评分系统的信任度高于先前的研究。", "conclusion": "虽然透明度提高了一些感知指标，但仍需进一步探讨以了解影响因素和提升整体接受度的方法。"}}
{"id": "2601.00759", "pdf": "https://arxiv.org/pdf/2601.00759", "abs": "https://arxiv.org/abs/2601.00759", "authors": ["Zhaiyu Chen", "Yuqing Wang", "Xiao Xiang Zhu"], "title": "Unified Primitive Proxies for Structured Shape Completion", "categories": ["cs.CV"], "comment": null, "summary": "Structured shape completion recovers missing geometry as primitives rather than as unstructured points, which enables primitive-based surface reconstruction. Instead of following the prevailing cascade, we rethink how primitives and points should interact, and find it more effective to decode primitives in a dedicated pathway that attends to shared shape features. Following this principle, we present UniCo, which in a single feed-forward pass predicts a set of primitives with complete geometry, semantics, and inlier membership. To drive this unified representation, we introduce primitive proxies, learnable queries that are contextualized to produce assembly-ready outputs. To ensure consistent optimization, our training strategy couples primitives and points with online target updates. Across synthetic and real-world benchmarks with four independent assembly solvers, UniCo consistently outperforms recent baselines, lowering Chamfer distance by up to 50% and improving normal consistency by up to 7%. These results establish an attractive recipe for structured 3D understanding from incomplete data. Project page: https://unico-completion.github.io.", "AI": {"tldr": "本文提出了UniCo，一种单一前向传递预测完整几何、语义和内点成员的结构化形状补全方法。", "motivation": "现有方法采用级联方式处理形状补全问题，但效果不理想。作者认为通过引入可学习查询来生成组装就绪输出更为有效。", "method": "UniCo通过统一表示预测完整几何、语义和内点成员，并且在训练策略上将原始体元与点耦合以确保一致优化。", "result": "实验显示，相较于最近的基线方法，UniCo显著降低了50%的Chamfer距离并提高了7%的法向量一致性。", "conclusion": "该研究提供了一种有效的结构化3D理解从不完整数据的方法，并在多个基准测试中证明了其优越性。"}}
{"id": "2601.00754", "pdf": "https://arxiv.org/pdf/2601.00754", "abs": "https://arxiv.org/abs/2601.00754", "authors": ["Maria Teresa Parreira", "Isabel Neto", "Filipa Rocha", "Wendy Ju"], "title": "Calling for Backup: How Children Navigate Successive Robot Communication Failures", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "How do children respond to repeated robot errors? While prior research has examined adult reactions to successive robot errors, children's responses remain largely unexplored. In this study, we explore children's reactions to robot social errors and performance errors. For the latter, this study reproduces the successive robot failure paradigm of Liu et al. with child participants (N=59, ages 8-10) to examine how young users respond to repeated robot conversational errors. Participants interacted with a robot that failed to understand their prompts three times in succession, with their behavioral responses video-recorded and analyzed. We found both similarities and differences compared to adult responses from the original study. Like adults, children adjusted their prompts, modified their verbal tone, and exhibited increasingly emotional non-verbal responses throughout successive errors. However, children demonstrated more disengagement behaviors, including temporarily ignoring the robot or actively seeking an adult. Errors did not affect participants' perception of the robot, suggesting more flexible conversational expectations in children. These findings inform the design of more effective and developmentally appropriate human-robot interaction systems for young users.", "AI": {"tldr": "研究探讨了儿童在面对连续的机器人对话错误时的行为反应。", "motivation": "前人已对成人应对连续机器人错误的行为进行了大量研究，但关于儿童如何处理这一问题的研究却相对匮乏。为了填补这个空白，并为设计更适合儿童的人机交互系统提供依据，该研究关注于8至10岁儿童面对重复的机器人对话错误时的具体行为。", "method": "实验中59名年龄介于8至10岁的儿童参与了与机器人的对话，其中机器人连续三次未能理解孩子们的指令。参与者的行为反应被录像并分析。", "result": "结果表明，孩子在应对多次失败后会调整他们的提示方式、改变说话语气，并且表现出越来越强烈的情感非言语回应。然而，与成年人不同的是，儿童还展示出更多的疏远行为，例如暂时忽略机器人或主动寻求成人的帮助。此外，这些错误并未影响孩子们对机器人的感知。", "conclusion": "该研究揭示了儿童在面对重复的对话失误时的行为模式，并强调了设计更有效且符合孩子特点的人机交互系统的重要性。"}}
{"id": "2601.00743", "pdf": "https://arxiv.org/pdf/2601.00743", "abs": "https://arxiv.org/abs/2601.00743", "authors": ["Aliakbar Nafar", "Chetan Chigurupati", "Danial Kamali", "Hamid Karimian", "Parisa Kordjamshidi"], "title": "An Agentic Framework for Neuro-Symbolic Programming", "categories": ["cs.AI"], "comment": ":I.2.7", "summary": "Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.", "AI": {"tldr": "提出AgenticDomiKnowS（ADS）框架，该框架能够将自由形式的任务描述转换为完整的DominoKnowS程序，并支持人机协作。", "motivation": "现有的神经符号编程框架仍然需要用户熟悉特定的库语法。为此，研究者希望通过创建一个无需这种依赖性的工具来降低开发难度和时间成本。", "method": "ADS使用代理工作流将自由形式的任务描述转换为DominoKnowS程序，并支持在中间输出中进行人工干预。", "result": "结果显示，经验丰富的DominoKnowS用户和非用户都可以通过ADS快速构建神经符号程序，大大缩短了开发时间。", "conclusion": "ADS使得即使是没有相关编程知识的人也能够轻松地创建复杂的神经符号程序。"}}
{"id": "2601.00737", "pdf": "https://arxiv.org/pdf/2601.00737", "abs": "https://arxiv.org/abs/2601.00737", "authors": ["Uğurcan Özalp"], "title": "Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty", "categories": ["cs.LG", "cs.AI", "eess.SY"], "comment": "19 pages", "summary": "Off-policy actor-critic methods in reinforcement learning train a critic with temporal-difference updates and use it as a learning signal for the policy (actor). This design typically achieves higher sample efficiency than purely on-policy methods. However, critic networks tend to overestimate value estimates systematically. This is often addressed by introducing a pessimistic bias based on uncertainty estimates. Current methods employ ensembling to quantify the critic's epistemic uncertainty-uncertainty due to limited data and model ambiguity-to scale pessimistic updates. In this work, we propose a new algorithm called Stochastic Actor-Critic (STAC) that incorporates temporal (one-step) aleatoric uncertainty-uncertainty arising from stochastic transitions, rewards, and policy-induced variability in Bellman targets-to scale pessimistic bias in temporal-difference updates, rather than relying on epistemic uncertainty. STAC uses a single distributional critic network to model the temporal return uncertainty, and applies dropout to both the critic and actor networks for regularization. Our results show that pessimism based on a distributional critic alone suffices to mitigate overestimation, and naturally leads to risk-averse behavior in stochastic environments. Introducing dropout further improves training stability and performance by means of regularization. With this design, STAC achieves improved computational efficiency using a single distributional critic network.", "AI": {"tldr": "提出了新的算法Stochastic Actor-Critic (STAC)，通过引入时间的随机性不确定性来减少价值估计的高估问题。", "motivation": "当前的方法使用模型集成量化批评家的认知不确定性，但这往往不够有效。本文旨在利用时间上的随机性不确定性来更好地解决过度评估的问题，并促进在随机环境中的风险规避行为。", "method": "通过引入时间分布式批评家网络来建模返回的不确定性和应用dropout技术到批评家和代理网络中进行正则化来实现这个目标，这样就不再依赖于模型集成。", "result": "结果表明，基于分布式的批评家可以有效减少过度估计，并且自然地导致在随机环境中风险规避的行为。引入dropout进一步提高了训练的稳定性和性能。", "conclusion": "通过使用单一的分布式批评家网络设计的STAC算法，在保持计算效率的同时实现了更好的性能和稳定性。"}}
{"id": "2601.00736", "pdf": "https://arxiv.org/pdf/2601.00736", "abs": "https://arxiv.org/abs/2601.00736", "authors": ["Alphaeus Dmonte", "Roland Oruche", "Tharindu Ranasinghe", "Marcos Zampieri", "Prasad Calyam"], "title": "Exploring the Performance of Large Language Models on Subjective Span Identification Tasks", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.", "AI": {"tldr": "研究大型语言模型在主观跨度识别任务中的表现", "motivation": "现有工作主要集中在基于较小预训练语言模型的显式跨度识别上，而使用大型语言模型进行更主观的任务如情感分析等方面的研究较少。本文填补了这一空白。", "method": "评估不同大型语言模型在三个流行任务（情感分析、攻击性言论识别和声明验证）中对文本跨度识别的表现，并探索指令微调、上下文学习和链式思维等方法", "result": "研究表明，文本内部的关系有助于大型语言模型识别精确的文本跨度。", "conclusion": "大型语言模型在主观跨度识别任务上表现出色，表明它们能够利用文本内部关系来提高精度。"}}
{"id": "2601.00730", "pdf": "https://arxiv.org/pdf/2601.00730", "abs": "https://arxiv.org/abs/2601.00730", "authors": ["Janez Perš", "Jon Muhovič", "Andrej Košir", "Boštjan Murovec"], "title": "Grading Handwritten Engineering Exams with Multimodal Large Language Models", "categories": ["cs.CV"], "comment": "10 pages, 5 figures, 2 tables. Supplementary material available at https://lmi.fe.uni-lj.si/en/janez-pers-2/supplementary-material/", "summary": "Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\\approx$17% at $D_{\\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.", "AI": {"tldr": "论文提出了一种使用多模态大型语言模型（LLM）对扫描的手写工程考试进行批改的端到端工作流程，该方法保持了标准的考试过程，并提高了评分效率。", "motivation": "手工批改STEM学科的手写考试既耗时又难以扩展。为了解决这一问题，论文提出了一个使用多模态大型语言模型的方法来提高批改效率和准确性。", "method": "通过讲师提供手写参考答案和简短的评分规则，将参考答案转换成文本摘要以条件化评分过程。采用多阶段设计包括格式/存在检查、独立评卷人集成、监督聚合以及确定性验证模板，生成可审计且机器可解析的报告。", "result": "使用最先进的后端（如GPT-5.2和Gemini-3 Pro），整个工作流程在实际课程测验中的平均绝对误差约为8分，估计的手动复查触发率为大约17%，表明方法的有效性和准确性。", "conclusion": "研究证明了结构化提示和参考答案对提高批改准确性的必要性，并展示了多模态大型语言模型在手写考试评分任务上的潜力。"}}
{"id": "2601.00725", "pdf": "https://arxiv.org/pdf/2601.00725", "abs": "https://arxiv.org/abs/2601.00725", "authors": ["Johannes C. Bauer", "Paul Geng", "Stephan Trattnig", "Petr Dokládal", "Rüdiger Daub"], "title": "Multi-Level Feature Fusion for Continual Learning in Visual Quality Inspection", "categories": ["cs.CV"], "comment": "Accepted at the 2025 IEEE 13th International Conference on Control, Mechatronics and Automation (ICCMA)", "summary": "Deep neural networks show great potential for automating various visual quality inspection tasks in manufacturing. However, their applicability is limited in more volatile scenarios, such as remanufacturing, where the inspected products and defect patterns often change. In such settings, deployed models require frequent adaptation to novel conditions, effectively posing a continual learning problem. To enable quick adaptation, the necessary training processes must be computationally efficient while still avoiding effects like catastrophic forgetting. This work presents a multi-level feature fusion (MLFF) approach that aims to improve both aspects simultaneously by utilizing representations from different depths of a pretrained network. We show that our approach is able to match the performance of end-to-end training for different quality inspection problems while using significantly less trainable parameters. Furthermore, it reduces catastrophic forgetting and improves generalization robustness to new product types or defects.", "AI": {"tldr": "提出了一种多级特征融合方法，用于视觉质量检测中的连续学习问题", "motivation": "在制造过程中，深度神经网络的自动化能力有限，尤其是在产品和缺陷模式频繁变化的情境中。为了适应这种情况并减少灾难性遗忘，需要一种能够快速调整且计算效率高的解决方案", "method": "通过利用预训练网络不同层次的表示来融合特征，以提高模型的表现力和泛化能力", "result": "该方法在不同的质量检测问题上表现与端到端训练相当，并使用了更少的可训练参数。同时减少了灾难性遗忘并提高了对新产品的适应性", "conclusion": "MLFF 方法为视觉质量检测中的连续学习提供了有效的解决方案，既保持了高性能又减轻了计算负担"}}
{"id": "2601.00716", "pdf": "https://arxiv.org/pdf/2601.00716", "abs": "https://arxiv.org/abs/2601.00716", "authors": ["Hao Guan", "Li Zhou"], "title": "Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model", "categories": ["cs.CV", "cs.AI"], "comment": "8 pages, 6 figures", "summary": "Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.", "AI": {"tldr": "本文研究了病理学视觉语言模型在数据分布变化下的性能退化检测方法，开发了DomainSAT工具箱，并结合输入数据偏移和输出预测置信度指标进行更可靠的性能退化监测。", "motivation": "大型预训练的视觉语言模型在部署后，可能因输入数据分布的变化而出现性能下降。为了确保临床可靠性，需要有效的性能降解检测方法来监控模型的表现。", "method": "研究开发了DomainSAT工具箱用于系统性分析输入数据偏移，并引入置信度指标直接反映预测变化，结合这两种监测方式以实现更可靠的性能退化检测。", "result": "实验表明，输入数据偏移检测能有效识别分布变化但并不总与实际性能降解对应。输出预测置信度的改变则与性能下降有密切关系，二者结合可以提高模型可靠性的监控效果。", "conclusion": "该研究提供了一种实用且互补的方法框架，通过结合输入数据偏移和输出置信度指标来更有效地监测视觉语言模型在病理学中的可靠性。"}}
{"id": "2601.00711", "pdf": "https://arxiv.org/pdf/2601.00711", "abs": "https://arxiv.org/abs/2601.00711", "authors": ["Ali Abbassi", "Yann Dujardin", "Eric Gourdin", "Philippe Lacomme", "Caroline Prodhon"], "title": "Assessing Quantum Annealing to Solve the Minimum Vertex Multicut", "categories": ["quant-ph", "cs.ET"], "comment": "Published in Codit 2025", "summary": "Cybersecurity in telecommunication networks often leads to hard combinatorial optimization problems that are challenging to solve with classical methods. This work investigates the practical feasibility of using quantum annealing to address the Restricted Vertex Minimum Multicut Problem. The problem is formulated as a Quadratic Unconstrained Binary Optimization model and implemented on D-Wave s quantum annealer. Rather than focusing on solution quality alone, we analyze key aspects of the quantum workflow including minor embedding techniques, chain length, topology constraints, chain strength selection, unembedding procedures, and postprocessing. Our results show that quantum annealing faces substantial hardware-level constraints limitations in embedding and scalability, especially for large instances, while hybrid quantum-classical solvers provide improved feasibility. This study offers a realistic assessment of the D-Wave system s current capabilities and identifies crucial parameters that govern the success of quantum optimization in cybersecurity-related network problems.", "AI": {"tldr": "评估量子退火在解决最小顶点多割问题中的实际可行性。", "motivation": "网络安全中常见的组合优化问题是经典方法难以处理的，研究旨在探讨使用量子退火来解决受限顶点最小多割问题的实际可能性。", "method": "将问题建模为二次无约束二进制优化模型，并在D-Wave量子退火器上实现。分析了嵌入技术、链长度、拓扑约束等关键量子工作流程参数。", "result": "结果显示，量子退火面临硬件限制和可扩展性挑战，特别是对于大规模实例而言；混合量子-经典求解器提供了更好的可行性。", "conclusion": "研究为D-Wave系统的当前能力提供了一个现实的评估，并确定了影响网络安全相关网络问题中量子优化成功的关键参数。"}}
{"id": "2601.00705", "pdf": "https://arxiv.org/pdf/2601.00705", "abs": "https://arxiv.org/abs/2601.00705", "authors": ["Wei-Tse Cheng", "Yen-Jen Chiou", "Yuan-Fu Yang"], "title": "RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization", "categories": ["cs.CV", "cs.RO"], "comment": "10 pages, 9 figures", "summary": "We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replaces the residual-driven densification stage of GS-SLAM with a training-free correspondence-to-Gaussian initialization. Instead of progressively adding Gaussians as residuals reveal missing geometry, RGS-SLAM performs a one-shot triangulation of dense multi-view correspondences derived from DINOv3 descriptors refined through a confidence-aware inlier classifier, generating a well-distributed and structure-aware Gaussian seed prior to optimization. This initialization stabilizes early mapping and accelerates convergence by roughly 20\\%, yielding higher rendering fidelity in texture-rich and cluttered scenes while remaining fully compatible with existing GS-SLAM pipelines. Evaluated on the TUM RGB-D and Replica datasets, RGS-SLAM achieves competitive or superior localization and reconstruction accuracy compared with state-of-the-art Gaussian and point-based SLAM systems, sustaining real-time mapping performance at up to 925 FPS.", "AI": {"tldr": "该论文提出了一种鲁棒的高斯拟合SLAM框架，通过一次性生成密集多视角对应关系初始化方法来改进GS-SLAM。", "motivation": "传统的GS-SLAM需要逐步添加高斯模型以填补几何缺陷，这导致早期地图不稳定和收敛慢。为了提高稳定性和加速收敛速度，同时提升纹理丰富和复杂环境中的重建精度，论文引入了一种新的初始化方法。", "method": "RGS-SLAM利用DINOv3描述子生成多视角对应关系，并通过置信度感知的内点分类器进行优化，一次性完成高斯种子的密集分布和结构感知初始化。这种新方法无需训练即可实现有效地图初始化并保持与现有GS-SLAM框架兼容。", "result": "RGS-SLAM在TUM RGB-D和Replica数据集上进行了评估，在定位和重建精度方面表现出色，相比其他高斯基点SLAM系统更加稳定高效，并且能够达到每秒925帧的实时地图构建性能。", "conclusion": "该论文通过引入一次性生成密集多视角对应关系的方法改进了GS-SLAM框架，显著提高了早期地图稳定性、加速了收敛过程并保持了高重建精度，在多种场景下表现出优异性能。"}}
{"id": "2601.00703", "pdf": "https://arxiv.org/pdf/2601.00703", "abs": "https://arxiv.org/abs/2601.00703", "authors": ["Cory Fan", "Wenchao Zhang"], "title": "Efficient Deep Demosaicing with Spatially Downsampled Isotropic Networks", "categories": ["cs.CV"], "comment": "9 pages, 5 figures. To be published at WVAQ Workshop at WACV", "summary": "In digital imaging, image demosaicing is a crucial first step which recovers the RGB information from a color filter array (CFA). Oftentimes, deep learning is utilized to perform image demosaicing. Given that most modern digital imaging applications occur on mobile platforms, applying deep learning to demosaicing requires lightweight and efficient networks. Isotropic networks, also known as residual-in-residual networks, have been often employed for image demosaicing and joint-demosaicing-and-denoising (JDD). Most demosaicing isotropic networks avoid spatial downsampling entirely, and thus are often prohibitively expensive computationally for mobile applications. Contrary to previous isotropic network designs, this paper claims that spatial downsampling to a signficant degree can improve the efficiency and performance of isotropic networks. To validate this claim, we design simple fully convolutional networks with and without downsampling using a mathematical architecture design technique adapted from DeepMAD, and find that downsampling improves empirical performance. Additionally, empirical testing of the downsampled variant, JD3Net, of our fully convolutional networks reveals strong empirical performance on a variety of image demosaicing and JDD tasks.", "AI": {"tldr": "提出了一种通过空间下采样改进的等向网络JD3Net，用于图像解马赛克和联合去噪解马赛克任务。", "motivation": "传统等向网络避免空间下采样导致计算成本高，在移动设备上应用受限；引入空间下采样可提升性能并降低成本。", "method": "设计了带与不带空间下采样的全卷积网络，通过一种源自DeepMAD的数学架构设计技术验证下采样的效果，并测试JD3Net在解马赛克和联合去噪解马赛克任务中的表现。", "result": "实验显示，引入空间下采样的变体网络JD3Net表现出色，在多种图像解马赛克及联合去噪解马赛克任务中均取得良好结果。", "conclusion": "通过合理利用空间下采样技术，可以显著提升等向网络的性能和效率，使其更加适合移动平台应用。"}}
{"id": "2601.00702", "pdf": "https://arxiv.org/pdf/2601.00702", "abs": "https://arxiv.org/abs/2601.00702", "authors": ["Samuel Cerezo", "Javier Civera"], "title": "DefVINS: Visual-Inertial Odometry for Deformable Scenes", "categories": ["cs.RO", "cs.CV"], "comment": "4 figures, 3 tables. Submitted to RA-L", "summary": "Deformable scenes violate the rigidity assumptions underpinning classical visual-inertial odometry (VIO), often leading to over-fitting to local non-rigid motion or severe drift when deformation dominates visual parallax. We introduce DefVINS, a visual-inertial odometry framework that explicitly separates a rigid, IMU-anchored state from a non--rigid warp represented by an embedded deformation graph. The system is initialized using a standard VIO procedure that fixes gravity, velocity, and IMU biases, after which non-rigid degrees of freedom are activated progressively as the estimation becomes well conditioned. An observability analysis is included to characterize how inertial measurements constrain the rigid motion and render otherwise unobservable modes identifiable in the presence of deformation. This analysis motivates the use of IMU anchoring and informs a conditioning-based activation strategy that prevents ill-posed updates under poor excitation. Ablation studies demonstrate the benefits of combining inertial constraints with observability-aware deformation activation, resulting in improved robustness under non-rigid environments.", "AI": {"tldr": "提出了一种用于可变形场景的视觉惯性里程计框架DefVINS，该框架能够分离刚性和非刚性运动。", "motivation": "传统视觉惯性里程计在处理可变形场景时容易过度拟合局部非刚性运动或因变形主导视觉视差而出现严重漂移。为了改善这些问题，引入了DefVINS。", "method": "通过使用标准的视觉惯性初始化程序固定重力、速度和惯性测量单元偏差后逐步激活非刚性自由度，并利用嵌入式变形图表示非刚性运动来实现任务分离。", "result": "结合惯性约束与可观察性感知变形激活策略，提高了在非刚性环境中的鲁棒性。", "conclusion": "DefVINS框架有效解决了传统视觉惯性里程计在处理可变形场景时的问题，通过合理的初始化和逐步激活自由度的方法，确保了系统的稳定性和准确性。"}}
{"id": "2601.00696", "pdf": "https://arxiv.org/pdf/2601.00696", "abs": "https://arxiv.org/abs/2601.00696", "authors": ["Yash Jain", "Xinjie Liu", "Lasse Peters", "David Fridovich-Keil", "Ufuk Topcu"], "title": "Bayesian Inverse Games with High-Dimensional Multi-Modal Observations", "categories": ["cs.LG", "cs.GT", "cs.RO"], "comment": null, "summary": "Many multi-agent interaction scenarios can be naturally modeled as noncooperative games, where each agent's decisions depend on others' future actions. However, deploying game-theoretic planners for autonomous decision-making requires a specification of all agents' objectives. To circumvent this practical difficulty, recent work develops maximum likelihood techniques for solving inverse games that can identify unknown agent objectives from interaction data. Unfortunately, these methods only infer point estimates and do not quantify estimator uncertainty; correspondingly, downstream planning decisions can overconfidently commit to unsafe actions. We present an approximate Bayesian inference approach for solving the inverse game problem, which can incorporate observation data from multiple modalities and be used to generate samples from the Bayesian posterior over the hidden agent objectives given limited sensor observations in real time. Concretely, the proposed Bayesian inverse game framework trains a structured variational autoencoder with an embedded differentiable Nash game solver on interaction datasets and does not require labels of agents' true objectives. Extensive experiments show that our framework successfully learns prior and posterior distributions, improves inference quality over maximum likelihood estimation-based inverse game approaches, and enables safer downstream decision-making without sacrificing efficiency. When trajectory information is uninformative or unavailable, multimodal inference further reduces uncertainty by exploiting additional observation modalities.", "AI": {"tldr": "提出了一种基于贝叶斯逆博弈框架的方法，用于从多模态观测数据中推断代理目标，并生成后验分布样本。", "motivation": "为了克服传统最大似然估计方法仅提供点估计且无法量化不确定性的缺点，本文旨在通过引入贝叶斯推理来提高对未知代理目标的识别精度和下游决策的安全性。", "method": "采用结构化变分自动编码器与嵌入式可微纳什博弈求解器相结合的方式，在互作数据集上进行训练，并利用多模态观测信息生成后验分布样本。", "result": "实验结果表明，所提框架能够在有限传感器观测条件下学习先验和后验概率分布，改善了最大似然估计方法的推断质量，并在不牺牲效率的情况下增强了下游决策的安全性。", "conclusion": "该研究成功地提出了一个有效的贝叶斯逆博弈框架，它不仅能够处理多模态数据，还能够在不确定性较高的情况下提高对代理目标的识别准确度和规划安全性。"}}
{"id": "2601.00694", "pdf": "https://arxiv.org/pdf/2601.00694", "abs": "https://arxiv.org/abs/2601.00694", "authors": ["Qingwen Pu", "Kun Xie", "Hong Yang", "Guocong Zhai"], "title": "A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference", "categories": ["cs.AI"], "comment": null, "summary": "Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.", "AI": {"tldr": "本文介绍了一种基于大型语言模型增强的行人过街行为推理框架PedX-LLM，该框架通过结合视觉特征和领域知识提升了行人过街行为预测的一般化性能。", "motivation": "现有行人过街行为推断方法在新环境中的泛化能力较差。本文旨在开发一种新的基于大型语言模型的方法来增强这一领域的预测准确性。", "method": "PedX-LLM框架通过结合视觉特征和领域知识对预训练的LLaMA-2-7B基础模型进行低秩适应（LoRA）微调，以提升行人过街行为的推理能力。", "result": "实验结果表明，PedX-LLM达到了82.0%的平衡精度，并在五个未见过测试地点上实现了66.9%的零样本准确度和72.2%的少量样本学习准确度，显著优于传统方法。", "conclusion": "通过视觉增强模块以及领域知识的集成，PedX-LLM成功地提高了行人过街行为预测的一般化性能，并展示了其在未见过环境中的强大应用潜力。"}}
{"id": "2601.00689", "pdf": "https://arxiv.org/pdf/2601.00689", "abs": "https://arxiv.org/abs/2601.00689", "authors": ["Alireza Rezaee"], "title": "Cost Optimization in Production Line Using Genetic Algorithm", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "This paper presents a genetic algorithm (GA) approach to cost-optimal task scheduling in a production line. The system consists of a set of serial processing tasks, each with a given duration, unit execution cost, and precedence constraints, which must be assigned to an unlimited number of stations subject to a per-station duration bound. The objective is to minimize the total production cost, modeled as a station-wise function of task costs and the duration bound, while strictly satisfying all prerequisite and capacity constraints. Two chromosome encoding strategies are investigated: a station-based representation implemented using the JGAP library with SuperGene validity checks, and a task-based representation in which genes encode station assignments directly. For each encoding, standard GA operators (crossover, mutation, selection, and replacement) are adapted to preserve feasibility and drive the population toward lower-cost schedules. Experimental results on three classes of precedence structures-tightly coupled, loosely coupled, and uncoupled-demonstrate that the task-based encoding yields smoother convergence and more reliable cost minimization than the station-based encoding, particularly when the number of valid schedules is large. The study highlights the advantages of GA over gradient-based and analytical methods for combinatorial scheduling problems, especially in the presence of complex constraints and non-differentiable cost landscapes.", "AI": {"tldr": "本文提出了一种使用遗传算法（GA）的方法来优化生产线中的任务调度，以最小化总生产成本。", "motivation": "为了在满足所有先决条件和容量约束的情况下，减少生产过程中的总体成本，本研究探索了两种不同的染色体编码策略，并通过实验验证其效果。", "method": "采用了遗传算法（GA）的方法，包括标准的交叉、变异、选择和替换操作。具体实现中使用了基于站点的表示方法和基于任务的表示方法来适应可行性和驱动种群向更低成本的日程安排发展。", "result": "实验结果表明，在处理耦合程度较高的先决结构时，基于任务的编码策略比基于站点的编码更能够平滑地收敛并可靠地实现成本最小化。", "conclusion": "研究表明遗传算法在解决具有复杂约束和非可微费用地形的组合调度问题上优于梯度法和解析方法。"}}
{"id": "2601.00679", "pdf": "https://arxiv.org/pdf/2601.00679", "abs": "https://arxiv.org/abs/2601.00679", "authors": ["Rachmad Vidya Wicaksana Putra", "Pasindu Wickramasinghe", "Muhammad Shafique"], "title": "QSLM: A Performance- and Memory-aware Quantization Framework with Tiered Search Strategy for Spike-driven Language Models", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": "Accepted at the Design, Automation and Test in Europe Conference (DATE) 2025 on April 20th-22nd, 2025 in Verona, Italy", "summary": "Large Language Models (LLMs) have been emerging as prominent AI models for solving many natural language tasks due to their high performance (e.g., accuracy) and capabilities in generating high-quality responses to the given inputs. However, their large computational cost, huge memory footprints, and high processing power/energy make it challenging for their embedded deployments. Amid several tinyLLMs, recent works have proposed spike-driven language models (SLMs) for significantly reducing the processing power/energy of LLMs. However, their memory footprints still remain too large for low-cost and resource-constrained embedded devices. Manual quantization approach may effectively compress SLM memory footprints, but it requires a huge design time and compute power to find the quantization setting for each network, hence making this approach not-scalable for handling different networks, performance requirements, and memory budgets. To bridge this gap, we propose QSLM, a novel framework that performs automated quantization for compressing pre-trained SLMs, while meeting the performance and memory constraints. To achieve this, QSLM first identifies the hierarchy of the given network architecture and the sensitivity of network layers under quantization, then employs a tiered quantization strategy (e.g., global-, block-, and module-level quantization) while leveraging a multi-objective performance-and-memory trade-off function to select the final quantization setting. Experimental results indicate that our QSLM reduces memory footprint by up to 86.5%, reduces power consumption by up to 20%, maintains high performance across different tasks (i.e., by up to 84.4% accuracy of sentiment classification on the SST-2 dataset and perplexity score of 23.2 for text generation on the WikiText-2 dataset) close to the original non-quantized model while meeting the performance and memory constraints.", "AI": {"tldr": "提出了一种针对脉冲驱动语言模型的自动化量化框架QSLM，以压缩内存占用并保持性能。", "motivation": "降低大型语言模型在嵌入式部署中的计算成本和内存开销。解决手动量化方法耗时且难以扩展的问题。", "method": "通过识别网络架构层次结构和量化敏感度，采用分层量化策略（全局、块级和模块级）并使用多目标性能与内存权衡函数选择最终量化设置。", "result": "实验表明QSLM可以减少高达86.5%的内存占用，降低20%的能耗，并在不同的任务上保持高精度接近原始模型。", "conclusion": "QSLM有效地压缩了脉冲驱动语言模型的内存占用并减少了能源消耗，同时满足性能和内存约束。"}}
{"id": "2601.00678", "pdf": "https://arxiv.org/pdf/2601.00678", "abs": "https://arxiv.org/abs/2601.00678", "authors": ["Melonie de Almeida", "Daniela Ivanova", "Tong Shi", "John H. Williamson", "Paul Henderson"], "title": "Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians", "categories": ["cs.CV"], "comment": null, "summary": "Humans excel at forecasting the future dynamics of a scene given just a single image. Video generation models that can mimic this ability are an essential component for intelligent systems. Recent approaches have improved temporal coherence and 3D consistency in single-image-conditioned video generation. However, these methods often lack robust user controllability, such as modifying the camera path, limiting their applicability in real-world applications. Most existing camera-controlled image-to-video models struggle with accurately modeling camera motion, maintaining temporal consistency, and preserving geometric integrity. Leveraging explicit intermediate 3D representations offers a promising solution by enabling coherent video generation aligned with a given camera trajectory. Although these methods often use 3D point clouds to render scenes and introduce object motion in a later stage, this two-step process still falls short in achieving full temporal consistency, despite allowing precise control over camera movement. We propose a novel framework that constructs a 3D Gaussian scene representation and samples plausible object motion, given a single image in a single forward pass. This enables fast, camera-guided video generation without the need for iterative denoising to inject object motion into render frames. Extensive experiments on the KITTI, Waymo, RealEstate10K and DL3DV-10K datasets demonstrate that our method achieves state-of-the-art video quality and inference efficiency. The project page is available at https://melonienimasha.github.io/Pixel-to-4D-Website.", "AI": {"tldr": "基于单张图像生成视频，通过构建3D高斯场景表示和样本对象运动实现快速、可控的视频生成。", "motivation": "现有方法在模仿人类根据单一图像预测未来动态方面表现不佳，缺乏相机路径控制能力。本文旨在提高模型对于相机轨迹的适应性以及保持几何完整性与时间一致性。", "method": "提出了一种新框架，该框架通过单次前向传播构建3D高斯场景表示并抽样可能的对象运动，实现了快速、基于相机引导视频生成，无需迭代去噪注入对象运动。", "result": "实验表明该方法在视频质量和推理效率方面达到最先进的水平。", "conclusion": "本文框架成功地解决了现有技术中存在的问题，并通过实验证明了其优越性。"}}
{"id": "2601.00677", "pdf": "https://arxiv.org/pdf/2601.00677", "abs": "https://arxiv.org/abs/2601.00677", "authors": ["Haonan Song", "Qingchen Xie", "Huan Zhu", "Feng Xiao", "Luxi Xing", "Fuzhen Li", "Liu Kang", "Feng Jiang", "Zhiyong Zheng", "Fan Yang"], "title": "IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 4 figures", "summary": "Generative Reward Models (GRMs) have attracted considerable research interest in reward modeling due to their interpretability, inference-time scalability, and potential for refinement through reinforcement learning (RL). However, widely used pairwise GRMs create a computational bottleneck when integrated with RL algorithms such as Group Relative Policy Optimization (GRPO). This bottleneck arises from two factors: (i) the O(n^2) time complexity of pairwise comparisons required to obtain relative scores, and (ii) the computational overhead of repeated sampling or additional chain-of-thought (CoT) reasoning to improve performance. To address the first factor, we propose Intergroup Relative Preference Optimization (IRPO), a novel RL framework that incorporates the well-established Bradley-Terry model into GRPO. By generating a pointwise score for each response, IRPO enables efficient evaluation of arbitrarily many candidates during RL training while preserving interpretability and fine-grained reward signals. Experimental results demonstrate that IRPO achieves state-of-the-art (SOTA) performance among pointwise GRMs across multiple benchmarks, with performance comparable to that of current leading pairwise GRMs. Furthermore, we show that IRPO significantly outperforms pairwise GRMs in post-training evaluations.", "AI": {"tldr": "IRPO是一种新的强化学习框架，通过引入Bradley-Terry模型来解决生成奖励模型在与RL算法集成时的计算瓶颈问题。", "motivation": "生成式奖励模型因其可解释性、推理时间规模和通过强化学习改进的能力而受到关注。然而，在将其与诸如GRPO这样的RL算法结合使用时，常用的成对模型会导致计算瓶颈，主要由于需要进行O(n^2)的时间复杂度的成对比较以获取相对分数。", "method": "IRPO框架生成每个响应的点对评分，从而在RL训练期间可以高效地评估任意数量的候选者，并保留可解释性与细粒度奖励信号。该方法解决了计算瓶颈问题，同时保持了模型性能。", "result": "实验结果表明，在多个基准测试中，IRPO实现了SOTA水平的表现；此外，其在后期评测中的表现也显著优于成对GRMs。", "conclusion": "IRPO通过引入Bradley-Terry模型克服了生成奖励模型与RL算法集成时的计算瓶颈，并且在保持高可解释性的同时达到了优秀的性能。"}}
{"id": "2601.00675", "pdf": "https://arxiv.org/pdf/2601.00675", "abs": "https://arxiv.org/abs/2601.00675", "authors": ["Tony Lee", "Andrew Wagenmaker", "Karl Pertsch", "Percy Liang", "Sergey Levine", "Chelsea Finn"], "title": "RoboReward: General-Purpose Vision-Language Reward Models for Robotics", "categories": ["cs.RO"], "comment": null, "summary": "A well-designed reward is critical for effective reinforcement learning-based policy improvement. In real-world robotic domains, obtaining such rewards typically requires either labor-intensive human labeling or brittle, handcrafted objectives. Vision-language models (VLMs) have shown promise as automatic reward models, yet their effectiveness on real robot tasks is poorly understood. In this work, we aim to close this gap by introducing (1) \\textbf{RoboReward}, a robotics reward dataset and benchmark built on large-scale real-robot corpora from Open X-Embodiment (OXE) and RoboArena, and (2) vision-language reward models trained on this dataset (RoboReward 4B/8B). Because OXE is success-heavy and lacks failure examples, we propose a \\emph{negative examples data augmentation} pipeline that generates calibrated \\emph{negatives} and \\emph{near-misses} via counterfactual relabeling of successful episodes and temporal clipping to create partial-progress outcomes from the same videos. Using this framework, we produce an extensive training and evaluation dataset that spans diverse tasks and embodiments and enables systematic evaluation of whether state-of-the-art VLMs can reliably provide rewards for robotics. Our evaluation of leading open-weight and proprietary VLMs reveals that no model excels across all tasks, underscoring substantial room for improvement. We then train general-purpose 4B- and 8B-parameter models that outperform much larger VLMs in assigning rewards for short-horizon robotic tasks. Finally, we deploy the 8B-parameter reward VLM in real-robot reinforcement learning and find that it improves policy learning over Gemini Robotics-ER 1.5, a frontier physical reasoning VLM trained on robotics data, by a large margin, while substantially narrowing the gap to RL training with human-provided rewards.", "AI": {"tldr": "本文提出了一种名为RoboReward的奖励模型，用于机器人领域中的强化学习任务。该模型基于大规模的真实机器人大数据集，并通过负样本增强的方法生成训练和评估数据。", "motivation": "设计有效的奖励机制对于基于强化学习的策略改进至关重要。然而，在现实世界中获取这样的奖励通常需要耗时的人工标注或脆弱的手动制定的目标。本文旨在填补视觉语言模型在机器人任务中的性能差距，展示它们作为自动化奖励模型的有效性。", "method": "创建了一个名为RoboReward的大规模真实机器人大数据集和基准测试，并提出了一种负样本增强方法以生成训练和评估所需的数据。该方法通过反事实重标记成功案例并进行时间裁剪来生成负面示例和接近失败的示例，从而扩大了任务多样性和机器人类型的范围。", "result": "对前沿视觉语言模型进行评估发现，没有任何一个模型能够全面胜出所有任务，表明仍有改进空间。同时训练出了4B参数和8B参数的一般性奖励模型，在短时域机器人的奖励分配方面超过了更大的VLM模型。在实际机器人强化学习中部署了8B参数的奖励视觉语言模型，并取得了显著优于其他模型的结果。", "conclusion": "RoboReward通过大规模真实数据训练出了一种有效的通用视觉语言奖励模型，该模型能够为多种类型的机器人任务提供准确的奖励信号，并且在实际应用中表现优越。"}}
{"id": "2601.00671", "pdf": "https://arxiv.org/pdf/2601.00671", "abs": "https://arxiv.org/abs/2601.00671", "authors": ["Tianyu Zhao", "Llion Jones"], "title": "Fast-weight Product Key Memory", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, \"fast-weight\" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.", "AI": {"tldr": "提出了Fast-weight Product Key Memory (FwPKM) 架构，以解决序列建模层中的存储容量与计算效率之间的矛盾。", "motivation": "现代语言模型的序列建模层通常面临着存储容量和计算效率之间的权衡。Softmax注意力提供了无限存储但成本高昂，而线性变体虽然有效率但却受限于固定大小的存储空间。", "method": "FwPKM通过将稀疏Product Key Memory（PKM）从静态模块转变为动态的“快速权重”临时记忆来解决这一问题，并且在训练和推理过程中都利用局部块级别的梯度下降更新其参数，从而允许模型迅速地记住和检索新的键值对。", "result": "实验表明FwPKM作为一个有效的临时记忆，补充了标准模块的语义记忆，在长期上下文数据集上显著降低了困惑度，并且在128K标记的上下文中表现出良好的泛化能力。", "conclusion": "FwPKM架构成功解决了序列建模层中的存储容量和计算效率之间的矛盾，证明其作为有效临时记忆的重要价值。"}}
{"id": "2601.00670", "pdf": "https://arxiv.org/pdf/2601.00670", "abs": "https://arxiv.org/abs/2601.00670", "authors": ["Argha Kamal Samanta", "Deepak Mewada", "Monalisa Sarma", "Debasis Samanta"], "title": "Wave2Word: A Multimodal Transformer Framework for Joint EEG-Text Alignment and Multi-Task Representation Learning in Neurocritical Care", "categories": ["cs.HC"], "comment": null, "summary": "Continuous electroencephalography (EEG) is routinely used in neurocritical care to monitor seizures and other harmful brain activity, including rhythmic and periodic patterns that are clinically significant. Although deep learning methods have achieved high accuracy in seizure detection, most existing approaches remain seizure-centric, rely on discrete-label supervision, and are primarily evaluated using accuracy-based metrics. A central limitation of current EEG modeling practice is the weak correspondence between learned representations and how EEG findings are interpreted and summarized in clinical workflows. Harmful EEG activity exhibits overlapping patterns, graded expert agreement, and temporal persistence, which are not well captured by classification objectives alone. This work proposes a multimodal EEG representation learning framework that integrates signal-domain modeling with structured clinical language supervision. First, raw EEG is transformed into a longitudinal bipolar montage and time-frequency representations. Second, dual transformer-based encoders model complementary temporal and frequency-centric dependencies and are fused using an adaptive gating mechanism. Third, EEG embeddings are aligned with structured expert consensus descriptions through a contrastive objective. Finally, an EEG-conditioned text reconstruction loss is introduced as a representation-level constraint alongside standard classification loss. Experimental evaluation using a controlled train-validation-test split achieves a six-class test accuracy of 0.9797. Ablation analyses show that removing contrastive alignment reduces cross-modal retrieval performance from Recall@10 of 0.3390 to 0.0045, despite minimal change in classification accuracy. These findings demonstrate that discriminative accuracy does not reliably reflect representation quality for clinically meaningful EEG modeling.", "AI": {"tldr": "提出了一种结合信号域建模和结构化临床语言监督的多模式EEG表示学习框架。", "motivation": "现有方法依赖于离散标签监督，且主要通过基于准确性的指标进行评价。这些方法未能充分反映临床工作流中对EEG发现的解释与总结方式，难以捕捉有害脑活动的重叠模式、专家共识及时间持久性。", "method": "首先将原始EEG转换为纵向双极蒙太奇和时频表示；其次利用双重变压器编码器建模互补的时间和频率依赖关系，并通过自适应门控机制进行融合；最后，通过对比目标对EEG嵌入与结构化专家共识描述进行对齐。", "result": "实验评价结果显示六类测试准确率为0.9797。移除对比对齐后交叉模态检索性能从Recall@10的0.3390降至0.0045，尽管分类准确性变化不大。", "conclusion": "研究发现表明基于准确性的鉴别性精度不能可靠地反映EEG建模中的表示质量。"}}
{"id": "2601.00668", "pdf": "https://arxiv.org/pdf/2601.00668", "abs": "https://arxiv.org/abs/2601.00668", "authors": ["Luke Vassallo", "Nima Taherinejad"], "title": "Three factor delay learning rules for spiking neural networks", "categories": ["cs.NE", "cs.LG"], "comment": "7 pages, 5 figures", "summary": "Spiking Neural Networks (SNNs) are dynamical systems that operate on spatiotemporal data, yet their learnable parameters are often limited to synaptic weights, contributing little to temporal pattern recognition. Learnable parameters that delay spike times can improve classification performance in temporal tasks, but existing methods rely on large networks and offline learning, making them unsuitable for real-time operation in resource-constrained environments. In this paper, we introduce synaptic and axonal delays to leaky integrate and fire (LIF)-based feedforward and recurrent SNNs, and propose three-factor learning rules to simultaneously learn delay parameters online. We employ a smooth Gaussian surrogate to approximate spike derivatives exclusively for the eligibility trace calculation, and together with a top-down error signal determine parameter updates. Our experiments show that incorporating delays improves accuracy by up to 20% over a weights-only baseline, and for networks with similar parameter counts, jointly learning weights and delays yields up to 14% higher accuracy. On the SHD speech recognition dataset, our method achieves similar accuracy to offline backpropagation-based approaches. Compared to state-of-the-art methods, it reduces model size by 6.6x and inference latency by 67%, with only a 2.4% drop in classification accuracy. Our findings benefit the design of power and area-constrained neuromorphic processors by enabling on-device learning and lowering memory requirements.", "AI": {"tldr": "论文提出了一种针对脉冲神经网络的三因素延迟学习规则，用于同时在线学习突触和轴索延迟参数。", "motivation": "现有的脉冲神经网络的学习方法仅限于权重调整，并且依赖大模型及离线学习，限制了其在实时操作中的应用。引入可学习的时间延迟有助于改进分类性能，但需要适合资源受限环境的解决方案。", "method": "通过为基于LIF的前馈和递归SNN增加突触和轴索延迟，并使用平滑高斯代理计算责任迹线以确定参数更新，实现了三因素在线学习规则。", "result": "实验表明，在类似参数计数的网络中，同时学习权重和时间延迟可提升分类准确率最多14%。在SHD语音识别数据集上，方法与离线反向传播法具有相似精度，并且模型大小减少了6.6倍，推理延迟降低了67%，仅损失了2.4％的准确性。", "conclusion": "通过引入时间延迟参数和三因素在线学习规则，该研究为设计适用于低功耗、面积受限环境中的神经形态处理器提供了新的思路。"}}
{"id": "2601.00664", "pdf": "https://arxiv.org/pdf/2601.00664", "abs": "https://arxiv.org/abs/2601.00664", "authors": ["Taekyung Ki", "Sangwon Jang", "Jaehyeong Jo", "Jaehong Yoon", "Sung Ju Hwang"], "title": "Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.HC", "cs.MM"], "comment": "Project page: https://taekyungki.github.io/AvatarForcing/", "summary": "Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.", "AI": {"tldr": "本文提出了Avatar Forcing框架，用于实现实时交互式头像生成。", "motivation": "现有模型难以实现实时互动交流，缺乏情感参与。该研究旨在解决实时运动生成和无标签数据表达学习两个关键挑战。", "method": "通过扩散强迫设计，使头像能够处理包括语音和动作在内的实时多模态输入，低延迟反应并使用直接偏好优化方法进行无标签的数据学习。", "result": "实验结果表明该框架实现了实现实时交互，并且相较于基线模型有6.8倍的速度提升，生成的互动表情效果在80%以上的测试中优于基线。", "conclusion": "Avatar Forcing为实时头像生成提供了有效的解决方案，提高了用户体验和交流质量。"}}
{"id": "2601.00659", "pdf": "https://arxiv.org/pdf/2601.00659", "abs": "https://arxiv.org/abs/2601.00659", "authors": ["Neeraj Anand", "Samyak Jha", "Udbhav Bamba", "Rahul Rahaman"], "title": "CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models", "categories": ["cs.CV"], "comment": "Accepted at TMLR 2026", "summary": "Despite the rapid success of Large Vision-Language Models (LVLMs), a persistent challenge is their tendency to generate hallucinated content, undermining reliability in real-world use. Existing training-free methods address hallucinations but face two limitations: (i) they rely on narrow assumptions about hallucination sources, and (ii) their effectiveness declines toward the end of generation, where hallucinations are most likely to occur. A common strategy is to build hallucinated models by completely or partially removing visual tokens and contrasting them with the original model. Yet, this alone proves insufficient, since visual information still propagates into generated text. Building on this insight, we propose a novel hallucinated model that captures hallucination effects by selectively removing key text tokens. We further introduce Generalized Contrastive Decoding, which integrates multiple hallucinated models to represent diverse hallucination sources. Together, these ideas form CRoPS, a training-free hallucination mitigation framework that improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.", "AI": {"tldr": "CRoPS是一种无需训练的幻觉缓解框架，用于改进大型视觉语言模型生成内容的可靠性。", "motivation": "大型视觉语言模型容易产生不真实的幻觉内容，现有的无训练方法存在依赖狭窄假设和有效性随生成过程减弱的问题。因此需要一种新的解决方案来解决这一挑战。", "method": "该论文提出了CRoPS框架，通过选择性地移除关键文本令牌来捕捉幻觉效应，并引入广义对比解码以整合多种幻觉模型表示多样化的幻觉来源。", "result": "在六种基准测试和三个大型视觉语言模型家族中，CRoPS显著提升了CHAIR分数达20%，并且实现了持续的性能提升。", "conclusion": "通过提出一种新的无训练方法CRoPS框架，论文成功改善了大型视觉语言模型生成内容的质量，增强了其在实际应用中的可靠性。"}}
{"id": "2601.00658", "pdf": "https://arxiv.org/pdf/2601.00658", "abs": "https://arxiv.org/abs/2601.00658", "authors": ["Zhaiyu Chen", "Yuanyuan Wang", "Yilei Shi", "Xiao Xiang Zhu"], "title": "Reconstructing Building Height from Spaceborne TomoSAR Point Clouds Using a Dual-Topology Network", "categories": ["cs.CV"], "comment": "Accepted for publication in IEEE Transactions on Geoscience and Remote Sensing", "summary": "Reliable building height estimation is essential for various urban applications. Spaceborne SAR tomography (TomoSAR) provides weather-independent, side-looking observations that capture facade-level structure, offering a promising alternative to conventional optical methods. However, TomoSAR point clouds often suffer from noise, anisotropic point distributions, and data voids on incoherent surfaces, all of which hinder accurate height reconstruction. To address these challenges, we introduce a learning-based framework for converting raw TomoSAR points into high-resolution building height maps. Our dual-topology network alternates between a point branch that models irregular scatterer features and a grid branch that enforces spatial consistency. By jointly processing these representations, the network denoises the input points and inpaints missing regions to produce continuous height estimates. To our knowledge, this is the first proof of concept for large-scale urban height mapping directly from TomoSAR point clouds. Extensive experiments on data from Munich and Berlin validate the effectiveness of our approach. Moreover, we demonstrate that our framework can be extended to incorporate optical satellite imagery, further enhancing reconstruction quality. The source code is available at https://github.com/zhu-xlab/tomosar2height.", "AI": {"tldr": "本文提出了一种基于学习的框架，从空间层析SAR点云中重建建筑物高度。", "motivation": "可靠的建筑高度估计对于各种城市应用至关重要。然而，TomoSAR点云通常受到噪声、非均匀分布和不相干表面的数据缺失的影响，这些因素阻碍了准确的高度重建。", "method": "本文提出了一种双拓扑网络框架，该框架通过交替使用表示散射特征的点分支和保证空间一致性的网格分支，处理输入点并生成连续高度估计。", "result": "实验结果表明，本文的方法在慕尼黑和柏林的数据上有效。此外，还展示了将光学卫星图像集成到框架中以进一步提高重建质量。", "conclusion": "这是从TomoSAR点云直接进行大规模城市高度映射的第一个概念证明。该方法的有效性和潜力已通过实验得到验证，并且代码已经公开。"}}
{"id": "2601.00656", "pdf": "https://arxiv.org/pdf/2601.00656", "abs": "https://arxiv.org/abs/2601.00656", "authors": ["Biraja Ghoshal"], "title": "Quantum Simulation of Protein Fragment Electronic Structure Using Moment-based Adaptive Variational Quantum Algorithms", "categories": ["q-bio.QM", "cs.ET"], "comment": "Keywords: quantum computing, variational quantum eigensolver, protein fragments, electronic structure, drug discovery, enzyme engineering", "summary": "Background: Understanding electronic interactions in protein active sites is fundamental to drug discovery and enzyme engineering, but remains computationally challenging due to exponential scaling of quantum mechanical calculations. Results: We present a quantum-classical hybrid framework for simulating protein fragment electronic structure using variational quantum algorithms. We construct fermionic Hamiltonians from experimentally determined protein structures, map them to qubits via Jordan-Wigner transformation, and optimize ground state energies using the Variational Quantum Eigensolver implemented in pure Python. For a 4-orbital serine protease fragment, we achieve chemical accuracy (< 1.6 mHartree) with 95.3% correlation energy recovery. Systematic analysis reveals three-phase convergence behaviour with exponential decay (α = 0.95), power law optimization (γ = 1.21), and asymptotic approach. Application to SARS-CoV-2 protease inhibition demonstrates predictive accuracy (MAE=0.25 kcal/mol), while cytochrome P450 metabolism predictions achieve 85% site accuracy. Conclusions: This work establishes a pathway for quantum-enhanced biomolecular simulations on near-term quantum hardware, bridging quantum algorithm development with practical biological applications.", "AI": {"tldr": "论文主要任务是通过量子算法模拟蛋白质片段的电子结构，以促进药物发现和酶工程。", "motivation": "理解蛋白活性位点中的电子相互作用对于药物开发及酶工程技术至关重要，但由于量子力学计算指数级增长的问题而难以实现。", "method": "提出了一种基于变分量子算法的量子-经典混合框架来模拟蛋白质片段的电子结构。该方法从实验确定的蛋白质结构中构建费米子哈密顿量，并通过约旦-维格纳转换将其映射到量子比特，然后使用在纯Python中实现的变分量子特征值求解器优化基态能量。", "result": "对4轨道丝氨酸蛋白酶片段实现了化学精度（<1.6毫赫尔兹）和95.3%的相关能恢复。应用于SARS-CoV-2蛋白酶抑制剂预测，平均绝对误差为0.25千卡/摩尔；对于细胞色素P450代谢预测，则达到了85%的位点准确性。", "conclusion": "该工作建立了一种在近期量子硬件上进行量子增强生物分子模拟的方法，将量子算法发展与实际生物学应用相结合。"}}
{"id": "2601.00655", "pdf": "https://arxiv.org/pdf/2601.00655", "abs": "https://arxiv.org/abs/2601.00655", "authors": ["Kasra Fouladi", "Hamta Rahmani"], "title": "Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages", "summary": "This paper introduces Interpretability-Guided Bi-objective Optimization (IGBO), a framework that trains interpretable models by incorporating structured domain knowledge via a bi-objective formulation. IGBO encodes feature importance hierarchies as a Directed Acyclic Graph (DAG) and uses Temporal Integrated Gradients (TIG) to measure feature importance. To address the Out-of-Distribution (OOD) problem in TIG computation, we propose an Optimal Path Oracle that learns data-manifold-aware integration paths. Theoretical analysis proves convergence properties and robustness to mini-batch noise, while empirical results on time-series data demonstrate IGBO's effectiveness in enforcing DAG constraints with minimal accuracy loss, outperforming standard regularization baselines.", "AI": {"tldr": "介绍了一种通过结合结构化领域知识的双目标优化框架来训练可解释模型的方法。", "motivation": "解决传统方法在保持准确性的同时难以兼顾模型可解释性的问题，特别是在处理分布外数据时。", "method": "采用有向无环图（DAG）编码特征重要性层级，并使用时间集成梯度（TIG）衡量特征的重要性；提出最优路径预言机来学习数据流形感知的积分路径。", "result": "理论分析证明了收敛性质和对抗小批量噪声的鲁棒性，实证结果表明在时序数据上可以有效约束DAG限制并保持较高的准确性。", "conclusion": "通过双目标优化框架IGBO，在提高模型可解释性的同时保证了预测精度。"}}
{"id": "2601.00645", "pdf": "https://arxiv.org/pdf/2601.00645", "abs": "https://arxiv.org/abs/2601.00645", "authors": ["Shrikant Kapse", "Priyankkumar Dhrangdhariya", "Priya Kedia", "Manasi Patwardhan", "Shankar Kausley", "Soumyadipta Maiti", "Beena Rai", "Shirish Karande"], "title": "Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach", "categories": ["cs.CV"], "comment": null, "summary": "Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.", "AI": {"tldr": "本文通过转移学习利用CNN和Vision Transformer的方法检测储存中的土豆品质，包括芽眼检测、重量损失估计以及货架期预测。", "motivation": "基于图像的深度学习为监测存储期间土豆的质量提供了一种非侵入性的可扩展解决方案。该研究旨在解决诸如发芽检测、重量损失评估以及剩余保质期预测等关键挑战。", "method": "利用ResNet，VGG，DenseNet和Vision Transformer（ViT）的强大预训练架构设计了两种专门模型：高精度的二分类器用于发芽检测和先进的多类别预测器以估计重量损失及货架期预测。研究收集了在控制温度和湿度条件下储存200天期间的图像及相应的重量数据。", "result": "DenseNet在芽眼检测中表现出色，准确率达到98.03%；粗粒度分类（2-5个类别）下的剩余保质期预测模型表现最好，准确率超过89.83%，而细粒度分类准确性下降，因为细微的视觉差异及每个类别的数据有限。", "conclusion": "这些发现证明了将基于图像的模型集成到自动分拣和库存系统中的可行性，并支持早期识别发芽土豆以及根据存储阶段进行动态分类。实际应用包括改善库存管理、差异化定价策略以及减少整个供应链中食物浪费。未来的研究应致力于开发能够适应不同品种土豆及储存条件的一般化模型以提高适应性和可扩展性。"}}
{"id": "2601.00626", "pdf": "https://arxiv.org/pdf/2601.00626", "abs": "https://arxiv.org/abs/2601.00626", "authors": ["Shuren Gabriel Yu", "Sikang Ren", "Yongji Tian"], "title": "HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis", "categories": ["cs.CV", "cs.LG"], "comment": "6 pages, 2 figures, 2 tables", "summary": "Preoperative prognosis of Ependymoma is critical for treatment planning but challenging due to the lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail to leverage this privileged text data when it is unavailable during inference. To bridge this gap, we propose HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information (LUPI) framework. We introduce a Severed Graph Strategy, utilizing a shared encoder to process both a Teacher graph (enriched with privileged post-surgery information) and a Student graph (restricted to pre-operation data). Through dual-stream distillation, the Student learns to hallucinate semantic community structures from visual features alone. Validated on a multi-center cohort of 311 patients, HyperPriv-EPN achieves state-of-the-art diagnostic accuracy and survival stratification. This effectively transfers expert knowledge to the preoperative setting, unlocking the value of historical post-operative data to guide the diagnosis of new patients without requiring text at inference.", "AI": {"tldr": "提出了一种基于超图的利用特权信息框架HyperPriv-EPN，用于提高Ependymoma术前预后的准确性。", "motivation": "现有的多模态方法在没有特权文本数据的情况下无法有效提升预后准确性，而术后报告提供了重要的语义洞察力。为了解决这一问题，该论文提出了一个能够利用这些特权信息的新框架。", "method": "通过引入共享编码器处理包含特权信息的教师图和仅含术前数据的学生图，并采用双流蒸馏技术使学生模型学会从视觉特征中推断语义社区结构。", "result": "在311名患者的多中心队列上验证了HyperPriv-EPN，其诊断准确性和生存分层达到了当前的最佳水平。", "conclusion": "该框架成功地将专家知识转移到术前环境中，有效解锁了历史术后数据的价值，为没有文本信息的新患者提供了指导。"}}
{"id": "2601.00625", "pdf": "https://arxiv.org/pdf/2601.00625", "abs": "https://arxiv.org/abs/2601.00625", "authors": ["Junxiao Xue", "Pavel Smirnov", "Ziao Li", "Yunyun Shi", "Shi Chen", "Xinyi Yin", "Xiaohan Yue", "Lei Wang", "Yiduo Wang", "Feng Lin", "Yijia Chen", "Xiao Ma", "Xiaoran Yan", "Qing Zhang", "Fengjian Xue", "Xuecheng Wu"], "title": "RePose: A Real-Time 3D Human Pose Estimation and Biomechanical Analysis Framework for Rehabilitation", "categories": ["cs.CV"], "comment": null, "summary": "We propose a real-time 3D human pose estimation and motion analysis method termed RePose for rehabilitation training. It is capable of real-time monitoring and evaluation of patients'motion during rehabilitation, providing immediate feedback and guidance to assist patients in executing rehabilitation exercises correctly. Firstly, we introduce a unified pipeline for end-to-end real-time human pose estimation and motion analysis using RGB video input from multiple cameras which can be applied to the field of rehabilitation training. The pipeline can help to monitor and correct patients'actions, thus aiding them in regaining muscle strength and motor functions. Secondly, we propose a fast tracking method for medical rehabilitation scenarios with multiple-person interference, which requires less than 1ms for tracking for a single frame. Additionally, we modify SmoothNet for real-time posture estimation, effectively reducing pose estimation errors and restoring the patient's true motion state, making it visually smoother. Finally, we use Unity platform for real-time monitoring and evaluation of patients' motion during rehabilitation, and to display the muscle stress conditions to assist patients with their rehabilitation training.", "AI": {"tldr": "提出了一种用于康复训练的实时人体姿态估计和运动分析方法RePose。", "motivation": "为了实现对患者康复过程中动作的实时监控与反馈，提高康复效果。", "method": "开发了一个统一的端到端管道，使用RGB视频输入实现实时3D人体姿态估计和运动分析。此外还提出了一种快速跟踪方法以处理多个人体相互干扰的情况，并修改了SmoothNet算法以减少姿势估计误差。", "result": "该框架能够提供实时监测、纠正患者动作的功能，有助于恢复肌肉力量和运动功能。", "conclusion": "RePose可以有效辅助康复训练，提升患者的康复效果。"}}
{"id": "2601.00623", "pdf": "https://arxiv.org/pdf/2601.00623", "abs": "https://arxiv.org/abs/2601.00623", "authors": ["Longtian Qiu", "Shan Ning", "Chuyu Zhang", "Jiaxuan Sun", "Xuming He"], "title": "DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations", "categories": ["cs.AI"], "comment": "Accepted by TMLR", "summary": "Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.", "AI": {"tldr": "本文提出了一种成本效益高的难度感知偏好优化框架，用于减少多模态大型语言模型的幻觉。", "motivation": "现有的多模态直接偏好优化方法由于偏置数据的难度不平衡而容易过拟合。为了解决这个问题，作者提出了困难感知直接偏好优化（DA-DPO）框架。", "method": "该框架包括两个主要组件：一是利用预训练的视觉-语言模型来估计样本的难度；二是根据每个样本的难度重新加权偏好对，减轻过拟合并使模型更加关注难以区分的情况。", "result": "实验结果表明，DA-DPO能显著改善多模态偏好优化，并且在标准基准上表现出更强的幻觉鲁棒性和更好的泛化能力，同时保持了计算效率。", "conclusion": "该框架通过优先处理困难样本而无需额外的数据或微调阶段来提高偏好优化效果。"}}
{"id": "2601.00617", "pdf": "https://arxiv.org/pdf/2601.00617", "abs": "https://arxiv.org/abs/2601.00617", "authors": ["Huixin Sun", "Linlin Yang", "Ronyu Chen", "Kerui Gu", "Baochang Zhang", "Angela Yao", "Xianbin Cao"], "title": "Noise-Robust Tiny Object Localization with Flows", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 5 figures", "summary": "Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.", "AI": {"tldr": "本文提出了Tiny Object Localization with Flows (TOLF) 方法，旨在解决小目标定位中的噪声敏感性问题。", "motivation": "研究指出，在小目标定位任务中，由于标注噪音的影响，现有方法难以达到与大尺度对象相同的性能表现。因此，需要一种新的框架来提高对噪声的鲁棒性和优化学习过程，以减少过拟合风险。", "method": "TOLF利用归一化流进行灵活的误差建模，并通过不确定性引导的优化实现稳健学习。该方法能捕捉复杂的非高斯预测分布，同时采用基于不确定性的梯度调节机制来抑制噪声样本的学习，从而稳定训练过程。", "result": "实验结果表明，与DINO基线相比，在AI-TOD数据集上TOLF提升了1.2%的AP。", "conclusion": "该研究提出了一种新的方法来提高小目标定位任务中的鲁棒性和准确性。"}}
{"id": "2601.00614", "pdf": "https://arxiv.org/pdf/2601.00614", "abs": "https://arxiv.org/abs/2601.00614", "authors": ["Mogens Plessen"], "title": "From 2D to 3D terrain-following area coverage path planning", "categories": ["cs.RO", "eess.SY"], "comment": "6 pages, 10 figures, 1 table", "summary": "An algorithm for 3D terrain-following area coverage path planning is presented. Multiple adjacent paths are generated that are (i) locally apart from each other by a distance equal to the working width of a machinery, while (ii) simultaneously floating at a projection distance equal to a specific working height above the terrain. The complexities of the algorithm in comparison to its 2D equivalent are highlighted. These include uniformly spaced elevation data generation using an Inverse Distance Weighting-approach and a local search. Area coverage path planning results for real-world 3D data within an agricultural context are presented to validate the algorithm.", "AI": {"tldr": "提出了一种用于三维地形跟随区域覆盖路径规划的算法。", "motivation": "为了在农业环境中实现高效的三维区域覆盖，该论文提出了一个基于二维平面路径规划的方法，并扩展到三维空间中。", "method": "利用逆距离加权方法生成均匀分布的高度数据，并通过局部搜索优化路径规划。", "result": "展示了使用真实世界3D数据进行区域覆盖路径规划的结果，验证了算法的有效性。", "conclusion": "该算法能够有效地在农业环境中实现三维地形跟随的区域覆盖路径规划。"}}
{"id": "2601.00611", "pdf": "https://arxiv.org/pdf/2601.00611", "abs": "https://arxiv.org/abs/2601.00611", "authors": ["Hareshkumar Jadav", "Ranveer Singh", "Vaneet Aggarwal"], "title": "Stronger Approximation Guarantees for Non-Monotone γ-Weakly DR-Submodular Maximization", "categories": ["cs.LG", "cs.AI", "cs.CC", "math.OC"], "comment": "Extended version of paper accepted in AAMAS 2026", "summary": "Maximizing submodular objectives under constraints is a fundamental problem in machine learning and optimization. We study the maximization of a nonnegative, non-monotone $γ$-weakly DR-submodular function over a down-closed convex body. Our main result is an approximation algorithm whose guarantee depends smoothly on $γ$; in particular, when $γ=1$ (the DR-submodular case) our bound recovers the $0.401$ approximation factor, while for $γ<1$ the guarantee degrades gracefully and, it improves upon previously reported bounds for $γ$-weakly DR-submodular maximization under the same constraints. Our approach combines a Frank-Wolfe-guided continuous-greedy framework with a $γ$-aware double-greedy step, yielding a simple yet effective procedure for handling non-monotonicity. This results in state-of-the-art guarantees for non-monotone $γ$-weakly DR-submodular maximization over down-closed convex bodies.", "AI": {"tldr": "研究在下闭凸体约束下非负、非单调γ弱次梯度子模最大化问题，提出一种新的近似算法。", "motivation": "为了提高非单调γ弱次梯度子模函数最大化的近似保证，在特定的约束条件下寻找更好的解法。", "method": "采用Frank-Wolfe引导的连续贪婪框架和γ感知双贪心步骤来处理非单调性问题。", "result": "提出的方法在γ=1时达到0.401近似因子，对于γ<1的情况保证平滑下降，并改进了已有的非单调γ弱次梯度子模最大化的界限。", "conclusion": "该研究为非单调γ弱次梯度子模最大化提供了状态-of-the-art的近似保证。"}}
{"id": "2601.00610", "pdf": "https://arxiv.org/pdf/2601.00610", "abs": "https://arxiv.org/abs/2601.00610", "authors": ["Mehdi Heydari Shahna", "Pauli Mustalahti", "Jouni Mattila"], "title": "Vision-based Goal-Reaching Control for Mobile Robots Using a Hierarchical Learning Framework", "categories": ["cs.RO"], "comment": null, "summary": "Reinforcement learning (RL) is effective in many robotic applications, but it requires extensive exploration of the state-action space, during which behaviors can be unsafe. This significantly limits its applicability to large robots with complex actuators operating on unstable terrain. Hence, to design a safe goal-reaching control framework for large-scale robots, this paper decomposes the whole system into a set of tightly coupled functional modules. 1) A real-time visual pose estimation approach is employed to provide accurate robot states to 2) an RL motion planner for goal-reaching tasks that explicitly respects robot specifications. The RL module generates real-time smooth motion commands for the actuator system, independent of its underlying dynamic complexity. 3) In the actuation mechanism, a supervised deep learning model is trained to capture the complex dynamics of the robot and provide this model to 4) a model-based robust adaptive controller that guarantees the wheels track the RL motion commands even on slip-prone terrain. 5) Finally, to reduce human intervention, a mathematical safety supervisor monitors the robot, stops it on unsafe faults, and autonomously guides it back to a safe inspection area. The proposed framework guarantees uniform exponential stability of the actuation system and safety of the whole operation. Experiments on a 6,000 kg robot in different scenarios confirm the effectiveness of the proposed framework.", "AI": {"tldr": "提出了一个基于视觉的目标到达控制框架，用于大型移动机器人。", "motivation": "强化学习在许多机器人应用中有效，但在实际操作中需要大量的状态-动作空间探索，这可能导致不安全行为。为了解决这一问题，本文旨在设计一种适用于大型复杂机器人的目标到达的安全控制系统。", "method": "通过将系统分解成一系列紧密耦合的功能模块来实现：1）实时视觉姿态估计；2）强化学习运动规划器；3）深度监督学习模型捕捉机器人动态特性；4）基于模型的鲁棒自适应控制器保证轮子跟踪规划命令；5）数学安全监控器确保操作的安全性。", "result": "实验表明，该框架能在不同场景下有效运行，并能保证系统的统一指数稳定性以及整体操作安全性。", "conclusion": "本文提出了一种利用分层学习架构的视觉目标到达控制方法，成功应用于6000公斤级别的机器人上，在各种地形条件下均表现出色。"}}
{"id": "2601.00609", "pdf": "https://arxiv.org/pdf/2601.00609", "abs": "https://arxiv.org/abs/2601.00609", "authors": ["Mehdi Heydari Shahna", "Pauli Mustalahti", "Jouni Mattila"], "title": "NMPC-Augmented Visual Navigation and Safe Learning Control for Large-Scale Mobile Robots", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "A large-scale mobile robot (LSMR) is a high-order multibody system that often operates on loose, unconsolidated terrain, which reduces traction. This paper presents a comprehensive navigation and control framework for an LSMR that ensures stability and safety-defined performance, delivering robust operation on slip-prone terrain by jointly leveraging high-performance techniques. The proposed architecture comprises four main modules: (1) a visual pose-estimation module that fuses onboard sensors and stereo cameras to provide an accurate, low-latency robot pose, (2) a high-level nonlinear model predictive control that updates the wheel motion commands to correct robot drift from the robot reference pose on slip-prone terrain, (3) a low-level deep neural network control policy that approximates the complex behavior of the wheel-driven actuation mechanism in LSMRs, augmented with robust adaptive control to handle out-of-distribution disturbances, ensuring that the wheels accurately track the updated commands issued by high-level control module, and (4) a logarithmic safety module to monitor the entire robot stack and guarantees safe operation. The proposed low-level control framework guarantees uniform exponential stability of the actuation subsystem, while the safety module ensures the whole system-level safety during operation. Comparative experiments on a 6,000 kg LSMR actuated by two complex electro-hydrostatic drives, while synchronizing modules operating at different frequencies.", "AI": {"tldr": "提出了一种适用于大型移动机器人的导航和控制框架，确保在滑移地形上的稳定性和安全性。", "motivation": "大尺度移动机器人（LSMR）在松散、不稳定的地形上操作时，牵引力减小，需要一个综合的导航与控制系统来保障其安全运行。", "method": "该框架包括四个主要模块：视觉姿态估计模块、非线性模型预测控制模块、低级别深度神经网络控制策略以及对整个机器人堆栈的安全监控模块。", "result": "实验结果表明所提方法可保证LSMR在滑移地形上的稳定性和安全性，并且能够在不同频率下同步操作各个模块。", "conclusion": "本文提出的导航和控制系统能够有效地解决大型移动机器人在复杂环境中的稳定性和安全问题，为未来的研究提供了新的方向。"}}
{"id": "2601.00598", "pdf": "https://arxiv.org/pdf/2601.00598", "abs": "https://arxiv.org/abs/2601.00598", "authors": ["Xianhui Liu", "Siqi Jiang", "Yi Xie", "Yuqing Lin", "Siao Liu"], "title": "Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception", "categories": ["cs.CV"], "comment": null, "summary": "RGB-Infrared (RGB-IR) multimodal perception is fundamental to embodied multimedia systems operating in complex physical environments. Although recent cross-modal fusion methods have advanced RGB-IR detection, the optimization dynamics caused by asymmetric modality characteristics remain underexplored. In practice, disparities in information density and feature quality introduce persistent optimization bias, leading training to overemphasize a dominant modality and hindering effective fusion. To quantify this phenomenon, we propose the Modality Dominance Index (MDI), which measures modality dominance by jointly modeling feature entropy and gradient contribution. Based on MDI, we develop a Modality Dominance-Aware Cross-modal Learning (MDACL) framework that regulates cross-modal optimization. MDACL incorporates Hierarchical Cross-modal Guidance (HCG) to enhance feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics during fusion. Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves SOTA performance.", "AI": {"tldr": "本文提出了一种用于RGB和红外融合感知的模态主导意识优化框架，以缓解训练过程中的优化偏见。", "motivation": "在复杂的物理环境中，由于信息密度和特征质量的不同导致了持久性的优化偏差，使得训练倾向于强调一种主导模式，并阻碍有效的跨模态融合。为了解决这个问题，本文提出了MDI来量化这种现象，并基于MDI开发了一种新的框架来调节跨模态优化。", "method": "提出Modality Dominance-Aware Cross-modal Learning (MDACL) 框架，包括Hierarchical Cross-modal Guidance（HCG）和Adversarial Equilibrium Regularization（AER），以增强特征对齐并平衡融合过程中的优化动态。", "result": "在三个RGB-IR基准测试上进行的广泛实验表明，MDACL有效地缓解了优化偏见，并取得了最先进的性能。", "conclusion": "通过解决训练过程中由于模态特性差异引起的持续优化偏差问题，MDACL框架为提高RGB和红外融合感知的效果提供了一种新的方法。"}}
{"id": "2601.00592", "pdf": "https://arxiv.org/pdf/2601.00592", "abs": "https://arxiv.org/abs/2601.00592", "authors": ["Sanjida Islam Era", "Ishika Tarin Ime", "A. B. M. Alim Al Islam"], "title": "Evaluating Web Accessibility and Usability in Bangladesh: A Comparative Analysis of Government and Non-Government Websites", "categories": ["cs.HC"], "comment": null, "summary": "Ensuring digital accessibility is essential for inclusive access to online services. However, many government and non-government websites that provide critical services - such as education, healthcare, and public administration - continue to exhibit significant accessibility and usability barriers. This study evaluates the accessibility of Bangladeshi government and non-government websites under WCAG~2.2 by combining automated accessibility assessments with user-reported feedback. A total of 212 websites were analyzed using multiple automated tools, complemented by a survey of 103 users to capture real-world usability, accessibility, and security experiences. The results reveal substantial disparities between government and non-government websites, highlighting persistent issues related to navigation complexity, interaction cost, visual readability, accessibility feature adoption, and authentication mechanisms. While non-government websites generally demonstrate better usability and functional performance, accessibility support remains inconsistent across both categories. The findings underscore the need for regular accessibility audits, user-centered design practices, and policy-driven interventions to improve digital inclusivity and ensure equitable access to online services for diverse user populations.", "AI": {"tldr": "评估孟加拉国政府和非政府网站的网络无障碍性和可用性。", "motivation": "确保数字访问对于包容性的在线服务至关重要。但是，提供教育、医疗保健和公共行政等关键服务的许多网站仍然存在显著的可访问性和易用性障碍。", "method": "使用自动化工具对212个网站进行评估，并通过调查收集了103名用户的反馈。", "result": "结果显示政府网站与非政府网站之间在导航复杂度、交互成本、视觉清晰度、无障碍特性的采用和认证机制方面存在显著差异。", "conclusion": "研究强调需要定期进行无障碍审核，采用以用户为中心的设计实践，并采取政策驱动的干预措施来提高数字包容性并确保不同人群平等访问在线服务。"}}
{"id": "2601.00590", "pdf": "https://arxiv.org/pdf/2601.00590", "abs": "https://arxiv.org/abs/2601.00590", "authors": ["Yiling Wang", "Zeyu Zhang", "Yiran Wang", "Hao Tang"], "title": "SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.", "AI": {"tldr": "SafeMo提出了一个可信的文本到动作生成框架，通过最小化运动卸载(MMU)策略来解决现有方法的安全性和性能问题。", "motivation": "现有的文本到动作(T2M)生成模型存在安全风险，包括代码替换导致的任务漂移和量化损失，以及训练数据中的不安全意图。SafeMo旨在克服这些问题，并提供一种新的卸载技术以提高安全性。", "method": "SafeMo采用两阶段机器卸载策略，在连续空间中生成安全的人类动作序列，同时保持平滑的自然过渡并保留良好的性能。", "result": "实验表明，SafeMo在不牺牲正常提示性能的情况下显著提高了对危险提示的记忆清除效果，比现有最佳方法LCP高2.5倍和14.4倍。", "conclusion": "通过引入MMU策略和构建安全训练集，SafeMo成功地提高了文本到动作生成的安全性和实用性。"}}
{"id": "2601.00584", "pdf": "https://arxiv.org/pdf/2601.00584", "abs": "https://arxiv.org/abs/2601.00584", "authors": ["Mingyu Jeon", "Sunjae Yoon", "Jonghee Kim", "Junyeoung Kim"], "title": "GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval", "categories": ["cs.CV"], "comment": "Accepted to AAAI 2026", "summary": "Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.", "AI": {"tldr": "提出了一种无训练框架GranAlign，用于解决零样本视频时刻检索中的语义粒度不匹配问题", "motivation": "现有方法未能平衡文本查询和视觉内容之间的语义粒度，在没有依赖特定任务的训练数据的情况下进行准确的零样本视频时刻检索时遇到挑战", "method": "引入了基于粒度的查询重写和技术意识的字幕生成，通过配对多层次查询与无查询意识及有查询意识的字幕，解决语义不匹配问题", "result": "在QVHighlights、Charades-STA和ActivityNet-Captions三个主要基准测试中均达到新的最先进水平，特别是在挑战性较大的QVHighlights数据集上实现了3.23% mAP@avg的显著提升", "conclusion": "GranAlign通过解决语义粒度不匹配问题，显著改善了零样本视频时刻检索任务的表现"}}
{"id": "2601.00583", "pdf": "https://arxiv.org/pdf/2601.00583", "abs": "https://arxiv.org/abs/2601.00583", "authors": ["Zihan Fang", "Zheng Lin", "Senkang Hu", "Yanan Ma", "Yihang Tao", "Yiqin Deng", "Xianhao Chen", "Yuguang Fang"], "title": "HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts", "categories": ["cs.LG", "cs.AI", "cs.NI"], "comment": "14 pages, 16 figures", "summary": "While federated learning (FL) enables fine-tuning of large language models (LLMs) without compromising data privacy, the substantial size of an LLM renders on-device training impractical for resource-constrained clients, such as mobile devices. Thus, Mixture-of-Experts (MoE) models have emerged as a computation-efficient solution, which activates only a sparse subset of experts during model training to reduce computing burden without sacrificing performance. Though integrating MoE into FL fine-tuning holds significant potential, it still encounters three key challenges: i) selecting appropriate experts for clients remains challenging due to the lack of a reliable metric to measure each expert's impact on local fine-tuning performance, ii) the heterogeneous computing resources across clients severely hinder MoE-based LLM fine-tuning, as dynamic expert activations across diverse input samples can overwhelm resource-constrained devices, and iii) client-specific expert subsets and routing preference undermine global aggregation, where misaligned expert updates and inconsistent gating networks in troduce destructive interference. To address these challenges, we propose HFedMoE, a heterogeneous MoE-based FL fine-tuning framework that customizes a subset of experts to each client for computation-efficient LLM fine-tuning. Specifically, HFedMoE identifies the expert importance based on its contributions to fine-tuning performance, and then adaptively selects a subset of experts from an information bottleneck perspective to align with each client' s computing budget. A sparsity-aware model aggregation strategy is also designed to aggregate the actively fine-tuned experts and gating parameters with importance weighted contributions. Extensive experiments demonstrate that HFedMoE outperforms state-of-the-art benchmarks in training accuracy and convergence speed.", "AI": {"tldr": "提出HFedMoE框架，解决资源受限设备上混合专家模型联邦学习的挑战", "motivation": "大型语言模型在联邦学习中的训练对资源有限的客户端不友好，为了解决这个问题并提高性能和效率，研究者们开发了HFedMoE框架。", "method": "根据每个专家对于微调性能的影响来定制一个专家子集给每个客户端，并设计了一个稀疏感知模型聚合策略以整合活跃微调的专家和门控参数", "result": "实验证明HFedMoE在训练准确性和收敛速度上优于现有的基准方法。", "conclusion": "提出的HFedMoE框架能够有效地解决联邦学习中资源受限设备的问题，提高了大型语言模型的微调性能和效率。"}}
{"id": "2601.00580", "pdf": "https://arxiv.org/pdf/2601.00580", "abs": "https://arxiv.org/abs/2601.00580", "authors": ["Kanghoon Lee", "Hyeonjun Kim", "Jiachen Li", "Jinkyoo Park"], "title": "Priority-Aware Multi-Robot Coverage Path Planning", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": "IEEE Robotics and Automation Letters, 8 pages, 10 figures", "summary": "Multi-robot systems are widely used for coverage tasks that require efficient coordination across large environments. In Multi-Robot Coverage Path Planning (MCPP), the objective is typically to minimize the makespan by generating non-overlapping paths for full-area coverage. However, most existing methods assume uniform importance across regions, limiting their effectiveness in scenarios where some zones require faster attention. We introduce the Priority-Aware MCPP (PA-MCPP) problem, where a subset of the environment is designated as prioritized zones with associated weights. The goal is to minimize, in lexicographic order, the total priority-weighted latency of zone coverage and the overall makespan. To address this, we propose a scalable two-phase framework combining (1) greedy zone assignment with local search, spanning-tree-based path planning, and (2) Steiner-tree-guided residual coverage. Experiments across diverse scenarios demonstrate that our method significantly reduces priority-weighted latency compared to standard MCPP baselines, while maintaining competitive makespan. Sensitivity analyses further show that the method scales well with the number of robots and that zone coverage behavior can be effectively controlled by adjusting priority weights.", "AI": {"tldr": "本文提出了一种优先级感知的多机器人覆盖路径规划方法，旨在提高对不同重要性区域的有效响应。", "motivation": "现有的多机器人覆盖路径规划方法未能充分考虑环境中的差异化需求，导致某些需要快速关注的区域未得到及时处理。因此，引入了优先级概念来优化系统性能。", "method": "提出了一个两阶段框架结合贪婪区分配和局部搜索、基于跨度树的路径规划以及斯坦纳树引导剩余覆盖策略，以最小化带权延迟和整体完成时间。", "result": "实验表明该方法相比于标准多机器人覆盖路径规划基准方法显著减少了优先级加权延迟，并保持了具有竞争力的整体完成时间。", "conclusion": "研究证明提出的优先级感知多机器人覆盖路径规划框架能够在多种场景下有效提高系统性能，同时还能通过调整优先级权重来控制区域覆盖率。"}}
{"id": "2601.00579", "pdf": "https://arxiv.org/pdf/2601.00579", "abs": "https://arxiv.org/abs/2601.00579", "authors": ["Obada Kraishan"], "title": "The AI Invisibility Effect: Understanding Human-AI Interaction When Users Don't Recognize Artificial Intelligence", "categories": ["cs.HC"], "comment": "18 pages, 4 figures, 8 tables. Data and code available upon request", "summary": "The fast integration of artificial intelligence into mobile applications has completely changed the digital landscape; however, the impact of this change on user perception of AI features remains poorly understood. This large-scale analysis examined 1,484,633 mobile application reviews across 422 applications (200 AI-featuring, 222 control) from iOS App Store and Google Play Store. By employing sentiment classification, topic modeling, and concern-benefit categorization, we identified a major disconnect: only 11.9% of reviews mentioned AI, even though 47.4% of applications featured AI capabilities. AI-featuring applications received significantly lower ratings than traditional applications (d = 0.40); however, hierarchical regression revealed a hidden pattern - the negative relationship reversed after controlling for AI mentions and review characteristics (b = 0.405, p < .001). Privacy dominated user concerns (34.8% of concern-expressing reviews), while efficiency represented the primary benefit (42.3%). Effects varied greatly by category, from positive for Assistant applications (d = 0.55) to negative for Entertainment (d = -0.23). These findings suggest that AI features often operate below user awareness thresholds, and it is the explicit recognition of AI, rather than its mere presence, that drives negative evaluations. This challenges basic assumptions about technology acceptance in AI systems.", "AI": {"tldr": "分析了用户在移动应用中对AI功能的认识和评价，发现了当用户不明确意识到AI存在时的负面效果。", "motivation": "探讨人工智能快速集成到应用程序中的情况下，用户的感知变化以及这种变化如何影响他们对AI特性的认识与评价。", "method": "通过大规模分析来自苹果App Store和Google Play Store的422款应用（其中200款包含AI功能）共1,484,633条用户评论，运用情感分类、主题建模及关注-优势类别化等方法进行研究。", "result": "发现只有约11.9%的评论中提到了AI，而具有AI能力的应用占比为47.4%，且这些应用的整体评分低于传统应用。然而，在控制了用户提及AI和评论特征后，负面关系反转；隐私是主要担忧领域（占34.8％），效率则是最主要的优势（42.3%）。不同类别间效果差异显著。", "conclusion": "研究显示当用户未明确意识到AI存在时，其功能往往处于用户的认知阈值以下。这是导致对应用负面评价的原因之一，并挑战了关于技术接受的基本假设。"}}
{"id": "2601.00578", "pdf": "https://arxiv.org/pdf/2601.00578", "abs": "https://arxiv.org/abs/2601.00578", "authors": ["Waqas Ahmed", "Sheeba Samuel", "Kevin Coakley", "Birgitta Koenig-Ries", "Odd Erik Gundersen"], "title": "Learning to be Reproducible: Custom Loss Design for Robust Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "To enhance the reproducibility and reliability of deep learning models, we address a critical gap in current training methodologies: the lack of mechanisms that ensure consistent and robust performance across runs. Our empirical analysis reveals that even under controlled initialization and training conditions, the accuracy of the model can exhibit significant variability. To address this issue, we propose a Custom Loss Function (CLF) that reduces the sensitivity of training outcomes to stochastic factors such as weight initialization and data shuffling. By fine-tuning its parameters, CLF explicitly balances predictive accuracy with training stability, leading to more consistent and reliable model performance. Extensive experiments across diverse architectures for both image classification and time series forecasting demonstrate that our approach significantly improves training robustness without sacrificing predictive performance. These results establish CLF as an effective and efficient strategy for developing more stable, reliable and trustworthy neural networks.", "AI": {"tldr": "本文提出了一种自定义损失函数（CLF）以提高深度学习模型的可重复性和可靠性。", "motivation": "现有训练方法缺乏确保跨运行一致和稳健性能的机制，即使在受控初始化和训练条件下，模型准确性仍然存在显著差异。为解决此问题，作者提出了降低训练结果对随机因素如权重初始化和数据洗牌敏感性的方法。", "method": "通过调整其参数以平衡预测准确性和训练稳定性，设计了一种自定义损失函数（CLF）。该方法在图像分类和时间序列预测的不同架构上进行了广泛的实验验证。", "result": "结果显示，所提出的方法显著提高了模型的训练稳健性而不牺牲预测性能。", "conclusion": "自定义损失函数（CLF）作为一种有效且高效的策略，能够开发出更稳定、可靠及可信赖的神经网络。"}}
{"id": "2601.00573", "pdf": "https://arxiv.org/pdf/2601.00573", "abs": "https://arxiv.org/abs/2601.00573", "authors": ["Yihe Wang", "Zhiqiao Kang", "Bohan Chen", "Yu Zhang", "Xiang Zhang"], "title": "Benchmarking ERP Analysis: Manual Features, Deep Learning, and Foundation Models", "categories": ["cs.NE", "cs.CE"], "comment": "This work is submitted to the IEEE for possible publication", "summary": "Event-related potential (ERP), a specialized paradigm of electroencephalographic (EEG), reflects neurological responses to external stimuli or events, generally associated with the brain's processing of specific cognitive tasks. ERP plays a critical role in cognitive analysis, the detection of neurological diseases, and the assessment of psychological states. Recent years have seen substantial advances in deep learning-based methods for spontaneous EEG and other non-time-locked task-related EEG signals. However, their effectiveness on ERP data remains underexplored, and many existing ERP studies still rely heavily on manually extracted features. In this paper, we conduct a comprehensive benchmark study that systematically compares traditional manual features (followed by a linear classifier), deep learning models, and pre-trained EEG foundation models for ERP analysis. We establish a unified data preprocessing and training pipeline and evaluate these approaches on two representative tasks, ERP stimulus classification and ERP-based brain disease detection, across 12 publicly available datasets. Furthermore, we investigate various patch-embedding strategies within advanced Transformer architectures to identify embedding designs that better suit ERP data. Our study provides a landmark framework to guide method selection and tailored model design for future ERP analysis. The code is available at https://github.com/DL4mHealth/ERP-Benchmark.", "AI": {"tldr": "本文进行了系统性基准研究，对比了传统手动特征、深度学习模型和预训练的EEG基础模型在ERP分析中的表现。", "motivation": "近年来，在自发EEG和其他非时间锁定任务相关EEG信号上基于深度学习的方法有了显著进展。然而，这些方法在ERP数据上的有效性仍需探索。许多现有研究仍然依赖手动提取特征。本文旨在填补这一空白，推动ERP分析领域的进步。", "method": "文章建立了统一的数据预处理和训练流程，并使用线性分类器、深度学习模型和EEG基础模型对12个公开数据集进行了评估。此外，探讨了高级Transformer架构中的各种patch嵌入策略以适应ERP数据。", "result": "研究结果表明不同的方法在ERP刺激分类和基于ERP的脑疾病检测任务上表现出不同性能，提供了一种指导未来ERP分析的方法选择和模型设计框架。", "conclusion": "本文通过系统性基准研究明确了传统手动特征、深度学习模型及EEG基础模型之间的差异，并为未来的ERP分析提供了方法选择与模型设计的指南。"}}
{"id": "2601.00570", "pdf": "https://arxiv.org/pdf/2601.00570", "abs": "https://arxiv.org/abs/2601.00570", "authors": ["Ananya Bhattacharjee", "Jina Suh", "Mohit Chandra", "Javier Hernandez"], "title": "User Perceptions of an LLM-Based Chatbot for Cognitive Reappraisal of Stress: Feasibility Study", "categories": ["cs.HC"], "comment": null, "summary": "Cognitive reappraisal is a well-studied emotion regulation strategy that helps individuals reinterpret stressful situations to reduce their impact. Many digital mental health tools struggle to support this process because rigid scripts fail to accommodate how users naturally describe stressors. This study examined the feasibility of an LLM-based single-session intervention (SSI) for workplace stress reappraisal. We assessed short-term changes in stress-related outcomes and examined design tensions during use. We conducted a feasibility study with 100 employees at a large technology company who completed a structured cognitive reappraisal session delivered by a GPT-4o-based chatbot. Pre-post measures included perceived stress intensity, stress mindset, perceived demand, and perceived resources. These outcomes were analyzed using paired Wilcoxon signed-rank tests with correction for multiple comparisons. We also examined sentiment and stress trajectories across conversation quartiles using two RoBERTa-based classifiers and an LLM-based stress rater. Open-ended responses were analyzed using thematic analysis. Results showed significant reductions in perceived stress intensity and significant improvements in stress mindset. Changes in perceived resources and perceived demand trended in expected directions but were not statistically significant. Automated analyses indicated consistent declines in negative sentiment and stress over the course of the interaction. Qualitative findings suggested that participants valued the structured prompts for organizing thoughts, gaining perspective, and feeling acknowledged. Participants also reported tensions around scriptedness, preferred interaction length, and reactions to AI-driven empathy. These findings highlight both the promise and the design constraints of integrating LLMs into DMH interventions for workplace settings.", "AI": {"tldr": "研究探讨了基于LLM的聊天机器人在职场压力重评中的可行性。", "motivation": "许多数字心理健康工具难以支持认知重评过程，因为固定的脚本无法适应用户自然描述的压力情况。因此，该研究旨在评估一个基于GPT-4o的聊天机器人的单次干预是否可行，以帮助员工应对工作压力。", "method": "进行了为期一天的可行性研究，参与者为100名大公司的员工。通过聊天机器人提供结构化的认知重评会话，并使用配对Wilcoxon符号秩检验分析了相关结果变化趋势。同时，利用两个基于RoBERTa的情感分类器和一个LLM压力评分系统进行自动分析。", "result": "结果显示，在感知的压力强度和压力心态方面有显著改善。虽然感知资源和需求的变化也在预期的方向上，但未达到统计学意义。自动化分析显示负面情绪和压力在互动过程中持续下降。", "conclusion": "研究结果表明，将LLM整合到数字心理健康干预措施中有潜力也有设计上的挑战。参与者重视结构化提示来组织思想、获得新视角并感到被理解；但也提出了一些关于脚本性、交互长度以及对AI驱动的同情反应的问题。"}}
