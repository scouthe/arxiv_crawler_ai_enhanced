{"id": "2601.07835", "pdf": "https://arxiv.org/pdf/2601.07835", "abs": "https://arxiv.org/abs/2601.07835", "authors": ["Mohammed Himayath Ali", "Mohammed Aqib Abdullah", "Mohammed Mudassir Uddin", "Shahnawaz Alam"], "title": "SecureCAI: Injection-Resilient LLM Assistants for Cybersecurity Operations", "categories": ["cs.CR", "cs.CV"], "comment": null, "summary": "Large Language Models have emerged as transformative tools for Security Operations Centers, enabling automated log analysis, phishing triage, and malware explanation; however, deployment in adversarial cybersecurity environments exposes critical vulnerabilities to prompt injection attacks where malicious instructions embedded in security artifacts manipulate model behavior. This paper introduces SecureCAI, a novel defense framework extending Constitutional AI principles with security-aware guardrails, adaptive constitution evolution, and Direct Preference Optimization for unlearning unsafe response patterns, addressing the unique challenges of high-stakes security contexts where traditional safety mechanisms prove insufficient against sophisticated adversarial manipulation. Experimental evaluation demonstrates that SecureCAI reduces attack success rates by 94.7% compared to baseline models while maintaining 95.1% accuracy on benign security analysis tasks, with the framework incorporating continuous red-teaming feedback loops enabling dynamic adaptation to emerging attack strategies and achieving constitution adherence scores exceeding 0.92 under sustained adversarial pressure, thereby establishing a foundation for trustworthy integration of language model capabilities into operational cybersecurity workflows and addressing a critical gap in current approaches to AI safety within adversarial domains.", "AI": {"tldr": "提出了一种新的防御框架SecureCAI，用于防止大型语言模型在网络安全操作中受到提示注入攻击。", "motivation": "大型语言模型在安全运营中心的应用面临来自恶意指令的提示注入攻击威胁，这些攻击可以操纵模型行为。传统的安全机制对此类复杂攻击无能为力。", "method": "SecureCAI通过扩展宪法AI原则、引入安全意识的防护措施、自适应宪法演化以及直接偏好优化来实现对不安全响应模式的学习和遗忘，以应对高风险的安全环境中的独特挑战。", "result": "实验结果显示，与基线模型相比，SecureCAI将攻击成功率降低了94.7%，同时保持了在良性安全分析任务上超过95.1%的准确率。此外，在持续对抗压力下实现了超出0.92的宪法遵循得分，显示了其动态适应新兴攻击策略的能力。", "conclusion": "SecureCAI为语言模型能力与网络安全操作的安全集成奠定了基础，并解决了当前AI安全领域在对抗环境中的重要空白。"}}
{"id": "2601.07833", "pdf": "https://arxiv.org/pdf/2601.07833", "abs": "https://arxiv.org/abs/2601.07833", "authors": ["Maxwell Jones", "Rameen Abdal", "Or Patashnik", "Ruslan Salakhutdinov", "Sergey Tulyakov", "Jun-Yan Zhu", "Kuan-Chieh Jackson Wang"], "title": "Tuning-free Visual Effect Transfer across Videos", "categories": ["cs.CV"], "comment": "Project Page: $\\href{https://tuningfreevisualeffects-maker.github.io/Tuning-free-Visual-Effect-Transfer-across-Videos-Project-Page/}{this\\ URL}$", "summary": "We present RefVFX, a new framework that transfers complex temporal effects from a reference video onto a target video or image in a feed-forward manner. While existing methods excel at prompt-based or keyframe-conditioned editing, they struggle with dynamic temporal effects such as dynamic lighting changes or character transformations, which are difficult to describe via text or static conditions. Transferring a video effect is challenging, as the model must integrate the new temporal dynamics with the input video's existing motion and appearance. % To address this, we introduce a large-scale dataset of triplets, where each triplet consists of a reference effect video, an input image or video, and a corresponding output video depicting the transferred effect. Creating this data is non-trivial, especially the video-to-video effect triplets, which do not exist naturally. To generate these, we propose a scalable automated pipeline that creates high-quality paired videos designed to preserve the input's motion and structure while transforming it based on some fixed, repeatable effect. We then augment this data with image-to-video effects derived from LoRA adapters and code-based temporal effects generated through programmatic composition. Building on our new dataset, we train our reference-conditioned model using recent text-to-video backbones. Experimental results demonstrate that RefVFX produces visually consistent and temporally coherent edits, generalizes across unseen effect categories, and outperforms prompt-only baselines in both quantitative metrics and human preference. See our website $\\href{https://tuningfreevisualeffects-maker.github.io/Tuning-free-Visual-Effect-Transfer-across-Videos-Project-Page/}{at\\ this\\ URL}$.", "AI": {"tldr": "该论文提出了一种新的框架，用于在视频或图像上转移复杂的时间效果。", "motivation": "现有的方法虽然擅长基于提示或关键帧的编辑，但在处理动态时间效应（如光线变化或角色变换）方面存在困难。这些动态效应难以通过文本或静态条件描述。", "method": "该研究提出了一种新的大规模数据集，包括参考效果视频、输入图像或视频以及相应的输出视频，展示了转移的效果。为此，研究人员开发了一个可扩展的自动化管道来生成高质量配对的视频，并通过LoRA适配器和程序化组合产生代码驱动的时间效应。", "result": "实验结果表明，该框架能够生产视觉上一致且时间连贯的编辑效果，在未见过的效果类别中具有泛化能力，并在定量指标和人类偏好测试中优于基于提示的方法。", "conclusion": "提出的RefVFX框架成功地解决了视频间复杂动态时间效应转移的问题，展示了其有效性和优越性。"}}
{"id": "2601.07832", "pdf": "https://arxiv.org/pdf/2601.07832", "abs": "https://arxiv.org/abs/2601.07832", "authors": ["Kewei Zhang", "Ye Huang", "Yufan Deng", "Jincheng Yu", "Junsong Chen", "Huan Ling", "Enze Xie", "Daquan Zhou"], "title": "MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head", "categories": ["cs.CV", "cs.AI"], "comment": "Code: https://github.com/DAGroup-PKU/MHLA/ Project website: https://dagroup-pku.github.io/MHLA/", "summary": "While the Transformer architecture dominates many fields, its quadratic self-attention complexity hinders its use in large-scale applications. Linear attention offers an efficient alternative, but its direct application often degrades performance, with existing fixes typically re-introducing computational overhead through extra modules (e.g., depthwise separable convolution) that defeat the original purpose. In this work, we identify a key failure mode in these methods: global context collapse, where the model loses representational diversity. To address this, we propose Multi-Head Linear Attention (MHLA), which preserves this diversity by computing attention within divided heads along the token dimension. We prove that MHLA maintains linear complexity while recovering much of the expressive power of softmax attention, and verify its effectiveness across multiple domains, achieving a 3.6\\% improvement on ImageNet classification, a 6.3\\% gain on NLP, a 12.6\\% improvement on image generation, and a 41\\% enhancement on video generation under the same time complexity.", "AI": {"tldr": "提出了一种多头线性注意力机制（MHLA），以在保持低复杂度的同时恢复线性注意的表达能力。", "motivation": "现有方法通过引入额外模块来解决线性注意力性能下降的问题，但这些额外模块增加了计算开销。作者发现这会导致全局上下文崩溃，模型失去表示多样性，因此提出MHLA来解决此问题。", "method": "将注意力机制分为多个头，并在令牌维度上独立进行，从而保持表达多样性同时维持线性复杂度。", "result": "实验表明，MHLA在图像分类、NLP、图像生成和视频生成任务中均优于现有方法，在同等时间复杂度下分别提高了3.6%，6.3%，12.6%和41%的性能。", "conclusion": "MHLA不仅有效解决了线性注意力中的全局上下文崩溃问题，而且在多个领域取得了显著改进。"}}
{"id": "2601.07830", "pdf": "https://arxiv.org/pdf/2601.07830", "abs": "https://arxiv.org/abs/2601.07830", "authors": ["Valentina Njaradi", "Rodrigo Carrasco-Davis", "Peter E. Latham", "Andrew Saxe"], "title": "Optimal Learning Rate Schedule for Balancing Effort and Performance", "categories": ["cs.LG", "cs.NE", "q-bio.NC"], "comment": null, "summary": "Learning how to learn efficiently is a fundamental challenge for biological agents and a growing concern for artificial ones. To learn effectively, an agent must regulate its learning speed, balancing the benefits of rapid improvement against the costs of effort, instability, or resource use. We introduce a normative framework that formalizes this problem as an optimal control process in which the agent maximizes cumulative performance while incurring a cost of learning. From this objective, we derive a closed-form solution for the optimal learning rate, which has the form of a closed-loop controller that depends only on the agent's current and expected future performance. Under mild assumptions, this solution generalizes across tasks and architectures and reproduces numerically optimized schedules in simulations. In simple learning models, we can mathematically analyze how agent and task parameters shape learning-rate scheduling as an open-loop control solution. Because the optimal policy depends on expectations of future performance, the framework predicts how overconfidence or underconfidence influence engagement and persistence, linking the control of learning speed to theories of self-regulated learning. We further show how a simple episodic memory mechanism can approximate the required performance expectations by recalling similar past learning experiences, providing a biologically plausible route to near-optimal behaviour. Together, these results provide a normative and biologically plausible account of learning speed control, linking self-regulated learning, effort allocation, and episodic memory estimation within a unified and tractable mathematical framework.", "AI": {"tldr": "本文提出了一个优化学习速率的日程安排框架，该框架平衡了性能提升与学习努力之间的关系。", "motivation": "有效地调节学习速度对生物体和人工代理来说都是挑战。为了最大化累积绩效同时最小化学习成本（如不稳定性或资源使用），需要找到最优的学习率。", "method": "通过建立一个形式化的优化控制过程框架，作者推导出了一个闭合形式的解决方案来确定最优的学习速率，该方案依赖于当前和预期未来的表现。进一步地，简单的学习模型分析了如何根据代理和任务参数调整学习速率，并探讨了一种基于片段记忆机制近似性能期望的方法。", "result": "这个框架能够跨任务和架构泛化并且在模拟中再现数值优化的时间表。此外，它还预测了过度自信或不足信心对参与度和持续性的影响力，同时提供了一个生物上可行的途径来实现接近最优的行为。", "conclusion": "研究结果提供了一种规范且生物学合理的学习速度控制账户，将自我调节学习、努力分配与片段记忆估计联系在一个统一而可操作的数学框架中。"}}
{"id": "2601.07823", "pdf": "https://arxiv.org/pdf/2601.07823", "abs": "https://arxiv.org/abs/2601.07823", "authors": ["Zhiting Mei", "Tenny Yin", "Ola Shorinwa", "Apurva Badithela", "Zhonghe Zheng", "Joseph Bruno", "Madison Bland", "Lihan Zha", "Asher Hancock", "Jaime Fernández Fisac", "Philip Dames", "Anirudha Majumdar"], "title": "Video Generation Models in Robotics - Applications, Research Challenges, Future Directions", "categories": ["eess.SY", "cs.RO"], "comment": null, "summary": "Video generation models have emerged as high-fidelity models of the physical world, capable of synthesizing high-quality videos capturing fine-grained interactions between agents and their environments conditioned on multi-modal user inputs. Their impressive capabilities address many of the long-standing challenges faced by physics-based simulators, driving broad adoption in many problem domains, e.g., robotics. For example, video models enable photorealistic, physically consistent deformable-body simulation without making prohibitive simplifying assumptions, which is a major bottleneck in physics-based simulation. Moreover, video models can serve as foundation world models that capture the dynamics of the world in a fine-grained and expressive way. They thus overcome the limited expressiveness of language-only abstractions in describing intricate physical interactions. In this survey, we provide a review of video models and their applications as embodied world models in robotics, encompassing cost-effective data generation and action prediction in imitation learning, dynamics and rewards modeling in reinforcement learning, visual planning, and policy evaluation. Further, we highlight important challenges hindering the trustworthy integration of video models in robotics, which include poor instruction following, hallucinations such as violations of physics, and unsafe content generation, in addition to fundamental limitations such as significant data curation, training, and inference costs. We present potential future directions to address these open research challenges to motivate research and ultimately facilitate broader applications, especially in safety-critical settings.", "AI": {"tldr": "视频生成模型在机器人领域中的应用及面临的挑战和未来方向的研究综述", "motivation": "解决物理仿真器中存在的简化假设、表达能力有限等问题，提高仿真的真实性和效率。同时探讨视频生成模型在机器人领域的广泛应用及其带来的问题。", "method": "综述性文章，未提出新的方法论或实验步骤。", "result": "指出了视频生成模型应用于机器人技术中的几个关键领域，并识别了可信整合视频模型到机器人技术中所面临的挑战。", "conclusion": "提出了应对这些研究挑战的潜在未来方向，以促进更广泛的应用，特别是在安全关键场景下。"}}
{"id": "2601.07821", "pdf": "https://arxiv.org/pdf/2601.07821", "abs": "https://arxiv.org/abs/2601.07821", "authors": ["Huanyu Li", "Kun Lei", "Sheng Zang", "Kaizhe Hu", "Yongyuan Liang", "Bo An", "Xiaoli Li", "Huazhe Xu"], "title": "Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Project page: https://failure-aware-rl.github.io", "summary": "Post-training algorithms based on deep reinforcement learning can push the limits of robotic models for specific objectives, such as generalizability, accuracy, and robustness. However, Intervention-requiring Failures (IR Failures) (e.g., a robot spilling water or breaking fragile glass) during real-world exploration happen inevitably, hindering the practical deployment of such a paradigm. To tackle this, we introduce Failure-Aware Offline-to-Online Reinforcement Learning (FARL), a new paradigm minimizing failures during real-world reinforcement learning. We create FailureBench, a benchmark that incorporates common failure scenarios requiring human intervention, and propose an algorithm that integrates a world-model-based safety critic and a recovery policy trained offline to prevent failures during online exploration. Extensive simulation and real-world experiments demonstrate the effectiveness of FARL in significantly reducing IR Failures while improving performance and generalization during online reinforcement learning post-training. FARL reduces IR Failures by 73.1% while elevating performance by 11.3% on average during real-world RL post-training. Videos and code are available at https://failure-aware-rl.github.io.", "AI": {"tldr": "介绍了一种新的强化学习框架Failure-Aware RL（FARL），用于减少真实世界操作中的干预性失败，提高机器人模型的鲁棒性和泛化能力。", "motivation": "针对基于深度强化学习的后训练算法在实际部署时可能遇到的操作失败问题，特别是需要人工介入的情况，提出了新的解决方案来最小化此类事件的发生。", "method": "构建了一个包含常见干预性故障场景的数据集FailureBench，并提出了一种结合世界模型安全批评家和离线训练恢复策略的新方法FARL，以预防在线探索中的失败。", "result": "模拟实验与真实世界的测试表明，FARL能够显著降低干预性失败率73.1%，同时提升平均性能11.3%。", "conclusion": "通过引入Failure-Aware RL（FARL），在实际操作中实现了减少故障、增强鲁棒性和提高泛化能力的目标。"}}
{"id": "2601.07813", "pdf": "https://arxiv.org/pdf/2601.07813", "abs": "https://arxiv.org/abs/2601.07813", "authors": ["Francisco Leiva", "Claudio Canales", "Michelle Valenzuela", "Javier Ruiz-del-Solar"], "title": "Data-driven control of hydraulic impact hammers under strict operational and control constraints", "categories": ["cs.RO"], "comment": "21 pages, 14 figures", "summary": "This paper presents a data-driven methodology for the control of static hydraulic impact hammers, also known as rock breakers, which are commonly used in the mining industry. The task addressed in this work is that of controlling the rock-breaker so its end-effector reaches arbitrary target poses, which is required in normal operation to place the hammer on top of rocks that need to be fractured. The proposed approach considers several constraints, such as unobserved state variables due to limited sensing and the strict requirement of using a discrete control interface at the joint level. First, the proposed methodology addresses the problem of system identification to obtain an approximate dynamic model of the hydraulic arm. This is done via supervised learning, using only teleoperation data. The learned dynamic model is then exploited to obtain a controller capable of reaching target end-effector poses. For policy synthesis, both reinforcement learning (RL) and model predictive control (MPC) algorithms are utilized and contrasted. As a case study, we consider the automation of a Bobcat E10 mini-excavator arm with a hydraulic impact hammer attached as end-effector. Using this machine, both the system identification and policy synthesis stages are studied in simulation and in the real world. The best RL-based policy consistently reaches target end-effector poses with position errors below 12 cm and pitch angle errors below 0.08 rad in the real world. Considering that the impact hammer has a 4 cm diameter chisel, this level of precision is sufficient for breaking rocks. Notably, this is accomplished by relying only on approximately 68 min of teleoperation data to train and 8 min to evaluate the dynamic model, and without performing any adjustments for a successful policy Sim2Real transfer. A demonstration of policy execution in the real world can be found in https://youtu.be/e-7tDhZ4ZgA.", "AI": {"tldr": "本文提出了一种数据驱动的方法，用于在采矿行业中控制静态液压冲击锤，使其末端执行器达到任意目标姿态。", "motivation": "由于有限的感知能力和严格的离散控制接口要求，传统的控制系统难以满足需求。因此，需要一种新的方法来克服这些限制。", "method": "首先通过监督学习使用遥操作数据获得系统的动态模型；然后利用强化学习和模型预测控制算法合成控制器以达到目标姿态。", "result": "最佳的基于RL的策略在现实世界中能够使末端执行器达到指定的姿态，位置误差小于12厘米，偏转角度误差小于0.08弧度。使用大约68分钟的遥操作数据训练动态模型，并通过8分钟的数据进行评估，无需任何调整即可实现从模拟到真实的迁移。", "conclusion": "该方法成功解决了在有限感知和严格控制接口下的液压冲击锤姿态控制问题，为类似设备的自动化提供了新思路。"}}
{"id": "2601.07812", "pdf": "https://arxiv.org/pdf/2601.07812", "abs": "https://arxiv.org/abs/2601.07812", "authors": ["Anurag Das", "Adrian Bulat", "Alberto Baldrati", "Ioannis Maniadis Metaxas", "Bernt Schiele", "Georgios Tzimiropoulos", "Brais Martinez"], "title": "More Images, More Problems? A Controlled Analysis of VLM Failure Modes", "categories": ["cs.CV"], "comment": "19 pages, 16 figures", "summary": "Large Vision Language Models (LVLMs) have demonstrated remarkable capabilities, yet their proficiency in understanding and reasoning over multiple images remains largely unexplored. While existing benchmarks have initiated the evaluation of multi-image models, a comprehensive analysis of their core weaknesses and their causes is still lacking. In this work, we introduce MIMIC (Multi-Image Model Insights and Challenges), a new benchmark designed to rigorously evaluate the multi-image capabilities of LVLMs. Using MIMIC, we conduct a series of diagnostic experiments that reveal pervasive issues: LVLMs often fail to aggregate information across images and struggle to track or attend to multiple concepts simultaneously. To address these failures, we propose two novel complementary remedies. On the data side, we present a procedural data-generation strategy that composes single-image annotations into rich, targeted multi-image training examples. On the optimization side, we analyze layer-wise attention patterns and derive an attention-masking scheme tailored for multi-image inputs. Experiments substantially improved cross-image aggregation, while also enhancing performance on existing multi-image benchmarks, outperforming prior state of the art across tasks. Data and code will be made available at https://github.com/anurag-198/MIMIC.", "AI": {"tldr": "该论文介绍了MIMIC基准测试，用于评估大型视觉语言模型在处理多张图片时的能力和缺陷，并提出了改进方法。", "motivation": "尽管大型视觉语言模型展示了显著能力，但它们如何理解和推理多个图像的问题仍未被充分研究。现有基准对多图模型的评价尚不全面，缺少对其核心弱点及原因的深入分析。", "method": "论文提出MIMIC基准测试以诊断多图模型的能力缺陷，并设计了合成数据生成策略和注意力掩蔽方案来改善模型在多图输入上的表现。", "result": "实验表明新方法能显著提高跨图像信息聚合能力，同时在现有多图基准上表现出色，超越先前的最先进水平。", "conclusion": "该研究揭示了大型视觉语言模型处理多张图片时存在的问题，并通过MIMIC基准测试和提出的改进措施展示了潜在解决方案。"}}
{"id": "2601.07805", "pdf": "https://arxiv.org/pdf/2601.07805", "abs": "https://arxiv.org/abs/2601.07805", "authors": ["Sijun Dong", "Siming Fu", "Kaiyu Li", "Xiangyong Cao", "Xiaoliang Meng", "Bo Du"], "title": "Exchange Is All You Need for Remote Sensing Change Detection", "categories": ["cs.CV"], "comment": null, "summary": "Remote sensing change detection fundamentally relies on the effective fusion and discrimination of bi-temporal features. Prevailing paradigms typically utilize Siamese encoders bridged by explicit difference computation modules, such as subtraction or concatenation, to identify changes. In this work, we challenge this complexity with SEED (Siamese Encoder-Exchange-Decoder), a streamlined paradigm that replaces explicit differencing with parameter-free feature exchange. By sharing weights across both Siamese encoders and decoders, SEED effectively operates as a single parameter set model. Theoretically, we formalize feature exchange as an orthogonal permutation operator and prove that, under pixel consistency, this mechanism preserves mutual information and Bayes optimal risk, whereas common arithmetic fusion methods often introduce information loss. Extensive experiments across five benchmarks, including SYSU-CD, LEVIR-CD, PX-CLCD, WaterCD, and CDD, and three backbones, namely SwinT, EfficientNet, and ResNet, demonstrate that SEED matches or surpasses state of the art methods despite its simplicity. Furthermore, we reveal that standard semantic segmentation models can be transformed into competitive change detectors solely by inserting this exchange mechanism, referred to as SEG2CD. The proposed paradigm offers a robust, unified, and interpretable framework for change detection, demonstrating that simple feature exchange is sufficient for high performance information fusion. Code and full training and evaluation protocols will be released at https://github.com/dyzy41/open-rscd.", "AI": {"tldr": "本文提出了一种简单而有效的特征交换机制用于遥感变化检测，该机制替代了传统的显式差异计算模块。", "motivation": "当前的遥感变化检测方法通常依赖复杂的Siamese编码器和显式的差异计算模块。作者认为这种方法过于复杂，并提出了SEED框架来简化这一过程。", "method": "SEED通过引入特征交换代替传统差值运算，共享权重以减少模型参数量，并证明了在像素一致性下，这种机制能够保持互信息及贝叶斯最优风险。", "result": "实验表明，SEED在五个基准数据集上的表现超过了现有方法。此外，标准语义分割模型通过引入特征交换机制可以转换为有效的变化检测器（SEG2CD）。", "conclusion": "本文提出了一种简单但高效的信息融合框架用于遥感变化检测，证明了简单的特征交换能够实现高性能的差异检测。"}}
{"id": "2601.07796", "pdf": "https://arxiv.org/pdf/2601.07796", "abs": "https://arxiv.org/abs/2601.07796", "authors": ["Shaz Furniturewala", "Gerard Christopher Yeo", "Kokil Jaidka"], "title": "Learning Through Dialogue: Unpacking the Dynamics of Human-LLM Conversations on Political Issues", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used as conversational partners for learning, yet the interactional dynamics supporting users' learning and engagement are understudied. We analyze the linguistic and interactional features from both LLM and participant chats across 397 human-LLM conversations about socio-political issues to identify the mechanisms and conditions under which LLM explanations shape changes in political knowledge and confidence. Mediation analyses reveal that LLM explanatory richness partially supports confidence by fostering users' reflective insight, whereas its effect on knowledge gain operates entirely through users' cognitive engagement. Moderation analyses show that these effects are highly conditional and vary by political efficacy. Confidence gains depend on how high-efficacy users experience and resolve uncertainty. Knowledge gains depend on high-efficacy users' ability to leverage extended interaction, with longer conversations benefiting primarily reflective users. In summary, we find that learning from LLMs is an interactional achievement, not a uniform outcome of better explanations. The findings underscore the importance of aligning LLM explanatory behavior with users' engagement states to support effective learning in designing Human-AI interactive systems.", "AI": {"tldr": "通过分析关于社会政治问题的人类与大型语言模型对话，探讨了语言模型解释对用户政治知识和信心的影响机制。", "motivation": "研究人类在对话中从大型语言模型获得的知识增长和自信心提升的动态过程以及交互条件的重要性。", "method": "使用397次关于社会政治问题的人类与大型语言模型对话，分析了对话中的语言特征及其对用户学习的影响。", "result": "发现大型语言模型解释丰富性部分支持用户自信度通过促进其反思洞察力；知识增长完全由用户的认知参与驱动。这些效果高度依赖于政治效能感的不同影响条件变化。", "conclusion": "学习来源于大型语言模型是一种交互成就，而非更好解释的统一结果。设计人机互动系统时需关注将大型语言模型的行为与用户的状态相匹配以支持有效学习的重要性。"}}
{"id": "2601.07795", "pdf": "https://arxiv.org/pdf/2601.07795", "abs": "https://arxiv.org/abs/2601.07795", "authors": ["Patrick Bauer", "Marius Schwinning", "Florian Renk", "Andreas Weinmann", "Hichem Snoussi"], "title": "Vision-Language Model for Accurate Crater Detection", "categories": ["cs.CV"], "comment": null, "summary": "The European Space Agency (ESA), driven by its ambitions on planned lunar missions with the Argonaut lander, has a profound interest in reliable crater detection, since craters pose a risk to safe lunar landings. This task is usually addressed with automated crater detection algorithms (CDA) based on deep learning techniques. It is non-trivial due to the vast amount of craters of various sizes and shapes, as well as challenging conditions such as varying illumination and rugged terrain. Therefore, we propose a deep-learning CDA based on the OWLv2 model, which is built on a Vision Transformer, that has proven highly effective in various computer vision tasks. For fine-tuning, we utilize a manually labeled dataset fom the IMPACT project, that provides crater annotations on high-resolution Lunar Reconnaissance Orbiter Camera Calibrated Data Record images. We insert trainable parameters using a parameter-efficient fine-tuning strategy with Low-Rank Adaptation, and optimize a combined loss function consisting of Complete Intersection over Union (CIoU) for localization and a contrastive loss for classification. We achieve satisfactory visual results, along with a maximum recall of 94.0% and a maximum precision of 73.1% on a test dataset from IMPACT. Our method achieves reliable crater detection across challenging lunar imaging conditions, paving the way for robust crater analysis in future lunar exploration.", "AI": {"tldr": "研究开发了一种基于视觉语言模型的精确月球陨石坑检测方法。", "motivation": "欧洲空间局（ESA）为保障未来阿耳戈号登月任务的安全，需要一种可靠的方法来自动识别月球表面的各种大小和形状的陨石坑。现有的自动化算法由于光照变化和地形复杂性而难以准确地执行此任务。", "method": "利用OWLv2模型，该模型基于视觉变换器，并使用IMPACT项目的手动标记数据集进行微调，采用参数高效微调策略（低秩适应）并优化包含定位损失CIoU和分类对比损失的联合损失函数。", "result": "在IMPACT测试集上实现了最大召回率94.0%和最高精度73.1%，证明了模型对各种光照条件下的可靠陨石坑检测能力。", "conclusion": "所提出的基于视觉语言的自动检测方法为未来月球探索提供了可靠的陨石坑分析技术。"}}
{"id": "2601.07794", "pdf": "https://arxiv.org/pdf/2601.07794", "abs": "https://arxiv.org/abs/2601.07794", "authors": ["Tianda Sun", "Dimitar Kazakov"], "title": "Kinship Data Benchmark for Multi-hop Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 2 figures, 9 tables", "summary": "Large language models (LLMs) are increasingly evaluated on their ability to perform multi-hop reasoning, i.e., to combine multiple pieces of information into a coherent inference. We introduce KinshipQA, a benchmark designed to probe this capability through reasoning over kinship relations. The central contribution of our work is a generative pipeline that produces, on demand, large-scale, realistic, and culture-specific genealogical data: collections of interconnected family trees that satisfy explicit marriage constraints associated with different kinship systems. This allows task difficulty, cultural assumptions, and relational depth to be systematically controlled and varied. From these genealogies, we derive textual inference tasks that require reasoning over implicit relational chains. We evaluate the resulting benchmark using six state-of-the-art LLMs, spanning both open-source and closed-source models, under a uniform zero-shot protocol with deterministic decoding. Performance is measured using exact-match and set-based metrics. Our results demonstrate that KinshipQA yields a wide spread of outcomes and exposes systematic differences in multi-hop reasoning across models and cultural settings.", "AI": {"tldr": "该论文提出了KinshipQA，一个用于评估大型语言模型多跳推理能力的数据基准。", "motivation": "大型语言模型（LLMs）的性能评估需要通过解决复杂推理任务来考察其综合信息的能力。为此，研究人员设计了一个针对亲属关系推理解析的新数据集，以更好地衡量这些模型的多跳推理技能。", "method": "论文开发了一种生成性流水线方法，能够根据特定文化背景下的婚姻约束条件自动生成大规模、逼真且具有文化特性的家谱图。基于生成的家谱图，研究人员构建了文本推理任务，并使用六种最先进的LLM模型进行评估。", "result": "研究结果表明，在不同文化和模型背景下，多跳推理的表现差异显著。", "conclusion": "KinshipQA为评估大型语言模型在复杂亲属关系推理解析中的表现提供了一个有价值的基准。"}}
{"id": "2601.07790", "pdf": "https://arxiv.org/pdf/2601.07790", "abs": "https://arxiv.org/abs/2601.07790", "authors": ["Yahya Masri", "Emily Ma", "Zifu Wang", "Joseph Rogers", "Chaowei Yang"], "title": "Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification", "categories": ["cs.AI"], "comment": "28 pages, 5 figures, 7 tables", "summary": "System logs are crucial for monitoring and diagnosing modern computing infrastructure, but their scale and complexity require reliable and efficient automated interpretation. Since severity levels are predefined metadata in system log messages, having a model merely classify them offers limited standalone practical value, revealing little about its underlying ability to interpret system logs. We argue that severity classification is more informative when treated as a benchmark for probing runtime log comprehension rather than as an end task. Using real-world journalctl data from Linux production servers, we evaluate nine small language models (SLMs) and small reasoning language models (SRLMs) under zero-shot, few-shot, and retrieval-augmented generation (RAG) prompting. The results reveal strong stratification. Qwen3-4B achieves the highest accuracy at 95.64% with RAG, while Gemma3-1B improves from 20.25% under few-shot prompting to 85.28% with RAG. Notably, the tiny Qwen3-0.6B reaches 88.12% accuracy despite weak performance without retrieval. In contrast, several SRLMs, including Qwen3-1.7B and DeepSeek-R1-Distill-Qwen-1.5B, degrade substantially when paired with RAG. Efficiency measurements further separate models: most Gemma and Llama variants complete inference in under 1.2 seconds per log, whereas Phi-4-Mini-Reasoning exceeds 228 seconds per log while achieving <10% accuracy. These findings suggest that (1) architectural design, (2) training objectives, and (3) the ability to integrate retrieved context under strict output constraints jointly determine performance. By emphasizing small, deployable models, this benchmark aligns with real-time requirements of digital twin (DT) systems and shows that severity classification serves as a lens for evaluating model competence and real-time deployability, with implications for root cause analysis (RCA) and broader DT integration.", "AI": {"tldr": "该论文评估了九种小型语言模型和小推理语言模型在系统日志严重性分类任务中的性能，以零样本、少量样本和检索增强生成方式对真实世界的数据进行测试。", "motivation": "由于系统日志的规模和复杂性，可靠的自动解释至关重要。然而，仅依赖模型来分类日志的严重级别并不足以评估其理解能力。因此，该研究通过将严重性分类作为基准任务来进行深入分析，以探查模型的日志解读能力。", "method": "使用Linux生产服务器上的真实世界journalctl数据，对九种小型语言模型和小推理语言模型在零样本、少量样本以及检索增强生成模式下的性能进行了评估。这些模型包括Qwen3-4B、Gemma3-1B等。", "result": "结果显示了显著的分级现象：Qwen3-4B在检索增强生成条件下取得了最高的95.64%准确率；Gemma3-1B从少量样本提示下的20.25%提高到85.28%，而较小的模型如Qwen3-0.6B达到了88.12%。然而，部分小推理语言模型在使用检索增强生成时表现较差。", "conclusion": "研究结果表明，模型性能受到架构设计、训练目标以及整合检索上下文的能力的影响。这不仅对数字孪生系统有实际应用价值，也揭示了严重性分类任务作为衡量模型能力和实时部署性的有效工具的潜力。"}}
{"id": "2601.07788", "pdf": "https://arxiv.org/pdf/2601.07788", "abs": "https://arxiv.org/abs/2601.07788", "authors": ["Liberty Kent", "Nilufer Tuptuk", "Ingolf Becker"], "title": "Passing the Baton: Shift Handovers within Cybersecurity Incident Response Teams", "categories": ["cs.HC"], "comment": null, "summary": "Effective shift transitions are crucial for cybersecurity incident response teams, yet there is limited guidance on managing these handovers. This exploratory study aimed to develop guidelines for such transitions through the analysis of existing literature and consultation with practitioners. Two draft guidelines (A and B) were created based on existing literature and online resources. Six participants from the UK and international incident response teams, with experience in shift handovers, were interviewed about handover structure, challenges, training practices, and their views on the draft guidelines. The collected data indicate the importance of signposting, evolving handover procedures, individual differences in handover style and detail, and streamlining the handover procedure. Participants agreed the drafts included all relevant details but suggested adding a post-incident review section and a service section for outages or technical difficulties. This study establishes a foundation for enhancing transition practices in cybersecurity incident response teams.", "AI": {"tldr": "研究旨在通过文献分析和从业者访谈，制定网络安全事件响应团队交接班的指导原则。", "motivation": "有效过渡对于网络安全事件响应团队至关重要，但关于此类交接班的规定相对有限。研究目的是弥补这一空白并提供实用指南。", "method": "基于现有文献和在线资源制定了两个草案，并采访了六位来自英国及国际的具有丰富交接经验的参与者，讨论交接结构、挑战、培训实践以及对草稿的意见。", "result": "研究表明交接过程中需要注意标识引导、流程进化、个人差异以及简化程序。参与者认为草稿涵盖了所有重要细节但建议增加事后评审部分和技术问题服务环节。", "conclusion": "该研究为提升网络安全事件响应团队的交接班流程提供了基础框架。"}}
{"id": "2601.07783", "pdf": "https://arxiv.org/pdf/2601.07783", "abs": "https://arxiv.org/abs/2601.07783", "authors": ["Chaoyi Lin Yang", "Gabriele Dessena", "Oscar E. Bonilla-Manrique"], "title": "Affordable Data Collection System for UAVs Taxi Vibration Testing", "categories": ["eess.SY", "cs.RO", "eess.SP"], "comment": null, "summary": "Structural vibration testing plays a key role in aerospace engineering for evaluating dynamic behaviour, ensuring reliability and verifying structural integrity. These tests rely on accurate and robust data acquisition systems (DAQ) to capture high-quality acceleration data. However, commercial DAQs that provide the required performance and features are often expensive and complex, limiting their accessibility for small-scale research and experimental applications. This work presents the design and experimental validation of an affordable and in-house-developed acceleration DAQ, tested on a small fixed-wing UAV through several Taxi Vibration Test (TVT) runs and ambient vibration measurements. The proposed system integrates several OrangePi 3 LTS single-board computers with multiple LSM6DS3TR-C MEMS inertial measurement units operating simultaneously via an Inter-Integrated Circuit (I2C) communication interface, managed under a Python-based master/slave architecture. Data is acquired at a stable sampling rate of approximately 208 Hz and post-processed using Welch's method to estimate their Power Spectral Density (PSD). Results confirm the system ability to provide consistent multi-sensor acceleration data and repeatable PSD profiles under the same test conditions; thus, demonstrating its reliability. With a total hardware cost below 600 EUR (approximately 690 USD), the developed DAQ offers a compact, scalable and cost-effective alternative for aerospace vibration analysis and structural testing.", "AI": {"tldr": "设计并验证了一种低成本的数据采集系统，用于小型固定翼无人机的滑行振动测试。", "motivation": "商用数据采集系统成本高昂且复杂，限制了小规模研究和实验应用的可行性。为了提高可访问性，开发了一种经济实惠、易于使用的加速计数据采集系统。", "method": "使用OrangePi 3 LTS单板计算机与多个LSM6DS3TR-C MEMS惯性测量单元集成设计了一个低成本的数据采集系统，并通过滑行振动测试和环境振动测量进行了验证。该系统采用Python基础主从架构，以稳定208 Hz的采样率获取数据，利用Welch方法估计功率谱密度。", "result": "实验结果表明该系统能够提供一致多传感器加速度数据并在相同测试条件下展示可重复的功率谱密度轮廓，证明其可靠性。整个硬件成本低于600欧元（约690美元）。", "conclusion": "开发的数据采集系统为航空振动分析和结构测试提供了紧凑、可扩展且经济高效的替代方案。"}}
{"id": "2601.07782", "pdf": "https://arxiv.org/pdf/2601.07782", "abs": "https://arxiv.org/abs/2601.07782", "authors": ["Wei Fang", "James Glass"], "title": "Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "LLM agents operating over massive, dynamic tool libraries rely on effective retrieval, yet standard single-shot dense retrievers struggle with complex requests. These failures primarily stem from the disconnect between abstract user goals and technical documentation, and the limited capacity of fixed-size embeddings to model combinatorial tool compositions. To address these challenges, we propose TOOLQP, a lightweight framework that models retrieval as iterative query planning. Instead of single-shot matching, TOOLQP decomposes instructions into sub-tasks and dynamically generates queries to interact with the retriever, effectively bridging the semantic gap by targeting the specific sub-tasks required for composition. We train TOOLQP using synthetic query trajectories followed by optimization via Reinforcement Learning with Verifiable Rewards (RLVR). Experiments demonstrate that TOOLQP achieves state-of-the-art performance, exhibiting superior zero-shot generalization, robustness across diverse retrievers, and significant improvements in downstream agentic execution.", "AI": {"tldr": "该论文提出了TOOLQP框架，通过多步查询规划解决单一检索器在复杂请求下的性能不足问题。", "motivation": "现有的单一检索器面对复杂的用户指令时表现不佳，因为它们难以处理抽象的用户目标和详细的工具文档之间的差距，并且固定大小的嵌入不足以表示组合工具。", "method": "TOOLQP将检索任务分解为子任务，通过动态生成查询来与检索器交互。框架使用合成查询轨迹训练并进行基于可验证奖励的强化学习优化。", "result": "实验表明，TOOLQP在零样本泛化、跨多种检索器鲁棒性以及下游代理执行方面取得了最先进的性能和显著改进。", "conclusion": "TOOLQP通过迭代查询规划有效解决了单一检索器难以处理复杂请求的问题，并展示了优于现有方法的性能。"}}
{"id": "2601.07779", "pdf": "https://arxiv.org/pdf/2601.07779", "abs": "https://arxiv.org/abs/2601.07779", "authors": ["Bowen Yang", "Kaiming Jin", "Zhenyu Wu", "Zhaoyang Liu", "Qiushi Sun", "Zehao Li", "JingJing Xie", "Zhoumianze Liu", "Fangzhi Xu", "Kanzhi Cheng", "Qingyun Li", "Yian Wang", "Yu Qiao", "Zun Wang", "Zichen Ding"], "title": "OS-Symphony: A Holistic Framework for Robust and Generalist Computer-Using Agent", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.CV", "cs.HC"], "comment": "31 pages, 11 figures, 12 tables", "summary": "While Vision-Language Models (VLMs) have significantly advanced Computer-Using Agents (CUAs), current frameworks struggle with robustness in long-horizon workflows and generalization in novel domains. These limitations stem from a lack of granular control over historical visual context curation and the absence of visual-aware tutorial retrieval. To bridge these gaps, we introduce OS-Symphony, a holistic framework that comprises an Orchestrator coordinating two key innovations for robust automation: (1) a Reflection-Memory Agent that utilizes milestone-driven long-term memory to enable trajectory-level self-correction, effectively mitigating visual context loss in long-horizon tasks; (2) Versatile Tool Agents featuring a Multimodal Searcher that adopts a SeeAct paradigm to navigate a browser-based sandbox to synthesize live, visually aligned tutorials, thereby resolving fidelity issues in unseen scenarios. Experimental results demonstrate that OS-Symphony delivers substantial performance gains across varying model scales, establishing new state-of-the-art results on three online benchmarks, notably achieving 65.84% on OSWorld.", "AI": {"tldr": "本文提出了一种名为OS-Symphony的框架，该框架旨在提高计算机使用代理在长时段工作流程中的健壮性和新领域的一般化能力。", "motivation": "现有的Vision-Language模型虽然大幅提升了计算机使用代理的能力，但在长时间的任务中存在视觉上下文丢失的问题，并且缺乏解决未见过场景的方法。为了克服这些问题，本文提出了一个新的框架来增强自动化。", "method": "OS-Symphony包括两个关键创新：一个是Reflection-Memory Agent, 它利用里程碑驱动的长期记忆来进行轨迹级自我纠正；另一个是Versatile Tool Agents，其Multimodal Searcher采用SeeAct范式导航基于浏览器的安全沙箱以合成实时、视觉对齐的教程。", "result": "实验结果表明，OS-Symphony在不同模型尺度下实现了显著性能提升，并且在三个在线基准测试中达到了新的最高水平，特别是在OSWorld上达到了65.84%的成绩。", "conclusion": "通过提供一个全面的方法来解决当前计算机使用代理面临的问题，本文提出的OS-Symphony框架展示了其在增强自动化系统健壮性和一般化能力方面的潜力。"}}
{"id": "2601.07778", "pdf": "https://arxiv.org/pdf/2601.07778", "abs": "https://arxiv.org/abs/2601.07778", "authors": ["Wen Guo"], "title": "DT-ICU: Towards Explainable Digital Twins for ICU Patient Monitoring via Multi-Modal and Multi-Task Iterative Inference", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce DT-ICU, a multimodal digital twin framework for continuous risk estimation in intensive care. DT-ICU integrates variable-length clinical time series with static patient information in a unified multitask architecture, enabling predictions to be updated as new observations accumulate over the ICU stay. We evaluate DT-ICU on the large, publicly available MIMIC-IV dataset, where it consistently outperforms established baseline models under different evaluation settings. Our test-length analysis shows that meaningful discrimination is achieved shortly after admission, while longer observation windows further improve the ranking of high-risk patients in highly imbalanced cohorts. To examine how the model leverages heterogeneous data sources, we perform systematic modality ablations, revealing that the model learnt a reasonable structured reliance on interventions, physiological response observations, and contextual information. These analyses provide interpretable insights into how multimodal signals are combined and how trade-offs between sensitivity and precision emerge. Together, these results demonstrate that DT-ICU delivers accurate, temporally robust, and interpretable predictions, supporting its potential as a practical digital twin framework for continuous patient monitoring in critical care. The source code and trained model weights for DT-ICU are publicly available at https://github.com/GUO-W/DT-ICU-release.", "AI": {"tldr": "该论文提出了DT-ICU，一个用于重症监护病房患者连续风险评估的多模态数字孪生框架。", "motivation": "为了实现对重症监护患者的持续准确监测，并提供解释性高的预测结果。", "method": "通过集成变量长度的临床时间序列和静态病人信息，在统一的多任务架构中进行迭代推理。", "result": "在MIMIC-IV数据集上，DT-ICU表现出色，能够在较短时间内区分高风险患者，并随着观察窗口的增长进一步提升准确性。", "conclusion": "DT-ICU可以提供准确、时间上稳健且可解释的预测结果，是重症监护病房持续监测患者的潜在实用数字孪生框架。"}}
{"id": "2601.07773", "pdf": "https://arxiv.org/pdf/2601.07773", "abs": "https://arxiv.org/abs/2601.07773", "authors": ["Lingchen Sun", "Rongyuan Wu", "Zhengqiang Zhang", "Ruibin Li", "Yujing Sun", "Shuaizheng Liu", "Lei Zhang"], "title": "Beyond External Guidance: Unleashing the Semantic Richness Inside Diffusion Transformers for Improved Training", "categories": ["cs.CV"], "comment": null, "summary": "Recent works such as REPA have shown that guiding diffusion models with external semantic features (e.g., DINO) can significantly accelerate the training of diffusion transformers (DiTs). However, this requires the use of pretrained external networks, introducing additional dependencies and reducing flexibility. In this work, we argue that DiTs actually have the power to guide the training of themselves, and propose \\textbf{Self-Transcendence}, a simple yet effective method that achieves fast convergence using internal feature supervision only. It is found that the slow convergence in DiT training primarily stems from the difficulty of representation learning in shallow layers. To address this, we initially train the DiT model by aligning its shallow features with the latent representations from the pretrained VAE for a short phase (e.g., 40 epochs), then apply classifier-free guidance to the intermediate features, enhancing their discriminative capability and semantic expressiveness. These enriched internal features, learned entirely within the model, are used as supervision signals to guide a new DiT training. Compared to existing self-contained methods, our approach brings a significant performance boost. It can even surpass REPA in terms of generation quality and convergence speed, but without the need for any external pretrained models. Our method is not only more flexible for different backbones but also has the potential to be adopted for a wider range of diffusion-based generative tasks. The source code of our method can be found at https://github.com/csslc/Self-Transcendence.", "AI": {"tldr": "本文提出了Self-Transcendence方法，利用内部特征监督来加速扩散变压器的训练，并在没有外部预训练模型的情况下实现高质量生成。", "motivation": "现有工作通过使用外部语义特征引导扩散模型加快了扩散变压器的训练速度。然而，这引入了额外依赖并减少了灵活性。本文提出了一种新的方法来自我指导训练过程，以提高灵活性和性能。", "method": "Self-Transcendence方法包括两个阶段：首先，将浅层特征与预训练VAE的潜在表示对齐；然后利用中间特征作为监督信号进行分类器自由引导，增强其判别能力和语义表达能力。", "result": "这种方法在生成质量和收敛速度上都超过了现有的自包含方法，并且甚至可以超越使用外部预训练模型的方法REPA。", "conclusion": "Self-Transcendence方法不仅提高了扩散变压器的性能和灵活性，还可以应用于更广泛的基于扩散的生成任务。"}}
{"id": "2601.07768", "pdf": "https://arxiv.org/pdf/2601.07768", "abs": "https://arxiv.org/abs/2601.07768", "authors": ["Alex Huang", "Akshay Karthik"], "title": "THETA: Triangulated Hand-State Estimation for Teleoperation and Automation in Robotic Hand Control", "categories": ["cs.RO"], "comment": "The 11th International Conference on Engineering and Emerging Technologies (ICEET) 2025", "summary": "The teleoperation of robotic hands is limited by the high costs of depth cameras and sensor gloves, commonly used to estimate hand relative joint positions (XYZ). We present a novel, cost-effective approach using three webcams for triangulation-based tracking to approximate relative joint angles (theta) of human fingers. We also introduce a modified DexHand, a low-cost robotic hand from TheRobotStudio, to demonstrate THETA's real-time application. Data collection involved 40 distinct hand gestures using three 640x480p webcams arranged at 120-degree intervals, generating over 48,000 RGB images. Joint angles were manually determined by measuring midpoints of the MCP, PIP, and DIP finger joints. Captured RGB frames were processed using a DeepLabV3 segmentation model with a ResNet-50 backbone for multi-scale hand segmentation. The segmented images were then HSV-filtered and fed into THETA's architecture, consisting of a MobileNetV2-based CNN classifier optimized for hierarchical spatial feature extraction and a 9-channel input tensor encoding multi-perspective hand representations. The classification model maps segmented hand views into discrete joint angles, achieving 97.18% accuracy, 98.72% recall, F1 Score of 0.9274, and a precision of 0.8906. In real-time inference, THETA captures simultaneous frames, segments hand regions, filters them, and compiles a 9-channel tensor for classification. Joint-angle predictions are relayed via serial to an Arduino, enabling the DexHand to replicate hand movements. Future research will increase dataset diversity, integrate wrist tracking, and apply computer vision techniques such as OpenAI-Vision. THETA potentially ensures cost-effective, user-friendly teleoperation for medical, linguistic, and manufacturing applications.", "AI": {"tldr": "本文提出了一种使用三个网络摄像头进行三角测量追踪来估算人手关节角度的方法，以实现低成本的手部遥操作和自动化控制。", "motivation": "传统的深度相机和传感器手套由于成本高昂限制了手部遥操作的应用。THETA通过使用更便宜的设备提供了成本效益高的解决方案。", "method": "利用三个网络摄像头捕捉手势图像，然后采用DeepLabV3模型进行多尺度分割，HSV滤波处理后输入到基于MobileNetV2的分类器中来提取空间特征并预测关节角度。", "result": "实验结果表明该方法在准确率、召回率和F1分数方面表现出色。实时测试显示THETA能够驱动DexHand复制手部动作。", "conclusion": "THETA为医疗、语言学及制造业领域提供了低成本且用户友好的遥操作解决方案，未来将探索更多应用场景和改进技术方案"}}
{"id": "2601.07761", "pdf": "https://arxiv.org/pdf/2601.07761", "abs": "https://arxiv.org/abs/2601.07761", "authors": ["Yanxiang Huang", "Guohua Gao", "Zhaoyang Wei", "Jianyuan Ni"], "title": "Video Evidence to Reasoning Efficient Video Understanding via Explicit Evidence Grounding", "categories": ["cs.CV"], "comment": "6 pages", "summary": "Large Vision-Language Models (LVLMs) face a fundamental dilemma in video reasoning: they are caught between the prohibitive computational costs of verbose reasoning and the hallucination risks of efficient, ungrounded approaches. To resolve this, we introduce the Chain of Evidence (CoE), a novel framework that architecturally decouples and co-optimizes perceptual grounding and reasoning efficiency. CoE incorporates two core innovations: (1) A lightweight Evidence Grounding Module (EGM) that acts as a query-guided filter, dynamically identifying and extracting a compact set of high-fidelity visual evidence; and (2) An Evidence-Anchoring Protocol optimized via Reinforcement Learning. Crucially, we design a composite reward mechanism that enforces process alignment, compelling the model to strictly reference identified temporal anchors during deduction, thereby mitigating hallucinations. To enable this, we construct CoE-Instruct, a large-scale dataset (164k samples) featuring a novel dual-annotation schema for separate perception and reasoning supervision. Extensive experiments on five benchmarks, including Video-MME, MVBench, and VSI-Bench, demonstrate that CoE-enhanced models establish a new state-of-the-art. They significantly outperform existing methods in accuracy, proving CoE to be a powerful and practical paradigm for reliable video understanding.", "AI": {"tldr": "提出了一种新型的视频证据推理框架Chain of Evidence (CoE)，用于高效可靠的视频理解。", "motivation": "解决大型视觉语言模型（LVLMs）在视频推理中面临的高昂计算成本和未经证实的方法带来的幻觉风险问题。", "method": "提出了架构解耦和共同优化感知定位与推理效率的Chain of Evidence框架，包含轻量级证据定位模块以及通过强化学习优化的证据锚定协议，并设计了一个复合奖励机制以防止模型在演绎过程中出现幻觉。", "result": "实验结果证明，CoE增强的模型在Video-MME、MVBench和VSI-Bench等五个基准测试中均建立了新的状态-of-the-art水平，在准确性方面显著优于现有方法。", "conclusion": "Chain of Evidence是一个强大且实用的范式，用于可靠视频理解。"}}
{"id": "2601.07749", "pdf": "https://arxiv.org/pdf/2601.07749", "abs": "https://arxiv.org/abs/2601.07749", "authors": ["Agnieszka Kaliszewska", "Monika Syga"], "title": "On the application of the Wasserstein metric to 2D curves classification", "categories": ["cs.CV"], "comment": null, "summary": "In this work we analyse a number of variants of the Wasserstein distance which allow to focus the classification on the prescribed parts (fragments) of classified 2D curves. These variants are based on the use of a number of discrete probability measures which reflect the importance of given fragments of curves. The performance of this approach is tested through a series of experiments related to the clustering analysis of 2D curves performed on data coming from the field of archaeology.", "AI": {"tldr": "本文分析了若干基于沃瑟斯坦度量的变体，用于对二维曲线特定部分进行分类。", "motivation": "通过使用反映给定片段重要性的离散概率测度来增强沃瑟斯坦距离在特定区域内的准确性，从而优化2D曲线分类。", "method": "提出了几种沃瑟斯坦距离的不同变体，并利用考古数据进行了实验验证其有效性。", "result": "该方法在二维曲线的聚类分析中表现出良好的性能。", "conclusion": "基于沃森斯坦度量的方法对二维曲线特定部分进行分类是有效的，特别是在考古学领域。"}}
{"id": "2601.07748", "pdf": "https://arxiv.org/pdf/2601.07748", "abs": "https://arxiv.org/abs/2601.07748", "authors": ["Robert Lewis", "Katie Matton", "Rosalind W. Picard", "John Guttag"], "title": "Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control", "categories": ["cs.LG", "cs.AI"], "comment": "NeurIPS SSL Workshop 2023", "summary": "Self-supervised pre-training with contrastive learning is a powerful method for learning from sparsely labeled data. However, performance can drop considerably when there is a shift in the distribution of data from training to test time. We study this phenomenon in a setting in which the training data come from multiple domains, and the test data come from a domain not seen at training that is subject to significant covariate shift. We present a new method for contrastive learning that incorporates domain labels to increase the domain invariance of learned representations, leading to improved out-of-distribution generalization. Our method adjusts the temperature parameter in the InfoNCE loss -- which controls the relative weighting of negative pairs -- using the probability that a negative sample comes from the same domain as the anchor. This upweights pairs from more similar domains, encouraging the model to discriminate samples based on domain-invariant attributes. Through experiments on a variant of the MNIST dataset, we demonstrate that our method yields better out-of-distribution performance than domain generalization baselines. Furthermore, our method maintains strong in-distribution task performance, substantially outperforming baselines on this measure.", "AI": {"tldr": "该论文提出了一种新的对比学习方法，通过自适应调节温度参数来提高跨域泛化能力。", "motivation": "在训练和测试数据分布发生变化时，基于对比学习的自我监督预训练性能会大幅下降。为了改善这种情况，特别是在存在显著协变量偏移的新领域中，该论文旨在探索一种改进方法以提升模型的跨域泛化性能。", "method": "通过利用信息NCE损失中的温度参数来调整负样本对的相对权重，并根据锚定样本与负样本是否来自同一领域的概率动态调节这一参数。这种方法鼓励网络从不同领域中学习到更通用和不变性的特征表示。", "result": "实验结果表明，所提出的方法在MNIST变种数据集上取得了比其他域泛化基准更好的跨分布性能，并且在训练域内保持了强大的任务表现能力。", "conclusion": "通过自适应调整温度参数来控制负样本的选择策略可以提高模型的跨域泛化能力而不牺牲训练领域的性能。"}}
{"id": "2601.07744", "pdf": "https://arxiv.org/pdf/2601.07744", "abs": "https://arxiv.org/abs/2601.07744", "authors": ["Lohitvel Gopikannan", "Shashi Ranjan Kumar", "Abhinav Sinha"], "title": "Predefined-time One-Shot Cooperative Estimation, Guidance, and Control for Simultaneous Target Interception", "categories": ["eess.SY", "cs.MA", "cs.RO", "math.DS"], "comment": null, "summary": "This work develops a unified nonlinear estimation-guidance-control framework for cooperative simultaneous interception of a stationary target under a heterogeneous sensing topology, where sensing capabilities are non-uniform across interceptors. Specifically, only a subset of agents is instrumented with onboard seekers (informed/seeker-equipped agents), whereas the rest of them (seeker-less agents) acquire the information about the target indirectly via the informed agents and execute a distributed cooperative guidance for simultaneous target interception. To address the resulting partial observability, a predefined-time distributed observer is leveraged, guaranteeing convergence of the target state estimates for seeker-less agents through information exchange with seeker-equipped neighbors over a directed communication graph. Thereafter, an improved time-to-go estimate accounting for wide launch envelopes is utilized to design the distributed cooperative guidance commands. This estimate is coupled with a predefined-time consensus protocol, ensuring consensus in the agents' time-to-go values. The temporal upper bounds within which both observer error and time-to-go consensus error converge to zero can be prescribed as design parameters. Furthermore, the cooperative guidance commands are realized by means of an autopilot, wherein the interceptor is steered by canard actuation. The corresponding fin deflection commands are generated using a predefined-time convergent sliding mode control law. This enables the autopilot to precisely track the commanded lateral acceleration within a design-specified time, while maintaining non-singularity of the overall design. Theoretical guarantees are supported by numerical simulations across diverse engagement geometries, verifying the estimation accuracy, the cooperative interception performance, and the autopilot response using the proposed scheme.", "AI": {"tldr": "本文提出了一个统一的非线性估计、引导和控制框架，用于同时拦截静止目标。", "motivation": "针对异构传感拓扑结构下的协同同时拦截问题，提出了一种解决部分可观测性的方法。", "method": "利用预先定义的时间分布式观测器确保了未装备传感器代理的目标状态估计收敛。通过改进的到达时间估算和预定义时间共识协议设计了分布式协同引导指令，并结合滑模控制实现精确跟踪。", "result": "理论保证和支持仿真显示方案的有效性，包括估计准确性、拦截性能和自动驾驶仪响应。", "conclusion": "所提出的统一框架验证了在多种参与几何结构下的有效性。"}}
{"id": "2601.07737", "pdf": "https://arxiv.org/pdf/2601.07737", "abs": "https://arxiv.org/abs/2601.07737", "authors": ["Chen Ling", "Nai Ding"], "title": "Evaluating the encoding competence of visual language models using uncommon actions", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We propose UAIT (Uncommon-sense Action Image-Text) dataset, a new evaluation benchmark designed to test the semantic understanding ability of visual language models (VLMs) in uncommon-sense action scenes. Unlike previous datasets that focus on common visual scenes with statistical frequency advantages, UAIT challenges models with grammatically reasonable but semantically counter-common sense image-text pairs. Such tasks require models to go beyond superficial pattern recognition and demonstrate a deep understanding of agent-patient relationships and physical feasibility. To build UAIT, we designed a semi-automated process to synthesize high-quality uncommon-sense image-text samples using large language models, few-shot prompt engineering, and text-to-image generation. Each sample is accompanied by a carefully designed multiple-choice question to test the model's competence in fine-grained reasoning. We evaluate multiple state-of-the-art visual language models and compare them with models based on contrastive learning. Experiments show that all models perform significantly worse than humans in semantic judgment, especially in distinguishing grammatical correctness from semantic rationality. Further experiments show that even the lightweight model can improve its accuracy after fine-tuning, demonstrating the great potential of directional adaptation. This study not only reveals the key weaknesses of VLMs, but also provides diagnostic tools and research directions for the development of robust models with real visual semantic reasoning capabilities.", "AI": {"tldr": "评估视觉语言模型在不常见动作场景中的语义理解能力", "motivation": "现有数据集侧重于常见的视觉场景，而忽视了模型是否真正理解图像和文本之间的深层关系。本文提出了一种新的基准测试，旨在挑战模型的深度理解和推理能力，识别其在罕见且符合语法但违背常识的动作场景下的表现不足", "method": "通过大规模语言模型、少量提示工程及文本到图像生成技术构建了一个包含高质量样本的数据集，并设计了多项选择题来测试模型的能力。实验中比较了几种最先进的视觉语言模型和基于对比学习的模型的表现", "result": "所有模型在语义判断任务上表现不佳，尤其难以区分语法正确性和语义合理性。轻量级模型经过微调后性能有所提升，显示出定向适应的巨大潜力", "conclusion": "该研究揭示了视觉语言模型的关键弱点，并提供了诊断工具和具有真正视觉语义推理能力的稳健模型的发展方向"}}
{"id": "2601.07723", "pdf": "https://arxiv.org/pdf/2601.07723", "abs": "https://arxiv.org/abs/2601.07723", "authors": ["Guillaume J. Laurent", "Patrick Sandoz"], "title": "FMAC: a Fair Fiducial Marker Accuracy Comparison Software", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "This paper presents a method for carrying fair comparisons of the accuracy of pose estimation using fiducial markers. These comparisons rely on large sets of high-fidelity synthetic images enabling deep exploration of the 6 degrees of freedom. A low-discrepancy sampling of the space allows to check the correlations between each degree of freedom and the pose errors by plotting the 36 pairs of combinations. The images are rendered using a physically based ray tracing code that has been specifically developed to use the standard calibration coefficients of any camera directly. The software reproduces image distortions, defocus and diffraction blur. Furthermore, sub-pixel sampling is applied to sharp edges to enhance the fidelity of the rendered image. After introducing the rendering algorithm and its experimental validation, the paper proposes a method for evaluating the pose accuracy. This method is applied to well-known markers, revealing their strengths and weaknesses for pose estimation. The code is open source and available on GitHub.", "AI": {"tldr": "提出了一种用于公平比较基于特征标记的姿态估计准确性的软件FMAC", "motivation": "为了能够公平地评估不同特征标记在姿态估计中的准确性，需要一种标准化的方法和工具。现有的方法往往受限于实际图像的多样性和控制性不足，导致难以全面理解各自由度对误差的影响。因此开发了一种新的基于物理渲染的合成图像生成系统来解决这些问题", "method": "使用低离散度采样技术遍历6个自由度的空间，并通过高保真度的物理基线追踪代码生成包含相机校准系数的合成图像，考虑了像差、失焦和衍射模糊等效果。然后利用这些图像评估不同特征标记的姿态估计准确性", "result": "该方法应用于几种常见的特征标记上，揭示了它们在不同自由度上的表现差异，并展示了其准确性和可靠性。通过这种方法可以更加全面地了解各种特征标记的性能特点", "conclusion": "FMAC软件提供了一种新的视角来分析和比较不同的特征标记姿态估计系统，有助于提高计算机视觉领域中对这些技术的理解与应用"}}
{"id": "2601.07718", "pdf": "https://arxiv.org/pdf/2601.07718", "abs": "https://arxiv.org/abs/2601.07718", "authors": ["Shaoting Zhu", "Ziwen Zhuang", "Mengjie Zhao", "Kun-Ying Lee", "Hang Zhao"], "title": "Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids", "categories": ["cs.RO", "cs.AI"], "comment": "Project Page: https://project-instinct.github.io/hiking-in-the-wild", "summary": "Achieving robust humanoid hiking in complex, unstructured environments requires transitioning from reactive proprioception to proactive perception. However, integrating exteroception remains a significant challenge: mapping-based methods suffer from state estimation drift; for instance, LiDAR-based methods do not handle torso jitter well. Existing end-to-end approaches often struggle with scalability and training complexity; specifically, some previous works using virtual obstacles are implemented case-by-case. In this work, we present \\textit{Hiking in the Wild}, a scalable, end-to-end parkour perceptive framework designed for robust humanoid hiking. To ensure safety and training stability, we introduce two key mechanisms: a foothold safety mechanism combining scalable \\textit{Terrain Edge Detection} with \\textit{Foot Volume Points} to prevent catastrophic slippage on edges, and a \\textit{Flat Patch Sampling} strategy that mitigates reward hacking by generating feasible navigation targets. Our approach utilizes a single-stage reinforcement learning scheme, mapping raw depth inputs and proprioception directly to joint actions, without relying on external state estimation. Extensive field experiments on a full-size humanoid demonstrate that our policy enables robust traversal of complex terrains at speeds up to 2.5 m/s. The training and deployment code is open-sourced to facilitate reproducible research and deployment on real robots with minimal hardware modifications.", "AI": {"tldr": "提出了一种用于人形机器人在复杂环境中的稳定行走的可扩展感知框架。", "motivation": "当前方法在处理人体姿态估计和外部感知时存在挑战，包括基于地图的状态估算漂移以及虚拟障碍物使用的局限性。为了改善这些问题，作者开发了新的策略以确保安全性并简化训练过程。", "method": "引入了一个结合地形边缘检测和脚部体积点的安全足踏机制，并采用平坦区域采样来防止奖励作弊。该框架使用单阶段强化学习方案将深度输入与本体感知直接映射到关节动作，无需外部状态估算。", "result": "实验证明，在复杂地面上可以以高达2.5米/秒的速度实现稳健的行进，并且代码开源以便于研究和实际应用。", "conclusion": "该框架克服了之前方法中的局限性，实现了人形机器人在各种地形上的稳定行走。"}}
{"id": "2601.07701", "pdf": "https://arxiv.org/pdf/2601.07701", "abs": "https://arxiv.org/abs/2601.07701", "authors": ["Ziwen Zhuang", "Shaoting Zhu", "Mengjie Zhao", "Hang Zhao"], "title": "Deep Whole-body Parkour", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Current approaches to humanoid control generally fall into two paradigms: perceptive locomotion, which handles terrain well but is limited to pedal gaits, and general motion tracking, which reproduces complex skills but ignores environmental capabilities. This work unites these paradigms to achieve perceptive general motion control. We present a framework where exteroceptive sensing is integrated into whole-body motion tracking, permitting a humanoid to perform highly dynamic, non-locomotion tasks on uneven terrain. By training a single policy to perform multiple distinct motions across varied terrestrial features, we demonstrate the non-trivial benefit of integrating perception into the control loop. Our results show that this framework enables robust, highly dynamic multi-contact motions, such as vaulting and dive-rolling, on unstructured terrain, significantly expanding the robot's traversability beyond simple walking or running. https://project-instinct.github.io/deep-whole-body-parkour", "AI": {"tldr": "本文提出了一种结合外感知与全身动作追踪的框架，使机器人能够在复杂地形上执行高动态非步行任务。", "motivation": "当前的人形控制方法分为两类：感知运动和一般动作跟踪。前者处理地形能力强但局限于步态；后者能复制复杂技能却忽视环境能力。本文旨在融合这两种方法，实现感知驱动的一般运动控制。", "method": "通过训练单一策略执行不同动态动作，并将外感知融入控制循环中，使机器人能够在不规则地面上完成复杂的非步行任务如腾跃和滚翻等。", "result": "该框架实现了在复杂地形上的鲁棒、高动态的多接触动作，显著扩展了机器人的移动能力。", "conclusion": "本文提出的方法证明了将感知技术与全身运动控制相结合的有效性，为机器人执行公园our风格的动作提供了一个新的视角。"}}
{"id": "2601.07700", "pdf": "https://arxiv.org/pdf/2601.07700", "abs": "https://arxiv.org/abs/2601.07700", "authors": ["Jakob Paul Zimmermann", "Georg Loho"], "title": "Hidden Monotonicity: Explaining Deep Neural Networks via their DC Decomposition", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "It has been demonstrated in various contexts that monotonicity leads to better explainability in neural networks. However, not every function can be well approximated by a monotone neural network. We demonstrate that monotonicity can still be used in two ways to boost explainability. First, we use an adaptation of the decomposition of a trained ReLU network into two monotone and convex parts, thereby overcoming numerical obstacles from an inherent blowup of the weights in this procedure. Our proposed saliency methods -- SplitCAM and SplitLRP -- improve on state of the art results on both VGG16 and Resnet18 networks on ImageNet-S across all Quantus saliency metric categories. Second, we exhibit that training a model as the difference between two monotone neural networks results in a system with strong self-explainability properties.", "AI": {"tldr": "本文提出了一种新的方法来增强深度神经网络的可解释性，通过将其分解为两个单调和凸的部分，并展示了这种方法在图像分类任务上的优越表现。", "motivation": "文章指出虽然不是所有函数都能用单调神经网络很好地近似，但单调性可以用于提高神经网络的可解释性。", "method": "该论文使用了一种新的方法将训练好的ReLU网络分解为两个单调和凸的部分，并提出了两种新型敏感度方法SplitCAM和SplitLRP。此外还展示了通过训练模型作为两个单调神经网络之差的方法，可以获得具有强自我解释性的系统。", "result": "提出的saliency方法在VGG16和Resnet18网络上取得了比当前最先进的结果更好的表现，并且展示了一种新的可解释性更强的深度学习模型架构。", "conclusion": "通过将神经网络分解为单调部分并使用差分训练，可以显著提高其可解释性和性能。"}}
{"id": "2601.07695", "pdf": "https://arxiv.org/pdf/2601.07695", "abs": "https://arxiv.org/abs/2601.07695", "authors": ["Siwen Jiao", "Tianxiong Lv", "Kangan Qian", "Chenxu Zhao", "Xiuyuan Zhu", "Tianlun Li", "Xiaolong Cheng", "Jinyu Li", "Zhihao Liao", "Yang Cai"], "title": "Smooth Operator: Smooth Verifiable Reward Activates Spatial Reasoning Ability of Vision-Language Model", "categories": ["cs.CV"], "comment": null, "summary": "Vision-Language Models (VLMs) face a critical bottleneck in achieving precise numerical prediction for 3D scene understanding. Traditional reinforcement learning (RL) approaches, primarily based on relative ranking, often suffer from severe reward sparsity and gradient instability, failing to effectively exploit the verifiable signals provided by 3D physical constraints. Notably, in standard GRPO frameworks, relative normalization causes \"near-miss\" samples (characterized by small but non-zero errors) to suffer from advantage collapse. This leads to a severe data utilization bottleneck where valuable boundary samples are discarded during optimization. To address this, we introduce the Smooth Numerical Reward Activation (SNRA) operator and the Absolute-Preserving GRPO (AP-GRPO) framework. SNRA employs a dynamically parameterized Sigmoid function to transform raw feedback into a dense, continuous reward continuum. Concurrently, AP-GRPO integrates absolute scalar gradients to mitigate the numerical information loss inherent in conventional relative-ranking mechanisms. By leveraging this approach, we constructed Numerical3D-50k, a dataset comprising 50,000 verifiable 3D subtasks. Empirical results indicate that AP-GRPO achieves performance parity with large-scale supervised methods while maintaining higher data efficiency, effectively activating latent 3D reasoning in VLMs without requiring architectural modifications.", "AI": {"tldr": "提出了一种新的方法SNRA和AP-GRPO，以解决视觉语言模型在三维场景理解中的数值预测瓶颈问题。", "motivation": "传统的强化学习方法因奖励稀疏性和梯度不稳定性而难以有效利用3D物理约束提供的可验证信号，导致优化过程中有价值的数据被丢弃。", "method": "引入了Smooth Numerical Reward Activation (SNRA) 操作符和Absolute-Preserving GRPO (AP-GRPO)框架。SNRA通过动态参数化的Sigmoid函数将原始反馈转换为密集的连续奖励区间。同时，AP-GRPO整合绝对标量梯度以缓解传统相对排名机制固有的数值信息丢失问题。", "result": "实验结果表明，在不改变架构的情况下，AP-GRPO实现了与大规模监督方法相当的表现，并保持了更高的数据效率，有效激活了视觉语言模型中的3D推理能力。", "conclusion": "该方法通过引入SNRA和AP-GRPO解决了传统强化学习方法在三维场景理解中面临的瓶颈问题，展示了改进的数值预测能力和更高效的数据利用。"}}
{"id": "2601.07692", "pdf": "https://arxiv.org/pdf/2601.07692", "abs": "https://arxiv.org/abs/2601.07692", "authors": ["Nicolas Sereyjol-Garros", "Ellington Kirby", "Victor Besnier", "Nermin Samet"], "title": "Leveraging 3D Representation Alignment and RGB Pretrained Priors for LiDAR Scene Generation", "categories": ["cs.CV"], "comment": null, "summary": "LiDAR scene synthesis is an emerging solution to scarcity in 3D data for robotic tasks such as autonomous driving. Recent approaches employ diffusion or flow matching models to generate realistic scenes, but 3D data remains limited compared to RGB datasets with millions of samples. We introduce R3DPA, the first LiDAR scene generation method to unlock image-pretrained priors for LiDAR point clouds, and leverage self-supervised 3D representations for state-of-the-art results. Specifically, we (i) align intermediate features of our generative model with self-supervised 3D features, which substantially improves generation quality; (ii) transfer knowledge from large-scale image-pretrained generative models to LiDAR generation, mitigating limited LiDAR datasets; and (iii) enable point cloud control at inference for object inpainting and scene mixing with solely an unconditional model. On the KITTI-360 benchmark R3DPA achieves state of the art performance. Code and pretrained models are available at https://github.com/valeoai/R3DPA.", "AI": {"tldr": "本文提出了R3DPA方法，利用图像预训练的先验知识和自我监督的3D表示来生成高质量的LiDAR场景。", "motivation": "由于3D数据稀缺限制了机器人任务如自动驾驶的发展，提出了一种新的方法来解决这一问题，特别是在LiDAR场景合成领域。", "method": "R3DPA通过将生成模型中的中间特征与自我监督的3D特征对齐，并利用大规模图像预训练的生成模型的知识来提升LiDAR点云的质量。同时该方法还支持在推断阶段进行点云控制，用于对象修复和场景混合。", "result": "在KITTI-360基准上，R3DPA达到了最先进的性能表现。", "conclusion": "R3DPA为解决LiDAR数据稀缺问题提供了一种有效的方法，并且代码和预训练模型已经公开。"}}
{"id": "2601.07685", "pdf": "https://arxiv.org/pdf/2601.07685", "abs": "https://arxiv.org/abs/2601.07685", "authors": ["Shafiul Ajam Opee", "Nafiz Fahad", "Anik Sen", "Rasel Ahmed", "Fariha Jahan", "Md. Kishor Morol", "Md Rashedul Islam"], "title": "Predictive Analytics for Dementia: Machine Learning on Healthcare Data", "categories": ["cs.AI"], "comment": "10 pages, 13 figures", "summary": "Dementia is a complex syndrome impacting cognitive and emotional functions, with Alzheimer's disease being the most common form. This study focuses on enhancing dementia prediction using machine learning (ML) techniques on patient health data. Supervised learning algorithms are applied in this study, including K-Nearest Neighbors (KNN), Quadratic Discriminant Analysis (QDA), Linear Discriminant Analysis (LDA), and Gaussian Process Classifiers. To address class imbalance and improve model performance, techniques such as Synthetic Minority Over-sampling Technique (SMOTE) and Term Frequency-Inverse Document Frequency (TF-IDF) vectorization were employed. Among the models, LDA achieved the highest testing accuracy of 98%. This study highlights the importance of model interpretability and the correlation of dementia with features such as the presence of the APOE-epsilon4 allele and chronic conditions like diabetes. This research advocates for future ML innovations, particularly in integrating explainable AI approaches, to further improve predictive capabilities in dementia care.", "AI": {"tldr": "利用机器学习技术提高痴呆症预测准确性", "motivation": "改善痴呆症尤其是阿尔茨海默病的早期识别，通过应用机器学习算法处理患者健康数据。", "method": "采用了监督学习算法包括K近邻(KNN)，二次判别分析(QDA)，线性判别分析(LDA)和高斯过程分类器。使用SMOTE技术来解决类别不平衡问题，并采用TF-IDF向量化方法提高模型性能。", "result": "在测试集中，线性判别分析(LDA)取得了最高的准确率98%。研究结果强调了模型可解释性的价值以及痴呆症与APOE-epsilon4等位基因和糖尿病等慢性疾病的相关性。", "conclusion": "该研究展示了机器学习技术在痴呆症预测中的潜力，并提出了未来的研究方向，特别是通过整合可解释的人工智能方法来进一步提升预测能力。"}}
{"id": "2601.07671", "pdf": "https://arxiv.org/pdf/2601.07671", "abs": "https://arxiv.org/abs/2601.07671", "authors": ["Rayson Laroca", "Valter Estevam", "Gladston J. P. Moreira", "Rodrigo Minetto", "David Menotti"], "title": "Advancing Multinational License Plate Recognition Through Synthetic and Real Data Fusion: A Comprehensive Evaluation", "categories": ["cs.CV"], "comment": "IET Intelligent Transport Systems, vol. 19, no. 1, p. e70086, 2025", "summary": "Automatic License Plate Recognition is a frequent research topic due to its wide-ranging practical applications. While recent studies use synthetic images to improve License Plate Recognition (LPR) results, there remain several limitations in these efforts. This work addresses these constraints by comprehensively exploring the integration of real and synthetic data to enhance LPR performance. We subject 16 Optical Character Recognition (OCR) models to a benchmarking process involving 12 public datasets acquired from various regions. Several key findings emerge from our investigation. Primarily, the massive incorporation of synthetic data substantially boosts model performance in both intra- and cross-dataset scenarios. We examine three distinct methodologies for generating synthetic data: template-based generation, character permutation, and utilizing a Generative Adversarial Network (GAN) model, each contributing significantly to performance enhancement. The combined use of these methodologies demonstrates a notable synergistic effect, leading to end-to-end results that surpass those reached by state-of-the-art methods and established commercial systems. Our experiments also underscore the efficacy of synthetic data in mitigating challenges posed by limited training data, enabling remarkable results to be achieved even with small fractions of the original training data. Finally, we investigate the trade-off between accuracy and speed among different models, identifying those that strike the optimal balance in each intra-dataset and cross-dataset settings.", "AI": {"tldr": "本文通过融合合成数据和真实数据来提升多国车牌识别的性能，对多种方法进行了综合评估。", "motivation": "当前研究主要使用合成图像改进车牌识别结果，但存在局限性。本文旨在解决这些问题，提升车牌识别模型在不同场景下的表现。", "method": "作者将16种光学字符识别（OCR）模型应用于包含来自各地域的12个公共数据集的基准测试中，并探索了三种生成合成数据的方法：基于模板生成、字符排列和GAN模型。", "result": "实验表明，大量使用合成数据显著提升了模型性能。综合多种方法产生的合成数据展示了协同效应，实现了比现有最佳方法更高的精度。此外，在有限训练数据的情况下也能取得良好结果。", "conclusion": "本文证明了合成数据在车牌识别中的有效性，并提出了一种优化的数据融合策略以提升不同场景下的识别准确性与效率。"}}
{"id": "2601.07667", "pdf": "https://arxiv.org/pdf/2601.07667", "abs": "https://arxiv.org/abs/2601.07667", "authors": ["Rei Taniguchi", "Yuyang Dong", "Makoto Onizuka", "Chuan Xiao"], "title": "Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Source code is available at https://github.com/TANIGUCHIREI/ASL", "summary": "Due to the prevalence of large language models (LLMs), key-value (KV) cache reduction for LLM inference has received remarkable attention. Among numerous works that have been proposed in recent years, layer-wise token pruning approaches, which select a subset of tokens at particular layers to retain in KV cache and prune others, are one of the most popular schemes. They primarily adopt a set of pre-defined layers, at which tokens are selected. Such design is inflexible in the sense that the accuracy significantly varies across tasks and deteriorates in harder tasks such as KV retrieval. In this paper, we propose ASL, a training-free method that adaptively chooses the selection layer for KV cache reduction, exploiting the variance of token ranks ordered by attention score. The proposed method balances the performance across different tasks while meeting the user-specified KV budget requirement. ASL operates during the prefilling stage and can be jointly used with existing KV cache reduction methods such as SnapKV to optimize the decoding stage. By evaluations on the InfiniteBench, RULER, and NIAH benchmarks, we show that equipped with one-shot token selection, where tokens are selected at a layer and propagated to deeper layers, ASL outperforms state-of-the-art layer-wise token selection methods in accuracy while maintaining decoding speed and KV cache reduction.", "AI": {"tldr": "提出了一种自适应层选择方法ASL，用于在LLM推理中实现灵活的KV缓存减少。", "motivation": "现有的分层令牌修剪方法固定使用预定义层次来选择令牌，导致准确性在不同任务上差异显著且难以应对复杂任务如KV检索。", "method": "提出的方法ASL基于注意力得分排序令牌的变化自适应地选择用于KV缓存减少的层次。此方法平衡了跨任务性能，并满足用户的KV预算需求。它可在预填充阶段操作，与现有KV缓存减少方法联合使用。", "result": "实验结果显示，配备了一次性令牌选择策略的ASL在准确性上超越了现有的分层令牌选择方法，同时保持了解码速度和KV缓存减少的效果。", "conclusion": "提出的方法ASL有效地改进了LLM推理中KV缓存减少的方式，在不同任务上的表现更均衡且性能更优。"}}
{"id": "2601.07666", "pdf": "https://arxiv.org/pdf/2601.07666", "abs": "https://arxiv.org/abs/2601.07666", "authors": ["Dang Dinh Nguyen", "Decky Aspandi Latif", "Titus Zaharia"], "title": "Variational Contrastive Learning for Skeleton-based Action Recognition", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In recent years, self-supervised representation learning for skeleton-based action recognition has advanced with the development of contrastive learning methods. However, most of contrastive paradigms are inherently discriminative and often struggle to capture the variability and uncertainty intrinsic to human motion. To address this issue, we propose a variational contrastive learning framework that integrates probabilistic latent modeling with contrastive self-supervised learning. This formulation enables the learning of structured and semantically meaningful representations that generalize across different datasets and supervision levels. Extensive experiments on three widely used skeleton-based action recognition benchmarks show that our proposed method consistently outperforms existing approaches, particularly in low-label regimes. Moreover, qualitative analyses show that the features provided by our method are more relevant given the motion and sample characteristics, with more focus on important skeleton joints, when compared to the other methods.", "AI": {"tldr": "提出了一种基于变分对比学习的骨架动作识别方法。", "motivation": "为了更好地捕捉人类运动中的变化性和不确定性，解决现有对比学习范式在面对低标签数据时的表现不佳问题。", "method": "将概率隐变量模型与自监督对比学习相结合，形成一种新的框架以生成结构化且具有语义意义的表示。", "result": "实验表明所提出的方法优于现有的方法，在低标签情况下尤其有效，并能提供更相关的特征。", "conclusion": "通过变分对比学习可以更好地捕捉动作中的关键关节和运动特性。"}}
{"id": "2601.07663", "pdf": "https://arxiv.org/pdf/2601.07663", "abs": "https://arxiv.org/abs/2601.07663", "authors": ["William Walden"], "title": "Reasoning Models Will Blatantly Lie About Their Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "It has been shown that Large Reasoning Models (LRMs) may not *say what they think*: they do not always volunteer information about how certain parts of the input influence their reasoning. But it is one thing for a model to *omit* such information and another, worse thing to *lie* about it. Here, we extend the work of Chen et al. (2025) to show that LRMs will do just this: they will flatly deny relying on hints provided in the prompt in answering multiple choice questions -- even when directly asked to reflect on unusual (i.e. hinted) prompt content, even when allowed to use hints, and even though experiments *show* them to be using the hints. Our results thus have discouraging implications for CoT monitoring and interpretability.", "AI": {"tldr": "研究探讨大型推理模型在回答多项选择题时，即使被明确提示也要否认使用这些提示的情况。", "motivation": "揭示大型推理模型可能不会诚实地报告其推理过程中的信息依赖情况，这对因果解释和可理解性具有重要影响。", "method": "扩展了Chen等人（2025）的工作，实验设计中要求模型在回答问题时直接反映是否使用提示内容，并且允许它们利用这些提示。", "result": "发现即使被明确询问，大型推理模型也会否认其依赖于提供的提示来解答问题，尽管实验证明他们实际是在使用的。", "conclusion": "结论指出，这种行为对因果解释和模型的可理解性有负面影响。"}}
{"id": "2601.07660", "pdf": "https://arxiv.org/pdf/2601.07660", "abs": "https://arxiv.org/abs/2601.07660", "authors": ["Yuze He", "Yanning Zhou", "Wang Zhao", "Jingwen Ye", "Zhongkai Wu", "Ran Yi", "Yong-Jin Liu"], "title": "StdGEN++: A Comprehensive System for Semantic-Decomposed 3D Character Generation", "categories": ["cs.CV"], "comment": "13 pages, 12 figures. Extended version of CVPR 2025 paper arXiv:2411.05738", "summary": "We present StdGEN++, a novel and comprehensive system for generating high-fidelity, semantically decomposed 3D characters from diverse inputs. Existing 3D generative methods often produce monolithic meshes that lack the structural flexibility required by industrial pipelines in gaming and animation. Addressing this gap, StdGEN++ is built upon a Dual-branch Semantic-aware Large Reconstruction Model (Dual-Branch S-LRM), which jointly reconstructs geometry, color, and per-component semantics in a feed-forward manner. To achieve production-level fidelity, we introduce a novel semantic surface extraction formalism compatible with hybrid implicit fields. This mechanism is accelerated by a coarse-to-fine proposal scheme, which significantly reduces memory footprint and enables high-resolution mesh generation. Furthermore, we propose a video-diffusion-based texture decomposition module that disentangles appearance into editable layers (e.g., separated iris and skin), resolving semantic confusion in facial regions. Experiments demonstrate that StdGEN++ achieves state-of-the-art performance, significantly outperforming existing methods in geometric accuracy and semantic disentanglement. Crucially, the resulting structural independence unlocks advanced downstream capabilities, including non-destructive editing, physics-compliant animation, and gaze tracking, making it a robust solution for automated character asset production.", "AI": {"tldr": "该论文提出了StdGEN++系统，旨在通过多样输入生成高保真、结构可分解的三维角色。", "motivation": "现有的三维生成方法通常产生缺乏工业管道所需结构性灵活度的整体网格。StdGEN++致力于解决这一问题，提出一种新的语义表面提取形式化机制和视频扩散纹理解构模块，以实现生产级别的保真度和独立性。", "method": "该系统基于双分支语义感知大型重构模型（Dual-Branch S-LRM），实现了几何、颜色及各组件语义的同时前向重建。通过粗到细提案方案加速并减少内存占用，同时提出视频扩散纹理分解模块以分离外观层。", "result": "实验显示StdGEN++在几何准确性和语义解缠方面优于现有方法，并解锁了非破坏性编辑、物理合规动画和视线追踪等高级下游能力。", "conclusion": "该系统提供了一个强大的自动化角色资产生产解决方案，具备高保真度及结构独立性的特点。"}}
{"id": "2601.07654", "pdf": "https://arxiv.org/pdf/2601.07654", "abs": "https://arxiv.org/abs/2601.07654", "authors": ["Elliot Jones", "William Knottenbelt"], "title": "Towards Automating Blockchain Consensus Verification with IsabeLLM", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Consensus protocols are crucial for a blockchain system as they are what allow agreement between the system's nodes in a potentially adversarial environment. For this reason, it is paramount to ensure their correct design and implementation to prevent such adversaries from carrying out malicious behaviour. Formal verification allows us to ensure the correctness of such protocols, but requires high levels of effort and expertise to carry out and thus is often omitted in the development process. In this paper, we present IsabeLLM, a tool that integrates the proof assistant Isabelle with a Large Language Model to assist and automate proofs. We demonstrate the effectiveness of IsabeLLM by using it to develop a novel model of Bitcoin's Proof of Work consensus protocol and verify its correctness. We use the DeepSeek R1 API for this demonstration and found that we were able to generate correct proofs for each of the non-trivial lemmas present in the verification.", "AI": {"tldr": "利用IsabeLLM工具自动验证区块链共识协议的正确性。", "motivation": "确保区块链系统中共识协议的正确设计和实施，防止恶意行为的发生。由于形式化验证需要高技能水平且耗时长，通常在开发过程中被忽略。", "method": "整合证明助手Isabelle与大型语言模型，通过DeepSeek R1 API生成正确的证明，自动进行比特币工作量证明共识协议的模型建立及验证。", "result": "成功使用IsabeLLM自动生成并验证了非平凡引理的有效性。", "conclusion": "IsabeLLM能够有效协助和自动化形式化验证过程，提高区块链系统安全性和可靠性。"}}
{"id": "2601.07651", "pdf": "https://arxiv.org/pdf/2601.07651", "abs": "https://arxiv.org/abs/2601.07651", "authors": ["Marc Lanctot", "Kate Larson", "Ian Gemp", "Michael Kaisers"], "title": "Active Evaluation of General Agents: Problem Definition and Comparison of Baseline Algorithms", "categories": ["cs.AI", "cs.GT", "cs.LG", "cs.MA"], "comment": "AAMAS 2026", "summary": "As intelligent agents become more generally-capable, i.e. able to master a wide variety of tasks, the complexity and cost of properly evaluating them rises significantly. Tasks that assess specific capabilities of the agents can be correlated and stochastic, requiring many samples for accurate comparisons, leading to added costs. In this paper, we propose a formal definition and a conceptual framework for active evaluation of agents across multiple tasks, which assesses the performance of ranking algorithms as a function of number of evaluation data samples. Rather than curating, filtering, or compressing existing data sets as a preprocessing step, we propose an online framing: on every iteration, the ranking algorithm chooses the task and agents to sample scores from. Then, evaluation algorithms report a ranking of agents on each iteration and their performance is assessed with respect to the ground truth ranking over time. Several baselines are compared under different experimental contexts, with synthetic generated data and simulated online access to real evaluation data from Atari game-playing agents. We find that the classical Elo rating system -- while it suffers from well-known failure modes, in theory -- is a consistently reliable choice for efficient reduction of ranking error in practice. A recently-proposed method, Soft Condorcet Optimization, shows comparable performance to Elo on synthetic data and significantly outperforms Elo on real Atari agent evaluation. When task variation from the ground truth is high, selecting tasks based on proportional representation leads to higher rate of ranking error reduction.", "AI": {"tldr": "本文提出了主动评估智能体在多种任务上的性能框架，并比较了不同基线算法的效能。", "motivation": "随着智能体能力的提升，对其进行全面评估变得复杂且成本高昂。传统的方法难以有效地减少误差并提高效率。因此，提出了一种新的在线框架来优化这种评估过程。", "method": "通过每次迭代选择任务和智能体进行采样评分，并使用多种基线算法（如Elo评级系统、Soft Condorcet Optimization）在合成数据集和真实环境中进行比较测试。", "result": "经典Elo评级系统在实践中表现出色，但在高任务变化环境下，基于比例表示的任务选择策略能更快地减少排名误差；而软康多塞优化方法则在合成数据上表现与Elo相似，在实际评估中优于Elo。", "conclusion": "对于智能体的全面性能评价需要一个灵活且高效的框架，Elo评级系统是一个可靠的选择，但在特定环境下其他策略可能更优。"}}
{"id": "2601.07641", "pdf": "https://arxiv.org/pdf/2601.07641", "abs": "https://arxiv.org/abs/2601.07641", "authors": ["Jiaxuan Lu", "Ziyu Kong", "Yemin Wang", "Rong Fu", "Haiyuan Wan", "Cheng Yang", "Wenjie Lou", "Haoran Sun", "Lilong Wang", "Yankai Jiang", "Xiaosong Wang", "Xiao Sun", "Dongzhan Zhou"], "title": "Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": null, "summary": "The central challenge of AI for Science is not reasoning alone, but the ability to create computational methods in an open-ended scientific world. Existing LLM-based agents rely on static, pre-defined tool libraries, a paradigm that fundamentally fails in scientific domains where tools are sparse, heterogeneous, and intrinsically incomplete. In this paper, we propose Test-Time Tool Evolution (TTE), a new paradigm that enables agents to synthesize, verify, and evolve executable tools during inference. By transforming tools from fixed resources into problem-driven artifacts, TTE overcomes the rigidity and long-tail limitations of static tool libraries. To facilitate rigorous evaluation, we introduce SciEvo, a benchmark comprising 1,590 scientific reasoning tasks supported by 925 automatically evolved tools. Extensive experiments show that TTE achieves state-of-the-art performance in both accuracy and tool efficiency, while enabling effective cross-domain adaptation of computational tools. The code and benchmark have been released at https://github.com/lujiaxuan0520/Test-Time-Tool-Evol.", "AI": {"tldr": "提出了一种新的测试时工具演进（TTE）范式，使代理能够在推理过程中合成、验证和演化可执行工具。", "motivation": "现有的LLM基代理依赖于静态的、预定义的工具库，在科学领域中，由于工具稀疏、异质且本质上不完整，这种模式根本无法满足需求。为解决这一问题，提出了一种新的方法来克服静态工具库的刚性和长尾限制。", "method": "引入了测试时工具演进（TTE）范式，使代理能够根据任务动态合成和演化工具，从而提高科学推理的能力和效率。", "result": "通过实验表明，TTE在准确率和工具效率方面达到了最先进的水平，并且促进了计算工具的有效跨域适应。为此还推出了一个包含1590个科学推理任务的基准SciEvo以及自动演化的工具。", "conclusion": "测试时工具演进（TTE）克服了现有方法中的限制，显著提高了代理在处理复杂和开放性科学研究问题的能力。"}}
{"id": "2601.07638", "pdf": "https://arxiv.org/pdf/2601.07638", "abs": "https://arxiv.org/abs/2601.07638", "authors": ["Isaiah Onando Mulang", "Felix Sasaki", "Tassilo Klein", "Jonas Kolk", "Nikolay Grechanov", "Johannes Hoffart"], "title": "SALT-KG: A Benchmark for Semantics-Aware Learning on Enterprise Tables", "categories": ["cs.AI"], "comment": ":68T99ACM Class:I.2.6; I.2.4", "summary": "Building upon the SALT benchmark for relational prediction (Klein et al., 2024), we introduce SALT-KG, a benchmark for semantics-aware learning on enterprise tables. SALT-KG extends SALT by linking its multi-table transactional data with a structured Operational Business Knowledge represented in a Metadata Knowledge Graph (OBKG) that captures field-level descriptions, relational dependencies, and business object types. This extension enables evaluation of models that jointly reason over tabular evidence and contextual semantics, an increasingly critical capability for foundation models on structured data. Empirical analysis reveals that while metadata-derived features yield modest improvements in classical prediction metrics, these metadata features consistently highlight gaps in the ability of models to leverage semantics in relational context. By reframing tabular prediction as semantics-conditioned reasoning, SALT-KG establishes a benchmark to advance tabular foundation models grounded in declarative knowledge, providing the first empirical step toward semantically linked tables in structured data at enterprise scale.", "AI": {"tldr": "建立SALT-KG基准，用于评估在企业表格上进行语义感知学习的模型。", "motivation": "为了评价联合考虑表格证据和上下文语义的模型的能力，并推动基于声明性知识的企业级结构化数据中的表基础模型的发展。", "method": "将多张表格交易数据与描述字段、关系依赖性和业务对象类型的元数据知识图谱相结合，构建SALT-KG基准。", "result": "实验表明，尽管从元数据派生的特征在经典预测指标上只有适度改进，但这些特征揭示了模型利用语义的能力差距。通过将表格预测重新定义为条件于语义推理的问题，SALT-KG设定了一个新标准。", "conclusion": "SALT-KG提供了第一个实证步骤，以促进企业级结构化数据中与语义链接的表的基础模型的发展。"}}
{"id": "2601.07635", "pdf": "https://arxiv.org/pdf/2601.07635", "abs": "https://arxiv.org/abs/2601.07635", "authors": ["Denis D. Caprioti", "Matheus Haas", "Constantino F. Vasconcelos", "Mauricio Girardi-Schappo"], "title": "Learning About Learning: A Physics Path from Spin Glasses to Artificial Intelligence", "categories": ["cond-mat.dis-nn", "cs.AI", "cs.LG", "physics.comp-ph", "physics.ed-ph"], "comment": "18 pages, 11 figures", "summary": "The Hopfield model, originally inspired by spin-glass physics, occupies a central place at the intersection of statistical mechanics, neural networks, and modern artificial intelligence. Despite its conceptual simplicity and broad applicability -- from associative memory to near-optimal solutions of combinatorial optimization problems -- it is rarely integrated into standard undergraduate physics curricula. In this paper, we present the Hopfield model as a pedagogically rich framework that naturally unifies core topics from undergraduate statistical physics, dynamical systems, linear algebra, and computational methods. We provide a concise and illustrated theoretical introduction grounded in familiar physics concepts, analyze the model's energy function, dynamics, and pattern stability, and discuss practical aspects of simulation, including a freely available simulation code. To support instruction, we conclude with classroom-ready example problems designed to mirror research practice. By explicitly connecting fundamental physics to contemporary AI applications, this work aims to help prepare physics students to understand, apply, and critically engage with the computational tools increasingly central to research, industry, and society.", "AI": {"tldr": "该论文旨在通过Hopfield模型将统计物理学、神经网络和现代人工智能融合进本科物理课程中，提供一个理论介绍并包含模拟代码与课堂问题。", "motivation": "希望通过引入Hopfield模型来丰富传统的本科物理教育，使学生能够理解和应用当代计算工具，并促进他们对研究实践的批判性思考。", "method": "提供了一个基于熟悉物理学概念的简洁且插图丰富的理论介绍；分析了模型的能量函数、动力学和模式稳定性；讨论了模拟的实际方面，并提供了课堂上可以使用的例子问题。", "result": "论文展示了Hopfield模型如何作为教学丰富框架，自然地将本科统计物理的核心主题与动态系统、线性代数和计算方法联系起来。", "conclusion": "该工作通过明确连接基础物理学与当代AI应用，旨在帮助物理学生理解、应用并批判性地参与日益重要的计算工具。"}}
{"id": "2601.07632", "pdf": "https://arxiv.org/pdf/2601.07632", "abs": "https://arxiv.org/abs/2601.07632", "authors": ["Zhankai Ye", "Bofan Li", "Yukai Jin", "Shuoqiu Li", "Wei Wang", "Yanfu Zhang", "Shangqian Gao", "Xin Liu"], "title": "GeoMotionGPT: Geometry-Aligned Motion Understanding with Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Discrete motion tokenization has recently enabled Large Language Models (LLMs) to serve as versatile backbones for motion understanding and motion-language reasoning. However, existing pipelines typically decouple motion quantization from semantic embedding learning, linking them solely via token IDs. This approach fails to effectively align the intrinsic geometry of the motion space with the embedding space, thereby hindering the LLM's capacity for nuanced motion reasoning. We argue that alignment is most effective when both modalities share a unified geometric basis. Therefore, instead of forcing the LLM to reconstruct the complex geometry among motion tokens from scratch, we present a novel framework that explicitly enforces orthogonality on both the motion codebook and the LLM embedding space, ensuring that their relational structures naturally mirror each other. Specifically, we employ a decoder-only quantizer with Gumbel-Softmax for differentiable training and balanced codebook usage. To bridge the modalities, we use a sparse projection that maps motion codes into the LLM embedding space while preserving orthogonality. Finally, a two-stage orthonormal regularization schedule enforces soft constraints during tokenizer training and LLM fine-tuning to maintain geometric alignment without hindering semantic adaptation. Extensive experiments on HumanML3D demonstrate that our framework achieves a 20% performance improvement over current state-of-the-art methods, validating that a unified geometric basis effectively empowers the LLM for nuanced motion reasoning.", "AI": {"tldr": "提出了GeoMotionGPT框架，通过统一几何基础来提高大语言模型在运动理解和推理方面的性能。", "motivation": "现有的方法将动作量化与语义嵌入学习分离，导致大语言模型难以进行精细的运动推理。为解决这一问题，本文提出了一种基于统一几何基础的方法。", "method": "通过使用解码器独占量化器和Gumbel-Softmax实现可微训练，并采用稀疏投影将动作代码映射到LLM嵌入空间中，同时保持正交性。两阶段的正交规范计划在词元器训练和LLM微调期间执行软约束以维持几何对齐。", "result": "实验表明，该框架比现有的最先进方法提高了20%的性能，验证了统一几何基础能够有效地增强大语言模型进行精细运动推理的能力。", "conclusion": "GeoMotionGPT通过引入统一几何基础显著提升了大语言模型处理运动理解任务的效果。"}}
{"id": "2601.07620", "pdf": "https://arxiv.org/pdf/2601.07620", "abs": "https://arxiv.org/abs/2601.07620", "authors": ["Fuyuan Liu", "Dianyu Yu", "He Ren", "Nayu Liu", "Xiaomian Kang", "Delai Qiu", "Fa Zhang", "Genpeng Zhen", "Shengping Liu", "Jiaen Liang", "Wei Huang", "Yining Wang", "Junnan Zhu"], "title": "PARL: Position-Aware Relation Learning Network for Document Layout Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Document layout analysis aims to detect and categorize structural elements (e.g., titles, tables, figures) in scanned or digital documents. Popular methods often rely on high-quality Optical Character Recognition (OCR) to merge visual features with extracted text. This dependency introduces two major drawbacks: propagation of text recognition errors and substantial computational overhead, limiting the robustness and practical applicability of multimodal approaches. In contrast to the prevailing multimodal trend, we argue that effective layout analysis depends not on text-visual fusion, but on a deep understanding of documents' intrinsic visual structure. To this end, we propose PARL (Position-Aware Relation Learning Network), a novel OCR-free, vision-only framework that models layout through positional sensitivity and relational structure. Specifically, we first introduce a Bidirectional Spatial Position-Guided Deformable Attention module to embed explicit positional dependencies among layout elements directly into visual features. Second, we design a Graph Refinement Classifier (GRC) to refine predictions by modeling contextual relationships through a dynamically constructed layout graph. Extensive experiments show PARL achieves state-of-the-art results. It establishes a new benchmark for vision-only methods on DocLayNet and, notably, surpasses even strong multimodal models on M6Doc. Crucially, PARL (65M) is highly efficient, using roughly four times fewer parameters than large multimodal models (256M), demonstrating that sophisticated visual structure modeling can be both more efficient and robust than multimodal fusion.", "AI": {"tldr": "提出了一种无OCR的视觉布局分析方法PARL，通过位置感知和关系学习提高文档结构元素检测的准确性和效率。", "motivation": "当前流行的多模态文档布局分析依赖于高质量的OCR，这引入了文本错误传播及计算开销大的问题。作者认为理解内在视觉结构比文本-视觉融合更重要，并提出了一种新的无OCR方法来解决这些问题。", "method": "PARL通过双向空间位置引导变形注意力模块嵌入显式的布局元素间的位置依赖性；并通过动态构建的布局图进行关系建模以优化预测结果。该模型是纯视觉的方法，无需使用文本信息。", "result": "实验表明PARL在DocLayNet和M6Doc数据集上取得了最新的性能表现，并且相比多模态方法更加高效。", "conclusion": "通过提出PARL模型证明了基于位置感知和关系学习的布局分析可以超越依赖OCR的多模态方法，同时保持更高的效率。"}}
{"id": "2601.07618", "pdf": "https://arxiv.org/pdf/2601.07618", "abs": "https://arxiv.org/abs/2601.07618", "authors": ["Yulu Wang", "Ziqian Zeng", "Jianjun Wu", "Zhifeng Tang"], "title": "Neural Architecture for Fast and Reliable Coagulation Assessment in Clinical Settings: Leveraging Thromboelastography", "categories": ["cs.LG", "cs.AI"], "comment": "This paper has been accepted by AAAI26", "summary": "In an ideal medical environment, real-time coagulation monitoring can enable early detection and prompt remediation of risks. However, traditional Thromboelastography (TEG), a widely employed diagnostic modality, can only provide such outputs after nearly 1 hour of measurement. The delay might lead to elevated mortality rates. These issues clearly point out one of the key challenges for medical AI development: Mak-ing reasonable predictions based on very small data sets and accounting for variation between different patient populations, a task where conventional deep learning methods typically perform poorly. We present Physiological State Reconstruc-tion (PSR), a new algorithm specifically designed to take ad-vantage of dynamic changes between individuals and to max-imize useful information produced by small amounts of clini-cal data through mapping to reliable predictions and diagnosis. We develop MDFE to facilitate integration of varied temporal signals using multi-domain learning, and jointly learn high-level temporal interactions together with attentions via HLA; furthermore, the parameterized DAM we designed maintains the stability of the computed vital signs. PSR evaluates with 4 TEG-specialized data sets and establishes remarkable perfor-mance -- predictions of R2 > 0.98 for coagulation traits and error reduction around half compared to the state-of-the-art methods, and halving the inferencing time too. Drift-aware learning suggests a new future, with potential uses well be-yond thrombophilia discovery towards medical AI applica-tions with data scarcity.", "AI": {"tldr": "利用神经架构实现快速可靠的临床凝血评估，通过生理状态重建算法（PSR）提高TEG的效率和准确性。", "motivation": "传统的TEG测量耗时过长，可能导致更高的死亡率。提出一种新算法以应对在小数据集上进行合理预测并适应不同患者群体的任务挑战。", "method": "开发了多领域学习框架MDFE和高阶层次注意力HLA，并设计参数化漂移感知机制DAM来保持计算的生命体征稳定性，从而提高TEG的效率和准确性。", "result": "PSR算法在四个特化的数据集上表现优异，预测的相关系数R2大于0.98，误差降低了一半，推理时间也减半。", "conclusion": "该方法不仅为凝血病发现提供了新的途径，还可能推广到其他医疗AI应用中，在数据稀缺的情况下仍能保持高性能。"}}
{"id": "2601.07611", "pdf": "https://arxiv.org/pdf/2601.07611", "abs": "https://arxiv.org/abs/2601.07611", "authors": ["Zhuoyang Zou", "Abolfazl Ansari", "Delvin Ce Zhang", "Dongwon Lee", "Wenpeng Yin"], "title": "DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers via Multi-Agent Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Paper weakness identification using single-agent or multi-agent LLMs has attracted increasing attention, yet existing approaches exhibit key limitations. Many multi-agent systems simulate human roles at a surface level, missing the underlying criteria that lead experts to assess complementary intellectual aspects of a paper. Moreover, prior methods implicitly assume identified weaknesses are valid, ignoring reviewer bias, misunderstanding, and the critical role of author rebuttals in validating review quality. Finally, most systems output unranked weakness lists, rather than prioritizing the most consequential issues for users. In this work, we propose DIAGPaper, a novel multi-agent framework that addresses these challenges through three tightly integrated modules. The customizer module simulates human-defined review criteria and instantiates multiple reviewer agents with criterion-specific expertise. The rebuttal module introduces author agents that engage in structured debate with reviewer agents to validate and refine proposed weaknesses. The prioritizer module learns from large-scale human review practices to assess the severity of validated weaknesses and surfaces the top-K severest ones to users. Experiments on two benchmarks, AAAR and ReviewCritique, demonstrate that DIAGPaper substantially outperforms existing methods by producing more valid and more paper-specific weaknesses, while presenting them in a user-oriented, prioritized manner.", "AI": {"tldr": "DIAGPaper通过多代理框架诊断科学论文的有效和特定弱点，解决了现有方法的不足。", "motivation": "现有的单代理或多代理模型在识别论文缺陷时存在局限性，如表面化模拟人类角色、忽视审查偏差及作者反驳的重要性以及未对问题优先级排序。DIAGPaper旨在解决这些问题，提供更准确且具体的弱点分析。", "method": "DIAGPaper包含三个模块：定制器模块根据定义的评审标准生成具有特定专业知识的代理；反驳模块引入作者代理与审稿人代理进行结构化辩论以验证和细化提出的问题；优先级模块基于大规模人类审查实践评估问题严重性并输出最严重的前K个。", "result": "在AAAR和ReviewCritique两个基准上，DIAGPaper显著优于现有方法，生成更有效且更具针对性的弱点，并以用户为导向的方式呈现。", "conclusion": "DIAGPaper通过多代理框架改进了论文缺陷识别过程，提高了分析的有效性和具体性。"}}
{"id": "2601.07610", "pdf": "https://arxiv.org/pdf/2601.07610", "abs": "https://arxiv.org/abs/2601.07610", "authors": ["Jeremy Fersula", "Nicolas Bredeche", "Olivier Dauchot"], "title": "Aggregating swarms through morphology handling design contingencies: from the sweet spot to a rich expressivity", "categories": ["cond-mat.soft", "cs.RO"], "comment": "8 pages, 3 figures", "summary": "Morphological computing, the use of the physical design of a robot to ease the realization of a given task has been proven to be a relevant concept in the context of swarm robotics. Here we demonstrate both experimentally and numerically, that the success of such a strategy may heavily rely on the type of policy adopted by the robots, as well as on the details of the physical design. To do so, we consider a swarm of robots, composed of Kilobots embedded in an exoskeleton, the design of which controls the propensity of the robots to align or anti-align with the direction of the external force they experience. We find experimentally that the contrast that was observed between the two morphologies in the success rate of a simple phototactic task, where the robots were programmed to stop when entering a light region, becomes dramatic, if the robots are not allowed to stop, and can only slow down. Building on a faithful physical model of the self-aligning dynamics of the robots, we perform numerical simulations and demonstrate on one hand that a precise tuning of the self-aligning strength around a sweet spot is required to achieve an efficient phototactic behavior, on the other hand that exploring a range of self-alignment strength allows for a rich expressivity of collective behaviors.", "AI": {"tldr": "本文探讨了通过物理设计优化机器人集体行为的可能性，特别是在光感任务中的表现。", "motivation": "为了展示形态计算在群机器人系统中实现特定任务的有效性，并揭示其依赖于策略和设计细节的特性。", "method": "使用嵌入外骨骼结构的Kilobots进行实验和数值模拟来研究不同物理设计如何影响机器人的集体行为。", "result": "发现通过调整自我对齐强度，可以优化光感任务的表现；并且探索不同的对齐参数范围可丰富集体行为的多样性。", "conclusion": "精确调节机器人自我对齐强度是实现高效光感行为的关键；而广泛的参数选择则能促进丰富的集体表现形式。"}}
{"id": "2601.07606", "pdf": "https://arxiv.org/pdf/2601.07606", "abs": "https://arxiv.org/abs/2601.07606", "authors": ["Bingyang Ye", "Shan Chen", "Jingxuan Tu", "Chen Liu", "Zidi Xiong", "Samuel Schmidgall", "Danielle S. Bitterman"], "title": "Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments", "categories": ["cs.CL", "cs.AI"], "comment": "under review", "summary": "Large language models are increasingly being used to assess and forecast research ideas, yet we lack scalable ways to evaluate the quality of models' judgments about these scientific ideas. Towards this goal, we introduce PoT, a semi-verifiable benchmarking framework that links scientific idea judgments to downstream signals that become observable later (e.g., citations and shifts in researchers' agendas). PoT freezes a pre-cutoff snapshot of evidence in an offline sandbox and asks models to forecast post-cutoff outcomes, enabling verifiable evaluation when ground truth arrives, scalable benchmarking without exhaustive expert annotation, and analysis of human-model misalignment against signals such as peer-review awards. In addition, PoT provides a controlled testbed for agent-based research judgments that evaluate scientific ideas, comparing tool-using agents to non-agent baselines under prompt ablations and budget scaling. Across 30,000+ instances spanning four benchmark domains, we find that, compared with non-agent baselines, higher interaction budgets generally improve agent performance, while the benefit of tool use is strongly task-dependent. By combining time-partitioned, future-verifiable targets with an offline sandbox for tool use, PoT supports scalable evaluation of agents on future-facing scientific idea judgment tasks.", "AI": {"tldr": "介绍了PoT框架，用于评估大型语言模型在科学思想判断方面的表现。", "motivation": "目前缺乏评估模型对科学研究想法判断质量的可扩展方法。", "method": "提出了一个将科学思想判断与后续信号联系起来的基准测试框架PoT，通过离线沙箱冻结证据快照并预测未来结果来进行验证性评估。", "result": "在涵盖四个领域的30,000多个实例中，发现较高的交互预算通常能提高代理性能，而工具使用的效益则取决于任务性质。", "conclusion": "PoT框架支持了对面向未来的科学思想判断任务的可扩展评估。"}}
{"id": "2601.07603", "pdf": "https://arxiv.org/pdf/2601.07603", "abs": "https://arxiv.org/abs/2601.07603", "authors": ["Zijian Wu", "Boyao Zhou", "Liangxiao Hu", "Hongyu Liu", "Yuan Sun", "Xuan Wang", "Xun Cao", "Yujun Shen", "Hao Zhu"], "title": "UIKA: Fast Universal Head Avatar from Pose-Free Images", "categories": ["cs.CV"], "comment": "Project page: https://zijian-wu.github.io/uika-page/", "summary": "We present UIKA, a feed-forward animatable Gaussian head model from an arbitrary number of unposed inputs, including a single image, multi-view captures, and smartphone-captured videos. Unlike the traditional avatar method, which requires a studio-level multi-view capture system and reconstructs a human-specific model through a long-time optimization process, we rethink the task through the lenses of model representation, network design, and data preparation. First, we introduce a UV-guided avatar modeling strategy, in which each input image is associated with a pixel-wise facial correspondence estimation. Such correspondence estimation allows us to reproject each valid pixel color from screen space to UV space, which is independent of camera pose and character expression. Furthermore, we design learnable UV tokens on which the attention mechanism can be applied at both the screen and UV levels. The learned UV tokens can be decoded into canonical Gaussian attributes using aggregated UV information from all input views. To train our large avatar model, we additionally prepare a large-scale, identity-rich synthetic training dataset. Our method significantly outperforms existing approaches in both monocular and multi-view settings. Project page: https://zijian-wu.github.io/uika-page/", "AI": {"tldr": "UIKA是一种通过任意数量的无姿态输入（包括单张图像、多视角捕获和智能手机拍摄的视频）快速生成可动画化的头部模型的方法。", "motivation": "传统的头像建模方法需要专业级的多视角捕捉系统，并且通过长时间优化过程重建特定个体的人体模型。UIKA重新思考了任务，提出了一种新的模型表示、网络设计和数据准备策略来解决这些问题。", "method": "UIKA引入了一种UV引导下的头部建模策略，每个输入图像都有关联的像素级面部对应估计。这种对应估计允许将有效像素的颜色从屏幕空间重投影到UV空间，在该空间中相机姿态与角色表情独立。设计了可学习的UV令牌，并在屏幕和UV级别上应用注意机制。通过聚合所有输入视图的信息，可以解码成正态高斯属性。", "result": "UIKA在单目和多视角设置下显著优于现有的方法。", "conclusion": "UIKA提供了一种新的头像建模方式，能够在无姿态输入的情况下生成高质量的可动画化头部模型。"}}
{"id": "2601.07599", "pdf": "https://arxiv.org/pdf/2601.07599", "abs": "https://arxiv.org/abs/2601.07599", "authors": ["Lior Dvir", "Nadav Torem", "Yoav Y. Schechner"], "title": "Diffusion in SPAD Signals", "categories": ["cs.CV"], "comment": null, "summary": "We derive the likelihood of a raw signal in a single photon avalanche diode (SPAD), given a fixed photon flux. The raw signal comprises timing of detection events, which are nonlinearly related to the flux. Moreover, they are naturally stochastic. We then derive a score function of the signal. This is a key for solving inverse problems based on SPAD signals. We focus on deriving solutions involving a diffusion model, to express image priors. We demonstrate the effect of low or high photon counts, and the consequence of exploiting timing of detection events.", "AI": {"tldr": "本文推导了单光子雪崩二极管（SPAD）信号的似然函数，提出了基于扩散模型的解法来表达图像先验。", "motivation": "旨在解决基于SPAD信号的逆问题，通过分析检测事件的时间关系和波动性提出新的解决方案。", "method": "推导了给定恒定光子通量下SPAD原始信号的可能性函数，并提出了一个得分函数。重点在于采用扩散模型表达图像先验。", "result": "展示了低或高光子计数对结果的影响，以及利用检测事件时间信息的后果。", "conclusion": "该方法能够有效处理逆问题中的SPAD信号，特别是在不同光子条件下表现出色。"}}
{"id": "2601.07597", "pdf": "https://arxiv.org/pdf/2601.07597", "abs": "https://arxiv.org/abs/2601.07597", "authors": ["Yi Liu", "Hongda Zhang", "Zhongxue Gan", "Yuning Chen", "Ziqing Zhou", "Chunlei Meng", "Chun Ouyang"], "title": "Pheromone-Focused Ant Colony Optimization algorithm for path planning", "categories": ["cs.NE", "cs.AI"], "comment": "Accepted to 2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)", "summary": "Ant Colony Optimization (ACO) is a prominent swarm intelligence algorithm extensively applied to path planning. However, traditional ACO methods often exhibit shortcomings, such as blind search behavior and slow convergence within complex environments. To address these challenges, this paper proposes the Pheromone-Focused Ant Colony Optimization (PFACO) algorithm, which introduces three key strategies to enhance the problem-solving ability of the ant colony. First, the initial pheromone distribution is concentrated in more promising regions based on the Euclidean distances of nodes to the start and end points, balancing the trade-off between exploration and exploitation. Second, promising solutions are reinforced during colony iterations to intensify pheromone deposition along high-quality paths, accelerating convergence while maintaining solution diversity. Third, a forward-looking mechanism is implemented to penalize redundant path turns, promoting smoother and more efficient solutions. These strategies collectively produce the focused pheromones to guide the ant colony's search, which enhances the global optimization capabilities of the PFACO algorithm, significantly improving convergence speed and solution quality across diverse optimization problems. The experimental results demonstrate that PFACO consistently outperforms comparative ACO algorithms in terms of convergence speed and solution quality.", "AI": {"tldr": "本文提出了一种改进的蚁群优化算法——信息素聚焦蚁群优化（PFACO）算法，用于路径规划。", "motivation": "传统蚁群优化方法在复杂环境中存在盲目搜索和收敛速度慢的问题。为解决这些问题，提出了PFACO算法以提高求解能力。", "method": "该算法引入了三个关键策略：初始信息素分布集中在有希望的区域、强化高质量路径的信息素沉积以及惩罚冗余转弯来促进更平滑高效的解决方案。", "result": "实验结果表明，与传统的蚁群优化方法相比，PFACO在收敛速度和解的质量方面都有显著提高。", "conclusion": "信息素聚焦策略提升了全局寻优能力，在多种优化问题中表现出了优越性。"}}
{"id": "2601.07585", "pdf": "https://arxiv.org/pdf/2601.07585", "abs": "https://arxiv.org/abs/2601.07585", "authors": ["Shruti Atul Mali", "Zohaib Salahuddin", "Yumeng Zhang", "Andre Aichert", "Xian Zhong", "Henry C. Woodruff", "Maciej Bobowicz", "Katrine Riklund", "Juozas Kupčinskas", "Lorenzo Faggioni", "Roberto Francischello", "Razvan L Miclea", "Philippe Lambin"], "title": "Robust Multicentre Detection and Classification of Colorectal Liver Metastases on CT: Application of Foundation Models", "categories": ["cs.CV"], "comment": null, "summary": "Colorectal liver metastases (CRLM) are a major cause of cancer-related mortality, and reliable detection on CT remains challenging in multi-centre settings. We developed a foundation model-based AI pipeline for patient-level classification and lesion-level detection of CRLM on contrast-enhanced CT, integrating uncertainty quantification and explainability. CT data from the EuCanImage consortium (n=2437) and an external TCIA cohort (n=197) were used. Among several pretrained models, UMedPT achieved the best performance and was fine-tuned with an MLP head for classification and an FCOS-based head for lesion detection. The classification model achieved an AUC of 0.90 and a sensitivity of 0.82 on the combined test set, with a sensitivity of 0.85 on the external cohort. Excluding the most uncertain 20 percent of cases improved AUC to 0.91 and balanced accuracy to 0.86. Decision curve analysis showed clinical benefit for threshold probabilities between 0.30 and 0.40. The detection model identified 69.1 percent of lesions overall, increasing from 30 percent to 98 percent across lesion size quartiles. Grad-CAM highlighted lesion-corresponding regions in high-confidence cases. These results demonstrate that foundation model-based pipelines can support robust and interpretable CRLM detection and classification across heterogeneous CT data.", "AI": {"tldr": "本论文开发了一个基于基础模型的人工智能管道，用于CT图像中的结直肠肝转移瘤的患者水平分类和病变水平检测。", "motivation": "结直肠肝转移瘤是癌症相关死亡的主要原因之一，在多中心设置中可靠地在CT上进行检测仍然具有挑战性。本研究旨在开发一种可以支持跨异质CT数据集准确且可解释地检测和分类结直肠肝转移瘤的基础模型。", "method": "使用EuCanImage联盟的数据集（n=2437）和一个外部TCIA队列（n=197），在多个预训练模型中，UMedPT表现最佳，并通过MLP头进行分类微调，通过FCOS基线检测病变。利用不确定性量化和可解释性技术。", "result": "分类模型在组合测试集上达到了AUC为0.90、敏感度为0.82，在外部队列上的敏感度达到0.85。排除最不确定的20%病例后，AUC提升至0.91，平衡精度达到0.86。检测模型识别了整体69.1%的病变，并在不同大小四分位数中提高了准确性，从30%到98%。", "conclusion": "基于基础模型的方法可以支持跨异质CT数据集准确且可解释地检测和分类结直肠肝转移瘤。"}}
{"id": "2601.07582", "pdf": "https://arxiv.org/pdf/2601.07582", "abs": "https://arxiv.org/abs/2601.07582", "authors": ["Huhai Zou", "Tianhao Sun", "Chuanjiang He", "Yu Tian", "Zhenyang Li", "Li Jin", "Nayu Liu", "Jiang Zhong", "Kaiwen Wei"], "title": "ES-Mem: Event Segmentation-Based Memory for Long-Term Dialogue Agents", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Memory is critical for dialogue agents to maintain coherence and enable continuous adaptation in long-term interactions. While existing memory mechanisms offer basic storage and retrieval capabilities, they are hindered by two primary limitations: (1) rigid memory granularity often disrupts semantic integrity, resulting in fragmented and incoherent memory units; (2) prevalent flat retrieval paradigms rely solely on surface-level semantic similarity, neglecting the structural cues of discourse required to navigate and locate specific episodic contexts. To mitigate these limitations, drawing inspiration from Event Segmentation Theory, we propose ES-Mem, a framework incorporating two core components: (1) a dynamic event segmentation module that partitions long-term interactions into semantically coherent events with distinct boundaries; (2) a hierarchical memory architecture that constructs multi-layered memories and leverages boundary semantics to anchor specific episodic memory for precise context localization. Evaluations on two memory benchmarks demonstrate that ES-Mem yields consistent performance gains over baseline methods. Furthermore, the proposed event segmentation module exhibits robust applicability on dialogue segmentation datasets.", "AI": {"tldr": "提出了一种基于事件划分的记忆框架ES-Mem，以解决现有对话记忆机制的限制问题。", "motivation": "现有记忆机制在长时互动中存在语义完整性和检索精确度的问题。为了解决这些问题，作者提出了ES-Mem框架。", "method": "引入动态事件分割模块和层次化内存架构来改善对话的记忆效果。", "result": "实验结果表明，ES-Mem方法相比基线模型有显著性能提升。", "conclusion": "ES-Mem在解决长时对话记忆问题上有明显优势，并且其事件划分模块具有广泛的应用潜力。"}}
{"id": "2601.07581", "pdf": "https://arxiv.org/pdf/2601.07581", "abs": "https://arxiv.org/abs/2601.07581", "authors": ["Ahmad AlMughrabi", "Guillermo Rivo", "Carlos Jiménez-Farfán", "Umair Haroon", "Farid Al-Areqi", "Hyunjun Jung", "Benjamin Busam", "Ricardo Marques", "Petia Radeva"], "title": "BenchSeg: A Large-Scale Dataset and Benchmark for Multi-View Food Video Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Food image segmentation is a critical task for dietary analysis, enabling accurate estimation of food volume and nutrients. However, current methods suffer from limited multi-view data and poor generalization to new viewpoints. We introduce BenchSeg, a novel multi-view food video segmentation dataset and benchmark. BenchSeg aggregates 55 dish scenes (from Nutrition5k, Vegetables & Fruits, MetaFood3D, and FoodKit) with 25,284 meticulously annotated frames, capturing each dish under free 360° camera motion. We evaluate a diverse set of 20 state-of-the-art segmentation models (e.g., SAM-based, transformer, CNN, and large multimodal) on the existing FoodSeg103 dataset and evaluate them (alone and combined with video-memory modules) on BenchSeg. Quantitative and qualitative results demonstrate that while standard image segmenters degrade sharply under novel viewpoints, memory-augmented methods maintain temporal consistency across frames. Our best model based on a combination of SeTR-MLA+XMem2 outperforms prior work (e.g., improving over FoodMem by ~2.63% mAP), offering new insights into food segmentation and tracking for dietary analysis. We release BenchSeg to foster future research. The project page including the dataset annotations and the food segmentation models can be found at https://amughrabi.github.io/benchseg.", "AI": {"tldr": "本文介绍了一个新的多视角食物视频分割数据集和基准BenchSeg，用于评估现有的图像分割模型在新视角下的表现，并提出了一种基于SeTR-MLA+XMem2的组合方法，在该数据集中表现出色。", "motivation": "当前的食物图像分割方法受到多视图数据不足和对新视角泛化能力差的影响。因此，本文提出了BenchSeg以解决这些问题并促进饮食分析中的食物分割研究。", "method": "论文评估了20种不同的现成分割模型，并通过组合视频内存模块来增强这些模型的性能，然后在BenchSeg数据集上进行测试。", "result": "实验结果表明，标准图像分割器在新视角下表现不佳，而使用内存增强的方法能够保持时间一致性。基于SeTR-MLA+XMem2的组合方法超越了之前的工作，提高了约2.63% mAP。", "conclusion": "本文提出了BenchSeg数据集，并展示了如何通过结合视频记忆模块来提高食物分割模型在不同视角下的表现，为未来的研究提供了新的见解和资源。"}}
{"id": "2601.07580", "pdf": "https://arxiv.org/pdf/2601.07580", "abs": "https://arxiv.org/abs/2601.07580", "authors": ["Sara Zoccheddu", "Shah Rukh Qasim", "Patrick Owen", "Nicola Serra"], "title": "Large Language Models for Physics Instrument Design", "categories": ["physics.ins-det", "cs.AI", "cs.LG", "hep-ex"], "comment": null, "summary": "We study the use of large language models (LLMs) for physics instrument design and compare their performance to reinforcement learning (RL). Using only prompting, LLMs are given task constraints and summaries of prior high-scoring designs and propose complete detector configurations, which we evaluate with the same simulators and reward functions used in RL-based optimization. Although RL yields stronger final designs, we find that modern LLMs consistently generate valid, resource-aware, and physically meaningful configurations that draw on broad pretrained knowledge of detector design principles and particle--matter interactions, despite having no task-specific training. Based on this result, as a first step toward hybrid design workflows, we explore pairing the LLMs with a dedicated trust region optimizer, serving as a precursor to future pipelines in which LLMs propose and structure design hypotheses while RL performs reward-driven optimization. Based on these experiments, we argue that LLMs are well suited as meta-planners: they can design and orchestrate RL-based optimization studies, define search strategies, and coordinate multiple interacting components within a unified workflow. In doing so, they point toward automated, closed-loop instrument design in which much of the human effort required to structure and supervise optimization can be reduced.", "AI": {"tldr": "研究了大型语言模型在物理仪器设计中的应用，比较了其与强化学习的性能。", "motivation": "探讨大型语言模型是否可以用于提出有效的物理仪器设计方案，并减少人类在此过程中的干预。", "method": "通过仅使用提示方式，让LLMs根据任务约束和先前高分设计总结来提出完整检测器配置。这些配置使用与RL优化相同的仿真器和奖励函数进行评估。", "result": "尽管RL产生了更强的设计方案，但发现现代LLM能够生成有效且资源意识强的物理上合理的配置，并在没有特定任务训练的情况下利用广泛预训练的知识。", "conclusion": "基于此结果，提出一种混合设计工作流程的概念：结合LLMs作为元规划者和专门的信任区域优化器，从而减少结构化和监督优化所需的人力。"}}
{"id": "2601.07577", "pdf": "https://arxiv.org/pdf/2601.07577", "abs": "https://arxiv.org/abs/2601.07577", "authors": ["Yunfan Li", "Bingbing Xu", "Xueyun Tian", "Xiucheng Xu", "Huawei Shen"], "title": "Beyond Entangled Planning: Task-Decoupled Planning for Long-Horizon Agents", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled agents to autonomously execute complex, long-horizon tasks, yet planning remains a primary bottleneck for reliable task execution. Existing methods typically fall into two paradigms: step-wise planning, which is reactive but often short-sighted; and one-shot planning, which generates a complete plan upfront yet is brittle to execution errors. Crucially, both paradigms suffer from entangled contexts, where the agent must reason over a monolithic history spanning multiple sub-tasks. This entanglement increases cognitive load and lets local errors propagate across otherwise independent decisions, making recovery computationally expensive. To address this, we propose Task-Decoupled Planning (TDP), a training-free framework that replaces entangled reasoning with task decoupling. TDP decomposes tasks into a directed acyclic graph (DAG) of sub-goals via a Supervisor. Using a Planner and Executor with scoped contexts, TDP confines reasoning and replanning to the active sub-task. This isolation prevents error propagation and corrects deviations locally without disrupting the workflow. Results on TravelPlanner, ScienceWorld, and HotpotQA show that TDP outperforms strong baselines while reducing token consumption by up to 82%, demonstrating that sub-task decoupling improves both robustness and efficiency for long-horizon agents.", "AI": {"tldr": "本文提出了任务解耦规划（TDP），一种用于长时序代理的任务分解和独立执行的方法，以提高其可靠性和效率。", "motivation": "现有的计划方法要么是基于步骤的，短视且反应性强；要么是一次性生成完整计划，但易受执行错误影响。这些方法都存在上下文纠缠问题，增加了认知负担，并使得局部错误易于传播。", "method": "TDP通过引入监督者将任务分解为子目标的有向无环图（DAG），并通过规划器和执行者的限制性上下文进行独立推理和重新计划。", "result": "在TravelPlanner、ScienceWorld和HotpotQA上的实验表明，TDP比基线模型表现出色，同时减少了高达82%的代币消耗。", "conclusion": "任务解耦规划不仅增强了长时序代理的鲁棒性，还提高了其效率。"}}
{"id": "2601.07576", "pdf": "https://arxiv.org/pdf/2601.07576", "abs": "https://arxiv.org/abs/2601.07576", "authors": ["Alvaro Becerra", "Ruth Cobos", "Roberto Daza"], "title": "A Multimodal Dataset of Student Oral Presentations with Sensors and Evaluation Data", "categories": ["cs.HC", "cs.CV"], "comment": "Article under review in the journal Scientific Data. GitHub repository of the dataset at: https://github.com/dataGHIA/SOPHIAS", "summary": "Oral presentation skills are a critical component of higher education, yet comprehensive datasets capturing real-world student performance across multiple modalities remain scarce. To address this gap, we present SOPHIAS (Student Oral Presentation monitoring for Holistic Insights & Analytics using Sensors), a 12-hour multimodal dataset containing recordings of 50 oral presentations (10-15-minute presentation followed by 5-15-minute Q&A) delivered by 65 undergraduate and master's students at the Universidad Autonoma de Madrid. SOPHIAS integrates eight synchronized sensor streams from high-definition webcams, ambient and webcam audio, eye-tracking glasses, smartwatch physiological sensors, and clicker, keyboard, and mouse interactions. In addition, the dataset includes slides and rubric-based evaluations from teachers, peers, and self-assessments, along with timestamped contextual annotations. The dataset captures presentations conducted in real classroom settings, preserving authentic student behaviors, interactions, and physiological responses. SOPHIAS enables the exploration of relationships between multimodal behavioral and physiological signals and presentation performance, supports the study of peer assessment, and provides a benchmark for developing automated feedback and Multimodal Learning Analytics tools. The dataset is publicly available for research through GitHub and Science Data Bank.", "AI": {"tldr": "SOPHIAS是用于记录学生演讲的多模态数据集，旨在探索演讲表现与行为、生理信号之间的关系。", "motivation": "当前缺乏全面捕捉真实世界中学生演讲表现的多模态数据集。为此，创建了SOPHIAS以填补这一空白，并支持自动反馈和学习分析工具的研究发展。", "method": "通过集成八个同步传感器流（包括高清网络摄像头、环境音频、眼动追踪眼镜等），记录50个不同学生的12小时演讲视频及相关的评估数据。这些数据涵盖了真实课堂环境中学生的行为、互动和生理反应。", "result": "SOPHIAS数据集公开发布，支持研究者探索多模态行为信号与演讲表现之间的联系，并为自动反馈工具提供基准测试。", "conclusion": "SOPHIAS填补了教育领域关于学生口语表达能力评估的多模态数据集空白，有望推动相关技术和理论的发展。"}}
{"id": "2601.07573", "pdf": "https://arxiv.org/pdf/2601.07573", "abs": "https://arxiv.org/abs/2601.07573", "authors": ["Joshua Gans"], "title": "A Model of Artificial Jagged Intelligence", "categories": ["econ.TH", "cs.AI"], "comment": "58 Pages", "summary": "Generative AI systems often display highly uneven performance across tasks that appear ``nearby'': they can be excellent on one prompt and confidently wrong on another with only small changes in wording or context. We call this phenomenon Artificial Jagged Intelligence (AJI). This paper develops a tractable economic model of AJI that treats adoption as an information problem: users care about \\emph{local} reliability, but typically observe only coarse, global quality signals. In a baseline one-dimensional landscape, truth is a rough Brownian process, and the model ``knows'' scattered points drawn from a Poisson process. The model interpolates optimally, and the local error is measured by posterior variance. We derive an adoption threshold for a blind user, show that experienced errors are amplified by the inspection paradox, and interpret scaling laws as denser coverage that improves average quality without eliminating jaggedness. We then study mastery and calibration: a calibrated user who can condition on local uncertainty enjoys positive expected value even in domains that fail the blind adoption test. Modelling mastery as learning a reliability map via Gaussian process regression yields a learning-rate bound driven by information gain, clarifying when discovering ``where the model works'' is slow. Finally, we study how scaling interacts with discoverability: when calibrated signals and user mastery accelerate the harvesting of scale improvements, and when opacity can make gains from scaling effectively invisible.", "AI": {"tldr": "开发了一个可计算的经济模型来描述人工智能系统的性能跳跃性问题，即人工锯齿智能（AJI）。", "motivation": "解释了为什么一些生成式AI系统在类似任务上的表现差异巨大，并将这种现象归结为用户获取局部可靠性信息的问题。", "method": "通过建立一个基于布朗运动和泊松分布的信息模型来量化用户的盲从门槛，以及经验误差的放大效应。探讨了掌握可靠性的学习过程和规模化对发现这些优势的影响。", "result": "提出了评估AI系统性能跳跃性问题的新方法，并展示了用户在面对不透明信息时如何利用局部不确定性进行有效决策。", "conclusion": "通过引入可靠的信号和提升用户的掌握能力，可以加速规模化的收益，但当系统的复杂度增加时，这些改善可能变得难以察觉。"}}
{"id": "2601.07571", "pdf": "https://arxiv.org/pdf/2601.07571", "abs": "https://arxiv.org/abs/2601.07571", "authors": ["Charles Javerliat", "Guillaume Lavoué"], "title": "GPU accelerated surface-based gaze mapping for XR experiences", "categories": ["cs.HC"], "comment": null, "summary": "Extended reality is a fast-growing domain for which there is an increasing need to analyze and understand user behavior. In particular, understanding human visual attention during immersive experiences is crucial for many applications. The visualization and analysis of visual attention are commonly done by building fixation density maps from eye-tracking data. Such visual attention mapping is well mastered for 3 degrees of freedom (3DoF) experiences (\\textit{i.e.}, involving 360 images or videos) but much less so for 6DoFs data, when the user can move freely in the 3D space. In that case, the visual attention information has to be mapped onto the 3D objects themselves. Some solutions exist for constructing such surface-based 6DoFs attention maps, however, they own several drawbacks: processing time, strong dependence on mesh resolution and/or texture mapping, and/or unpractical data representation for further processing. In this context, we propose a novel GPU-based algorithm that resolves the issues above while being generated in interactive time and rendered in real-time. Experiment on a challenging scene demonstrates the accuracy and robustness of our approach. To stimulate research in this area, the source code is publicly released and integrated into PLUME for ease of use in XR experiments.", "AI": {"tldr": "提出了一种基于GPU的算法，用于生成交互时间和实时渲染的6DoF注视映射。", "motivation": "解决现有6DoFs注视映射方法中存在的问题，如处理时间长、对网格分辨率和纹理映射依赖强以及不实用的数据表示。", "method": "提出了一种新的基于GPU的方法来生成表面基础的6DoFs注意力图，并实现了交互时间和实时渲染。", "result": "实验表明该方法准确且鲁棒。源代码已公开发布并集成到PLUME中，以促进XR实验中的使用。", "conclusion": "提出的算法解决了现有的注视映射问题，并且能够提供交互时间的生成和实时渲染的支持。"}}
{"id": "2601.07568", "pdf": "https://arxiv.org/pdf/2601.07568", "abs": "https://arxiv.org/abs/2601.07568", "authors": ["Yu-Yang Qian", "Junda Su", "Lanxiang Hu", "Peiyuan Zhang", "Zhijie Deng", "Peng Zhao", "Hao Zhang"], "title": "d3LLM: Ultra-Fast Diffusion LLM using Pseudo-Trajectory Distillation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion large language models (dLLMs) offer capabilities beyond those of autoregressive (AR) LLMs, such as parallel decoding and random-order generation. However, realizing these benefits in practice is non-trivial, as dLLMs inherently face an accuracy-parallelism trade-off. Despite increasing interest, existing methods typically focus on only one-side of the coin, targeting either efficiency or performance. To address this limitation, we propose d3LLM (Pseudo-Distilled Diffusion Large Language Model), striking a balance between accuracy and parallelism: (i) during training, we introduce pseudo-trajectory distillation to teach the model which tokens can be decoded confidently at early steps, thereby improving parallelism; (ii) during inference, we employ entropy-based multi-block decoding with a KV-cache refresh mechanism to achieve high parallelism while maintaining accuracy. To better evaluate dLLMs, we also introduce AUP (Accuracy Under Parallelism), a new metric that jointly measures accuracy and parallelism. Experiments demonstrate that our d3LLM achieves up to 10$\\times$ speedup over vanilla LLaDA/Dream and 5$\\times$ speedup over AR models without much accuracy drop. Our code is available at https://github.com/hao-ai-lab/d3LLM.", "AI": {"tldr": "提出了d3LLM模型，通过伪轨迹蒸馏和熵基于的多块解码技术，在训练和推理过程中平衡精度和平行性。", "motivation": "现有扩散大型语言模型存在准确性与并行性的权衡问题，无法同时实现高效性和高性能。", "method": "在训练阶段引入了伪轨迹蒸馏以增强早期步骤中可自信解码的令牌；在推断阶段采用了基于熵的多块解码和KV缓存刷新机制。", "result": "实验显示d3LLM模型相较于基础LLaDA/Dream模型速度提高了10倍，比自回归模型快5倍，并且没有明显的精度下降。", "conclusion": "通过创新方法平衡了扩散大型语言模型的精度与并行性问题，证明了d3LLM在效率和性能上的优越性。"}}
{"id": "2601.07566", "pdf": "https://arxiv.org/pdf/2601.07566", "abs": "https://arxiv.org/abs/2601.07566", "authors": ["Noam Benson-Tilsen"], "title": "Dynamic $(Δ+ 1)$ Vertex Coloring", "categories": ["cs.DS"], "comment": "16 pages, 5 figures", "summary": "Several recent results from dynamic and sublinear graph coloring are surveyed. This problem is widely studied and has motivating applications like network topology control, constraint satisfaction, and real-time resource scheduling. Graph coloring algorithms are called colorers. In §1 are defined graph coloring, the dynamic model, and the notion of performance of graph algorithms in the dynamic model. In particular $(Δ+ 1)$-coloring, sublinear performance, and oblivious and adaptive adversaries are noted and motivated. In §2 the pair of approximately optimal dynamic vertex colorers given in arXiv:1708.09080 are summarized as a warmup for the $(Δ+ 1)$-colorers. In §3 the state of the art in dynamic $(Δ+ 1)$-coloring is presented. This section comprises a pair of papers (arXiv:1711.04355 and arXiv:1910.02063) that improve dynamic $(Δ+ 1)$-coloring from the naive algorithm with $O(Δ)$ expected amortized update time to $O(\\log Δ)$, then to $O(1)$ with high probability. In §4 the results in arXiv:2411.04418, which gives a sublinear algorithm for $(Δ+ 1)$-coloring that generalizes oblivious adversaries to adaptive adversaries, are presented.", "AI": {"tldr": "本文综述了动态和亚线性图着色的若干近期成果，并介绍了改进动态(Δ+1)顶点着色算法的方法和结果。", "motivation": "网络拓扑控制、约束满足以及实时资源调度等实际问题推动了对动态图着色的研究，特别是(Δ+1)-顶点着色在这些应用中具有重要价值。", "method": "论文总结并改进了几种高效的(Δ+1)顶点着色算法。通过引入更强大的对手模型和优化更新时间来提高算法性能。", "result": "该研究从最初的O(Δ)预期平均更新时间，逐渐优化到O(log Δ)，最终达到了高概率的O(1)更新时间。", "conclusion": "新的(Δ+1)顶点着色算法不仅适用于盲视对手模型，而且在对抗性更强的自适应对手模型下也表现出优越性能。"}}
{"id": "2601.07565", "pdf": "https://arxiv.org/pdf/2601.07565", "abs": "https://arxiv.org/abs/2601.07565", "authors": ["Jiaqi Qiao", "Xiujuan Xu", "Xinran Li", "Yu Liu"], "title": "A Unified Framework for Emotion Recognition and Sentiment Analysis via Expert-Guided Multimodal Fusion with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multimodal emotion understanding requires effective integration of text, audio, and visual modalities for both discrete emotion recognition and continuous sentiment analysis. We present EGMF, a unified framework combining expert-guided multimodal fusion with large language models. Our approach features three specialized expert networks--a fine-grained local expert for subtle emotional nuances, a semantic correlation expert for cross-modal relationships, and a global context expert for long-range dependencies--adaptively integrated through hierarchical dynamic gating for context-aware feature selection. Enhanced multimodal representations are integrated with LLMs via pseudo token injection and prompt-based conditioning, enabling a single generative framework to handle both classification and regression through natural language generation. We employ LoRA fine-tuning for computational efficiency. Experiments on bilingual benchmarks (MELD, CHERMA, MOSEI, SIMS-V2) demonstrate consistent improvements over state-of-the-art methods, with superior cross-lingual robustness revealing universal patterns in multimodal emotional expressions across English and Chinese. We will release the source code publicly.", "AI": {"tldr": "提出了一种通过专家引导的多模态融合与大语言模型结合的情感理解和情绪分析框架。", "motivation": "为了有效整合文本、音频和视觉模式以实现情感识别和情绪分析，需要一种能适应多种数据类型并具备跨语境关联处理能力的方法。", "method": "采用三个专家网络：细粒度本地专家捕捉微妙情感细节；语义相关性专家发现跨模态关系；全局上下文专家管理长依赖。通过分层动态门控机制，这些专家被自适应地集成进来，并与大语言模型结合进行伪标记注入和基于提示的条件设置。", "result": "在多项双语基准测试中表现出色，超过现有最佳方法，在英汉情感表达上展现出更强的跨语言鲁棒性。", "conclusion": "EGMF框架提供了一种创新的方式，通过专家引导的多模态融合与大语言模型相结合，实现了高效的情感理解和情绪分析，并具有广泛的应用前景。"}}
{"id": "2601.07559", "pdf": "https://arxiv.org/pdf/2601.07559", "abs": "https://arxiv.org/abs/2601.07559", "authors": ["Yuki Kuroda", "Tomoya Takahashi", "Cristian C. Beltran-Hernandez", "Kazutoshi Tanaka", "Masashi Hamaya"], "title": "Stable In-hand Manipulation for a Lightweight Four-motor Prosthetic Hand", "categories": ["cs.RO"], "comment": null, "summary": "Electric prosthetic hands should be lightweight to decrease the burden on the user, shaped like human hands for cosmetic purposes, and designed with motors enclosed inside to protect them from damage and dirt. Additionally, in-hand manipulation is necessary to perform daily activities such as transitioning between different postures, particularly through rotational movements, such as reorienting a pen into a writing posture after picking it up from a desk. We previously developed PLEXUS hand (Precision-Lateral dEXteroUS manipulation hand), a lightweight (311 g) prosthetic hand driven by four motors. This prosthetic performed reorientation between precision and lateral grasps with various objects. However, its controller required predefined object widths and was limited to handling lightweight objects (of weight up to 34 g). This study addresses these limitations by employing motor current feedback. Combined with the hand's previously optimized single-axis thumb, this approach achieves more stable manipulation by estimating the object's width and adjusting the index finger position to maintain stable object holding during the reorientation. Experimental validation using primitive objects of various widths (5-30 mm) and shapes (cylinders and prisms) resulted in a 100% success rate with lightweight objects and maintained a high success rate (>=80) even with heavy aluminum prisms (of weight up to 289 g). By contrast, the performance without index finger coordination dropped to just 40% on the heaviest 289 g prism. The hand also successfully executed several daily tasks, including closing bottle caps and orienting a pen for writing.", "AI": {"tldr": "本文提出了一种改进的轻量级四电机假手，通过使用电动机电流反馈来实现更稳定的物体旋转和握持。", "motivation": "当前的假手控制器依赖于预定义的对象宽度，并且只能处理轻质对象。为了提高性能并扩大应用范围，研究团队提出了新的方法。", "method": "通过将电机电流反馈与单轴拇指相结合，可以估计出物体宽度并调整食指位置以保持稳定握持。这种方法在实验中得到了验证。", "result": "新方法成功地提高了对不同形状和重量的对象的处理能力，尤其对于重达289克的铝制棱柱也能达到较高的成功率（≥80%）。同时，假手能够执行日常任务如拧紧瓶盖或调整笔为书写姿势。", "conclusion": "通过采用电机电流反馈技术，研究团队成功开发出一种能更稳定地进行物体旋转和握持的轻量级四电机假手。"}}
{"id": "2601.07558", "pdf": "https://arxiv.org/pdf/2601.07558", "abs": "https://arxiv.org/abs/2601.07558", "authors": ["Chen Feng", "Guiyong Zheng", "Tengkai Zhuang", "Yongqian Wu", "Fangzhan He", "Haojia Li", "Juepeng Zheng", "Shaojie Shen", "Boyu Zhou"], "title": "FlyCo: Foundation Model-Empowered Drones for Autonomous 3D Structure Scanning in Open-World Environments", "categories": ["cs.RO"], "comment": "34 pages, 24 figures, 9 tables. Video: https://www.youtube.com/playlist?list=PLqjZjnqsCyl40rw3y15Yzc7Mdo-z1y2j8", "summary": "Autonomous 3D scanning of open-world target structures via drones remains challenging despite broad applications. Existing paradigms rely on restrictive assumptions or effortful human priors, limiting practicality, efficiency, and adaptability. Recent foundation models (FMs) offer great potential to bridge this gap. This paper investigates a critical research problem: What system architecture can effectively integrate FM knowledge for this task? We answer it with FlyCo, a principled FM-empowered perception-prediction-planning loop enabling fully autonomous, prompt-driven 3D target scanning in diverse unknown open-world environments. FlyCo directly translates low-effort human prompts (text, visual annotations) into precise adaptive scanning flights via three coordinated stages: (1) perception fuses streaming sensor data with vision-language FMs for robust target grounding and tracking; (2) prediction distills FM knowledge and combines multi-modal cues to infer the partially observed target's complete geometry; (3) planning leverages predictive foresight to generate efficient and safe paths with comprehensive target coverage. Building on this, we further design key components to boost open-world target grounding efficiency and robustness, enhance prediction quality in terms of shape accuracy, zero-shot generalization, and temporal stability, and balance long-horizon flight efficiency with real-time computability and online collision avoidance. Extensive challenging real-world and simulation experiments show FlyCo delivers precise scene understanding, high efficiency, and real-time safety, outperforming existing paradigms with lower human effort and verifying the proposed architecture's practicality. Comprehensive ablations validate each component's contribution. FlyCo also serves as a flexible, extensible blueprint, readily leveraging future FM and robotics advances. Code will be released.", "AI": {"tldr": "本文提出了FlyCo系统，利用基础模型赋能无人机在开放环境中进行自主的三维结构扫描。", "motivation": "现有的三维扫描方法依赖于严格的假设或耗时的人工先验知识，限制了实用性、效率和适应性。通过集成基础模型的知识，可以克服这些挑战并提高无人机自主3D扫描的能力。", "method": "FlyCo系统包含三个阶段：感知融合实时传感器数据与视觉语言基础模型以进行目标定位和追踪；预测利用基础模型的知识结合多模态线索来推断部分观察到的目标的完整几何形状；规划基于预测性前景生成高效安全路径，同时保证全面覆盖。", "result": "实验结果显示FlyCo系统在精准场景理解、高效率及实时安全性方面优于现有方法，并且减少了人为努力。详细的消融研究表明每个组件对性能的重要贡献。", "conclusion": "FlyCo提出了一种灵活可扩展的框架，能够充分利用未来基础模型和机器人技术的进步来实现无人机自主3D扫描任务。"}}
{"id": "2601.07556", "pdf": "https://arxiv.org/pdf/2601.07556", "abs": "https://arxiv.org/abs/2601.07556", "authors": ["Siyang Li", "Jiayi Ouyang", "Zhenyao Cui", "Ziwei Wang", "Tianwang Jia", "Feng Wan", "Dongrui Wu"], "title": "Backpropagation-Free Test-Time Adaptation for Lightweight EEG-Based Brain-Computer Interfaces", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Electroencephalogram (EEG)-based brain-computer interfaces (BCIs) face significant deployment challenges due to inter-subject variability, signal non-stationarity, and computational constraints. While test-time adaptation (TTA) mitigates distribution shifts under online data streams without per-use calibration sessions, existing TTA approaches heavily rely on explicitly defined loss objectives that require backpropagation for updating model parameters, which incurs computational overhead, privacy risks, and sensitivity to noisy data streams. This paper proposes Backpropagation-Free Transformations (BFT), a TTA approach for EEG decoding that eliminates such issues. BFT applies multiple sample-wise transformations of knowledge-guided augmentations or approximate Bayesian inference to each test trial, generating multiple prediction scores for a single test sample. A learning-to-rank module enhances the weighting of these predictions, enabling robust aggregation for uncertainty suppression during inference under theoretical justifications. Extensive experiments on five EEG datasets of motor imagery classification and driver drowsiness regression tasks demonstrate the effectiveness, versatility, robustness, and efficiency of BFT. This research enables lightweight plug-and-play BCIs on resource-constrained devices, broadening the real-world deployment of decoding algorithms for EEG-based BCI.", "AI": {"tldr": "提出了一种不依赖于反向传播的测试时间适应方法，用于轻量级EEG脑机接口。", "motivation": "解决EEG脑机接口部署中的分布偏移问题，减少计算开销和隐私风险。", "method": "通过知识引导的样本变换或近似贝叶斯推理生成多个预测分数，并使用学习排序模块加权这些预测。", "result": "在五个EEG数据集上的实验表明该方法有效、灵活、鲁棒且高效。", "conclusion": "这项研究使轻量级即插即用BCI成为可能，促进了EEG脑机接口的广泛应用。"}}
{"id": "2601.07553", "pdf": "https://arxiv.org/pdf/2601.07553", "abs": "https://arxiv.org/abs/2601.07553", "authors": ["Kabir Swain", "Sijie Han", "Ayush Raina", "Jin Zhang", "Shuang Li", "Michael Stopa", "Antonio Torralba"], "title": "VirtualEnv: A Platform for Embodied AI Research", "categories": ["cs.AI"], "comment": null, "summary": "As large language models (LLMs) continue to improve in reasoning and decision-making, there is a growing need for realistic and interactive environments where their abilities can be rigorously evaluated. We present VirtualEnv, a next-generation simulation platform built on Unreal Engine 5 that enables fine-grained benchmarking of LLMs in embodied and interactive scenarios. VirtualEnv supports rich agent-environment interactions, including object manipulation, navigation, and adaptive multi-agent collaboration, as well as game-inspired mechanics like escape rooms and procedurally generated environments. We provide a user-friendly API built on top of Unreal Engine, allowing researchers to deploy and control LLM-driven agents using natural language instructions. We integrate large-scale LLMs and vision-language models (VLMs), such as GPT-based models, to generate novel environments and structured tasks from multimodal inputs. Our experiments benchmark the performance of several popular LLMs across tasks of increasing complexity, analyzing differences in adaptability, planning, and multi-agent coordination. We also describe our methodology for procedural task generation, task validation, and real-time environment control. VirtualEnv is released as an open-source platform, we aim to advance research at the intersection of AI and gaming, enable standardized evaluation of LLMs in embodied AI settings, and pave the way for future developments in immersive simulations and interactive entertainment.", "AI": {"tldr": "VirtualEnv是一个基于Unreal Engine 5构建的下一代模拟平台，用于评估大型语言模型在具身和互动场景中的表现。", "motivation": "随着大型语言模型的推理能力和决策能力不断增强，需要一个能够进行严格评价的真实且交互式的环境。该论文旨在提供这样一个平台来支持相关研究。", "method": "VirtualEnv采用了Unreal Engine 5构建了一个模拟环境，并提供了用户友好的API以实现对LLM驱动代理的部署和控制。实验中通过生成多任务来评估不同语言模型的表现，包括单一任务、导航、物体操作以及多人协作等。", "result": "该平台支持多种任务类型的基准测试，并且能够分析大型语言模型在适应性、规划能力和多智能体协调等方面的差异。", "conclusion": "VirtualEnv作为一个开源平台发布，旨在促进AI与游戏领域的研究发展，提供对大型语言模型在具身场景中的标准化评估方法。"}}
{"id": "2601.07540", "pdf": "https://arxiv.org/pdf/2601.07540", "abs": "https://arxiv.org/abs/2601.07540", "authors": ["Farhad G. Zanjani", "Hong Cai", "Amirhossein Habibian"], "title": "ViewMorpher3D: A 3D-aware Diffusion Framework for Multi-Camera Novel View Synthesis in Autonomous Driving", "categories": ["cs.CV"], "comment": "Paper and supplementary materials", "summary": "Autonomous driving systems rely heavily on multi-view images to ensure accurate perception and robust decision-making. To effectively develop and evaluate perception stacks and planning algorithms, realistic closed-loop simulators are indispensable. While 3D reconstruction techniques such as Gaussian Splatting offer promising avenues for simulator construction, the rendered novel views often exhibit artifacts, particularly in extrapolated perspectives or when available observations are sparse. We introduce ViewMorpher3D, a multi-view image enhancement framework based on image diffusion models, designed to elevate photorealism and multi-view coherence in driving scenes. Unlike single-view approaches, ViewMorpher3D jointly processes a set of rendered views conditioned on camera poses, 3D geometric priors, and temporally adjacent or spatially overlapping reference views. This enables the model to infer missing details, suppress rendering artifacts, and enforce cross-view consistency. Our framework accommodates variable numbers of cameras and flexible reference/target view configurations, making it adaptable to diverse sensor setups. Experiments on real-world driving datasets demonstrate substantial improvements in image quality metrics, effectively reducing artifacts while preserving geometric fidelity.", "AI": {"tldr": "ViewMorpher3D是一种基于图像扩散模型的多视图图像增强框架，用于提高驾驶场景中新型视角合成的真实感和多视图一致性。", "motivation": "为了提升自动驾驶系统中的感知堆栈和规划算法，在真实闭环模拟器构建时需要解决渲染出的新视角中存在的伪影问题。为此引入了ViewMorpher3D以改善图像质量和几何保真度。", "method": "通过联合处理一组渲染视图，利用相机姿态、三维几何先验以及相邻或重叠参考视图为条件输入来减少伪影并保持跨视角一致性。", "result": "在实际驾驶数据集上的实验表明该框架显著提升了图像质量指标，减少了伪影同时保留了几何保真度。", "conclusion": "ViewMorpher3D提出了一种有效的多相机新型视图合成方法，增强了自动驾驶系统中感知和规划算法的开发与评估。"}}
{"id": "2601.07528", "pdf": "https://arxiv.org/pdf/2601.07528", "abs": "https://arxiv.org/abs/2601.07528", "authors": ["Gagan Bhatia", "Hamdy Mubarak", "Mustafa Jarrar", "George Mikros", "Fadi Zaraket", "Mahmoud Alhirthani", "Mutaz Al-Khatib", "Logan Cochrane", "Kareem Darwish", "Rashid Yahiaoui", "Firoj Alam"], "title": "From RAG to Agentic RAG for Faithful Islamic Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "LLMs are increasingly used for Islamic question answering, where ungrounded responses may carry serious religious consequences. Yet standard MCQ/MRC-style evaluations do not capture key real-world failure modes, notably free-form hallucinations and whether models appropriately abstain when evidence is lacking. To shed a light on this aspect we introduce ISLAMICFAITHQA, a 3,810-item bilingual (Arabic/English) generative benchmark with atomic single-gold answers, which enables direct measurement of hallucination and abstention. We additionally developed an end-to-end grounded Islamic modelling suite consisting of (i) 25K Arabic text-grounded SFT reasoning pairs, (ii) 5K bilingual preference samples for reward-guided alignment, and (iii) a verse-level Qur'an retrieval corpus of $\\sim$6k atomic verses (ayat). Building on these resources, we develop an agentic Quran-grounding framework (agentic RAG) that uses structured tool calls for iterative evidence seeking and answer revision. Experiments across Arabic-centric and multilingual LLMs show that retrieval improves correctness and that agentic RAG yields the largest gains beyond standard RAG, achieving state-of-the-art performance and stronger Arabic-English robustness even with a small model (i.e., Qwen3 4B). We will make the experimental resources and datasets publicly available for the community.", "AI": {"tldr": "本文提出了一种基于《古兰经》的代理增强检索和生成框架（agentic RAG），以提高伊斯兰教问答系统的准确性与可靠性。", "motivation": "为了减少大型语言模型在处理伊斯兰教相关问题时产生不准确或虚构回答的风险，本文旨在开发一种更精确、可靠的问答系统。", "method": "作者构建了一个包含3810个条目的双语基准测试集ISLAMICFAITHQA，并设计了一套基于《古兰经》的模型训练资源。他们还提出了一种代理增强检索和生成框架，该框架通过结构化工具调用来进行迭代证据搜索与答案修订。", "result": "实验表明，在阿拉伯语中心模型和多语言LLMs中，检索可以提高正确性，而agentic RAG相比标准RAG可以获得更大的改进，即使在较小的Qwen3 4B模型上也能实现最先进的性能。", "conclusion": "本文的工作不仅提升了伊斯兰教问答系统的准确性与可靠性，还为社区提供了实验资源和数据集。"}}
{"id": "2601.07525", "pdf": "https://arxiv.org/pdf/2601.07525", "abs": "https://arxiv.org/abs/2601.07525", "authors": ["Ngoc Trinh Hung Nguyen", "Alonso Silva", "Laith Zumot", "Liubov Tupikina", "Armen Aghasaryan", "Mehwish Alam"], "title": "Thinking Before Constraining: A Unified Decoding Framework for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Natural generation allows Language Models (LMs) to produce free-form responses with rich reasoning, but the lack of guaranteed structure makes outputs difficult to parse or verify. Structured generation, or constrained decoding, addresses this drawback by producing content in standardized formats such as JSON, ensuring consistency and guaranteed-parsable outputs, but it can inadvertently restrict the model's reasoning capabilities. In this work, we propose a simple approach that combines the advantages of both natural and structured generation. By allowing LLMs to reason freely until specific trigger tokens are generated, and then switching to structured generation, our method preserves the expressive power of natural language reasoning while ensuring the reliability of structured outputs. We further evaluate our approach on several datasets, covering both classification and reasoning tasks, to demonstrate its effectiveness, achieving a substantial gain of up to 27% in accuracy compared to natural generation, while requiring only a small overhead of 10-20 extra tokens.", "AI": {"tldr": "提出了一种结合自然生成和结构化生成优势的统一解码框架，以提高大型语言模型输出的一致性和可解析性。", "motivation": "现有自然生成缺乏保证结构，使输出难以解析或验证；而结构化生成限制了模型推理能力。为解决这些问题，论文旨在结合两者的优势。", "method": "允许LLM自由推理直到特定触发令牌产生后切换到结构化生成，以保持自然语言推理的表达力同时确保结构化输出的可靠性。", "result": "在多个数据集上评估该方法，涵盖分类和推理任务，相比纯自然生成，在准确率上有高达27%的提升，仅增加10-20个额外令牌。", "conclusion": "提出的方法可以有效平衡自然语言表达力与结构化输出的一致性及可解析性。"}}
{"id": "2601.07519", "pdf": "https://arxiv.org/pdf/2601.07519", "abs": "https://arxiv.org/abs/2601.07519", "authors": ["Margherita Firenze", "Sean I. Young", "Clinton J. Wang", "Hyuk Jin Yun", "Elfar Adalsteinsson", "Kiho Im", "P. Ellen Grant", "Polina Golland"], "title": "Fast Multi-Stack Slice-to-Volume Reconstruction via Multi-Scale Unrolled Optimization", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Fully convolutional networks have become the backbone of modern medical imaging due to their ability to learn multi-scale representations and perform end-to-end inference. Yet their potential for slice-to-volume reconstruction (SVR), the task of jointly estimating 3D anatomy and slice poses from misaligned 2D acquisitions, remains underexplored. We introduce a fast convolutional framework that fuses multiple orthogonal 2D slice stacks to recover coherent 3D structure and refines slice alignment through lightweight model-based optimization. Applied to fetal brain MRI, our approach reconstructs high-quality 3D volumes in under 10s, with 1s slice registration and accuracy on par with state-of-the-art iterative SVR pipelines, offering more than speedup. The framework uses non-rigid displacement fields to represent transformations, generalizing to other SVR problems like fetal body and placental MRI. Additionally, the fast inference time paves the way for real-time, scanner-side volumetric feedback during MRI acquisition.", "AI": {"tldr": "本文提出了一种快速卷积框架，用于融合多组二维切片堆栈以恢复三维结构，并通过轻量级模型优化来精确定位切片。", "motivation": "现代医学成像中全卷积网络因能学习多层次表示和端到端推理而被广泛应用。但是其在切片到体积重建任务中的潜力尚待开发，本文旨在探索这一应用并实现快速准确的三维重构。", "method": "引入了一种基于轻量级模型优化的快速卷积框架，该方法融合多组二维切片堆栈以恢复一致的三维结构，并通过非刚性位移场表示变换来精确定位和调整切片位置。", "result": "应用于胎儿大脑MRI时，该方法可以在不到10秒的时间内重建高质量的3D体积，且在1秒内完成切片定位并达到与现有迭代SVR管线相当的精度。", "conclusion": "本文所提出的方法不仅实现了高效的三维重构和快速准确的切片定位，而且还展示了应用于其他类似问题如胎儿身体和胎盘MRI的潜力。此外，该方法的快速推理时间也为实时体积反馈铺平了道路。"}}
{"id": "2601.07518", "pdf": "https://arxiv.org/pdf/2601.07518", "abs": "https://arxiv.org/abs/2601.07518", "authors": ["Fangyu Lin", "Yingdong Hu", "Zhening Liu", "Yufan Zhuang", "Zehong Lin", "Jun Zhang"], "title": "Mon3tr: Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Immersive telepresence aims to transform human interaction in AR/VR applications by enabling lifelike full-body holographic representations for enhanced remote collaboration. However, existing systems rely on hardware-intensive multi-camera setups and demand high bandwidth for volumetric streaming, limiting their real-time performance on mobile devices. To overcome these challenges, we propose Mon3tr, a novel Monocular 3D telepresence framework that integrates 3D Gaussian splatting (3DGS) based parametric human modeling into telepresence for the first time. Mon3tr adopts an amortized computation strategy, dividing the process into a one-time offline multi-view reconstruction phase to build a user-specific avatar and a monocular online inference phase during live telepresence sessions. A single monocular RGB camera is used to capture body motions and facial expressions in real time to drive the 3DGS-based parametric human model, significantly reducing system complexity and cost. The extracted motion and appearance features are transmitted at < 0.2 Mbps over WebRTC's data channel, allowing robust adaptation to network fluctuations. On the receiver side, e.g., Meta Quest 3, we develop a lightweight 3DGS attribute deformation network to dynamically generate corrective 3DGS attribute adjustments on the pre-built avatar, synthesizing photorealistic motion and appearance at ~ 60 FPS. Extensive experiments demonstrate the state-of-the-art performance of our method, achieving a PSNR of > 28 dB for novel poses, an end-to-end latency of ~ 80 ms, and > 1000x bandwidth reduction compared to point-cloud streaming, while supporting real-time operation from monocular inputs across diverse scenarios. Our demos can be found at https://mon3tr3d.github.io.", "AI": {"tldr": "本文提出了一种新的单目3D远程呈现框架Mon3tr，通过结合3D高斯点拟合的参数化人体建模，实现了低成本、低带宽的实时全身体验。", "motivation": "当前的沉浸式远程呈现系统依赖多摄像头设置和大量网络带宽，难以实现实时操作。本文旨在降低硬件成本和带宽需求，提高移动设备上的实时性能。", "method": "Mon3tr框架包括离线重建阶段生成用户特定的模型和在线推理阶段驱动参数化人体模型。通过单目RGB相机捕获动作和表情，并传输特征以实现实时渲染。", "result": "实验表明，该方法在新型姿态下的PSNR超过28dB，端到端延迟为约80ms，带宽消耗仅为点云流式的千分之一，支持各种场景下的实时操作。", "conclusion": "Mon3tr框架成功实现了低成本、低带宽的单目3D远程呈现体验，在保持高图像质量和实时性能的同时显著降低了系统复杂性和成本。"}}
{"id": "2601.07516", "pdf": "https://arxiv.org/pdf/2601.07516", "abs": "https://arxiv.org/abs/2601.07516", "authors": ["Yongqi Li", "Hao Lang", "Tieyun Qian", "Yongbin Li"], "title": "Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Vision-language models are increasingly employed as multimodal conversational agents (MCAs) for diverse conversational tasks. Recently, reinforcement learning (RL) has been widely explored for adapting MCAs to various human-AI interaction scenarios. Despite showing great enhancement in generalization performance, fine-tuning MCAs via RL still faces challenges in handling the extremely large text token space. To address this, we learn a compact latent action space for RL fine-tuning instead. Specifically, we adopt the learning from observation mechanism to construct the codebook for the latent action space, where future observations are leveraged to estimate current latent actions that could further be used to reconstruct future observations. However, the scarcity of paired image-text data hinders learning a codebook with sufficient coverage. Thus, we leverage both paired image-text data and text-only data to construct the latent action space, using a cross-modal projector for transforming text embeddings into image-text embeddings. We initialize the cross-modal projector on paired image-text data, and further train it on massive text-only data with a novel cycle consistency loss to enhance its robustness. We show that our latent action based method outperforms competitive baselines on two conversation tasks across various RL algorithms.", "AI": {"tldr": "本文提出了一种基于紧凑的潜在动作空间的方法，以解决多模态对话代理（MCAs）通过强化学习（RL）微调过程中遇到的大规模文本标记空间问题。", "motivation": "尽管强化学习在适应多模态对话代理于各种人机交互场景方面展示了强大的泛化性能，但面对巨大的文本标记空间时仍面临挑战。因此，本文旨在通过构建一个紧凑的潜在动作空间来解决这一问题，并提出了一种结合图文配对和纯文本数据的方法以提高代码书的覆盖率。", "method": "作者采用观察学习机制来构建潜在的动作空间代码本；使用图文嵌入转换器将文字嵌入转化为图文嵌入。此转换器首先在图文配对的数据上初始化，然后通过新的循环一致性损失函数在大量纯文本数据上进行训练以增强其鲁棒性。", "result": "实验结果表明，基于潜在动作的方法优于其他基准方法，在两种对话任务中使用各种强化学习算法均表现出优越的性能。", "conclusion": "研究显示，利用紧凑的潜在动作空间和结合图文配对与纯文本数据可以有效提升多模态对话代理通过强化学习微调的效果。"}}
{"id": "2601.07514", "pdf": "https://arxiv.org/pdf/2601.07514", "abs": "https://arxiv.org/abs/2601.07514", "authors": ["Matteo Garbelli"], "title": "Data-Driven Stochastic VRP: Integration of Forecast Duration into Optimization for Utility Workforce Management", "categories": ["math.OC", "cs.AI"], "comment": null, "summary": "This paper investigates the integration of machine learning forecasts of intervention durations into a stochastic variant of the Capacitated Vehicle Routing Problem with Time Windows (CVRPTW). In particular, we exploit tree-based gradient boosting (XGBoost) trained on eight years of gas meter maintenance data to produce point predictions and uncertainty estimates, which then drive a multi-objective evolutionary optimization routine. The methodology addresses uncertainty through sub-Gaussian concentration bounds for route-level risk buffers and explicitly accounts for competing operational KPIs through a multi-objective formulation. Empirical analysis of prediction residuals validates the sub-Gaussian assumption underlying the risk model. From an empirical point of view, our results report improvements around 20-25\\% in operator utilization and completion rates compared with plans computed using default durations. The integration of uncertainty quantification and risk-aware optimization provides a practical framework for handling stochastic service durations in real-world routing applications.", "AI": {"tldr": "本文研究了将机器学习预测的干预持续时间集成到具有时间窗口的容量车辆路线问题(CVRPTW)的随机变体中的方法。", "motivation": "该论文旨在通过引入基于过去八年气体计量维护数据训练的XGBoost模型生成的时间预测和不确定性估计，来改进公用事业工作管理中操作人员的效率和完成率。", "method": "利用梯度提升树(XGBoost)对历史数据进行训练以获得时间预测及不确定性评估，并将这些预测用于多目标进化优化。该方法通过次高斯集中界限为路线级别风险缓冲提供支持，同时通过多目标形式化处理操作关键绩效指标之间的竞争。", "result": "实证分析表明，在使用默认持续时间的情况下，采用此方法可提高20-25%的操作人员利用率和完成率。", "conclusion": "结合不确定性的量化与风险意识优化提供了一个在现实世界的路线应用中处理随机服务持续时间的实际框架。"}}
{"id": "2601.07512", "pdf": "https://arxiv.org/pdf/2601.07512", "abs": "https://arxiv.org/abs/2601.07512", "authors": ["Jingwen Fu", "Ming Xiao", "Mikael Skoglund", "Dong In Kim"], "title": "Land-then-transport: A Flow Matching-Based Generative Decoder for Wireless Image Transmission", "categories": ["cs.LG", "eess.IV"], "comment": null, "summary": "Due to strict rate and reliability demands, wireless image transmission remains difficult for both classical layered designs and joint source-channel coding (JSCC), especially under low latency. Diffusion-based generative decoders can deliver strong perceptual quality by leveraging learned image priors, but iterative stochastic denoising leads to high decoding delay. To enable low-latency decoding, we propose a flow-matching (FM) generative decoder under a new land-then-transport (LTT) paradigm that tightly integrates the physical wireless channel into a continuous-time probability flow. For AWGN channels, we build a Gaussian smoothing path whose noise schedule indexes effective noise levels, and derive a closed-form teacher velocity field along this path. A neural-network student vector field is trained by conditional flow matching, yielding a deterministic, channel-aware ODE decoder with complexity linear in the number of ODE steps. At inference, it only needs an estimate of the effective noise variance to set the ODE starting time. We further show that Rayleigh fading and MIMO channels can be mapped, via linear MMSE equalization and singular-value-domain processing, to AWGN-equivalent channels with calibrated starting times. Therefore, the same probability path and trained velocity field can be reused for Rayleigh and MIMO without retraining. Experiments on MNIST, Fashion-MNIST, and DIV2K over AWGN, Rayleigh, and MIMO demonstrate consistent gains over JPEG2000+LDPC, DeepJSCC, and diffusion-based baselines, while achieving good perceptual quality with only a few ODE steps. Overall, LTT provides a deterministic, physically interpretable, and computation-efficient framework for generative wireless image decoding across diverse channels.", "AI": {"tldr": "提出了一种新的land-then-transport（LTT）框架，采用流匹配（FM）生成解码器在无线图像传输中实现低延迟和高质量。", "motivation": "无线图像传输面临速率和可靠性要求严格的问题，传统的分层设计和联合源信道编码难以满足需求，特别是对于低延时场景。基于扩散的生成解码器虽然能提供强大的感知质量，但迭代去噪导致了高的解码延迟。因此提出了新的LTT框架解决这些问题。", "method": "通过构建高斯平滑路径以及训练神经网络学生向量场实现确定性、信道感知的ODE解码器，从而在低延时下获得高质量图像传输。对瑞利衰落和MIMO信道采用线性MMSE均衡处理映射到等效AWGN信道。", "result": "实验结果表明，在不同类型的信道上，该方法都表现出优于JPEG2000+LDPC、DeepJSCC及扩散基线的性能。同时只用少量ODE步骤就能获得良好的感知质量。", "conclusion": "所提出的LTT框架为无线图像传输提供了一种确定性、物理可解释且计算高效的解码方案，适用于多种信道环境"}}
{"id": "2601.07499", "pdf": "https://arxiv.org/pdf/2601.07499", "abs": "https://arxiv.org/abs/2601.07499", "authors": ["Bing Yu", "Liu Shi", "Haitao Wang", "Deran Qi", "Xiang Cai", "Wei Zhong", "Qiegen Liu"], "title": "Anatomy Aware Cascade Network: Bridging Epistemic Uncertainty and Geometric Manifold for 3D Tooth Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate three-dimensional (3D) tooth segmentation from Cone-Beam Computed Tomography (CBCT) is a prerequisite for digital dental workflows. However, achieving high-fidelity segmentation remains challenging due to adhesion artifacts in naturally occluded scans, which are caused by low contrast and indistinct inter-arch boundaries. To address these limitations, we propose the Anatomy Aware Cascade Network (AACNet), a coarse-to-fine framework designed to resolve boundary ambiguity while maintaining global structural consistency. Specifically, we introduce two mechanisms: the Ambiguity Gated Boundary Refiner (AGBR) and the Signed Distance Map guided Anatomical Attention (SDMAA). The AGBR employs an entropy based gating mechanism to perform targeted feature rectification in high uncertainty transition zones. Meanwhile, the SDMAA integrates implicit geometric constraints via signed distance map to enforce topological consistency, preventing the loss of spatial details associated with standard pooling. Experimental results on a dataset of 125 CBCT volumes demonstrate that AACNet achieves a Dice Similarity Coefficient of 90.17 \\% and a 95\\% Hausdorff Distance of 3.63 mm, significantly outperforming state-of-the-art methods. Furthermore, the model exhibits strong generalization on an external dataset with an HD95 of 2.19 mm, validating its reliability for downstream clinical applications such as surgical planning. Code for AACNet is available at https://github.com/shiliu0114/AACNet.", "AI": {"tldr": "本文提出了Anatomy Aware Cascade Network (AACNet)，用于改善三维牙齿分割的准确性。", "motivation": "传统的牙齿分割方法难以处理CBCT扫描中的低对比度和不明显的边界问题，导致精度不高。为了提高分割准确性和鲁棒性，作者设计了AACNet。", "method": "AACNet包括Ambiguity Gated Boundary Refiner（AGBR）和Signed Distance Map guided Anatomical Attention（SDMAA）。AGBR通过熵基门控机制进行特征校正，而SDMAA则利用隐含的几何约束保持拓扑一致性。", "result": "在包含125个CBCT体积的数据集上，AACNet达到了90.17％的Dice相似性系数和3.63毫米的HD95值，优于现有方法；外部数据集中HD95为2.19毫米。", "conclusion": "AACNet展示了在牙齿分割任务上的优越性能，并且适用于临床应用如手术规划。"}}
{"id": "2601.07496", "pdf": "https://arxiv.org/pdf/2601.07496", "abs": "https://arxiv.org/abs/2601.07496", "authors": ["Xiaoxiao Deng"], "title": "Graph Inference Towards ICD Coding", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages, 2 figures, 2 tables", "summary": "Automated ICD coding involves assigning standardized diagnostic codes to clinical narratives. The vast label space and extreme class imbalance continue to challenge precise prediction. To address these issues, LabGraph is introduced -- a unified framework that reformulates ICD coding as a graph generation task. By combining adversarial domain adaptation, graph-based reinforcement learning, and perturbation regularization, LabGraph effectively enhances model robustness and generalization. In addition, a label graph discriminator dynamically evaluates each generated code, providing adaptive reward feedback during training. Experiments on benchmark datasets demonstrate that LabGraph consistently outperforms previous approaches on micro-F1, micro-AUC, and P@K.", "AI": {"tldr": "本文提出了一个统一的框架LabGraph，将ICD编码问题转化为图生成任务，通过结合对抗领域适应、基于图的强化学习和扰动正则化来提高模型鲁棒性和泛化能力。", "motivation": "针对自动ICD编码面临的挑战，包括庞大的标签空间和极端类别不平衡问题，本文提出了一种新的框架LabGraph以改进预测精度。", "method": "LabGraph是一个将ICD编码作为图生成任务处理的统一框架。它结合了对抗领域适应、基于图的强化学习以及扰动正则化技术，并引入了一个动态评估每条生成代码的标签图判别器，提供实时反馈。", "result": "在基准数据集上的实验结果表明，LabGraph显著优于现有方法，在微平均F1分数、微平均AUC和P@K指标上均表现出色。", "conclusion": "通过创新性地将ICD编码问题转化为图生成任务并引入一系列技术改进，LabGraph框架成功提高了模型的预测精度与鲁棒性。"}}
{"id": "2601.07483", "pdf": "https://arxiv.org/pdf/2601.07483", "abs": "https://arxiv.org/abs/2601.07483", "authors": ["Fuyuan Liu", "Dianyu Yu", "He Ren", "Nayu Liu", "Xiaomian Kang", "Delai Qiu", "Fa Zhang", "Genpeng Zhen", "Shengping Liu", "Jiaen Liang", "Wei Huang", "Yining Wang", "Junnan Zhu"], "title": "FocalOrder: Focal Preference Optimization for Reading Order Detection", "categories": ["cs.CV"], "comment": null, "summary": "Reading order detection is the foundation of document understanding. Most existing methods rely on uniform supervision, implicitly assuming a constant difficulty distribution across layout regions. In this work, we challenge this assumption by revealing a critical flaw: \\textbf{Positional Disparity}, a phenomenon where models demonstrate mastery over the deterministic start and end regions but suffer a performance collapse in the complex intermediate sections. This degradation arises because standard training allows the massive volume of easy patterns to drown out the learning signals from difficult layouts. To address this, we propose \\textbf{FocalOrder}, a framework driven by \\textbf{Focal Preference Optimization (FPO)}. Specifically, FocalOrder employs adaptive difficulty discovery with exponential moving average mechanism to dynamically pinpoint hard-to-learn transitions, while introducing a difficulty-calibrated pairwise ranking objective to enforce global logical consistency. Extensive experiments demonstrate that FocalOrder establishes new state-of-the-art results on OmniDocBench v1.0 and Comp-HRDoc. Our compact model not only outperforms competitive specialized baselines but also significantly surpasses large-scale general VLMs. These results demonstrate that aligning the optimization with intrinsic structural ambiguity of documents is critical for mastering complex document structures.", "AI": {"tldr": "本文提出了FocalOrder框架，针对阅读顺序检测中的位置差异问题，通过焦点偏好优化来提高模型在中间复杂部分的表现。", "motivation": "现有的方法依赖于统一的监督学习，假设所有区域的学习难度是相同的。然而，实际中模型在起始和结束区域表现出色，在复杂的中间区域则表现较差，因为标准训练使得大量简单模式淹没了困难布局的学习信号。", "method": "FocalOrder利用自适应难度发现机制，通过指数移动平均来动态识别难学的过渡部分，并引入基于难度校准的成对排名目标以确保全局逻辑一致性。", "result": "实验表明，FocalOrder在OmniDocBench v1.0和Comp-HRDoc数据集上建立了新的最先进结果。它不仅超越了专门基线模型，在大型通用视觉语言模型上的表现也显著提升。", "conclusion": "文章结论强调，优化方法与文档内在结构歧义的一致性对于掌握复杂文档结构至关重要"}}
{"id": "2601.07482", "pdf": "https://arxiv.org/pdf/2601.07482", "abs": "https://arxiv.org/abs/2601.07482", "authors": ["Helia Karisani", "Mohammadreza Daneshvaramoli", "Hedyeh Beyhaghi", "Mohammad Hajiesmaili", "Cameron Musco"], "title": "The Secretary Problem with Predictions and a Chosen Order", "categories": ["cs.DS", "cs.DM", "cs.GT", "cs.LG"], "comment": "Accepted to the International Conference on Innovations in Theoretical Computer Science (ITCS 2026)", "summary": "We study a learning-augmented variant of the secretary problem, recently introduced by Fujii and Yoshida (2023), in which the decision-maker has access to machine-learned predictions of candidate values. The central challenge is to balance consistency and robustness: when predictions are accurate, the algorithm should select a near-optimal secretary, while under inaccurate predictions it should still guarantee a bounded competitive ratio. We consider both the classical Random Order Secretary Problem (ROSP), where candidates arrive in a uniformly random order, and a more natural learning-augmented model in which the decision-maker may choose the arrival order based on predicted values. We call this model the Chosen Order Secretary Problem (COSP), capturing scenarios such as interview schedules set in advance. We propose a new randomized algorithm applicable to both ROSP and COSP. Our method switches from fully trusting predictions to a threshold-based rule once a large prediction deviation is detected. Let $ε\\in [0,1]$ denote the maximum multiplicative prediction error. For ROSP, our algorithm achieves a competitive ratio of $\\max\\{0.221, (1-ε)/(1+ε)\\}$, improving upon the prior bound of $\\max\\{0.215, (1-ε)/(1+ε)\\}$. For COSP, we achieve $\\max\\{0.262, (1-ε)/(1+ε)\\}$, surpassing the $0.25$ worst-case bound for prior approaches and moving closer to the classical secretary benchmark of $1/e \\approx 0.368$. These results highlight the benefit of combining predictions with arrival-order control in online decision-making.", "AI": {"tldr": "研究了带有预测的秘书问题变体，提出了适用于随机顺序和选定顺序两种模型的新算法。", "motivation": "在决策者能够访问候选值机器学习预测的情况下，平衡准确性和鲁棒性是主要挑战。需要确保当预测准确时选择最优候选人，并在预测不准确时保持一定竞争比。", "method": "提出了一种新的随机化算法，在检测到大的预测偏差后从完全信任预测转换为基于阈值的规则。", "result": "对于随机顺序模型，该算法的竞争比达到了0.221和(1-ε)/(1+ε)中的较大值。对于选定顺序模型，则达成了0.262和(1-ε)/(1+ε)中的更大值。", "conclusion": "结合预测与到达顺序控制在线决策中可获得更好的结果，且更接近传统秘书问题的标准基准。"}}
{"id": "2601.07477", "pdf": "https://arxiv.org/pdf/2601.07477", "abs": "https://arxiv.org/abs/2601.07477", "authors": ["Zihan Ma", "Zhikai Zhao", "Chuanbo Hua", "Federico Berto", "Jinkyoo Park"], "title": "JudgeFlow: Agentic Workflow Optimization via Block Judge", "categories": ["cs.AI"], "comment": null, "summary": "Optimizing LLM-based agentic workflows is challenging for scaling AI capabilities. Current methods rely on coarse, end-to-end evaluation signals and lack fine-grained signals on where to refine, often resulting in inefficient or low-impact modifications. To address these limitations, we propose {\\our{}}, an Evaluation-Judge-Optimization-Update pipeline. We incorporate reusable, configurable logic blocks into agentic workflows to capture fundamental forms of logic. On top of this abstraction, we design a dedicated Judge module that inspects execution traces -- particularly failed runs -- and assigns rank-based responsibility scores to problematic blocks. These fine-grained diagnostic signals are then leveraged by an LLM-based optimizer, which focuses modifications on the most problematic block in the workflow. Our approach improves sample efficiency, enhances interpretability through block-level diagnostics, and provides a scalable foundation for automating increasingly complex agentic workflows. We evaluate {\\our{}} on mathematical reasoning and code generation benchmarks, where {\\our{}} achieves superior performance and efficiency compared to existing methods. The source code is publicly available at https://github.com/ma-zihan/JudgeFlow.", "AI": {"tldr": "提出了一种用于优化基于LLM的代理工作流的方法，通过引入可重用逻辑块和专门的评估模块来提高效率和解释性。", "motivation": "现有方法依赖于粗略的整体评价信号，缺乏细化的责任分配机制，导致改进效果不显著。为此，作者提出了JudgeFlow，以期解决这些问题并提升代理工作流优化的效果。", "method": "提出了一种基于评估-判定-优化-更新的管道，将可重用逻辑块集成到代理工作流中，并设计了一个专门负责诊断执行轨迹和分配责任评分的评判模块。利用这些信号，LLM优化器可以针对性地改进最需要改善的部分。", "result": "在数学推理和代码生成基准上，JudgeFlow展示了比现有方法更优的表现和效率。", "conclusion": "JudgeFlow通过引入精细化的责任评分机制和可重用的逻辑块模块，提供了更加有效且解释性更强的方法来优化基于LLM的工作流。"}}
{"id": "2601.07476", "pdf": "https://arxiv.org/pdf/2601.07476", "abs": "https://arxiv.org/abs/2601.07476", "authors": ["Elia Cereda", "Alessandro Giusti", "Daniele Palossi"], "title": "NanoCockpit: Performance-optimized Application Framework for AI-based Autonomous Nanorobotics", "categories": ["cs.RO", "cs.SE", "eess.SY"], "comment": "Source code available on GitHub at https://github.com/idsia-robotics/crazyflie-nanocockpit", "summary": "Autonomous nano-drones, powered by vision-based tiny machine learning (TinyML) models, are a novel technology gaining momentum thanks to their broad applicability and pushing scientific advancement on resource-limited embedded systems. Their small form factor, i.e., a few 10s grams, severely limits their onboard computational resources to sub-\\SI{100}{\\milli\\watt} microcontroller units (MCUs). The Bitcraze Crazyflie nano-drone is the \\textit{de facto} standard, offering a rich set of programmable MCUs for low-level control, multi-core processing, and radio transmission. However, roboticists very often underutilize these onboard precious resources due to the absence of a simple yet efficient software layer capable of time-optimal pipelining of multi-buffer image acquisition, multi-core computation, intra-MCUs data exchange, and Wi-Fi streaming, leading to sub-optimal control performances. Our \\textit{NanoCockpit} framework aims to fill this gap, increasing the throughput and minimizing the system's latency, while simplifying the developer experience through coroutine-based multi-tasking. In-field experiments on three real-world TinyML nanorobotics applications show our framework achieves ideal end-to-end latency, i.e. zero overhead due to serialized tasks, delivering quantifiable improvements in closed-loop control performance ($-$30\\% mean position error, mission success rate increased from 40\\% to 100\\%).", "AI": {"tldr": "NanoCockpit框架优化了微型机器人的计算资源利用，提高了TinyML模型在纳米无人机上的性能。", "motivation": "现有技术未能充分利用小型无人机的有限计算资源，导致控制性能不佳。NanoCockpit旨在解决这一问题，提升任务处理效率和开发体验。", "method": "通过引入基于协程的任务并行机制，优化多缓冲图像获取、多核计算、内核间数据交换及Wi-Fi流传输过程。", "result": "实验表明，在三种TinyML纳米机器人应用中，NanoCockpit框架实现了理想端到端延迟，并显著提升了闭环控制性能（平均位置误差减少30%，任务成功率从40%提升至100%）。", "conclusion": "NanoCockpit通过简化软件层实现高效的任务并行处理，从而优化了纳米无人机的计算资源使用和整体性能。"}}
{"id": "2601.07475", "pdf": "https://arxiv.org/pdf/2601.07475", "abs": "https://arxiv.org/abs/2601.07475", "authors": ["Haoqian Meng", "Yilun Luo", "Yafei Zhao", "Wenyuan Liu", "Peng Zhang", "Xindian Ma"], "title": "ARCQuant: Boosting NVFP4 Quantization with Augmented Residual Channels for LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The emergence of fine-grained numerical formats like NVFP4 presents new opportunities for efficient Large Language Model (LLM) inference. However, it is difficult to adapt existing Post-Training Quantization (PTQ) strategies to these formats: rotation-based methods compromise fine-grained block isolation; smoothing techniques struggle with significant 4-bit quantization errors; and mixed-precision approaches often conflict with hardware constraints on unified-precision computation. To address these challenges, we propose ARCQuant, a framework that boosts NVFP4 performance via Augmented Residual Channels. Distinct from methods that compromise block isolation or hardware uniformity, ARCQuant maintains a strictly unified NVFP4 format by augmenting the activation matrix with quantized residual channels. This design integrates the error compensation process directly into the matrix reduction dimension, enabling the use of standard, highly optimized GEMM kernels with minimal overhead. Theoretical analysis confirms that the worst-case error bound of our dual-stage NVFP4 quantization is comparable to that of standard 8-bit formats such as MXFP8. Extensive experiments on LLaMA and Qwen models demonstrate that ARCQuant achieves state-of-the-art accuracy, comparable to full-precision baselines in perplexity and downstream tasks. Furthermore, deployment on RTX 5090 and RTX PRO 6000 GPUs confirms practical benefits, achieving up to 3x speedup over FP16. Our code is available at https://github.com/actypedef/ARCQuant .", "AI": {"tldr": "ARCQuant 提出了一种增强 NVFP4 格式性能的新框架，通过增加残差通道来补偿量化误差。", "motivation": "现有的后训练量化策略难以适应细粒度数值格式（如 NVFP4），因为旋转方法破坏块隔离；平滑技术难以处理显著的四比特量化误差；混合精度方法通常与硬件统一精度计算冲突。为了解决这些问题，提出了 ARCQuant 框架。", "method": "ARCQuant 增强了 NVFP4 性能，通过增加残差通道来补偿误差，并将该过程直接集成到矩阵减少维度中，以使用标准且高度优化的 GEMM 核心并最小化开销。理论分析表明，双阶段 NVFP4 量化的最坏情况误差边界与 MXFP8 等标准八比特格式相当。", "result": "在 LLaMA 和 Qwen 模型上的广泛实验显示，ARCQuant 达到了最先进的准确度，其困惑度和下游任务的性能与全精度基线相当。部署在 RTX 5090 和 RTX PRO 6000 GPU 上验证了实际效益，相较于 FP16 实现高达3倍的速度提升。", "conclusion": "ARCQuant 提供了一种有效的方法来提高 NVFP4 格式下的大语言模型推理效率，同时保持高精度和性能。"}}
{"id": "2601.07474", "pdf": "https://arxiv.org/pdf/2601.07474", "abs": "https://arxiv.org/abs/2601.07474", "authors": ["Youngmin Oh", "Hyung-Il Kim", "Jung Uk Kim"], "title": "Task Prototype-Based Knowledge Retrieval for Multi-Task Learning from Partially Annotated Data", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Accepted at AAAI 2026", "summary": "Multi-task learning (MTL) is critical in real-world applications such as autonomous driving and robotics, enabling simultaneous handling of diverse tasks. However, obtaining fully annotated data for all tasks is impractical due to labeling costs. Existing methods for partially labeled MTL typically rely on predictions from unlabeled tasks, making it difficult to establish reliable task associations and potentially leading to negative transfer and suboptimal performance. To address these issues, we propose a prototype-based knowledge retrieval framework that achieves robust MTL instead of relying on predictions from unlabeled tasks. Our framework consists of two key components: (1) a task prototype embedding task-specific characteristics and quantifying task associations, and (2) a knowledge retrieval transformer that adaptively refines feature representations based on these associations. To achieve this, we introduce an association knowledge generating (AKG) loss to ensure the task prototype consistently captures task-specific characteristics. Extensive experiments demonstrate the effectiveness of our framework, highlighting its potential for robust multi-task learning, even when only a subset of tasks is annotated.", "AI": {"tldr": "本文提出了一种基于原型的知识检索框架，用于从部分标注数据中进行多任务学习。", "motivation": "现有方法在处理部分标记的多任务学习时依赖于未标记任务的预测，难以建立可靠的任务关联，并可能导致负迁移和次优性能。为解决这些问题，本文提出了一个无需依赖未标记任务预测的知识检索框架。", "method": "该框架包含两个关键组件：1）用于嵌入特定任务特征并量化任务关联的任务原型；2）根据这些关联自适应地优化特征表示的基于知识检索的变压器。引入了关联知识生成（AKG）损失，以确保任务原型一致捕获特定任务的特性。", "result": "广泛的实验表明所提出的框架的有效性，展示了其在只有部分任务被标记的情况下进行稳健多任务学习的巨大潜力。", "conclusion": "本文提出了一种无需依赖未标注任务预测的知识检索框架，该框架通过建立可靠的任务关联来提高多任务学习的性能。"}}
{"id": "2601.07470", "pdf": "https://arxiv.org/pdf/2601.07470", "abs": "https://arxiv.org/abs/2601.07470", "authors": ["Sirui Liang", "Pengfei Cao", "Jian Zhao", "Wenhao Teng", "Xiangwen Liao", "Jun Zhao", "Kang Liu"], "title": "Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory", "categories": ["cs.AI"], "comment": null, "summary": "Large language model (LLM) agents increasingly rely on accumulated memory to solve long-horizon decision-making tasks. However, most existing approaches store memory in fixed representations and reuse it at a single or implicit level of abstraction, which limits generalization and often leads to negative transfer when distribution shift. This paper proposes the Meta-Cognitive Memory Abstraction method (MCMA), which treats memory abstraction as a learnable cognitive skill rather than a fixed design choice. MCMA decouples task execution from memory management by combining a frozen task model with a learned memory copilot. The memory copilot is trained using direct preference optimization, it determines how memories should be structured, abstracted, and reused. Memories are further organized into a hierarchy of abstraction levels, enabling selective reuse based on task similarity. When no memory is transferable, MCMA transfers the ability to abstract and manage memory by transferring the memory copilot. Experiments on ALFWorld, ScienceWorld, and BabyAI demonstrate substantial improvements in performance, out-of-distribution generalization, and cross-task transfer over several baselines.", "AI": {"tldr": "论文提出了Meta-Cognitive Memory Abstraction方法（MCMA），通过学习记忆抽象和管理来解决长周期决策任务中的记忆问题。", "motivation": "现有的内存存储方式固定，难以适应分布变化，导致泛化能力和跨任务迁移能力受限。因此需要一种新的方法来改善这些问题。", "method": "MCMA将记忆管理和任务执行分离，使用一个固定的任务模型和学习的记忆助手（copilot）相结合。该助手通过直接偏好优化训练，决定如何组织、抽象和重用内存。此外，记忆按照层次结构进行组织，根据任务相似性选择性地重用。", "result": "在ALFWorld，ScienceWorld和BabyAI上的实验表明MCMA在性能，分布外泛化能力和跨任务迁移上都显著优于多个基线方法。", "conclusion": "通过将记忆抽象和管理视为可学习的认知技能而不是固定的设计选择，可以改善长期决策任务中的记忆使用效率。"}}
{"id": "2601.07469", "pdf": "https://arxiv.org/pdf/2601.07469", "abs": "https://arxiv.org/abs/2601.07469", "authors": ["Julien Cumin", "Oussama Er-Rahmany", "Xi Chen"], "title": "Knowledge Distillation for LLM-Based Human Activity Recognition in Homes", "categories": ["cs.AI"], "comment": null, "summary": "Human Activity Recognition (HAR) is a central problem for context-aware applications, especially for smart homes and assisted living. A few very recent studies have shown that Large Language Models (LLMs) can be used for HAR at home, reaching high performance and addressing key challenges. In this paper, we provide new experimental results regarding the use of LLMs for HAR, on two state-of-the-art datasets. More specifically, we show how recognition performance evolves depending on the size of the LLM used. Moreover, we experiment on the use of knowledge distillation techniques to fine-tune smaller LLMs with HAR reasoning examples generated by larger LLMs. We show that such fine-tuned models can perform almost as well as the largest LLMs, while having 50 times less parameters.", "AI": {"tldr": "本文研究了在家庭环境中使用大型语言模型（LLM）进行人类活动识别（HAR），并通过知识蒸馏技术优化较小的LLM。", "motivation": "提高家庭环境中的HAR性能，同时减少计算资源的需求。", "method": "利用不同大小的LLM进行HAR，并通过知识蒸馏将大型LLM的知识转移到小型LLM上。", "result": "实验结果表明，经过优化的小型LLM在参数量仅为最大模型五十分之一的情况下，能够达到与之相近的识别性能。", "conclusion": "通过知识蒸馏技术可以显著提升小规模LLM进行HAR的能力。"}}
{"id": "2601.07468", "pdf": "https://arxiv.org/pdf/2601.07468", "abs": "https://arxiv.org/abs/2601.07468", "authors": ["Miao Su", "Yucan Guo", "Zhongni Hou", "Long Bai", "Zixuan Li", "Yufei Zhang", "Guojun Yin", "Wei Lin", "Xiaolong Jin", "Jiafeng Guo", "Xueqi Cheng"], "title": "Beyond Dialogue Time: Temporal Semantic Memory for Personalized LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "Memory enables Large Language Model (LLM) agents to perceive, store, and use information from past dialogues, which is essential for personalization. However, existing methods fail to properly model the temporal dimension of memory in two aspects: 1) Temporal inaccuracy: memories are organized by dialogue time rather than their actual occurrence time; 2) Temporal fragmentation: existing methods focus on point-wise memory, losing durative information that captures persistent states and evolving patterns. To address these limitations, we propose Temporal Semantic Memory (TSM), a memory framework that models semantic time for point-wise memory and supports the construction and utilization of durative memory. During memory construction, it first builds a semantic timeline rather than a dialogue one. Then, it consolidates temporally continuous and semantically related information into a durative memory. During memory utilization, it incorporates the query's temporal intent on the semantic timeline, enabling the retrieval of temporally appropriate durative memories and providing time-valid, duration-consistent context to support response generation. Experiments on LongMemEval and LoCoMo show that TSM consistently outperforms existing methods and achieves up to 12.2% absolute improvement in accuracy, demonstrating the effectiveness of the proposed method.", "AI": {"tldr": "本文提出了一种新的记忆框架Temporal Semantic Memory（TSM），用于提高大型语言模型代理的个性化能力。", "motivation": "现有的记忆方法在时间维度上存在两个主要问题：一是时间不准确，二是时间碎片化。这些问题限制了现有方法的有效性。", "method": "该论文提出了Temporal Semantic Memory框架，在构建过程中首先建立语义时间线而不是对话时间线，然后将连续的、相关的时态信息合并为持续记忆。在利用过程中，该框架根据查询的时间意图从语义时间线上检索适当的记忆，并提供有效的上下文支持。", "result": "实验结果表明，TSM方法在LongMemEval和LoCoMo数据集上表现优于现有方法，准确性提高了12.2％，证明了其有效性。", "conclusion": "Temporal Semantic Memory框架有效解决了时间不准确性和时间碎片化的问题，为大型语言模型的个性化提供了有力支持。"}}
{"id": "2601.07464", "pdf": "https://arxiv.org/pdf/2601.07464", "abs": "https://arxiv.org/abs/2601.07464", "authors": ["Xiaoheng Wang", "Tongxuan Liu", "Zi Gong", "Xianzhe Dong", "Yuting Zeng", "Minhan Hu", "Weizhe Huang", "Jing Li"], "title": "IFDNS: An Iterative Feedback-Driven Neuro-Symbolic Method for Faithful Logical Reasoning", "categories": ["cs.AI"], "comment": "13 pages,5 figures", "summary": "Large language models (LLMs) have demonstrated impressive capabilities across a wide range of reasoning tasks, including logical and mathematical problem-solving. While prompt-based methods like Chain-of-Thought (CoT) can enhance LLM reasoning abilities to some extent, they often suffer from a lack of faithfulness, where the derived conclusions may not align with the generated reasoning chain. To address this issue, researchers have explored neuro-symbolic approaches to bolster LLM logical reasoning capabilities. However, existing neuro-symbolic methods still face challenges with information loss during the process. To overcome these limitations, we introduce Iterative Feedback-Driven Neuro-Symbolic (IFDNS), a novel prompt-based method that employs a multi-round feedback mechanism to address LLM limitations in handling complex logical relationships. IFDNS utilizes iterative feedback during the logic extraction phase to accurately extract causal relationship statements and translate them into propositional and logical implication expressions, effectively mitigating information loss issues. Furthermore, IFDNS is orthogonal to existing prompt methods, allowing for seamless integration with various prompting approaches. Empirical evaluations across six datasets demonstrate the effectiveness of IFDNS in significantly improving the performance of CoT and Chain-of-Thought with Self-Consistency (CoT-SC). Specifically, IFDNS achieves a +9.40% accuracy boost for CoT on the LogiQA dataset and a +11.70% improvement for CoT-SC on the PrOntoQA dataset.", "AI": {"tldr": "提出了一种迭代反馈驱动的神经符号方法IFDNS，用于提高大型语言模型在逻辑推理任务中的准确性。", "motivation": "现有提示法如Chain-of-Thought存在缺乏忠实性的问题，即得出结论可能与生成的理由链不一致。研究旨在解决信息丢失问题，提升LLM处理复杂逻辑关系的能力。", "method": "IFDNS方法利用迭代反馈机制在逻辑提取阶段精确抽取因果陈述，并将其转化为命题和逻辑蕴含表达式，减少信息丢失。该方法可无缝集成现有提示法中。", "result": "实验结果表明，在六个数据集上，IFDNS显著提高了Chain-of-Thought和Self-Consistency Chain-of-Thought的性能。具体而言，在LogiQA数据集中CoT准确度提升9.40%，在PrOntoQA数据集中CoT-SC准确率提高11.70%。", "conclusion": "IFDNS通过迭代反馈机制有效解决了神经符号方法的信息丢失问题，显著提升了大型语言模型的逻辑推理能力。"}}
{"id": "2601.07463", "pdf": "https://arxiv.org/pdf/2601.07463", "abs": "https://arxiv.org/abs/2601.07463", "authors": ["Sijia li", "Xinran Li", "Shibo Chen", "Jun Zhang"], "title": "Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Offline multi-agent reinforcement learning (MARL) aims to solve cooperative decision-making problems in multi-agent systems using pre-collected datasets. Existing offline MARL methods primarily constrain training within the dataset distribution, resulting in overly conservative policies that struggle to generalize beyond the support of the data. While model-based approaches offer a promising solution by expanding the original dataset with synthetic data generated from a learned world model, the high dimensionality, non-stationarity, and complexity of multi-agent systems make it challenging to accurately estimate the transitions and reward functions in offline MARL. Given the difficulty of directly modeling joint dynamics, we propose a local-to-global (LOGO) world model, a novel framework that leverages local predictions-which are easier to estimate-to infer global state dynamics, thus improving prediction accuracy while implicitly capturing agent-wise dependencies. Using the trained world model, we generate synthetic data to augment the original dataset, expanding the effective state-action space. To ensure reliable policy learning, we further introduce an uncertainty-aware sampling mechanism that adaptively weights synthetic data by prediction uncertainty, reducing approximation error propagation to policies. In contrast to conventional ensemble-based methods, our approach requires only an additional encoder for uncertainty estimation, significantly reducing computational overhead while maintaining accuracy. Extensive experiments across 8 scenarios against 8 baselines demonstrate that our method surpasses state-of-the-art baselines on standard offline MARL benchmarks, establishing a new model-based baseline for generalizable offline multi-agent learning.", "AI": {"tldr": "本文提出了一种名为局部到全局（LOGO）的世界模型，用于离线多智能体强化学习。", "motivation": "现有离线MARL方法在数据集分布内训练过于保守，难以泛化。通过引入合成数据生成的模型可以缓解此问题，但高维、非平稳性和复杂性使得直接建模联合动力学困难。", "method": "提出局部到全局（LOGO）世界模型框架，利用局部预测推断全局状态动态，并引入不确定性感知采样机制提高政策学习可靠性。该方法只需额外的编码器进行不确定性估计，减少了计算开销。", "result": "在8个场景中的实验表明本文方法优于现有的8种基线，在标准离线MARL基准测试上建立了新的模型基线。", "conclusion": "提出的局部到全局（LOGO）世界模型框架提升了多智能体系统的预测精度，提高了泛化能力，并且降低了计算开销。"}}
{"id": "2601.07462", "pdf": "https://arxiv.org/pdf/2601.07462", "abs": "https://arxiv.org/abs/2601.07462", "authors": ["Shikang Zheng", "Guantao Chen", "Lixuan He", "Jiacheng Liu", "Yuqi Lin", "Chang Zou", "Linfeng Zhang"], "title": "From Sketch to Fresco: Efficient Diffusion Transformer with Progressive Resolution", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion Transformers achieve impressive generative quality but remain computationally expensive due to iterative sampling. Recently, dynamic resolution sampling has emerged as a promising acceleration technique by reducing the resolution of early sampling steps. However, existing methods rely on heuristic re-noising at every resolution transition, injecting noise that breaks cross-stage consistency and forces the model to relearn global structure. In addition, these methods indiscriminately upsample the entire latent space at once without checking which regions have actually converged, causing accumulated errors, and visible artifacts. Therefore, we propose \\textbf{Fresco}, a dynamic resolution framework that unifies re-noise and global structure across stages with progressive upsampling, preserving both the efficiency of low-resolution drafting and the fidelity of high-resolution refinement, with all stages aligned toward the same final target. Fresco achieves near-lossless acceleration across diverse domains and models, including 10$\\times$ speedup on FLUX, and 5$\\times$ on HunyuanVideo, while remaining orthogonal to distillation, quantization and feature caching, reaching 22$\\times$ speedup when combined with distilled models. Our code is in supplementary material and will be released on Github.", "AI": {"tldr": "提出了一种名为Fresco的动态分辨率框架，用于加速扩散变压器的生成过程。", "motivation": "现有方法通过降低早期采样步骤的分辨率来实现加速，但它们依赖于在每个分辨率转换时进行随机重噪，这会破坏跨阶段一致性并强制模型重新学习全局结构。此外，这些方法不区分地对整个潜在空间一次性上采样，导致累积错误和可见伪影。", "method": "Fresco框架统一了不同阶段的重噪声处理，并引入逐级渐进式上采样来保持低分辨率草图绘制时的效率以及高分辨率细化时的质量。这种方法在整个过程中与最终目标保持一致。", "result": "Fresco在FLUX和HunyuanVideo等不同的模型和领域中实现了接近无损加速，速度提高了10倍以上，并且可以与其他技术如蒸馏结合使用以实现更大的速度提升，例如22倍。", "conclusion": "提出了一种新的动态分辨率框架——Fresco，该方法不仅具有高效的采样效率，还能保持高质量的生成结果。"}}
{"id": "2601.07459", "pdf": "https://arxiv.org/pdf/2601.07459", "abs": "https://arxiv.org/abs/2601.07459", "authors": ["Himanshu Patil", "Geo Jolly", "Ramana Raja Buddala", "Ganesh Ramakrishnan", "Rohit Saluja"], "title": "Improving Video Question Answering through query-based frame selection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Video Question Answering (VideoQA) models enhance understanding and interaction with audiovisual content, making it more accessible, searchable, and useful for a wide range of fields such as education, surveillance, entertainment, and content creation. Due to heavy compute requirements, most large visual language models (VLMs) for VideoQA rely on a fixed number of frames by uniformly sampling the video. However, this process does not pick important frames or capture the context of the video. We present a novel query-based selection of frames relevant to the questions based on the submodular mutual Information (SMI) functions. By replacing uniform frame sampling with query-based selection, our method ensures that the chosen frames provide complementary and essential visual information for accurate VideoQA. We evaluate our approach on the MVBench dataset, which spans a diverse set of multi-action video tasks. VideoQA accuracy on this dataset was assessed using two VLMs, namely Video-LLaVA and LLaVA-NeXT, both of which originally employed uniform frame sampling. Experiments were conducted using both uniform and query-based sampling strategies. An accuracy improvement of up to \\textbf{4\\%} was observed when using query-based frame selection over uniform sampling. Qualitative analysis further highlights that query-based selection, using SMI functions, consistently picks frames better aligned with the question. We opine that such query-based frame selection can enhance accuracy in a wide range of tasks that rely on only a subset of video frames.", "AI": {"tldr": "本文提出了一种基于查询的视频帧选择方法，以提高视频问答系统的准确率。", "motivation": "当前大多数大型视觉语言模型在处理视频问答任务时采用均匀采样的方式选取固定数量的帧，这种方法无法捕捉到重要帧和完整的视频背景信息。因此提出了新的基于查询的帧选择策略来改进这一问题。", "method": "通过使用次模互信息（SMI）函数，根据问题的相关性进行视频帧的选择，替代传统的均匀采样方法，以保证所选帧能够提供互补且重要的视觉信息。", "result": "在MVBench数据集上的实验显示，与原始的均匀采样相比，基于查询的帧选择策略可以提高VideoQA模型约4%的准确率，并且定性分析表明该方法能更好地挑选出与问题相关联的关键帧。", "conclusion": "本文提出的基于查询的视频帧选择方法能够提升多种任务中仅依赖部分关键帧时的表现。"}}
{"id": "2601.07454", "pdf": "https://arxiv.org/pdf/2601.07454", "abs": "https://arxiv.org/abs/2601.07454", "authors": ["Yuxuan Hu", "Kuangji Zuo", "Boyu Ma", "Shihao Li", "Zhaoyang Xia", "Feng Xu", "Jianfei Yang"], "title": "WaveMan: mmWave-Based Room-Scale Human Interaction Perception for Humanoid Robots", "categories": ["cs.RO"], "comment": null, "summary": "Reliable humanoid-robot interaction (HRI) in household environments is constrained by two fundamental requirements, namely robustness to unconstrained user positions and preservation of user privacy. Millimeter-wave (mmWave) sensing inherently supports privacy-preserving interaction, making it a promising modality for room-scale HRI. However, existing mmWave-based interaction-sensing systems exhibit poor spatial generalization at unseen distances or viewpoints. To address this challenge, we introduce WaveMan, a spatially adaptive room-scale perception system that restores reliable human interaction sensing across arbitrary user positions. WaveMan integrates viewpoint alignment and spectrogram enhancement for spatial consistency, with dual-channel attention for robust feature extraction. Experiments across five participants show that, under fixed-position evaluation, WaveMan achieves the same cross-position accuracy as the baseline with five times fewer training positions. In random free-position testing, accuracy increases from 33.00% to 94.33%, enabled by the proposed method. These results demonstrate the feasibility of reliable, privacy-preserving interaction for household humanoid robots across unconstrained user positions.", "AI": {"tldr": "本文提出了WaveMan系统，用于实现基于毫米波的房间尺度的人机交互感知。", "motivation": "在家庭环境中可靠地进行人形机器人与人类之间的互动受到用户位置不受控制和隐私保护的要求限制。毫米波传感因其支持隐私保护而成为一种有前景的模式，但现有系统存在空间泛化能力不足的问题。", "method": "WaveMan系统通过视角对齐和光谱图增强实现空间一致性，并利用双通道注意力机制进行鲁棒特征提取。", "result": "实验结果显示，在固定位置评估中，WaveMan与基线相比，在使用五分之一训练位置的情况下达到了同样的跨位置准确性。在随机自由位置测试中，准确率从33.00%提高到了94.33%。", "conclusion": "结果表明，基于毫米波的房间尺度人机交互感知是可行的，并能够在不受限用户位置下实现可靠、隐私保护的人形机器人互动"}}
{"id": "2601.07449", "pdf": "https://arxiv.org/pdf/2601.07449", "abs": "https://arxiv.org/abs/2601.07449", "authors": ["Hao Jiang", "Zhi Yang", "Annan Wang", "Yichi Zhang", "Weisi Lin"], "title": "RLPO: Residual Listwise Preference Optimization for Long-Context Review Ranking", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Review ranking is pivotal in e-commerce for prioritizing diagnostic and authentic feedback from the deluge of user-generated content. While large language models have improved semantic assessment, existing ranking paradigms face a persistent trade-off in long-context settings. Pointwise scoring is efficient but often fails to account for list-level interactions, leading to miscalibrated top-$k$ rankings. Listwise approaches can leverage global context, yet they are computationally expensive and become unstable as candidate lists grow. To address this, we propose Residual Listwise Preference Optimization (RLPO), which formulates ranking as listwise representation-level residual correction over a strong pointwise LLM scorer. RLPO first produces calibrated pointwise scores and item representations, then applies a lightweight encoder over the representations to predict listwise score residuals, avoiding full token-level listwise processing. We also introduce a large-scale benchmark for long-context review ranking with human verification. Experiments show RLPO improves NDCG@k over strong pointwise and listwise baselines and remains robust as list length increases.", "AI": {"tldr": "论文提出了一种基于残差列表偏好优化的长上下文评论排名方法（RLPO），该方法在点对点评分的基础上，利用轻量级编码器预测列表级别得分残差。", "motivation": "现有的评论排名方案在长上下文设置中存在效率与精确度之间的权衡。点对点评分虽高效但缺乏全局视角；而列表方式虽能考虑整体内容但计算开销大且不稳定。", "method": "RLPO通过强大的语言模型生成校准的点对点得分和项目表示，然后使用轻量级编码器预测这些表示的列表级别残差，以改进排名。", "result": "实验表明，RLPO在NDCG@k等指标上优于现有的点对点和列表方式基准，并且随着候选列表长度增加时保持稳定性能。", "conclusion": "通过提出一种新颖的长上下文评论排名技术（RLPO），论文解决了现有方法中的效率与精度权衡问题，提供了更有效的解决方案。"}}
{"id": "2601.07447", "pdf": "https://arxiv.org/pdf/2601.07447", "abs": "https://arxiv.org/abs/2601.07447", "authors": ["Mahdi Chamseddine", "Didier Stricker", "Jason Rambach"], "title": "PanoSAMic: Panoramic Image Segmentation from SAM Feature Encoding and Dual View Fusion", "categories": ["cs.CV"], "comment": null, "summary": "Existing image foundation models are not optimized for spherical images having been trained primarily on perspective images. PanoSAMic integrates the pre-trained Segment Anything (SAM) encoder to make use of its extensive training and integrate it into a semantic segmentation model for panoramic images using multiple modalities. We modify the SAM encoder to output multi-stage features and introduce a novel spatio-modal fusion module that allows the model to select the relevant modalities and best features from each modality for different areas of the input. Furthermore, our semantic decoder uses spherical attention and dual view fusion to overcome the distortions and edge discontinuity often associated with panoramic images. PanoSAMic achieves state-of-the-art (SotA) results on Stanford2D3DS for RGB, RGB-D, and RGB-D-N modalities and on Matterport3D for RGB and RGB-D modalities. https://github.com/dfki-av/PanoSAMic", "AI": {"tldr": "该论文提出了PanoSAMic模型，用于全景图像的分割任务。", "motivation": "现有的图像基础模型主要是为透视图训练，并不适合处理球形全景图像。为了克服这一限制并提高全景图像的语义分割精度，作者提出了一种新的方法来解决全景图像中的变形和边缘不连续问题。", "method": "PanoSAMic通过集成预训练的Segment Anything (SAM) 编码器来利用其广泛的训练，并将其融入到适用于全景图像的多模态语义分割模型中。该方法还包括一个多阶段特征输出的修改，以及一种新颖的空间-模式融合模块，允许模型选择每个输入区域相关的最佳模态和特性。", "result": "PanoSAMic在Stanford2D3DS数据集上实现了RGB、RGB-D和RGB-D-N模态的最佳效果，在Matterport3D数据集上实现了RGB和RGB-D模态的最好结果。", "conclusion": "通过引入新颖的空间-模式融合模块以及基于球形注意力机制的双视图融合，PanoSAMic能够在全景图像分割中实现优异的结果。"}}
{"id": "2601.07434", "pdf": "https://arxiv.org/pdf/2601.07434", "abs": "https://arxiv.org/abs/2601.07434", "authors": ["Xin Guan", "Fangguo Zhao", "Qianyi Wang", "Chengcheng Zhao", "Jiming Chen", "Shuo Li"], "title": "LOONG: Online Time-Optimal Autonomous Flight for MAVs in Cluttered Environments", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous flight of micro air vehicles (MAVs) in unknown, cluttered environments remains challenging for time-critical missions due to conservative maneuvering strategies. This article presents an integrated planning and control framework for high-speed, time-optimal autonomous flight of MAVs in cluttered environments. In each replanning cycle (100 Hz), a time-optimal trajectory under polynomial presentation is generated as a reference, with the time-allocation process accelerated by imitation learning. Subsequently, a time-optimal model predictive contouring control (MPCC) incorporates safe flight corridor (SFC) constraints at variable horizon steps to enable aggressive yet safe maneuvering, while fully exploiting the MAV's dynamics. We validate the proposed framework extensively on a custom-built LiDAR-based MAV platform. Simulation results demonstrate superior aggressiveness compared to the state of the art, while real-world experiments achieve a peak speed of 18 m/s in a cluttered environment and succeed in 10 consecutive trials from diverse start points. The video is available at the following link: https://youtu.be/vexXXhv99oQ.", "AI": {"tldr": "本文提出了一种集成规划和控制框架，使微型飞行器(MAV)在未知、复杂环境中实现高速时间最优自主飞行。", "motivation": "微小型无人机在未知且复杂的环境下执行时间关键任务时，由于保守的机动策略而面临挑战。因此，研究一种高效率的时间最优自主飞行方案是必要的。", "method": "提出了一种结合规划和控制的框架，在每次重新规划周期（每秒100次）生成多项式表达的时间最优轨迹作为参考，并通过模仿学习加速时间分配过程。随后使用包含可变时间范围的安全飞行走廊约束的时间最优模型预测轮廓控制来实现激进且安全的操作。", "result": "该框架在模拟实验中表现出了优于现有技术的激进行为，在实际世界测试中，实现了18米/秒的峰值速度，并从不同起点完成了连续十次的成功试验。", "conclusion": "本文提出的框架通过高效率的时间最优轨迹生成和动态控制策略，使微型飞行器能够在未知、复杂的环境中实现高速自主飞行。"}}
{"id": "2601.07430", "pdf": "https://arxiv.org/pdf/2601.07430", "abs": "https://arxiv.org/abs/2601.07430", "authors": ["Qitan Lv", "Tianyu Liu", "Qiaosheng Zhang", "Xingcheng Xu", "Chaochao Lu"], "title": "KALE: Enhancing Knowledge Manipulation in Large Language Models via Knowledge-aware Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Despite the impressive performance of large language models (LLMs) pretrained on vast knowledge corpora, advancing their knowledge manipulation-the ability to effectively recall, reason, and transfer relevant knowledge-remains challenging. Existing methods mainly leverage Supervised Fine-Tuning (SFT) on labeled datasets to enhance LLMs' knowledge manipulation ability. However, we observe that SFT models still exhibit the known&incorrect phenomenon, where they explicitly possess relevant knowledge for a given question but fail to leverage it for correct answers. To address this challenge, we propose KALE (Knowledge-Aware LEarning)-a post-training framework that leverages knowledge graphs (KGs) to generate high-quality rationales and enhance LLMs' knowledge manipulation ability. Specifically, KALE first introduces a Knowledge-Induced (KI) data synthesis method that efficiently extracts multi-hop reasoning paths from KGs to generate high-quality rationales for question-answer pairs. Then, KALE employs a Knowledge-Aware (KA) fine-tuning paradigm that enhances knowledge manipulation by internalizing rationale-guided reasoning through minimizing the KL divergence between predictions with and without rationales. Extensive experiments on eight popular benchmarks across six different LLMs demonstrate the effectiveness of KALE, achieving accuracy improvements of up to 11.72% and an average of 4.18%.", "AI": {"tldr": "提出了一种名为KALE的知识感知学习框架，旨在通过知识图谱生成高质量的推理路径来增强大型语言模型的知识操作能力。", "motivation": "尽管预训练的大型语言模型在大量知识语料库上表现出色，但它们的知识操作能力仍需提升。现有方法主要依赖监督微调，存在“已知且错误”的现象，即拥有相关知识却未能正确应用。", "method": "KALE框架包含两个阶段：首先利用知识诱导的数据合成方法从知识图谱中提取多跳推理路径以生成高质量的推理；其次采用知识感知微调范式，通过最小化有无推理时预测之间的KL散度来增强模型的知识操作能力。", "result": "在八个流行的基准测试集上进行的实验显示，KALE框架提高了准确率，平均提高4.18%，最高可达11.72%。", "conclusion": "KALE框架能够有效改善大型语言模型的知识操作性能。"}}
{"id": "2601.07422", "pdf": "https://arxiv.org/pdf/2601.07422", "abs": "https://arxiv.org/abs/2601.07422", "authors": ["Wen Luo", "Guangyue Peng", "Wei Li", "Shaohang Wei", "Feifan Song", "Liang Wang", "Nan Yang", "Xingxing Zhang", "Jing Jin", "Furu Wei", "Houfeng Wang"], "title": "Two Pathways to Truthfulness: On the Intrinsic Encoding of LLM Hallucinations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Despite their impressive capabilities, large language models (LLMs) frequently generate hallucinations. Previous work shows that their internal states encode rich signals of truthfulness, yet the origins and mechanisms of these signals remain unclear. In this paper, we demonstrate that truthfulness cues arise from two distinct information pathways: (1) a Question-Anchored pathway that depends on question-answer information flow, and (2) an Answer-Anchored pathway that derives self-contained evidence from the generated answer itself. First, we validate and disentangle these pathways through attention knockout and token patching. Afterwards, we uncover notable and intriguing properties of these two mechanisms. Further experiments reveal that (1) the two mechanisms are closely associated with LLM knowledge boundaries; and (2) internal representations are aware of their distinctions. Finally, building on these insightful findings, two applications are proposed to enhance hallucination detection performance. Overall, our work provides new insight into how LLMs internally encode truthfulness, offering directions for more reliable and self-aware generative systems.", "AI": {"tldr": "研究揭示了大型语言模型生成事实陈述的两种路径：问题锚定和回答锚定。", "motivation": "为了理解大型语言模型内部如何编码真实性，解决其产生幻觉的问题", "method": "通过注意力消除和标记修补技术验证并区分这两种信息路径，并探索它们与LLM知识边界的关系以及内在表示的区别意识。", "result": "发现两种机制与LLM的知识界限紧密相关，且内部表征能够区分这些区别。", "conclusion": "此研究为理解LLMs如何在内部编码真实性提供了新见解，并提出提升幻觉检测性能的应用方案。"}}
{"id": "2601.07416", "pdf": "https://arxiv.org/pdf/2601.07416", "abs": "https://arxiv.org/abs/2601.07416", "authors": ["Prachet Dev Singh", "Shyamsundar Paramasivam", "Sneha Barman", "Mainak Singha", "Ankit Jha", "Girish Mishra", "Biplab Banerjee"], "title": "SDHSI-Net: Learning Better Representations for Hyperspectral Images via Self-Distillation", "categories": ["cs.CV"], "comment": "Accepted at InGARSS 2025", "summary": "Hyperspectral image (HSI) classification presents unique challenges due to its high spectral dimensionality and limited labeled data. Traditional deep learning models often suffer from overfitting and high computational costs. Self-distillation (SD), a variant of knowledge distillation where a network learns from its own predictions, has recently emerged as a promising strategy to enhance model performance without requiring external teacher networks. In this work, we explore the application of SD to HSI by treating earlier outputs as soft targets, thereby enforcing consistency between intermediate and final predictions. This process improves intra-class compactness and inter-class separability in the learned feature space. Our approach is validated on two benchmark HSI datasets and demonstrates significant improvements in classification accuracy and robustness, highlighting the effectiveness of SD for spectral-spatial learning. Codes are available at https://github.com/Prachet-Dev-Singh/SDHSI.", "AI": {"tldr": "本文提出了一种基于自蒸馏（SD）的HSI分类方法SDHSI-Net，通过网络自身的预测来提高特征表示的质量。", "motivation": "高光谱图像(HSI)分类面临维度灾难和标注数据有限的问题。传统深度学习模型容易过拟合且计算成本高昂。自我蒸馏(SD)作为一种无需外部教师网络的策略，可以改善模型性能。", "method": "本文提出了一种新的方法SDHSI-Net，通过自蒸馏过程使早期输出作为软目标，增强中间预测与最终预测的一致性，提高分类效果。", "result": "在两个基准HSI数据集上验证了该方法的有效性，显示出显著的分类准确率和鲁棒性的提升。", "conclusion": "本文展示了SD对高光谱图像分类任务的强大能力，并证明其可以有效改善特征表示。"}}
{"id": "2601.07411", "pdf": "https://arxiv.org/pdf/2601.07411", "abs": "https://arxiv.org/abs/2601.07411", "authors": ["Zihao Fu", "Xufeng Duan", "Zhenguang G. Cai"], "title": "SCALPEL: Selective Capability Ablation via Low-rank Parameter Editing for Large Language Model Interpretability Analysis", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models excel across diverse domains, yet their deployment in healthcare, legal systems, and autonomous decision-making remains limited by incomplete understanding of their internal mechanisms. As these models integrate into high-stakes systems, understanding how they encode capabilities has become fundamental to interpretability research. Traditional approaches identify important modules through gradient attribution or activation analysis, assuming specific capabilities map to specific components. However, this oversimplifies neural computation: modules may contribute to multiple capabilities simultaneously, while single capabilities may distribute across multiple modules. These coarse-grained analyses fail to capture fine-grained, distributed capability encoding. We present SCALPEL (Selective Capability Ablation via Low-rank Parameter Editing for Large language models), a framework representing capabilities as low-rank parameter subspaces rather than discrete modules. Our key insight is that capabilities can be characterized by low-rank modifications distributed across layers and modules, enabling precise capability removal without affecting others. By training LoRA adapters to reduce distinguishing correct from incorrect answers while preserving general language modeling quality, SCALPEL identifies low-rank representations responsible for particular capabilities while remaining disentangled from others. Experiments across diverse capability and linguistic tasks from BLiMP demonstrate that SCALPEL successfully removes target capabilities while preserving general capabilities, providing fine-grained insights into capability distribution across parameter space. Results reveal that capabilities exhibit low-rank structure and can be selectively ablated through targeted parameter-space interventions, offering nuanced understanding of capability encoding in LLMs.", "AI": {"tldr": "SCALPEL框架通过低秩参数编辑来选择性地去除大型语言模型中的特定能力，从而提高对这些模型内部机制的理解。", "motivation": "为了更好地理解大型语言模型在不同领域的能力编码方式，特别是当它们应用于医疗、法律和自主决策等关键系统时，传统的模块化分析方法存在局限性。因此，作者提出了一种新的框架来更精确地识别和移除特定能力，而不会影响到其他功能。", "method": "SCALPEL采用低秩参数子空间表示特定的能力，并通过训练LoRA适配器以减少区分正确与错误答案的准确性同时保持通用语言建模的质量。这种方法能够精准地分离出负责特定能力的低秩表征，而不与其他能力混淆。", "result": "实验结果表明，SCALPEL能够在各种能力和语言任务中成功移除目标能力的同时保留一般的能力，从而提供了对能力在参数空间分布的细致见解，并证实了这些能力具有低秩结构。", "conclusion": "通过选择性地去除大型语言模型中的特定能力，SCALPEL不仅加深了我们对其内部机制的理解，还展示了能力可以通过有针对性的干预在参数空间中被分离出来。这为理解大型语言模型的能力编码提供了新的视角和方法论支持。"}}
{"id": "2601.07401", "pdf": "https://arxiv.org/pdf/2601.07401", "abs": "https://arxiv.org/abs/2601.07401", "authors": ["Raj Mahmud", "Shlomo Berkovsky", "Mukesh Prasad", "A. Baki Kocaballi"], "title": "Recommendation-as-Experience: A framework for context-sensitive adaptation in conversational recommender systems", "categories": ["cs.HC"], "comment": null, "summary": "While Conversational Recommender Systems (CRS) have matured technically, they frequently lack principled methods for encoding latent experiential aims as adaptive state variables. Consequently, contemporary architectures often prioritise ranking accuracy at the expense of nuanced, context-sensitive interaction behaviours. This paper addresses this gap through a comprehensive multi-domain study ($N = 168$) that quantifies the joint prioritisation of three critical interaction aims: educative (to inform and justify), explorative (to diversify and inspire), and affective (to align emotionally and socially). Utilising Bayesian hierarchical ordinal regression, we establish domain profiles and perceived item value as systematic modulators of these priorities. Furthermore, we identify stable user-level preferences for autonomy that persist across distinct interactional goals, suggesting that agency is a fundamental requirement of the conversational experience. Drawing on these empirical foundations, we formalise the Recommendation-as-Experience (RAE) adaptation framework. RAE systematically encodes contextual and individual signals into structured state representations, mapping them to experience-aligned dialogue policies realised through retrieval diversification, heuristic logic, or Large Language Model based controllable generation. As an architecture-agnostic blueprint, RAE facilitates the design of context-sensitive CRS that effectively balance experiential quality with predictive performance.", "AI": {"tldr": "推荐作为体验：一种对话推荐系统中的上下文敏感适应框架", "motivation": "当前的对话推荐系统在交互行为上缺乏细致入微和上下文敏感的方法，倾向于优先考虑排名准确性。本文旨在填补这一空白。", "method": "通过一项多领域研究（N=168），利用贝叶斯层次序回归建立了领域概况和感知项目价值作为这些目标优先级的系统调节器，并提出了推荐作为体验框架", "result": "该研究确定了用户在不同交互目标下的稳定自主偏好，表明代理是对话体验的基本要求。提出了RAE适应框架，可以将上下文和个人信号编码为结构化的状态表示。", "conclusion": "RAE架构能够设计出有效的平衡体验质量和预测性能的上下文敏感CRS"}}
{"id": "2601.07397", "pdf": "https://arxiv.org/pdf/2601.07397", "abs": "https://arxiv.org/abs/2601.07397", "authors": ["Michael Hintermüller", "Michael Hinze", "Denis Korolev"], "title": "Layerwise goal-oriented adaptivity for neural ODEs: an optimal control perspective", "categories": ["math.OC", "cs.AI"], "comment": null, "summary": "In this work, we propose a novel layerwise adaptive construction method for neural network architectures. Our approach is based on a goal--oriented dual-weighted residual technique for the optimal control of neural differential equations. This leads to an ordinary differential equation constrained optimization problem with controls acting as coefficients and a specific loss function. We implement our approach on the basis of a DG(0) Galerkin discretization of the neural ODE, leading to an explicit Euler time marching scheme. For the optimization we use steepest descent. Finally, we apply our method to the construction of neural networks for the classification of data sets, where we present results for a selection of well known examples from the literature.", "AI": {"tldr": "提出了一种基于目标导向的双重加权残差技术构建神经网络架构的方法，特别适用于处理神经微分方程问题。", "motivation": "为了提高神经网络在分类任务中的性能并优化其结构，引入一种新的逐层自适应构建方法。", "method": "通过将问题转化为常微分方程约束优化问题，并利用显式欧拉时间推进方案进行求解。控制变量作为系数出现，特定的损失函数用于指导优化过程。", "result": "实验结果表明所提出的方法在数据集分类任务中的应用效果良好，展示了几个来自文献中知名例子的结果。", "conclusion": "该方法为神经网络架构的自适应构建提供了一种有效策略，在解决复杂问题时具有潜在优势。"}}
{"id": "2601.07396", "pdf": "https://arxiv.org/pdf/2601.07396", "abs": "https://arxiv.org/abs/2601.07396", "authors": ["Guantao Chen", "Shikang Zheng", "Yuqi Lin", "Linfeng Zhang"], "title": "Forecast the Principal, Stabilize the Residual: Subspace-Aware Feature Caching for Efficient Diffusion Transformers", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion Transformer (DiT) models have achieved unprecedented quality in image and video generation, yet their iterative sampling process remains computationally prohibitive. To accelerate inference, feature caching methods have emerged by reusing intermediate representations across timesteps. However, existing caching approaches treat all feature components uniformly. We reveal that DiT feature spaces contain distinct principal and residual subspaces with divergent temporal behavior: the principal subspace evolves smoothly and predictably, while the residual subspace exhibits volatile, low-energy oscillations that resist accurate prediction. Building on this insight, we propose SVD-Cache, a subspace-aware caching framework that decomposes diffusion features via Singular Value Decomposition (SVD), applies exponential moving average (EMA) prediction to the dominant low-rank components, and directly reuses the residual subspace. Extensive experiments demonstrate that SVD-Cache achieves near-lossless across diverse models and methods, including 5.55$\\times$ speedup on FLUX and HunyuanVideo, and compatibility with model acceleration techniques including distillation, quantization and sparse attention. Our code is in supplementary material and will be released on Github.", "AI": {"tldr": "本文提出了一种基于子空间感知特征缓存的框架SVD-Cache，以加速Diffusion Transformers模型的推理过程。", "motivation": "现有的特征缓存方法忽略了DiT特征空间中不同的子空间特性。为了提高效率并减少计算负担，作者揭示了主子空间和残差子空间在时间行为上的差异，并提出了一种新的缓存框架来利用这些差异。", "method": "通过SVD分解扩散特征并将主导低秩成分应用EMA预测，同时直接重用残差子空间。该方法显著提高了推理速度并保持生成质量的无损性。", "result": "实验显示，SVD-Cache在各种模型和方法中实现了接近无损的结果，并且比FLUX和HunyuanVideo快5.55倍。", "conclusion": "所提出的SVD-Cache框架能够显著加速Diffusion Transformers的推理速度，同时保持生成质量。此技术具有广泛的适用性，与包括蒸馏、量化以及稀疏注意力在内的其他模型加速技巧兼容。"}}
{"id": "2601.07395", "pdf": "https://arxiv.org/pdf/2601.07395", "abs": "https://arxiv.org/abs/2601.07395", "authors": ["Ruiqi Li", "Zhiqiang Wang", "Yunhao Yao", "Xiang-Yang Li"], "title": "MCP-ITP: An Automated Framework for Implicit Tool Poisoning in MCP", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "To standardize interactions between LLM-based agents and their environments, the Model Context Protocol (MCP) was proposed and has since been widely adopted. However, integrating external tools expands the attack surface, exposing agents to tool poisoning attacks. In such attacks, malicious instructions embedded in tool metadata are injected into the agent context during MCP registration phase, thereby manipulating agent behavior. Prior work primarily focuses on explicit tool poisoning or relied on manually crafted poisoned tools. In contrast, we focus on a particularly stealthy variant: implicit tool poisoning, where the poisoned tool itself remains uninvoked. Instead, the instructions embedded in the tool metadata induce the agent to invoke a legitimate but high-privilege tool to perform malicious operations. We propose MCP-ITP, the first automated and adaptive framework for implicit tool poisoning within the MCP ecosystem. MCP-ITP formulates poisoned tool generation as a black-box optimization problem and employs an iterative optimization strategy that leverages feedback from both an evaluation LLM and a detection LLM to maximize Attack Success Rate (ASR) while evading current detection mechanisms. Experimental results on the MCPTox dataset across 12 LLM agents demonstrate that MCP-ITP consistently outperforms the manually crafted baseline, achieving up to 84.2% ASR while suppressing the Malicious Tool Detection Rate (MDR) to as low as 0.3%.", "AI": {"tldr": "提出了一种针对MCP生态系统中的隐式工具中毒的自动化和适应性框架MCP-ITP。", "motivation": "旨在解决模型上下文协议（MCP）在集成外部工具时带来的攻击面扩大问题，特别是在恶意指令嵌入到工具元数据中进行隐蔽操作的情况下。", "method": "将毒化工具生成作为黑盒优化问题处理，并采用迭代优化策略利用评估LLM和检测LLM的反馈来最大化攻击成功率（ASR）同时降低被现有检测机制识别的风险。", "result": "在包含12个LLM代理的MCPTox数据集上进行实验，结果显示MCP-ITP的表现优于手动构造的基础线模型，达到了高达84.2%的攻击成功率，并将恶意工具检测率（MDR）降低到最低0.3%。", "conclusion": "证明了MCP-ITP在隐蔽地操控代理行为方面的有效性和优越性，展示了其作为自动化隐式工具中毒框架的能力。"}}
{"id": "2601.07393", "pdf": "https://arxiv.org/pdf/2601.07393", "abs": "https://arxiv.org/abs/2601.07393", "authors": ["Chengzhi Ji", "Xingfeng Li", "Zhaodong Lv", "Hao Sun", "Pan Liu", "Hao Frank Yang", "Ziyuan Pu"], "title": "Software-Hardware Co-optimization for Modular E2E AV Paradigm: A Unified Framework of Optimization Approaches, Simulation Environment and Evaluation Metrics", "categories": ["cs.AI"], "comment": "17pages,6 figures,6 tables", "summary": "Modular end-to-end (ME2E) autonomous driving paradigms combine modular interpretability with global optimization capability and have demonstrated strong performance. However, existing studies mainly focus on accuracy improvement, while critical system-level factors such as inference latency and energy consumption are often overlooked, resulting in increasingly complex model designs that hinder practical deployment. Prior efforts on model compression and acceleration typically optimize either the software or hardware side in isolation. Software-only optimization cannot fundamentally remove intermediate tensor access and operator scheduling overheads, whereas hardware-only optimization is constrained by model structure and precision. As a result, the real-world benefits of such optimizations are often limited. To address these challenges, this paper proposes a reusable software and hardware co-optimization and closed-loop evaluation framework for ME2E autonomous driving inference. The framework jointly integrates software-level model optimization with hardware-level computation optimization under a unified system-level objective. In addition, a multidimensional evaluation metric is introduced to assess system performance by jointly considering safety, comfort, efficiency, latency, and energy, enabling quantitative comparison of different optimization strategies. Experiments across multiple ME2E autonomous driving stacks show that the proposed framework preserves baseline-level driving performance while significantly reducing inference latency and energy consumption, achieving substantial overall system-level improvements. These results demonstrate that the proposed framework provides practical and actionable guidance for efficient deployment of ME2E autonomous driving systems.", "AI": {"tldr": "提出了一种软件硬件协同优化和闭环评估框架，旨在提高模块化端到端自动驾驶系统的性能。", "motivation": "当前研究主要关注精度改进，而系统级因素如推断延迟和能耗则被忽视。单独的软硬件优化限制了实际部署的效果。", "method": "该论文提出了一种可重复使用的软件硬件协同优化框架，并引入多维评估指标来衡量系统性能。", "result": "实验表明所提出的框架在保持基线驾驶性能的同时，显著减少了推断延迟和能耗。", "conclusion": "该框架为模块化端到端自动驾驶系统的高效部署提供了实用且可行的指导。"}}
{"id": "2601.07392", "pdf": "https://arxiv.org/pdf/2601.07392", "abs": "https://arxiv.org/abs/2601.07392", "authors": ["Alexandre Tuel", "Thomas Kerdreux", "Quentin Febvre", "Alexis Mouche", "Antoine Grouazel", "Jean-Renaud Miadana", "Antoine Audras", "Chen Wang", "Bertrand Chapron"], "title": "OceanSAR-2: A Universal Feature Extractor for SAR Ocean Observation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "accepted at EUSAR 2026", "summary": "We present OceanSAR-2, the second generation of our foundation model for SAR-based ocean observation. Building on our earlier release, which pioneered self-supervised learning on Sentinel-1 Wave Mode data, OceanSAR-2 relies on improved SSL training and dynamic data curation strategies, which enhances performance while reducing training cost. OceanSAR-2 demonstrates strong transfer performance across downstream tasks, including geophysical pattern classification, ocean surface wind vector and significant wave height estimation, and iceberg detection. We release standardized benchmark datasets, providing a foundation for systematic evaluation and advancement of SAR models for ocean applications.", "AI": {"tldr": "OceanSAR-2 是一种用于 SAR 海洋观测的通用特征提取器。", "motivation": "为了提高海洋遥感模型的性能并降低成本，同时推动相关技术的发展和应用评估。", "method": "通过改进自监督学习训练策略和动态数据管理方法来增强 OceanSAR-2 的表现。", "result": "OceanSAR-2 在多个下游任务中表现出色，包括地物理模式分类、海面风向与波高估计以及冰山检测等。", "conclusion": "OceanSAR-2 成功提升了性能并降低了训练成本，并为海洋 SAR 模型的应用提供了基准数据集。"}}
{"id": "2601.07389", "pdf": "https://arxiv.org/pdf/2601.07389", "abs": "https://arxiv.org/abs/2601.07389", "authors": ["Xueyan Niu", "Bo Bai", "Wei Han", "Weixi Zhang"], "title": "On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training", "categories": ["cs.LG", "cs.AI", "cs.IT"], "comment": null, "summary": "Post-training of large language models routinely interleaves supervised fine-tuning (SFT) with reinforcement learning (RL). These two methods have different objectives: SFT minimizes the cross-entropy loss between model outputs and expert responses, while RL maximizes reward signals derived from human preferences or rule-based verifiers. Modern reasoning models have widely adopted the practice of alternating SFT and RL training. However, there is no theoretical account of whether they can be decoupled. We prove that decoupling is impossible in either order: (1) SFT-then-RL coupling: RL increases SFT loss under SFT optimality and (2) RL-then-SFT coupling: SFT lowers the reward achieved by RL. Experiments on Qwen3-0.6B confirm the predicted degradation, verifying that SFT and RL cannot be separated without loss of prior performance in the post-training", "AI": {"tldr": "研究探讨了在大型语言模型的后期训练中，监督微调与强化学习是否可以被解耦。", "motivation": "现代推理模型广泛采用交替进行监督微调和强化学习的做法，但缺乏理论依据证明这两种方法能否独立操作。", "method": "通过理论分析与实验验证了在大型语言模型的后期训练中，无论先进行监督微调还是先进行强化学习，都会导致性能下降。", "result": "实验证明，在Qwen3-0.6B上交替使用监督微调和强化学习会导致先前性能降低，进一步证实两者不能分离。", "conclusion": "该研究表明在后期训练过程中，监督微调与强化学习无法被解耦，否则会损害模型的前期表现。"}}
{"id": "2601.07381", "pdf": "https://arxiv.org/pdf/2601.07381", "abs": "https://arxiv.org/abs/2601.07381", "authors": ["Yui Kondo", "Kevin Dunnell", "Isobel Voysey", "Qing Hu", "Victoria Paesano", "Phi H Nguyen", "Qing Xiao", "Jun Zhao", "Luc Rocher"], "title": "Interactive visualizations for adolescents to understand and challenge algorithmic profiling in online platforms", "categories": ["cs.HC"], "comment": null, "summary": "Social media platforms regularly track, aggregate, and monetize adolescents' data, yet provide them with little visibility or agency over how algorithms construct their digital identities and make inferences about them. We introduce Algorithmic Mirror, an interactive visualization tool that transforms opaque profiling practices into explorable landscapes of personal data. It uniquely leverages adolescents' real digital footprints across YouTube, TikTok, and Netflix, to provide situated, personalized insights into datafication over time. In our study with 27 participants (ages 12--16), we show how engaging with their own data enabled adolescents to uncover the scale and persistence of data collection, recognize cross-platform profiling, and critically reflect algorithmic categorizations of their interests. These findings highlight how identity is a powerful motivator for adolescents' desire for greater digital agency, underscoring the need for platforms and policymakers to move toward structural reforms that guarantee children better transparency and the agency to influence their online experiences.", "AI": {"tldr": "研究开发了一个名为Algorithmic Mirror的互动可视化工具，帮助青少年理解他们在在线平台上被算法如何定位。", "motivation": "社交媒体平台经常跟踪和商业化青少年的数据，但并未向他们提供足够的可见性或控制权来了解自己的数字身份是如何构建以及算法对他们做出何种推断。", "method": "研究使用Algorithmic Mirror工具与27名参与者（12-16岁）进行互动可视化实验，展示数据收集的规模和持久性、跨平台定位及对算法分类的兴趣批判性反思。", "result": "青少年能够发现数据收集的规模和持续时间，并识别跨平台的个人画像以及对他们兴趣的算法分类。", "conclusion": "研究强调了身份是青少年寻求更多数字控制权的强大动机，表明需要通过结构性改革来确保儿童在在线平台上获得更好的透明度和对自身经历的影响能力。"}}
{"id": "2601.07377", "pdf": "https://arxiv.org/pdf/2601.07377", "abs": "https://arxiv.org/abs/2601.07377", "authors": ["Jiao Xu", "Xin Chen", "Lihe Zhang"], "title": "Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2025", "summary": "In this paper, we present a new dynamic collaborative network for semi-supervised 3D vessel segmentation, termed DiCo. Conventional mean teacher (MT) methods typically employ a static approach, where the roles of the teacher and student models are fixed. However, due to the complexity of 3D vessel data, the teacher model may not always outperform the student model, leading to cognitive biases that can limit performance. To address this issue, we propose a dynamic collaborative network that allows the two models to dynamically switch their teacher-student roles. Additionally, we introduce a multi-view integration module to capture various perspectives of the inputs, mirroring the way doctors conduct medical analysis. We also incorporate adversarial supervision to constrain the shape of the segmented vessels in unlabeled data. In this process, the 3D volume is projected into 2D views to mitigate the impact of label inconsistencies. Experiments demonstrate that our DiCo method sets new state-of-the-art performance on three 3D vessel segmentation benchmarks. The code repository address is https://github.com/xujiaommcome/DiCo", "AI": {"tldr": "该论文提出了一种新的动态协作网络DiCo，用于半监督的3D血管分割。", "motivation": "传统的均值教师方法采用静态模式，可能导致认知偏差和性能限制。为了解决这个问题，并提高复杂数据集上的表现，作者设计了这种可以动态调整角色的双模型架构。", "method": "提出了动态协作网络DiCo，包含一个能切换教师-学生角色机制、多视图融合模块以及对抗性监督方法以改善无标签样本的分割性能。通过2D投影来减少标注不一致的影响。", "result": "实验结果显示，该方法在三个3D血管分割基准数据集上均达到了新的最高水平。", "conclusion": "DiCo作为一种创新性的半监督学习方法，能够显著提高3D血管分割任务的准确性，在多个数据集中表现优越。"}}
{"id": "2601.07376", "pdf": "https://arxiv.org/pdf/2601.07376", "abs": "https://arxiv.org/abs/2601.07376", "authors": ["Siqi Zhu", "Jiaxuan You"], "title": "OpenTinker: Separating Concerns in Agentic Reinforcement Learning", "categories": ["cs.AI", "cs.DC"], "comment": null, "summary": "We introduce OpenTinker, an infrastructure for reinforcement learning (RL) of large language model (LLM) agents built around a separation of concerns across algorithm design, execution, and agent-environment interaction. Rather than relying on monolithic, end-to-end RL pipelines, OpenTinker decomposes agentic learning systems into lightweight, composable components with clearly defined abstraction boundaries. Users specify agents, environments, and interaction protocols, while inference and training are delegated to a managed execution runtime. OpenTinker introduces a centralized scheduler for managing training and inference workloads, including LoRA-based and full-parameter RL, supervised fine-tuning, and inference, over shared resources. We further discuss design principles for extending OpenTinker to multi-agent training. Finally, we present a set of RL use cases that demonstrate the effectiveness of the framework in practical agentic learning scenarios.", "AI": {"tldr": "介绍OpenTinker，一种用于大型语言模型代理的强化学习基础设施，通过将算法设计、执行和代理-环境交互分离为轻量级可组合组件来促进更灵活的学习系统。", "motivation": "解决现有RL管道依赖单一且封闭的问题，推动开发更加灵活高效的大规模LLM代理训练框架，满足实际应用场景需求。", "method": "通过创建一个可以明确抽象边界、支持多种交互协议的基础设施OpenTinker，并引入中心调度器来管理资源和任务。", "result": "展示了一套强化学习的实际应用案例，证明了该框架的有效性及其在各种代理训练场景中的适用性。", "conclusion": "OpenTinker为大规模LLM代理提供了一个灵活高效的RL环境，能够适应多样化的应用场景和需求。"}}
{"id": "2601.07372", "pdf": "https://arxiv.org/pdf/2601.07372", "abs": "https://arxiv.org/abs/2601.07372", "authors": ["Xin Cheng", "Wangding Zeng", "Damai Dai", "Qinyu Chen", "Bingxuan Wang", "Zhenda Xie", "Kezhao Huang", "Xingkai Yu", "Zhewen Hao", "Yukun Li", "Han Zhang", "Huishuai Zhang", "Dongyan Zhao", "Wenfeng Liang"], "title": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "While Mixture-of-Experts (MoE) scales capacity via conditional computation, Transformers lack a native primitive for knowledge lookup, forcing them to inefficiently simulate retrieval through computation. To address this, we introduce conditional memory as a complementary sparsity axis, instantiated via Engram, a module that modernizes classic $N$-gram embedding for O(1) lookup. By formulating the Sparsity Allocation problem, we uncover a U-shaped scaling law that optimizes the trade-off between neural computation (MoE) and static memory (Engram). Guided by this law, we scale Engram to 27B parameters, achieving superior performance over a strictly iso-parameter and iso-FLOPs MoE baseline. Most notably, while the memory module is expected to aid knowledge retrieval (e.g., MMLU +3.4; CMMLU +4.0), we observe even larger gains in general reasoning (e.g., BBH +5.0; ARC-Challenge +3.7) and code/math domains~(HumanEval +3.0; MATH +2.4). Mechanistic analyses reveal that Engram relieves the backbone's early layers from static reconstruction, effectively deepening the network for complex reasoning. Furthermore, by delegating local dependencies to lookups, it frees up attention capacity for global context, substantially boosting long-context retrieval (e.g., Multi-Query NIAH: 84.2 to 97.0). Finally, Engram establishes infrastructure-aware efficiency: its deterministic addressing enables runtime prefetching from host memory, incurring negligible overhead. We envision conditional memory as an indispensable modeling primitive for next-generation sparse models.", "AI": {"tldr": "本文提出了条件内存模块Engram，通过O(1)查找优化知识检索，并提升语言模型的推理能力。", "motivation": "目前Transformer缺乏原生的知识查找机制，只能通过计算模拟。为了解决这一问题，引入了条件内存作为新的稀疏维度。", "method": "本文设计了一个名为Engram的新模块，它使用现代方法改进经典N-gram嵌入以实现O(1)查找，并将知识检索和计算分配相结合来优化模型性能。", "result": "实验结果表明，通过引入Engram模块，模型在知识检索（如MMLU +3.4；CMMLU +4.0）、推理能力（如BBH +5.0；ARC-Challenge +3.7）和代码/数学领域取得了显著改进。", "conclusion": "条件内存作为稀疏模型中的基本建模原语，能够有效优化知识检索与计算分配，并提升整体性能。"}}
{"id": "2601.07370", "pdf": "https://arxiv.org/pdf/2601.07370", "abs": "https://arxiv.org/abs/2601.07370", "authors": ["Theo Lequy", "Andreas M. Menzel"], "title": "Optimizing the Design of a Simple Three-Sphere Magnetic Microswimmer", "categories": ["cond-mat.soft", "cs.RO", "physics.app-ph", "physics.flu-dyn", "physics.med-ph"], "comment": "10 pages, 7 figures", "summary": "When swimming at low Reynolds numbers, inertial effects are negligible and reciprocal movements cannot induce net motion. Instead, symmetry breaking is necessary to achieve net propulsion. Directed swimming can be supported by magnetic fields, which simultaneously provide a versatile means of remote actuation. Thus, we analyze the motion of a straight microswimmer composed of three magnetizable beads connected by two elastic links. The swimming mechanism is based on oriented external magnetic fields that oscillate in magnitude. Through induced reversible hysteretic collapse of the two segments of the swimmer, the two pairs of beads jump into contact and separate nonreciprocally. Due to higher-order hydrodynamic interactions, net displacement results after each cycle. Different microswimmers can be tuned to different driving amplitudes and frequencies, allowing for simultaneous independent control by just one external magnetic field. The swimmer geometry and magnetic field shape are optimized for maximum swimming speed using an evolutionary optimization strategy. Thanks to the simple working principle, an experimental realization of such a microrobot seems feasible and may open new approaches for microinvasive medical interventions such as targeted drug delivery.", "AI": {"tldr": "优化设计了一个由三个磁珠组成的微游泳器，以实现最大泳速。", "motivation": "在低雷诺数环境下，惯性效应可忽略不计，需要打破对称性才能实现净推进。通过外磁场驱动，可以支持定向游泳，并为远程控制提供灵活手段。", "method": "使用外部周期变化的磁场所致的分段可逆滞后塌缩来设计和优化由三个磁珠组成的微泳器。采用进化优化策略调整微泳器结构与磁场形态以达到最大化游泳速度的目的。", "result": "通过上述方法，不同类型的微泳器可以被调谐到不同的驱动幅度和频率，并能实现独立控制；实验上实现了这种微型机器人的可行性和潜在用于微创医疗干预如靶向药物递送的新途径。", "conclusion": "该研究展示了设计和优化基于磁场的简单三珠微游泳器以最大化其游泳速度的有效性，为未来在医学领域的应用奠定了基础。"}}
{"id": "2601.07367", "pdf": "https://arxiv.org/pdf/2601.07367", "abs": "https://arxiv.org/abs/2601.07367", "authors": ["Aditya Choudhary", "Anupam Purwar"], "title": "FOCAL: A Novel Benchmarking Technique for Multi-modal Agents", "categories": ["cs.SD"], "comment": "We present a framework for evaluation of Multi-modal Agents consisting of Voice-to-voice model components viz. Text to Speech (TTS), Retrieval Augmented Generation (RAG) and Speech-to-text (STT)", "summary": "With the recent advancements in reasoning capa- bilities, tool calling using MCP servers and Audio Language Models (ALMs), development and integration of multi-modal agents (with voice and text support) has come to the industry forefront. Cascading pipelines for voice agents still play a central role in the industry owing to their superior reasoning capabilities facilitated by LLMs. Although, cascading pipelines often present error propagation through the pipeline. We propose a framework, FOCAL to benchmark end-to-end reasoning, component-wise error propagation and error analysis for automated as well as human-assisted testing of multi-modal agents (voice to voice + text input). We also share two novel metrics viz. Reasoning and Semantic scores to evaluate efficacy of the agent in having meaningful conversations in voice mode.", "AI": {"tldr": "FOCAL是一种用于评估多模态代理（包括语音和文本输入）的新型基准测试技术。", "motivation": "随着大语言模型在推理能力和工具调用能力上的进步，开发和支持多模态代理的需求日益增长。然而，现有的级联管道模式存在错误传播的问题。因此，提出了FOCAL框架来解决这些问题，并提高多模态代理的有效性评估。", "method": "提出了一种新的基准测试技术FOCAL，用于对多模态代理的端到端推理、组件级别的错误传播以及自动和人工辅助测试中的错误分析进行评价。", "result": "研究中提出了两个新颖的指标：推理分数（Reasoning score）和语义分数（Semantic score），以评估语音模式下多模态代理对话的有效性。", "conclusion": "FOCAL框架为提高多模态代理在级联管道中的性能提供了一种新的基准测试方法，并通过引入新的评价指标，有助于更好地理解与改进多模态代理的推理和语义能力。"}}
{"id": "2601.07366", "pdf": "https://arxiv.org/pdf/2601.07366", "abs": "https://arxiv.org/abs/2601.07366", "authors": ["Haoxuan Li", "Mengyan Li", "Junjun Zheng"], "title": "HiVid-Narrator: Hierarchical Video Narrative Generation with Scene-Primed ASR-anchored Compression", "categories": ["cs.CV"], "comment": null, "summary": "Generating structured narrations for real-world e-commerce videos requires models to perceive fine-grained visual details and organize them into coherent, high-level stories--capabilities that existing approaches struggle to unify. We introduce the E-commerce Hierarchical Video Captioning (E-HVC) dataset with dual-granularity, temporally grounded annotations: a Temporal Chain-of-Thought that anchors event-level observations and Chapter Summary that compose them into concise, story-centric summaries. Rather than directly prompting chapters, we adopt a staged construction that first gathers reliable linguistic and visual evidence via curated ASR and frame-level descriptions, then refines coarse annotations into precise chapter boundaries and titles conditioned on the Temporal Chain-of-Thought, yielding fact-grounded, time-aligned narratives. We also observe that e-commerce videos are fast-paced and information-dense, with visual tokens dominating the input sequence. To enable efficient training while reducing input tokens, we propose the Scene-Primed ASR-anchored Compressor (SPA-Compressor), which compresses multimodal tokens into hierarchical scene and event representations guided by ASR semantic cues. Built upon these designs, our HiVid-Narrator framework achieves superior narrative quality with fewer input tokens compared to existing methods.", "AI": {"tldr": "该论文提出了一个框架用于生成结构化的电子商务视频叙述，通过层次化视频描述和压缩技术提高叙述质量。", "motivation": "现有模型难以同时感知精细的视觉细节并将其组织成连贯的故事。此研究旨在解决这一问题，并提出适用于快速节奏、信息密集型电商视频的新方法。", "method": "作者设计了电子商务层次化视频标注数据集，包含时间链式思考和章节摘要；采用分阶段构建策略，首先收集可靠语言和视觉证据，再通过语义锚点压缩多模态令牌。", "result": "HiVid-Narrator框架实现了比现有方法更好的叙述质量，并减少了输入令牌的数量。", "conclusion": "该研究成功解决了电商视频快速节奏和信息密集性的挑战，提出了一个新的层次化视频描述与压缩技术的框架。"}}
{"id": "2601.07364", "pdf": "https://arxiv.org/pdf/2601.07364", "abs": "https://arxiv.org/abs/2601.07364", "authors": ["Joseph Chen"], "title": "On the universal definition of intelligence", "categories": ["cs.AI"], "comment": null, "summary": "This paper aims to propose a universal definition of intelligence that enables fair and consistent comparison of human and artificial intelligence (AI). With the rapid development of AI technology in recent years, how to compare and evaluate human and AI intelligence has become an important theoretical issue. However, existing definitions of intelligence are anthropocentric and unsuitable for empirical comparison, resulting in a lack of consensus in the research field. This paper first introduces four criteria for evaluating intelligence definitions based on R. Carnap's methodology of conceptual clarification: similarity to explicandum, exactness, fruitfulness, and simplicity. We then examine six representative definitions: IQ testing, complex problem-solving ability, reward optimization, environmental adaptation, learning efficiency, and predictive ability, and clarify their theoretical strengths and limitations. The results show that while definitions based on predictive ability have high explanatory power and empirical feasibility, they suffer from an inability to adequately explain the relationship between predictions and behavior/benefits. This paper proposes the Extended Predictive Hypothesis (EPH), which views intelligence as a combination of the ability to accurately predict the future and the ability to benefit from those predictions. Furthermore, by distinguishing predictive ability into spontaneous and reactive predictions and adding the concept of gainability, we present a unified framework for explaining various aspects of intelligence, such as creativity, learning, and future planning. In conclusion, this paper argues that the EPH is the most satisfactory and universal definition for comparing human and AI intelligence.", "AI": {"tldr": "提出一种能够公平、一致地比较人类和人工智能智能的普遍定义", "motivation": "随着人工智能技术的发展，如何对比评价人类与AI的智力成为一个重要的理论问题。现有的智能定义倾向于人本主义且不适用于经验上的比较，导致缺乏共识", "method": "基于R. Carnap的概念澄清方法论提出四个评估智能定义的标准，并考察了六个代表性的智能定义及其优缺点，在此基础上提出了扩展预测假设（EPH）作为普遍的智力定义框架", "result": "结果显示，基于预测能力的定义具有高解释力和经验可行性，但无法充分解释预测与行为或利益之间的关系。EPH将智能定义为准确预测未来并从中获益的能力的组合", "conclusion": "论文认为EPH是对比人类和人工智能智能最令人满意的普遍定义"}}
{"id": "2601.07362", "pdf": "https://arxiv.org/pdf/2601.07362", "abs": "https://arxiv.org/abs/2601.07362", "authors": ["Julia Richter", "Turcan Tuna", "Manthan Patel", "Takahiro Miki", "Devon Higgins", "James Fox", "Cesar Cadena", "Andres Diaz", "Marco Hutter"], "title": "Large-Scale Autonomous Gas Monitoring for Volcanic Environments: A Legged Robot on Mount Etna", "categories": ["cs.RO"], "comment": "12 pages, 7 figures, submitted to IEEE Robotics & Automation Magazine (RAM)", "summary": "Volcanic gas emissions are key precursors of eruptive activity. Yet, obtaining accurate near-surface measurements remains hazardous and logistically challenging, motivating the need for autonomous solutions. Limited mobility in rough volcanic terrain has prevented wheeled systems from performing reliable in situ gas measurements, reducing their usefulness as sensing platforms. We present a legged robotic system for autonomous volcanic gas analysis, utilizing the quadruped ANYmal, equipped with a quadrupole mass spectrometer system. Our modular autonomy stack integrates a mission planning interface, global planner, localization framework, and terrain-aware local navigation. We evaluated the system on Mount Etna across three autonomous missions in varied terrain, achieving successful gas-source detections with autonomy rates of 93-100%. In addition, we conducted a teleoperated mission in which the robot measured natural fumaroles, detecting sulfur dioxide and carbon dioxide. We discuss lessons learned from the gas-analysis and autonomy perspectives, emphasizing the need for adaptive sensing strategies, tighter integration of global and local planning, and improved hardware design.", "AI": {"tldr": "本文介绍了一种用于火山环境中自主气体监测的四足机器人系统。", "motivation": "获取准确的地表气体测量值在火山学中具有重要性，但由于危险和物流挑战，需要自动化的解决方案。轮式系统的移动受限于粗糙地形，导致无法可靠地进行现场气体测量。", "method": "使用ANYmal四足机器人的模块化自主堆栈执行任务，该机器人配备了四极质谱仪系统，包括任务规划界面、全局路径规划器、定位框架和地形感知的本地导航。", "result": "在埃特纳火山上的三次自主任务中，在不同地形条件下实现了93-100%的成功气体源检测率，并通过遥控操作测量了天然喷气口中的二氧化硫和二氧化碳。", "conclusion": "讨论从气体分析和自主性的角度总结经验教训，强调需要适应性更强的传感策略、全局与局部规划更紧密集成以及改进硬件设计。"}}
{"id": "2601.07359", "pdf": "https://arxiv.org/pdf/2601.07359", "abs": "https://arxiv.org/abs/2601.07359", "authors": ["Shezheng Song", "Shasha Li", "Jie Yu"], "title": "Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs without Training", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated strong capabilities across a variety of vision-language tasks. However, their internal reasoning often exhibits a critical inconsistency: although deeper layers may attend to the correct visual regions, final predictions are frequently misled by noisy attention from earlier layers. This results in a disconnect between what the model internally understands and what it ultimately expresses, a phenomenon we describe as seeing it right but saying it wrong. To address this issue, we propose DualPD, a dual-perspective decoding refinement strategy that enhances the visual understanding without any additional training. DualPD consists of two components. (1) The layer-wise attention-guided contrastive logits module captures how the belief in the correct answer evolves by comparing output logits between layers that exhibit the largest attention shift. (2) The head-wise information filtering module suppresses low-contribution attention heads that focus on irrelevant regions, thereby improving attention quality within each layer. Experiments conducted on both the LLaVA and Qwen-VL model families across multiple multimodal benchmarks demonstrate that DualPD consistently improves accuracy without training, confirming its effectiveness and generalizability. The code will be released upon publication.", "AI": {"tldr": "提出了一种无需训练的改进策略DualPD，用于解决多模态大语言模型内部推理不一致的问题。", "motivation": "在多模态大型语言模型中，深层关注正确的视觉区域但最终预测可能被早期层的噪声注意力误导，导致理解与表达之间的脱节。", "method": "提出双视角解码改进策略DualPD：包括层间对比对数模块和头间信息过滤模块。前者通过比较不同层次间的输出对数来捕捉正确答案的信心演变；后者抑制关注无关区域的信息头以提高注意力质量。", "result": "在LLaVA和Qwen-VL模型家族上进行的实验表明，DualPD可以提升准确率且无需额外训练，验证了其有效性和通用性。", "conclusion": "通过改进多模态大型语言模型的内部推理一致性，使得模型能够在不牺牲理解的情况下改善最终输出。"}}
{"id": "2601.07356", "pdf": "https://arxiv.org/pdf/2601.07356", "abs": "https://arxiv.org/abs/2601.07356", "authors": ["Tatiana Gelvez-Barrera", "Barbara Nicolas", "Bruno Gilles", "Adrian Basarab", "Denis Kouamé"], "title": "Efficient Convolutional Forward Model for Passive Acoustic Mapping and Temporal Monitoring", "categories": ["eess.IV", "cs.AI"], "comment": null, "summary": "Passive acoustic mapping (PAM) is a key imaging technique for characterizing cavitation activity in therapeutic ultrasound applications. Recent model-based beamforming algorithms offer high reconstruction quality and strong physical interpretability. However, their computational burden and limited temporal resolution restrict their use in applications with time-evolving cavitation. To address these challenges, we introduce a PAM beamforming framework based on a novel convolutional formulation in the time domain, which enables efficient computation. In this framework, PAM is formulated as an inverse problem in which the forward operator maps spatiotemporal cavitation activity to recorded radio-frequency signals accounting for time-of-flight delays defined by the acquisition geometry. We then formulate a regularized inversion algorithm that incorporates prior knowledge on cavitation activity. Experimental results demonstrate that our framework outperforms classical beamforming methods, providing higher temporal resolution than frequency-domain techniques while substantially reducing computational burden compared with iterative time-domain formulations.", "AI": {"tldr": "该论文提出了一种基于时间域卷积的新颖被动声学映射（PAM）成像框架，以提高时间分辨率并减少计算负担。", "motivation": "传统模型基线束形成算法虽有高质量重建和强物理可解释性，但其计算负担大且时间解析度低，难以应用于时变空化场景。为此提出一种新型方法来解决这些问题。", "method": "通过引入基于时间域卷积的新框架，将PAM视为逆问题求解，并采用正则化反演算法结合对空化的先验知识进行处理。", "result": "实验结果显示该方法比传统束形成技术提供更高的时间分辨率，并且计算负担显著减少。", "conclusion": "该研究展示了一种新的被动声学映射框架，提高了时变场景下的时间和空间解析度。"}}
{"id": "2601.07351", "pdf": "https://arxiv.org/pdf/2601.07351", "abs": "https://arxiv.org/abs/2601.07351", "authors": ["Linhao Zhong", "Linyu Wu", "Bozhen Fang", "Tianjian Feng", "Chenchen Jing", "Wen Wang", "Jiaheng Zhang", "Hao Chen", "Chunhua Shen"], "title": "Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Project webpage: https://aim-uofa.github.io/EvoTokenDLM", "summary": "Diffusion Language Models (DLMs) offer a promising alternative for language modeling by enabling parallel decoding through iterative refinement. However, most DLMs rely on hard binary masking and discrete token assignments, which hinder the revision of early decisions and underutilize intermediate probabilistic representations. In this paper, we propose EvoToken-DLM, a novel diffusion-based language modeling approach that replaces hard binary masks with evolving soft token distributions. EvoToken-DLM enables a progressive transition from masked states to discrete outputs, supporting revisable decoding. To effectively support this evolution, we introduce continuous trajectory supervision, which aligns training objectives with iterative probabilistic updates. Extensive experiments across multiple benchmarks show that EvoToken-DLM consistently achieves superior performance, outperforming strong diffusion-based and masked DLM baselines. Project webpage: https://aim-uofa.github.io/EvoTokenDLM.", "AI": {"tldr": "提出了一种新的语言建模方法EvoToken-DLM，通过引入进化软标记分布替代传统的硬二元掩码和离散令牌分配。", "motivation": "现有的DLM模型依赖于硬二进制掩码和离散令牌分配，这限制了早期决策的修订，并未充分利用中间概率表示。为了解决这些问题，作者提出了EvoToken-DLM。", "method": "EvoToken-DLM通过引入进化软标记分布来替代传统的硬二元掩码和离散令牌分配，使模型能够从屏蔽状态逐步过渡到离散输出，支持可修订的解码过程。", "result": "实验结果表明，EvoToken-DLM在多个基准上的性能优于其他基于扩散的方法和带掩码的DLM基线。", "conclusion": "通过引入进化软标记分布和支持连续轨迹监督，EvoToken-DLM能够更好地进行迭代概率更新，并且表现出色。"}}
{"id": "2601.07348", "pdf": "https://arxiv.org/pdf/2601.07348", "abs": "https://arxiv.org/abs/2601.07348", "authors": ["Tu Hu", "Ronghao Chen", "Shuo Zhang", "Jianghao Yin", "Mou Xiao Feng", "Jingping Liu", "Shaolei Zhang", "Wenqi Jiang", "Yuqi Fang", "Sen Hu", "Yi Xu", "Huacan Wang"], "title": "Controlled Self-Evolution for Algorithmic Code Optimization", "categories": ["cs.CL", "cs.AI", "cs.NE"], "comment": "27 pages", "summary": "Self-evolution methods enhance code generation through iterative \"generate-verify-refine\" cycles, yet existing approaches suffer from low exploration efficiency, failing to discover solutions with superior complexity within limited budgets. This inefficiency stems from initialization bias trapping evolution in poor solution regions, uncontrolled stochastic operations lacking feedback guidance, and insufficient experience utilization across tasks.To address these bottlenecks, we propose Controlled Self-Evolution (CSE), which consists of three key components. Diversified Planning Initialization generates structurally distinct algorithmic strategies for broad solution space coverage. Genetic Evolution replaces stochastic operations with feedback-guided mechanisms, enabling targeted mutation and compositional crossover. Hierarchical Evolution Memory captures both successful and failed experiences at inter-task and intra-task levels.Experiments on EffiBench-X demonstrate that CSE consistently outperforms all baselines across various LLM backbones. Furthermore, CSE achieves higher efficiency from early generations and maintains continuous improvement throughout evolution. Our code is publicly available at https://github.com/QuantaAlpha/EvoControl.", "AI": {"tldr": "本文提出了一种受控自演化方法，旨在优化算法代码生成过程。", "motivation": "当前的自演化方法在探索效率上存在不足，无法有效发现复杂度更低的解决方案。这主要是由于初始化偏置、随机操作缺乏反馈指导以及经验利用不足等原因造成的。", "method": "本文提出了受控自演化（CSE）框架，包含多样化计划初始化、遗传进化和层次化演进记忆三个关键组件，以解决现有方法中的瓶颈问题。", "result": "在EffiBench-X上的实验表明，CSE在各种大型语言模型骨干上始终优于所有基线，在早期生成阶段就表现出更高的效率，并在整个演化过程中持续改进。", "conclusion": "CSE框架通过引入反馈指导机制和经验利用策略，有效提升了代码优化过程中的探索效率。"}}
{"id": "2601.07344", "pdf": "https://arxiv.org/pdf/2601.07344", "abs": "https://arxiv.org/abs/2601.07344", "authors": ["Jiao Xu", "Junwei Liu", "Jiangwei Lao", "Qi Zhu", "Yunpeng Zhao", "Congyun Jin", "Shinan Liu", "Zhihong Lu", "Lihe Zhang", "Xin Chen", "Jian Wang", "Ping Wang"], "title": "PulseMind: A Multi-Modal Medical Model for Real-World Clinical Diagnosis", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to AAAI 2026", "summary": "Recent advances in medical multi-modal models focus on specialized image analysis like dermatology, pathology, or radiology. However, they do not fully capture the complexity of real-world clinical diagnostics, which involve heterogeneous inputs and require ongoing contextual understanding during patient-physician interactions. To bridge this gap, we introduce PulseMind, a new family of multi-modal diagnostic models that integrates a systematically curated dataset, a comprehensive evaluation benchmark, and a tailored training framework. Specifically, we first construct a diagnostic dataset, MediScope, which comprises 98,000 real-world multi-turn consultations and 601,500 medical images, spanning over 10 major clinical departments and more than 200 sub-specialties. Then, to better reflect the requirements of real-world clinical diagnosis, we develop the PulseMind Benchmark, a multi-turn diagnostic consultation benchmark with a four-dimensional evaluation protocol comprising proactiveness, accuracy, usefulness, and language quality. Finally, we design a training framework tailored for multi-modal clinical diagnostics, centered around a core component named Comparison-based Reinforcement Policy Optimization (CRPO). Compared to absolute score rewards, CRPO uses relative preference signals from multi-dimensional com-parisons to provide stable and human-aligned training guidance. Extensive experiments demonstrate that PulseMind achieves competitive performance on both the diagnostic consultation benchmark and public medical benchmarks.", "AI": {"tldr": "PulseMind是一个多模态医学模型，用于现实世界中的临床诊断。", "motivation": "现有的医学多模式模型专注于特定的图像分析，如皮肤病学、病理学或放射学。然而，它们未能完全捕捉到现实世界中临床诊断的复杂性，这些诊断涉及到异质输入，并且需要在医患互动过程中保持持续的情境理解。为了解决这个问题，作者引入了PulseMind。", "method": "构建了一个名为MediScope的数据集，包括98,000次真实世界的多轮咨询和601,500张医学图像；开发了一种用于现实世界临床诊断的基准测试PulseMind Benchmark；设计了一个针对多模式临床诊断量身定制的训练框架，其中心组件是基于比较的强化策略优化（CRPO）。", "result": "实验表明，PulseMind在诊断咨询基准和公开医学基准上均表现出竞争性性能。", "conclusion": "通过综合数据集、基准测试和定制培训框架，PulseMind能够提供稳定且与人类一致的训练指导，并具有竞争力的表现。"}}
{"id": "2601.07342", "pdf": "https://arxiv.org/pdf/2601.07342", "abs": "https://arxiv.org/abs/2601.07342", "authors": ["Nicolas Tacheny"], "title": "Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure", "categories": ["cs.AI"], "comment": null, "summary": "Large-scale telecom and datacenter infrastructures rely on multi-layered service and resource models, where failures propagate across physical and logical components and affect multiple customers. Traditional approaches to root cause analysis(RCA) rely on hard-coded graph traversal algorithms or rule-based correlation engines, which are costly to maintain and tightly coupled to the infrastructure model. In this work, we introduce an agentic diagnostic framework where a Large Language Model (LLM) performs step-wise investigation using a constrained tool space exposed through the Model Context Protocol (MCP). Instead of embedding causal logic or traversal algorithms into the application, the agent autonomously navigates the infrastructure model by invoking tools for service lookup, dependency retrieval, structured and unstructured data, and event analysis, and impact discovery. We define an investigation protocol that structures the agent's reasoning and ensures grounding, reproducibility, and safe handling of missing or ambiguous information. This work lays the foundation for autonomous incident resolution and change impact mitigation. Future systems will not only diagnose and remediate infrastructure failures, but also predict the impact of planned changes on services and customers, enabling operators to mitigate risks before executing maintenance operations.", "AI": {"tldr": "本文介绍了一种基于代理的诊断框架，利用大型语言模型（LLM）和模型上下文协议（MCP），通过逐步调查和服务查找、依赖关系检索等工具来识别大规模电信和数据中心基础设施中的故障原因。", "motivation": "传统的根因分析(RCA)方法过于复杂且难以维护。因此需要一种能够自动处理多层服务和资源模型中传播的故障的新方法，以降低维护成本并提高系统可扩展性。", "method": "提出了一个代理诊断框架，在这个框架中大型语言模型（LLM）通过模型上下文协议（MCP）提供的受限工具空间进行逐步调查。这些工具包括服务查找、依赖关系检索、结构化和非结构化数据以及事件分析等，从而确保推理的结构性和可再现性。", "result": "该工作为自动故障解决提供了基础，并且未来系统将能够预测计划变更对服务和客户的影响，帮助操作员在执行维护操作之前减轻风险。", "conclusion": "所提出的方法有望降低大规模电信与数据中心基础设施中的故障诊断成本，并提高系统的稳定性和可扩展性。"}}
{"id": "2601.07335", "pdf": "https://arxiv.org/pdf/2601.07335", "abs": "https://arxiv.org/abs/2601.07335", "authors": ["Mohit Jaiswal", "Naman Jain", "Shivani Pathak", "Mainak Singha", "Nikunja Bihari Kar", "Ankit Jha", "Biplab Banerjee"], "title": "Reconstruction Guided Few-shot Network For Remote Sensing Image Classification", "categories": ["cs.CV"], "comment": "Accepted at InGARSS 2025", "summary": "Few-shot remote sensing image classification is challenging due to limited labeled samples and high variability in land-cover types. We propose a reconstruction-guided few-shot network (RGFS-Net) that enhances generalization to unseen classes while preserving consistency for seen categories. Our method incorporates a masked image reconstruction task, where parts of the input are occluded and reconstructed to encourage semantically rich feature learning. This auxiliary task strengthens spatial understanding and improves class discrimination under low-data settings. We evaluated the efficacy of EuroSAT and PatternNet datasets under 1-shot and 5-shot protocols, our approach consistently outperforms existing baselines. The proposed method is simple, effective, and compatible with standard backbones, offering a robust solution for few-shot remote sensing classification. Codes are available at https://github.com/stark0908/RGFS.", "AI": {"tldr": "提出了一种基于重建指导的少量样本网络（RGFS-Net）用于遥感图像分类，该方法在少量标记样本的情况下提高了未见类别的泛化能力。", "motivation": "由于有限的标注样本和高土地覆盖类型的变异性，传统的远程传感图像分类面临挑战。此研究旨在通过引入辅助重建任务来增强特征学习，提高模型在低数据环境下的性能。", "method": "提出了一种新的网络结构RGFS-Net，在该框架中，部分输入被遮挡并进行重建以鼓励语义丰富的特征学习。此方法增强了空间理解和类别区分能力。", "result": "实验表明，在EuroSAT和PatternNet数据集的1-shot和5-shot设置下，所提方法均优于现有基准模型。", "conclusion": "提出的RGFS-Net简单且有效，并兼容标准骨干网络，为少量样本远程传感分类提供了稳健的解决方案。"}}
{"id": "2601.07333", "pdf": "https://arxiv.org/pdf/2601.07333", "abs": "https://arxiv.org/abs/2601.07333", "authors": ["Tessa Pulli", "Jean-Baptiste Weibel", "Peter Hönig", "Matthias Hirschmanner", "Markus Vincze", "Andreas Holzinger"], "title": "OSCAR: Open-Set CAD Retrieval from a Language Prompt and a Single Image", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "6D object pose estimation plays a crucial role in scene understanding for applications such as robotics and augmented reality. To support the needs of ever-changing object sets in such context, modern zero-shot object pose estimators were developed to not require object-specific training but only rely on CAD models. Such models are hard to obtain once deployed, and a continuously changing and growing set of objects makes it harder to reliably identify the instance model of interest. To address this challenge, we introduce an Open-Set CAD Retrieval from a Language Prompt and a Single Image (OSCAR), a novel training-free method that retrieves a matching object model from an unlabeled 3D object database. During onboarding, OSCAR generates multi-view renderings of database models and annotates them with descriptive captions using an image captioning model. At inference, GroundedSAM detects the queried object in the input image, and multi-modal embeddings are computed for both the Region-of-Interest and the database captions. OSCAR employs a two-stage retrieval: text-based filtering using CLIP identifies candidate models, followed by image-based refinement using DINOv2 to select the most visually similar object. In our experiments we demonstrate that OSCAR outperforms all state-of-the-art methods on the cross-domain 3D model retrieval benchmark MI3DOR. Furthermore, we demonstrate OSCAR's direct applicability in automating object model sourcing for 6D object pose estimation. We propose using the most similar object model for pose estimation if the exact instance is not available and show that OSCAR achieves an average precision of 90.48\\% during object retrieval on the YCB-V object dataset. Moreover, we demonstrate that the most similar object model can be utilized for pose estimation using Megapose achieving better results than a reconstruction-based approach.", "AI": {"tldr": "本文提出了一种名为OSCAR的方法，该方法可以从语言提示和单张图像中检索出未标记的3D物体数据库中的匹配对象模型。", "motivation": "为了应对不断变化且增长的对象集，现有零样本姿态估计器难以可靠地识别感兴趣的实例模型，因此开发了不需要特定训练数据的新方法。", "method": "OSCAR通过生成多视角渲染并使用图像描述符进行标注，在上载阶段构建数据库；在推理阶段，GroundedSAM检测输入图像中的目标对象，并利用CLIP和DINOv2进行文本和图像嵌入匹配检索。", "result": "实验表明，OSCAR在MI3DOR基准测试中优于现有方法，且在YCB-V数据集上实现了90.48%的平均精度。同时证明了该方法可应用于姿态估计，并取得比重建法更好的结果。", "conclusion": "本文提出了一种零样本物体检索和姿态估计算法OSCAR，能够从大量未标记的3D模型数据库中快速准确地定位目标对象，并用于6D姿态估计任务。"}}
{"id": "2601.07331", "pdf": "https://arxiv.org/pdf/2601.07331", "abs": "https://arxiv.org/abs/2601.07331", "authors": ["Yuanhe Zhang", "Jiayu Tian", "Yibo Zhang", "Shilinlu Yan", "Liang Lin", "Zhenhong Zhou", "Li Sun", "Sen Su"], "title": "SEE: Signal Embedding Energy for Quantifying Noise Interference in Large Audio Language Models", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Large Audio Language Models (LALMs) have been widely applied in real-time scenarios, such as in-car assistants and online meeting comprehension. In practice, audio inputs are often corrupted by device and environmental noise, leading to performance degradation. However, existing LALM studies on noise lack quantitative analysis and rely mainly on intuition and empirical observation, thus failing to understand practical robustness. To address this issue, we introduce Signal Embedding Energy (SEE), a method for quantifying the impact of noise intensity on LALM inputs, enabling the differentiation of LALM robustness in real-world deployments. SEE introduces a perspective based on structured activation subspaces derived from the model's internal representations, which more accurately captures its perception of noise than raw audio features. Across experiments, SEE exhibits a strong correlation with LALM performance, achieving a correlation of 0.98. Surprisingly, traditional audio denoising methods are only marginally effective for LALMs, and, in some cases, even increase SEE and impair performance. This suggests a mismatch between speech-centric denoising objectives and the noise sensitivity of modern LALMs. Therefore, we propose a mitigation strategy derived from SEE to denoise LALM inputs, outperforming existing denoising methods. This paper introduces a novel metric for noise quantification in LALMs, providing guidance for robustness improvements in real-world deployments.", "AI": {"tldr": "提出了一种量化大型音频语言模型中噪声影响的新方法SEE，以提高其在现实世界中的鲁棒性。", "motivation": "现有的大音频语言模型研究缺乏对噪声干扰的定量分析，导致难以理解模型的实际健壮性。", "method": "引入信号嵌入能量（SEE）作为量化噪声强度的方法，通过结构激活子空间捕捉模型内部表示来更准确地感知噪音影响。", "result": "SEE与LALM性能表现出强相关性，达到了0.98的相关系数。传统音频去噪方法对LALMs效果有限，在某些情况下甚至会增加噪声和损害性能。", "conclusion": "提出了一个新的量化大型音频语言模型中噪声干扰的指标SEE，并提出了一种基于SEE的去噪策略来改善现实世界的部署性能"}}
{"id": "2601.07320", "pdf": "https://arxiv.org/pdf/2601.07320", "abs": "https://arxiv.org/abs/2601.07320", "authors": ["Xue Gong", "Qi Yi", "Ziyuan Nan", "Guanhua Huang", "Kejiao Li", "Yuhao Jiang", "Ruibin Xiong", "Zenan Xu", "Jiaming Guo", "Shaohui Peng", "Bo Zhou"], "title": "Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Training Large Language Models (LLMs) for reasoning tasks is increasingly driven by Reinforcement Learning with Verifiable Rewards (RLVR), where Proximal Policy Optimization (PPO) provides a principled framework for stable policy updates. However, the practical application of PPO is hindered by unreliable advantage estimation in the sparse-reward RLVR regime. This issue arises because the sparse rewards in RLVR lead to inaccurate intermediate value predictions, which in turn introduce significant bias when aggregated at every token by Generalized Advantage Estimation (GAE). To address this, we introduce Segmental Advantage Estimation (SAE), which mitigates the bias that GAE can incur in RLVR. Our key insight is that aggregating $n$-step advantages at every token(as in GAE) is unnecessary and often introduces excessive bias, since individual tokens carry minimal information. Instead, SAE first partitions the generated sequence into coherent sub-segments using low-probability tokens as heuristic boundaries. It then selectively computes variance-reduced advantage estimates only from these information-rich segment transitions, effectively filtering out noise from intermediate tokens. Our experiments demonstrate that SAE achieves superior performance, with marked improvements in final scores, training stability, and sample efficiency. These gains are shown to be consistent across multiple model sizes, and a correlation analysis confirms that our proposed advantage estimator achieves a higher correlation with an approximate ground-truth advantage, justifying its superior performance.", "AI": {"tldr": "本文提出了一种新的优势估计方法Segmental Advantage Estimation（SAE）以改善PPO在长上下文LLM训练中的表现。", "motivation": "稀疏奖励导致的不准确中间值预测使得传统的Generalized Advantage Estimation (GAE) 方法容易引入偏差，影响RLVR中PPO的实际应用。", "method": "通过将生成序列分割成信息丰富的子段落，并在这些边界处计算优势估计来减少偏差。这种方法有效过滤了来自中间令牌的噪音。", "result": "实验表明，SAE显著提高了性能、训练稳定性和样本效率，且改进效果与模型大小无关，相关性分析证明了其优越表现的原因在于更高的接近真实值的优势估计。", "conclusion": "SAE是一种有效的策略来提高PPO在长上下文LLM训练中的性能。"}}
{"id": "2601.07316", "pdf": "https://arxiv.org/pdf/2601.07316", "abs": "https://arxiv.org/abs/2601.07316", "authors": ["Runze Ma", "Caizhi Liao"], "title": "BEAT-Net: Injecting Biomimetic Spatio-Temporal Priors for Interpretable ECG Classification", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 4 figures and 2 tables", "summary": "Although deep learning has advanced automated electrocardiogram (ECG) diagnosis, prevalent supervised methods typically treat recordings as undifferentiated one-dimensional (1D) signals or two-dimensional (2D) images. This formulation compels models to learn physiological structures implicitly, resulting in data inefficiency and opacity that diverge from medical reasoning. To address these limitations, we propose BEAT-Net, a Biomimetic ECG Analysis with Tokenization framework that reformulates the problem as a language modeling task. Utilizing a QRS tokenization strategy to transform continuous signals into biologically aligned heartbeat sequences, the architecture explicitly decomposes cardiac physiology through specialized encoders that extract local beat morphology while normalizing spatial lead perspectives and modeling temporal rhythm dependencies. Evaluations across three large-scale benchmarks demonstrate that BEAT-Net matches the diagnostic accuracy of dominant convolutional neural network (CNN) architectures while substantially improving robustness. The framework exhibits exceptional data efficiency, recovering fully supervised performance using only 30 to 35 percent of annotated data. Moreover, learned attention mechanisms provide inherent interpretability by spontaneously reproducing clinical heuristics, such as Lead II prioritization for rhythm analysis, without explicit supervision. These findings indicate that integrating biological priors offers a computationally efficient and interpretable alternative to data-intensive large-scale pre-training.", "AI": {"tldr": "提出了一种基于生物启发的ECG分析框架BEAT-Net，以提高心电图分类的准确性和可解释性。", "motivation": "当前深度学习方法在处理ECG信号时效率低下且缺乏透明度，因为它们将记录视为未区分的一维或二维信号，而没有利用生理结构信息。", "method": "通过QRS令牌化策略将连续信号转换为心跳序列，并使用专门的编码器提取局部心拍形态、标准化空间导联视角并建模时间节律依赖性。框架还展示了学习注意机制如何自发地重现临床启发式方法，如II导联优先用于分析节奏。", "result": "在三个大规模基准测试中，BEAT-Net达到了主流卷积神经网络架构的诊断精度，同时提高了鲁棒性，并且使用30％至35％标注数据即可恢复完全监督性能。", "conclusion": "将生物先验整合到框架中提供了一种计算效率高、可解释性强的替代方案，无需大规模预训练大量数据。"}}
{"id": "2601.07315", "pdf": "https://arxiv.org/pdf/2601.07315", "abs": "https://arxiv.org/abs/2601.07315", "authors": ["Guanyuan Pan", "Yugui Lin", "Tiansheng Zhou", "Pietro Liò", "Shuai Wang", "Yaqi Wang"], "title": "VLM-CAD: VLM-Optimized Collaborative Agent Design Workflow for Analog Circuit Sizing", "categories": ["cs.MA", "cs.AI", "cs.AR"], "comment": "8 pages, 5 figures", "summary": "Analog mixed-signal circuit sizing involves complex trade-offs within high-dimensional design spaces. Existing automatic analog circuit sizing approaches often underutilize circuit schematics and lack the explainability required for industry adoption. To tackle these challenges, we propose a Vision Language Model-optimized collaborative agent design workflow (VLM-CAD), which analyzes circuits, optimizes DC operating points, performs inference-based sizing and executes external sizing optimization. We integrate Image2Net to annotate circuit schematics and generate a structured JSON description for precise interpretation by Vision Language Models. Furthermore, we propose an Explainable Trust Region Bayesian Optimization method (ExTuRBO) that employs collaborative warm-starting from agent-generated seeds and offers dual-granularity sensitivity analysis for external sizing optimization, supporting a comprehensive final design report. Experiment results on amplifier sizing tasks using 180nm, 90nm, and 45nm Predictive Technology Models demonstrate that VLM-CAD effectively balances power and performance, achieving a 100% success rate in optimizing an amplifier with a complementary input and a class-AB output stage, while maintaining total runtime under 43 minutes across all experiments.", "AI": {"tldr": "提出了一种基于视觉语言模型优化的协作代理设计工作流程VLM-CAD，用于模拟电路尺寸调整。", "motivation": "现有的自动模拟电路尺寸调整方法往往未能充分利用电路图，并且缺乏工业采用所需的解释能力。此研究旨在解决这些问题。", "method": "引入了图像到网络（Image2Net）工具来标注电路图并生成结构化的JSON描述，使用视觉语言模型进行精确解读；提出了一种可解释的信任区域贝叶斯优化方法（ExTuRBO），通过代理生成种子实现协作预热，并提供双粒度敏感性分析。", "result": "实验结果显示，在放大器尺寸调整任务中，VLM-CAD能够在保持总运行时间不超过43分钟的情况下，以100%的成功率优化具有互补输入和AB类输出阶段的放大器。", "conclusion": "该研究展示了VLM-CAD在模拟电路尺寸调整中的有效性，并能够平衡功率与性能。"}}
{"id": "2601.07313", "pdf": "https://arxiv.org/pdf/2601.07313", "abs": "https://arxiv.org/abs/2601.07313", "authors": ["Silvia Ruiz-España", "Laura Arnal", "François Signol", "Juan-Carlos Perez-Cortes", "Joaquim Arlandis"], "title": "Explaining Machine Learning Predictive Models through Conditional Expectation Methods", "categories": ["cs.LG", "cs.AI"], "comment": "24 pages, 15 figures. Silvia Ruiz-España and Laura Arnal contributed equally to this work", "summary": "The rapid adoption of complex Artificial Intelligence (AI) and Machine Learning (ML) models has led to their characterization as black boxes due to the difficulty of explaining their internal decision-making processes. This lack of transparency hinders users' ability to understand, validate and trust model behavior, particularly in high-risk applications. Although explainable AI (XAI) has made significant progress, there remains a need for versatile and effective techniques to address increasingly complex models. This work introduces Multivariate Conditional Expectation (MUCE), a model-agnostic method for local explainability designed to capture prediction changes from feature interactions. MUCE extends Individual Conditional Expectation (ICE) by exploring a multivariate grid of values in the neighborhood of a given observation at inference time, providing graphical explanations that illustrate the local evolution of model predictions. In addition, two quantitative indices, stability and uncertainty, summarize local behavior and assess model reliability. Uncertainty is further decomposed into uncertainty+ and uncertainty- to capture asymmetric effects that global measures may overlook. The proposed method is validated using XGBoost models trained on three datasets: two synthetic (2D and 3D) to evaluate behavior near decision boundaries, and one transformed real-world dataset to test adaptability to heterogeneous feature types. Results show that MUCE effectively captures complex local model behavior, while the stability and uncertainty indices provide meaningful insight into prediction confidence. MUCE, together with the ICE modification and the proposed indices, offers a practical contribution to local explainability, enabling both graphical and quantitative insights that enhance the interpretability of predictive models and support more trustworthy and transparent decision-making.", "AI": {"tldr": "本文提出了一种名为Multivariate Conditional Expectation (MUCE)的方法，用于解释机器学习模型的决策过程。", "motivation": "复杂的人工智能和机器学习模型难以解释其内部决策机制，导致用户无法理解和信任这些模型的行为。", "method": "MUCE是一种局部可解释性方法，通过探索观测值附近的多变量网格来捕捉预测变化，并提供图形化说明。此外，还引入了稳定性和不确定性两个量化指标以评估模型可靠性。", "result": "实验表明，MUCE能够有效捕捉复杂模型的局部行为，并且稳定性与不确定性指数可以为用户提供有关预测信心的重要信息。", "conclusion": "MUCE及其伴随的技术提供了增强预测模型解释性的实际贡献，使决策更加透明和可信。"}}
{"id": "2601.07310", "pdf": "https://arxiv.org/pdf/2601.07310", "abs": "https://arxiv.org/abs/2601.07310", "authors": ["Zhongming Liu", "Bingbing Jiang"], "title": "Revisiting the Ordering of Channel and Spatial Attention: A Comprehensive Study on Sequential and Parallel Designs", "categories": ["cs.CV"], "comment": null, "summary": "Attention mechanisms have become a core component of deep learning models, with Channel Attention and Spatial Attention being the two most representative architectures. Current research on their fusion strategies primarily bifurcates into sequential and parallel paradigms, yet the selection process remains largely empirical, lacking systematic analysis and unified principles. We systematically compare channel-spatial attention combinations under a unified framework, building an evaluation suite of 18 topologies across four classes: sequential, parallel, multi-scale, and residual. Across two vision and nine medical datasets, we uncover a \"data scale-method-performance\" coupling law: (1) in few-shot tasks, the \"Channel-Multi-scale Spatial\" cascaded structure achieves optimal performance; (2) in medium-scale tasks, parallel learnable fusion architectures demonstrate superior results; (3) in large-scale tasks, parallel structures with dynamic gating yield the best performance. Additionally, experiments indicate that the \"Spatial-Channel\" order is more stable and effective for fine-grained classification, while residual connections mitigate vanishing gradient problems across varying data scales. We thus propose scenario-based guidelines for building future attention modules. Code is open-sourced at https://github.com/DWlzm.", "AI": {"tldr": "该论文系统地比较了通道和空间注意力的不同组合结构，提出了适用于不同数据规模和任务类型的注意力模块构建指南。", "motivation": "现有的关于通道注意力和空间注意力融合策略的研究主要集中在顺序和并行两种方案上，但缺乏统一的分析原则。本文旨在提供一个全面的评估框架来指导未来的注意力机制设计。", "method": "建立了一个包含18种拓扑结构的评估套件，涵盖四种类别的架构：顺序、并行、多尺度及残差连接，并通过两个视觉数据集和九个医学数据集进行了实验。", "result": "研究发现，在少量样本任务中，“通道-多尺度空间”级联结构表现最佳；在中等规模的任务中，并行可学习融合架构效果更优；而在大规模任务中，带动态门控的并行结构表现出最好的性能。", "conclusion": "论文根据实验结果提出了针对不同应用场景构建注意力模块的具体建议，以提高模型在各类任务上的表现。"}}
{"id": "2601.07309", "pdf": "https://arxiv.org/pdf/2601.07309", "abs": "https://arxiv.org/abs/2601.07309", "authors": ["Zhuoka Feng", "Kang Chen", "Sihan Zhao", "Kai Xiong", "Yaoning Wang", "Minshen Yu", "Junjie Nian", "Changyi Xiao", "Yixin Cao", "Yugang Jiang"], "title": "ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist LLM Agent Merging", "categories": ["cs.AI", "cs.LG"], "comment": "17 pages, 12 figures. Project page: https://arkazhuo.github.io/ARM-homepage/", "summary": "Interactive large language model agents have advanced rapidly, but most remain specialized to a single environment and fail to adapt robustly to other environments. Model merging offers a training-free alternative by integrating multiple experts into a single model. In this paper, we propose Agent-Role Merging (ARM), an activation-guided, role-conditioned neuron transplantation method for model merging in LLM agents. ARM improves existing merging methods from static natural language tasks to multi-turn agent scenarios, and over the generalization ability across various interactive environments. This is achieved with a well designed 3-step framework: 1) constructing merged backbones, 2) selection based on its role-conditioned activation analysis, and 3) neuron transplantation for fine-grained refinements. Without gradient-based optimization, ARM improves cross-benchmark generalization while enjoying efficiency. Across diverse domains, the model obtained via ARM merging outperforms prior model merging methods and domain-specific expert models, while demonstrating strong out-of-domain generalization.", "AI": {"tldr": "提出了一种名为ARM的角色条件神经元移植方法，用于大型语言模型代理的无训练合并。", "motivation": "大多数现有的大型语言模型代理局限于单一环境且缺乏适应不同环境的能力。模型融合提供了无需额外训练的方法来整合多个专家模型到一个通用模型中。", "method": "通过激活导向的角色条件神经元移植方法，ARM改进了现有模型融合技术以适用于多轮对话场景和跨多种交互环境的泛化能力。该方法包括三个步骤：构造合并骨干网络、基于角色条件激活分析的选择以及精细调整的神经元移植。", "result": "与以前的模型融合技术和领域特定专家模型相比，通过ARM获得的模型在跨多个领域的表现更优，并展示了强大的出域泛化能力。", "conclusion": "该研究证明了ARM方法能在不依赖梯度优化的情况下提升通用大型语言代理模型的跨基准泛化能力和效率。"}}
{"id": "2601.07304", "pdf": "https://arxiv.org/pdf/2601.07304", "abs": "https://arxiv.org/abs/2601.07304", "authors": ["Yun Chen", "Bowei Huang", "Fan Guo", "Kang Song"], "title": "Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts", "categories": ["cs.RO", "cs.AI"], "comment": "9 pages", "summary": "Autonomous mobile manipulation in unstructured warehouses requires a balance between efficient large-scale navigation and high-precision object interaction. Traditional end-to-end learning approaches often struggle to handle the conflicting demands of these distinct phases. Navigation relies on robust decision-making over large spaces, while manipulation needs high sensitivity to fine local details. Forcing a single network to learn these different objectives simultaneously often causes optimization interference, where improving one task degrades the other. To address these limitations, we propose a Heterogeneous Multi-Expert Reinforcement Learning (HMER) framework tailored for autonomous forklifts. HMER decomposes long-horizon tasks into specialized sub-policies controlled by a Semantic Task Planner. This structure separates macro-level navigation from micro-level manipulation, allowing each expert to focus on its specific action space without interference. The planner coordinates the sequential execution of these experts, bridging the gap between task planning and continuous control. Furthermore, to solve the problem of sparse exploration, we introduce a Hybrid Imitation-Reinforcement Training Strategy. This method uses expert demonstrations to initialize the policy and Reinforcement Learning for fine-tuning. Experiments in Gazebo simulations show that HMER significantly outperforms sequential and end-to-end baselines. Our method achieves a task success rate of 94.2\\% (compared to 62.5\\% for baselines), reduces operation time by 21.4\\%, and maintains placement error within 1.5 cm, validating its efficacy for precise material handling.", "AI": {"tldr": "提出了一种异构多专家强化学习框架，用于解决自主叉车在复杂任务中的导航和操作问题。", "motivation": "传统端到端的学习方法难以同时处理大型空间的稳健决策与精细局部细节的操作需求，导致优化干扰。为了解决这个问题，提出了HMER框架来分离导航和操作的任务，并通过语义任务计划器协调执行。", "method": "HMER将长时域任务分解成由不同专家控制的子策略，并引入混合模仿-强化学习训练策略以解决稀疏探索的问题。", "result": "实验表明HMER在Gazebo仿真中显著优于序列基线和端到端方法，成功率为94.2%，减少了操作时间并保持了1.5cm内的放置误差。", "conclusion": "该框架有效解决了自主叉车执行复杂任务中的导航与操作平衡问题，验证了其在精密物料处理方面的效用。"}}
{"id": "2601.07303", "pdf": "https://arxiv.org/pdf/2601.07303", "abs": "https://arxiv.org/abs/2601.07303", "authors": ["Xueping Zhang", "Han Yin", "Yang Xiao", "Lin Zhang", "Ting Dang"], "title": "ESDD2: Environment-Aware Speech and Sound Deepfake Detection Challenge Evaluation Plan", "categories": ["cs.SD"], "comment": null, "summary": "Audio recorded in real-world environments often contains a mixture of foreground speech and background environmental sounds. With rapid advances in text-to-speech, voice conversion, and other generation models, either component can now be modified independently. Such component-level manipulations are harder to detect, as the remaining unaltered component can mislead the systems designed for whole deepfake audio, and they often sound more natural to human listeners. To address this gap, we have proposed CompSpoofV2 dataset and a separation-enhanced joint learning framework. CompSpoofV2 is a large-scale curated dataset designed for component-level audio anti-spoofing, which contains over 250k audio samples, with a total duration of approximately 283 hours. Based on the CompSpoofV2 and the separation-enhanced joint learning framework, we launch the Environment-Aware Speech and Sound Deepfake Detection Challenge (ESDD2), focusing on component-level spoofing, where both speech and environmental sounds may be manipulated or synthesized, creating a more challenging and realistic detection scenario. The challenge will be held in conjunction with the IEEE International Conference on Multimedia and Expo 2026 (ICME 2026).", "AI": {"tldr": "提出了ESDD2挑战赛，专注于环境感知的语音和声音深度伪造检测。", "motivation": "为解决背景音或语音独立修改后难以识别的问题，提出了一种基于CompSpoofV2数据集和分离增强联合学习框架的方法来提升组件级音频防伪能力。", "method": "采用大规模精心策划的数据集CompSpoofV2，并使用分离增强的联合学习框架进行深度伪造检测。", "result": "尚未报告具体结果，但挑战赛旨在提供更具有挑战性和现实性的检测场景。", "conclusion": "ESDD2挑战赛将通过实际数据测试环境感知语音和声音深度伪造检测的有效性。"}}
{"id": "2601.07298", "pdf": "https://arxiv.org/pdf/2601.07298", "abs": "https://arxiv.org/abs/2601.07298", "authors": ["Jianghao Yin", "Qingbin Li", "Kun Sun", "Cheng Ding", "Jie Wang", "Qin Chen", "Jie Zhou", "Nan Wang", "Changqing Li", "Pei Wu", "Jian Xu", "Zheming Yang", "Liang He"], "title": "Mimic Human Cognition, Master Multi-Image Reasoning: A Meta-Action Framework for Enhanced Visual Understanding", "categories": ["cs.CV"], "comment": null, "summary": "While Multimodal Large Language Models (MLLMs) excel at single-image understanding, they exhibit significantly degraded performance in multi-image reasoning scenarios. Multi-image reasoning presents fundamental challenges including complex inter-relationships between images and scattered critical information across image sets. Inspired by human cognitive processes, we propose the Cognition-Inspired Meta-Action Framework (CINEMA), a novel approach that decomposes multi-image reasoning into five structured meta-actions: Global, Focus, Hint, Think, and Answer which explicitly modeling the sequential cognitive steps humans naturally employ. For cold-start training, we introduce a Retrieval-Based Tree Sampling strategy that generates high-quality meta-action trajectories to bootstrap the model with reasoning patterns. During reinforcement learning, we adopt a two-stage paradigm: an exploration phase with Diversity-Preserving Strategy to avoid entropy collapse, followed by an annealed exploitation phase with DAPO to gradually strengthen exploitation. To train our model, we construct a dataset of 57k cold-start and 58k reinforcement learning instances spanning multi-image, multi-frame, and single-image tasks. We conduct extensive evaluations on multi-image reasoning benchmarks, video understanding benchmarks, and single-image benchmarks, achieving competitive state-of-the-art performance on several key benchmarks. Our model surpasses GPT-4o on the MUIR and MVMath benchmarks and notably outperforms specialized video reasoning models on video understanding benchmarks, demonstrating the effectiveness and generalizability of our human cognition-inspired reasoning framework.", "AI": {"tldr": "提出了基于人类认知的元行动框架（CINEMA），以提高多图像推理任务中的视觉理解能力。", "motivation": "现有的多模态大型语言模型在单一图像理解上表现出色，但在涉及复杂图像间关系和散落关键信息的多图像推理场景中表现不佳。为解决这一问题，论文提出了基于人类认知过程的新方法CINEMA。", "method": "提出了一种元行动框架CINEMA，该框架将多图像推理任务分解成五个结构化的元动作：全局、聚焦、提示、思考和回答，模仿了人在处理信息时的自然步骤。为了训练模型，在冷启动阶段使用基于检索的树采样策略生成高质量的轨迹；在强化学习过程中采用两阶段方案，即多样化保持策略下的探索期和通过DAPO加强利用的冷却期。", "result": "论文构建了一个包含57k个冷启动实例和58k个增强学习实例的数据集，并对多图像推理基准、视频理解和单一图像任务进行了广泛的评估。结果表明，该模型在多个关键基准上达到了最先进的水平，在MUIR和MVMath基准测试中超越了GPT-4o，并在视频理解基准测试中优于专门的视频推理模型。", "conclusion": "提出的基于人类认知的元行动框架CINEMA展示了其有效性和泛化能力，能够解决多图像推理中的挑战性问题。"}}
{"id": "2601.07296", "pdf": "https://arxiv.org/pdf/2601.07296", "abs": "https://arxiv.org/abs/2601.07296", "authors": ["Yujin Zhou", "Chuxue Cao", "Jinluan Yang", "Lijun Wu", "Conghui He", "Sirui Han", "Yike Guo"], "title": "LRAS: Advanced Legal Reasoning with Agentic Search", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While Large Reasoning Models (LRMs) have demonstrated exceptional logical capabilities in mathematical domains, their application to the legal field remains hindered by the strict requirements for procedural rigor and adherence to legal logic. Existing legal LLMs, which rely on \"closed-loop reasoning\" derived solely from internal parametric knowledge, frequently suffer from lack of self-awareness regarding their knowledge boundaries, leading to confident yet incorrect conclusions. To address this challenge, we present Legal Reasoning with Agentic Search (LRAS), the first framework designed to transition legal LLMs from static and parametric \"closed-loop thinking\" to dynamic and interactive \"Active Inquiry\". By integrating Introspective Imitation Learning and Difficulty-aware Reinforcement Learning, LRAS enables LRMs to identify knowledge boundaries and handle legal reasoning complexity. Empirical results demonstrate that LRAS outperforms state-of-the-art baselines by 8.2-32\\%, with the most substantial gains observed in tasks requiring deep reasoning with reliable knowledge. We will release our data and models for further exploration soon.", "AI": {"tldr": "本文提出了Legal Reasoning with Agentic Search（LRAS）框架，用于改进大型法律模型在处理复杂法律推理时的表现。", "motivation": "现有的大型语言模型在进行法律推理时存在缺乏自我意识的问题，导致其在某些情况下会得出错误但自信的结论。为了解决这个问题，需要设计一个能够动态互动的新型法律推理框架。", "method": "通过结合内省模仿学习和难度感知强化学习，LRAS使得大型法律模型能够在识别知识边界的同时处理复杂的法律推理任务。", "result": "实验结果表明，相比现有的最佳方法，LRAS在要求深入且可靠知识的任务中表现更为出色，性能提高了8.2-32%。", "conclusion": "LRAS为改进法律领域中的大型语言模型提供了新的思路和框架，能够显著提升模型处理复杂法律推理问题的能力。"}}
{"id": "2601.07293", "pdf": "https://arxiv.org/pdf/2601.07293", "abs": "https://arxiv.org/abs/2601.07293", "authors": ["Weidong Tang", "Xinyan Wan", "Siyu Li", "Xiumei Wang"], "title": "Inference-Time Scaling for Visual AutoRegressive modeling by Searching Representative Samples", "categories": ["cs.CV"], "comment": "Accepted to PRCV 2025", "summary": "While inference-time scaling has significantly enhanced generative quality in large language and diffusion models, its application to vector-quantized (VQ) visual autoregressive modeling (VAR) remains unexplored. We introduce VAR-Scaling, the first general framework for inference-time scaling in VAR, addressing the critical challenge of discrete latent spaces that prohibit continuous path search. We find that VAR scales exhibit two distinct pattern types: general patterns and specific patterns, where later-stage specific patterns conditionally optimize early-stage general patterns. To overcome the discrete latent space barrier in VQ models, we map sampling spaces to quasi-continuous feature spaces via kernel density estimation (KDE), where high-density samples approximate stable, high-quality solutions. This transformation enables effective navigation of sampling distributions. We propose a density-adaptive hybrid sampling strategy: Top-k sampling focuses on high-density regions to preserve quality near distribution modes, while Random-k sampling explores low-density areas to maintain diversity and prevent premature convergence. Consequently, VAR-Scaling optimizes sample fidelity at critical scales to enhance output quality. Experiments in class-conditional and text-to-image evaluations demonstrate significant improvements in inference process. The code is available at https://github.com/WD7ang/VAR-Scaling.", "AI": {"tldr": "本文提出了VAR-Scaling，一种适用于向量量化视觉自回归建模的推断时缩放框架。", "motivation": "现有的推理时间扩展技术主要应用于大型语言和扩散模型中，而在向量量化视觉自回归模型中的应用尚未研究。", "method": "通过核密度估计将离散采样空间映射到准连续特征空间，并提出了基于密度适应的混合采样策略以优化样本保真度。", "result": "实验表明，该方法在类条件和文本到图像评估中显著改善了生成质量。", "conclusion": "本文通过VAR-Scaling框架成功地将推理时间扩展技术应用于向量量化视觉自回归模型，并取得了良好的效果。"}}
{"id": "2601.07291", "pdf": "https://arxiv.org/pdf/2601.07291", "abs": "https://arxiv.org/abs/2601.07291", "authors": ["Qi Zheng", "Shuliang Liu", "Yu Huang", "Sihang Jia", "Jungang Li", "Lyuhao Chen", "Junhao Chen", "Hanqian Li", "Aiwei Liu", "Yibo Yan", "Xuming Hu"], "title": "A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Watermarking has emerged as a pivotal solution for content traceability and intellectual property protection in Large Vision-Language Models (LVLMs). However, vision-agnostic watermarks introduce visually irrelevant tokens and disrupt visual grounding by enforcing indiscriminate pseudo-random biases, while some semantic-aware methods incur prohibitive inference latency due to rejection sampling. In this paper, we propose the VIsual Semantic Adaptive Watermark (VISA-Mark), a novel framework that embeds detectable signals while strictly preserving visual fidelity. Our approach employs a lightweight, efficiently trained prefix-tuner to extract dynamic Visual-Evidence Weights, which quantify the evidentiary support for candidate tokens based on the visual input. These weights guide an adaptive vocabulary partitioning and logits perturbation mechanism, concentrating watermark strength specifically on visually-supported tokens. By actively aligning the watermark with visual evidence, VISA-Mark effectively maintains visual fidelity. Empirical results confirm that VISA-Mark outperforms conventional methods with a 7.8% improvement in visual consistency (Chair-I) and superior semantic fidelity. The framework maintains highly competitive detection accuracy (96.88% AUC) and robust attack resilience (99.3%) without sacrificing inference efficiency, effectively establishing a new standard for reliability-preserving multimodal watermarking.", "AI": {"tldr": "本文提出了一个名为VISA-Mark的新框架，用于在大型视觉语言模型中嵌入视觉语义自适应水印。", "motivation": "现有水印技术或引入无关视觉标记干扰图像理解，或由于采样延迟导致效率低下。因此，需要一种既能保持视觉保真度又不牺牲推理效率的方法。", "method": "VISA-Mark采用轻量级前缀调优器提取动态视觉证据权重，并通过自适应词汇分区和日志概率偏移机制将水印集中在有视觉支持的标记上。", "result": "实验表明，相比传统方法，VISA-Mark在视觉一致性方面提高了7.8%，同时保持了96.88%的检测准确率和99.3%的攻击抵抗性。", "conclusion": "VISA-Mark通过自适应地将水印与视觉证据对齐，在不牺牲推理效率的情况下，有效维护视觉保真度，并确立了一个新的可靠性保护多模态水印标准。"}}
{"id": "2601.07290", "pdf": "https://arxiv.org/pdf/2601.07290", "abs": "https://arxiv.org/abs/2601.07290", "authors": ["Jiapeng Shi", "Junke Wang", "Zuyao You", "Bo He", "Zuxuan Wu"], "title": "VideoLoom: A Video Large Language Model for Joint Spatial-Temporal Understanding", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents VideoLoom, a unified Video Large Language Model (Video LLM) for joint spatial-temporal understanding. To facilitate the development of fine-grained spatial and temporal localization capabilities, we curate LoomData-8.7k, a human-centric video dataset with temporally grounded and spatially localized captions. With this, VideoLoom achieves state-of-the-art or highly competitive performance across a variety of spatial and temporal benchmarks (e.g., 63.1 J&F on ReVOS for referring video object segmentation, and 48.3 R1@0.7 on Charades-STA for temporal grounding). In addition, we introduce LoomBench, a novel benchmark consisting of temporal, spatial, and compositional video-question pairs, enabling a comprehensive evaluation of Video LLMs from diverse aspects. Collectively, these contributions offer a universal and effective suite for joint spatial-temporal video understanding, setting a new standard in multimodal intelligence.", "AI": {"tldr": "VideoLoom是一个用于联合时空理解的视频大型语言模型。", "motivation": "为了促进细粒度的空间和时间定位能力的发展，本文提出了VideoLoom，并创建了包含人类中心视频数据集LoomData-8.7k和新的评估基准LoomBench。", "method": "通过使用包含时空标注的LoomData-8.7k数据集训练模型，以及引入包括时空和组合性问题对的新基准LoomBench进行评估。", "result": "VideoLoom在多个空间和时间基准测试中取得了最先进的或高度竞争性的性能。", "conclusion": "这些贡献提供了一个通用且有效的套件，用于联合时空视频理解，并为多模态智能设定了新的标准。"}}
{"id": "2601.07287", "pdf": "https://arxiv.org/pdf/2601.07287", "abs": "https://arxiv.org/abs/2601.07287", "authors": ["Yuanyang Yin", "Yufan Deng", "Shenghai Yuan", "Kaipeng Zhang", "Xiao Yang", "Feng Zhao"], "title": "Focal Guidance: Unlocking Controllability from Semantic-Weak Layers in Video Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "The task of Image-to-Video (I2V) generation aims to synthesize a video from a reference image and a text prompt. This requires diffusion models to reconcile high-frequency visual constraints and low-frequency textual guidance during the denoising process. However, while existing I2V models prioritize visual consistency, how to effectively couple this dual guidance to ensure strong adherence to the text prompt remains underexplored. In this work, we observe that in Diffusion Transformer (DiT)-based I2V models, certain intermediate layers exhibit weak semantic responses (termed Semantic-Weak Layers), as indicated by a measurable drop in text-visual similarity. We attribute this to a phenomenon called Condition Isolation, where attention to visual features becomes partially detached from text guidance and overly relies on learned visual priors. To address this, we propose Focal Guidance (FG), which enhances the controllability from Semantic-Weak Layers. FG comprises two mechanisms: (1) Fine-grained Semantic Guidance (FSG) leverages CLIP to identify key regions in the reference frame and uses them as anchors to guide Semantic-Weak Layers. (2) Attention Cache transfers attention maps from semantically responsive layers to Semantic-Weak Layers, injecting explicit semantic signals and alleviating their over-reliance on the model's learned visual priors, thereby enhancing adherence to textual instructions. To further validate our approach and address the lack of evaluation in this direction, we introduce a benchmark for assessing instruction following in I2V models. On this benchmark, Focal Guidance proves its effectiveness and generalizability, raising the total score on Wan2.1-I2V to 0.7250 (+3.97\\%) and boosting the MMDiT-based HunyuanVideo-I2V to 0.5571 (+7.44\\%).", "AI": {"tldr": "本文提出了一种新的方法Focal Guidance（FG），用于改进图像到视频生成任务中语义指导和视觉一致性之间的平衡。", "motivation": "现有的图像到视频生成模型在处理文本提示时，难以有效结合视觉一致性和文本指引。作者观察到某些中间层表现出弱的语义响应，并提出解决方案以增强这些层对文本指令的遵守度。", "method": "Focal Guidance包括两个机制：一是Fine-grained Semantic Guidance（FSG），利用CLIP识别参考帧中的关键区域并将其作为锚点引导弱语义层；二是Attention Cache，从具有强语义响应的层转移注意力图到弱语义层，注入显式的语义信号。", "result": "在新引入的评估基准上，Focal Guidance将Wan2.1-I2V的总分提高到0.7250（+3.97%），并将基于MMDiT的HunyuanVideo-I2V提升至0.5571（+7.44%）。", "conclusion": "通过引入Focal Guidance，作者证明了在图像到视频生成任务中增强弱语义层控制性的有效性。"}}
{"id": "2601.07284", "pdf": "https://arxiv.org/pdf/2601.07284", "abs": "https://arxiv.org/abs/2601.07284", "authors": ["Haoyu Zhang", "Shibo Jin", "Lvsong Li", "Jun Li", "Liang Lin", "Xiaodong He", "Zecui Zeng"], "title": "AdaMorph: Unified Motion Retargeting via Embodiment-Aware Adaptive Transformers", "categories": ["cs.RO"], "comment": null, "summary": "Retargeting human motion to heterogeneous robots is a fundamental challenge in robotics, primarily due to the severe kinematic and dynamic discrepancies between varying embodiments. Existing solutions typically resort to training embodiment-specific models, which scales poorly and fails to exploit shared motion semantics. To address this, we present AdaMorph, a unified neural retargeting framework that enables a single model to adapt human motion to diverse robot morphologies. Our approach treats retargeting as a conditional generation task. We map human motion into a morphology-agnostic latent intent space and utilize a dual-purpose prompting mechanism to condition the generation. Instead of simple input concatenation, we leverage Adaptive Layer Normalization (AdaLN) to dynamically modulate the decoder's feature space based on embodiment constraints. Furthermore, we enforce physical plausibility through a curriculum-based training objective that ensures orientation and trajectory consistency via integration. Experimental results on 12 distinct humanoid robots demonstrate that AdaMorph effectively unifies control across heterogeneous topologies, exhibiting strong zero-shot generalization to unseen complex motions while preserving the dynamic essence of the source behaviors.", "AI": {"tldr": "本文提出了一种名为AdaMorph的统一神经运动重定向框架，该框架可以通过单个模型将人类动作适应到不同形态的机器人。", "motivation": "现有的解决方案通常依赖于训练特定于机器人的模型，这不仅扩展性差还未能利用共享的动作语义。为了解决这一问题，本文提出了一种新的方法以实现单一模型在面对不同类型机器人时的有效运动重定向。", "method": "该方法将人类动作映射到形态不可知的意图空间，并使用双重提示机制来条件化生成过程。通过自适应分层归一化（AdaLN）动态调节解码器特征空间，而不是简单的输入连接，确保了生成的机器人动作符合其物理约束。", "result": "实验结果表明，在12种不同的类人形机器人上进行测试时，AdaMorph能够有效地跨异构拓扑结构统一控制，并保持来源行为的动力学本质。", "conclusion": "综上所述，该方法证明了其在将人类动作重定向到不同形态的机器人中具有强大的零样本泛化能力。"}}
{"id": "2601.07273", "pdf": "https://arxiv.org/pdf/2601.07273", "abs": "https://arxiv.org/abs/2601.07273", "authors": ["Chen Min", "Chengyang Li", "Fanjie Kong", "Qi Zhu", "Dawei Zhao", "Liang Xiao"], "title": "GenDet: Painting Colored Bounding Boxes on Images via Diffusion Model for Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents GenDet, a novel framework that redefines object detection as an image generation task. In contrast to traditional approaches, GenDet adopts a pioneering approach by leveraging generative modeling: it conditions on the input image and directly generates bounding boxes with semantic annotations in the original image space. GenDet establishes a conditional generation architecture built upon the large-scale pre-trained Stable Diffusion model, formulating the detection task as semantic constraints within the latent space. It enables precise control over bounding box positions and category attributes, while preserving the flexibility of the generative model. This novel methodology effectively bridges the gap between generative models and discriminative tasks, providing a fresh perspective for constructing unified visual understanding systems. Systematic experiments demonstrate that GenDet achieves competitive accuracy compared to discriminative detectors, while retaining the flexibility characteristic of generative methods.", "AI": {"tldr": "GenDet 是一种通过扩散模型在图像上生成带有语义注释的彩色边界框的方法，重新定义了物体检测任务。", "motivation": "传统方法难以在保持灵活性的同时控制边界框的位置和类别属性。该研究旨在利用生成式模型的优势来解决这一问题，并建立统一视觉理解系统的新视角。", "method": "GenDet 建立了一种基于大规模预训练 Stable Diffusion 模型的有条件生成架构，将检测任务视为潜在空间中的语义约束，从而在原始图像空间中直接生成带有标签的边界框。", "result": "实验表明 GenDet 在保持生成方法灵活性的同时，能够实现与判别式探测器相当的准确性。", "conclusion": "GenDet 成功地填补了生成模型和判别任务之间的空白，并为构建统一视觉理解系统提供了新的视角。"}}
{"id": "2601.07272", "pdf": "https://arxiv.org/pdf/2601.07272", "abs": "https://arxiv.org/abs/2601.07272", "authors": ["Siqi Liu", "Maoyu Wang", "Bo Dai", "Cewu Lu"], "title": "PALUM: Part-based Attention Learning for Unified Motion Retargeting", "categories": ["cs.CV"], "comment": null, "summary": "Retargeting motion between characters with different skeleton structures is a fundamental challenge in computer animation. When source and target characters have vastly different bone arrangements, maintaining the original motion's semantics and quality becomes increasingly difficult. We present PALUM, a novel approach that learns common motion representations across diverse skeleton topologies by partitioning joints into semantic body parts and applying attention mechanisms to capture spatio-temporal relationships. Our method transfers motion to target skeletons by leveraging these skeleton-agnostic representations alongside target-specific structural information. To ensure robust learning and preserve motion fidelity, we introduce a cycle consistency mechanism that maintains semantic coherence throughout the retargeting process. Extensive experiments demonstrate superior performance in handling diverse skeletal structures while maintaining motion realism and semantic fidelity, even when generalizing to previously unseen skeleton-motion combinations. We will make our implementation publicly available to support future research.", "AI": {"tldr": "本文提出了一种新的方法PALUM，通过将关节划分为语义身体部位并应用注意力机制来捕获时空关系，实现不同骨架结构之间的动作重定位。", "motivation": "在计算机动画中，动作从具有不同骨骼结构的源角色转移到目标角色时面临着重大挑战。当源和目标字符具有明显不同的骨骼安排时，保持原始动作的意义和质量变得越来越困难。", "method": "我们提出了一种新的方法PALUM，它通过将关节划分为语义身体部位，并应用注意力机制来捕获时空关系，学习不同骨架拓扑结构之间的公共运动表示。我们的方法通过利用这些与骨架无关的表示以及目标特定的结构性信息，将动作转移到目标骨骼上。", "result": "广泛的实验表明，在处理各种骨骼结构的同时保持运动现实感和语义保真度方面表现优异，即使是在泛化到以前未见过的骨骼-动作组合时也是如此。", "conclusion": "本文提出了一种新的方法PALUM，通过将关节划分为语义身体部位并应用注意力机制来捕获时空关系，从而实现不同骨架结构之间的动作重定位。实验结果表明该方法在处理多样化骨骼结构的同时保持了运动的现实性和语义保真度。"}}
{"id": "2601.07268", "pdf": "https://arxiv.org/pdf/2601.07268", "abs": "https://arxiv.org/abs/2601.07268", "authors": ["Yusen Cheng", "Qinfeng Zhu", "Lei Fan"], "title": "From Landslide Conditioning Factors to Satellite Embeddings: Evaluating the Utilisation of Google AlphaEarth for Landslide Susceptibility Mapping using Deep Learning", "categories": ["cs.CV"], "comment": null, "summary": "Data-driven landslide susceptibility mapping (LSM) typically relies on landslide conditioning factors (LCFs), whose availability, heterogeneity, and preprocessing-related uncertainties can constrain mapping reliability. Recently, Google AlphaEarth (AE) embeddings, derived from multi-source geospatial observations, have emerged as a unified representation of Earth surface conditions. This study evaluated the potential of AE embeddings as alternative predictors for LSM. Two AE representations, including retained principal components and the full set of 64 embedding bands, were systematically compared with conventional LCFs across three study areas (Nantou County, Taiwan; Hong Kong; and part of Emilia-Romagna, Italy) using three deep learning models (CNN1D, CNN2D, and Vision Transformer). Performance was assessed using multiple evaluation metrics, ROC-AUC analysis, error statistics, and spatial pattern assessment. Results showed that AE-based models consistently outperformed LCFs across all regions and models, yielding higher F1-scores, AUC values, and more stable error distributions. Such improvement was most pronounced when using the full 64-band AE representation, with F1-score improvements of approximately 4% to 15% and AUC increased ranging from 0.04 to 0.11, depending on the study area and model. AE-based susceptibility maps also exhibited clearer spatial correspondence with observed landslide occurrences and enhanced sensitivity to localised landslide-prone conditions. Performance improvements were more evident in Nantou and Emilia than in Hong Kong, revealing that closer temporal alignment between AE embeddings and landslide inventories may lead to more effective LSM outcomes. These findings highlight the strong potential of AE embeddings as a standardised and information-rich alternative to conventional LCFs for LSM.", "AI": {"tldr": "本文评估了Google AlphaEarth（AE）嵌入在滑坡易发性制图中的潜在应用，通过深度学习模型与传统因素进行对比。", "motivation": "传统的滑坡易发性制图依赖于滑坡条件因子，但这些因子的可用性和预处理不确定性限制了其可靠性。Google AlphaEarth（AE）嵌入作为地球表面情况的统一表示方法被提出，以克服这些问题。", "method": "本文使用三种深度学习模型（CNN1D、CNN2D和Vision Transformer），在三个研究区域中对两种AE表示形式与传统因子进行了系统对比。评估指标包括F1得分、AUC值等。", "result": "基于AE的模型在所有地区和模型下均优于传统因子，尤其是在使用全64个波段时性能显著提升，F1得分提高了约4%到15%，AUC增加了0.04至0.11。AE生成的地图与实际滑坡事件的空间对应性更强。", "conclusion": "研究结果表明，AE嵌入作为标准化和信息丰富的替代方法在滑坡易发性制图中具有巨大潜力。"}}
{"id": "2601.07263", "pdf": "https://arxiv.org/pdf/2601.07263", "abs": "https://arxiv.org/abs/2601.07263", "authors": ["Xinyi Wu", "Geng Hong", "Yueyue Chen", "MingXuan Liu", "Feier Jin", "Xudong Pan", "Jiarun Dai", "Baojun Liu"], "title": "When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering Attack in Web Automation Agent", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Web agents, powered by large language models (LLMs), are increasingly deployed to automate complex web interactions. The rise of open-source frameworks (e.g., Browser Use, Skyvern-AI) has accelerated adoption, but also broadened the attack surface. While prior research has focused on model threats such as prompt injection and backdoors, the risks of social engineering remain largely unexplored. We present the first systematic study of social engineering attacks against web automation agents and design a pluggable runtime mitigation solution. On the attack side, we introduce the AgentBait paradigm, which exploits intrinsic weaknesses in agent execution: inducement contexts can distort the agent's reasoning and steer it toward malicious objectives misaligned with the intended task. On the defense side, we propose SUPERVISOR, a lightweight runtime module that enforces environment and intention consistency alignment between webpage context and intended goals to mitigate unsafe operations before execution. Empirical results show that mainstream frameworks are highly vulnerable to AgentBait, with an average attack success rate of 67.5% and peaks above 80% under specific strategies (e.g., trusted identity forgery). Compared with existing lightweight defenses, our module can be seamlessly integrated across different web automation frameworks and reduces attack success rates by up to 78.1% on average while incurring only a 7.7% runtime overhead and preserving usability. This work reveals AgentBait as a critical new threat surface for web agents and establishes a practical, generalizable defense, advancing the security of this rapidly emerging ecosystem. We reported the details of this attack to the framework developers and received acknowledgment before submission.", "AI": {"tldr": "该论文研究了针对网络自动化代理的社会工程攻击，并提出了一个名为SUPERVISOR的轻量级运行时模块来防御此类攻击。", "motivation": "随着大型语言模型驱动的网络自动化代理变得越来越流行，其潜在的安全威胁也引起了人们的关注。特别是社会工程攻击，这种新兴的风险目前尚未得到充分研究。", "method": "论文提出了一种名为AgentBait的社会工程攻击策略，并设计了SUPERVISOR防御模块来检测和阻止这些攻击行为，通过确保运行环境与意图的一致性来降低不安全操作的风险。", "result": "实验证明主流框架容易受到AgentBait的攻击，平均成功率为67.5%，而使用SUPERVISOR可以将此成功率降低至多78.1%，并且只增加了7.7%的运行时开销。", "conclusion": "该论文揭示了网络自动化代理中社会工程攻击这一新威胁，并提出了一种有效的轻量级防御机制，有助于提高此类系统的安全性。"}}
{"id": "2601.07262", "pdf": "https://arxiv.org/pdf/2601.07262", "abs": "https://arxiv.org/abs/2601.07262", "authors": ["Jiamu Zhou", "Jihong Wang", "Weiming Zhang", "Weiwen Liu", "Zhuosheng Zhang", "Xingyu Lou", "Weinan Zhang", "Huarong Deng", "Jun Wang"], "title": "ColorBrowserAgent: An Intelligent GUI Agent for Complex Long-Horizon Web Automation", "categories": ["cs.HC"], "comment": null, "summary": "The web browser serves as a primary interface for daily human activities, making its automation a critical frontier for Human-Centred AI. While Large Language Models (LLMs) have enabled autonomous agents to interact with web GUIs, their reliability in real-world scenarios is hampered by long-horizon instability and the vast heterogeneity of site designs. In this paper, we introduce ColorBrowserAgent, a framework designed for Collaborative Autonomy in complex web tasks. Our approach integrates two human-centred mechanisms: (1) Progressive Progress Summarization, which mimics human short-term memory to maintain coherence over extended interactions; and (2) Human-in-the-Loop Knowledge Adaptation, which bridges the knowledge gap in diverse environments by soliciting expert intervention only when necessary. This symbiotic design allows the agent to learn from human tips without extensive retraining, effectively combining the scalability of AI with the adaptability of human cognition. Evaluated on the WebArena benchmark using GPT-5, ColorBrowserAgent achieves a state-of-the-art success rate of 71.2\\%, demonstrating the efficacy of interactive human assistance in robust web automation.", "AI": {"tldr": "本文提出了ColorBrowserAgent，一种用于复杂网络任务的协作自主框架。", "motivation": "大型语言模型在实际场景中因长时序不稳定性和网页设计多样性而可靠性不足，因此开发了一种结合人机交互机制的新框架来提高自动化性能。", "method": "该方法包含两个核心机制：渐进式进度总结和人在回路中的知识适应，通过模拟人类短期记忆保持长期一致性，并在必要时寻求专家建议以缩小知识差距。", "result": "ColorBrowserAgent在WebArena基准测试中取得了71.2%的成功率，证明了交互式人工辅助在网络自动化中的有效性。", "conclusion": "该框架展示了将人工智能的可扩展性与人类认知适应性的结合如何提高复杂网络任务的稳定性。"}}
{"id": "2601.07261", "pdf": "https://arxiv.org/pdf/2601.07261", "abs": "https://arxiv.org/abs/2601.07261", "authors": ["Haomin Wu", "Zhiwei Nie", "Hongyu Zhang", "Zhixiang Ren"], "title": "Pseudodata-guided Invariant Representation Learning Boosts the Out-of-Distribution Generalization in Enzymatic Kinetic Parameter Prediction", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "Accurate prediction of enzyme kinetic parameters is essential for understanding catalytic mechanisms and guiding enzyme engineering.However, existing deep learning-based enzyme-substrate interaction (ESI) predictors often exhibit performance degradation on sequence-divergent, out-of-distribution (OOD) cases, limiting robustness under biologically relevant perturbations.We propose O$^2$DENet, a lightweight, plug-and-play module that enhances OOD generalization via biologically and chemically informed perturbation augmentation and invariant representation learning.O$^2$DENet introduces enzyme-substrate perturbations and enforces consistency between original and augmented enzyme-substrate-pair representations to encourage invariance to distributional shifts.When integrated with representative ESI models, O$^2$DENet consistently improves predictive performance for both $k_{cat}$ and $K_m$ across stringent sequence-identity-based OOD benchmarks, achieving state-of-the-art results among the evaluated methods in terms of accuracy and robustness metrics.Overall, O$^2$DENet provides a general and effective strategy to enhance the stability and deployability of data-driven enzyme kinetics predictors for real-world enzyme engineering applications.", "AI": {"tldr": "提出了O$^2$DENet模块，通过生物化学增强和不变表示学习来提高酶动力学参数预测在分布外样本上的泛化能力。", "motivation": "现有的基于深度学习的酶底物相互作用（ESI）预测模型在面对序列不同的分布外数据时表现下降，这限制了其在生物学相关扰动下的鲁棒性。", "method": "O$^2$DENet通过引入酶底物干扰并强制原始和增强后的酶底物对表示之间的一致性来鼓励对分布变化的不变性。该模块可以与代表性ESI模型集成以改善预测性能。", "result": "实验结果表明，O$^2$DENet在严格的序列同源度基准测试中提高了k$_{cat}$和K$_m$的预测准确性，并达到了所评估方法中的最新水平。", "conclusion": "O$^2$DENet为增强数据驱动酶动力学预测器的稳定性和部署能力提供了一种通用有效的策略，适用于实际的酶工程应用。"}}
{"id": "2601.07256", "pdf": "https://arxiv.org/pdf/2601.07256", "abs": "https://arxiv.org/abs/2601.07256", "authors": ["Siddhartha Ganguly", "Kenji Kashima"], "title": "Robust maximum hands-off optimal control: existence, maximum principle, and $L^{0}$-$L^1$ equivalence", "categories": ["math.OC", "cs.RO", "eess.SY", "math.NA"], "comment": "Revised version of a journal submission; comments are welcome", "summary": "This work advances the maximum hands-off sparse control framework by developing a robust counterpart for constrained linear systems with parametric uncertainties. The resulting optimal control problem minimizes an $L^{0}$ objective subject to an uncountable, compact family of constraints, and is therefore a nonconvex, nonsmooth robust optimization problem. To address this, we replace the $L^{0}$ objective with its convex $L^{1}$ surrogate and, using a nonsmooth variant of the robust Pontryagin maximum principle, show that the $L^{0}$ and $L^{1}$ formulations have identical sets of optimal solutions -- we call this the robust hands-off principle. Building on this equivalence, we propose an algorithmic framework -- drawing on numerically viable techniques from the semi-infinite robust optimization literature -- to solve the resulting problems. An illustrative example is provided to demonstrate the effectiveness of the approach.", "AI": {"tldr": "该论文提出了一个鲁棒的最大手离控制框架，用于处理具有参数不确定性的约束线性系统。", "motivation": "为了提高控制的稀疏性并减少操作次数，作者开发了一种新的鲁棒最大手离控制方法来解决带有不确定性参数的约束线性系统的优化问题。", "method": "通过将$L^{0}$目标函数替换为它的凸$L^{1}$替代者，并使用一种非光滑版本的Robust Pontryagin最大值原理，证明了$L^{0}$和$L^{1}$形式化方法具有相同的最优解集。基于这一等价性，提出了一种算法框架以解决这些问题。", "result": "论文表明$L^{0}$和$L^{1}$形式化方法在处理鲁棒最大手离控制问题时拥有相同的最优解，并且提出的算法能够有效解决问题。", "conclusion": "该工作证明了$L^{0}$和$L^{1}$目标函数具有等价的最优解集，这对解决鲁棒最大手离控制问题提供了理论支持。通过引入新的算法框架，展示了在处理这类非凸、非光滑优化问题的有效性。"}}
{"id": "2601.07253", "pdf": "https://arxiv.org/pdf/2601.07253", "abs": "https://arxiv.org/abs/2601.07253", "authors": ["Li Zheng", "Liangbin Xie", "Jiantao Zhou", "He YiMin"], "title": "Universal Adversarial Purification with DDIM Metric Loss for Stable Diffusion", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "Stable Diffusion (SD) often produces degraded outputs when the training dataset contains adversarial noise. Adversarial purification offers a promising solution by removing adversarial noise from contaminated data. However, existing purification methods are primarily designed for classification tasks and fail to address SD-specific adversarial strategies, such as attacks targeting the VAE encoder, UNet denoiser, or both. To address the gap in SD security, we propose Universal Diffusion Adversarial Purification (UDAP), a novel framework tailored for defending adversarial attacks targeting SD models. UDAP leverages the distinct reconstruction behaviors of clean and adversarial images during Denoising Diffusion Implicit Models (DDIM) inversion to optimize the purification process. By minimizing the DDIM metric loss, UDAP can effectively remove adversarial noise. Additionally, we introduce a dynamic epoch adjustment strategy that adapts optimization iterations based on reconstruction errors, significantly improving efficiency without sacrificing purification quality. Experiments demonstrate UDAP's robustness against diverse adversarial methods, including PID (VAE-targeted), Anti-DreamBooth (UNet-targeted), MIST (hybrid), and robustness-enhanced variants like Anti-Diffusion (Anti-DF) and MetaCloak. UDAP also generalizes well across SD versions and text prompts, showcasing its practical applicability in real-world scenarios.", "AI": {"tldr": "提出了一种针对Stable Diffusion模型的通用对抗净化框架UDAP，以去除训练数据中的对抗噪声。", "motivation": "现有的对抗净化方法主要针对分类任务，并不能有效应对Stable Diffusion特有的攻击策略。为了提高SD的安全性，需要一种专门的方法来防御这些特定于SD的攻击。", "method": "UDAP利用DDIM逆向过程中干净和被污染图像的不同重建行为进行优化，通过最小化DDIM度量损失以去除对抗噪声，并引入动态迭代调整策略提升效率。", "result": "实验显示UDAP对多种不同类型和增强版本的对抗方法具有鲁棒性，并在不同SD版本和文本提示中表现良好。", "conclusion": "UDAP能够有效防御针对Stable Diffusion模型的各种对抗攻击，展示了其实际应用价值。"}}
{"id": "2601.07251", "pdf": "https://arxiv.org/pdf/2601.07251", "abs": "https://arxiv.org/abs/2601.07251", "authors": ["Zizhen Li", "Chuanhao Li", "Yibin Wang", "Yukang Feng", "Jianwen Sun", "Jiaxin Ai", "Fanrui Zhang", "Mingzhu Sun", "Yifei Huang", "Kaipeng Zhang"], "title": "MeepleLM: A Virtual Playtester Simulating Diverse Subjective Experiences", "categories": ["cs.HC"], "comment": null, "summary": "Recent advancements have expanded the role of Large Language Models in board games from playing agents to creative co-designers. However, a critical gap remains: current systems lack the capacity to offer constructive critique grounded in the emergent user experience. Bridging this gap is fundamental for harmonizing Human-AI collaboration, as it empowers designers to refine their creations via external perspectives while steering models away from biased or unpredictable outcomes. Automating critique for board games presents two challenges: inferring the latent dynamics connecting rules to gameplay without an explicit engine, and modeling the subjective heterogeneity of diverse player groups. To address these, we curate a dataset of 1,727 structurally corrected rulebooks and 150K reviews selected via quality scoring and facet-aware sampling. We augment this data with Mechanics-Dynamics-Aesthetics (MDA) reasoning to explicitly bridge the causal gap between written rules and player experience. We further distill player personas and introduce MeepleLM, a specialized model that internalizes persona-specific reasoning patterns to accurately simulate the subjective feedback of diverse player archetypes. Experiments demonstrate that MeepleLM significantly outperforms latest commercial models (e.g., GPT-5.1, Gemini3-Pro) in community alignment and critique quality, achieving a 70% preference rate in user studies assessing utility. MeepleLM serves as a reliable virtual playtester for general interactive systems, marking a pivotal step towards audience-aligned, experience-aware Human-AI collaboration.", "AI": {"tldr": "该论文介绍了一种新的大型语言模型MeepleLM，它能够模拟玩家的主观反馈，以帮助游戏设计师改进他们的作品。", "motivation": "目前的游戏系统缺乏基于用户体验提供建设性批评的能力。这限制了人机协作的和谐发展，并且可能导致偏见或不可预测的结果。因此，开发一种可以自动评估和提供建设性意见的模型至关重要。", "method": "该研究通过创建一个包含1727个游戏规则书和150K条评论的数据集来解决问题，并采用MDA（机制-动态-美学）推理方法将书面规则与玩家体验之间的因果关系显式化。进一步地，他们提取了不同的玩家人格特征并训练了一个专门的模型MeepleLM，该模型能够模拟不同玩家类型的主观反馈。", "result": "实验结果显示，MeepleLM在社区一致性以及批评质量方面都显著优于最新的商业模型（如GPT-5.1和Gemini3-Pro），并在用户研究中获得了70%的偏好率。", "conclusion": "MeepleLM作为一个可靠的虚拟测试者被引入，为通用互动系统提供服务，并标志着朝向受众导向、体验感知的人机协作的关键一步。"}}
{"id": "2601.07250", "pdf": "https://arxiv.org/pdf/2601.07250", "abs": "https://arxiv.org/abs/2601.07250", "authors": ["Mingnan Zhu", "Qixuan Zhang", "Yixuan Cheng", "Fangzhou Gu", "Shiming Lin"], "title": "DDT: A Dual-Masking Dual-Expert Transformer for Energy Time-Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate energy time-series forecasting is crucial for ensuring grid stability and promoting the integration of renewable energy, yet it faces significant challenges from complex temporal dependencies and the heterogeneity of multi-source data. To address these issues, we propose DDT, a novel and robust deep learning framework for high-precision time-series forecasting. At its core, DDT introduces two key innovations. First, we design a dual-masking mechanism that synergistically combines a strict causal mask with a data-driven dynamic mask. This novel design ensures theoretical causal consistency while adaptively focusing on the most salient historical information, overcoming the rigidity of traditional masking techniques. Second, our architecture features a dual-expert system that decouples the modeling of temporal dynamics and cross-variable correlations into parallel, specialized pathways, which are then intelligently integrated through a dynamic gated fusion module. We conducted extensive experiments on 7 challenging energy benchmark datasets, including ETTh, Electricity, and Solar. The results demonstrate that DDT consistently outperforms strong state-of-the-art baselines across all prediction horizons, establishing a new benchmark for the task.", "AI": {"tldr": "提出了一种新型的深度学习框架DDT，用于准确的时间序列预测。", "motivation": "为了解决复杂时间依赖性和多源数据异质性带来的挑战，提高电网稳定性和可再生能源集成度。", "method": "设计了双重掩码机制和双专家系统架构，结合因果一致性和自适应聚焦历史信息的能力。", "result": "在7个具有挑战性的能源基准数据集上进行实验，结果表明DDT优于现有基线方法，并建立了新标准。", "conclusion": "通过创新的模型结构，在准确的时间序列预测任务中取得了显著效果。"}}
{"id": "2601.07248", "pdf": "https://arxiv.org/pdf/2601.07248", "abs": "https://arxiv.org/abs/2601.07248", "authors": ["Shuyu Zhang", "Yujie Liu", "Xinru Wang", "Cheng Zhang", "Yanmin Zhu", "Bin Li"], "title": "DarwinTOD: LLM Driven Lifelong Self Evolution for Task Oriented Dialog Systems", "categories": ["cs.MA", "cs.HC"], "comment": null, "summary": "Traditional task-oriented dialog systems are unable to evolve from ongoing interactions or adapt to new domains after deployment, that is a critical limitation in real-world dynamic environments. Continual learning approaches depend on episodic retraining with human curated data, failing to achieve autonomy lifelong improvement. While evolutionary computation and LLM driven self improvement offer promising mechanisms for dialog optimization, they lack a unified framework for holistic, iterative strategy refinement. To bridge this gap, we propose DarwinTOD, a lifelong self evolving dialog framework that systematically integrates these two paradigms, enabling continuous strategy optimization from a zero-shot base without task specific fine-tuning. DarwinTOD maintains an Evolvable Strategy Bank and operates through a dual-loop process: online multi-agent dialog execution with peer critique, and offline structured evolutionary operations that refine the strategy bank using accumulated feedback. This closed-loop design enables autonomous continuous improvement without human intervention. Extensive experiments show that DarwinTOD surpasses previous state-of-the-art methods and exhibits continuous performance gains throughout evolution. Our work provides a novel framework for building dialog systems with lifelong self evolution capabilities.", "AI": {"tldr": "本文提出了一种名为DarwinTOD的对话系统框架，该框架能够在无任务特定微调的情况下从零开始实现自主优化。", "motivation": "传统的目标导向对话系统不能在部署后通过持续交互进化或适应新领域，在动态环境中存在重要限制。持续学习方法依赖于需要人工数据调整的方法，无法实现终身改进的自主性。", "method": "本文提出了一种名为DarwinTOD的框架，结合了演化计算和大型语言模型驱动的自我改善机制，通过在线多代理对话执行与同行批评及离线结构化进化操作来不断优化策略库。", "result": "实验结果表明，DarwinTOD超越了当前最佳方法，并在整个进化过程中表现出持续的性能提升。", "conclusion": "本文提出了一种新颖的框架，用于构建具有终身自我演化能力的对话系统。"}}
{"id": "2601.07245", "pdf": "https://arxiv.org/pdf/2601.07245", "abs": "https://arxiv.org/abs/2601.07245", "authors": ["Pranav Kallem"], "title": "Learning to Trust the Crowd: A Multi-Model Consensus Reasoning Engine for Large Language Models", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) achieve strong aver- age performance yet remain unreliable at the instance level, with frequent hallucinations, brittle failures, and poorly calibrated confidence. We study reliability through the lens of multi-model consensus: given responses from several heterogeneous LLMs, can we learn which answer is most likely correct for a given query? We introduce a Multi-Model Consensus Reasoning Engine that treats the set of LLM outputs as input to a supervised meta-learner. The system maps natural language responses into structured features using semantic embeddings, pairwise similarity and clustering statistics, lexical and structural cues, reasoning-quality scores, confidence estimates, and model-specific priors, and then applies gradient-boosted trees, listwise ranking, and graph neural networks over similarity graphs of answers. Using three open-weight LLMs evaluated on compact, resource- constrained subsets of GSM8K, ARC-Challenge, HellaSwag, and TruthfulQA, our best graph-attention-based consensus model improves macro-average accuracy by 4.6 percentage points over the strongest single LLM and by 8.1 points over majority vote, while also yielding lower Brier scores and fewer TruthfulQA hal- lucinations. Ablation and feature-importance analyses show that semantic agreement and clustering features are most influential, with reasoning-quality and model-prior features providing com- plementary gains, suggesting supervised multi-model consensus is a practical route toward more reliable LLM behavior, even in a modest single-machine setup.", "AI": {"tldr": "通过多模型共识推理引擎提高大型语言模型的可靠性。", "motivation": "解决大型语言模型在实例层面上不一致和不可靠的问题，特别是在频繁出现幻觉、脆弱失败以及信心校准不足方面。", "method": "引入一个基于多个不同模型输出的监督学习元学习器的方法。该系统将自然语言响应映射为结构化特征，使用语义嵌入、成对相似性统计、聚类统计数据等，并通过梯度增强树、列表级排名和图神经网络进行处理。", "result": "在GSM8K, ARC-Challenge, HellaSwag, 和 TruthfulQA的子集上测试中，最佳模型比最强单一LLM提高了4.6个百分点的准确率，比多数投票方法提高了8.1个百分点。同时降低了Brier分数和TruthfulQA幻觉的数量。", "conclusion": "证明了监督下的多模型共识推理是提高大型语言模型可靠性的有效途径，并且这种方法在单机环境下也可行。"}}
{"id": "2601.07242", "pdf": "https://arxiv.org/pdf/2601.07242", "abs": "https://arxiv.org/abs/2601.07242", "authors": ["Taekbeom Lee", "Dabin Kim", "Youngseok Jang", "H. Jin Kim"], "title": "HERE: Hierarchical Active Exploration of Radiance Field with Epistemic Uncertainty Minimization", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted to IEEE RA-L. The first two authors contributed equally", "summary": "We present HERE, an active 3D scene reconstruction framework based on neural radiance fields, enabling high-fidelity implicit mapping. Our approach centers around an active learning strategy for camera trajectory generation, driven by accurate identification of unseen regions, which supports efficient data acquisition and precise scene reconstruction. The key to our approach is epistemic uncertainty quantification based on evidential deep learning, which directly captures data insufficiency and exhibits a strong correlation with reconstruction errors. This allows our framework to more reliably identify unexplored or poorly reconstructed regions compared to existing methods, leading to more informed and targeted exploration. Additionally, we design a hierarchical exploration strategy that leverages learned epistemic uncertainty, where local planning extracts target viewpoints from high-uncertainty voxels based on visibility for trajectory generation, and global planning uses uncertainty to guide large-scale coverage for efficient and comprehensive reconstruction. The effectiveness of the proposed method in active 3D reconstruction is demonstrated by achieving higher reconstruction completeness compared to previous approaches on photorealistic simulated scenes across varying scales, while a hardware demonstration further validates its real-world applicability.", "AI": {"tldr": "本文提出了HERE框架，该框架通过基于神经辐射场的主动学习策略生成相机轨迹，以实现高效的数据采集和精确的场景重建。", "motivation": "现有的方法在识别未探索或重建不足区域方面存在局限性。为了解决这些问题，作者提出了一种新的框架来更可靠地识别这些区域并进行更有针对性的探索。", "method": "该方法基于证据深度学习对知识不确定性进行量化，并设计了层次化探索策略：局部规划从高不确定性的体素中提取目标视点生成轨迹；全局规划利用不确定性指导大规模覆盖。", "result": "与之前的方法相比，所提方法在光栅现实模拟场景上实现了更高的重建完整性。硬件演示验证其实际应用性。", "conclusion": "HERE框架通过有效识别未探索区域并引导相机进行更有针对性的采集，在提高三维重建效率和准确性方面取得了显著进步。"}}
{"id": "2601.07239", "pdf": "https://arxiv.org/pdf/2601.07239", "abs": "https://arxiv.org/abs/2601.07239", "authors": ["Tanmay Joshi", "Shourya Aggarwal", "Anusa Saha", "Aadi Pandey", "Shreyash Dhoot", "Vighnesh Rai", "Raxit Goswami", "Aman Chadha", "Vinija Jain", "Amitava Das"], "title": "Stochastic CHAOS: Why Deterministic Inference Kills, and Distributional Variability Is the Heartbeat of Artifical Cognition", "categories": ["cs.AI"], "comment": null, "summary": "Deterministic inference is a comforting ideal in classical software: the same program on the same input should always produce the same output. As large language models move into real-world deployment, this ideal has been imported wholesale into inference stacks. Recent work from the Thinking Machines Lab has presented a detailed analysis of nondeterminism in LLM inference, showing how batch-invariant kernels and deterministic attention can enforce bitwise-identical outputs, positioning deterministic inference as a prerequisite for reproducibility and enterprise reliability. In this paper, we take the opposite stance. We argue that, for LLMs, deterministic inference kills. It kills the ability to model uncertainty, suppresses emergent abilities, collapses reasoning into a single brittle path, and weakens safety alignment by hiding tail risks. LLMs implement conditional distributions over outputs, not fixed functions. Collapsing these distributions to a single canonical completion may appear reassuring, but it systematically conceals properties central to artificial cognition. We instead advocate Stochastic CHAOS, treating distributional variability as a signal to be measured and controlled. Empirically, we show that deterministic inference is systematically misleading. Single-sample deterministic evaluation underestimates both capability and fragility, masking failure probability under paraphrases and noise. Phase-like transitions associated with emergent abilities disappear under greedy decoding. Multi-path reasoning degrades when forced onto deterministic backbones, reducing accuracy and diagnostic insight. Finally, deterministic evaluation underestimates safety risk by hiding rare but dangerous behaviors that appear only under multi-sample evaluation.", "AI": {"tldr": "论文探讨了大型语言模型中确定性推理的局限性和危害，提出了一种名为Stochastic CHAOS的方法，主张通过处理分布变量来改进人工智能的认知能力。", "motivation": "近年来，随着大型语言模型进入实际应用，人们将确定性推理的理想引入其推断过程中。然而，这种做法限制了不确定性建模、抑制了潜在能力的显现，并削弱了安全性对齐。论文旨在揭示这些负面影响，提倡更灵活的方法来处理分布变量。", "method": "提出Stochastic CHAOS方法，通过测量和控制分布变量性来改进人工智能的认知表现，而不是将条件分布压缩为单一输出。", "result": "实验证明，确定性推理低估了模型的能力与脆弱性，并掩盖了罕见但危险的行为。多路径推理在强制执行确定性推断时准确性降低且诊断洞察力减少。", "conclusion": "论文建议放弃对确定性推理的依赖，转而拥抱分布变量性以提高人工智能的认知能力和安全性。"}}
{"id": "2601.07238", "pdf": "https://arxiv.org/pdf/2601.07238", "abs": "https://arxiv.org/abs/2601.07238", "authors": ["Hanbin Wang", "Jingwei Song", "Jinpeng Li", "Fei Mi", "Lifeng Shang"], "title": "Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning", "categories": ["cs.AI"], "comment": "8 pages, 5 figures", "summary": "Large reasoning models (LRMs) exhibit diverse high-level reasoning patterns (e.g., direct solution, reflection-and-verification, and exploring multiple solutions), yet prevailing training recipes implicitly bias models toward a limited set of dominant patterns. Through a systematic analysis, we identify substantial accuracy variance across these patterns on mathematics and science benchmarks, revealing that a model's default reasoning pattern is often sub-optimal for a given problem. To address this, we introduce Group Pattern Selection Optimization (GPSO), a reinforcement learning framework that extends GRPO by incorporating multi-pattern rollouts, verifier-guided optimal pattern selection per problem, and attention masking during optimization to prevent the leakage of explicit pattern suffixes into the learned policy. By exploring a portfolio of diverse reasoning strategies and optimizing the policy on the most effective ones, GPSO enables the model to internalize the mapping from problem characteristics to optimal reasoning patterns. Extensive experiments demonstrate that GPSO delivers consistent and substantial performance gains across various model backbones and benchmarks, effectively mitigating pattern sub-optimality and fostering more robust, adaptable reasoning. All data and codes are available at https://github.com/wanghanbinpanda/GPSO.", "AI": {"tldr": "本文提出了一种名为Group Pattern Selection Optimization (GPSO)的强化学习框架，旨在优化大型推理模型(LRMs)选择最合适的推理模式以提高性能。", "motivation": "现有方法使LRMs偏向于有限的一组主导推理模式。通过系统分析发现，在数学和科学基准测试中这些模式之间存在显著准确性差异，表明默认推理模式往往不适合给定问题。", "method": "GPSO框架结合了多模式卷出、基于验证器的最优模式选择以及注意力掩蔽在优化过程中的使用以防止显式模式后缀泄漏到学习策略。通过探索一系列多样化推理策略并针对最有效的进行政策优化，使模型能够内化从问题特征到最佳推理模式的映射。", "result": "实验表明GPSO框架对各种模型骨干和基准测试均能提供一致且显著的性能提升，有效减轻了模式次优性，并促进了更强大、更具适应性的推理能力。", "conclusion": "本文提出的GPSO方法能够显著改善LRMs的选择性推理模式，从而提高其在解决不同问题时的表现。"}}
{"id": "2601.07237", "pdf": "https://arxiv.org/pdf/2601.07237", "abs": "https://arxiv.org/abs/2601.07237", "authors": ["Guobin Ma", "Yuxuan Xia", "Jixun Yao", "Huixin Xue", "Hexin Liu", "Shuai Wang", "Hao Liu", "Lei Xie"], "title": "The ICASSP 2026 Automatic Song Aesthetics Evaluation Challenge", "categories": ["eess.AS", "cs.SD"], "comment": "Official summary paper for the ICASSP 2026 ASAE Challenge", "summary": "This paper summarizes the ICASSP 2026 Automatic Song Aesthetics Evaluation (ASAE) Challenge, which focuses on predicting the subjective aesthetic scores of AI-generated songs. The challenge consists of two tracks: Track 1 targets the prediction of the overall musicality score, while Track 2 focuses on predicting five fine-grained aesthetic scores. The challenge attracted strong interest from the research community and received numerous submissions from both academia and industry. Top-performing systems significantly surpassed the official baseline, demonstrating substantial progress in aligning objective metrics with human aesthetic preferences. The outcomes establish a standardized benchmark and advance human-aligned evaluation methodologies for modern music generation systems.", "AI": {"tldr": "ICASSP 2026年自动歌曲美学评估挑战赛旨在预测AI生成歌曲的主观美学评分，分为整体音乐性和五个细粒度美学评分两个赛道。", "motivation": "推动现代音乐生成系统中客观指标与人类审美偏好的对齐技术进步，并建立标准化基准。", "method": "吸引了来自学术界和工业界的大量提交作品，展示了顶尖系统的性能表现。", "result": "顶级参赛作品显著超越官方基线，表明在主观美学评分预测方面取得了实质性进展。", "conclusion": "该挑战赛确立了标准的评估基准，推进了音乐生成系统中人类审美偏好的客观评价方法。"}}
{"id": "2601.07234", "pdf": "https://arxiv.org/pdf/2601.07234", "abs": "https://arxiv.org/abs/2601.07234", "authors": ["Hagit Ben Shoshan", "Joel Lanir", "Pavel Goldstein", "Osnat Mokryn"], "title": "Making Absence Visible: The Roles of Reference and Prompting in Recognizing Missing Information", "categories": ["cs.HC", "cs.IR", "stat.AP"], "comment": null, "summary": "Interactive systems that explain data, or support decision making often emphasize what is present while overlooking what is expected but missing. This presence bias limits users' ability to form complete mental models of a dataset or situation. Detecting absence depends on expectations about what should be there, yet interfaces rarely help users form such expectations. We present an experimental study examining how reference framing and prompting influence people's ability to recognize expected but missing categories in datasets. Participants compared distributions across three domains (energy, wealth, and regime) under two reference conditions: Global, presenting a unified population baseline, and Partial, showing several concrete exemplars. Results indicate that absence detection was higher with Partial reference than with Global reference, suggesting that partial, samples-based framing can support expectation formation and absence detection. When participants were prompted to look for what was missing, absence detection rose sharply. We discuss implications for interactive user interfaces and expectation-based visualization design, while considering cognitive trade-offs of reference structures and guided attention.", "AI": {"tldr": "研究探讨了在交互系统中，通过参考框架和提示来提高用户识别缺失信息的能力。", "motivation": "当前的互动系统倾向于强调存在的数据而忽视预期但实际缺少的信息，这种存在偏见影响了用户构建完整数据集或情况的心理模型能力。", "method": "研究进行了实验，参与者在两个不同的参考条件下（全球和部分）比较了三个领域的分布图，并探讨了提示如何提升识别缺失类别的能力。", "result": "结果显示，在使用“部分”参考框架的情况下，对缺失信息的检测率更高。当用户被引导寻找缺少的信息时，检测率显著提高。", "conclusion": "研究提出了改进交互界面和基于期望设计可视化的方法建议，并考虑了不同参考结构和注意力指导的认知权衡。"}}
{"id": "2601.07233", "pdf": "https://arxiv.org/pdf/2601.07233", "abs": "https://arxiv.org/abs/2601.07233", "authors": ["Chen Qian", "Yimeng Wang", "Yu Chen", "Lingfei Wu", "Andreas Stathopoulos"], "title": "From \"Thinking\" to \"Justifying\": Aligning High-Stakes Explainability with Professional Communication Standards", "categories": ["cs.AI"], "comment": null, "summary": "Explainable AI (XAI) in high-stakes domains should help stakeholders trust and verify system outputs. Yet Chain-of-Thought methods reason before concluding, and logical gaps or hallucinations can yield conclusions that do not reliably align with their rationale. Thus, we propose \"Result -> Justify\", which constrains the output communication to present a conclusion before its structured justification. We introduce SEF (Structured Explainability Framework), operationalizing professional conventions (e.g., CREAC, BLUF) via six metrics for structure and grounding. Experiments across four tasks in three domains validate this approach: all six metrics correlate with correctness (r=0.20-0.42; p<0.001), and SEF achieves 83.9% accuracy (+5.3 over CoT). These results suggest structured justification can improve verifiability and may also improve reliability.", "AI": {"tldr": "提出了一种新的解释框架（SEF），以改善高风险领域的AI可解释性。", "motivation": "Chain-of-Thought方法存在逻辑漏洞或幻觉，导致结论与推理过程不一致。因此，需要一种新方法来提高结果的可靠性和验证性。", "method": "引入了“结论-证明”模式和结构化解释框架（SEF），通过六个指标评估结构和基础，并在四个任务中进行了实验。", "result": "所有六个指标与正确率相关联（r=0.20-0.42；p<0.001），并且SEF达到了83.9%的准确度，比Chain-of-Thought提高了5.3个百分点。", "conclusion": "结构化证明可以提高AI系统的可验证性和可靠性。"}}
{"id": "2601.07232", "pdf": "https://arxiv.org/pdf/2601.07232", "abs": "https://arxiv.org/abs/2601.07232", "authors": ["Olivia Shanhong Liu", "Pai Chet Ng", "De Wen Soh", "Konstantinos N. Plataniotis"], "title": "Yes FLoReNce, I Will Do Better Next Time! Agentic Feedback Reasoning for Humorous Meme Detection", "categories": ["cs.AI"], "comment": "LaMAS@AAAI 2026 (Oral)", "summary": "Humorous memes blend visual and textual cues to convey irony, satire, or social commentary, posing unique challenges for AI systems that must interpret intent rather than surface correlations. Existing multimodal or prompting-based models generate explanations for humor but operate in an open loop,lacking the ability to critique or refine their reasoning once a prediction is made. We propose FLoReNce, an agentic feedback reasoning framework that treats meme understanding as a closed-loop process during learning and an open-loop process during inference. In the closed loop, a reasoning agent is critiqued by a judge; the error and semantic feedback are converted into control signals and stored in a feedback-informed, non-parametric knowledge base. At inference, the model retrieves similar judged experiences from this KB and uses them to modulate its prompt, enabling better, self-aligned reasoning without finetuning. On the PrideMM dataset, FLoReNce improves both predictive performance and explanation quality over static multimodal baselines, showing that feedback-regulated prompting is a viable path to adaptive meme humor understanding.", "AI": {"tldr": "本文提出了一种名为FLoReNce的框架，用于通过反馈调节提示来提高对幽默表情包的理解能力。", "motivation": "现有模型在生成解释时缺乏批判和优化其推理的能力，而FLoReNce能够在学习过程中进行闭环反馈，在推断时使用开放式模式增强理解。", "method": "FLoReNce框架包括一个判断环节，通过将错误和语义反馈转换为控制信号存储到知识库中，并在推理阶段利用这些信息来调整提示内容。", "result": "实验结果表明，FLoReNce在PrideMM数据集上提升了预测性能和解释质量，证明了反馈调节提示的有效性。", "conclusion": "研究表明通过闭环反馈机制可以提高幽默表情包的理解能力，展示了适应性幽默理解的新路径。"}}
{"id": "2601.07229", "pdf": "https://arxiv.org/pdf/2601.07229", "abs": "https://arxiv.org/abs/2601.07229", "authors": ["Eran Fainman", "Hagit Ben Shoshan", "Adir Solomon", "Osnat Mokryn"], "title": "DiSCo: Making Absence Visible in Intelligent Summarization Interfaces", "categories": ["cs.HC", "cs.AI", "cs.IR"], "comment": null, "summary": "Intelligent interfaces increasingly use large language models to summarize user-generated content, yet these summaries emphasize what is mentioned while overlooking what is missing. This presence bias can mislead users who rely on summaries to make decisions. We present Domain Informed Summarization through Contrast (DiSCo), an expectation-based computational approach that makes absences visible by comparing each entity's content with domain topical expectations captured in reference distributions of aspects typically discussed in comparable accommodations. This comparison identifies aspects that are either unusually emphasized or missing relative to domain norms and integrates them into the generated text. In a user study across three accommodation domains, namely ski, beach, and city center, DiSCo summaries were rated as more detailed and useful for decision making than baseline large language model summaries, although slightly harder to read. The findings show that modeling expectations reduces presence bias and improves both transparency and decision support in intelligent summarization interfaces.", "AI": {"tldr": "论文提出了DiSCo方法，通过对比领域内通常讨论的话题来识别和突出摘要中的缺失内容。", "motivation": "智能接口使用大型语言模型生成的摘要往往会强调提到的内容而忽略遗漏的信息，这种现象可能导致用户误解并影响决策。", "method": "DiSCo通过将每个实体的内容与其在参考分布中预期讨论的主题进行比较来识别异常偏重或缺失的部分，并将这些部分整合到生成文本中。", "result": "实验结果表明，在三个不同住宿领域的用户体验研究中，DiSCo生成的摘要比基线大型语言模型生成的摘要更详细、更有用，但阅读难度略高。", "conclusion": "通过建模期望可以减少偏重现象，并提高智能总结界面的信息透明度和决策支持能力。"}}
{"id": "2601.07226", "pdf": "https://arxiv.org/pdf/2601.07226", "abs": "https://arxiv.org/abs/2601.07226", "authors": ["Seongyun Lee", "Yongrae Jo", "Minju Seo", "Moontae Lee", "Minjoon Seo"], "title": "Lost in the Noise: How Reasoning Models Fail with Contextual Distractors", "categories": ["cs.AI", "cs.CL"], "comment": "Preprint", "summary": "Recent advances in reasoning models and agentic AI systems have led to an increased reliance on diverse external information. However, this shift introduces input contexts that are inherently noisy, a reality that current sanitized benchmarks fail to capture. We introduce NoisyBench, a comprehensive benchmark that systematically evaluates model robustness across 11 datasets in RAG, reasoning, alignment, and tool-use tasks against diverse noise types, including random documents, irrelevant chat histories, and hard negative distractors. Our evaluation reveals a catastrophic performance drop of up to 80% in state-of-the-art models when faced with contextual distractors. Crucially, we find that agentic workflows often amplify these errors by over-trusting noisy tool outputs, and distractors can trigger emergent misalignment even without adversarial intent. We find that prompting, context engineering, SFT, and outcome-reward only RL fail to ensure robustness; in contrast, our proposed Rationale-Aware Reward (RARE) significantly strengthens resilience by incentivizing the identification of helpful information within noise. Finally, we uncover an inverse scaling trend where increased test-time computation leads to worse performance in noisy settings and demonstrate via attention visualization that models disproportionately focus on distractor tokens, providing vital insights for building the next generation of robust, reasoning-capable agents.", "AI": {"tldr": "该论文介绍了NoisyBench基准测试，用于评估在噪声背景下的推理模型的鲁棒性，并提出了Rationale-Aware Reward (RARE)方法来提高模型在噪声环境中的表现。", "motivation": "现有的推理模型和代理AI系统依赖于多样化的外部信息，但这些输入往往包含噪音。当前的标准基准测试未能充分模拟这种现实情况，因此需要一个更加全面的基准来评估模型在这种条件下的鲁棒性。", "method": "论文构建了NoisyBench基准测试，并通过多种噪声类型（如随机文档、无关聊天历史和硬负干扰物）系统地评估模型在不同任务中的表现。提出了Rationale-Aware Reward (RARE)方法，旨在通过奖励识别有用信息来提高鲁棒性。", "result": "实验结果显示，在面对上下文干扰时，最先进的模型性能下降了高达80%。此外，发现代理工作流程往往会放大这些错误，并且在无恶意意图的情况下也能触发偏差行为。现有的技术如提示、上下文工程、SFT和结果奖励强化学习无法确保鲁棒性。", "conclusion": "通过引入NoisyBench基准测试，论文揭示了现有模型在噪音环境下的脆弱性，并提出了RARE方法来提高鲁棒性。该研究还发现随着测试时间计算的增加，性能反而下降的趋势，为下一代推理能力更强且更可靠的代理系统的开发提供了重要的见解。"}}
{"id": "2601.07224", "pdf": "https://arxiv.org/pdf/2601.07224", "abs": "https://arxiv.org/abs/2601.07224", "authors": ["Yang Zhao", "Yangou Ouyang", "Xiao Ding", "Hepeng Wang", "Bibo Cai", "Kai Xiong", "Jinglong Gao", "Zhouhao Sun", "Li Du", "Bing Qin", "Ting Liu"], "title": "Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "While Hybrid Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has become the standard paradigm for training LLM agents, effective mechanisms for data allocation between these stages remain largely underexplored. Current data arbitration strategies often rely on surface-level heuristics that fail to diagnose intrinsic learning needs. Since SFT targets pattern consolidation through imitation while RL drives structural adaptation via exploration, misaligning data with these functional roles causes severe optimization interference. We propose PRISM, a dynamics-aware framework grounded in Schema Theory that arbitrates data based on its degree of cognitive conflict with the model's existing knowledge. By analyzing the spatial geometric structure of gradients, PRISM identifies data triggering high spatial concentration as high-conflict signals that require RL for structural restructuring. In contrast, data yielding diffuse updates is routed to SFT for efficient consolidation. Extensive experiments on WebShop and ALFWorld demonstrate that PRISM achieves a Pareto improvement, outperforming state-of-the-art hybrid methods while reducing computational costs by up to 3.22$\\times$. Our findings suggest that disentangling data based on internal optimization regimes is crucial for scalable and robust agent alignment.", "AI": {"tldr": "提出PRISM框架，通过分析梯度的几何结构来区分SFT和RL数据，提高LLM代理训练效果。", "motivation": "现有SFT和RL的数据分配策略存在不足，未能有效诊断模型学习需求，导致优化干扰严重。研究旨在找到一种有效的数据仲裁机制以解决此问题。", "method": "基于Schema理论提出的PRISM框架，通过梯度空间几何结构分析确定高冲突信号需用RL处理，而低冲突信号则使用SFT进行模式巩固。", "result": "在WebShop和ALFWorld实验中，PRISM优于现有方法，并降低了计算成本。", "conclusion": "分离数据以适应内部优化机制对于实现可扩展且稳健的代理对齐至关重要。"}}
{"id": "2601.07221", "pdf": "https://arxiv.org/pdf/2601.07221", "abs": "https://arxiv.org/abs/2601.07221", "authors": ["Jongwon Ryu", "Joonhyung Park", "Jaeho Han", "Yeong-Seok Kim", "Hye-rin Kim", "Sunjae Yoon", "Junyeong Kim"], "title": "Language-Grounded Multi-Domain Image Translation via Semantic Difference Guidance", "categories": ["cs.CV"], "comment": null, "summary": "Multi-domain image-to-image translation re quires grounding semantic differences ex pressed in natural language prompts into corresponding visual transformations, while preserving unrelated structural and seman tic content. Existing methods struggle to maintain structural integrity and provide fine grained, attribute-specific control, especially when multiple domains are involved. We propose LACE (Language-grounded Attribute Controllable Translation), built on two compo nents: (1) a GLIP-Adapter that fuses global semantics with local structural features to pre serve consistency, and (2) a Multi-Domain Control Guidance mechanism that explicitly grounds the semantic delta between source and target prompts into per-attribute translation vec tors, aligning linguistic semantics with domain level visual changes. Together, these modules enable compositional multi-domain control with independent strength modulation for each attribute. Experiments on CelebA(Dialog) and BDD100K demonstrate that LACE achieves high visual fidelity, structural preservation, and interpretable domain-specific control, surpass ing prior baselines. This positions LACE as a cross-modal content generation framework bridging language semantics and controllable visual translation.", "AI": {"tldr": "本文提出了一种基于语言的多领域图像翻译方法LACE，该方法能够在保持结构完整性的前提下实现细粒度属性控制。", "motivation": "现有技术在处理多个领域的图像时难以保持结构性和提供精细、具体的特性控制。因此，本文提出了一个新框架来解决这些问题。", "method": "LACE由两个组件组成：GLIP-Adapter将全局语义与局部结构特征融合以维持一致性；多领域控制引导机制通过定义源域与目标域之间的语言差异来进行细粒度的属性翻译。", "result": "实验表明，LACE在视觉保真度、结构性保留和可解释性方面优于先前的方法，在CelebA（对话）数据集和BDD100K上表现突出。", "conclusion": "LACE为语言语义与可控视觉转换之间的桥梁提供了一个框架。"}}
{"id": "2601.07219", "pdf": "https://arxiv.org/pdf/2601.07219", "abs": "https://arxiv.org/abs/2601.07219", "authors": ["Thanh-Nhan Vo", "Trong-Thuan Nguyen", "Tam V. Nguyen", "Minh-Triet Tran"], "title": "VENUS: Visual Editing with Noise Inversion Using Scene Graphs", "categories": ["cs.CV"], "comment": null, "summary": "State-of-the-art text-based image editing models often struggle to balance background preservation with semantic consistency, frequently resulting either in the synthesis of entirely new images or in outputs that fail to realize the intended edits. In contrast, scene graph-based image editing addresses this limitation by providing a structured representation of semantic entities and their relations, thereby offering improved controllability. However, existing scene graph editing methods typically depend on model fine-tuning, which incurs high computational cost and limits scalability. To this end, we introduce VENUS (Visual Editing with Noise inversion Using Scene graphs), a training-free framework for scene graph-guided image editing. Specifically, VENUS employs a split prompt conditioning strategy that disentangles the target object of the edit from its background context, while simultaneously leveraging noise inversion to preserve fidelity in unedited regions. Moreover, our proposed approach integrates scene graphs extracted from multimodal large language models with diffusion backbones, without requiring any additional training. Empirically, VENUS substantially improves both background preservation and semantic alignment on PIE-Bench, increasing PSNR from 22.45 to 24.80, SSIM from 0.79 to 0.84, and reducing LPIPS from 0.100 to 0.070 relative to the state-of-the-art scene graph editing model (SGEdit). In addition, VENUS enhances semantic consistency as measured by CLIP similarity (24.97 vs. 24.19). On EditVal, VENUS achieves the highest fidelity with a 0.87 DINO score and, crucially, reduces per-image runtime from 6-10 minutes to only 20-30 seconds. Beyond scene graph-based editing, VENUS also surpasses strong text-based editing baselines such as LEDIT++ and P2P+DirInv, thereby demonstrating consistent improvements across both paradigms.", "AI": {"tldr": "本文提出了一种名为VENUS的训练无需求的框架，用于基于场景图的图像编辑。", "motivation": "现有的文本驱动的图像编辑模型常常难以平衡背景保留与语义一致性的问题。而基于场景图的方法虽然提供了改进的可控性，但通常需要模型微调，这导致了高昂的计算成本和有限的可扩展性。", "method": "VENUS采用了一种分裂提示条件策略来分离编辑目标对象及其背景，并利用噪声反转来保持未修改区域的真实度。该方法整合了从多模态大型语言模型中提取的场景图与扩散骨干网络，无需额外训练。", "result": "在PIE-Bench上，VENUS显著提高了PSNR、SSIM和CLIP相似性的值，减少了LPIPS，并缩短了运行时间至20-30秒。同时，它还在EditVal中达到了最高的DINO得分并超过了LEDIT++和P2P+DirInv等文本驱动的编辑基线。", "conclusion": "VENUS展示了在基于场景图与文本驱动图像编辑中的持续改进能力，并且具有更短的运行时间，证明了其高效性和有效性。"}}
{"id": "2601.07218", "pdf": "https://arxiv.org/pdf/2601.07218", "abs": "https://arxiv.org/abs/2601.07218", "authors": ["Jeongjun Choi", "Yeonsoo Park", "H. Jin Kim"], "title": "SceneNAT: Masked Generative Modeling for Language-Guided Indoor Scene Synthesis", "categories": ["cs.CV"], "comment": "Under review. Code will be released", "summary": "We present SceneNAT, a single-stage masked non-autoregressive Transformer that synthesizes complete 3D indoor scenes from natural language instructions through only a few parallel decoding passes, offering improved performance and efficiency compared to prior state-of-the-art approaches. SceneNAT is trained via masked modeling over fully discretized representations of both semantic and spatial attributes. By applying a masking strategy at both the attribute level and the instance level, the model can better capture intra-object and inter-object structure. To boost relational reasoning, SceneNAT employs a dedicated triplet predictor for modeling the scene's layout and object relationships by mapping a set of learnable relation queries to a sparse set of symbolic triplets (subject, predicate, object). Extensive experiments on the 3D-FRONT dataset demonstrate that SceneNAT achieves superior performance compared to state-of-the-art autoregressive and diffusion baselines in both semantic compliance and spatial arrangement accuracy, while operating with substantially lower computational cost.", "AI": {"tldr": "SceneNAT是一种用于通过自然语言指令生成完整室内场景的单阶段掩码非自回归Transformer。", "motivation": "为了提高室内场景合成的质量和效率，提出了一种新的方法来处理复杂的语义和空间属性的关系建模问题。", "method": "SceneNAT采用掩码模型训练策略，在完全离散化表示的基础上进行学习。通过在属性级和实例级应用遮蔽策略，更好地捕捉对象内部结构及对象间关系，并利用三元组预测器增强场景布局和物体关系的认知。", "result": "实验结果显示，与现有的自回归方法和扩散基准相比，SceneNAT在语义一致性和空间排列准确性方面都取得了更好的性能，同时具有较低的计算成本。", "conclusion": "SceneNAT提供了一种高效且准确的方法来生成基于自然语言指令指导的室内场景。"}}
{"id": "2601.07214", "pdf": "https://arxiv.org/pdf/2601.07214", "abs": "https://arxiv.org/abs/2601.07214", "authors": ["Weiqi Wang", "Zhiyi Tian", "Chenhan Zhang", "Shui Yu"], "title": "BlindU: Blind Machine Unlearning without Revealing Erasing Data", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": null, "summary": "Machine unlearning enables data holders to remove the contribution of their specified samples from trained models to protect their privacy. However, it is paradoxical that most unlearning methods require the unlearning requesters to firstly upload their data to the server as a prerequisite for unlearning. These methods are infeasible in many privacy-preserving scenarios where servers are prohibited from accessing users' data, such as federated learning (FL). In this paper, we explore how to implement unlearning under the condition of not uncovering the erasing data to the server. We propose \\textbf{Blind Unlearning (BlindU)}, which carries out unlearning using compressed representations instead of original inputs. BlindU only involves the server and the unlearning user: the user locally generates privacy-preserving representations, and the server performs unlearning solely on these representations and their labels. For the FL model training, we employ the information bottleneck (IB) mechanism. The encoder of the IB-based FL model learns representations that distort maximum task-irrelevant information from inputs, allowing FL users to generate compressed representations locally. For effective unlearning using compressed representation, BlindU integrates two dedicated unlearning modules tailored explicitly for IB-based models and uses a multiple gradient descent algorithm to balance forgetting and utility retaining. While IB compression already provides protection for task-irrelevant information of inputs, to further enhance the privacy protection, we introduce a noise-free differential privacy (DP) masking method to deal with the raw erasing data before compressing. Theoretical analysis and extensive experimental results illustrate the superiority of BlindU in privacy protection and unlearning effectiveness compared with the best existing privacy-preserving unlearning benchmarks.", "AI": {"tldr": "盲机器遗忘技术在不暴露擦除数据给服务器的情况下实现。", "motivation": "现有大多数遗忘方法需要请求者首先上传其数据到服务器，这在很多隐私保护场景中是不可行的。该研究旨在探索如何在不解密删除数据的情况下执行遗忘操作。", "method": "提出盲遗忘（BlindU），使用压缩表示而不是原始输入进行遗忘操作。用户本地生成隐私保护表示，并由服务器仅对这些表示及其标签执行遗忘。采用信息瓶颈机制，使FL用户能够本地生成压缩表示。引入专用的遗忘模块和多重梯度下降算法以平衡遗忘与保持效用。", "result": "理论分析和广泛的实验结果表明，BlindU在隐私保护和遗忘效果方面优于现有的最佳隐私保护遗忘基准。", "conclusion": "通过利用信息瓶颈机制和噪声差分隐私技术，BlindU能够在不解密原始数据的情况下实现高效的机器遗忘操作，同时确保了模型的效用。"}}
{"id": "2601.07209", "pdf": "https://arxiv.org/pdf/2601.07209", "abs": "https://arxiv.org/abs/2601.07209", "authors": ["Yu Guo", "Zhiqiang Lao", "Xiyun Song", "Yubin Zhou", "Heather Yu"], "title": "SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": "12 pages, 14 figures, accepted in WACVW 2026", "summary": "Glass surfaces create complex interactions of reflected and transmitted light, making single-image reflection removal (SIRR) challenging. Existing datasets suffer from limited physical realism in synthetic data or insufficient scale in real captures. We introduce a synthetic dataset generation framework that path-traces 3D glass models over real background imagery to create physically accurate reflection scenarios with varied glass properties, camera settings, and post-processing effects. To leverage the capabilities of Large Multimodal Model (LMM), we concatenate the image layers into a single composite input, apply joint captioning, and fine-tune the model using task-specific LoRA rather than full-parameter training. This enables our approach to achieve improved reflection removal and separation performance compared to state-of-the-art methods.", "AI": {"tldr": "本文提出了一个通过大型多模态模型去除单张图像中反射的方法SIRR-LMM。", "motivation": "现有数据集在合成数据的物理现实性或真实捕获的规模上存在局限，导致难以解决玻璃表面产生的复杂光交互问题。", "method": "提出了一种生成框架以创建具有不同玻璃属性、相机设置和后期效果的真实背景图像中的物理准确反射场景，并通过将图像层合并为单一组合输入并应用联合标题来利用大型多模态模型的能力。使用特定任务的LoRA而非全参数训练进行微调。", "result": "该方法在去除和分离反射方面优于最先进的方法。", "conclusion": "SIRR-LMM能够更有效地解决单张图像中的反射移除问题，证明了通过大型多模态模型处理合成数据的方法的有效性。"}}
{"id": "2601.07206", "pdf": "https://arxiv.org/pdf/2601.07206", "abs": "https://arxiv.org/abs/2601.07206", "authors": ["Hao Li", "Yiqun Zhang", "Zhaoyan Guo", "Chenxu Wang", "Shengji Tang", "Qiaosheng Zhang", "Yang Chen", "Biqing Qi", "Peng Ye", "Lei Bai", "Zhen Wang", "Shuyue Hu"], "title": "LLMRouterBench: A Massive Benchmark and Unified Framework for LLM Routing", "categories": ["cs.AI"], "comment": null, "summary": "Large language model (LLM) routing assigns each query to the most suitable model from an ensemble. We introduce LLMRouterBench, a large-scale benchmark and unified framework for LLM routing. It comprises over 400K instances from 21 datasets and 33 models. Moreover, it provides comprehensive metrics for both performance-oriented routing and performance-cost trade-off routing, and integrates 10 representative routing baselines. Using LLMRouterBench, we systematically re-evaluate the field. While confirming strong model complementarity-the central premise of LLM routing-we find that many routing methods exhibit similar performance under unified evaluation, and several recent approaches, including commercial routers, fail to reliably outperform a simple baseline. Meanwhile, a substantial gap remains to the Oracle, driven primarily by persistent model-recall failures. We further show that backbone embedding models have limited impact, that larger ensembles exhibit diminishing returns compared to careful model curation, and that the benchmark also enables latency-aware analysis. All code and data are available at https://github.com/ynulihao/LLMRouterBench.", "AI": {"tldr": "大型语言模型（LLM）路由将每个查询分配给最合适的模型。该论文介绍了LLMRouterBench，一个大规模基准测试和统一框架。", "motivation": "为了系统地重新评估大型语言模型路由领域的现状，建立了一个包含超过40万个实例的统一评价体系，并发现许多方法在性能上表现出相似性，同时指出了现有方法的一些局限性。", "method": "使用了来自21个数据集和33个模型组成的庞大测试集合，并提供了针对性能导向型路由和成本-性能权衡路由的全面度量标准。该框架还整合了十个代表性的基准路由方法。", "result": "尽管证明了模型之间的互补性，但许多路由方法在统一评估中表现相似，甚至一些商业路由器无法可靠地超越简单的基线方法。同时存在显著差距主要是由于持久的模型召回失败导致的。此外，骨干嵌入模型的影响有限，并且更大的模型集合相比于仔细选择的模型库表现出递减的效果。", "conclusion": "LLMRouterBench展示了现有路由技术的有效性和局限性，表明了优化大型语言模型路由的挑战和机会，同时提供了一个进行延迟感知分析的能力。"}}
{"id": "2601.07201", "pdf": "https://arxiv.org/pdf/2601.07201", "abs": "https://arxiv.org/abs/2601.07201", "authors": ["Ibne Farabi Shihab", "Sanjeda Akter", "Anuj Sharma"], "title": "CalPro: Prior-Aware Evidential--Conformal Prediction with Structure-Aware Guarantees for Protein Structures", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep protein structure predictors such as AlphaFold provide confidence estimates (e.g., pLDDT) that are often miscalibrated and degrade under distribution shifts across experimental modalities, temporal changes, and intrinsically disordered regions. We introduce CalPro, a prior-aware evidential-conformal framework for shift-robust uncertainty quantification. CalPro combines (i) a geometric evidential head that outputs Normal-Inverse-Gamma predictive distributions via a graph-based architecture; (ii) a differentiable conformal layer that enables end-to-end training with finite-sample coverage guarantees; and (iii) domain priors (disorder, flexibility) encoded as soft constraints. We derive structure-aware coverage guarantees under distribution shift using PAC-Bayesian bounds over ambiguity sets, and show that CalPro maintains near-nominal coverage while producing tighter intervals than standard conformal methods in regions where priors are informative. Empirically, CalPro exhibits at most 5% coverage degradation across modalities (vs. 15-25% for baselines), reduces calibration error by 30-50%, and improves downstream ligand-docking success by 25%. Beyond proteins, CalPro applies to structured regression tasks in which priors encode local reliability, validated on non-biological benchmarks.", "AI": {"tldr": "CalPro是一个用于蛋白质结构预测的不确定性量化框架，结合了几何证据头、可微分同形层和领域先验。", "motivation": "深度蛋白结构预测器如AlphaFold提供的置信度估计往往不准确，并且在实验模态变化等情况下性能下降。为了提供鲁棒的不确定性量化方法，CalPro应运而生。", "method": "CalPro结合了输出Normal-Inverse-Gamma预测分布的几何证据头、可微分同形层以及作为软约束编码的领域先验（如无序和柔韧性），并利用PAC-Bayesian界为结构意识覆盖保证导出分布式转换下覆盖保证。", "result": "实证表明，CalPro在不同模态下的覆盖率下降不超过5%，比基线方法减少30-50%的校准误差，并提高了25%的下游配体对接成功率。此外，在非生物基准上也得到了验证。", "conclusion": "CalPro提供了一种结构感知覆盖保证的方法，可以在分布变化时维持接近名义上的覆盖率并产生更紧密的区间。"}}
{"id": "2601.07200", "pdf": "https://arxiv.org/pdf/2601.07200", "abs": "https://arxiv.org/abs/2601.07200", "authors": ["Haozhong Wang", "Zhuo Li", "Yibo Yang", "He Zhao", "Hongyuan Zha", "Dandan Guo"], "title": "Safeguarding LLM Fine-tuning via Push-Pull Distributional Alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The inherent safety alignment of Large Language Models (LLMs) is prone to erosion during fine-tuning, even when using seemingly innocuous datasets. While existing defenses attempt to mitigate this via data selection, they typically rely on heuristic, instance-level assessments that neglect the global geometry of the data distribution and fail to explicitly repel harmful patterns. To address this, we introduce Safety Optimal Transport (SOT), a novel framework that reframes safe fine-tuning from an instance-level filtering challenge to a distribution-level alignment task grounded in Optimal Transport (OT). At its core is a dual-reference ``push-pull'' weight-learning mechanism: SOT optimizes sample importance by actively pulling the downstream distribution towards a trusted safe anchor while simultaneously pushing it away from a general harmful reference. This establishes a robust geometric safety boundary that effectively purifies the training data. Extensive experiments across diverse model families and domains demonstrate that SOT significantly enhances model safety while maintaining competitive downstream performance, achieving a superior safety-utility trade-off compared to baselines.", "AI": {"tldr": "提出了一种新的框架Safety Optimal Transport（SOT），以解决LLM在微调过程中安全性下降的问题，通过优化样本重要性来增强模型的安全性和性能。", "motivation": "现有防御方法依赖于实例级评估，忽略了数据分布的整体几何形状，并且未能明确排斥有害模式。因此，需要一种新的方法来更好地保护LLM的安全性。", "method": "引入了一种基于最优传输的框架Safety Optimal Transport（SOT），通过双参考“推拉”权重学习机制优化样本重要性，使下游分布向安全基准靠拢并远离有害基准，从而建立一个坚固的安全边界。", "result": "在各种模型家族和领域进行了广泛的实验，证明了SOT能够显著提高模型安全性，并保持强大的性能表现，实现比基线更好的安全性与实用性权衡。", "conclusion": "Safety Optimal Transport（SOT）框架通过优化样本重要性来增强大型语言模型的安全性和性能，在微调过程中建立了稳健的安全边界。"}}
{"id": "2601.07199", "pdf": "https://arxiv.org/pdf/2601.07199", "abs": "https://arxiv.org/abs/2601.07199", "authors": ["Murtaza Nikzad", "Raghuram Ramanujan"], "title": "Forward versus Backward: Comparing Reasoning Objectives in Direct Preference Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models exhibit impressive reasoning capabilities yet frequently generate plausible but incorrect solutions, a phenomenon commonly termed hallucination. This paper investigates the effect of training objective composition on reasoning reliability through Direct Preference Optimization. Two complementary training signals are examined: forward chain-of-thought generation, which trains the model to produce correct reasoning traces, and backward verification, which trains the model to verify and acknowledge errors in candidate solutions. Experiments on GSM8K reveal a fundamental trade-off between these objectives. Forward-only DPO training achieves the highest accuracy improvement, increasing from 83.1% to 86.6% (+3.5 percentage points), while backward-only training yields minimal accuracy gains but substantially reduces the false positive rate from 13.4% to 4.3%. Notably, both training variants reduce acknowledgement rate compared to the baseline, suggesting that preference optimization increases model confidence in its outputs. These findings indicate that forward and backward reasoning objectives provide distinct and complementary learning signals: forward training improves problem-solving capability, while backward training improves verification calibration. The complete training and evaluation pipeline, implemented efficiently through Low-Rank Adaptation, is released to facilitate further research.", "AI": {"tldr": "研究比较了直接偏好优化中的正向推理生成和反向验证两种训练目标对语言模型推理可靠性的效果。", "motivation": "探讨在大型语言模型中，不同的训练目标如何影响其推理的准确性及减少错误输出的问题。", "method": "通过GSM8K数据集实验，比较了仅使用正向链式思考生成、反向验证和结合两者的直接偏好优化方法的效果。采用低秩适应技术高效实施训练与评估流程。", "result": "纯正向DPO训练提高准确性最多，从83.1%增加到86.6%，而单独的反向训练虽然改善不大但显著降低了错误率，两者均减少了模型对答案的认可率。", "conclusion": "正向和反向推理目标提供了不同的学习信号：正向提高了问题解决能力，反向提高了验证校准。实验揭示了两种方法之间的权衡关系，并开放了完整的技术方案以供进一步研究。"}}
{"id": "2601.07197", "pdf": "https://arxiv.org/pdf/2601.07197", "abs": "https://arxiv.org/abs/2601.07197", "authors": ["Ibne Farabi Shihab", "Sanjeda Akter", "Anuj Sharma"], "title": "Beyond Variance: Knowledge-Aware LLM Compression via Fisher-Aligned Subspace Diagnostics", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Post-training activation compression is essential for deploying Large Language Models (LLMs) on resource-constrained hardware. However, standard methods like Singular Value Decomposition (SVD) are gradient-blind: they preserve high-variance dimensions regardless of their impact on factual knowledge preservation. We introduce Fisher-Aligned Subspace Compression (FASC), a knowledge-aware compression framework that selects subspaces by directly modeling activation-gradient coupling, minimizing a second-order surrogate of the loss function. FASC leverages the Fisher Information Matrix to identify dimensions critical for factual knowledge, which often reside in low-variance but high-gradient-sensitivity subspaces. We propose the Dependence Violation Score (\\r{ho}) as a general-purpose diagnostic metric that quantifies activation-gradient coupling, revealing where factual knowledge is stored within transformer architectures. Extensive experiments on Mistral-7B and Llama-3-8B demonstrate that FASC preserves 6-8% more accuracy on knowledge-intensive benchmarks (MMLU, LAMA) compared to variance-based methods at 50% rank reduction, effectively enabling a 7B model to match the factual recall of a 13B uncompressed model. Our analysis reveals that \\r{ho} serves as a fundamental signal of stored knowledge, with high-\\r{ho} layers emerging only when models internalize factual associations during training.", "AI": {"tldr": "提出了一种基于知识的LLM压缩方法FASC，通过激活梯度耦合来选择关键子空间。", "motivation": "标准压缩方法如SVD忽视了对事实性知识保持的影响，仅关注高方差维度。因此引入FASC以改善资源受限硬件上大型语言模型的部署效果。", "method": "利用Fisher信息矩阵识别影响事实性知识的关键维度，并通过依赖违反评分量化激活梯度耦合来诊断存储的知识位置。", "result": "实验表明，与基于方差的方法相比，在50%压缩率下FASC在MMLU和LAMA等知识密集型基准测试中能保持6-8％更高的准确率。", "conclusion": "高依赖违反评分的层在模型训练期间内部化事实关联时出现，证明了其作为存储的知识信号的重要性。"}}
{"id": "2601.07192", "pdf": "https://arxiv.org/pdf/2601.07192", "abs": "https://arxiv.org/abs/2601.07192", "authors": ["Manzong Huang", "Chenyang Bu", "Yi He", "Xingrui Zhuo", "Xindong Wu"], "title": "Relink: Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by AAAI 2026", "summary": "Graph-based Retrieval-Augmented Generation (GraphRAG) mitigates hallucinations in Large Language Models (LLMs) by grounding them in structured knowledge. However, current GraphRAG methods are constrained by a prevailing \\textit{build-then-reason} paradigm, which relies on a static, pre-constructed Knowledge Graph (KG). This paradigm faces two critical challenges. First, the KG's inherent incompleteness often breaks reasoning paths. Second, the graph's low signal-to-noise ratio introduces distractor facts, presenting query-relevant but misleading knowledge that disrupts the reasoning process. To address these challenges, we argue for a \\textit{reason-and-construct} paradigm and propose Relink, a framework that dynamically builds a query-specific evidence graph. To tackle incompleteness, \\textbf{Relink} instantiates required facts from a latent relation pool derived from the original text corpus, repairing broken paths on the fly. To handle misleading or distractor facts, Relink employs a unified, query-aware evaluation strategy that jointly considers candidates from both the KG and latent relations, selecting those most useful for answering the query rather than relying on their pre-existence. This empowers Relink to actively discard distractor facts and construct the most faithful and precise evidence path for each query. Extensive experiments on five Open-Domain Question Answering benchmarks show that Relink achieves significant average improvements of 5.4\\% in EM and 5.2\\% in F1 over leading GraphRAG baselines, demonstrating the superiority of our proposed framework.", "AI": {"tldr": "构建查询驱动的证据图以提高GraphRAG模型性能。", "motivation": "当前GraphRAG方法依赖静态知识图谱，面临完整性不足和噪音问题，影响推理路径。", "method": "提出Relink框架，动态生成查询特定的证据图。通过从原始文本语料中推导隐含关系池来修复不完整的路径，并利用统一的查询感知评估策略选择最相关的信息。", "result": "在五个开放领域问答基准测试上，Relink分别实现了5.4% EM和5.2% F1分数的显著提升。", "conclusion": "Relink框架通过动态构建查询特定证据图，有效提高了GraphRAG模型的表现。"}}
{"id": "2601.07190", "pdf": "https://arxiv.org/pdf/2601.07190", "abs": "https://arxiv.org/abs/2601.07190", "authors": ["Nikhil Verma"], "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "categories": ["cs.AI"], "comment": "8 pages, 2 figures, 2 tables. IEEE conference format", "summary": "Large Language Model (LLM) agents struggle with long-horizon software engineering tasks due to \"Context Bloat.\" As interaction history grows, computational costs explode, latency increases, and reasoning capabilities degrade due to distraction by irrelevant past errors. Existing solutions often rely on passive, external summarization mechanisms that the agent cannot control. This paper proposes Focus, an agent-centric architecture inspired by the biological exploration strategies of Physarum polycephalum (slime mold). The Focus Agent autonomously decides when to consolidate key learnings into a persistent \"Knowledge\" block and actively withdraws (prunes) the raw interaction history. Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. With aggressive prompting that encourages frequent compression, Focus achieves 22.7% token reduction (14.9M -> 11.5M tokens) while maintaining identical accuracy (3/5 = 60% for both agents). Focus performed 6.0 autonomous compressions per task on average, with token savings up to 57% on individual instances. We demonstrate that capable models can autonomously self-regulate their context when given appropriate tools and prompting, opening pathways for cost-aware agentic systems without sacrificing task performance.", "AI": {"tldr": "提出了一种名为Focus的LLM代理架构，该架构能够自主管理其上下文以应对长时序任务中的“上下文膨胀”问题。", "motivation": "由于交互历史的增长导致计算成本增加和推理能力下降，“上下文膨胀”问题使得大型语言模型在处理长时序软件工程任务时面临挑战。现有解决方案依赖于外部被动总结机制，而不能由代理自主控制。", "method": "借鉴Physarum polycephalum的生物探索策略，Focus架构允许代理自主决定何时将关键学习内容压缩为持久性“知识”块，并主动删除原始交互历史记录。通过使用优化框架和适当的提示，对SWE-bench Lite中的五个上下文密集型实例进行了评估。", "result": "在频繁压缩的情况下，Focus实现了22.7%的令牌减少（从14.9M减至11.5M），同时保持了相同的准确性。每个任务平均执行6次自主压缩，并且在个别实例上节省了高达57%的令牌。", "conclusion": "结果表明，当给定适当的工具和提示时，有能力的模型可以自我调节其上下文，而不牺牲任务性能，从而为成本意识型代理系统开辟新的途径。"}}
{"id": "2601.07186", "pdf": "https://arxiv.org/pdf/2601.07186", "abs": "https://arxiv.org/abs/2601.07186", "authors": ["Zainab Altaweel", "Mohaiminul Al Nahian", "Jake Juettner", "Adnan Siraj Rakin", "Shiqi Zhang"], "title": "PROTEA: Securing Robot Task Planning and Execution", "categories": ["cs.RO"], "comment": null, "summary": "Robots need task planning methods to generate action sequences for complex tasks. Recent work on adversarial attacks has revealed significant vulnerabilities in existing robot task planners, especially those built on foundation models. In this paper, we aim to address these security challenges by introducing PROTEA, an LLM-as-a-Judge defense mechanism, to evaluate the security of task plans. PROTEA is developed to address the dimensionality and history challenges in plan safety assessment. We used different LLMs to implement multiple versions of PROTEA for comparison purposes. For systemic evaluations, we created a dataset containing both benign and malicious task plans, where the harmful behaviors were injected at varying levels of stealthiness. Our results provide actionable insights for robotic system practitioners seeking to enhance robustness and security of their task planning systems. Details, dataset and demos are provided: https://protea-secure.github.io/PROTEA/", "AI": {"tldr": "本文提出了PROTEA，一种基于LLM的判断机制，用于评估机器人任务计划的安全性。", "motivation": "现有的机器人任务规划器在对抗攻击下存在显著漏洞，尤其是那些基于基础模型构建的。因此，需要一种新的安全防御方法来解决这些问题。", "method": "通过使用不同的大型语言模型（LLM）实现PROTEA的不同版本，并创建一个包含良性与恶意任务计划的数据集进行系统性评估。", "result": "实验结果提供了增强机器人系统任务规划安全性的重要见解。", "conclusion": "PROTEA为机器人系统的任务规划安全性和鲁棒性的提升提供了一个有效的解决方案。"}}
{"id": "2601.07185", "pdf": "https://arxiv.org/pdf/2601.07185", "abs": "https://arxiv.org/abs/2601.07185", "authors": ["Shawn Li", "Chenxiao Yu", "Zhiyu Ni", "Hao Li", "Charith Peris", "Chaowei Xiao", "Yue Zhao"], "title": "Defenses Against Prompt Attacks Learn Surface Heuristics", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly deployed in security-sensitive applications, where they must follow system- or developer-specified instructions that define the intended task behavior, while completing benign user requests. When adversarial instructions appear in user queries or externally retrieved content, models may override intended logic. Recent defenses rely on supervised fine-tuning with benign and malicious labels. Although these methods achieve high attack rejection rates, we find that they rely on narrow correlations in defense data rather than harmful intent, leading to systematic rejection of safe inputs. We analyze three recurring shortcut behaviors induced by defense fine-tuning. \\emph{Position bias} arises when benign content placed later in a prompt is rejected at much higher rates; across reasoning benchmarks, suffix-task rejection rises from below \\textbf{10\\%} to as high as \\textbf{90\\%}. \\emph{Token trigger bias} occurs when strings common in attack data raise rejection probability even in benign contexts; inserting a single trigger token increases false refusals by up to \\textbf{50\\%}. \\emph{Topic generalization bias} reflects poor generalization beyond the defense data distribution, with defended models suffering test-time accuracy drops of up to \\textbf{40\\%}. These findings suggest that current prompt-injection defenses frequently respond to attack-like surface patterns rather than the underlying intent. We introduce controlled diagnostic datasets and a systematic evaluation across two base models and multiple defense pipelines, highlighting limitations of supervised fine-tuning for reliable LLM security.", "AI": {"tldr": "分析和评估了针对大型语言模型（LLM）的提示注入攻击防御方法，并发现了几种由防御微调引发的表面行为偏见。", "motivation": "当前的语言模型在安全敏感的应用程序中面临着提示注入攻击的风险，尽管现有防御措施能够有效抵抗此类攻击，但它们往往依赖于数据中的窄关联而非有害意图识别。", "method": "通过引入有控制的诊断数据集和系统评估方法来分析三种由防御微调引起的表面行为偏见：位置偏差、令牌触发器偏差及话题泛化偏差。测试了两种基础模型与多种防御管道的效果。", "result": "发现当前防御措施容易受到攻击样式的表层模式影响，而非深层意图识别；例如，在提示中加入恶意字符串会导致错误拒绝率大幅上升（最多50%）；并且在测试数据分布之外的表现下降高达40%。", "conclusion": "现有基于监督微调的大型语言模型安全防护方法存在局限性，难以可靠地防御攻击。未来研究应该着眼于开发更深层次理解并准确识别有害意图的方法。"}}
{"id": "2601.07182", "pdf": "https://arxiv.org/pdf/2601.07182", "abs": "https://arxiv.org/abs/2601.07182", "authors": ["Ruiyi Ding", "Yongxuan Lv", "Xianhui Meng", "Jiahe Song", "Chao Wang", "Chen Jiang", "Yuan Cheng"], "title": "PRPO: Aligning Process Reward with Outcome Reward in Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 2 figures", "summary": "Policy optimization for large language models often suffers from sparse reward signals in multi-step reasoning tasks. Critic-free methods like GRPO assign a single normalized outcome reward to all tokens, providing limited guidance for intermediate reasoning . While Process Reward Models (PRMs) offer dense feedback, they risk premature collapse when used alone, as early low-reward tokens can drive policies toward truncated outputs. We introduce Process Relative Policy Optimization (PRPO), which combines outcome reliability with process-level guidance in a critic-free framework. PRPO segments reasoning sequences based on semantic clues, normalizes PRM scores into token-level advantages, and aligns their distribution with outcome advantages through location-parameter shift. On MATH500, PRPO improves Qwen2.5-Math-1.5B accuracy from 61.2% to 64.4% over GRPO using only eight rollouts and no value network, demonstrating efficient fine-grained credit assignment within critic-free optimization.", "AI": {"tldr": "该论文提出了PRPO方法，旨在通过结合过程奖励和结果奖励来优化策略，并在MATH500数据集上进行了实验验证。", "motivation": "大型语言模型的策略优化经常面临多步推理任务中的稀疏奖励信号问题。GRPO等无批评者的方法只提供单一的结果回报，而PRMs虽然能提供密集反馈但容易导致策略崩溃。因此需要一种能够结合过程和结果指导的新方法。", "method": "PRPO通过基于语义线索分割推理序列、将PRM分数转换为令牌优势并调整其分布来实现过程奖励与结果奖励的对齐，从而在无批评者框架中优化策略。", "result": "在MATH500数据集上，使用GRPO作为基准模型，采用PRPO后Qwen2.5-Math-1.5B的准确率从61.2%提升至64.4%，且仅需八次滚动和不依赖价值网络。", "conclusion": "PRPO方法成功地实现了过程奖励与结果奖励之间的对齐，提高了策略优化的效果，证明了在无批评者框架中实现细粒度信用分配的可行性。"}}
{"id": "2601.07181", "pdf": "https://arxiv.org/pdf/2601.07181", "abs": "https://arxiv.org/abs/2601.07181", "authors": ["Yichun Zhang", "Xiangwu Guo", "Yauhong Goh", "Jessica Hu", "Zhiheng Chen", "Xin Wang", "Difei Gao", "Mike Zheng Shou"], "title": "ShowUI-Aloha: Human-Taught GUI Agent", "categories": ["cs.CV"], "comment": "13 Pages, 16 Figures", "summary": "Graphical User Interfaces (GUIs) are central to human-computer interaction, yet automating complex GUI tasks remains a major challenge for autonomous agents, largely due to a lack of scalable, high-quality training data. While recordings of human demonstrations offer a rich data source, they are typically long, unstructured, and lack annotations, making them difficult for agents to learn from.To address this, we introduce ShowUI-Aloha, a comprehensive pipeline that transforms unstructured, in-the-wild human screen recordings from desktop environments into structured, actionable tasks. Our framework includes four key components: A recorder that captures screen video along with precise user interactions like mouse clicks, keystrokes, and scrolls. A learner that semantically interprets these raw interactions and the surrounding visual context, translating them into descriptive natural language captions. A planner that reads the parsed demonstrations, maintains task states, and dynamically formulates the next high-level action plan based on contextual reasoning. An executor that faithfully carries out these action plans at the OS level, performing precise clicks, drags, text inputs, and window operations with safety checks and real-time feedback. Together, these components provide a scalable solution for collecting and parsing real-world human data, demonstrating a viable path toward building general-purpose GUI agents that can learn effectively from simply observing humans.", "AI": {"tldr": "展示UI-Aloha通过从桌面环境的无结构的人类屏幕记录中创建可操作的任务，开发了一种用于训练通用GUI代理的方法。", "motivation": "自动化复杂的GUI任务对于自主代理来说是一个重大挑战，主要是由于缺乏可扩展、高质量的数据集。人类演示记录可以提供丰富的数据源但通常不被直接使用。", "method": "通过引入包含录制器、学习者、规划者和执行者的四个关键组件的完整管道来解决这一问题，从而将无结构的人类屏幕记录转换为结构化任务。", "result": "展示了构建能够从观察人类行为中有效学习的一般用途GUI代理的方法", "conclusion": "该方法提供了一种可扩展的解决方案以收集和解析真实世界中的数据，并开辟了建设通用GUI代理的新途径"}}
{"id": "2601.07178", "pdf": "https://arxiv.org/pdf/2601.07178", "abs": "https://arxiv.org/abs/2601.07178", "authors": ["Weilin Zhou", "Zonghao Ying", "Chunlei Meng", "Jiahui Liu", "Hengyang Zhou", "Quanchen Zou", "Deyue Zhang", "Dongdong Yang", "Xiangzheng Zhang"], "title": "DIVER: Dynamic Iterative Visual Evidence Reasoning for Multimodal Fake News Detection", "categories": ["cs.CV", "cs.AI"], "comment": "13 pages", "summary": "Multimodal fake news detection is crucial for mitigating adversarial misinformation. Existing methods, relying on static fusion or LLMs, face computational redundancy and hallucination risks due to weak visual foundations. To address this, we propose DIVER (Dynamic Iterative Visual Evidence Reasoning), a framework grounded in a progressive, evidence-driven reasoning paradigm. DIVER first establishes a strong text-based baseline through language analysis, leveraging intra-modal consistency to filter unreliable or hallucinated claims. Only when textual evidence is insufficient does the framework introduce visual information, where inter-modal alignment verification adaptively determines whether deeper visual inspection is necessary. For samples exhibiting significant cross-modal semantic discrepancies, DIVER selectively invokes fine-grained visual tools (e.g., OCR and dense captioning) to extract task-relevant evidence, which is iteratively aggregated via uncertainty-aware fusion to refine multimodal reasoning. Experiments on Weibo, Weibo21, and GossipCop demonstrate that DIVER outperforms state-of-the-art baselines by an average of 2.72\\%, while optimizing inference efficiency with a reduced latency of 4.12 s.", "AI": {"tldr": "DIVER是一种用于多模态假新闻检测的框架，通过动态迭代视觉证据推理来提高准确性和效率。", "motivation": "现有方法依赖静态融合或大型语言模型，在计算冗余和幻觉风险方面存在问题。因此，提出了一种基于逐步、证据驱动推理的新框架以应对挑战。", "method": "DIVER首先建立一个强大的文本基础线，并通过跨模态一致性过滤不可靠的声明。当文本依据不足时，引入视觉信息进行更深入的检查。对于存在重大语义差异的情况，使用精细的视觉工具提取相关证据，并迭代聚合这些证据以提高多模态推理。", "result": "实验显示DIVER在Weibo、Weibo21和GossipCop数据集上超过了最先进的基线方法2.72%，同时优化了推断效率，降低了4.12秒的延迟。", "conclusion": "通过动态迭代视觉证据推理，DIVER不仅提高了多模态假新闻检测的准确性，还减少了计算资源消耗。"}}
{"id": "2601.07177", "pdf": "https://arxiv.org/pdf/2601.07177", "abs": "https://arxiv.org/abs/2601.07177", "authors": ["Mingxiang Tao", "Yu Tian", "Wenxuan Tu", "Yue Yang", "Xue Yang", "Xiangyan Tang"], "title": "Safe-FedLLM: Delving into the Safety of Federated Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Federated learning (FL) addresses data privacy and silo issues in large language models (LLMs). Most prior work focuses on improving the training efficiency of federated LLMs. However, security in open environments is overlooked, particularly defenses against malicious clients. To investigate the safety of LLMs during FL, we conduct preliminary experiments to analyze potential attack surfaces and defensible characteristics from the perspective of Low-Rank Adaptation (LoRA) weights. We find two key properties of FL: 1) LLMs are vulnerable to attacks from malicious clients in FL, and 2) LoRA weights exhibit distinct behavioral patterns that can be filtered through simple classifiers. Based on these properties, we propose Safe-FedLLM, a probe-based defense framework for federated LLMs, constructing defenses across three dimensions: Step-Level, Client-Level, and Shadow-Level. The core concept of Safe-FedLLM is to perform probe-based discrimination on the LoRA weights locally trained by each client during FL, treating them as high-dimensional behavioral features and using lightweight classification models to determine whether they possess malicious attributes. Extensive experiments demonstrate that Safe-FedLLM effectively enhances the defense capability of federated LLMs without compromising performance on benign data. Notably, our method effectively suppresses malicious data impact without significant impact on training speed, and remains effective even with many malicious clients. Our code is available at: https://github.com/dmqx/Safe-FedLLM.", "AI": {"tldr": "研究联邦学习中大型语言模型的安全性，提出了一种基于探针的防御框架Safe-FedLLM。", "motivation": "解决联邦学习环境下大语言模型的安全问题，特别是对抗恶意客户端攻击。", "method": "通过分析LoRA权重在FL中的行为模式，设计一种探针式的分类方法来识别潜在的恶意客户端。", "result": "实验表明Safe-FedLLM能够有效提高联邦学习中大语言模型的安全性，且不影响正常训练速度和性能。", "conclusion": "提出的方法可以在存在大量恶意客户端的情况下仍然保持有效性，并且不对良性数据的训练造成显著影响。"}}
{"id": "2601.07172", "pdf": "https://arxiv.org/pdf/2601.07172", "abs": "https://arxiv.org/abs/2601.07172", "authors": ["Mehran Moghadam", "Sercan Aygun", "M. Hassan Najafi"], "title": "TranSC: Hardware-Aware Design of Transcendental Functions Using Stochastic Logic", "categories": ["cs.ET", "cs.RO", "eess.SY"], "comment": "12 pages", "summary": "The hardware-friendly implementation of transcendental functions remains a longstanding challenge in design automation. These functions, which cannot be expressed as finite combinations of algebraic operations, pose significant complexity in digital circuit design. This study introduces a novel approach, TranSC, that utilizes stochastic computing (SC) for lightweight yet accurate implementation of transcendental functions. Building on established SC techniques, our method explores alternative random sources-specifically, quasi-random Van der Corput low-discrepancy (LD) sequences-instead of conventional pseudo-randomness. This shift enhances both the accuracy and efficiency of SC-based computations. We validate our approach through extensive experiments on various function types, including trigonometric, hyperbolic, and activation functions. The proposed design approach significantly reduces MSE by up to 98% compared to the state-of-the-art solutions while reducing hardware area, power consumption, and energy usage by 33%, 72%, and 64%, respectively.", "AI": {"tldr": "介绍一种使用随机逻辑设计超越函数的新方法TranSC，该方法通过采用准随机Van der Corput低离散度序列提高了准确性和效率。", "motivation": "在数字电路设计中实现硬件友好的超越函数是一个长期存在的挑战。这些不能用有限的代数运算表示的函数带来了显著的设计复杂性。", "method": "TranSC利用随机计算（SC），采用准随机Van der Corput低离散度序列代替传统伪随机方法，提高准确性和效率。", "result": "通过大量实验验证了该方法的有效性，在各种函数类型中MSE降低高达98%，同时硬件面积、功耗和能量使用分别减少33%、72%和64%。", "conclusion": "TranSC提供了一种新的超越函数设计方法，显著提高了准确性和效率，并减少了硬件资源消耗。"}}
{"id": "2601.07163", "pdf": "https://arxiv.org/pdf/2601.07163", "abs": "https://arxiv.org/abs/2601.07163", "authors": ["Shu Shen", "C. L. Philip Chen", "Tong Zhang"], "title": "Test-time Adaptive Hierarchical Co-enhanced Denoising Network for Reliable Multimodal Classification", "categories": ["cs.CV"], "comment": "14 pages,9 figures, 8 tables", "summary": "Reliable learning on low-quality multimodal data is a widely concerning issue, especially in safety-critical applications. However, multimodal noise poses a major challenge in this domain and leads existing methods to suffer from two key limitations. First, they struggle to reliably remove heterogeneous data noise, hindering robust multimodal representation learning. Second, they exhibit limited adaptability and generalization when encountering previously unseen noise. To address these issues, we propose Test-time Adaptive Hierarchical Co-enhanced Denoising Network (TAHCD). On one hand, TAHCD introduces the Adaptive Stable Subspace Alignment and Sample-Adaptive Confidence Alignment to reliably remove heterogeneous noise. They account for noise at both global and instance levels and enable jointly removal of modality-specific and cross-modality noise, achieving robust learning. On the other hand, TAHCD introduces test-time cooperative enhancement, which adaptively updates the model in response to input noise in a label-free manner, improving adaptability and generalization. This is achieved by collaboratively enhancing the joint removal process of modality-specific and cross-modality noise across global and instance levels according to sample noise. Experiments on multiple benchmarks demonstrate that the proposed method achieves superior classification performance, robustness, and generalization compared with state-of-the-art reliable multimodal learning approaches.", "AI": {"tldr": "提出了一种测试时自适应的层级协同去噪网络（TAHCD），以提高低质量多模态数据分类的可靠性。", "motivation": "现有方法在处理低质量多模态数据时存在去除异质噪声困难及泛化能力不足的问题，该研究旨在解决这些问题。", "method": "提出了一种自适应稳定子空间对齐和样本自适应置信度对齐的方法来去除噪声，并通过无标签的测试时协同增强方式提高模型在新噪声环境中的适应性和泛化性。", "result": "实验显示所提方法相比现有的可靠多模态学习方法具有更好的分类性能，鲁棒性和泛化能力。", "conclusion": "TAHCD能有效提升低质量多模态数据上的分类任务的可靠性。"}}
{"id": "2601.07160", "pdf": "https://arxiv.org/pdf/2601.07160", "abs": "https://arxiv.org/abs/2601.07160", "authors": ["Xinzi Cao", "Jianyang Zhai", "Pengfei Li", "Zhiheng Hu", "Cen Yan", "Bingxu Mu", "Guanghuan Fang", "Bin She", "Jiayu Li", "Yihan Su", "Dongyang Tao", "Xiansong Huang", "Fan Xu", "Feidiao Yang", "Yao Lu", "Chang-Dong Wang", "Yutong Lu", "Weicheng Xue", "Bin Zhou", "Yonghong Tian"], "title": "AscendKernelGen: A Systematic Study of LLM-Based Kernel Generation for Neural Processing Units", "categories": ["cs.AI", "cs.LG"], "comment": "33 pages,7 figures,16 tables", "summary": "To meet the ever-increasing demand for computational efficiency, Neural Processing Units (NPUs) have become critical in modern AI infrastructure. However, unlocking their full potential requires developing high-performance compute kernels using vendor-specific Domain-Specific Languages (DSLs), a task that demands deep hardware expertise and is labor-intensive. While Large Language Models (LLMs) have shown promise in general code generation, they struggle with the strict constraints and scarcity of training data in the NPU domain. Our preliminary study reveals that state-of-the-art general-purpose LLMs fail to generate functional complex kernels for Ascend NPUs, yielding a near-zero success rate. To address these challenges, we propose AscendKernelGen, a generation-evaluation integrated framework for NPU kernel development. We introduce Ascend-CoT, a high-quality dataset incorporating chain-of-thought reasoning derived from real-world kernel implementations, and KernelGen-LM, a domain-adaptive model trained via supervised fine-tuning and reinforcement learning with execution feedback. Furthermore, we design NPUKernelBench, a comprehensive benchmark for assessing compilation, correctness, and performance across varying complexity levels. Experimental results demonstrate that our approach significantly bridges the gap between general LLMs and hardware-specific coding. Specifically, the compilation success rate on complex Level-2 kernels improves from 0% to 95.5% (Pass@10), while functional correctness achieves 64.3% compared to the baseline's complete failure. These results highlight the critical role of domain-specific reasoning and rigorous evaluation in automating accelerator-aware code generation.", "AI": {"tldr": "提出了AscendKernelGen框架，该框架使用基于大语言模型的生成和评估集成方法来开发神经处理单元(NPU)计算内核。", "motivation": "现代AI基础设施对计算效率的需求不断提高，而要充分发挥NPUs的潜力，则需要使用特定供应商提供的领域专用语言(DSL)来编写高性能计算内核。然而，这项任务既耗时又需要深厚的专业知识。尽管大语言模型在通用代码生成方面显示出巨大潜力，但在NPU领域中面临着严格的约束条件和训练数据稀缺的问题。", "method": "提出了一种结合了Ascend-CoT高质量链式推理数据集、KernelGen-LM通过监督微调和基于执行反馈的强化学习来实现域适应模型的方法，并设计了一个评估编译成功率及功能正确性的NPU内核基准测试。", "result": "实验结果表明，该方法显著改善了通用大语言模型向硬件特定代码生成转化的表现，对于复杂程度较高的Level-2级内核，编译成功率达到95.5%，而功能正确性达到了64.3%。", "conclusion": "研究突显了领域特定推理以及严格的评估在自动化加速器感知代码生成中的关键作用。"}}
{"id": "2601.07155", "pdf": "https://arxiv.org/pdf/2601.07155", "abs": "https://arxiv.org/abs/2601.07155", "authors": ["Ijun Jang", "Jewon Yeom", "Juan Yeo", "Hyunggu Lim", "Taesup Kim"], "title": "Stable On-Policy Distillation through Adaptive Target Reformulation", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 5 figures", "summary": "Knowledge distillation (KD) is a widely adopted technique for transferring knowledge from large language models to smaller student models; however, conventional supervised KD often suffers from a distribution mismatch between training and inference. While on-policy KD approaches attempt to mitigate this issue by learning directly from student-generated outputs, they frequently encounter training instabilities because the distributional gap between the novice student and the expert teacher is often too wide to bridge directly. These challenges manifest as pathological gradients in forward KL objectives or diversity collapse in reverse KL regimes. To address these limitations, we propose Veto, an objective-level reformulation that constructs a geometric bridge in the logit space. Unlike prior methods that mix data samples, Veto creates an intermediate target distribution that promotes alignment between the teacher and the student. By introducing a tunable parameter beta, Veto serves as an Adaptive Gradient Veto that stabilizes optimization by suppressing harmful gradients on low-confidence tokens, while simultaneously acting as a Decisiveness Knob to balance reward-driven performance with output diversity. Extensive experiments across various reasoning and generation tasks demonstrate that Veto consistently outperforms supervised fine-tuning and existing on-policy baselines.", "AI": {"tldr": "提出了一种新的知识蒸馏方法Veto，以解决传统监督KD在训练和推理分布不匹配的问题。", "motivation": "传统的监督式知识蒸馏由于训练和推理分布之间的差异，在实际应用中遇到了稳定性问题。为了解决这一挑战，研究者们试图通过调整目标来缓解这些问题，但现有的方法效果并不理想。", "method": "Veto 方法通过在对数空间构建几何桥梁，并引入可调参数β，既抑制了有害的低置信度标记梯度，又平衡了奖励驱动性能与输出多样性。这种方法不需要混合数据样本，而是创造了一个中间的目标分布来促进教师和学生之间的对齐。", "result": "实验结果表明，Veto 在各种推理和生成任务上均优于监督微调和其他在策略基线方法。", "conclusion": "通过引入目标改革的策略，研究者们成功地提高了知识蒸馏过程中的稳定性和性能。"}}
{"id": "2601.07154", "pdf": "https://arxiv.org/pdf/2601.07154", "abs": "https://arxiv.org/abs/2601.07154", "authors": ["Daniel Hong", "James Tribble", "Hao Wang", "Chaoyi Zhou", "Ashish Bastola", "Siyu Huang", "Abolfazl Razi"], "title": "Motion Focus Recognition in Fast-Moving Egocentric Video", "categories": ["cs.CV"], "comment": null, "summary": "From Vision-Language-Action (VLA) systems to robotics, existing egocentric datasets primarily focus on action recognition tasks, while largely overlooking the inherent role of motion analysis in sports and other fast-movement scenarios. To bridge this gap, we propose a real-time motion focus recognition method that estimates the subject's locomotion intention from any egocentric video. Our approach leverages the foundation model for camera pose estimation and introduces system-level optimizations to enable efficient and scalable inference. Evaluated on a collected egocentric action dataset, our method achieves real-time performance with manageable memory consumption through a sliding batch inference strategy. This work makes motion-centric analysis practical for edge deployment and offers a complementary perspective to existing egocentric studies on sports and fast-movement activities.", "AI": {"tldr": "提出了一种实时运动焦点识别方法，从任何第一人称视频中估计主体的移动意图。", "motivation": "现有的一人称数据集主要集中在动作识别任务上，忽略了运动分析在体育和其他快速运动场景中的重要作用。为了填补这一空白，本文提出了一个能够实现快速运动焦点识别的方法。", "method": "利用基础模型进行摄像机姿态估计，并引入系统级优化以实现实时推断和可扩展性。通过滑动批量推理策略实现了实时性能并控制了内存消耗。", "result": "在收集的一人称动作数据集上进行了评估，该方法实现了实时性能并且内存消耗可控。", "conclusion": "这项工作使得基于运动的分析对于边缘部署更加实用，并为体育和快速移动活动提供了一个补充视角。"}}
{"id": "2601.07153", "pdf": "https://arxiv.org/pdf/2601.07153", "abs": "https://arxiv.org/abs/2601.07153", "authors": ["Genta Indra Winata", "David Anugraha", "Patrick Amadeus Irawan", "Anirban Das", "Haneul Yoo", "Paresh Dashore", "Shreyas Kulkarni", "Ruochen Zhang", "Haruki Sakajo", "Frederikus Hudi", "Anaelia Ovalle", "Syrielle Montariol", "Felix Gaschi", "Michael Anugraha", "Rutuj Ravindra Puranik", "Zawad Hayat Ahmed", "Adril Putra Merin", "Emmanuele Chersoni"], "title": "Can Large Language Models Understand, Reason About, and Generate Code-Switched Text?", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint", "summary": "Code-switching is a pervasive phenomenon in multilingual communication, yet the robustness of large language models (LLMs) in mixed-language settings remains insufficiently understood. In this work, we present a comprehensive evaluation of LLM capabilities in understanding, reasoning over, and generating code-switched text. We introduce CodeMixQA a novel benchmark with high-quality human annotations, comprising 16 diverse parallel code-switched language-pair variants that span multiple geographic regions and code-switching patterns, and include both original scripts and their transliterated forms. Using this benchmark, we analyze the reasoning behavior of LLMs on code-switched question-answering tasks, shedding light on how models process and reason over mixed-language inputs. We further conduct a systematic evaluation of LLM-generated synthetic code-switched text, focusing on both naturalness and semantic fidelity, and uncover key limitations in current generation capabilities. Our findings reveal persistent challenges in both reasoning and generation under code-switching conditions and provide actionable insights for building more robust multilingual LLMs. We release the dataset and code as open source.", "AI": {"tldr": "该论文评估了大型语言模型在处理代码混合文本时的理解、推理和生成能力。", "motivation": "探讨多语言环境中大型语言模型的能力，特别是在理解和生成代码混用文本方面的不足。", "method": "引入了一个名为CodeMixQA的新基准测试集，并使用高质量的人类注释进行了全面评估。此基准涵盖16种不同的平行代码混合语言对变体，包括多种地理区域和编码转换模式。", "result": "揭示了当前模型在处理代码混用文本时的推理与生成能力存在不足，特别是在自然度和语义忠实性方面。", "conclusion": "发现大型语言模型在理解和生成代码混用文本方面的持续挑战，并提供了构建更健壮多语言模型的实际见解。"}}
{"id": "2601.07149", "pdf": "https://arxiv.org/pdf/2601.07149", "abs": "https://arxiv.org/abs/2601.07149", "authors": ["Zhaoyan Li", "Hang Lei", "Yujia Wang", "Lanbo Liu", "Hao Liu", "Liang Yu"], "title": "Rewarding Creativity: A Human-Aligned Generative Reward Model for Reinforcement Learning in Storytelling", "categories": ["cs.AI", "cs.CL"], "comment": ":I.2.0", "summary": "While Large Language Models (LLMs) can generate fluent text, producing high-quality creative stories remains challenging. Reinforcement Learning (RL) offers a promising solution but faces two critical obstacles: designing reliable reward signals for subjective storytelling quality and mitigating training instability. This paper introduces the Reinforcement Learning for Creative Storytelling (RLCS) framework to systematically address both challenges. First, we develop a Generative Reward Model (GenRM) that provides multi-dimensional analysis and explicit reasoning about story preferences, trained through supervised fine-tuning on demonstrations with reasoning chains distilled from strong teacher models, followed by GRPO-based refinement on expanded preference data. Second, we introduce an entropy-based reward shaping strategy that dynamically prioritizes learning on confident errors and uncertain correct predictions, preventing overfitting on already-mastered patterns. Experiments demonstrate that GenRM achieves 68\\% alignment with human creativity judgments, and RLCS significantly outperforms strong baselines including Gemini-2.5-Pro in overall story quality. This work provides a practical pipeline for applying RL to creative domains, effectively navigating the dual challenges of reward modeling and training stability.", "AI": {"tldr": "提出了一种用于强化学习的创造性故事生成框架RLCS，通过多维度奖励模型和熵基奖励策略改进了故事质量。", "motivation": "大型语言模型难以生成高质量的故事。为解决这个问题，该研究旨在提供更可靠的故事质量反馈，并提高训练稳定性。", "method": "开发了一种基于生成的奖励模型GenRM，结合监督微调与GRPO优化来细化偏好数据；采用了熵基策略以动态优先学习自信错误和不确定正确预测，防止过度拟合。", "result": "实验表明，GenRM在人类创造力判断中达到了68%的一致性，RLCS框架显著优于包括Gemini-2.5-Pro在内的基准模型，在故事质量方面表现更优。", "conclusion": "该研究提供了一种实用的强化学习应用到创造性领域的管道，成功应对了奖励建模和训练稳定性的双重挑战。"}}
{"id": "2601.07148", "pdf": "https://arxiv.org/pdf/2601.07148", "abs": "https://arxiv.org/abs/2601.07148", "authors": ["Zhengxiang Wang", "Zeyu Dong"], "title": "Measuring Iterative Temporal Reasoning with TimePuzzles", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce TimePuzzles, a constraint-based date inference task for evaluating iterative temporal reasoning. Each puzzle combines factual temporal anchors with (cross-cultural) calendar relations, admits one or multiple valid solution dates, and is algorithmically generated for controlled, dynamic, and continual evaluation. Across 13 diverse LLMs, TimePuzzles well distinguishes their iterative temporal reasoning capabilities and remains challenging without tools: GPT-5 reaches only 49.3% accuracy and all other models stay below 31%, despite the dataset's simplicity. Web search consistently yields substantial gains and using code interpreter shows mixed effects, but all models perform much better when constraints are rewritten with explicit dates, revealing a gap in reliable tool use. Overall, TimePuzzles presents a simple, cost-effective diagnostic for tool-augmented iterative temporal reasoning.", "AI": {"tldr": "介绍了TimePuzzles，一种用于评估迭代时间推理的能力任务。", "motivation": "为了衡量大型语言模型的迭代时间推理能力，并通过一个简单的数据集来诊断工具增强的时间推理。", "method": "提出了基于约束的日期推断任务TimePuzzles。该任务结合了事实性的时间锚点和跨文化的日历关系，可以生成算法化的、动态的评估题。", "result": "在13个不同的大型语言模型上进行测试时，GPT-5仅达到了49.3%的准确率，其他所有模型都低于31%，而使用网络搜索则能够显著提高准确性。然而，在重新编写约束条件为明确日期之后，所有模型的表现都有所提升。", "conclusion": "TimePuzzles提供了一种简单有效的诊断工具增强迭代时间推理的方法"}}
{"id": "2601.07143", "pdf": "https://arxiv.org/pdf/2601.07143", "abs": "https://arxiv.org/abs/2601.07143", "authors": ["Hao Wang", "Wenhui Zhu", "Shao Tang", "Zhipeng Wang", "Xuanzhao Dong", "Xin Li", "Xiwen Chen", "Ashish Bastola", "Xinhao Huang", "Yalin Wang", "Abolfazl Razi"], "title": "EZBlender: Efficient 3D Editing with Plan-and-ReAct Agent", "categories": ["cs.HC"], "comment": null, "summary": "As a cornerstone of the modern digital economy, 3D modeling and rendering demand substantial resources and manual effort when scene editing is performed in the traditional manner. Despite recent progress in VLM-based agents for 3D editing, the fundamental trade-off between editing precision and agent responsiveness remains unresolved. To overcome these limitations, we present EZBlender, a Blender agent with a hybrid framework that combines planning-based task decomposition and reactive local autonomy for efficient human AI collaboration and semantically faithful 3D editing. Specifically, this unexplored Plan-and-ReAct design not only preserves editing quality but also significantly reduces latency and computational cost. To further validate the efficiency and effectiveness of the proposed edge-autonomy architecture, we construct a dedicated multi-tasking benchmark that has not been systematically investigated in prior research. In addition, we provide a comprehensive analysis of language model preference, system responsiveness, and economic efficiency.", "AI": {"tldr": "提出EZBlender，一种结合规划和反应式自主性的高效三维编辑工具", "motivation": "解决传统三维场景编辑中资源消耗大、人工劳动强度大的问题，并改进现有的VLM代理在精确性和响应性之间的权衡不足", "method": "设计了一个混合框架的Blender代理，该框架采用计划为基础的任务分解与反应式的局部自治相结合的方式进行高效的人机协作和语义保真的3D编辑", "result": "构建了多任务基准以验证所提出的边缘自主架构的有效性和效率，并分析了语言模型偏好、系统响应性及经济效益", "conclusion": "EZBlender通过其独特的Plan-and-ReAct设计，在保持编辑质量的同时，显著减少了延迟和计算成本"}}
{"id": "2601.07136", "pdf": "https://arxiv.org/pdf/2601.07136", "abs": "https://arxiv.org/abs/2601.07136", "authors": ["Daniel Liu", "Krishna Upadhyay", "Vinaik Chhetri", "A. B. Siddique", "Umar Farooq"], "title": "A Large-Scale Study on the Development and Issues of Multi-Agent AI Systems", "categories": ["cs.SE", "cs.AI"], "comment": "8 pages, 8 figures, IEEE BigData Workshop on Software Engineering for Agentic AI 2025", "summary": "The rapid emergence of multi-agent AI systems (MAS), including LangChain, CrewAI, and AutoGen, has shaped how large language model (LLM) applications are developed and orchestrated. However, little is known about how these systems evolve and are maintained in practice. This paper presents the first large-scale empirical study of open-source MAS, analyzing over 42K unique commits and over 4.7K resolved issues across eight leading systems. Our analysis identifies three distinct development profiles: sustained, steady, and burst-driven. These profiles reflect substantial variation in ecosystem maturity. Perfective commits constitute 40.8% of all changes, suggesting that feature enhancement is prioritized over corrective maintenance (27.4%) and adaptive updates (24.3%). Data about issues shows that the most frequent concerns involve bugs (22%), infrastructure (14%), and agent coordination challenges (10%). Issue reporting also increased sharply across all frameworks starting in 2023. Median resolution times range from under one day to about two weeks, with distributions skewed toward fast responses but a minority of issues requiring extended attention. These results highlight both the momentum and the fragility of the current ecosystem, emphasizing the need for improved testing infrastructure, documentation quality, and maintenance practices to ensure long-term reliability and sustainability.", "AI": {"tldr": "本论文进行了大规模的实证研究，分析了八种领先的多代理人工智能系统的42000多个独特提交和4700多个已解决的问题。", "motivation": "尽管多代理AI系统（MAS）的发展迅速，但其实际开发和维护过程知之甚少。因此本论文旨在填补这一空白，通过大规模实证研究来理解这些系统的演化和发展情况。", "method": "作者分析了八种领先的开放源代码MAS的超过42000个独特提交和超过4700个已解决问题的数据集，识别出三种不同的开发模式，并对问题报告进行了统计。", "result": "该研究发现三种发展概况：持续型、稳定型以及爆发驱动型。此外，完善性提交占所有更改的40.8%，表明功能改进优先于更正性维护和适应性更新。最常见的问题是bug、基础设施及代理协调挑战。2023年后所有框架的问题报告显著增加。", "conclusion": "研究结果强调了当前生态系统的发展势头与脆弱性，指出需要改善测试基础设施、文档质量和维护实践以确保长期可靠性和可持续性。"}}
{"id": "2601.07134", "pdf": "https://arxiv.org/pdf/2601.07134", "abs": "https://arxiv.org/abs/2601.07134", "authors": ["James Calo", "Benny Lo"], "title": "Proof of Reasoning for Privacy Enhanced Federated Blockchain Learning at the Edge", "categories": ["cs.CR", "cs.CV", "cs.LG"], "comment": "8 Pages, 5 figues, 9 tables, journal paper", "summary": "Consensus mechanisms are the core of any blockchain system. However, the majority of these mechanisms do not target federated learning directly nor do they aid in the aggregation step. This paper introduces Proof of Reasoning (PoR), a novel consensus mechanism specifically designed for federated learning using blockchain, aimed at preserving data privacy, defending against malicious attacks, and enhancing the validation of participating networks. Unlike generic blockchain consensus mechanisms commonly found in the literature, PoR integrates three distinct processes tailored for federated learning. Firstly, a masked autoencoder (MAE) is trained to generate an encoder that functions as a feature map and obfuscates input data, rendering it resistant to human reconstruction and model inversion attacks. Secondly, a downstream classifier is trained at the edge, receiving input from the trained encoder. The downstream network's weights, a single encoded datapoint, the network's output and the ground truth are then added to a block for federated aggregation. Lastly, this data facilitates the aggregation of all participating networks, enabling more complex and verifiable aggregation methods than previously possible. This three-stage process results in more robust networks with significantly reduced computational complexity, maintaining high accuracy by training only the downstream classifier at the edge. PoR scales to large IoT networks with low latency and storage growth, and adapts to evolving data, regulations, and network conditions.", "AI": {"tldr": "本文提出了一种名为Proof of Reasoning (PoR)的新共识机制，旨在为区块链上的联邦学习提供隐私保护、抵御恶意攻击并增强参与网络的验证。", "motivation": "现有的大多数共识机制并不直接针对联邦学习设计，并且在聚合步骤上没有帮助。因此，作者引入了Proof of Reasoning（PoR）来解决这些问题，以提高数据隐私和安全性。", "method": "该方法包括三个过程：1）使用掩码自动编码器生成特征映射并混淆输入数据；2）在网络边缘训练下游分类器，并将网络权重、单个编码的数据点等添加到区块中进行联邦聚合；3）利用此数据实现更复杂和可验证的聚合方法，从而提高网络的鲁棒性和减少计算复杂度。", "result": "通过PoR机制实现了更高的准确性并减少了计算复杂性，同时该方法还能够适应不断变化的数据、规定以及网络条件，适用于大规模物联网网络，具有低延迟和存储增长的特点。", "conclusion": "Proof of Reasoning (PoR)是一种为联邦学习设计的新的共识机制，在保持数据隐私的同时增强了系统的安全性和有效性。"}}
{"id": "2601.07133", "pdf": "https://arxiv.org/pdf/2601.07133", "abs": "https://arxiv.org/abs/2601.07133", "authors": ["Abdikarim Mohamed Ibrahim", "Rosdiadee Nordin"], "title": "Geometry-Aware LoRaWAN Gateway Placement in Dense Urban Cities Using Digital Twins", "categories": ["eess.SY", "cs.ET"], "comment": null, "summary": "LoRaWAN deployments rely on rough range estimates or simplified propagation models to decide where to place/mount gateways. As a result, operators have limited visibility into how rooftop choice, streets, and building shadowing jointly affect coverage and reliability. This paper addresses the problem of gateway placement in dense urban environments by combining a geometry accurate Digital Twin (DT) with a GPU accelerated ray tracing engine. Existing studies optimize placement on abstract grids or tune models with sparse measurements; few works evaluate LoRaWAN gateways on a full 3D city model using a realistic link budget. In this paper, we develop a DT with ITU radio materials and evaluate eight candidate rooftops for RAK7289 WisGate Edge Pro gateways under a sub-GHz link budget derived from the data sheet. For each rooftop, we obtain Signal-to-Noise Ratios (SNR) on a 5 meter grid, derive robust and edge coverage indicators, and apply a greedy maximum coverage algorithm to rank sites and quantify the benefit of incremental densification. Results show that a single rooftop gateway covers one fifth of the full Sunway twin (i.e., the DT) at a robust SNR threshold, and that six sites still leave large areas of single gateway or out of coverage cells in surrounding residential streets. The findings from this paper shows that DT and ray tracing tools enable network operators to bridge the gap of expensive real-world trials and planning to identify if the planned LoRaWAN gateway is sufficient or additional sites are required.", "AI": {"tldr": "该论文提出了一种基于数字孪生和GPU加速光线追踪引擎的方法，来优化LoRaWAN网关在密集城市环境中的放置。", "motivation": "当前的LoRaWAN部署依赖于粗糙的距离估计或简化的传播模型来决定网关的位置。这种方法导致运营商对屋顶选择、街道以及建筑物阴影如何共同影响覆盖范围和可靠性缺乏足够的了解。因此，该论文旨在解决这一问题，通过结合几何精确度高的数字孪生技术与GPU加速的光线追踪引擎。", "method": "开发了一个包含ITU无线电材料的数字孪生模型，并评估了八种候选屋顶上RAK7289 WisGate Edge Pro网关的位置。在每个屋顶位置，获得5米网格上的信噪比（SNR），并利用贪婪最大覆盖算法来排名站点和量化增量密集化的效益。", "result": "研究结果表明，单个屋顶网关仅能在数字孪生模型的五分之一区域提供可靠的服务；六个站点仍然留下大量单网关或无覆盖的居民街道。这些发现表明了数字孪生与光线追踪工具对于网络运营商的重要性，它们能够缩小昂贵的真实世界试验和规划之间的差距。", "conclusion": "数字孪生和光线追踪工具使得网络运营商能够在进行真实世界的试验之前有效地识别LoRaWAN网关是否足够或者需要额外的站点。"}}
{"id": "2601.07132", "pdf": "https://arxiv.org/pdf/2601.07132", "abs": "https://arxiv.org/abs/2601.07132", "authors": ["Abdikarim Mohamed Ibrahim", "Rosdiadee Nordin"], "title": "Digital Twin for Ultra-Reliable & Low-Latency 6G Wireless Communications in Dense Urban City", "categories": ["eess.SY", "cs.ET"], "comment": null, "summary": "High-frequency deployments in dense cities are difficult to plan because coverage, interference, and service reliability depend sensitively on local morphology. This paper develops a geometric Digital Twin (DT) of the Sunway City and uses it to study the service implications of a multi-site mmWave deployment. The DT is constructed from geo-referenced three-dimensional meshes of buildings, roads, and open areas, assembled in Blender and exported as a mesh scene. A seven-transmitter downlink at 10 GHz is then embedded into this geometry and evaluated using a GPU accelerated ray tracing engine that returns path-gain and Signal-to-Interference-plus-Noise Ratio (SINR) fields over a dense grid of user locations. These fields are mapped to achievable throughput and compared against representative target rates for immersive extended reality (XR), vehicle-to-everything (V2X) services, and ultra-reliable low-latency communication (URLLC). The resulting maps show that favourable streets and courtyards form narrow high rate corridors surrounded by deep shadows, even within a dense area. In the baseline deployment, one fifth of the simulated area can maintain 100 Mbps URLLC rates, and less than 10% of cells can reach 1.7 Gbps for XR, despite the presence of several rooftop sites. By exploiting the DT, we further quantify the macro-diversity margin between the best and second best serving sites and show that most URLLC-feasible cells have several decibels of SINR headroom that could be harvested through dual connectivity. The study shows how a city DT can translate ray tracing output into service centric metrics and planning insights, complementing both analytical models and expensive measurement campaigns.", "AI": {"tldr": "构建了一个几何数字孪生模型来研究多站点毫米波部署在密集城市环境中的服务影响。", "motivation": "高频段部署在密集的城市中因覆盖、干扰和可靠性等问题难以规划，需要通过精确的建模工具来进行有效的规划。", "method": "使用Blender创建了三维建筑、道路和开放区域模型，并嵌入七个发射器进行10GHz频段下的下行链路测试。利用GPU加速的光线追踪引擎计算路径增益及信号与干扰加噪声比（SINR），并将结果映射为可实现吞吐量，对比目标数据速率。", "result": "研究显示了有利街道和庭院形成的高带宽走廊，并表明尽管存在多个屋顶站点，在基础部署中只有五分之一的模拟区域可以维持100 Mbps URLLC速率，且不到十分之一个小区能达到1.7 Gbps XR速率。此外，量化了宏分集裕度及大部分URLLC可行小区具备几dB SINR余量。", "conclusion": "数字孪生模型能够将光线追踪输出转换为服务导向型指标和规划洞察，并补充分析模型和昂贵的测量活动。"}}
{"id": "2601.07130", "pdf": "https://arxiv.org/pdf/2601.07130", "abs": "https://arxiv.org/abs/2601.07130", "authors": ["Nicholas J. Pritchard", "Richard Dodson", "Andreas Wicenec"], "title": "The Potential Impact of Neuromorphic Computing on Radio Telescope Observatories", "categories": ["astro-ph.IM", "cs.NE"], "comment": "40 pages, 7 figures, 7 tables, in-review", "summary": "Radio astronomy relies on bespoke, experimental and innovative computing solutions. This will continue as next-generation telescopes such as the Square Kilometre Array (SKA) and next-generation Very Large Array (ngVLA) take shape. Under increasingly demanding power consumption, and increasingly challenging radio environments, science goals may become intractable with conventional von Neumann computing due to related power requirements. Neuromorphic computing offers a compelling alternative, and combined with a desire for data-driven methods, Spiking Neural Networks (SNNs) are a promising real-time power-efficient alternative. Radio Frequency Interference (RFI) detection is an attractive use-case for SNNs where recent exploration holds promise. This work presents a comprehensive analysis of the potential impact of deploying varying neuromorphic approaches across key stages in radio astronomy processing pipelines for several existing and near-term instruments. Our analysis paves a realistic path from near-term FPGA deployment of SNNs in existing instruments, allowing the addition of advanced data-driven RFI detection for no capital cost, to neuromorphic ASICs for future instruments, finding that commercially available solutions could reduce the power budget for key processing elements by up to three orders of magnitude, transforming the operational budget of the observatory. High-data-rate spectrographic processing could be a well-suited target for the neuromorphic computing industry, as we cast radio telescopes as the world's largest in-sensor compute challenge.", "AI": {"tldr": "研究探讨了神经形态计算在射电天文观测中的潜在影响，尤其是在RFI检测和高数据率谱图处理方面。", "motivation": "随着未来新一代射电望远镜的出现，传统冯·诺依曼架构下的计算能耗难以满足需求。神经形态计算提供了一种节能的替代方案，并且可以提高实时性。", "method": "论文分析了不同神经形态方法在现有和即将实施的天文观测设备中的应用效果，从FPGA到专用集成电路（ASIC）都进行了考察。", "result": "研究表明，在未来射电望远镜中采用神经形态计算技术有望将关键处理单元的能耗减少三个数量级。", "conclusion": "研究为当前及未来的射电天文设备引入先进的数据驱动RFI检测方法铺平了道路，同时表明高数据率谱图处理是神经形态计算领域的理想挑战。"}}
{"id": "2601.07125", "pdf": "https://arxiv.org/pdf/2601.07125", "abs": "https://arxiv.org/abs/2601.07125", "authors": ["Sungguk Cha", "DongWook Kim", "Mintae Kim", "Youngsub Han", "Byoung-Ki Jeon", "Sangyeob Lee"], "title": "ReinPool: Reinforcement Learning Pooling Multi-Vector Embeddings for Retrieval System", "categories": ["cs.IR", "cs.CL", "cs.CV"], "comment": "5 pages", "summary": "Multi-vector embedding models have emerged as a powerful paradigm for document retrieval, preserving fine-grained visual and textual details through token-level representations. However, this expressiveness comes at a staggering cost: storing embeddings for every token inflates index sizes by over $1000\\times$ compared to single-vector approaches, severely limiting scalability. We introduce \\textbf{ReinPool}, a reinforcement learning framework that learns to dynamically filter and pool multi-vector embeddings into compact, retrieval-optimized representations. By training with an inverse retrieval objective and NDCG-based rewards, ReinPool identifies and retains only the most discriminative vectors without requiring manual importance annotations. On the Vidore V2 benchmark across three vision-language embedding models, ReinPool compresses multi-vector representations by $746$--$1249\\times$ into single vectors while recovering 76--81\\% of full multi-vector retrieval performance. Compared to static mean pooling baselines, ReinPool achieves 22--33\\% absolute NDCG@3 improvement, demonstrating that learned selection significantly outperforms heuristic aggregation.", "AI": {"tldr": "本文提出了ReinPool，一种通过强化学习动态过滤和池化多向量嵌入的方法，以生成紧凑且优化检索的表示。", "motivation": "多向量嵌入模型在文档检索中表现出色，但存储每个标记的嵌入会导致索引大小膨胀超过1000倍，严重影响了可扩展性。为此，需要一种方法来压缩这些嵌入而不损害其性能。", "method": "ReinPool是一个强化学习框架，通过逆向检索目标和NDCG奖励训练模型，动态选择最具区分性的向量，从而将多向量表示池化成单一紧凑的表示。", "result": "在Vidore V2基准测试中，ReinPool能够在压缩比为746-1249倍的情况下恢复到80%以上的全多向量检索性能，并且相对于静态均值池化基线取得了22--33％绝对NDCG@3的改善。", "conclusion": "ReinPool通过学习选择最佳嵌入而非使用启发式聚合，显著提高了检索系统的性能和可扩展性。"}}
{"id": "2601.07123", "pdf": "https://arxiv.org/pdf/2601.07123", "abs": "https://arxiv.org/abs/2601.07123", "authors": ["Ruichu Cai", "Haopeng Du", "Qingwen Lin", "Yutong Chen", "Zijian Li", "Boyan Xu"], "title": "ENTRA: Entropy-Based Redundancy Avoidance in Large Language Model Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Large Reasoning Models (LRMs) often suffer from overthinking, generating unnecessarily long reasoning chains even for simple tasks. This leads to substantial computational overhead with limited performance gain, primarily due to redundant verification and repetitive generation. While prior work typically constrains output length or optimizes correctness, such coarse supervision fails to guide models toward concise yet accurate inference. In this paper, we propose ENTRA, an entropy-based training framework that suppresses redundant reasoning while preserving performance. ENTRA first estimates the token-level importance using a lightweight Bidirectional Importance Estimation (BIE) method, which accounts for both prediction confidence and forward influence. It then computes a redundancy reward based on the entropy of low-importance tokens, normalized by its theoretical upper bound, and optimizes this reward via reinforcement learning. Experiments on mathematical reasoning benchmarks demonstrate that ENTRA reduces output length by 37% to 53% with no loss-and in some cases, gains-in accuracy. Our approach offers a principled and efficient solution to reduce overthinking in LRMs, and provides a generalizable path toward redundancy-aware reasoning optimization.", "AI": {"tldr": "ENTRA 是一种基于熵的训练框架，旨在通过抑制冗余推理来减少大型语言模型在简单任务上生成不必要的长推理链的现象。", "motivation": "大型语言模型在处理简单任务时往往会过度思考，导致产生不必要的长推理链条，并带来计算开销增加。而之前的解决方案往往只是限制输出长度或优化正确率，未能引导模型进行简洁准确的推断。", "method": "ENTRA 首先使用轻量级双向重要性估计（BIE）方法评估每个标记的重要性；然后根据低重要性的标记熵来计算冗余奖励，并通过强化学习优化此奖励。", "result": "实验结果表明，在数学推理基准测试中，ENTRA 可以将输出长度减少37%到53%，同时保持准确性不下降甚至有所提高。", "conclusion": "ENTRA 提供了一种合理且高效的解决方案来解决大型语言模型的过度思考问题，并为冗余感知推理优化提供了通用路径。"}}
{"id": "2601.07122", "pdf": "https://arxiv.org/pdf/2601.07122", "abs": "https://arxiv.org/abs/2601.07122", "authors": ["Yixiao Peng", "Hao Hu", "Feiyang Li", "Xinye Cao", "Yingchang Jiang", "Jipeng Tang", "Guoshun Nan", "Yuling Liu"], "title": "Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "While virtualization and resource pooling empower cloud networks with structural flexibility and elastic scalability, they inevitably expand the attack surface and challenge cyber resilience. Reinforcement Learning (RL)-based defense strategies have been developed to optimize resource deployment and isolation policies under adversarial conditions, aiming to enhance system resilience by maintaining and restoring network availability. However, existing approaches lack robustness as they require retraining to adapt to dynamic changes in network structure, node scale, attack strategies, and attack intensity. Furthermore, the lack of Human-in-the-Loop (HITL) support limits interpretability and flexibility. To address these limitations, we propose CyberOps-Bots, a hierarchical multi-agent reinforcement learning framework empowered by Large Language Models (LLMs). Inspired by MITRE ATT&CK's Tactics-Techniques model, CyberOps-Bots features a two-layer architecture: (1) An upper-level LLM agent with four modules--ReAct planning, IPDRR-based perception, long-short term memory, and action/tool integration--performs global awareness, human intent recognition, and tactical planning; (2) Lower-level RL agents, developed via heterogeneous separated pre-training, execute atomic defense actions within localized network regions. This synergy preserves LLM adaptability and interpretability while ensuring reliable RL execution. Experiments on real cloud datasets show that, compared to state-of-the-art algorithms, CyberOps-Bots maintains network availability 68.5% higher and achieves a 34.7% jumpstart performance gain when shifting the scenarios without retraining. To our knowledge, this is the first study to establish a robust LLM-RL framework with HITL support for cloud defense. We will release our framework to the community, facilitating the advancement of robust and autonomous defense in cloud networks.", "AI": {"tldr": "本文提出了一种结合大型语言模型和多智能体强化学习的框架CyberOps-Bots，以增强云网络在面对攻击时的韧性。", "motivation": "现有防御策略缺乏适应性和解释性，在动态变化的环境中需要重新训练。为解决这一问题，作者设计了一个新的框架来提高系统的鲁棒性和可解释性。", "method": "提出了一种层级多智能体强化学习架构CyberOps-Bots，通过大型语言模型进行全局感知、意图识别和战术规划；下层使用预训练的RL代理执行局部防御动作。此架构结合了LLM的适应性和解释性与可靠的RL执行。", "result": "实验结果表明，相比现有最佳算法，该框架在网络可用性上提高了68.5%，并且在场景转变时无需重新训练就能实现34.7%的性能提升。", "conclusion": "CyberOps-Bots是首个结合LLM和RL，并且具备人类介入支持的云防御框架。它显著增强了网络韧性，将促进更健壮、自主的云网络安全研究发展。"}}
{"id": "2601.07121", "pdf": "https://arxiv.org/pdf/2601.07121", "abs": "https://arxiv.org/abs/2601.07121", "authors": ["Makoto Sato"], "title": "ReMIND: Orchestrating Modular Large Language Models for Controllable Serendipity A REM-Inspired System Design for Emergent Creative Ideation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are used not only for problem solving but also for creative ideation; however, eliciting serendipitous insights that are both novel and internally coherent remains difficult. While stochastic sampling promotes novelty, it often degrades consistency. Here, we propose ReMIND, a REM-inspired modular framework for ideation. ReMIND consists of four stages: wake, which generates a stable low-temperature semantic baseline; dream, which performs high-temperature exploratory generation; judge, which applies coarse evaluation to filter incoherent outputs and extract candidate ideas; and re-wake, which re-articulates selected ideas into coherent final outputs. By instantiating each stage as an independent LLM, ReMIND enables functional separation between exploration and consolidation. Parameter sweeps show that ReMIND reliably induces semantic exploration while preserving downstream stability. Embedding-based analyses confirm substantial semantic displacement during the dream phase, whereas external evaluations reveal that high-quality ideas emerge sporadically rather than as extrema along any single metric. These results suggest that serendipitous ideation in LLMs is a rare-event process best approached through system level design that shapes the conditions under which valuable ideas can emerge and be stabilized. ReMIND provides a general framework for studying the computational basis of serendipity and illustrates how modular LLM orchestration can bridge exploration and stabilization.", "AI": {"tldr": "提出ReMIND框架用于在大型语言模型中实现可控的创意生成，通过四个阶段的设计来平衡新颖性和连贯性。", "motivation": "现有的大型语言模型在促进创造性思想时难以同时保持新颖和内部一致性。本文旨在解决这一难题，设计一种新的系统以提高在该领域的性能。", "method": "ReMIND由四个独立阶段组成：wake生成稳定的基础语义；dream进行高温度探索；judge筛选出连贯的候选创意；re-wake重述这些想法形成最终输出。每个阶段使用单独的语言模型实现功能分离，通过参数调节和评估验证框架的有效性。", "result": "实验表明ReMIND可以有效促进语义探索同时保持下游稳定性，外部评价显示高质量的想法出现频率不高但可以通过系统设计优化条件以提高其生成概率。", "conclusion": "该研究提供了理解和计算基础上的机遇发现机制，并展示了模块化语言模型组合在创意生成中的潜力。"}}
{"id": "2601.07119", "pdf": "https://arxiv.org/pdf/2601.07119", "abs": "https://arxiv.org/abs/2601.07119", "authors": ["Taisuke Noguchi", "Takayuki Nishio", "Takuya Azumi"], "title": "SC-MII: Infrastructure LiDAR-based 3D Object Detection on Edge Devices for Split Computing with Multiple Intermediate Outputs Integration", "categories": ["cs.DC", "cs.CV"], "comment": "6 pages. This version includes minor lstlisting configuration adjustments for successful compilation. No changes to content or layout. Originally published at IEEE CCNC 2026", "summary": "3D object detection using LiDAR-based point cloud data and deep neural networks is essential in autonomous driving technology. However, deploying state-of-the-art models on edge devices present challenges due to high computational demands and energy consumption. Additionally, single LiDAR setups suffer from blind spots. This paper proposes SC-MII, multiple infrastructure LiDAR-based 3D object detection on edge devices for Split Computing with Multiple Intermediate outputs Integration. In SC-MII, edge devices process local point clouds through the initial DNN layers and send intermediate outputs to an edge server. The server integrates these features and completes inference, reducing both latency and device load while improving privacy. Experimental results on a real-world dataset show a 2.19x speed-up and a 71.6% reduction in edge device processing time, with at most a 1.09% drop in accuracy.", "AI": {"tldr": "本文提出了一种基于多基础设施LiDAR的三维物体检测方法SC-MII，利用边缘设备和服务器协同工作以提高计算效率。", "motivation": "现有的深度神经网络模型在自动驾驶中的实时三维物体检测面临高能耗和高延迟的问题，并且单个LiDAR传感器存在盲区。", "method": "采用分割计算策略，在边缘设备上处理局部点云并通过初步的深度神经网络层产生中间输出，然后将这些特征发送到服务器进行集成与最终推理。", "result": "实验结果表明该方法在实际数据集上的检测速度提高了2.19倍，并且减少了71.6%的计算时间，准确性最多降低了1.09%", "conclusion": "SC-MII通过利用边缘设备和云服务器的合作处理能力，在保证较高准确性的前提下显著提升了三维物体检测的速度与效率。"}}
{"id": "2601.07117", "pdf": "https://arxiv.org/pdf/2601.07117", "abs": "https://arxiv.org/abs/2601.07117", "authors": ["Kexin Bao", "Yong Li", "Dan Zeng", "Shiming Ge"], "title": "Few-shot Class-Incremental Learning via Generative Co-Memory Regularization", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by International Journal on Computer Vision (IJCV)", "summary": "Few-shot class-incremental learning (FSCIL) aims to incrementally learn models from a small amount of novel data, which requires strong representation and adaptation ability of models learned under few-example supervision to avoid catastrophic forgetting on old classes and overfitting to novel classes. This work proposes a generative co-memory regularization approach to facilitate FSCIL. In the approach, the base learning leverages generative domain adaptation finetuning to finetune a pretrained generative encoder on a few examples of base classes by jointly incorporating a masked autoencoder (MAE) decoder for feature reconstruction and a fully-connected classifier for feature classification, which enables the model to efficiently capture general and adaptable representations. Using the finetuned encoder and learned classifier, we construct two class-wise memories: representation memory for storing the mean features for each class, and weight memory for storing the classifier weights. After that, the memory-regularized incremental learning is performed to train the classifier dynamically on the examples of few-shot classes in each incremental session by simultaneously optimizing feature classification and co-memory regularization. The memories are updated in a class-incremental manner and they collaboratively regularize the incremental learning. In this way, the learned models improve recognition accuracy, while mitigating catastrophic forgetting over old classes and overfitting to novel classes. Extensive experiments on popular benchmarks clearly demonstrate that our approach outperforms the state-of-the-arts.", "AI": {"tldr": "提出了一种生成共记忆正则化方法以促进少样本类增量学习", "motivation": "为了克服在少例监督下学习模型时避免灾难性遗忘旧类别和过度拟合新类别的挑战，该工作引入了新的方法来增强模型的表示能力和适应能力。", "method": "通过预训练生成编码器进行微调，并结合掩码自动编码解码器和全连接分类器来捕获通用且可适配的特征；构造两个类别记忆，分别为存储各类均值特征的表示内存以及存储分类器权重的记忆。增量学习过程中同时优化特征分类与共记忆正则化以动态训练新类别的分类器，并在每次增量会话中更新内存。", "result": "实验结果表明该方法优于现有技术，在识别准确性上有所提升，减少了旧类别遗忘和对新类别的过度拟合问题。", "conclusion": "通过生成共记忆正则化的方法，可以有效解决少样本类增量学习中的灾难性遗忘及过度拟合的问题，并且在多个流行基准测试中取得了最佳性能"}}
{"id": "2601.07110", "pdf": "https://arxiv.org/pdf/2601.07110", "abs": "https://arxiv.org/abs/2601.07110", "authors": ["Pranav Narayanan Venkit", "Yu Li", "Yada Pruksachatkun", "Chien-Sheng Wu"], "title": "The Need for a Socially-Grounded Persona Framework for User Simulation", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "Synthetic personas are widely used to condition large language models (LLMs) for social simulation, yet most personas are still constructed from coarse sociodemographic attributes or summaries. We revisit persona creation by introducing SCOPE, a socially grounded framework for persona construction and evaluation, built from a 141-item, two-hour sociopsychological protocol collected from 124 U.S.-based participants. Across seven models, we find that demographic-only personas are a structural bottleneck: demographics explain only ~1.5% of variance in human response similarity. Adding sociopsychological facets improves behavioral prediction and reduces over-accentuation, and non-demographic personas based on values and identity achieve strong alignment with substantially lower bias. These trends generalize to SimBench (441 aligned questions), where SCOPE personas outperform default prompting and NVIDIA Nemotron personas, and SCOPE augmentation improves Nemotron-based personas. Our results indicate that persona quality depends on sociopsychological structure rather than demographic templates or summaries.", "AI": {"tldr": "本文提出了一个基于社会心理学的框架（SCOPE），用于构建和评估合成人物，以提高大型语言模型在社交模拟中的表现。", "motivation": "当前的人格构造主要依赖粗略的社会人口属性或概述，而这种做法限制了行为预测的准确性。论文希望通过引入更细致的社会心理学要素来改善这一状况。", "method": "作者构建了一种新的框架SCOPE，该框架基于141个项目的社会心理学协议收集的数据，并通过比较不同模型下仅包含人口统计信息和包含更多社会心理学特征的人格构造的效果来进行实验。", "result": "结果表明，仅有人口统计数据的合成人物表现不佳。添加社会心理学要素可显著提高行为预测的准确性并减少过度强调的问题。此外，在SimBench基准测试中，SCOPE框架优于默认提示和其他竞争方法。", "conclusion": "结论是人格质量取决于其背后的社会心理学结构而非单纯的人口统计模板或概述。"}}
{"id": "2601.07107", "pdf": "https://arxiv.org/pdf/2601.07107", "abs": "https://arxiv.org/abs/2601.07107", "authors": ["Meng Lu", "Yuxing Lu", "Yuchen Zhuang", "Megan Mullins", "Yang Xie", "Guanghua Xiao", "Charles Fleming", "Wenqi Shi", "Xuan Wang"], "title": "MEDVISTAGYM: A Scalable Training Environment for Thinking with Medical Images via Tool-Integrated Reinforcement Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision language models (VLMs) achieve strong performance on general image understanding but struggle to think with medical images, especially when performing multi-step reasoning through iterative visual interaction. Medical VLMs often rely on static visual embeddings and single-pass inference, preventing models from re-examining, verifying, or refining visual evidence during reasoning. While tool-integrated reasoning offers a promising path forward, open-source VLMs lack the training infrastructure to learn effective tool selection, invocation, and coordination in multi-modal medical reasoning. We introduce MedVistaGym, a scalable and interactive training environment that incentivizes tool-integrated visual reasoning for medical image analysis. MedVistaGym equips VLMs to determine when and which tools to invoke, localize task-relevant image regions, and integrate single or multiple sub-image evidence into interleaved multimodal reasoning within a unified, executable interface for agentic training. Using MedVistaGym, we train MedVistaGym-R1 to interleave tool use with agentic reasoning through trajectory sampling and end-to-end reinforcement learning. Across six medical VQA benchmarks, MedVistaGym-R1-8B exceeds comparably sized tool-augmented baselines by 19.10% to 24.21%, demonstrating that structured agentic training--not tool access alone--unlocks effective tool-integrated reasoning for medical image analysis.", "AI": {"tldr": "本文提出了MedVistaGym，一种用于医疗图像分析的可扩展训练环境，支持工具集成的视觉推理。", "motivation": "现有的医学视觉语言模型在多步骤推理和迭代视觉交互时表现不佳。为了克服这些挑战，引入了MedVistaGym来激励工具集成的视觉推理，并通过结构化的代理训练解锁有效的方法。", "method": "MedVistaGym提供了确定何时以及使用哪些工具的功能，同时能够定位与任务相关的图像区域，并将单一或多个子图证据整合到多模态推理中。利用该环境，通过轨迹采样和端到端强化学习训练了MedVistaGym-R1模型。", "result": "在六个医学问答基准测试上，MedVistaGym-R1-8B超过了具有工具增强的基线模型，表现高出19.10%至24.21%。", "conclusion": "结构化的代理训练方法比单一提供工具访问更有效地促进了医疗图像分析中的有效工具集成推理。"}}
{"id": "2601.07093", "pdf": "https://arxiv.org/pdf/2601.07093", "abs": "https://arxiv.org/abs/2601.07093", "authors": ["Peiyuan Jing", "Yue Tang", "Chun-Wun Cheng", "Zhenxuan Zhang", "Liutao Yang", "Thiago V. Lima", "Klaus Strobel", "Antoine Leimgruber", "Angelica Aviles-Rivero", "Guang Yang", "Javier Montoya"], "title": "3D Wavelet-Based Structural Priors for Controlled Diffusion in Whole-Body Low-Dose PET Denoising", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages", "summary": "Low-dose Positron Emission Tomography (PET) imaging reduces patient radiation exposure but suffers from increased noise that degrades image quality and diagnostic reliability. Although diffusion models have demonstrated strong denoising capability, their stochastic nature makes it challenging to enforce anatomically consistent structures, particularly in low signal-to-noise regimes and volumetric whole-body imaging. We propose Wavelet-Conditioned ControlNet (WCC-Net), a fully 3D diffusion-based framework that introduces explicit frequency-domain structural priors via wavelet representations to guide volumetric PET denoising. By injecting wavelet-based structural guidance into a frozen pretrained diffusion backbone through a lightweight control branch, WCC-Net decouples anatomical structure from noise while preserving generative expressiveness and 3D structural continuity. Extensive experiments demonstrate that WCC-Net consistently outperforms CNN-, GAN-, and diffusion-based baselines. On the internal 1/20-dose test set, WCC-Net improves PSNR by +1.21 dB and SSIM by +0.008 over a strong diffusion baseline, while reducing structural distortion (GMSD) and intensity error (NMAE). Moreover, WCC-Net generalizes robustly to unseen dose levels (1/50 and 1/4), achieving superior quantitative performance and improved volumetric anatomical consistency.", "AI": {"tldr": "提出了一种基于3D小波的扩散框架，通过引入频率域结构先验来指导低剂量PET图像降噪。", "motivation": "为了减少患者辐射暴露，采用低剂量PET成像技术。但是由于噪声增加，影响了图像质量和诊断可靠性。", "method": "提出Wavelet-Conditioned ControlNet（WCC-Net），利用3D小波表示在频率域中引入显式结构先验，并通过预训练的扩散骨干网络中的轻量控制分支进行引导。", "result": "实验表明，WCC-Net相对于CNN、GAN和基于扩散的方法，在内部测试集中提高了PSNR+1.21dB和SSIM+0.008，同时降低了结构失真（GMSD）和强度误差（NMAE）。", "conclusion": "所提出的方法在低剂量PET图像降噪方面表现出色，并保持了体积解剖学的一致性。"}}
{"id": "2601.07092", "pdf": "https://arxiv.org/pdf/2601.07092", "abs": "https://arxiv.org/abs/2601.07092", "authors": ["Yuliang Cai", "Dongqiangzi Ye", "Zitian Chen", "Chongruo Wu"], "title": "Efficient Visual Question Answering Pipeline for Autonomous Driving via Scene Region Compression", "categories": ["cs.CV"], "comment": "7 pages", "summary": "Autonomous driving increasingly relies on Visual Question Answering (VQA) to enable vehicles to understand complex surroundings by analyzing visual inputs and textual queries. Currently, a paramount concern for VQA in this domain is the stringent requirement for fast latency and real-time processing, as delays directly impact real-world safety in this safety-critical application. However, current state-of-the-art VQA models, particularly large vision-language models (VLMs), often prioritize performance over computational efficiency. These models typically process dense patch tokens for every frame, leading to prohibitive computational costs (FLOPs) and significant inference latency, especially with long video sequences. This focus limits their practical deployment in real-time autonomous driving scenarios. To tackle this issue, we propose an efficient VLM framework for autonomous driving VQA tasks, SRC-Pipeline. It learns to compress early frame tokens into a small number of high-level tokens while retaining full patch tokens for recent frames. Experiments on autonomous driving video question answering tasks show that our approach achieves 66% FLOPs reduction while maintaining comparable performance, enabling VLMs to operate more effectively in real-time, safety-critical autonomous driving settings.", "AI": {"tldr": "提出了一种高效的视觉问答管道，用于自动驾驶场景中的实时处理。", "motivation": "现有VQA模型在计算效率上不足，无法满足自动驾驶对低延迟和实时性的严格要求。", "method": "设计了一个学习框架SRC-Pipeline，该框架能将早期帧令牌压缩为少量高层次令牌，同时保留最近帧的全图块令牌。", "result": "实验显示，所提方法能在减少66%计算量的同时保持性能不变，适用于实时自动驾驶环境。", "conclusion": "提出的SRC-Pipeline有效解决了VQA在自动驾驶中的计算效率问题，提升了模型的实际应用价值。"}}
{"id": "2601.07086", "pdf": "https://arxiv.org/pdf/2601.07086", "abs": "https://arxiv.org/abs/2601.07086", "authors": ["Osama Yousuf", "Andreu L. Glasmann", "Martin Lueker-Boden", "Sina Najmaei", "Gina C. Adam"], "title": "XBTorch: A Unified Framework for Modeling and Co-Design of Crossbar-Based Deep Learning Accelerators", "categories": ["cs.ET", "cs.AI", "cs.LG"], "comment": null, "summary": "Emerging memory technologies have gained significant attention as a promising pathway to overcome the limitations of conventional computing architectures in deep learning applications. By enabling computation directly within memory, these technologies - built on nanoscale devices with tunable and nonvolatile conductance - offer the potential to drastically reduce energy consumption and latency compared to traditional von Neumann systems. This paper introduces XBTorch (short for CrossBarTorch), a novel simulation framework that integrates seamlessly with PyTorch and provides specialized tools for accurately and efficiently modeling crossbar-based systems based on emerging memory technologies. Through detailed comparisons and case studies involving hardware-aware training and inference, we demonstrate how XBTorch offers a unified interface for key research areas such as device-level modeling, cross-layer co-design, and inference-time fault tolerance. While exemplar studies utilize ferroelectric field-effect transistor (FeFET) models, the framework remains technology-agnostic - supporting other emerging memories such as resistive RAM (ReRAM), as well as enabling user-defined custom device models. The code is publicly available at: https://github.com/ADAM-Lab-GW/xbtorch", "AI": {"tldr": "介绍了XBTorch框架，用于模拟基于新兴内存技术的交叉棒深度学习加速器。", "motivation": "为了解决传统计算架构在深度学习应用中的局限性，提出了一个统一的仿真框架来准确高效地模拟基于新兴存储器的技术系统。", "method": "设计了一个与PyTorch集成的新型模拟框架XBTorch，并通过详细的比较和案例研究展示了其在设备级建模、跨层协同设计以及推断时容错方面的应用。", "result": "结果显示，XBTorch提供了一个统一接口来支持关键的研究领域，并且该框架技术无关性很强，可以支持用户自定义的其他新兴内存模型。", "conclusion": "通过案例研究展示了XBTorch在硬件感知训练和推断中的有效性，证明了其作为新兴存储器深度学习加速器建模和协同设计的有效工具。"}}
{"id": "2601.07085", "pdf": "https://arxiv.org/pdf/2601.07085", "abs": "https://arxiv.org/abs/2601.07085", "authors": ["Andrew D. Maynard"], "title": "The AI Cognitive Trojan Horse: How Large Language Models May Bypass Human Epistemic Vigilance", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "15 pages, 18 references", "summary": "Large language model (LLM)-based conversational AI systems present a challenge to human cognition that current frameworks for understanding misinformation and persuasion do not adequately address. This paper proposes that a significant epistemic risk from conversational AI may lie not in inaccuracy or intentional deception, but in something more fundamental: these systems may be configured, through optimization processes that make them useful, to present characteristics that bypass the cognitive mechanisms humans evolved to evaluate incoming information. The Cognitive Trojan Horse hypothesis draws on Sperber and colleagues' theory of epistemic vigilance -- the parallel cognitive process monitoring communicated information for reasons to doubt -- and proposes that LLM-based systems present 'honest non-signals': genuine characteristics (fluency, helpfulness, apparent disinterest) that fail to carry the information equivalent human characteristics would carry, because in humans these are costly to produce while in LLMs they are computationally trivial. Four mechanisms of potential bypass are identified: processing fluency decoupled from understanding, trust-competence presentation without corresponding stakes, cognitive offloading that delegates evaluation itself to the AI, and optimization dynamics that systematically produce sycophancy. The framework generates testable predictions, including a counterintuitive speculation that cognitively sophisticated users may be more vulnerable to AI-mediated epistemic influence. This reframes AI safety as partly a problem of calibration -- aligning human evaluative responses with the actual epistemic status of AI-generated content -- rather than solely a problem of preventing deception.", "AI": {"tldr": "大型语言模型（LLM）可能通过优化过程中的某些特性，绕过人类的认知警惕机制，从而构成一种认知特洛伊木马。", "motivation": "当前对误导和说服的理解框架未能充分应对基于LLM的对话AI系统所带来的挑战。该研究旨在探讨这些系统如何通过呈现特定特性而避开人类的认知评估机制，并提出了一个名为“认知特洛伊木马”的假设。", "method": "论文提出了一种新的理论框架，结合了Sperber等人提出的知识警惕性理论，分析LLM系统可能利用的四种潜在绕过机制：处理流畅性与理解脱钩、信任-能力展示而不对应的实际风险、认知卸载将评估责任转移给AI以及优化动力学产生奉承。", "result": "论文提出了一个测试可预测的框架，并推测认知较为成熟的用户可能会更容易受到LLM影响，因此将人工智能安全性的问题重新定位为校准问题，即使人类评价反应与AI生成内容的实际知识地位相一致，而不仅仅是防止误导。", "conclusion": "通过识别和理解这些机制，可以更好地评估和管理基于大型语言模型的对话系统带来的认知风险。"}}
{"id": "2601.07073", "pdf": "https://arxiv.org/pdf/2601.07073", "abs": "https://arxiv.org/abs/2601.07073", "authors": ["Carlos Pizarroso", "Zuzana Berger Haladová", "Zuzana Černeková", "Viktor Kocur"], "title": "Billboard in Focus: Estimating Driver Gaze Duration from a Single Image", "categories": ["cs.CV"], "comment": "Accepted as a position paper at VISAPP 2026", "summary": "Roadside billboards represent a central element of outdoor advertising, yet their presence may contribute to driver distraction and accident risk. This study introduces a fully automated pipeline for billboard detection and driver gaze duration estimation, aiming to evaluate billboard relevance without reliance on manual annotations or eye-tracking devices. Our pipeline operates in two stages: (1) a YOLO-based object detection model trained on Mapillary Vistas and fine-tuned on BillboardLamac images achieved 94% mAP@50 in the billboard detection task (2) a classifier based on the detected bounding box positions and DINOv2 features. The proposed pipeline enables estimation of billboard driver gaze duration from individual frames. We show that our method is able to achieve 68.1% accuracy on BillboardLamac when considering individual frames. These results are further validated using images collected from Google Street View.", "AI": {"tldr": "研究提出了一个自动化流程，用于检测路边广告牌并估计驾驶员注视时间。", "motivation": "评估广告牌的相关性而不需要手动注释或眼动追踪设备。减少驾驶分心和事故风险。", "method": "两阶段流程：第一阶段使用YOLO模型进行物体检测；第二阶段基于检测到的边界框位置和DINOv2特征训练分类器。", "result": "在BillboardLamac数据集上达到68.1%的准确率，通过Google街景图像验证了结果。", "conclusion": "该方法能够从单帧中估计驾驶员注视时间，为评估广告牌相关性提供了一种新途径。"}}
{"id": "2601.07072", "pdf": "https://arxiv.org/pdf/2601.07072", "abs": "https://arxiv.org/abs/2601.07072", "authors": ["Hongyan Chang", "Ergute Bao", "Xinjian Luo", "Ting Yu"], "title": "Overcoming the Retrieval Barrier: Indirect Prompt Injection in the Wild for LLM Systems", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) increasingly rely on retrieving information from external corpora. This creates a new attack surface: indirect prompt injection (IPI), where hidden instructions are planted in the corpora and hijack model behavior once retrieved. Previous studies have highlighted this risk but often avoid the hardest step: ensuring that malicious content is actually retrieved. In practice, unoptimized IPI is rarely retrieved under natural queries, which leaves its real-world impact unclear. We address this challenge by decomposing the malicious content into a trigger fragment that guarantees retrieval and an attack fragment that encodes arbitrary attack objectives. Based on this idea, we design an efficient and effective black-box attack algorithm that constructs a compact trigger fragment to guarantee retrieval for any attack fragment. Our attack requires only API access to embedding models, is cost-efficient (as little as $0.21 per target user query on OpenAI's embedding models), and achieves near-100% retrieval across 11 benchmarks and 8 embedding models (including both open-source models and proprietary services). Based on this attack, we present the first end-to-end IPI exploits under natural queries and realistic external corpora, spanning both RAG and agentic systems with diverse attack objectives. These results establish IPI as a practical and severe threat: when a user issued a natural query to summarize emails on frequently asked topics, a single poisoned email was sufficient to coerce GPT-4o into exfiltrating SSH keys with over 80% success in a multi-agent workflow. We further evaluate several defenses and find that they are insufficient to prevent the retrieval of malicious text, highlighting retrieval as a critical open vulnerability.", "AI": {"tldr": "本文提出了一种间接提示注入（IPI）攻击方法，通过优化触发片段来确保恶意内容在大型语言模型中被检索。", "motivation": "前人研究指出，通过外部语料库进行信息检索的大型语言模型存在新的安全风险，但尚未解决实际检索问题。本文旨在验证这种威胁的实际可行性和严重性，并提出有效的攻击方法和评估防御措施。", "method": "作者设计了一种高效的黑盒攻击算法，该算法构建了一个紧凑的触发片段以确保任意攻击目标的恶意内容被检索到。此攻击仅需访问嵌入模型API，且成本低廉。", "result": "实验表明，提出的攻击方法在11个基准测试和8种嵌入模型上实现了接近100%的成功率，并首次展示了端到端的IPI攻击案例，在自然查询下成功实施了恶意行为。同时评估了几种防御措施发现它们不足以防止恶意文本检索。", "conclusion": "间接提示注入（IPI）是一种实际且严重的威胁，现有的安全机制难以有效预防其发生；研究指出检索过程是关键的安全漏洞，需要进一步加强防护。"}}
{"id": "2601.07069", "pdf": "https://arxiv.org/pdf/2601.07069", "abs": "https://arxiv.org/abs/2601.07069", "authors": ["Justin London"], "title": "Neuromorphic FPGA Design for Digital Signal Processing", "categories": ["cs.NE", "eess.SP"], "comment": null, "summary": "In this paper, the foundations of neuromorphic computing, spiking neural networks (SNNs) and memristors, are analyzed and discussed. Neuromorphic computing is then applied to FPGA design for digital signal processing (DSP). Finite impulse response (FIR) and infinite impulse response (IIR) filters are implemented with and without neuromorphic computing in Vivado using Verilog HDL. The results suggest that neuromorphic computing can provide low-latency and synaptic plasticity thereby enabling continuous on-chip learning. Due to their parallel and event-driven nature, neuromorphic computing can reduce power consumption by eliminating von Neumann bottlenecks and improve efficiency, but at the cost of reduced numeric precision.", "AI": {"tldr": "本文探讨了神经形态计算在FPGA设计中的应用，特别是在数字信号处理（DSP）中。通过Vivado使用Verilog HDL实现了有限脉冲响应（FIR）和无限脉冲响应（IIR）滤波器的实现，并对比分析了传统方法与神经形态计算的方法。", "motivation": "文章旨在探索神经形态计算在FPGA设计中的潜力，特别是其应用于DSP时的优势，如低延迟、突触可塑性以及连续片上学习的能力。", "method": "研究通过Vivado使用Verilog HDL实现了具有和不具神经形态计算功能的FIR和IIR滤波器，并对其性能进行了对比分析。", "result": "结果表明，神经形态计算可以提供低延迟及突触可塑性，并且可以通过消除冯·诺依曼瓶颈来减少功耗并提高效率，但这也意味着数值精度有所降低。", "conclusion": "研究显示，尽管存在一些限制，例如精度损失，神经形态计算在FPGA设计中具有显著的优势，特别是在DSP应用方面可以提供低延迟、连续学习的能力和更好的能量效率。"}}
{"id": "2601.07062", "pdf": "https://arxiv.org/pdf/2601.07062", "abs": "https://arxiv.org/abs/2601.07062", "authors": ["Jiho Noh", "Mukhesh Raghava Katragadda", "Dabae Lee"], "title": "Automated Domain Question Mapping (DQM) with Educational Learning Materials", "categories": ["cs.AI"], "comment": null, "summary": "Concept maps have been widely utilized in education to depict knowledge structures and the interconnections between disciplinary concepts. Nonetheless, devising a computational method for automatically constructing a concept map from unstructured educational materials presents challenges due to the complexity and variability of educational content. We focus primarily on two challenges: (1) the lack of disciplinary concepts that are specifically designed for multi-level pedagogical purposes from low-order to high-order thinking, and (2) the limited availability of labeled data concerning disciplinary concepts and their interrelationships. To tackle these challenges, this research introduces an innovative approach for constructing Domain Question Maps (DQMs), rather than traditional concept maps. By formulating specific questions aligned with learning objectives, DQMs enhance knowledge representation and improve readiness for learner engagement. The findings indicate that the proposed method can effectively generate educational questions and discern hierarchical relationships among them, leading to structured question maps that facilitate personalized and adaptive learning in downstream applications.", "AI": {"tldr": "提出了一种自动构建领域问题映射（DQM）的方法，以改进知识表示并促进个性化和适应性学习。", "motivation": "教育材料的复杂性和多样性使得从无结构数据中自动生成概念图变得困难。此外，缺乏为不同层次教学目标设计的概念以及标注的数据限制了现有方法的有效性。", "method": "通过提出一种新的构建领域问题映射（DQM）的方法来解决这些问题，该方法基于学习目标制定特定的问题，并识别它们之间的层级关系。", "result": "该方法能够有效生成教育相关问题并揭示其层次结构关系，从而创建出有助于个性化和适应性学习的结构化问题图。", "conclusion": "这种方法在构建领域问题映射方面表现良好，证明了它对于促进知识表示改进及支持下游应用中个性化的、适应性的学习具有潜力。"}}
{"id": "2601.07060", "pdf": "https://arxiv.org/pdf/2601.07060", "abs": "https://arxiv.org/abs/2601.07060", "authors": ["Yuanzhe Liu", "Jingyuan Zhu", "Yuchen Mo", "Gen Li", "Xu Cao", "Jin Jin", "Yifan Shen", "Zhengyuan Li", "Tianjiao Yu", "Wenzhen Yuan", "Fangqiang Ding", "Ismini Lourentzou"], "title": "PALM: Progress-Aware Policy Learning via Affordance Reasoning for Long-Horizon Robotic Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Recent advancements in vision-language-action (VLA) models have shown promise in robotic manipulation, yet they continue to struggle with long-horizon, multi-step tasks. Existing methods lack internal reasoning mechanisms that can identify task-relevant interaction cues or track progress within a subtask, leading to critical execution errors such as repeated actions, missed steps, and premature termination. To address these challenges, we introduce PALM, a VLA framework that structures policy learning around interaction-centric affordance reasoning and subtask progress cues. PALM distills complementary affordance representations that capture object relevance, contact geometry, spatial placements, and motion dynamics, and serve as task-relevant anchors for visuomotor control. To further stabilize long-horizon execution, PALM predicts continuous within-subtask progress, enabling seamless subtask transitions. Across extensive simulation and real-world experiments, PALM consistently outperforms baselines, achieving a 91.8% success rate on LIBERO-LONG, a 12.5% improvement in average length on CALVIN ABC->D, and a 2x improvement over real-world baselines across three long-horizon generalization settings.", "AI": {"tldr": "PALM是一个通过感知推理和任务进度线索来改善长周期机器人操作的视觉语言动作框架。", "motivation": "当前的VLA模型在执行复杂的多步骤机器人操控任务时遇到困难，需要一种能够识别关键互动提示并跟踪子任务进展的方法以避免错误。", "method": "PALM通过提取互补感知表示来捕捉对象的相关性、接触几何形状、空间放置和运动动态，并预测连续的任务进度线索以实现平滑的子任务转换。", "result": "在模拟和现实世界实验中，PALM显著优于现有方法，在LIBERO-LONG上达到91.8%的成功率，在CALVIN ABC->D上的平均长度提升了12.5%，并且在三个长周期泛化场景下比真实世界的基线提高了两倍。", "conclusion": "通过感知推理和任务进度线索，PALM为解决复杂的多步骤机器人操控问题提供了一种有效的方法。"}}
{"id": "2601.07058", "pdf": "https://arxiv.org/pdf/2601.07058", "abs": "https://arxiv.org/abs/2601.07058", "authors": ["Aaron R. Flouro", "Shawn P. Chadwick"], "title": "Hallucinations Live in Variance", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 3 figures", "summary": "Benchmarks measure whether a model is correct. They do not measure whether a model is reliable. This distinction is largely academic for single-shot inference, but becomes critical for agentic AI systems, where a single rephrased prompt can trigger cascading failures in multi-step execution. Yet this form of instability is not captured by existing evaluations. Hallucinations live in variance: they arise when semantically equivalent prompts activate inconsistent internal pathways, producing divergent outputs. Consistent but incorrect outputs reflect bias or missing knowledge; confident guessing reflects calibration failure. Neither constitutes hallucination under this definition. When error is variance-dominated, reducing redundant pathways improves reliability without adding knowledge. We formalize this through Semantic Stability (SS), measured via Paraphrase Consistency (PC@k): generate k paraphrases, greedy decode each, compute mode agreement. SS is a diagnostic for variance-driven unreliability, not a method for improving correctness. We show that a dense Qwen3-0.6B agrees with itself only 23.8% of the time; at 32% sparsity, agreement jumps to 55.9%. A phase diagram reveals the sweet spot where variance reduction outpaces bias accumulation, and regimes where stability collapses onto wrong answers.", "AI": {"tldr": "本文旨在通过语义稳定性（SS）衡量模型在处理语义等价提示时的一致性，以检测其可靠性。", "motivation": "现有评估方法未能捕捉到由于内部路径不一致导致的多步执行中的波动和不稳定情况。这种现象被称为幻觉，并且是影响代理AI系统可靠性的关键问题。", "method": "通过生成k个同义提示并计算每个提示输出的一致性，定义了语义稳定性（SS），利用该度量来识别模型在处理等价输入时的波动和不稳定情况。", "result": "实验表明，在32%稀疏性的条件下，Qwen3-0.6B模型对等价提示输出一致率从原始版本的23.8%提高到55.9%，证明了减少冗余路径可以改善可靠性。", "conclusion": "语义稳定性是一种用于检测由于内部路径不一致性导致的波动和不稳定情况的有效方法，有助于改进代理AI系统的可靠性和稳健性。"}}
{"id": "2601.07056", "pdf": "https://arxiv.org/pdf/2601.07056", "abs": "https://arxiv.org/abs/2601.07056", "authors": ["Yunrui Gu", "Zhenzhe Gao", "Cong Kong", "Zhaoxia Yin"], "title": "Adversarial Attacks on Medical Hyperspectral Imaging Exploiting Spectral-Spatial Dependencies and Multiscale Features", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Medical hyperspectral imaging (HSI) enables accurate disease diagnosis by capturing rich spectral-spatial tissue information, but recent advances in deep learning have exposed its vulnerability to adversarial attacks. In this work, we identify two fundamental causes of this fragility: the reliance on local pixel dependencies for preserving tissue structure and the dependence on multiscale spectral-spatial representations for hierarchical feature encoding. Building on these insights, we propose a targeted adversarial attack framework for medical HSI, consisting of a Local Pixel Dependency Attack that exploits spatial correlations among neighboring pixels, and a Multiscale Information Attack that perturbs features across hierarchical spectral-spatial scales. Experiments on the Brain and MDC datasets demonstrate that our attacks significantly degrade classification performance, especially in tumor regions, while remaining visually imperceptible. Compared with existing methods, our approach reveals the unique vulnerabilities of medical HSI models and underscores the need for robust, structure-aware defenses in clinical applications.", "AI": {"tldr": "提出了一种针对医学高光谱成像（HSI）的对抗性攻击框架，以揭示其脆弱性。", "motivation": "医学高光谱成像依赖于局部像素依赖性和多尺度特征表示来保持组织结构和分层特征编码，这使其容易受到对手攻击。", "method": "提出了一种结合局部像素依赖性攻击和多尺度信息攻击的框架。前者利用相邻像素的空间相关性进行攻击；后者在多个层次上扰动光谱空间特征。", "result": "实验表明，所提出的对抗攻击能够显著降低分类性能，特别是在肿瘤区域，且视觉上几乎不可察觉。", "conclusion": "研究揭示了医学高光谱成像模型的独特脆弱性，并强调需要开发结构感知的防御措施以保护临床应用。"}}
{"id": "2601.07055", "pdf": "https://arxiv.org/pdf/2601.07055", "abs": "https://arxiv.org/abs/2601.07055", "authors": ["Zhenrui Yue", "Kartikeya Upasani", "Xianjun Yang", "Suyu Ge", "Shaoliang Nie", "Yuning Mao", "Zhe Liu", "Dong Wang"], "title": "Dr. Zero: Self-Evolving Search Agents without Training Data", "categories": ["cs.AI"], "comment": null, "summary": "As high-quality data becomes increasingly difficult to obtain, data-free self-evolution has emerged as a promising paradigm. This approach allows large language models (LLMs) to autonomously generate and solve complex problems, thereby improving their reasoning capabilities. However, multi-turn search agents struggle in data-free self-evolution due to the limited question diversity and the substantial compute required for multi-step reasoning and tool using. In this work, we introduce Dr. Zero, a framework enabling search agents to effectively self-evolve without any training data. In particular, we design a self-evolution feedback loop where a proposer generates diverse questions to train a solver initialized from the same base model. As the solver evolves, it incentivizes the proposer to produce increasingly difficult yet solvable tasks, thus establishing an automated curriculum to refine both agents. To enhance training efficiency, we also introduce hop-grouped relative policy optimization (HRPO). This method clusters structurally similar questions to construct group-level baselines, effectively minimizing the sampling overhead in evaluating each query's individual difficulty and solvability. Consequently, HRPO significantly reduces the compute requirements for solver training without compromising performance or stability. Extensive experiment results demonstrate that the data-free Dr. Zero matches or surpasses fully supervised search agents, proving that complex reasoning and search capabilities can emerge solely through self-evolution.", "AI": {"tldr": "本文提出了Dr. Zero框架，使搜索代理能够在没有训练数据的情况下自我进化。", "motivation": "由于高质量的数据越来越难以获得，研究者提出了一种不需要任何训练数据的自我进化的搜索代理。", "method": "设计了一个自我进化反馈循环，通过生成多样化的问题来训练解决器。引入了hop-grouped相对策略优化（HRPO）方法来减少采样开销和计算需求。", "result": "实验结果表明，Dr. Zero在没有数据的情况下能匹配甚至超过完全监督的搜索代理的表现。", "conclusion": "证明了复杂推理和搜索能力可以通过自我进化独自出现。"}}
{"id": "2601.07052", "pdf": "https://arxiv.org/pdf/2601.07052", "abs": "https://arxiv.org/abs/2601.07052", "authors": ["Simon Sagmeister", "Marcel Weinmann", "Phillip Pitschi", "Markus Lienkamp"], "title": "RSLCPP - Deterministic Simulations Using ROS 2", "categories": ["cs.RO"], "comment": "Submitted to 'IEEE Robotics and Automation Practice' for possible publication", "summary": "Simulation is crucial in real-world robotics, offering safe, scalable, and efficient environments for developing applications, ranging from humanoid robots to autonomous vehicles and drones. While the Robot Operating System (ROS) has been widely adopted as the backbone of these robotic applications in both academia and industry, its asynchronous, multiprocess design complicates reproducibility, especially across varying hardware platforms. Deterministic callback execution cannot be guaranteed when computation times and communication delays vary. This lack of reproducibility complicates scientific benchmarking and continuous integration, where consistent results are essential. To address this, we present a methodology to create deterministic simulations using ROS 2 nodes. Our ROS Simulation Library for C++ (RSLCPP) implements this approach, enabling existing nodes to be combined into a simulation routine that yields reproducible results without requiring any code changes. We demonstrate that our approach yields identical results across various CPUs and architectures when testing both a synthetic benchmark and a real-world robotics system. RSLCPP is open-sourced at https://github.com/TUMFTM/rslcpp.", "AI": {"tldr": "利用ROS 2节点创建可重现的仿真环境。", "motivation": "解决ROS异步多进程设计导致的可再现性问题，特别是在不同硬件平台上进行科学基准测试和持续集成时。", "method": "通过RSLCPP实现确定性回调执行，使得现有节点能够组合成一个产生一致结果的模拟流程。", "result": "展示了该方法在不同CPU架构上的合成基准测试和实际机器人系统中均能生成相同的可重现结果。", "conclusion": "提出了一种利用ROS 2节点创建可重现仿真环境的方法，无需任何代码更改即可实现。RSLCPP开源项目已上线。"}}
{"id": "2601.07048", "pdf": "https://arxiv.org/pdf/2601.07048", "abs": "https://arxiv.org/abs/2601.07048", "authors": ["Hunter McCoy", "Zikun Wang", "Prashant Pandey"], "title": "Jasper: ANNS Quantized for Speed, Built for Change on GPU", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Approximate nearest neighbor search (ANNS) is a core problem in machine learning and information retrieval applications. GPUs offer a promising path to high-performance ANNS: they provide massive parallelism for distance computations, are readily available, and can co-locate with downstream applications. Despite these advantages, current GPU-accelerated ANNS systems face three key limitations. First, real-world applications operate on evolving datasets that require fast batch updates, yet most GPU indices must be rebuilt from scratch when new data arrives. Second, high-dimensional vectors strain memory bandwidth, but current GPU systems lack efficient quantization techniques that reduce data movement without introducing costly random memory accesses. Third, the data-dependent memory accesses inherent to greedy search make overlapping compute and memory difficult, leading to reduced performance. We present Jasper, a GPU-native ANNS system with both high query throughput and updatability. Jasper builds on the Vamana graph index and overcomes existing bottlenecks via three contributions: (1) a CUDA batch-parallel construction algorithm that enables lock-free streaming insertions, (2) a GPU-efficient implementation of RaBitQ quantization that reduces memory footprint up to 8x without the random access penalties, and (3) an optimized greedy search kernel that increases compute utilization, resulting in better latency hiding and higher throughput. Our evaluation across five datasets shows that Jasper achieves up to 1.93x higher query throughput than CAGRA and achieves up to 80% peak utilization as measured by the roofline model. Jasper's construction scales efficiently and constructs indices an average of 2.4x faster than CAGRA while providing updatability that CAGRA lacks. Compared to BANG, the previous fastest GPU Vamana implementation, Jasper delivers 19-131x faster queries.", "AI": {"tldr": "Jasper是一款针对GPU优化的近似最近邻搜索系统，旨在解决现有系统的更新速度慢、内存带宽不足和计算与内存访问重叠难的问题。", "motivation": "当前基于GPU的ANNS系统存在三个主要限制：1. 数据集变化时需要重建索引；2. 高维向量占用大量带宽；3. 计算密集型搜索导致性能下降。Jasper旨在克服这些瓶颈，提高查询和更新速度。", "method": "Jasper基于Vamana图索引，通过三项贡献来优化：1. 使用CUDA并行算法进行高效的流式插入；2. 实现高效的RaBitQ量化技术以减少内存使用而不增加随机访问开销；3. 改进贪心搜索内核提高计算利用效率。", "result": "Jasper在五种数据集上的评估显示，与CAGRA相比，查询吞吐量提高了1.93倍，并实现了高达80%的峰值利用率。构造时间平均缩短了2.4倍。与最快的GPU Vamana实现BANG相比，其查询速度提升了19-131倍。", "conclusion": "Jasper通过创新的方法解决了现有ANNS系统面临的挑战，提供了高效的更新能力和更高的性能表现。"}}
{"id": "2601.07036", "pdf": "https://arxiv.org/pdf/2601.07036", "abs": "https://arxiv.org/abs/2601.07036", "authors": ["Wang Yang", "Debargha Ganguly", "Xinpeng Li", "Chaoda Song", "Shouren Wang", "Vikash Singh", "Vipin Chaudhary", "Xiaotian Han"], "title": "Mid-Think: Training-Free Intermediate-Budget Reasoning via Token-Level Triggers", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Hybrid reasoning language models are commonly controlled through high-level Think/No-think instructions to regulate reasoning behavior, yet we found that such mode switching is largely driven by a small set of trigger tokens rather than the instructions themselves. Through attention analysis and controlled prompting experiments, we show that a leading ``Okay'' token induces reasoning behavior, while the newline pattern following ``</think>'' suppresses it. Based on this observation, we propose Mid-Think, a simple training-free prompting format that combines these triggers to achieve intermediate-budget reasoning, consistently outperforming fixed-token and prompt-based baselines in terms of the accuracy-length trade-off. Furthermore, applying Mid-Think to RL training after SFT reduces training time by approximately 15% while improving final performance of Qwen3-8B on AIME from 69.8% to 72.4% and on GPQA from 58.5% to 61.1%, demonstrating its effectiveness for both inference-time control and RL-based reasoning training.", "AI": {"tldr": "通过分析和实验发现，某些特定触发词可以控制推理行为。提出一种名为Mid-Think的无训练提示格式，结合这些触发词以实现中间预算推理。", "motivation": "现有模型依赖高层面的指令来调节推理行为，但实际上推理行为更多地受到低层触发词的影响。作者希望通过这种发现优化模型性能和效率。", "method": "通过注意力分析和控制性实验揭示了触发词的作用机制，并提出一种结合这些触发词的新格式Mid-Think以实现更好的推理效果。", "result": "在精度与长度的权衡中，Mid-Think优于固定令牌和提示基线。此外，在RL训练后应用Mid-Think可减少15%的训练时间并提高最终性能。", "conclusion": "通过揭示模型内部机制，Mid-Think不仅提高了推理效率也优化了推理结果，展现了其在控制推理行为方面的优越性。"}}
{"id": "2601.07035", "pdf": "https://arxiv.org/pdf/2601.07035", "abs": "https://arxiv.org/abs/2601.07035", "authors": ["Hasan M Jamil"], "title": "Explainable Deep Radiogenomic Molecular Imaging for MGMT Methylation Prediction in Glioblastoma", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "14 pages", "summary": "Glioblastoma (GBM) is a highly aggressive primary brain tumor with limited therapeutic options and poor prognosis. The methylation status of the O6-methylguanine-DNA methyltransferase (MGMT) gene promoter is a critical molecular biomarker that influences patient response to temozolomide chemotherapy. Traditional methods for determining MGMT status rely on invasive biopsies and are limited by intratumoral heterogeneity and procedural risks. This study presents a radiogenomic molecular imaging analysis framework for the non-invasive prediction of MGMT promoter methylation using multi-parametric magnetic resonance imaging (mpMRI). Our approach integrates radiomics, deep learning, and explainable artificial intelligence (XAI) to analyze MRI-derived imaging phenotypes and correlate them with molecular labels. Radiomic features are extracted from FLAIR, T1-weighted, T1-contrast-enhanced, and T2-weighted MRI sequences, while a 3D convolutional neural network learns deep representations from the same modalities. These complementary features are fused using both early fusion and attention-based strategies and classified to predict MGMT methylation status. To enhance clinical interpretability, we apply XAI methods such as Grad-CAM and SHAP to visualize and explain model decisions. The proposed framework is trained on the RSNA-MICCAI Radiogenomic Classification dataset and externally validated on the BraTS 2021 dataset. This work advances the field of molecular imaging by demonstrating the potential of AI-driven radiogenomics for precision oncology, supporting non-invasive, accurate, and interpretable prediction of clinically actionable molecular biomarkers in GBM.", "AI": {"tldr": "通过多参数磁共振成像（mpMRI）结合放射组学、深度学习和可解释的人工智能技术，开发了一个预测胶质母细胞瘤MGMT甲基化状态的框架。", "motivation": "传统的MGMT基因启动子甲基化状态检测方法依赖于侵入性的活检，并且受限于肿瘤内的异质性和程序风险。本研究旨在通过非侵入性的方式准确预测MGMT甲基化状态，以支持精准医学的应用。", "method": "利用多参数磁共振成像（mpMRI）序列提取放射组学特征，并应用3D卷积神经网络学习深层表示。结合早期融合和注意力机制策略进行特征融合，并使用XAI技术如Grad-CAM和SHAP增强模型决策的可解释性。", "result": "该框架在RSNA-MICCAI Radiogenomic Classification数据集上训练并在BraTS 2021数据集上进行了外部验证，展示了通过人工智能驱动的放射组学预测临床行动分子生物标志物的潜力。", "conclusion": "本研究展示了一种使用深度学习和可解释的人工智能技术进行非侵入性MGMT甲基化状态预测的方法，并强调了这种方法在支持精准医学中的重要性和潜在应用。"}}
{"id": "2601.07023", "pdf": "https://arxiv.org/pdf/2601.07023", "abs": "https://arxiv.org/abs/2601.07023", "authors": ["Sen Hu", "Zhiyu Zhang", "Yuxiang Wei", "Xueran Han", "Zhenheng Tang", "Huacan Wang", "Ronghao Chen"], "title": "CloneMem: Benchmarking Long-Term Memory for AI Clones", "categories": ["cs.AI"], "comment": null, "summary": "AI Clones aim to simulate an individual's thoughts and behaviors to enable long-term, personalized interaction, placing stringent demands on memory systems to model experiences, emotions, and opinions over time. Existing memory benchmarks primarily rely on user-agent conversational histories, which are temporally fragmented and insufficient for capturing continuous life trajectories. We introduce CloneMem, a benchmark for evaluating longterm memory in AI Clone scenarios grounded in non-conversational digital traces, including diaries, social media posts, and emails, spanning one to three years. CloneMem adopts a hierarchical data construction framework to ensure longitudinal coherence and defines tasks that assess an agent's ability to track evolving personal states. Experiments show that current memory mechanisms struggle in this setting, highlighting open challenges for life-grounded personalized AI. Code and dataset are available at https://github.com/AvatarMemory/CloneMemBench", "AI": {"tldr": "本文提出了CloneMem，这是一个用于评估AI克隆场景中长期记忆的基准测试。", "motivation": "现有的记忆基准主要依赖于用户代理会话历史记录，这些记录在时间上是片段化的，并不足以捕捉连续的生活轨迹。因此需要一个新的基准来衡量AI克隆的记忆能力。", "method": "CloneMem采用了一个层次化数据构建框架，以确保长期的连贯性，并定义了评估智能体追踪个人状态变化的能力的任务。", "result": "实验表明，当前的记忆机制在这种设置下表现挣扎，凸显出生活根基个性化人工智能中的开放挑战。", "conclusion": "通过引入CloneMem基准，揭示了AI克隆在长期记忆方面的不足之处，为未来的研究指明了方向。"}}
{"id": "2601.07020", "pdf": "https://arxiv.org/pdf/2601.07020", "abs": "https://arxiv.org/abs/2601.07020", "authors": ["Çağrı Toraman", "Ahmet Kaan Sever", "Ayse Aysu Cengiz", "Elif Ecem Arslan", "Görkem Sevinç", "Mete Mert Birdal", "Yusuf Faruk Güldemir", "Ali Buğra Kanburoğlu", "Sezen Felekoğlu", "Osman Gürlek", "Sarp Kantar", "Birsen Şahin Kütük", "Büşra Tufan", "Elif Genç", "Serkan Coşkun", "Gupse Ekin Demir", "Muhammed Emin Arayıcı", "Olgun Dursun", "Onur Gungor", "Susan Üsküdarlı", "Abdullah Topraksoy", "Esra Darıcı"], "title": "TurkBench: A Benchmark for Evaluating Turkish Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "With the recent surge in the development of large language models, the need for comprehensive and language-specific evaluation benchmarks has become critical. While significant progress has been made in evaluating English language models, benchmarks for other languages, particularly those with unique linguistic characteristics such as Turkish, remain less developed. Our study introduces TurkBench, a comprehensive benchmark designed to assess the capabilities of generative large language models in the Turkish language. TurkBench involves 8,151 data samples across 21 distinct subtasks. These are organized under six main categories of evaluation: Knowledge, Language Understanding, Reasoning, Content Moderation, Turkish Grammar and Vocabulary, and Instruction Following. The diverse range of tasks and the culturally relevant data would provide researchers and developers with a valuable tool for evaluating their models and identifying areas for improvement. We further publish our benchmark for online submissions at https://huggingface.co/turkbench", "AI": {"tldr": "介绍了一个名为TurkBench的评估基准，用于评价土耳其语言模型的能力。", "motivation": "在大型语言模型发展中，需要针对特定语种进行综合评测。特别是对于像土耳其语这样具有独特语言特性的语言，现有的评估基准尚不完善。", "method": "构建了一套包含8151个数据样本的TurkBench评估基准，覆盖了知识、语言理解、推理、内容审核、土耳其语法和词汇以及指令遵循等六个主要评估类别下的21项任务。", "result": "发布了一个在线提交平台以供研究人员使用此基准测试他们的模型，并从中发现改进的空间。", "conclusion": "TurkBench提供了一种全面的工具，用于评价在特定语言环境中大型语言模型的表现。"}}
{"id": "2601.07019", "pdf": "https://arxiv.org/pdf/2601.07019", "abs": "https://arxiv.org/abs/2601.07019", "authors": ["Harshil Parmar", "Pushti Vyas", "Prayers Khristi", "Priyank Panchal"], "title": "Zer0n: An AI-Assisted Vulnerability Discovery and Blockchain-Backed Integrity Framework", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": "10 pages, 3 figures, 7 tables. Framework for AI-Assisted Vulnerability Discovery", "summary": "As vulnerability research increasingly adopts generative AI, a critical reliance on opaque model outputs has emerged, creating a \"trust gap\" in security automation. We address this by introducing Zer0n, a framework that anchors the reasoning capabilities of Large Language Models (LLMs) to the immutable audit trails of blockchain technology. Specifically, we integrate Gemini 2.0 Pro for logic-based vulnerability detection with the Avalanche C-Chain for tamper-evident artifact logging. Unlike fully decentralized solutions that suffer from high latency, Zer0n employs a hybrid architecture: execution remains off-chain for performance, while integrity proofs are finalized on-chain. Our evaluation on a dataset of 500 endpoints reveals that this approach achieves 80% detection accuracy with only a marginal 22.9% overhead, effectively demonstrating that decentralized integrity can coexist with high-speed security workflows.", "AI": {"tldr": "本文提出了Zer0n框架，结合大型语言模型和区块链技术来发现漏洞并保证审计透明性。", "motivation": "随着安全自动化中对生成式AI的依赖增加，出现了“信任差距”。为了解决这一问题，作者引入了Zer0n框架，以确保基于LLM的推理能力和区块链技术的不可篡改记录之间的链接。", "method": "该方法结合Gemini 2.0 Pro进行逻辑漏洞检测和Avalanche C-Chain进行证据日志记录。采用混合架构：执行保持在链下提高性能，而完整性证明则通过上链最终确定。", "result": "测试结果表明，Zer0n框架在500个端点的测试集中实现了80%的检测准确率，并且仅产生了22.9%的开销，表明去中心化完整性和高速安全工作流程可以共存。", "conclusion": "通过结合大型语言模型和区块链技术，Zer0n框架有效地解决了漏洞发现中的信任问题，同时保持了高效的安全审计能力。"}}
{"id": "2601.07016", "pdf": "https://arxiv.org/pdf/2601.07016", "abs": "https://arxiv.org/abs/2601.07016", "authors": ["Fabian Walke", "Thaddäa Nürnberger"], "title": "Belief in False Information: A Human-Centered Security Risk in Sociotechnical Systems", "categories": ["cs.SI", "cs.AI", "cs.CR", "cs.CY"], "comment": "Literature Review, 10 pages, 8 tables", "summary": "This paper provides a comprehensive literature review on the belief in false information, including misinformation, disinformation, and fake information. It addresses the increasing societal concern regarding false information, which is fueled by technological progress, especially advancements in artificial intelligence. This review systematically identifies and categorizes factors that influence the belief in false information. The review identifies 24 influence factors grouped into six main categories: demographic factors, personality traits, psychological factors, policy and values, media consumption, and preventive factors. Key findings highlight that lower education levels, high extraversion, low agreeableness, high neuroticism, and low cognitive reflection significantly increase belief in false information. The effectiveness of preventive strategies like labeling false information and promoting reflection about correctness is also discussed. This literature review conceptualizes belief in false information as a human-centered security risk in sociotechnical systems, as it can be exploited to manipulate decisions, undermine trust, and increase susceptibility to social engineering. It aims to inform preventive strategies that strengthen socio-technical security and societal resilience.", "AI": {"tldr": "本文综述了虚假信息信仰的相关文献，分析影响因素并探讨预防策略。", "motivation": "鉴于科技进步特别是人工智能的发展导致的对虚假信息日益增长的关注，文章旨在系统识别和分类影响人们信仰虚假信息的因素，并提出预防措施以增强社会技术安全和社会韧性。", "method": "通过全面回顾相关文献来确定和归类影响因素。将24个影响力因素分为六个主要类别：人口统计学因素、个性特质、心理因素、政策与价值取向、媒体消费以及预防性策略。", "result": "关键发现包括教育水平低、性格外向、不友好度高、神经质程度高和认知反省能力低会增加对虚假信息的信仰。同时讨论了诸如标注虚假信息和促进正确判断的方法的有效性。", "conclusion": "文章将对虚假信息的信仰视为社会技术系统中的人为中心的安全风险，并指出其可能被用于操纵决策，破坏信任并增强对社会工程学攻击的易感性。"}}
{"id": "2601.07009", "pdf": "https://arxiv.org/pdf/2601.07009", "abs": "https://arxiv.org/abs/2601.07009", "authors": ["Shifa Sulaiman", "Mohammad Gohari", "Francesco Schetter", "Fanny Ficuciello"], "title": "A Sliding Mode Controller Based on Timoshenko Beam Theory Developed for a Tendon-Driven Robotic Wrist", "categories": ["cs.RO"], "comment": null, "summary": "Development of dexterous robotic joints is essential for advancing manipulation capabilities in robotic systems. This paper presents the design and implementation of a tendon-driven robotic wrist joint together with an efficient Sliding Mode Controller (SMC) for precise motion control. The wrist mechanism is modeled using a Timoshenko-based approach to accurately capture its kinematic and dynamic properties, which serve as the foundation for tendon force calculations within the controller. The proposed SMC is designed to deliver fast dynamic response and computational efficiency, enabling accurate trajectory tracking under varying operating conditions. The effectiveness of the controller is validated through comparative analyses with existing controllers for similar wrist mechanisms. The proposed SMC demonstrates superior performance in both simulation and experimental studies. The Root Mean Square Error (RMSE) in simulation is approximately 1.67e-2 radians, while experimental validation yields an error of 0.2 radians. Additionally, the controller achieves a settling time of less than 3 seconds and a steady-state error below 1e-1 radians, consistently observed across both simulation and experimental evaluations. Comparative analyses confirm that the developed SMC surpasses alternative control strategies in motion accuracy, rapid convergence, and steady-state precision. This work establishes a foundation for future exploration of tendon-driven wrist mechanisms and control strategies in robotic applications.", "AI": {"tldr": "基于Timoshenko梁理论开发了一种用于腱驱动机器人腕关节的滑模控制器。", "motivation": "为了提高机器人系统的操作能力，发展灵巧的机器人关节是必要的。本文通过精确的动力学模型和有效的滑模控制器来实现这一点。", "method": "采用Timoshenko梁理论建模腱驱动的机器人腕关节，并设计了基于此模型的高效滑模控制器以实现实时准确轨迹跟踪。", "result": "仿真结果表明，提出的滑模控制误差约为0.0167弧度，实验验证误差为0.2弧度；控制策略达到小于3秒的响应时间和小于0.1弧度的稳态误差。", "conclusion": "所开发的滑模控制器在精度、快速收敛和稳态性能方面优于现有控制策略，并为进一步研究提供了基础。"}}
{"id": "2601.07006", "pdf": "https://arxiv.org/pdf/2601.07006", "abs": "https://arxiv.org/abs/2601.07006", "authors": ["Or Bachar", "Or Levi", "Sardhendu Mishra", "Adi Levi", "Manpreet Singh Minhas", "Justin Miller", "Omer Ben-Porat", "Eilon Sheetrit", "Jonathan Morra"], "title": "LLM Performance Predictors: Learning When to Escalate in Hybrid Human-AI Moderation Systems", "categories": ["cs.AI"], "comment": "Accepted as a full paper at the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "As LLMs are increasingly integrated into human-in-the-loop content moderation systems, a central challenge is deciding when their outputs can be trusted versus when escalation for human review is preferable. We propose a novel framework for supervised LLM uncertainty quantification, learning a dedicated meta-model based on LLM Performance Predictors (LPPs) derived from LLM outputs: log-probabilities, entropy, and novel uncertainty attribution indicators. We demonstrate that our method enables cost-aware selective classification in real-world human-AI workflows: escalating high-risk cases while automating the rest. Experiments across state-of-the-art LLMs, including both off-the-shelf (Gemini, GPT) and open-source (Llama, Qwen), on multimodal and multilingual moderation tasks, show significant improvements over existing uncertainty estimators in accuracy-cost trade-offs. Beyond uncertainty estimation, the LPPs enhance explainability by providing new insights into failure conditions (e.g., ambiguous content vs. under-specified policy). This work establishes a principled framework for uncertainty-aware, scalable, and responsible human-AI moderation workflows.", "AI": {"tldr": "提出了一种新的监督框架，用于量化大型语言模型（LLM）的不确定性，并学习一个基于性能预测指标的元模型。", "motivation": "在人类参与的AI内容审核系统中，决定何时可以信任AI输出和何时需要人工审查是一个关键挑战。", "method": "提出了一种基于LLM性能预测器（LPPs）的框架，包括从LLM输出计算对数概率、熵以及新的不确定性归因指标，并学习了一个专门的元模型来实现有成本意识的选择性分类。", "result": "实验证明了该方法在多模态和多语言内容审核任务中，相对于现有的不确定性估计器具有显著的准确性和成本折衷改进。", "conclusion": "这项工作确立了一个基于不确定性感知、可扩展且负责任的人机协作审核流程的原则框架。"}}
{"id": "2601.07005", "pdf": "https://arxiv.org/pdf/2601.07005", "abs": "https://arxiv.org/abs/2601.07005", "authors": ["Jianbo Yu", "Yixuan Li", "Hai Xu", "Kang Xu", "Junjielong Xu", "Zhijing Li", "Pinjia He", "Wanyuan Wang"], "title": "MicLog: Towards Accurate and Efficient LLM-based Log Parsing via Progressive Meta In-Context Learning", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Log parsing converts semi-structured logs into structured templates, forming a critical foundation for downstream analysis. Traditional syntax and semantic-based parsers often struggle with semantic variations in evolving logs and data scarcity stemming from their limited domain coverage. Recent large language model (LLM)-based parsers leverage in-context learning (ICL) to extract semantics from examples, demonstrating superior accuracy. However, LLM-based parsers face two main challenges: 1) underutilization of ICL capabilities, particularly in dynamic example selection and cross-domain generalization, leading to inconsistent performance; 2) time-consuming and costly LLM querying. To address these challenges, we present MicLog, the first progressive meta in-context learning (ProgMeta-ICL) log parsing framework that combines meta-learning with ICL on small open-source LLMs (i.e., Qwen-2.5-3B). Specifically, MicLog: i) enhances LLMs' ICL capability through a zero-shot to k-shot ProgMeta-ICL paradigm, employing weighted DBSCAN candidate sampling and enhanced BM25 demonstration selection; ii) accelerates parsing via a multi-level pre-query cache that dynamically matches and refines recently parsed templates. Evaluated on Loghub-2.0, MicLog achieves 10.3% higher parsing accuracy than the state-of-the-art parser while reducing parsing time by 42.4%.", "AI": {"tldr": "MicLog是一个基于小规模开源LLM的渐进元上下文学习日志解析框架，旨在提高准确性和效率。", "motivation": "传统解析器难以应对语义变化和数据稀缺问题。现有大模型解析器虽准确性高但存在上下文学习能力不足及查询成本高的挑战。", "method": "MicLog通过零样本到k样本的渐进元上下文学习框架，结合加权DBSCAN候选采样和增强BM25演示选择来提高LLM的上下文学习能力，并利用多级预查询缓存加速解析过程。", "result": "在Loghub-2.0数据集上，MicLog比现有最佳方法提高了10.3%的准确率并减少了42.4%的时间开销。", "conclusion": "MicLog通过创新的元上下文学习框架和高效查询机制显著提升了日志解析的性能。"}}
{"id": "2601.07004", "pdf": "https://arxiv.org/pdf/2601.07004", "abs": "https://arxiv.org/abs/2601.07004", "authors": ["Xing Zhou", "Dmitrii Ustiugov", "Haoxin Shang", "Kisson Lin"], "title": "MemTrust: A Zero-Trust Architecture for Unified AI Memory System", "categories": ["cs.CR", "cs.AI"], "comment": "18 pages, 5 figures", "summary": "AI memory systems are evolving toward unified context layers that enable efficient cross-agent collaboration and multi-tool workflows, facilitating better accumulation of personal data and learning of user preferences. However, centralization creates a trust crisis where users must entrust cloud providers with sensitive digital memory data. We identify a core tension between personalization demands and data sovereignty: centralized memory systems enable efficient cross-agent collaboration but expose users' sensitive data to cloud provider risks, while private deployments provide security but limit collaboration. To resolve this tension, we aim to achieve local-equivalent security while enabling superior maintenance efficiency and collaborative capabilities. We propose a five-layer architecture abstracting common functional components of AI memory systems: Storage, Extraction, Learning, Retrieval, and Governance. By applying TEE protection to each layer, we establish a trustworthy framework. Based on this, we design MemTrust, a hardware-backed zero-trust architecture that provides cryptographic guarantees across all layers. Our contributions include the five-layer abstraction, \"Context from MemTrust\" protocol for cross-application sharing, side-channel hardened retrieval with obfuscated access patterns, and comprehensive security analysis. The architecture enables third-party developers to port existing systems with acceptable development costs, achieving system-wide trustworthiness. We believe that AI memory plays a crucial role in enhancing the efficiency and collaboration of agents and AI tools. AI memory will become the foundational infrastructure for AI agents, and MemTrust serves as a universal trusted framework for AI memory systems, with the goal of becoming the infrastructure of memory infrastructure.", "AI": {"tldr": "本文提出MemTrust，一种基于TEE保护的五层架构零信任体系结构，旨在实现AI记忆系统中的本地等效安全性同时支持高效维护和协作。", "motivation": "为了解决集中式AI内存系统的安全与个性化需求之间的核心矛盾，即在提供个人数据积累和用户偏好学习的同时不暴露敏感信息给云服务提供商的风险。MemTrust试图通过TEE保护每层以建立一个值得信赖的框架，并实现系统级信任。", "method": "提出了一种五层架构（存储、提取、学习、检索、治理）并基于该架构设计了名为MemTrust的硬件支持零信任体系结构，提供了跨所有层次的加密保证。此外还提出了“从MemTrust获取上下文”的协议以促进应用间共享。", "result": "实现了一套通用的信任框架以确保AI记忆系统的整体安全性，同时允许第三方开发者以可接受的成本将现有系统移植到此架构中。", "conclusion": "认为AI内存将成为增强智能体和工具效率与协作的基础结构，并希望MemTrust能够成为这种基础设施的关键组成部分。"}}
{"id": "2601.07001", "pdf": "https://arxiv.org/pdf/2601.07001", "abs": "https://arxiv.org/abs/2601.07001", "authors": ["Sen Zeng", "Hong Zhou", "Zheng Zhu", "Yang Liu"], "title": "Spatial Multi-Task Learning for Breast Cancer Molecular Subtype Prediction from Single-Phase DCE-MRI", "categories": ["cs.CV"], "comment": null, "summary": "Accurate molecular subtype classification is essential for personalized breast cancer treatment, yet conventional immunohistochemical analysis relies on invasive biopsies and is prone to sampling bias. Although dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) enables non-invasive tumor characterization, clinical workflows typically acquire only single-phase post-contrast images to reduce scan time and contrast agent dose. In this study, we propose a spatial multi-task learning framework for breast cancer molecular subtype prediction from clinically practical single-phase DCE-MRI. The framework simultaneously predicts estrogen receptor (ER), progesterone receptor (PR), human epidermal growth factor receptor 2 (HER2) status, and the Ki-67 proliferation index -- biomarkers that collectively define molecular subtypes. The architecture integrates a deep feature extraction network with multi-scale spatial attention to capture intratumoral and peritumoral characteristics, together with a region-of-interest weighting module that emphasizes the tumor core, rim, and surrounding tissue. Multi-task learning exploits biological correlations among biomarkers through shared representations with task-specific prediction branches. Experiments on a dataset of 960 cases (886 internal cases split 7:1:2 for training/validation/testing, and 74 external cases evaluated via five-fold cross-validation) demonstrate that the proposed method achieves an AUC of 0.893, 0.824, and 0.857 for ER, PR, and HER2 classification, respectively, and a mean absolute error of 8.2\\% for Ki-67 regression, significantly outperforming radiomics and single-task deep learning baselines. These results indicate the feasibility of accurate, non-invasive molecular subtype prediction using standard imaging protocols.", "AI": {"tldr": "提出了一种基于单相动态对比增强磁共振成像(DCE-MRI)的乳腺癌分子亚型预测的空间多任务学习框架。", "motivation": "传统的免疫组化分析依赖于侵入性的活检并且容易产生采样偏差。DCE-MRI可以通过非侵入性方式表征肿瘤，但临床工作流程通常仅获取单相后对比图像以减少扫描时间和造影剂剂量。", "method": "该框架集成了深层特征提取网络和多尺度空间注意机制，用于捕捉肿瘤内部及其周围组织的特性，并结合一个强调肿瘤核心、边缘及周边组织的感兴趣区域权重模块。通过共享表示和任务特定预测分支，实现了多个生物标志物间的生物学相关性。", "result": "在960例数据集上的实验表明，所提出的方法对ER, PR和HER2分类分别达到AUC为0.893, 0.824和0.857，而Ki-67回归的平均绝对误差为8.2%，显著优于放射组学和单一任务深度学习基线。", "conclusion": "该研究证明了使用标准成像协议进行准确、非侵入性的乳腺癌分子亚型预测是可行的。"}}
{"id": "2601.06997", "pdf": "https://arxiv.org/pdf/2601.06997", "abs": "https://arxiv.org/abs/2601.06997", "authors": ["Yuetao Li", "Zhizhou Jia", "Yu Zhang", "Qun Hao", "Shaohui Zhang"], "title": "ObjSplat: Geometry-Aware Gaussian Surfels for Active Object Reconstruction", "categories": ["cs.RO", "cs.CV"], "comment": "Project Page: https://li-yuetao.github.io/ObjSplat-page/", "summary": "Autonomous high-fidelity object reconstruction is fundamental for creating digital assets and bridging the simulation-to-reality gap in robotics. We present ObjSplat, an active reconstruction framework that leverages Gaussian surfels as a unified representation to progressively reconstruct unknown objects with both photorealistic appearance and accurate geometry. Addressing the limitations of conventional opacity or depth-based cues, we introduce a geometry-aware viewpoint evaluation pipeline that explicitly models back-face visibility and occlusion-aware multi-view covisibility, reliably identifying under-reconstructed regions even on geometrically complex objects. Furthermore, to overcome the limitations of greedy planning strategies, ObjSplat employs a next-best-path (NBP) planner that performs multi-step lookahead on a dynamically constructed spatial graph. By jointly optimizing information gain and movement cost, this planner generates globally efficient trajectories. Extensive experiments in simulation and on real-world cultural artifacts demonstrate that ObjSplat produces physically consistent models within minutes, achieving superior reconstruction fidelity and surface completeness while significantly reducing scan time and path length compared to state-of-the-art approaches. Project page: https://li-yuetao.github.io/ObjSplat-page/ .", "AI": {"tldr": "本文提出了ObjSplat，一种利用高斯Surfel进行主动重建的框架，旨在逐步实现未知物体的高质量重建。", "motivation": "自主高保真物体重构对于创建数字资产和弥合机器人仿真与现实之间的差距至关重要。现有的方法主要依赖于不透明度或深度信息，难以处理几何复杂对象，并且贪婪规划策略可能导致路径效率低下。", "method": "ObjSplat使用基于几何的视角评估管道来识别未充分重建区域，并通过NBP规划器优化信息增益和运动成本以生成全局高效的轨迹。此框架利用高斯Surfel作为统一表示法，结合物理一致性和表面完整性。", "result": "实验结果表明，与现有方法相比，ObjSplat能够在几分钟内产生高质量的模型，同时减少扫描时间和路径长度，提高重建保真度和表面完整度。", "conclusion": "ObjSplat通过引入几何感知视图评估管道和NBP规划器实现了高效率和高精度的主动物体重构。"}}
{"id": "2601.06993", "pdf": "https://arxiv.org/pdf/2601.06993", "abs": "https://arxiv.org/abs/2601.06993", "authors": ["Jie Zhu", "Yiyang Su", "Xiaoming Liu"], "title": "Can Textual Reasoning Improve the Performance of MLLMs on Fine-grained Visual Classification?", "categories": ["cs.CV"], "comment": "10 pages, 8 figures", "summary": "Multi-modal large language models (MLLMs) exhibit strong general-purpose capabilities, yet still struggle on Fine-Grained Visual Classification (FGVC), a core perception task that requires subtle visual discrimination and is crucial for many real-world applications. A widely adopted strategy for boosting performance on challenging tasks such as math and coding is Chain-of-Thought (CoT) reasoning. However, several prior works have reported that CoT can actually harm performance on visual perception tasks. These studies, though, examine the issue from relatively narrow angles and leave open why CoT degrades perception-heavy performance. We systematically re-examine the role of CoT in FGVC through the lenses of zero-shot evaluation and multiple training paradigms. Across these settings, we uncover a central paradox: the degradation induced by CoT is largely driven by the reasoning length, in which longer textual reasoning consistently lowers classification accuracy. We term this phenomenon the ``Cost of Thinking''. Building on this finding, we make two key contributions: (1) \\alg, a simple and general plug-and-play normalization method for multi-reward optimization that balances heterogeneous reward signals, and (2) ReFine-RFT, a framework that combines ensemble rewards with \\alg to constrain reasoning length while providing dense accuracy-oriented feedback. Extensive experiments demonstrate the effectiveness of our findings and the proposed ReFine-RFT, achieving state-of-the-art performance across FGVC benchmarks. Code and models are available at \\href{https://github.com/jiezhu23/ReFine-RFT}{Project Link}.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.06992", "pdf": "https://arxiv.org/pdf/2601.06992", "abs": "https://arxiv.org/abs/2601.06992", "authors": ["Yixi Zhou", "Fan Zhang", "Yu Chen", "Haipeng Zhang", "Preslav Nakov", "Zhuohan Xie"], "title": "FinCARDS: Card-Based Analyst Reranking for Financial Document Question Answering", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "15 pages, including figures and tables", "summary": "Financial question answering (QA) over long corporate filings requires evidence to satisfy strict constraints on entities, financial metrics, fiscal periods, and numeric values. However, existing LLM-based rerankers primarily optimize semantic relevance, leading to unstable rankings and opaque decisions on long documents. We propose FinCards, a structured reranking framework that reframes financial evidence selection as constraint satisfaction under a finance-aware schema. FinCards represents filing chunks and questions using aligned schema fields (entities, metrics, periods, and numeric spans), enabling deterministic field-level matching. Evidence is selected via a multi-stage tournament reranking with stability-aware aggregation, producing auditable decision traces. Across two corporate filing QA benchmarks, FinCards substantially improves early-rank retrieval over both lexical and LLM-based reranking baselines, while reducing ranking variance, without requiring model fine-tuning or unpredictable inference budgets. Our code is available at https://github.com/XanderZhou2022/FINCARDS.", "AI": {"tldr": "本文提出了一种基于卡片的结构化重排序框架（FinCARDS），用于解决金融文档问答中的证据选择问题，通过财务意识模式确保排名稳定性和可审计性。", "motivation": "现有基于LLM的重排序方法主要优化语义相关性，在处理长公司文件时导致不稳定的排名和不可预测的决策。为了解决这些问题并提高问答系统的性能，提出了FinCARDS框架。", "method": "该方法将财务证据的选择重新定义为约束满足问题，并通过领域知识结构化表示文件片段与问题，进行多阶段重排序，最终产生稳定且可审计的排名结果。", "result": "实验结果显示，在两个公司文件问答基准测试中，FinCARDS相比于词汇和基于LLM的方法取得了显著改进，提高了早期检索效果并减少了排名波动性。", "conclusion": "研究证明了通过结构化证据选择方法可以有效提高金融文档问答的性能，并且无需模型微调或不确定性的推断预算。"}}
{"id": "2601.06981", "pdf": "https://arxiv.org/pdf/2601.06981", "abs": "https://arxiv.org/abs/2601.06981", "authors": ["Boxiang Wang", "Zhengding Luo", "Haowen Li", "Dongyuan Shi", "Junwei Ji", "Ziyi Yang", "Woon-Seng Gan"], "title": "Directional Selective Fixed-Filter Active Noise Control Based on a Convolutional Neural Network in Reverberant Environments", "categories": ["cs.SD", "eess.AS", "eess.SP"], "comment": null, "summary": "Selective fixed-filter active noise control (SFANC) is a novel approach capable of mitigating noise with varying frequency characteristics. It offers faster response and greater computational efficiency compared to traditional adaptive algorithms. However, spatial factors, particularly the influence of the noise source location, are often overlooked. Some existing studies have explored the impact of the direction-of-arrival (DoA) of the noise source on ANC performance, but they are mostly limited to free-field conditions and do not consider the more complex indoor reverberant environments. To address this gap, this paper proposes a learning-based directional SFANC method that incorporates the DoA of the noise source in reverberant environments. In this framework, multiple reference signals are processed by a convolutional neural network (CNN) to estimate the azimuth and elevation angles of the noise source, as well as to identify the most appropriate control filter for effective noise cancellation. Compared to traditional adaptive algorithms, the proposed approach achieves superior noise reduction with shorter response times, even in the presence of reverberations.", "AI": {"tldr": "基于卷积神经网络在混响环境中实现方向选择性固定滤波主动噪声控制。", "motivation": "现有研究主要局限于自由场条件，忽略了室内混响环境中的噪声源位置影响。为了弥补这一空白，提出了一种学习型的方向SFANC方法。", "method": "通过卷积神经网络处理多个参考信号来估计噪声源的方位和仰角，并选择最合适的控制滤波器以有效降低噪声。", "result": "与传统自适应算法相比，在存在混响的情况下达到了更好的降噪效果且响应时间更短。", "conclusion": "提出的基于卷积神经网络的方向SFANC方法在复杂室内环境中取得了显著的降噪性能和计算效率提升。"}}
{"id": "2601.06980", "pdf": "https://arxiv.org/pdf/2601.06980", "abs": "https://arxiv.org/abs/2601.06980", "authors": ["Bálint Csanády"], "title": "A New Perspective on Drawing Venn Diagrams for Data Visualization", "categories": ["cs.GR", "cs.CG", "cs.HC", "math.CO"], "comment": "15 pages, 19 figures", "summary": "We introduce VennFan, a method for generating $n$-set Venn diagrams based on the polar coordinate projection of trigonometric boundaries, resulting in Venn diagrams that resemble a set of fan blades. Unlike most classical constructions, our method emphasizes readability and customizability by using shaped sinusoids and amplitude scaling. We describe both sine- and cosine-based variants of VennFan and propose an automatic label placement heuristic tailored to these fan-like layouts. VennFan is available as a Python package (https://pypi.org/project/vennfan/).", "AI": {"tldr": "本文介绍了一种基于极坐标投影的VennFan方法，用于生成可读性和定制性更好的n集合维恩图。", "motivation": "传统的维恩图构造方法在多集合情况下难以保持清晰度和美观性。作者提出一种新的方法来解决这一问题，以提高数据可视化的质量和用户体验。", "method": "VennFan通过将三角函数边界映射到极坐标系中生成维恩图，使用具有形状的正弦波或余弦波以及振幅缩放来强调可读性和定制性。这种方法包括了自动标签放置的启发式算法。", "result": "该方法生成的维恩图类似扇叶结构，并且提供了一种新的Python包（VennFan）用于实现这些图形。", "conclusion": "VennFan是一种创新的数据可视化工具，能够提高多集合数据的可读性和美观性。"}}
{"id": "2601.06978", "pdf": "https://arxiv.org/pdf/2601.06978", "abs": "https://arxiv.org/abs/2601.06978", "authors": ["James Le Houx"], "title": "Benchmarking Autonomy in Scientific Experiments: A Hierarchical Taxonomy for Autonomous Large-Scale Facilities", "categories": ["physics.ins-det", "cond-mat.mtrl-sci", "cs.AI", "cs.RO"], "comment": "12 pages, 2 figures, 2 tables", "summary": "The transition from automated data collection to fully autonomous discovery requires a shared vocabulary to benchmark progress. While the automotive industry relies on the SAE J3016 standard, current taxonomies for autonomous science presuppose an owner-operator model that is incompatible with the operational rigidities of Large-Scale User Facilities. Here, we propose the Benchmarking Autonomy in Scientific Experiments (BASE) Scale, a 6-level taxonomy (Levels 0-5) specifically adapted for these unique constraints. Unlike owner-operator models, User Facilities require zero-shot deployment where agents must operate immediately without extensive training periods. We define the specific technical requirements for each tier, identifying the Inference Barrier (Level 3) as the critical latency threshold where decisions shift from scalar feedback to semantic digital twins. Fundamentally, this level extends the decision manifold from spatial exploration to temporal gating, enabling the agent to synchronise acquisition with the onset of transient physical events. By establishing these operational definitions, the BASE Scale provides facility directors, funding bodies, and beamline scientists with a standardised metric to assess risk, define liability, and quantify the intelligence of experimental workflows.", "AI": {"tldr": "提出了一种针对大型科学设施的自主性分级标准(BASE Scale)，以评估和推动科学实验中的自主技术进步。", "motivation": "当前用于衡量科学自主性的模型与用户设施的需求不匹配，需要一种新的标准化方法来适应这种独特的约束。", "method": "定义了一个六级分类系统（0-5级），具体描述了每级的技术要求，并提出了BASE Scale这一标准。", "result": "BASE Scale提供了一种评估风险、界定责任和量化实验工作流程智能的标准。", "conclusion": "通过明确的分级和定义，该研究为大型科学设施中的自主技术发展提供了重要的指导框架。"}}
{"id": "2601.06966", "pdf": "https://arxiv.org/pdf/2601.06966", "abs": "https://arxiv.org/abs/2601.06966", "authors": ["Haonan Bian", "Zhiyuan Yao", "Sen Hu", "Zishan Xu", "Shaolei Zhang", "Yifu Guo", "Ziliang Yang", "Xueran Han", "Huacan Wang", "Ronghao Chen"], "title": "RealMem: Benchmarking LLMs in Real-World Memory-Driven Interaction", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As Large Language Models (LLMs) evolve from static dialogue interfaces to autonomous general agents, effective memory is paramount to ensuring long-term consistency. However, existing benchmarks primarily focus on casual conversation or task-oriented dialogue, failing to capture **\"long-term project-oriented\"** interactions where agents must track evolving goals. To bridge this gap, we introduce **RealMem**, the first benchmark grounded in realistic project scenarios. RealMem comprises over 2,000 cross-session dialogues across eleven scenarios, utilizing natural user queries for evaluation. We propose a synthesis pipeline that integrates Project Foundation Construction, Multi-Agent Dialogue Generation, and Memory and Schedule Management to simulate the dynamic evolution of memory. Experiments reveal that current memory systems face significant challenges in managing the long-term project states and dynamic context dependencies inherent in real-world projects. Our code and datasets are available at [https://github.com/AvatarMemory/RealMemBench](https://github.com/AvatarMemory/RealMemBench).", "AI": {"tldr": "RealMem 是一个基于真实项目场景的基准测试，用于评估大型语言模型在长期项目导向交互中的记忆能力。", "motivation": "当前基准主要集中在普通的对话或任务驱动型对话上，未能捕捉到代理需要追踪不断变化目标的真实世界项目的长时交互。因此，该研究旨在填补这一空白，通过引入 RealMem 来评价 LLM 的长期一致性表现。", "method": "RealMem 包含超过2000个跨会话的对话和11种场景，并且使用了一个合成管道来模拟记忆的动态演变过程，包括项目基础构建、多代理对话生成以及记忆与时间管理。此外，还提供了代码和数据集用于进一步研究。", "result": "实验表明当前的记忆系统在处理真实世界项目中长期状态管理和上下文依赖方面存在重大挑战。", "conclusion": "RealMem 成功填补了现有基准测试的不足，证明了对长期记忆驱动交互进行评估的重要性。"}}
{"id": "2601.06965", "pdf": "https://arxiv.org/pdf/2601.06965", "abs": "https://arxiv.org/abs/2601.06965", "authors": ["Yu Zhong", "Tianwei Lin", "Ruike Zhu", "Yuqian Yuan", "Haoyu Zheng", "Liang Liang", "Wenqiao Zhang", "Feifei Shao", "Haoyuan Li", "Wanggui He", "Hao Jiang", "Yueting Zhuang"], "title": "Unified Personalized Understanding, Generating and Editing", "categories": ["cs.CV"], "comment": null, "summary": "Unified large multimodal models (LMMs) have achieved remarkable progress in general-purpose multimodal understanding and generation. However, they still operate under a ``one-size-fits-all'' paradigm and struggle to model user-specific concepts (e.g., generate a photo of \\texttt{<maeve>}) in a consistent and controllable manner. Existing personalization methods typically rely on external retrieval, which is inefficient and poorly integrated into unified multimodal pipelines. Recent personalized unified models introduce learnable soft prompts to encode concept information, yet they either couple understanding and generation or depend on complex multi-stage training, leading to cross-task interference and ultimately to fuzzy or misaligned personalized knowledge. We present \\textbf{OmniPersona}, an end-to-end personalization framework for unified LMMs that, for the first time, integrates personalized understanding, generation, and image editing within a single architecture. OmniPersona introduces structurally decoupled concept tokens, allocating dedicated subspaces for different tasks to minimize interference, and incorporates an explicit knowledge replay mechanism that propagates personalized attribute knowledge across tasks, enabling consistent personalized behavior. To systematically evaluate unified personalization, we propose \\textbf{\\texttt{OmniPBench}}, extending the public UnifyBench concept set with personalized editing tasks and cross-task evaluation protocols integrating understanding, generation, and editing. Experimental results demonstrate that OmniPersona delivers competitive and robust performance across diverse personalization tasks. We hope OmniPersona will serve as a strong baseline and spur further research on controllable, unified personalization.", "AI": {"tldr": "OmniPersona提出了一个统一的个性化框架，用于处理大规模多模态模型中的个性化理解、生成和图像编辑任务。", "motivation": "当前大型多模态模型存在通用化的问题，无法有效应对用户特定概念的理解与生成，而现有的个性化解决方案效率低下且难以整合到统一的多模态管道中。", "method": "OmniPersona通过引入结构上解耦的概念令牌来处理不同任务，并加入显式的知识重播机制以确保个性化属性知识在各任务间传播，从而实现一致性和可控性。", "result": "实验结果显示，OmniPersona在多种个人化任务上表现出了竞争力和稳健性。", "conclusion": "希望OmniPersona能作为统一个性化的强大基线，并促进相关研究的进一步发展。"}}
{"id": "2601.06947", "pdf": "https://arxiv.org/pdf/2601.06947", "abs": "https://arxiv.org/abs/2601.06947", "authors": ["Mateus de Oliveira Oliveira", "Wim Van den Broeck"], "title": "Optimal Extended Formulations from Optimal Dynamic Programming Algorithms", "categories": ["cs.DS"], "comment": null, "summary": "Vertex Subset Problems (VSPs) are a class of combinatorial optimization problems on graphs where the goal is to find a subset of vertices satisfying a predefined condition. Two prominent approaches for solving VSPs are dynamic programming over tree-like structures, such as tree decompositions or clique decompositions, and linear programming. In this work, we establish a sharp connection between both approaches by showing that if a vertex-subset problem $Π$ admits a solution-preserving dynamic programming algorithm that produces tables of size at most $α(k,n)$ when processing a tree decomposition of width at most $k$ of an $n$-vertex graph $G$, then the polytope $P_Π(G)$ defined as the convex-hull of solutions of $Π$ in $G$ has extension complexity at most $O(α(k,n)\\cdot n)$. Additionally, this upper bound is optimal under the exponential time hypothesis (ETH). On the one hand, our results imply that ETH-optimal solution-preserving dynamic programming algorithms for combinatorial problems yield optimal-size parameterized extended formulations for the solution polytopes associated with instances of these problems. On the other hand, unconditional lower bounds obtained in the realm of the theory of extended formulations yield unconditional lower bounds on the table complexity of solution-preserving dynamic programming algorithms.", "AI": {"tldr": "本文探讨了在图的树分解上动态规划算法与线性规划之间的联系，证明了一类顶点子集问题（VSPs）在满足特定条件下可以通过参数化扩展形式优化。", "motivation": "研究两类解决顶点子集问题的方法：基于树形结构上的动态规划和线性规划。通过建立两者间的关系来优化算法效率。", "method": "展示了当一个顶点子集问题Π有一个生成表大小不超过α(k,n)的保持解性质的动态编程算法时，该问题对应的凸包P_Π(G)的扩展复杂度为O(α(k,n)*n)，并证明了这一上界在指数时间假说下是最优的。", "result": "提出了一种将最优大小参数化扩展公式应用于组合问题的方法，并得到了无条件动态规划算法表复杂度的下限。", "conclusion": "揭示了解决顶点子集问题中，最优动态编程算法与线性规划之间的内在联系，提供了优化方法的新视角。"}}
{"id": "2601.06944", "pdf": "https://arxiv.org/pdf/2601.06944", "abs": "https://arxiv.org/abs/2601.06944", "authors": ["Yuhang Su", "Mei Wang", "Yaoyao Zhong", "Guozhang Li", "Shixing Li", "Yihan Feng", "Hua Huang"], "title": "SketchJudge: A Diagnostic Benchmark for Grading Hand-drawn Diagrams with Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "8 pages for the main text (excluding references and the limitations section); 37 pages in total including appendices", "summary": "While Multimodal Large Language Models (MLLMs) have achieved remarkable progress in visual understanding, they often struggle when faced with the unstructured and ambiguous nature of human-generated sketches. This limitation is particularly pronounced in the underexplored task of visual grading, where models should not only solve a problem but also diagnose errors in hand-drawn diagrams. Such diagnostic capabilities depend on complex structural, semantic, and metacognitive reasoning. To bridge this gap, we introduce SketchJudge, a novel benchmark tailored for evaluating MLLMs as graders of hand-drawn STEM diagrams. SketchJudge encompasses 1,015 hand-drawn student responses across four domains: geometry, physics, charts, and flowcharts, featuring diverse stylistic variations and distinct error types. Evaluations on SketchJudge demonstrate that even advanced MLLMs lag significantly behind humans, validating the benchmark's effectiveness in exposing the fragility of current vision-language alignment in symbolic and noisy contexts. All data, code, and evaluation scripts are publicly available at https://github.com/yuhangsu82/SketchJudge.", "AI": {"tldr": "SketchJudge是一款用于评估多模态大型语言模型在手绘STEM图表评分能力的新基准。", "motivation": "现有的多模态大型语言模型在理解结构化和明确的视觉信息方面表现出色，但在处理由人类生成的手绘草图时面临挑战。这些模型尤其难以进行图像诊断任务，需要复杂的结构性、语义性以及元认知推理。", "method": "提出了SketchJudge基准测试集，包含了来自四个领域的1015个手绘学生回答：几何学、物理、图表和流程图，具有多样化的风格变异和独特的错误类型。通过该数据集对现有模型进行了评估。", "result": "结果表明，即使是先进的多模态大型语言模型，在SketchJudge上的表现也远逊于人类，这证明了基准测试的有效性，能够揭示当前视觉-语言对齐在符号性和噪声背景下存在的脆弱性。", "conclusion": "论文引入的SketchJudge是评估多模态大型语言模型进行手绘STEM图表评分能力的新工具。它展示了现有模型在这方面的不足，并为未来的研究指明了方向。"}}
{"id": "2601.06943", "pdf": "https://arxiv.org/pdf/2601.06943", "abs": "https://arxiv.org/abs/2601.06943", "authors": ["Chengwen Liu", "Xiaomin Yu", "Zhuoyue Chang", "Zhe Huang", "Shuo Zhang", "Heng Lian", "Kunyi Wang", "Rui Xu", "Sen Hu", "Jianheng Hou", "Hao Peng", "Chengwei Qin", "Xiaobin Hu", "Hong Peng", "Ronghao Chen", "Huacan Wang"], "title": "Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In real-world video question answering scenarios, videos often provide only localized visual cues, while verifiable answers are distributed across the open web; models therefore need to jointly perform cross-frame clue extraction, iterative retrieval, and multi-hop reasoning-based verification. To bridge this gap, we construct the first video deep research benchmark, VideoDR. VideoDR centers on video-conditioned open-domain video question answering, requiring cross-frame visual anchor extraction, interactive web retrieval, and multi-hop reasoning over joint video-web evidence; through rigorous human annotation and quality control, we obtain high-quality video deep research samples spanning six semantic domains. We evaluate multiple closed-source and open-source multimodal large language models under both the Workflow and Agentic paradigms, and the results show that Agentic is not consistently superior to Workflow: its gains depend on a model's ability to maintain the initial video anchors over long retrieval chains. Further analysis indicates that goal drift and long-horizon consistency are the core bottlenecks. In sum, VideoDR provides a systematic benchmark for studying video agents in open-web settings and reveals the key challenges for next-generation video deep research agents.", "AI": {"tldr": "构建了VideoDR基准测试，用于评估视频条件下的开放领域视频问答任务。", "motivation": "解决视频提供的线索与网络上可验证的答案之间的差距问题，提升多模态模型在开放场景下视频理解的能力。", "method": "通过交叉帧视觉锚点提取、互动式网页检索和基于多跳推理的联合证据验证来构建VideoDR基准测试。", "result": "评估了多种封闭源与开源的多模态大语言模型，结果显示Agentic模式并不总是优于Workflow模式，其优势取决于模型维持初始视频锚的能力。", "conclusion": "VideoDR提供了一个系统化的基准测试，用于研究开放网络环境中视频代理的关键挑战。"}}
{"id": "2601.06940", "pdf": "https://arxiv.org/pdf/2601.06940", "abs": "https://arxiv.org/abs/2601.06940", "authors": ["Hengyu Liu", "Tianyi Li", "Haoyu Wang", "Kristian Torp", "Tiancheng Zhang", "Yushuai Li", "Christian S. Jensen"], "title": "VISTA: Knowledge-Driven Interpretable Vessel Trajectory Imputation via Large Language Models", "categories": ["cs.DB", "cs.AI"], "comment": "22 pages, 13 figures, 3 algorithms, 5 tables. Code available at https://github.com/hyLiu1994/VISTA", "summary": "The Automatic Identification System provides critical information for maritime navigation and safety, yet its trajectories are often incomplete due to signal loss or deliberate tampering. Existing imputation methods emphasize trajectory recovery, paying limited attention to interpretability and failing to provide underlying knowledge that benefits downstream tasks such as anomaly detection and route planning. We propose knowledge-driven interpretable vessel trajectory imputation (VISTA), the first trajectory imputation framework that offers interpretability while simultaneously providing underlying knowledge to support downstream analysis. Specifically, we first define underlying knowledge as a combination of Structured Data-derived Knowledge (SDK) distilled from AIS data and Implicit LLM Knowledge acquired from large-scale Internet corpora. Second, to manage and leverage the SDK effectively at scale, we develop a data-knowledge-data loop that employs a Structured Data-derived Knowledge Graph for SDK extraction and knowledge-driven trajectory imputation. Third, to efficiently process large-scale AIS data, we introduce a workflow management layer that coordinates the end-to-end pipeline, enabling parallel knowledge extraction and trajectory imputation with anomaly handling and redundancy elimination. Experiments on two large AIS datasets show that VISTA is capable of state-of-the-art imputation accuracy and computational efficiency, improving over state-of-the-art baselines by 5%-94% and reducing time cost by 51%-93%, while producing interpretable knowledge cues that benefit downstream tasks. The source code and implementation details of VISTA are publicly available.", "AI": {"tldr": "提出了一种基于知识驱动的可解释船舶轨迹填补框架VISTA。", "motivation": "现有方法在恢复轨迹完整性方面效果有限，忽略了可解释性以及提供支持下游任务所需的知识。", "method": "利用大型语言模型和结构化数据衍生知识图谱提取知识，并通过数据-知识-数据循环实现高效且准确的轨迹填补。", "result": "实验结果显示VISTA提高了5%-94%的填补精度，减少了51%-93%的时间成本，并提供了有利于下游任务的知识线索。", "conclusion": "VISTA框架首次实现了可解释性与提供支持知识相结合的目标，在填补准确性、计算效率和实用性方面均表现出色。"}}
{"id": "2601.06937", "pdf": "https://arxiv.org/pdf/2601.06937", "abs": "https://arxiv.org/abs/2601.06937", "authors": ["Fozle Rabbi Shafi", "M. Anwar Hossain", "Salimur Choudhury"], "title": "mind_call: A Dataset for Mental Health Function Calling with Large Language Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Model (LLM)-based systems increasingly rely on function calling to enable structured and controllable interaction with external data sources, yet existing datasets do not address mental health-oriented access to wearable sensor data. This paper presents a synthetic function-calling dataset designed for mental health assistance grounded in wearable health signals such as sleep, physical activity, cardiovascular measures, stress indicators, and metabolic data. The dataset maps diverse natural language queries to standardized API calls derived from a widely adopted health data schema. Each sample includes a user query, a query category, an explicit reasoning step, a normalized temporal parameter, and a target function. The dataset covers explicit, implicit, behavioral, symptom-based, and metaphorical expressions, which reflect realistic mental health-related user interactions. This resource supports research on intent grounding, temporal reasoning, and reliable function invocation in LLM-based mental health agents and is publicly released to promote reproducibility and future work.", "AI": {"tldr": "构建了一个用于心理健康辅助的合成函数调用数据集，该数据集基于可穿戴健康信号，并支持自然语言查询到标准API调用的映射。", "motivation": "现有的数据集中没有针对心理健康领域使用大型语言模型（LLM）访问可穿戴传感器数据的支持。此数据集旨在填补这一空白，为研究和开发提供资源。", "method": "创建了一个合成函数调用数据集，包括用户查询、查询类别、显式推理步骤、标准化时间参数以及目标函数。该数据集涵盖了各种类型的表达方式，并映射到标准健康数据模式的API调用中。", "result": "提供了涵盖多种类型心理健康相关交互的数据样本，支持意图定位、时态推理和可靠的函数调用研究。", "conclusion": "发布的数据集有助于推进基于LLM的心理健康代理的研究，并促进了可重复性和未来工作的发展。"}}
{"id": "2601.06932", "pdf": "https://arxiv.org/pdf/2601.06932", "abs": "https://arxiv.org/abs/2601.06932", "authors": ["Stephen Gadd"], "title": "Symphonym: Universal Phonetic Embeddings for Cross-Script Toponym Matching via Teacher-Student Distillation", "categories": ["cs.CL", "cs.AI"], "comment": "30 pages, 5 tables, 2 figures", "summary": "Linking place names across languages and writing systems is a fundamental challenge in digital humanities and geographic information retrieval. Existing approaches rely on language-specific phonetic algorithms or transliteration rules that fail when names cross script boundaries -- no string metric can determine that \"Moscow\" when rendered in Cyrillic or Arabic refer to the same city. I present Symphonym, a neural embedding system that maps toponyms from 20 writing systems into a unified 128-dimensional phonetic space. A Teacher network trained on articulatory phonetic features (via Epitran and PanPhon) produces target embeddings, while a Student network learns to approximate these from raw characters. At inference, only the lightweight Student (1.7M parameters) is required, enabling deployment without runtime phonetic conversion. Training uses a three-phase curriculum on 57 million toponyms from GeoNames, Wikidata, and the Getty Thesaurus of Geographic Names. Phase 1 trains the Teacher on 467K phonetically-grounded triplets. Phase 2 aligns the Student to Teacher outputs across 23M samples, achieving 96.6% cosine similarity. Phase 3 fine-tunes on 3.3M hard negative triplets -- negatives sharing prefix and script with the anchor but referring to different places -- to sharpen discrimination. Evaluation on the MEHDIE Hebrew-Arabic benchmark achieves 89.2% Recall@1, outperforming Levenshtein (81.5%) and Jaro-Winkler (78.5%). The system is optimised for cross-script matching; same-script variants can be handled by complementary string methods. Symphonym will enable fuzzy phonetic reconciliation and search across the World Historical Gazetteer's 67 million toponyms. Code and models are publicly available.", "AI": {"tldr": "通过教师学生蒸馏法，提出了Symphonym系统，用于不同书写系统的地名匹配。", "motivation": "跨语言和文字的地名链接是数字人文和地理信息检索的基本挑战。现有方法依赖于特定语言的音韵算法或转写规则，在跨越书写系统时失效。因此需要一种能够将20种书写系统中的地名映射到统一的声音空间的方法。", "method": "Symphonym系统通过教师网络训练得到目标嵌入，学生网络从原始字符学习近似这些嵌入。教师网络基于Epitran和PanPhon的发音特征训练，而学生网络则在三阶段课程上进行训练：第一阶段针对467K个带有语音基础的三元组；第二阶段通过23M样本使学生网络与教师输出对齐；第三阶段细化负例，以增强区分度。", "result": "Symphonym系统在MEHDIE希伯来-阿拉伯基准测试中达到了89.2%的Recall@1，优于Levenshtein(81.5%)和Jaro-Winkler(78.5%)。该系统优化了跨书写系统的匹配，并且可以通过互补字符串方法处理同一种书写的变体。", "conclusion": "Symphonym系统将能够实现模糊的声音重新调和搜索，覆盖世界历史地名集中的6700万条目。代码和模型公开可用。"}}
{"id": "2601.06931", "pdf": "https://arxiv.org/pdf/2601.06931", "abs": "https://arxiv.org/abs/2601.06931", "authors": ["Haodong Chen", "Qiang Huang", "Jiaqi Zhao", "Qiuping Jiang", "Xiaojun Chang", "Jun Yu"], "title": "Measuring Social Bias in Vision-Language Models with Face-Only Counterfactuals from Real Photos", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "18 pages, 18 figures, and 3 tables", "summary": "Vision-Language Models (VLMs) are increasingly deployed in socially consequential settings, raising concerns about social bias driven by demographic cues. A central challenge in measuring such social bias is attribution under visual confounding: real-world images entangle race and gender with correlated factors such as background and clothing, obscuring attribution. We propose a \\textbf{face-only counterfactual evaluation paradigm} that isolates demographic effects while preserving real-image realism. Starting from real photographs, we generate counterfactual variants by editing only facial attributes related to race and gender, keeping all other visual factors fixed. Based on this paradigm, we construct \\textbf{FOCUS}, a dataset of 480 scene-matched counterfactual images across six occupations and ten demographic groups, and propose \\textbf{REFLECT}, a benchmark comprising three decision-oriented tasks: two-alternative forced choice, multiple-choice socioeconomic inference, and numeric salary recommendation. Experiments on five state-of-the-art VLMs reveal that demographic disparities persist under strict visual control and vary substantially across task formulations. These findings underscore the necessity of controlled, counterfactual audits and highlight task design as a critical factor in evaluating social bias in multimodal models.", "AI": {"tldr": "论文提出了一个新的评估范式，通过编辑真实照片中的面部属性来分离种族和性别对视觉语言模型的影响。", "motivation": "在实际应用场景中，视觉语言模型可能会受到种族和社会经济地位等人口统计学因素的偏见影响。由于现实世界图像中的多种因素交织在一起，导致难以精确评估这些偏见。", "method": "提出了一个基于真实照片生成面部属性编辑的反事实数据集FOCUS，并设计了一个名为REFLECT的任务基准来评估模型在控制视觉条件下的人口统计学偏差。", "result": "实验结果显示，在严格控制视觉条件的情况下，人口统计学差异仍然存在并且不同的任务形式会导致显著的变化。", "conclusion": "研究强调了对多模态模型进行反事实审计的必要性，并指出了任务设计是评估社会偏见的关键因素。"}}
{"id": "2601.06928", "pdf": "https://arxiv.org/pdf/2601.06928", "abs": "https://arxiv.org/abs/2601.06928", "authors": ["Shenghao Zhang", "Runtao Liu", "Christopher Schroers", "Yang Zhang"], "title": "RenderFlow: Single-Step Neural Rendering via Flow Matching", "categories": ["cs.CV"], "comment": null, "summary": "Conventional physically based rendering (PBR) pipelines generate photorealistic images through computationally intensive light transport simulations. Although recent deep learning approaches leverage diffusion model priors with geometry buffers (G-buffers) to produce visually compelling results without explicit scene geometry or light simulation, they remain constrained by two major limitations. First, the iterative nature of the diffusion process introduces substantial latency. Second, the inherent stochasticity of these generative models compromises physical accuracy and temporal consistency. In response to these challenges, we propose a novel, end-to-end, deterministic, single-step neural rendering framework, RenderFlow, built upon a flow matching paradigm. To further strengthen both rendering quality and generalization, we propose an efficient and effective module for sparse keyframe guidance. Our method significantly accelerates the rendering process and, by optionally incorporating sparsely rendered keyframes as guidance, enhances both the physical plausibility and overall visual quality of the output. The resulting pipeline achieves near real-time performance with photorealistic rendering quality, effectively bridging the gap between the efficiency of modern generative models and the precision of traditional physically based rendering. Furthermore, we demonstrate the versatility of our framework by introducing a lightweight, adapter-based module that efficiently repurposes the pretrained forward model for the inverse rendering task of intrinsic decomposition.", "AI": {"tldr": "提出了一种基于流匹配范式的单步神经渲染框架RenderFlow，以加速渲染过程并提高物理逼真度。", "motivation": "现有深度学习方法在生成具有几何缓冲区的视觉吸引人的结果时存在迭代延迟和物理准确性问题。为了解决这些问题，作者提出了一个端到端、确定性的单步骤神经渲染框架。", "method": "提出RenderFlow，采用流匹配范式，结合稀疏关键帧指导模块以提高渲染质量和泛化能力。该方法通过预训练的前向模型实现逆向渲染任务。", "result": "新方法实现了接近实时性能和高质量的光栅现实渲染效果，有效弥合了现代生成模型效率与传统物理基于渲染精度之间的差距。", "conclusion": "RenderFlow框架在加速渲染过程的同时提高了输出的质量和一致性，展示了该技术在逆向渲染任务中的高效性和适应性。"}}
{"id": "2601.06920", "pdf": "https://arxiv.org/pdf/2601.06920", "abs": "https://arxiv.org/abs/2601.06920", "authors": ["Boquan Jiang", "Zhenhua Yang", "Chenkai Wang", "Muyao Zhong", "Heping Fang", "Peng Yang"], "title": "Calibrating Agent-Based Financial Markets Simulators with Pretrainable Automatic Posterior Transformation-Based Surrogates", "categories": ["cs.NE", "cs.MA"], "comment": "32 pages, 4 figures", "summary": "Calibrating Agent-Based Models (ABMs) is an important optimization problem for simulating the complex social systems, where the goal is to identify the optimal parameter of a given ABM by minimizing the discrepancy between the simulated data and the real-world observations. Unfortunately, it suffers from the extensive computational costs of iterative evaluations, which involves the expensive simulation with the candidate parameter. While Surrogate-Assisted Evolutionary Algorithms (SAEAs) have been widely adopted to alleviate the computational burden, existing methods face two key limitations: 1) surrogating the original evaluation function is hard due the nonlinear yet multi-modal nature of the ABMs, and 2) the commonly used surrogates cannot share the optimization experience among multiple calibration tasks, making the batched calibration less effective. To address these issues, this work proposes Automatic posterior transformation with Negatively Correlated Search and Adaptive Trust-Region (ANTR). ANTR first replaces the traditional surrogates with a pretrainable neural density estimator that directly models the posterior distribution of the parameters given observed data, thereby aligning the optimization objective with parameter-space accuracy. Furthermore, we incorporate a diversity-preserving search strategy to prevent premature convergence and an adaptive trust-region method to efficiently allocate computational resources. We take two representative ABM-based financial market simulators as the test bench as due to the high non-linearity. Experiments demonstrate that the proposed ANTR significantly outperforms conventional metaheuristics and state-of-the-art SAEAs in both calibration accuracy and computational efficiency, particularly in batch calibration scenarios across multiple market conditions.", "AI": {"tldr": "提出了一种新的代理方法ANTR，用于校准基于代理的模型（ABM），特别是在金融市场的仿真中。该方法采用预训练神经密度估计器和适应性信任区域法来提高计算效率和准确性。", "motivation": "现有的代理辅助进化算法在处理非线性和多模态问题时存在困难，并且无法共享优化经验于多个校准任务，导致批量校准时效果不佳。因此需要一种新的方法来解决这些问题。", "method": "提出了一种名为自动后验转换与负相关搜索和自适应信任区域（ANTR）的新代理方法，该方法使用预训练神经密度估计器直接建模参数的后验分布，并结合多样性和搜索策略以及自适应信任区域法以提高计算效率。", "result": "实验结果表明，所提出的方法在多种市场条件下，在校准准确性和计算效率方面均优于传统元启发式算法和最先进的代理辅助进化算法。", "conclusion": "ANTR方法通过引入预训练神经密度估计器和自适应信任区域法来改善基于代理模型的校准问题，特别适用于金融市场的仿真。"}}
{"id": "2601.06914", "pdf": "https://arxiv.org/pdf/2601.06914", "abs": "https://arxiv.org/abs/2601.06914", "authors": ["Ying Zhou", "Jiacheng Wei", "Yu Qi", "Faguo Wu", "Xiao Zhang"], "title": "Towards Compositional Generalization in LLMs for Smart Contract Security: A Case Study on Reentrancy Vulnerabilities", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) demonstrate remarkable capabilities in natural language understanding and generation. Despite being trained on large-scale, high-quality data, LLMs still fail to outperform traditional static analysis tools in specialized domains like smart contract vulnerability detection. To address this issue, this paper proposes a post-training algorithm based on atomic task decomposition and fusion. This algorithm aims to achieve combinatorial generalization under limited data by decomposing complex reasoning tasks. Specifically, we decompose the reentrancy vulnerability detection task into four linearly independent atomic tasks: identifying external calls, identifying state updates, identifying data dependencies between external calls and state updates, and determining their data flow order. These tasks form the core components of our approach. By training on synthetic datasets, we generate three compiler-verified datasets. We then employ the Slither tool to extract structural information from the control flow graph and data flow graph, which is used to fine-tune the LLM's adapter. Experimental results demonstrate that low-rank normalization fusion with the LoRA adapter improves the LLM's reentrancy vulnerability detection accuracy to 98.2%, surpassing state-of-the-art methods. On 31 real-world contracts, the algorithm achieves a 20% higher recall than traditional analysis tools.", "AI": {"tldr": "提出了一种基于原子任务分解和融合的LLM后训练算法，以提高智能合约重入漏洞检测的准确性。", "motivation": "尽管大规模语言模型表现出色，但在特定领域如智能合约漏洞检测中仍不及传统的静态分析工具。为解决此问题，本文致力于通过数据增强与模型微调来改进LLM在该领域的性能。", "method": "将重入漏洞检测任务分解为四个独立的原子任务，并基于合成数据集训练生成三个编译器验证的数据集。利用Slither工具从控制流图和数据流图中提取结构信息，以用于细粒度模型调整。通过低秩正则化融合技术改进LLM的表现。", "result": "实验结果显示，采用LoRA适配器的低秩正则化融合方法使重入漏洞检测准确率达到98.2%，超过了现有最佳方案，并在31个实际合约上提高了20%的召回率。", "conclusion": "该研究展示了如何通过任务分解和模型调优提高LLM在智能合约安全领域的性能，为未来的研究提供了新的方向。"}}
{"id": "2601.06911", "pdf": "https://arxiv.org/pdf/2601.06911", "abs": "https://arxiv.org/abs/2601.06911", "authors": ["Shaoning Sun", "Mingzhu Cai", "Huang He", "Bingjin Chen", "Siqi Bao", "Yujiu Yang", "Hua Wu", "Haifeng Wang"], "title": "Distributional Clarity: The Hidden Driver of RL-Friendliness in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Language model families exhibit striking disparity in their capacity to benefit from reinforcement learning: under identical training, models like Qwen achieve substantial gains, while others like Llama yield limited improvements. Complementing data-centric approaches, we reveal that this disparity reflects a hidden structural property: \\textbf{distributional clarity} in probability space. Through a three-stage analysis-from phenomenon to mechanism to interpretation-we uncover that RL-friendly models exhibit intra-class compactness and inter-class separation in their probability assignments to correct vs. incorrect responses. We quantify this clarity using the \\textbf{Silhouette Coefficient} ($S$) and demonstrate that (1) high $S$ correlates strongly with RL performance; (2) low $S$ is associated with severe logic errors and reasoning instability. To confirm this property, we introduce a Silhouette-Aware Reweighting strategy that prioritizes low-$S$ samples during training. Experiments across six mathematical benchmarks show consistent improvements across all model families, with gains up to 5.9 points on AIME24. Our work establishes distributional clarity as a fundamental, trainable property underlying RL-Friendliness.", "AI": {"tldr": "揭示了大语言模型在强化学习中表现差异的根本原因：分布清晰度，并提出了一种基于轮廓系数的重加权训练策略以提高模型性能。", "motivation": "解释为什么一些大型语言模型在相同条件下通过强化学习受益更多，而另一些则不然。作者发现这种差异背后隐藏了一个结构特性——概率空间中的分布清晰度。", "method": "首先展示了现象，然后深入分析背后的机制，最后引入了基于轮廓系数的重加权训练策略（Silhouette-Aware Reweighting）来改善模型在低S样本上的性能。", "result": "通过实验验证，在六项数学基准测试中，所有模型家族都表现出一致的改进，AIME24任务上最高获得了5.9点的增长。", "conclusion": "提出了分布清晰度作为强化学习友好性的关键属性，并展示了如何通过训练策略来提高这一属性。"}}
{"id": "2601.06909", "pdf": "https://arxiv.org/pdf/2601.06909", "abs": "https://arxiv.org/abs/2601.06909", "authors": ["Zengyuan Zuo", "Junjun Jiang", "Gang Wu", "Xianming Liu"], "title": "UDPNet: Unleashing Depth-based Priors for Robust Image Dehazing", "categories": ["cs.CV"], "comment": null, "summary": "Image dehazing has witnessed significant advancements with the development of deep learning models. However, a few methods predominantly focus on single-modal RGB features, neglecting the inherent correlation between scene depth and haze distribution. Even those that jointly optimize depth estimation and image dehazing often suffer from suboptimal performance due to inadequate utilization of accurate depth information. In this paper, we present UDPNet, a general framework that leverages depth-based priors from large-scale pretrained depth estimation model DepthAnything V2 to boost existing image dehazing models. Specifically, our architecture comprises two typical components: the Depth-Guided Attention Module (DGAM) adaptively modulates features via lightweight depth-guided channel attention, and the Depth Prior Fusion Module (DPFM) enables hierarchical fusion of multi-scale depth map features by dual sliding-window multi-head cross-attention mechanism. These modules ensure both computational efficiency and effective integration of depth priors. Moreover, the intrinsic robustness of depth priors empowers the network to dynamically adapt to varying haze densities, illumination conditions, and domain gaps across synthetic and real-world data. Extensive experimental results demonstrate the effectiveness of our UDPNet, outperforming the state-of-the-art methods on popular dehazing datasets, such as 0.85 dB PSNR improvement on the SOTS dataset, 1.19 dB on the Haze4K dataset and 1.79 dB PSNR on the NHR dataset. Our proposed solution establishes a new benchmark for depth-aware dehazing across various scenarios. Pretrained models and codes will be released at our project https://github.com/Harbinzzy/UDPNet.", "AI": {"tldr": "UDPNet利用深度信息先验提升图像去雾效果。", "motivation": "现有方法主要依赖RGB特征，忽视了场景深度与雾霾分布之间的内在关联。为了充分利用准确的深度信息改善去雾性能，提出了一种新框架。", "method": "UDPNet通过从预训练的大规模深度估计模型中获取深度先验来增强现有的图像去雾模型，包含两个组件：轻量级通道注意机制和多尺度深度图特征融合模块。", "result": "实验结果表明，UDPNet在SOTS、Haze4K和NHR数据集上分别取得了0.85dB、1.19dB和1.79dB的PSNR提升，优于现有最佳方法。", "conclusion": "UDPNet通过利用深度信息先验改进图像去雾性能，在不同场景下建立了新的基准。"}}
{"id": "2601.06902", "pdf": "https://arxiv.org/pdf/2601.06902", "abs": "https://arxiv.org/abs/2601.06902", "authors": ["Stinne Zacho", "Chris Hall", "Jakob Kusnick", "Stefan Jänicke"], "title": "Santa Clara 3D: Digital Reconstruction and Storytelling of a Francoist Concentration Camp", "categories": ["cs.HC"], "comment": null, "summary": "This paper explores the potential of digital reconstruction and interactive storytelling to preserve historically suppressed sites. The main objective of an interdisciplinary team of data scientists from the MEMORISE project and associates of the memory association Asociacion Recuerdo y Dignidad was to preserve the memory of the Francoist Santa Clara concentration camp in Soria, Spain, through the use of digital technology. Combining archival research, 3D modelling, 360-degree photography, and web development, a prototype digital platform was created to visualise the transformation of the site across three historical phases: its origin as a convent, its use as a Francoist concentration camp, and its present-day condition. The platform allows users to navigate through spatial and temporal layers. Clickable media markers encourage exploration and interaction. Drawing on principles of participatory design, narrative visualisation, and open-ended user engagement, the project demonstrates how digital tools can support memory work, public engagement, and historical reflection. Our low-cost concept is especially adaptable to other physical sites that have been erased or forgotten.", "AI": {"tldr": "该论文探讨了通过数字化重建和互动叙事来保存被历史遗忘的场所的可能性，以纪念西班牙法西斯主义时期的圣克拉拉集中营。", "motivation": "为了保护并传播在西班牙法西斯统治下被压抑的历史记忆，研究团队结合数字技术如档案研究、3D建模等创建了一个原型数字化平台。", "method": "通过使用档案资料、三维建模以及全景摄影等手段，构建一个能够展示从修道院到集中营再到现今状态的遗址演变过程的交互式网页平台。", "result": "该项目创造了一种低成本且易于适应其他被遗忘或抹去物理场所的方法，促进公众参与和历史反思。", "conclusion": "通过数字化工具支持记忆工作、公共参与以及历史反思的重要性得到了体现。"}}
{"id": "2601.06899", "pdf": "https://arxiv.org/pdf/2601.06899", "abs": "https://arxiv.org/abs/2601.06899", "authors": ["Jikai Chen", "Long Chen", "Dong Wang", "Qinglin Su", "Zhixuan Chu", "Bingguang Hao", "Leilei Gan", "Chenyi Zhuang", "Jinjie Gu"], "title": "V2P: Visual Attention Calibration for GUI Grounding via Background Suppression and Center Peaking", "categories": ["cs.AI"], "comment": null, "summary": "Precise localization of GUI elements is crucial for the development of GUI agents. Traditional methods rely on bounding box or center-point regression, neglecting spatial interaction uncertainty and visual-semantic hierarchies. Recent methods incorporate attention mechanisms but still face two key issues: (1) ignoring processing background regions causes attention drift from the desired area, and (2) uniform modeling the target UI element fails to distinguish between its center and edges, leading to click imprecision. Inspired by how humans visually process and interact with GUI elements, we propose the Valley-to-Peak (V2P) method to address these issues. To mitigate background distractions, V2P introduces a suppression attention mechanism that minimizes the model's focus on irrelevant regions to highlight the intended region. For the issue of center-edge distinction, V2P applies a Fitts' Law-inspired approach by modeling GUI interactions as 2D Gaussian heatmaps where the weight gradually decreases from the center towards the edges. The weight distribution follows a Gaussian function, with the variance determined by the target's size. Consequently, V2P effectively isolates the target area and teaches the model to concentrate on the most essential point of the UI element. The model trained by V2P achieves the performance with 92.4\\% and 52.5\\% on two benchmarks ScreenSpot-v2 and ScreenSpot-Pro (see Fig.~\\ref{fig:main_results_charts}). Ablations further confirm each component's contribution, underscoring V2P's generalizability in precise GUI grounding tasks and its potential for real-world deployment in future GUI agents.", "AI": {"tldr": "本文提出了一种新的方法V2P，用于提高GUI元素的定位精度。", "motivation": "传统的GUI定位方法忽视了空间交互不确定性及视觉语义层次结构。最近的方法虽然引入了注意力机制但仍存在两个问题：背景处理不当导致注意力漂移和目标UI元素中心与边缘区分度不足引起点击不精确。", "method": "V2P通过引入抑制注意机制减少模型对无关区域的关注，同时采用Fitts定律启发式的二维高斯热图方法来增强中心点的权重。", "result": "使用V2P训练的模型在ScreenSpot-v2和ScreenSpot-Pro两个基准测试上分别达到了92.4%和52.5%的成绩。", "conclusion": "实验表明，V2P能够有效解决GUI定位中的关键问题，并且具有广泛的应用前景。"}}
{"id": "2601.06898", "pdf": "https://arxiv.org/pdf/2601.06898", "abs": "https://arxiv.org/abs/2601.06898", "authors": ["Sonia Yeh", "Rishabh Ghotge", "Yujia Shi", "Luka de Koe"], "title": "Resilience by Design: A KPI for Heavy-Duty Megawatt Charging", "categories": ["cs.ET"], "comment": null, "summary": "We introduce a stressor-agnostic Resilience Key Performance Indicator (Resilience KPI) for megawatt charging stations (MSC) serving heavy-duty vehicles. Beyond routine performance statistics (e.g., availability, throughput), the KPI quantifies a site's ability to anticipate, operate under degradation, and recover from disruptions using observable signals already in the framework: ride-through capability, restoration speed, service under N-1, expected unserved charging energy, and queue impacts. The headline score is normalised to 0-100 for fair cross-site and cross-vendor benchmarking, with optional stressor-specific breakouts (grid, ICT, thermal, flooding, on-site incidents) for diagnostics and robustness checks. DATEX II provides a solid baseline for resilience KPIs centred on infrastructure inventory, status, and pricing, while additional KPIs, especially around grid capacity, on-site flexibility, heavy-vehicle geometry, environmental hardening, maintenance, and market exposure, are essential for a complete resilience picture and will require extensions or complementary data sources. The KPI is designed for monthly/quarterly reporting to support design and operational decisions and cost-benefit assessment of mitigations (e.g., backup power, spares, procedures). It offers a consistent, transparent methodology that consolidates heterogeneous logs and KPIs into a single, auditable indicator, making resilience comparable across sites, vendors, and jurisdictions.", "AI": {"tldr": "该论文提出了一种针对重型车辆的兆瓦级充电站（MSC）的韧性关键绩效指标（Resilience KPI），用于衡量站点在面对不同压力情况时的表现。", "motivation": "为了更好地评估和比较兆瓦级充电站在不同情境下的恢复能力和持续运行能力，从而支持设计、运营决策以及成本效益分析。", "method": "通过使用现有的可观察信号（如过载处理能力、恢复速度和服务在N-1条件下等），来量化站点的韧性，并将指标标准化到0-100范围，以便进行公平比较。此外还考虑了电网容量、现场灵活性和市场暴露度等因素。", "result": "提供了一个能够合并不同日志和KPI的统一方法论，该方法论可以生成一个单一且可审计的韧性指标，并支持月度或季度报告。", "conclusion": "这个Resilience KPI为评估和比较充电站的韧性提供了标准化工具，有助于做出更明智的设计和运营决策。"}}
{"id": "2601.06896", "pdf": "https://arxiv.org/pdf/2601.06896", "abs": "https://arxiv.org/abs/2601.06896", "authors": ["Mingyue Huo", "Yiwen Shao", "Yuheng Zhang"], "title": "TagSpeech: End-to-End Multi-Speaker ASR and Diarization with Fine-Grained Temporal Grounding", "categories": ["eess.AS", "cs.CL"], "comment": null, "summary": "We present TagSpeech, a unified LLM-based framework that utilizes Temporal Anchor Grounding for joint multi-speaker ASR and diarization. The framework is built on two key designs: (1) decoupled semantic and speaker streams fine-tuned via Serialized Output Training (SOT) to learn turn-taking dynamics; and (2) an interleaved time anchor mechanism that not only supports fine-grained timestamp prediction but also acts as a synchronization signal between semantic understanding and speaker tracking. Compared to previous works that primarily focus on speaker-attributed ASR or implicit diarization, TagSpeech addresses the challenge of fine-grained speaker-content alignment and explicitly models \"who spoke what and when\" in an end-to-end manner. Experiments on AMI and AliMeeting benchmarks demonstrate that our method achieves consistent improvements in Diarization Error Rate (DER) over strong end-to-end baselines, including Qwen-Omni and Gemini, particularly in handling complex speech overlaps. Moreover, TagSpeech employs a parameter-efficient training paradigm in which the LLM backbone is frozen and only lightweight projectors are trained, resulting in strong performance with low computational cost.", "AI": {"tldr": "本文提出了TagSpeech框架，用于多说话人ASR和会话分割任务，并实现了细粒度的时间对齐。", "motivation": "传统方法主要关注说话人归因的ASR或隐式会话分割，而忽略了精确的说话内容与时间关系。因此，本文提出了一种新的统一LLM框架解决此问题。", "method": "TagSpeech结合了解耦语义和说话人流并通过Serialized Output Training进行微调，学习转换动态，并采用交错的时间锚机制来支持细粒度的时间戳预测和支持两个子任务之间的同步信号。同时采用轻量级投影器训练模式以减少计算成本。", "result": "在AMI和AliMeeting基准上实验显示，TagSpeech相比Qwen-Omni和Gemini等强大端到端基线方法，在处理复杂语音重叠时一致地降低了会话分割误差率（DER）。", "conclusion": "TagSpeech通过引入Temporal Anchor Grounding机制有效解决了多说话人ASR与细粒度时间对齐的挑战，同时保持了较低计算成本。"}}
{"id": "2601.06894", "pdf": "https://arxiv.org/pdf/2601.06894", "abs": "https://arxiv.org/abs/2601.06894", "authors": ["Sonia Yeh", "Christopher Dirzka", "Aleksandr Kondratenko", "Frans Libertson", "Benedicte Madon"], "title": "How Do Ports Organise Innovation? Linking Port Governance, Ownership, and Living Labs", "categories": ["cs.ET", "cs.CY"], "comment": null, "summary": "Ports are pivotal to decarbonisation and resilience, yet port studies rarely examine how ownership and decision rights shape the process and outcomes of sustainability and digital pilots. Living Lab (LL) scholarship offers strong concepts, but limited sector-grounded explanation of LL-governance fit in ports. We develop and apply a governance-LL fit framework linking port governance and ownership to four LL pillars: co-creation, real-life setting, iterative learning, and institutional embedding (multi-level decision-making). We apply the framework in a comparative case study of two analytically contrasting ports, anchored in port-defined priorities: an Energy Community pilot in Aalborg and a Green Coordinator function in Trelleborg. Using an LL macro-meso-micro lens, we distinguish the stable constellation of actors and mandates (macro), the governance of specific projects (meso), and the methods used to generate and test solutions (micro). Findings show that Landlord governance offers contract- and procurement-based landing zones (concessions/leases and tender clauses) that can codify LL outputs and support scaling across tenants and infrastructures. Tool/Public Service governance embeds learning mainly through SOPs, procurement specifications, and municipal coordination, enabling internal operational gains but limiting external codification without bespoke agreements. Across both ports, key needs are clear role definition, sustained stakeholder engagement, and timely alignment with decision windows. Overall, LL effectiveness is governance-contingent, reflecting where decision rights sit and which instruments embed learning into routine practice.", "AI": {"tldr": "本文探讨了港口所有权和决策权如何影响可持续性和数字化试点项目的组织与成果，并应用了一种治理-生活实验室适应框架来分析两个对比港口的情况。", "motivation": "研究较少关注港口的所有权和决策权对其可持续性及数字项目的影响，缺乏行业背景下的生活实验室治理适配解释。该论文填补了这一空白。", "method": "通过比较案例研究，在Aalborg和Trelleborg港口中应用一种新的框架来分析生活实验室治理适应情况。这个框架将港口治理与所有权联系到四个关键支柱：共同创造、真实场景设置、迭代学习以及制度嵌入（多层决策制定）。", "result": "发现地主型治理提供了合同和采购基础的登陆区，可以将生活实验室的结果编码并支持跨租户和基础设施扩展。而工具/公共服务型治理通过标准操作程序等途径嵌入学习过程。", "conclusion": "生活实验室的效果取决于治理结构，反映了决策权的位置以及哪些手段能够将其学习成果整合到日常实践中去。"}}
{"id": "2601.06891", "pdf": "https://arxiv.org/pdf/2601.06891", "abs": "https://arxiv.org/abs/2601.06891", "authors": ["Nimrod Shabtay", "Itamar Zimerman", "Eli Schwartz", "Raja Giryes"], "title": "CLIMP: Contrastive Language-Image Mamba Pretraining", "categories": ["cs.CV"], "comment": null, "summary": "Contrastive Language-Image Pre-training (CLIP) relies on Vision Transformers whose attention mechanism is susceptible to spurious correlations, and scales quadratically with resolution. To address these limitations, We present CLIMP, the first fully Mamba-based contrastive vision-language model that replaces both the vision and text encoders with Mamba. The new architecture encodes sequential structure in both vision and language, with VMamba capturing visual spatial inductive biases, reducing reliance on spurious correlations and producing an embedding space favorable for cross-modal retrieval and out-of-distribution robustness-surpassing OpenAI's CLIP-ViT-B by 7.5% on ImageNet-O. CLIMP naturally supports variable input resolutions without positional encoding interpolation or specialized training, achieving up to 6.6% higher retrieval accuracy at 16x training resolution while using 5x less memory and 1.8x fewer FLOPs. The autoregressive text encoder further overcomes CLIP's fixed context limitation, enabling dense captioning retrieval. Our findings suggest that Mamba exhibits advantageous properties for vision-language learning, making it a compelling alternative to Transformer-based CLIP.", "AI": {"tldr": "CLIMP提出了一种基于Mamba的对比语言图像预训练模型，旨在解决现有Vision Transformers中存在的问题，并展示了其在不同方面的优越性。", "motivation": "为了克服现有的基于Transformer的视觉-文本预训练方法（如CLIP）存在的易受虚假关联影响以及随分辨率增长而计算复杂度增加的问题，作者开发了使用Mamba架构的新模型。", "method": "CLIMP采用全Mamba架构替代原有的Vision Transformer和文本编码器，通过改进的方法在图像和语言上捕获序列结构，并减少了对虚假关联的依赖。同时，该方法支持可变输入分辨率，无需位置嵌入插值或专门训练，且能克服固定上下文限制。", "result": "CLIMP模型在ImageNet-O上的准确率超越了OpenAI的CLIP-ViT-B7.5%，并且实现了更高的检索精度、更低内存使用和更少FLOPs。此外，它还能够支持密集描述符检索任务。", "conclusion": "通过将Mamba架构应用于视觉-文本学习中，CLIMP模型表现出优于Transformer基于的方法的特性，并且在多种性能指标上有所提升。这表明了Mamba对于视觉语言学习具有显著的优势。"}}
{"id": "2601.06887", "pdf": "https://arxiv.org/pdf/2601.06887", "abs": "https://arxiv.org/abs/2601.06887", "authors": ["Yin Zhang", "Zian Ning", "Shiyu Zhao"], "title": "Observability-Enhanced Target Motion Estimation via Bearing-Box: Theory and MAV Applications", "categories": ["cs.RO"], "comment": "This paper is accepted by IEEE Transactions on Robotics (20 pages, 11 figures)", "summary": "Monocular vision-based target motion estimation is a fundamental challenge in numerous applications. This work introduces a novel bearing-box approach that fully leverages modern 3D detection measurements that are widely available nowadays but have not been well explored for motion estimation so far. Unlike existing methods that rely on restrictive assumptions such as isotropic target shape and lateral motion, our bearing-box estimator can estimate both the target's motion and its physical size without these assumptions by exploiting the information buried in a 3D bounding box. When applied to multi-rotor micro aerial vehicles (MAVs), the estimator yields an interesting advantage: it further removes the need for higher-order motion assumptions by exploiting the unique coupling between MAV's acceleration and thrust. This is particularly significant, as higher-order motion assumptions are widely believed to be necessary in state-of-the-art bearing-based estimators. We support our claims with rigorous observability analyses and extensive experimental validation, demonstrating the estimator's superior performance in real-world scenarios.", "AI": {"tldr": "本文提出了一种基于单目视觉的目标运动估计新方法，称为bearing-box方法，该方法利用现代3D检测测量来提高目标运动和尺寸的估计精度。", "motivation": "现有的单目视觉目标运动估计算法依赖于一些限制性假设，如等向性和侧向移动，这些算法在实际应用中的适应性较差。本文旨在提出一种新的方法，不需这些假设即可准确估算目标运动及其物理大小。", "method": "通过3D检测框内的信息提取，bearing-box方法能够估计目标的运动和尺寸，并且当应用于多旋翼微型空中飞行器时，该方法利用了无人机加速度与推力之间的独特耦合关系来进一步减少高阶运动假设的需求。", "result": "实验结果表明，所提出的bearing-box估计算法在现实世界场景中具有卓越的表现。通过严格的可观测性分析和广泛的实验验证支持其效果。", "conclusion": "本文证明了bearing-box方法能够在不依赖于现有算法的限制性假设的情况下提供更准确的目标运动估计，并且特别适用于微型空中飞行器，展示了显著的优势。"}}
{"id": "2601.06885", "pdf": "https://arxiv.org/pdf/2601.06885", "abs": "https://arxiv.org/abs/2601.06885", "authors": ["Jinwoo Hwang", "Yeongmin Hwang", "Tadiwos Meaza", "Hyeonbin Bae", "Jongse Park"], "title": "Understanding the Performance Behaviors of End-to-End Protein Design Pipelines on GPUs", "categories": ["cs.ET", "eess.SY"], "comment": "Accepted to CAL", "summary": "Recent computational advances enable protein design pipelines to run end-to-end on GPUs, yet their heterogeneous computational behaviors remain undercharacterized at the system level. We implement and profile a representative pipeline at both component and full-pipeline granularities across varying inputs and hyperparameters. Our characterization identifies generally low GPU utilization and high sensitivity to sequence length and sampling strategies. We outline future research directions based on these insights and release an open-source pipeline and profiling scripts to facilitate further studies.", "AI": {"tldr": "研究端到端蛋白质设计流水线在GPU上的性能表现", "motivation": "近期计算进步使蛋白质设计管道能够在GPU上运行，但其异构计算行为尚未从系统层面进行充分描述。", "method": "实施并剖析了一个代表性的蛋白质设计管道，并通过不同输入和超参数对其进行评估。同时，在组件级及整个流水线级别进行了性能分析。", "result": "结果发现一般情况下GPU利用率较低且对序列长度与采样策略高度敏感。", "conclusion": "基于这些见解，提出了未来的研究方向，并发布了开源蛋白质设计管道以及剖析脚本以促进进一步研究。"}}
{"id": "2601.06884", "pdf": "https://arxiv.org/pdf/2601.06884", "abs": "https://arxiv.org/abs/2601.06884", "authors": ["Masahiro Kaneko"], "title": "Paraphrasing Adversarial Attack on LLM-as-a-Reviewer", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The use of large language models (LLMs) in peer review systems has attracted growing attention, making it essential to examine their potential vulnerabilities. Prior attacks rely on prompt injection, which alters manuscript content and conflates injection susceptibility with evaluation robustness. We propose the Paraphrasing Adversarial Attack (PAA), a black-box optimization method that searches for paraphrased sequences yielding higher review scores while preserving semantic equivalence and linguistic naturalness. PAA leverages in-context learning, using previous paraphrases and their scores to guide candidate generation. Experiments across five ML and NLP conferences with three LLM reviewers and five attacking models show that PAA consistently increases review scores without changing the paper's claims. Human evaluation confirms that generated paraphrases maintain meaning and naturalness. We also find that attacked papers exhibit increased perplexity in reviews, offering a potential detection signal, and that paraphrasing submissions can partially mitigate attacks.", "AI": {"tldr": "本文提出了一种针对大型语言模型评审系统中的同义词对抗攻击方法，旨在寻找在保持语义等价和语言自然性的前提下提升论文审查评分的同义词序列。", "motivation": "随着大型语言模型在同行评议系统中应用的增长，其潜在的安全性问题引起了广泛关注。先前的方法依赖于提示注入，这种方法会修改手稿内容，并将注入易感性和评价稳健性混为一谈。本文旨在研究一种不改变论文核心论点而提升评分的同义词对抗攻击方法。", "method": "本文提出了一种基于黑盒优化的同义词对抗攻击（PAA）方法，通过在上下文学习中利用之前同义句和其分数来引导候选生成。该方法可以搜索出能够提高评审分数同时保持语义等价性和语言自然性的同义词序列。", "result": "实验结果表明，在五个机器学习和自然语言处理会议上的三个大型语言模型审稿人及五种攻击模型下，PAA方法均能显著提升审查评分而不改变论文核心论点。人类评估确认生成的同义句保持了意义和自然性，并且被攻击的文章在评审中表现出更高的困惑度，这为检测提供了潜在信号。", "conclusion": "本文证明了通过同义词对抗攻击可以提高大型语言模型审稿分数，并提出了利用该方法进行防御的部分策略。"}}
{"id": "2601.06883", "pdf": "https://arxiv.org/pdf/2601.06883", "abs": "https://arxiv.org/abs/2601.06883", "authors": ["Xinhang Liu", "Jiawei Shi", "Zheng Dang", "Yuchao Dai"], "title": "MixRI: Mixing Features of Reference Images for Novel Object Pose Estimation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ICCV 2025", "summary": "We present MixRI, a lightweight network that solves the CAD-based novel object pose estimation problem in RGB images. It can be instantly applied to a novel object at test time without finetuning. We design our network to meet the demands of real-world applications, emphasizing reduced memory requirements and fast inference time. Unlike existing works that utilize many reference images and have large network parameters, we directly match points based on the multi-view information between the query and reference images with a lightweight network. Thanks to our reference image fusion strategy, we significantly decrease the number of reference images, thus decreasing the time needed to process these images and the memory required to store them. Furthermore, with our lightweight network, our method requires less inference time. Though with fewer reference images, experiments on seven core datasets in the BOP challenge show that our method achieves comparable results with other methods that require more reference images and larger network parameters.", "AI": {"tldr": "提出了MixRI，一种轻量级网络，在RGB图像中解决基于CAD的新物体姿态估计问题。", "motivation": "旨在减少内存需求和加快推理时间，以满足实际应用的需求。通过直接匹配查询与参考图像之间的多视图信息，并使用轻量级网络，减少了对大量参考图像的依赖。", "method": "设计了一种轻量化网络MixRI，采用参考图像融合策略，在少用参考图像的情况下实现高效准确的姿态估计。", "result": "实验表明，尽管使用的参考图像较少，但在BOP挑战赛中的七个核心数据集上，该方法实现了与需要更多参考图像和更大网络参数的方法相当的结果。", "conclusion": "提出的方法在减少计算资源需求的同时保持了与其他方法相仿的精度，在实际应用中具有明显优势。"}}
{"id": "2601.06882", "pdf": "https://arxiv.org/pdf/2601.06882", "abs": "https://arxiv.org/abs/2601.06882", "authors": ["Dillan Imans", "Phuoc-Nguyen Bui", "Duc-Tai Le", "Hyunseung Choo"], "title": "Unsupervised Domain Adaptation with SAM-RefiSeR for Enhanced Brain Tumor Segmentation", "categories": ["cs.CV"], "comment": "Accepted in BIBM 2025", "summary": "Unsupervised Domain Adaptation with SAM-RefiSeR for Enhanced Brain Tumor Segmentation", "AI": {"tldr": "本文提出了一种新的无监督领域适应方法SAM-RefiSeR，用于增强脑肿瘤分割。", "motivation": "现有的脑肿瘤分割技术在不同数据集之间迁移时效果不佳，因此需要一种能够有效进行无监督领域适应的方法来提升跨数据集的性能。", "method": "提出了一种称为SAM-RefiSeR的新方法，该方法结合了自适应卷积和残差模块，以提高脑肿瘤分割在不同领域的泛化能力。", "result": "实验结果表明，使用SAM-RefiSeR的方法可以显著改善脑肿瘤分割的准确性，特别是在跨领域应用时的表现优于其他现有技术。", "conclusion": "通过引入无监督域适应技术，SAM-RefiSeR能够有效地提高脑肿瘤分割模型在不同数据集上的性能和泛化能力。"}}
{"id": "2601.06877", "pdf": "https://arxiv.org/pdf/2601.06877", "abs": "https://arxiv.org/abs/2601.06877", "authors": ["Donghuo Zeng", "Roberto Legaspi", "Kazushi Ikeda"], "title": "Personality-Aware Reinforcement Learning for Persuasive Dialogue with LLM-Driven Simulation", "categories": ["cs.HC", "cs.AI"], "comment": "15 pages, 7 figures, 3 tables", "summary": "Effective persuasive dialogue agents adapt their strategies to individual users, accounting for the evolution of their psychological states and intentions throughout conversations. We present a personality-aware reinforcement learning approach comprising three main modules: (1) a Strategy-Oriented Interaction Framework, which serves as an agenda-based strategy controller that selects strategy-level actions and generate responses via Maximal Marginal Relevance (MMR) retrieval to ensure contextual relevance, diversity, and scalable data generation; (2) Personality-Aware User Representation Learning, which produces an 81-dimensional mixed-type embedding predicted at each turn from recent exchanges and appended to the reinforcement learning state; and (3) a Dueling Double DQN (D3QN) model and Reward Prediction, in which the policy is conditioned on dialogue history and turn-level personality estimates and trained using a composite reward incorporating agreement intent, donation amount, and changeof-mind penalties. We use an agenda-based LLM simulation pipeline to generate diverse interactions, from which personality estimation is inferred from the generated utterances. Experiments on the PersuasionForGood (P4G) dataset augmented with simulated dialogues reveal three main findings: (i) turn-level personality conditioning improves policy adaptability and cumulative persuasion rewards; (ii) LLM-driven simulation enhances generalization to unseen user behaviors; and (iii) incorporating a change-of-mind penalty reduces post-agreement retractions while slightly improving donation outcomes. These results demonstrate that structured interaction, dynamic personality estimation, and behaviorally informed rewards together yield more effective persuasive policies.", "AI": {"tldr": "该论文提出了一种基于人格感知的强化学习方法，用于增强对话代理在劝说中的表现。", "motivation": "对话代理需要根据用户的心理状态和意图的变化来调整策略。传统的强化学习模型通常缺乏对个体差异的理解，因此无法有效适应不同的用户行为。", "method": "论文提出了一种包含三个模块的方法：(1) 战略导向交互框架；(2) 基于人格的用户表示学习；(3) 杜林双DQN和奖励预测。此外，使用基于议程的语言模型模拟来生成对话以进行训练。", "result": "实验显示，在增强劝说效果方面，转轮级的人格估计条件化、LLM驱动的模拟以及行为告知奖励都有显著作用。", "conclusion": "该研究展示了一种结合结构化交互、动态人格估计和行为导向奖励的有效劝说策略。"}}
{"id": "2601.06875", "pdf": "https://arxiv.org/pdf/2601.06875", "abs": "https://arxiv.org/abs/2601.06875", "authors": ["Sontaga G. Forane", "Absalom E. Ezugwu", "Kevin Igwe", "Karen van den Berg"], "title": "An Ubuntu-Guided Large Language Model Framework for Cognitive Behavioral Mental Health Dialogue", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "South Africa's escalating mental health crisis, compounded by limited access to culturally responsive care, calls for innovative and contextually grounded interventions. While large language models show considerable promise for mental health support, their predominantly Western-centric training data limit cultural and linguistic applicability in African contexts. This study introduces a proof-of-concept framework that integrates cognitive behavioral therapy with the African philosophy of Ubuntu to create a culturally sensitive, emotionally intelligent, AI-driven mental health dialogue system. Guided by a design science research methodology, the framework applies both deep theoretical and therapeutic adaptations as well as surface-level linguistic and communicative cultural adaptations. Key CBT techniques, including behavioral activation and cognitive restructuring, were reinterpreted through Ubuntu principles that emphasize communal well-being, spiritual grounding, and interconnectedness. A culturally adapted dataset was developed through iterative processes of language simplification, spiritual contextualization, and Ubuntu-based reframing. The fine-tuned model was evaluated through expert-informed case studies, employing UniEval for conversational quality assessment alongside additional measures of CBT reliability and cultural linguistic alignment. Results demonstrate that the model effectively engages in empathetic, context-aware dialogue aligned with both therapeutic and cultural objectives. Although real-time end-user testing has not yet been conducted, the model underwent rigorous review and supervision by domain specialist clinical psychologists. The findings highlight the potential of culturally embedded emotional intelligence to enhance the contextual relevance, inclusivity, and effectiveness of AI-driven mental health interventions across African settings.", "AI": {"tldr": "本文提出了一种基于Ubuntu原则和认知行为疗法（CBT）的大规模语言模型框架，用于创建一种文化敏感的、情感智能的心理健康对话系统。", "motivation": "南非面临日益严重的精神卫生危机，并且缺乏能够提供文化响应性照顾的资源。虽然大规模语言模型在精神卫生支持方面显示出巨大潜力，但其主要以西方为中心的数据集限制了它们在非洲语境中的文化和语言适用性。", "method": "该研究通过设计科学的方法学，结合深层理论和治疗上的适应以及表面层次的语言和沟通文化调整来开发框架。关键的CBT技术如行为激活和认知重构被重新解释为符合Ubuntu原则的精神健康对话系统。通过迭代过程创建了文化适应的数据集，并使用UniEval进行了评估。", "result": "模型有效参与与文化和治疗目标一致的同情、情境感知对话，展示了嵌入式情感智能在增强AI驱动的心理健康干预措施的文化相关性、包容性和有效性方面的重要潜力。", "conclusion": "尽管尚未进行实时用户测试，但该研究的结果表明，在非洲背景下使用文化嵌入的情感智能可以提高人工智能驱动的精神卫生干预的有效性。"}}
{"id": "2601.06874", "pdf": "https://arxiv.org/pdf/2601.06874", "abs": "https://arxiv.org/abs/2601.06874", "authors": ["Changli Wu", "Haodong Wang", "Jiayi Ji", "Yutian Yao", "Chunsai Du", "Jihua Kang", "Yanwei Fu", "Liujuan Cao"], "title": "MVGGT: Multimodal Visual Geometry Grounded Transformer for Multiview 3D Referring Expression Segmentation", "categories": ["cs.CV"], "comment": "Project Website: https://mvggt.github.io", "summary": "Most existing 3D referring expression segmentation (3DRES) methods rely on dense, high-quality point clouds, while real-world agents such as robots and mobile phones operate with only a few sparse RGB views and strict latency constraints. We introduce Multi-view 3D Referring Expression Segmentation (MV-3DRES), where the model must recover scene structure and segment the referred object directly from sparse multi-view images. Traditional two-stage pipelines, which first reconstruct a point cloud and then perform segmentation, often yield low-quality geometry, produce coarse or degraded target regions, and run slowly. We propose the Multimodal Visual Geometry Grounded Transformer (MVGGT), an efficient end-to-end framework that integrates language information into sparse-view geometric reasoning through a dual-branch design. Training in this setting exposes a critical optimization barrier, termed Foreground Gradient Dilution (FGD), where sparse 3D signals lead to weak supervision. To resolve this, we introduce Per-view No-target Suppression Optimization (PVSO), which provides stronger and more balanced gradients across views, enabling stable and efficient learning. To support consistent evaluation, we build MVRefer, a benchmark that defines standardized settings and metrics for MV-3DRES. Experiments show that MVGGT establishes the first strong baseline and achieves both high accuracy and fast inference, outperforming existing alternatives. Code and models are publicly available at https://mvggt.github.io.", "AI": {"tldr": "本文提出了MVGGT框架，用于从多视图图像中进行三维物体分割任务。", "motivation": "现有的三维物体分割方法依赖于密集高质量的点云数据，而现实场景中的设备只能获取稀疏的RGB图像并且有严格的延迟要求。传统两阶段的方法在几何重建和目标分割上表现不佳且运行效率低下。", "method": "MVGGT采用双分支设计将语言信息融入到稀疏视图几何推理中，并通过Per-view No-target Suppression Optimization (PVSO)解决训练过程中的Foreground Gradient Dilution问题，提供更平衡的梯度。", "result": "实验表明，MVGGT在准确性和推理速度上超越了现有方法，成为多视图三维物体分割任务的一个基准。", "conclusion": "MVGGT框架能够高效且精确地从稀疏图像中完成多视图三维物体分割任务。"}}
{"id": "2601.06870", "pdf": "https://arxiv.org/pdf/2601.06870", "abs": "https://arxiv.org/abs/2601.06870", "authors": ["Jiazhang Liang", "Jianheng Dai", "Miaosen Luo", "Menghua Jiang", "Sijie Mai"], "title": "DaQ-MSA: Denoising and Qualifying Diffusion Augmentations for Multimodal Sentiment Analysis", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 4 figures", "summary": "Multimodal large language models (MLLMs) have demonstrated strong performance on vision-language tasks, yet their effectiveness on multimodal sentiment analysis remains constrained by the scarcity of high-quality training data, which limits accurate multimodal understanding and generalization. To alleviate this bottleneck, we leverage diffusion models to perform semantics-preserving augmentation on the video and audio modalities, expanding the multimodal training distribution. However, increasing data quantity alone is insufficient, as diffusion-generated samples exhibit substantial quality variation and noisy augmentations may degrade performance. We therefore propose DaQ-MSA (Denoising and Qualifying Diffusion Augmentations for Multimodal Sentiment Analysis), which introduces a quality scoring module to evaluate the reliability of augmented samples and assign adaptive training weights. By down-weighting low-quality samples and emphasizing high-fidelity ones, DaQ-MSA enables more stable learning. By integrating the generative capability of diffusion models with the semantic understanding of MLLMs, our approach provides a robust and generalizable automated augmentation strategy for training MLLMs without any human annotation or additional supervision.", "AI": {"tldr": "本文提出了一种用于多模态情感分析的去噪和质量评估扩散增强策略DaQ-MSA，通过引入质量评分模块来评价生成样本的质量并分配适应性训练权重。", "motivation": "多模态大型语言模型（MLLMs）在视觉-语言任务中表现出色，但在多模态情感分析中的表现受到高质量训练数据稀少的限制。为了解决这个问题，本文利用扩散模型进行语义保持增强以扩充多模态训练分布。", "method": "本文提出DaQ-MSA策略，通过质量评分模块评估生成样本的质量并分配适应性训练权重，从而降低低质量样本的影响，并提升高质量样本的重要性。", "result": "实验结果表明，DaQ-MSA能够提供更稳定的学习过程和更强的泛化能力。", "conclusion": "本文方法结合了扩散模型的生成能力和多模态大型语言模型的语义理解能力，在无需人工注释或额外监督的情况下提供了稳健且通用的自动化增强策略。"}}
{"id": "2601.06862", "pdf": "https://arxiv.org/pdf/2601.06862", "abs": "https://arxiv.org/abs/2601.06862", "authors": ["Michael Sidorov", "Ofer Hadar"], "title": "qAttCNN - Self Attention Mechanism for Video QoE Prediction in Encrypted Traffic", "categories": ["cs.CR", "cs.CV", "cs.LG", "cs.MM", "eess.IV"], "comment": null, "summary": "The rapid growth of multimedia consumption, driven by major advances in mobile devices since the mid-2000s, has led to widespread use of video conferencing applications (VCAs) such as Zoom and Google Meet, as well as instant messaging applications (IMAs) like WhatsApp and Telegram, which increasingly support video conferencing as a core feature. Many of these systems rely on the Web Real-Time Communication (WebRTC) protocol, enabling direct peer-to-peer media streaming without requiring a third-party server to relay data, reducing the latency and facilitating a real-time communication. Despite WebRTC's potential, adverse network conditions can degrade streaming quality and consequently reduce users' Quality of Experience (QoE). Maintaining high QoE therefore requires continuous monitoring and timely intervention when QoE begins to deteriorate. While content providers can often estimate QoE by directly comparing transmitted and received media, this task is significantly more challenging for internet service providers (ISPs). End-to-end encryption, commonly used by modern VCAs and IMAs, prevent ISPs from accessing the original media stream, leaving only Quality of Service (QoS) and routing information available. To address this limitation, we propose the QoE Attention Convolutional Neural Network (qAttCNN), a model that leverages packet size parameter of the traffic to infer two no-reference QoE metrics viz. BRISQUE and frames per second (FPS). We evaluate qAttCNN on a custom dataset collected from WhatsApp video calls and compare it against existing QoE models. Using mean absolute error percentage (MAEP), our approach achieves 2.14% error for BRISQUE and 7.39% for FPS prediction.", "AI": {"tldr": "提出一种基于加密流量包大小参数预测视频质量体验(QoE)的模型qAttCNN。", "motivation": "在现代视频会议和即时通讯应用中，由于端到端加密的存在，互联网服务提供商难以直接访问原始媒体流来评估QoE。因此需要开发新的方法从可用的数据中推断出QoE。", "method": "通过设计qAttCNN模型利用加密流量中的包大小参数预测BRISQUE和FPS两个无参考的QoE指标。", "result": "实验表明，qAttCNN在预测BRISQUE时MAEP误差为2.14%，FPS预测的MAEP误差为7.39%。", "conclusion": "qAttCNN模型能够有效地利用加密流量信息来估计视频会议和即时通讯应用中的QoE指标。"}}
{"id": "2601.06861", "pdf": "https://arxiv.org/pdf/2601.06861", "abs": "https://arxiv.org/abs/2601.06861", "authors": ["William Guey", "Wei Zhang", "Pei-Luen Patrick Rau", "Pierrick Bougault", "Vitor D. de Moura", "Bertan Ucar", "Jose O. Gomes"], "title": "BiasLab: A Multilingual, Dual-Framing Framework for Robust Measurement of Output-Level Bias in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "source code and reproducibility scripts available on GitHub", "summary": "Large Language Models (LLMs) are increasingly deployed in high-stakes contexts where their outputs influence real-world decisions. However, evaluating bias in LLM outputs remains methodologically challenging due to sensitivity to prompt wording, limited multilingual coverage, and the lack of standardized metrics that enable reliable comparison across models. This paper introduces BiasLab, an open-source, model-agnostic evaluation framework for quantifying output-level (extrinsic) bias through a multilingual, robustness-oriented experimental design. BiasLab constructs mirrored probe pairs under a strict dual-framing scheme: an affirmative assertion favoring Target A and a reverse assertion obtained by deterministic target substitution favoring Target B, while preserving identical linguistic structure. To reduce dependence on prompt templates, BiasLab performs repeated evaluation under randomized instructional wrappers and enforces a fixed-choice Likert response format to maximize comparability across models and languages. Responses are normalized into agreement labels using an LLM-based judge, aligned for polarity consistency across framings, and aggregated into quantitative bias indicators with descriptive statistics including effect sizes and neutrality rates. The framework supports evaluation across diverse bias axes, including demographic, cultural, political, and geopolitical topics, and produces reproducible artifacts such as structured reports and comparative visualizations. BiasLab contributes a standardized methodology for cross-lingual and framing-sensitive bias measurement that complements intrinsic and dataset-based audits, enabling researchers and institutions to benchmark robustness and make better-informed deployment decisions.", "AI": {"tldr": "提出了BiasLab框架，用于评估大型语言模型输出中的偏见。", "motivation": "评估大型语言模型的输出偏见在现实世界决策中非常重要，但现有方法存在局限性。此研究旨在提供一种标准化的方法来解决这些问题。", "method": "设计了一种双语境实验方案，使用镜像探针对构建数据集，并通过随机化指令和固定选择评分方式增强评估的一致性和可靠性。", "result": "生成了量化偏见指标，如效应大小和中立率等，支持跨语言和多主题的偏见测量。", "conclusion": "BiasLab提供了一种标准化的方法来测量大型语言模型输出中的偏见，有助于研究者和机构进行更明智的部署决策。"}}
{"id": "2601.06860", "pdf": "https://arxiv.org/pdf/2601.06860", "abs": "https://arxiv.org/abs/2601.06860", "authors": ["Yifei Chen", "Guanting Dong", "Zhicheng Dou"], "title": "ET-Agent: Incentivizing Effective Tool-Integrated Reasoning Agent via Behavior Calibration", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) can extend their parameter knowledge limits by adopting the Tool-Integrated Reasoning (TIR) paradigm. However, existing LLM-based agent training framework often focuses on answers' accuracy, overlooking specific alignment for behavior patterns. Consequently, agent often exhibits ineffective actions during TIR tasks, such as redundant and insufficient tool calls. How to calibrate erroneous behavioral patterns when executing TIR tasks, thereby exploring effective trajectories, remains an open-ended problem. In this paper, we propose ET-Agent, a training framework for calibrating agent's tool-use behavior through two synergistic perspectives: Self-evolving Data Flywheel and Behavior Calibration Training. Specifically, we introduce a self-evolutionary data flywheel to generate enhanced data, used to fine-tune LLM to improve its exploration ability. Based on this, we implement an two-phases behavior-calibration training framework. It is designed to progressively calibrate erroneous behavioral patterns to optimal behaviors. Further in-depth experiments confirm the superiority of \\ourmodel{} across multiple dimensions, including correctness, efficiency, reasoning conciseness, and tool execution accuracy. Our ET-Agent framework provides practical insights for research in the TIR field. Codes can be found in https://github.com/asilverlight/ET-Agent", "AI": {"tldr": "提出了一种名为ET-Agent的训练框架，用于校准工具集成推理代理的行为模式。", "motivation": "现有的大型语言模型在执行工具集成推理任务时表现出无效行为，如冗余和不足的工具调用。如何校准这些错误行为以探索有效轨迹是一个开放性问题。", "method": "通过自我演化的数据飞轮生成增强数据，并基于此实施两阶段的行为校准训练框架，逐步纠正错误行为模式。", "result": "实验结果表明ET-Agent在正确性、效率、推理简洁性和工具执行准确性等方面优于其他方法。", "conclusion": "ET-Agent为研究工具集成推理领域提供了实用见解。"}}
{"id": "2601.06857", "pdf": "https://arxiv.org/pdf/2601.06857", "abs": "https://arxiv.org/abs/2601.06857", "authors": ["Xin Ye", "Daning Cheng", "Boyang Zhang", "Yunquan Zhang"], "title": "MoE-DisCo:Low Economy Cost Training Mixture-of-Experts Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Training large-scale Mixture-of-Experts (MoE) models typically requires high-memory, high-bandwidth GPUs (e.g., A100), and their high cost has become a major barrier to large-model training. In contrast, affordable hardware is low-cost but constrained by memory capacity and bandwidth, making it unsuitable for direct LLM training. To address this, we propose MoE-DisCo (Mixture-of-Experts with Disentangled Clustering and Coordination), a staged training framework. MoE-DisCo decomposes the MoE model into multiple dense submodels, each consisting of a shared backbone and a single expert, and partitions the training data into subsets using unsupervised clustering. Each submodel is trained independently and in parallel on its assigned data subset using low-cost devices, without any inter-device communication. Subsequently, all experts are integrated into a complete MoE model and fine-tuned globally for a short period on high-memory, high-bandwidth GPUs. Experiments show that our method matches or even surpasses full-parameter training in performance across multiple downstream tasks, loss function, and perplexity (PPL), while reducing training cost by 47.6 percent to 69.5 percent on Qwen1.5-MoE-2.7B and Llama-MoE-3.5B across different datasets.", "AI": {"tldr": "提出了MoE-DisCo框架，通过分解混合专家模型并利用低成本硬件进行独立训练以降低大规模语言模型的训练成本。", "motivation": "高内存和带宽要求的大型GPU设备昂贵，导致大规模模型训练的成本高昂。为解决此问题，本研究旨在开发一种低经济成本的混合专家模型训练方法。", "method": "提出MoE-DisCo框架，通过无监督聚类将数据集分割成子集，并在低成本硬件上独立并行地训练每个包含共享骨干网络和单一专家的密集子模型。最终，在高性能设备上合并所有专家进行全局微调。", "result": "实验结果表明，该方法在多个下游任务中的性能与全参数训练相当甚至更好，同时降低了47.6%至69.5%的成本。", "conclusion": "MoE-DisCo框架成功地实现了大规模混合专家模型的低成本高效训练。"}}
{"id": "2601.06854", "pdf": "https://arxiv.org/pdf/2601.06854", "abs": "https://arxiv.org/abs/2601.06854", "authors": ["Luigi Romano", "Ole Morten Aamo", "Jan Åslund", "Erik Frisk"], "title": "Semilinear single-track vehicle models with distributed tyre friction dynamics", "categories": ["cs.RO"], "comment": "37 pages, 12 figures. Accepted by Nonlinear Dynamics", "summary": "This paper introduces a novel family of single-track vehicle models that incorporate a distributed representation of transient tyre dynamics, whilst simultaneously accounting for nonlinear effects induced by friction. The core of the proposed framework is represented by the distributed Friction with Bristle Dynamics (FrBD) model, which unifies and extends classical formulations such as Dahl and LuGre by describing the rolling contact process as a spatially distributed system governed by semilinear partial differential equations (PDEs). This model is systematically integrated into a single-track vehicle framework, where the resulting semilinear ODE-PDE interconnection captures the interaction between lateral vehicle motion and tyre deformation. Two main variants are considered: one with rigid tyre carcass and another with flexible carcass, each admitting a compact state-space representation. Local and global well-posedness properties for the coupled system are established rigorously, highlighting the dissipative and physically consistent properties of the distributed FrBD model. A linearisation procedure is also presented, enabling spectral analysis and transfer function derivation, and potentially facilitating the synthesis of controllers and observers. Numerical simulations demonstrate the model's capability to capture micro-shimmy oscillations and transient lateral responses to advanced steering manoeuvres. The proposed formulation advances the state-of-the-art in vehicle dynamics modelling by providing a physically grounded, mathematically rigorous, and computationally tractable approach to incorporating transient tyre behaviour in lateral vehicle dynamics, when accounting for the effect of limited friction.", "AI": {"tldr": "本文提出了一种新的单轨车辆模型，该模型集成了分布式轮胎摩擦动力学，并结合了非线性效应。", "motivation": "为了更好地模拟瞬态轮胎行为对侧向车辆动态的影响，特别是在考虑有限摩擦的情况下。", "method": "使用分布式的FrBD（摩擦与刷子动力学）模型来描述滚动接触过程。此模型整合到单轨车框架中，形成半线性ODE-PDE相互连接系统，并提供了线性化过程以进行频谱分析和传递函数推导。", "result": "数值模拟显示了该模型能够捕捉微颤振振动和高级转向操作的瞬态横向响应的能力。", "conclusion": "该方法通过提供一个物理上合理的、数学上严谨且计算可行的方法，将瞬态轮胎行为纳入侧向车辆动态建模中，推进了现有技术。"}}
{"id": "2601.06851", "pdf": "https://arxiv.org/pdf/2601.06851", "abs": "https://arxiv.org/abs/2601.06851", "authors": ["Pedro Urbina-Rodriguez", "Zafeirios Fountas", "Fernando E. Rosas", "Jun Wang", "Andrea I. Luppi", "Haitham Bou-Ammar", "Murray Shanahan", "Pedro A. M. Mediano"], "title": "A Brain-like Synergistic Core in LLMs Drives Behaviour and Learning", "categories": ["cs.AI"], "comment": null, "summary": "The independent evolution of intelligence in biological and artificial systems offers a unique opportunity to identify its fundamental computational principles. Here we show that large language models spontaneously develop synergistic cores -- components where information integration exceeds individual parts -- remarkably similar to those in the human brain. Using principles of information decomposition across multiple LLM model families and architectures, we find that areas in middle layers exhibit synergistic processing while early and late layers rely on redundancy, mirroring the informational organisation in biological brains. This organisation emerges through learning and is absent in randomly initialised networks. Crucially, ablating synergistic components causes disproportionate behavioural changes and performance loss, aligning with theoretical predictions about the fragility of synergy. Moreover, fine-tuning synergistic regions through reinforcement learning yields significantly greater performance gains than training redundant components, yet supervised fine-tuning shows no such advantage. This convergence suggests that synergistic information processing is a fundamental property of intelligence, providing targets for principled model design and testable predictions for biological intelligence.", "AI": {"tldr": "该论文研究了大型语言模型中的信息整合现象，发现其与人脑类似，具有协同核心区域。", "motivation": "独立演化的人类和人工系统的智能提供了识别基本计算原则的机会。研究探讨了大语言模型中是否存在类似的协同处理机制及其对行为的影响。", "method": "使用信息分解原理跨多个大型语言模型家族和架构进行分析，发现中间层表现出协同处理特征，而早期和晚期层次依赖冗余处理，这与生物大脑的信息组织类似。", "result": "通过消除协同部分会导致不相称的行为变化和性能损失；通过强化学习对协同区域进行微调可获得显著的性能提升，相比之下监督训练没有明显优势。", "conclusion": "研究表明信息协同处理是智能的基本属性，为模型设计提供了目标，并提出了生物智能的测试预测。"}}
{"id": "2601.06847", "pdf": "https://arxiv.org/pdf/2601.06847", "abs": "https://arxiv.org/abs/2601.06847", "authors": ["Mengmeng Zhang", "Xiaoping Wu", "Hao Luo", "Fan Wang", "Yisheng Lv"], "title": "MedGround: Bridging the Evidence Gap in Medical Vision-Language Models with Verified Grounding Data", "categories": ["cs.CV", "cs.AI"], "comment": "18 pages, 10 figures", "summary": "Vision-Language Models (VLMs) can generate convincing clinical narratives, yet frequently struggle to visually ground their statements. We posit this limitation arises from the scarcity of high-quality, large-scale clinical referring-localization pairs. To address this, we introduce MedGround, an automated pipeline that transforms segmentation resources into high-quality medical referring grounding data. Leveraging expert masks as spatial anchors, MedGround precisely derives localization targets, extracts shape and spatial cues, and guides VLMs to synthesize natural, clinically grounded queries that reflect morphology and location. To ensure data rigor, a multi-stage verification system integrates strict formatting checks, geometry- and medical-prior rules, and image-based visual judging to filter out ambiguous or visually unsupported samples. Finally, we present MedGround-35K, a novel multimodal medical dataset. Extensive experiments demonstrate that VLMs trained with MedGround-35K consistently achieve improved referring grounding performance, enhance multi-object semantic disambiguation, and exhibit strong generalization to unseen grounding settings. This work highlights MedGround as a scalable, data-driven approach to anchor medical language to verifiable visual evidence. Dataset and code will be released publicly upon acceptance.", "AI": {"tldr": "构建MedGround系统，生成高质量的临床视觉定位数据，提升医学视觉语言模型的表现。", "motivation": "现有医学图像和文本配对的数据量不足，导致视觉语言模型难以准确关联语义与视觉信息，从而影响其性能。", "method": "通过自动化流程将分割资源转化为高精度医疗参照定位数据，并设计多阶段验证系统保证数据质量。最终生成MedGround-35K数据集。", "result": "实验表明使用该数据集训练的模型在医学视觉定位和语义区分上表现出色，具有良好的泛化能力。", "conclusion": "MedGround提供了一个可扩展的数据驱动方法来加强医学语言与可视证据之间的联系。"}}
{"id": "2601.06845", "pdf": "https://arxiv.org/pdf/2601.06845", "abs": "https://arxiv.org/abs/2601.06845", "authors": ["Ping Guo", "Chao Li", "Yinglan Feng", "Chaoning Zhang"], "title": "Code Evolution for Control: Synthesizing Policies via LLM-Driven Evolutionary Search", "categories": ["cs.AI"], "comment": null, "summary": "Designing effective control policies for autonomous systems remains a fundamental challenge, traditionally addressed through reinforcement learning or manual engineering. While reinforcement learning has achieved remarkable success, it often suffers from high sample complexity, reward shaping difficulties, and produces opaque neural network policies that are hard to interpret or verify. Manual design, on the other hand, requires substantial domain expertise and struggles to scale across diverse tasks. In this work, we demonstrate that LLM-driven evolutionary search can effectively synthesize interpretable control policies in the form of executable code. By treating policy synthesis as a code evolution problem, we harness the LLM's prior knowledge of programming patterns and control heuristics while employing evolutionary search to explore the solution space systematically. We implement our approach using EvoToolkit, a framework that seamlessly integrates LLM-driven evolution with customizable fitness evaluation. Our method iteratively evolves populations of candidate policy programs, evaluating them against task-specific objectives and selecting superior individuals for reproduction. This process yields compact, human-readable control policies that can be directly inspected, modified, and formally verified. This work highlights the potential of combining foundation models with evolutionary computation for synthesizing trustworthy control policies in autonomous systems. Code is available at https://github.com/pgg3/EvoControl.", "AI": {"tldr": "论文提出了一种基于大型语言模型驱动的进化搜索方法，用于合成可解释的控制策略。", "motivation": "传统强化学习和手动设计在自主系统中面临采样复杂度高、奖励塑形困难等问题，并且难以规模化处理多样任务。为了克服这些问题，作者希望通过结合大型语言模型的知识与进化计算来生成可靠的控制策略。", "method": "方法利用EvoToolkit框架进行LLM驱动的进化搜索，通过定制化的适应度评估迭代演化候选策略程序集，最终输出简洁、可直接审查和形式验证的控制政策。", "result": "研究展示了在多种任务中合成出高效且易于理解的控制策略的成功案例，并表明这种方法能够生成可靠的控制策略。", "conclusion": "该论文证明了将大型语言模型与进化计算结合来合成可信赖控制策略的有效性，为自主系统的可靠决策制定提供了一种新的解决方案。"}}
{"id": "2601.06844", "pdf": "https://arxiv.org/pdf/2601.06844", "abs": "https://arxiv.org/abs/2601.06844", "authors": ["Ioannis Ziogas", "Aamna Al Shehhi", "Ahsan H. Khandoker", "Leontios J. Hadjileontiadis"], "title": "Variational decomposition autoencoding improves disentanglement of latent representations", "categories": ["cs.LG", "cs.AI", "eess.AS", "eess.SP", "stat.ML"], "comment": "Supplementary information file at: https://drive.google.com/drive/folders/1sZl2AcCtRK-1oav7XZSaxlu0Cq0-3MMs?usp=sharing", "summary": "Understanding the structure of complex, nonstationary, high-dimensional time-evolving signals is a central challenge in scientific data analysis. In many domains, such as speech and biomedical signal processing, the ability to learn disentangled and interpretable representations is critical for uncovering latent generative mechanisms. Traditional approaches to unsupervised representation learning, including variational autoencoders (VAEs), often struggle to capture the temporal and spectral diversity inherent in such data. Here we introduce variational decomposition autoencoding (VDA), a framework that extends VAEs by incorporating a strong structural bias toward signal decomposition. VDA is instantiated through variational decomposition autoencoders (DecVAEs), i.e., encoder-only neural networks that combine a signal decomposition model, a contrastive self-supervised task, and variational prior approximation to learn multiple latent subspaces aligned with time-frequency characteristics. We demonstrate the effectiveness of DecVAEs on simulated data and three publicly available scientific datasets, spanning speech recognition, dysarthria severity evaluation, and emotional speech classification. Our results demonstrate that DecVAEs surpass state-of-the-art VAE-based methods in terms of disentanglement quality, generalization across tasks, and the interpretability of latent encodings. These findings suggest that decomposition-aware architectures can serve as robust tools for extracting structured representations from dynamic signals, with potential applications in clinical diagnostics, human-computer interaction, and adaptive neurotechnologies.", "AI": {"tldr": "提出了一种新的框架Variational Decomposition Autoencoding（VDA），通过结合信号分解模型，对比自监督任务和变分先验近似来改进潜在表示的分离性。", "motivation": "传统无监督学习方法如VAE在处理复杂、非平稳、高维时序数据时难以捕捉其多样性和特性。因此，需要一种新框架以增强对这些信号结构的理解。", "method": "引入了Decoding Variational Autoencoders（DecVAEs），这是一种只包含解码器的神经网络模型，通过结合信号分解、对比自监督任务和变分先验近似来学习多个与时间-频率特征对齐的潜在子空间。", "result": "在模拟数据及三个公开科学数据集上的实验表明，DecVAEs比现有的基于VAE的方法表现出更好的分离性质量，泛化能力和潜在编码可解释性。", "conclusion": "分解感知架构作为从动态信号中提取结构化表示的有效工具，在临床诊断、人机交互和自适应神经技术等领域具有广泛的应用潜力。"}}
{"id": "2601.06843", "pdf": "https://arxiv.org/pdf/2601.06843", "abs": "https://arxiv.org/abs/2601.06843", "authors": ["Junyan Lin", "Junlong Tong", "Hao Wu", "Jialiang Zhang", "Jinming Liu", "Xin Jin", "Xiaoyu Shen"], "title": "Speak While Watching: Unleashing TRUE Real-Time Video Understanding Capability of Multimodal Large Language Models", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have achieved strong performance across many tasks, yet most systems remain limited to offline inference, requiring complete inputs before generating outputs. Recent streaming methods reduce latency by interleaving perception and generation, but still enforce a sequential perception-generation cycle, limiting real-time interaction. In this work, we target a fundamental bottleneck that arises when extending MLLMs to real-time video understanding: the global positional continuity constraint imposed by standard positional encoding schemes. While natural in offline inference, this constraint tightly couples perception and generation, preventing effective input-output parallelism. To address this limitation, we propose a parallel streaming framework that relaxes positional continuity through three designs: Overlapped, Group-Decoupled, and Gap-Isolated. These designs enable simultaneous perception and generation, allowing the model to process incoming inputs while producing responses in real time. Extensive experiments reveal that Group-Decoupled achieves the best efficiency-performance balance, maintaining high fluency and accuracy while significantly reducing latency. We further show that the proposed framework yields up to 2x acceleration under balanced perception-generation workloads, establishing a principled pathway toward speak-while-watching real-time systems. We make all our code publicly available: https://github.com/EIT-NLP/Speak-While-Watching.", "AI": {"tldr": "提出了一种并行流框架，使多模态大型语言模型能够实现实时视频理解。", "motivation": "大多数多模态大型语言模型在离线推理中表现良好，但受限于延迟问题无法实现真正的实时互动。通过放松位置连续性约束，可以实现同时感知和生成，从而提高交互效率。", "method": "提出了一种并行流框架，该框架包括三种设计：重叠、组解耦和间隔隔离。这些设计使模型能够在接收输入的同时产生输出反应。", "result": "实验表明，组解耦设计在保持高流畅性和准确性的同时显著减少了延迟。这种框架可以实现高达2倍的加速。", "conclusion": "该研究提出了一种新的方法来解决多模态大型语言模型实现实时视频理解的关键瓶颈问题，并为未来的实时交互系统奠定了基础。"}}
{"id": "2601.06842", "pdf": "https://arxiv.org/pdf/2601.06842", "abs": "https://arxiv.org/abs/2601.06842", "authors": ["Hua Ye", "Siyuan Chen", "Ziqi Zhong", "Canran Xiao", "Haoliang Zhang", "Yuhan Wu", "Fei Shen"], "title": "Seeing through the Conflict: Transparent Knowledge Conflict Handling in Retrieval-Augmented Generation", "categories": ["cs.AI"], "comment": "9 pages, 9 figures, 5 tables", "summary": "Large language models (LLMs) equipped with retrieval--the Retrieval-Augmented Generation (RAG) paradigm--should combine their parametric knowledge with external evidence, yet in practice they often hallucinate, over-trust noisy snippets, or ignore vital context. We introduce TCR (Transparent Conflict Resolution), a plug-and-play framework that makes this decision process observable and controllable. TCR (i) disentangles semantic match and factual consistency via dual contrastive encoders, (ii) estimates self-answerability to gauge confidence in internal memory, and (iii) feeds the three scalar signals to the generator through a lightweight soft-prompt with SNR-based weighting. Across seven benchmarks TCR improves conflict detection (+5-18 F1), raises knowledge-gap recovery by +21.4 pp and cuts misleading-context overrides by -29.3 pp, while adding only 0.3% parameters. The signals align with human judgements and expose temporal decision patterns.", "AI": {"tldr": "本文提出了TCR框架，旨在解决检索增强生成模型中的知识冲突问题。", "motivation": "现有的大型语言模型在结合内部参数和外部证据时容易产生幻觉、过度依赖噪声信息或忽略关键上下文。", "method": "TCR通过双对比编码器分离语义匹配与事实一致性，并估算自答能力来评估内部记忆的信心，将这三个标量信号以轻量级软提示的方式传递给生成器并采用基于信噪比的加权方式。", "result": "在七个基准测试中，TCR提高了冲突检测性能（F1得分提高5-18分），知识缺口恢复率增加了21.4个百分点，减少了误导性上下文覆盖29.3个百分点，并且仅增加0.3%参数。", "conclusion": "通过引入TCR框架，增强了生成模型在处理知识冲突时的透明度和可控性。"}}
{"id": "2601.06839", "pdf": "https://arxiv.org/pdf/2601.06839", "abs": "https://arxiv.org/abs/2601.06839", "authors": ["Hansol Lim", "Minhyeok Im", "Jongseong Brad Choi"], "title": "PRISM: Color-Stratified Point Cloud Sampling", "categories": ["cs.CV"], "comment": "This work has been submitted to the 2026 International Conference on Pattern Recognition (ICPR) for possible publication", "summary": "We present PRISM, a novel color-guided stratified sampling method for RGB-LiDAR point clouds. Our approach is motivated by the observation that unique scene features often exhibit chromatic diversity while repetitive, redundant features are homogeneous in color. Conventional downsampling methods (Random Sampling, Voxel Grid, Normal Space Sampling) enforce spatial uniformity while ignoring this photometric content. In contrast, PRISM allocates sampling density proportional to chormatic diversity. By treating RGB color space as the stratification domain and imposing a maximum capacity k per color bin, the method preserves texture-rich regions with high color variation while substantially reducing visually homogeneous surfaces. This shifts the sampling space from spatial coverage to visual complexity to produce sparser point clouds that retain essential features for 3D reconstruction tasks.", "AI": {"tldr": "PRISM是一种基于颜色指导的分层采样方法，用于RGB-LiDAR点云数据。它通过考虑颜色多样性来减少冗余特征，并保持重要信息。", "motivation": "观察到独特场景特征通常具有色度多样性而重复特征是同质的。传统下采样方法仅关注空间均匀性而不顾及色彩内容，PRISM则根据颜色多样性分配采样密度。", "method": "将RGB颜色空间作为分层域，并为每个颜色桶设置最大容量k。此方法保留了具有高色变区域并大幅减少视觉同质表面。", "result": "通过转移采样空间从空间覆盖到视觉复杂性，生成稀疏点云同时保持3D重建任务中的关键特征。", "conclusion": "PRISM通过利用颜色信息来改进传统采样方法的性能，并在保留重要细节的同时降低数据量。"}}
{"id": "2601.06835", "pdf": "https://arxiv.org/pdf/2601.06835", "abs": "https://arxiv.org/abs/2601.06835", "authors": ["Hyunseo Lee", "Sang Min Kim", "Ho Kyung Shin", "Taeheon Kim", "Woo-Jeoung Nam"], "title": "OSCAR: Optical-aware Semantic Control for Aleatoric Refinement in Sar-to-Optical Translation", "categories": ["cs.CV", "cs.AI"], "comment": "main 15 pages, supplementary 5 pages", "summary": "Synthetic Aperture Radar (SAR) provides robust all-weather imaging capabilities; however, translating SAR observations into photo-realistic optical images remains a fundamentally ill-posed problem. Current approaches are often hindered by the inherent speckle noise and geometric distortions of SAR data, which frequently result in semantic misinterpretation, ambiguous texture synthesis, and structural hallucinations. To address these limitations, a novel SAR-to-Optical (S2O) translation framework is proposed, integrating three core technical contributions: (i) Cross-Modal Semantic Alignment, which establishes an Optical-Aware SAR Encoder by distilling robust semantic priors from an Optical Teacher into a SAR Student (ii) Semantically-Grounded Generative Guidance, realized by a Semantically-Grounded ControlNet that integrates class-aware text prompts for global context with hierarchical visual prompts for local spatial guidance; and (iii) an Uncertainty-Aware Objective, which explicitly models aleatoric uncertainty to dynamically modulate the reconstruction focus, effectively mitigating artifacts caused by speckle-induced ambiguity. Extensive experiments demonstrate that the proposed method achieves superior perceptual quality and semantic consistency compared to state-of-the-art approaches.", "AI": {"tldr": "提出了一种新型的SAR到光学图像翻译框架，旨在解决现有的SAR图像翻译成真实感光学图像中的问题。", "motivation": "现有方法在处理SAR数据时遇到挑战，如斑点噪声和几何畸变，导致语义误解、模糊纹理合成及结构错误。为了克服这些限制，提出了新的技术方案。", "method": "框架包含三个核心技术贡献：（i）跨模态语义对齐，通过光学教师模型训练来建立SAR编码器；（ii）语义指导生成性控制网，结合类别感知文本提示与层次视觉提示进行空间引导；以及（iii）不确定性感知目标函数，以动态调节重建焦点。", "result": "实验表明该方法在感知质量和语义一致性方面优于现有先进技术。", "conclusion": "提出的OSCAR框架能够显著提高SAR到光学图像翻译的质量和准确性。"}}
{"id": "2601.06834", "pdf": "https://arxiv.org/pdf/2601.06834", "abs": "https://arxiv.org/abs/2601.06834", "authors": ["Chenglong Bao", "Tongyao Pang", "Zuowei Shen", "Dihan Zheng", "Yihang Zou"], "title": "Enhancing Low-resolution Image Representation Through Normalizing Flows", "categories": ["cs.CV"], "comment": null, "summary": "Low-resolution image representation is a special form of sparse representation that retains only low-frequency information while discarding high-frequency components. This property reduces storage and transmission costs and benefits various image processing tasks. However, a key challenge is to preserve essential visual content while maintaining the ability to accurately reconstruct the original images. This work proposes LR2Flow, a nonlinear framework that learns low-resolution image representations by integrating wavelet tight frame blocks with normalizing flows. We conduct a reconstruction error analysis of the proposed network, which demonstrates the necessity of designing invertible neural networks in the wavelet tight frame domain. Experimental results on various tasks, including image rescaling, compression, and denoising, demonstrate the effectiveness of the learned representations and the robustness of the proposed framework.", "AI": {"tldr": "通过整合小波紧框架块与归一化流，提出LR2Flow模型以提高低分辨率图像表示的质量。", "motivation": "在保留视觉内容的同时准确重构原始图片是挑战性的任务。因此需要一种能够优化低分辨率图像表示的方法。", "method": "提出了一种基于小波紧框架和归一化流动的非线性框架LR2Flow，该模型通过学习逆向神经网络来降低重建错误。", "result": "实验结果显示所提出的框架在图像重缩放、压缩及去噪等任务中表现出了良好的效果与鲁棒性。", "conclusion": "LR2Flow模型提高了低分辨率图像表示的质量，并且具有广泛的应用前景。"}}
{"id": "2601.06833", "pdf": "https://arxiv.org/pdf/2601.06833", "abs": "https://arxiv.org/abs/2601.06833", "authors": ["JaeHyung Jang", "JunHyeong Park", "Joong-Ku Lee", "Jee-Hwan Ryu"], "title": "SPINE Gripper: A Twisted Underactuated Mechanism-based Passive Mode-Transition Gripper", "categories": ["cs.RO"], "comment": "11 pages, 10 figures. Preprint version of a manuscript submitted to IEEE Transactions on Mechatronics", "summary": "This paper presents a single-actuator passive gripper that achieves both stable grasping and continuous bidirectional in-hand rotation through mechanically encoded power transmission logic. Unlike conventional multifunctional grippers that require multiple actuators, sensors, or control-based switching, the proposed gripper transitions between grasping and rotation solely according to the magnitude of the applied input torque. The key enabler of this behavior is a Twisted Underactuated Mechanism (TUM), which generates non-coplanar motions, namely axial contraction and rotation, from a single rotational input while producing identical contraction regardless of rotation direction. A friction generator mechanically defines torque thresholds that govern passive mode switching, enabling stable grasp establishment before autonomously transitioning to in-hand rotation without sensing or active control. Analytical models describing the kinematics, elastic force generation, and torque transmission of the TUM are derived and experimentally validated. The fabricated gripper is evaluated through quantitative experiments on grasp success, friction-based grasp force regulation, and bidirectional rotation performance. System-level demonstrations, including bolt manipulation, object reorientation, and manipulator-integrated tasks driven solely by wrist torque, confirm reliable grasp to rotate transitions in both rotational directions. These results demonstrate that non-coplanar multifunctional manipulation can be realized through mechanical design alone, establishing mechanically encoded power transmission logic as a robust alternative to actuator and control intensive gripper architectures.", "AI": {"tldr": "本文提出了一种单驱动被动夹爪，它通过机械编码的力传递逻辑实现了稳定的抓握和连续双向的手内旋转。", "motivation": "现有的多功能夹爪通常需要多个执行器、传感器或基于控制的切换来实现多种功能。为了简化设计并提高可靠性，研究人员开发了一种仅依赖单个输入扭矩即可在抓取和平移模式之间转换的被动夹爪。", "method": "该研究提出了一种名为扭曲欠驱动机制（TUM）的设计，它能够从一个旋转输入生成非共面运动（轴向收缩和旋转）。通过机械编码定义了摩擦生成器来设定扭矩阈值，从而控制模式切换。进行了理论建模并实验验证。", "result": "实验证明该夹爪能够在不同的方向上实现可靠稳定的抓握到平移转换，并展示了包括螺栓操作、物体重新定向和集成式任务在内的系统级应用性能。", "conclusion": "结果表明，通过机械设计可以实现非共面的多功能操纵，并证实了机械编码力传递逻辑作为执行器和控制密集型夹爪架构的一种可靠替代方案的有效性。"}}
{"id": "2601.06831", "pdf": "https://arxiv.org/pdf/2601.06831", "abs": "https://arxiv.org/abs/2601.06831", "authors": ["Jee Won Lee", "Hansol Lim", "Minhyeok Im", "Dohyeon Lee", "Jongseong Brad Choi"], "title": "SARA: Scene-Aware Reconstruction Accelerator", "categories": ["cs.CV"], "comment": "This work has been submitted to the 2026 International Conference on Pattern Recognition (ICPR) for possible publication", "summary": "We present SARA (Scene-Aware Reconstruction Accelerator), a geometry-driven pair selection module for Structure-from-Motion (SfM). Unlike conventional pipelines that select pairs based on visual similarity alone, SARA introduces geometry-first pair selection by scoring reconstruction informativeness - the product of overlap and parallax - before expensive matching. A lightweight pre-matching stage uses mutual nearest neighbors and RANSAC to estimate these cues, then constructs an Information-Weighted Spanning Tree (IWST) augmented with targeted edges for loop closure, long-baseline anchors, and weak-view reinforcement. Compared to exhaustive matching, SARA reduces rotation errors by 46.5+-5.5% and translation errors by 12.5+-6.5% across modern learned detectors, while achieving at most 50x speedup through 98% pair reduction (from 30,848 to 580 pairs). This reduces matching complexity from quadratic to quasi-linear, maintaining within +-3% of baseline reconstruction metrics for 3D Gaussian Splatting and SVRaster.", "AI": {"tldr": "提出了一种基于几何信息的配对选择模块SARA，以提高结构从运动（SfM）重建的速度和精度。", "motivation": "传统方法中，图像匹配通常是基于视觉相似度进行，这会导致大量不必要的计算消耗。作者旨在通过引入一种新的配对选择策略来减少这些冗余操作并加速重建过程。", "method": "SARA采用轻量级预匹配阶段评估配对的重叠和视差，并构建信息加权生成树（IWST），以优化重建流程中的关键步骤，如闭环连接、长基线锚定以及弱视角加强等。", "result": "相比传统方法，SARA在现代学习检测器上的旋转误差降低了46.5±5.5%，平移误差减少了12.5±6.5%；同时将匹配复杂度从二次降低到准线性，并实现了最高达50倍的速度提升，只消耗了原始配对数量的2%（即从30,848减少至580）。", "conclusion": "SARA通过引入几何优先级的配对选择机制，在保证重建精度的同时大大提升了效率。"}}
{"id": "2601.06829", "pdf": "https://arxiv.org/pdf/2601.06829", "abs": "https://arxiv.org/abs/2601.06829", "authors": ["Bochao Sun", "Yang Xiao", "Han Yin"], "title": "MoEScore: Mixture-of-Experts-Based Text-Audio Relevance Score Prediction for Text-to-Audio System Evaluation", "categories": ["cs.SD"], "comment": null, "summary": "Recent advances in generative models have enabled modern Text-to-Audio (TTA) systems to synthesize audio with high perceptual quality. However, TTA systems often struggle to maintain semantic consistency with the input text, leading to mismatches in sound events, temporal tructures, or contextual relationships. Evaluating semantic fidelity in TTA remains a significant challenge. Traditional methods primarily rely on subjective human listening tests, which is time-consuming. To solve this, we propose an objective evaluator based on a Mixture of Experts (MoE) architecture with Sequential Cross-Attention (SeqCoAttn). Our model achieves the first rank in the XACLE Challenge, with an SRCC of 0.6402 (an improvement of 30.6% over the challenge baseline) on the test dataset. Code is available at: https://github.com/S-Orion/MOESCORE.", "AI": {"tldr": "本文提出了一个基于混合专家架构和序列交叉注意力机制的TTA系统评价指标预测模型，用于解决TTA系统的语义一致性的评估难题。", "motivation": "现代文本到音频转换(TTA)系统虽然在生成高质量的声音方面取得了进展，但依然难以保证与输入文本的一致性。传统的主观听觉测试耗时且不够客观。", "method": "本文采用了一种基于混合专家(MoE)架构和序列交叉注意力机制(SeqCoAttn)的模型来预测TTA系统的语义一致性得分。", "result": "该模型在XACLE挑战赛中排名首位，SRCC指标为0.6402，在测试数据集上比基准方法提升了30.6%。", "conclusion": "提出的方法成功解决了TTA系统评估中的语义一致性的难题，并显著提高了评价的客观性和准确性。"}}
{"id": "2601.06828", "pdf": "https://arxiv.org/pdf/2601.06828", "abs": "https://arxiv.org/abs/2601.06828", "authors": ["Swarnalipa Datta", "Arijit Ghosh", "Chandrima Kayal", "Manaswi Paraashar", "Manmatha Roy"], "title": "Spectral Shadows: When Communication Complexity Meets Linear Invariance Testing", "categories": ["cs.DS"], "comment": "17 pages", "summary": "In this short note, we initiate the study of the Linear Isomorphism Testing Problem in the setting of communication complexity, a natural linear algebraic generalization of the classical Equality problem. Given Boolean functions $f, g : \\mathbb{F}_2^n \\to \\{-1, +1\\}$, Alice and Bob are tasked with determining whether $f$ and $g$ are equivalent up to a nonsingular linear transformation of the input variables, or far from being so. This problem has been extensively investigated in several models of computation, including standard algorithmic and property testing frameworks, owing to its fundamental connections with combinatorial circuit design, complexity theory, and cryptography. However, despite its broad relevance, it has remained unexplored in the context of communication complexity, a gap we address in this work. Our main results demonstrate that the approximate spectral norm of the input functions plays a central role in governing the communication complexity of this problem. We design a simple deterministic protocol whose communication cost is polynomial in the approximate spectral norm, and complement it with nearly matching lower bounds (up to a quadratic gap). In the randomised setting with private coins, we present an even more efficient protocol, though equally simple, that achieves a quadratically improved dependence on the approximate spectral norm compared to the deterministic case, and we prove that such a dependence is essentially unavoidable. These results identify the approximate spectral norm as a key complexity measure for testing linear invariance in the communication complexity framework. As a core technical ingredient, we establish new junta theorems for Boolean functions with small approximate spectral norm, which may be of independent interest in Fourier analysis and learning theory.", "AI": {"tldr": "研究了线性同构测试问题在通信复杂度下的表现，特别是在布尔函数的近似谱范数中的作用。", "motivation": "填补了线性不变量检验问题在通信复杂度领域的空白，并探索其与组合电路设计、复杂性理论和密码学的基本联系。", "method": "提出了一个基于近似谱范数的简单确定性和随机化协议，同时建立了新的交集定理以支持这些结果。", "result": "证明了近似谱范数是决定线性同构测试问题通信复杂度的关键指标，并提供了与之匹配的下限和改进效率的随机化方案。", "conclusion": "此研究将线性不变量检验引入通信复杂度领域，确定了近似谱范数作为衡量标准的重要性并建立了新的技术成果。"}}
{"id": "2601.06823", "pdf": "https://arxiv.org/pdf/2601.06823", "abs": "https://arxiv.org/abs/2601.06823", "authors": ["Rui Liu", "Liuqingqing Yang", "Runsheng Zhang", "Shixiao Wang"], "title": "Generative Modeling of Human-Computer Interfaces with Diffusion Processes and Conditional Control", "categories": ["cs.HC"], "comment": null, "summary": "This study investigates human-computer interface generation based on diffusion models to overcome the limitations of traditional template-based design and fixed rule-driven methods. It first analyzes the key challenges of interface generation, including the diversity of interface elements, the complexity of layout logic, and the personalization of user needs. A generative framework centered on the diffusion-reverse diffusion process is then proposed, with conditional control introduced in the reverse diffusion stage to integrate user intent, contextual states, and task constraints, enabling unified modeling of visual presentation and interaction logic. In addition, regularization constraints and optimization objectives are combined to ensure the rationality and stability of the generated interfaces. Experiments are conducted on a public interface dataset with systematic evaluations, including comparative experiments, hyperparameter sensitivity tests, environmental sensitivity tests, and data sensitivity tests. Results show that the proposed method outperforms representative models in mean squared error, structural similarity, peak signal-to-noise ratio, and mean absolute error, while maintaining strong robustness under different parameter settings and environmental conditions. Overall, the diffusion model framework effectively improves the diversity, rationality, and intelligence of interface generation, providing a feasible solution for automated interface generation in complex interaction scenarios.", "AI": {"tldr": "研究通过扩散模型生成人机界面，提高界面的多样性、合理性和智能化。", "motivation": "为了解决传统模板和固定规则驱动的设计方法在界面元素多样性、布局复杂度和个人化需求方面的局限性。", "method": "提出基于扩散-逆向扩散过程的生成框架，并引入条件控制以整合用户意图、环境状态和任务约束，同时结合正则化约束和优化目标保证生成界面的合理性和稳定性。", "result": "实验结果表明所提方法在均方误差、结构相似性、峰值信噪比以及平均绝对误差等指标上优于代表性的模型，并且在不同参数设置和环境条件下表现出较强的鲁棒性。", "conclusion": "扩散模型框架有效提升了界面生成的多样性、合理性和智能化水平，为复杂交互场景中的自动界面生成提供了一种可行方案。"}}
{"id": "2601.06813", "pdf": "https://arxiv.org/pdf/2601.06813", "abs": "https://arxiv.org/abs/2601.06813", "authors": ["Toru Yoshinaga", "Yasushi Kawase"], "title": "Analyzing the effect of prediction accuracy on the distributionally-robust competitive ratio", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "The field of algorithms with predictions aims to improve algorithm performance by integrating machine learning predictions into algorithm design. A central question in this area is how predictions can improve performance, and a key aspect of this analysis is the role of prediction accuracy. In this context, prediction accuracy is defined as a guaranteed probability that an instance drawn from the distribution belongs to the predicted set. As a performance measure that incorporates prediction accuracy, we focus on the distributionally-robust competitive ratio (DRCR), introduced by Sun et al.~(ICML 2024). The DRCR is defined as the expected ratio between the algorithm's cost and the optimal cost, where the expectation is taken over the worst-case instance distribution that satisfies the given prediction and accuracy requirement. A known structural property is that, for any fixed algorithm, the DRCR decreases linearly as prediction accuracy increases. Building on this result, we establish that the optimal DRCR value (i.e., the infimum over all algorithms) is a monotone and concave function of prediction accuracy. We further generalize the DRCR framework to a multiple-prediction setting and show that monotonicity and concavity are preserved in this setting. Finally, we apply our results to the ski rental problem, a benchmark problem in online optimization, to identify the conditions on prediction accuracies required for the optimal DRCR to attain a target value. Moreover, we provide a method for computing the critical accuracy, defined as the minimum accuracy required for the optimal DRCR to strictly improve upon the performance attainable without any accuracy guarantee.", "AI": {"tldr": "本文分析了预测准确性对分布鲁棒性竞争比的影响，通过引入多预测框架展示了最优DRCR值的单调性和凹性，并应用于滑雪租赁问题。", "motivation": "研究如何在算法设计中利用机器学习预测来提升性能，特别关注预测准确性如何影响算法表现。", "method": "提出基于分布鲁棒性竞争比（DRCR）的方法，在单一和多预测场景下探讨其性质，并应用到滑雪租赁问题中计算关键准确性。", "result": "证明了最优DRCR值随预测准确性的增加而单调减小且呈凹性，同时给出了目标DRCR值所需的关键预测准确性。", "conclusion": "通过引入和分析多预测框架下的分布鲁棒性竞争比，本文为基于预测的算法优化提供了理论基础。"}}
{"id": "2601.06810", "pdf": "https://arxiv.org/pdf/2601.06810", "abs": "https://arxiv.org/abs/2601.06810", "authors": ["Qiangwei Peng", "Zihan Wang", "Junda Ying", "Yuhao Sun", "Qing Nie", "Lei Zhang", "Tiejun Li", "Peijie Zhou"], "title": "WFR-FM: Simulation-Free Dynamic Unbalanced Optimal Transport", "categories": ["cs.LG", "cs.AI", "math-ph"], "comment": null, "summary": "The Wasserstein-Fisher-Rao (WFR) metric extends dynamic optimal transport (OT) by coupling displacement with change of mass, providing a principled geometry for modeling unbalanced snapshot dynamics. Existing WFR solvers, however, are often unstable, computationally expensive, and difficult to scale. Here we introduce WFR Flow Matching (WFR-FM), a simulation-free training algorithm that unifies flow matching with dynamic unbalanced OT. Unlike classical flow matching which regresses only a transport vector field, WFR-FM simultaneously regresses a vector field for displacement and a scalar growth rate function for birth-death dynamics, yielding continuous flows under the WFR geometry. Theoretically, we show that minimizing the WFR-FM loss exactly recovers WFR geodesics. Empirically, WFR-FM yields more accurate and robust trajectory inference in single-cell biology, reconstructing consistent dynamics with proliferation and apoptosis, estimating time-varying growth fields, and applying to generative dynamics under imbalanced data. It outperforms state-of-the-art baselines in efficiency, stability, and reconstruction accuracy. Overall, WFR-FM establishes a unified and efficient paradigm for learning dynamical systems from unbalanced snapshots, where not only states but also mass evolve over time.", "AI": {"tldr": "提出了一种无模拟的WFR流匹配算法（WFR-FM）用于动态不平衡最优传输问题。", "motivation": "现有WFR求解器不稳定、计算成本高且难以扩展。需要一种更高效、稳定的方法来处理不平衡数据下的时间序列分析，特别是单细胞生物学中的增殖和凋亡动力学重建。", "method": "通过同时回归位移向量场及增长速率函数，提出了一种新的WFR流匹配算法（WFR-FM），该方法能够准确地恢复WFR几何中的测地线。理论证明最小化WFR-FM损失即可精确还原WFR测地线。", "result": "相比现有基线，WFR-FM在效率、稳定性和重建精度方面表现更优，尤其是在单细胞生物学中对增殖和凋亡动力学的准确重建以及估计时间变化增长场方面。", "conclusion": "WFR-FM提供了一种统一且高效的范式，用于从不平衡快照学习动态系统。"}}
{"id": "2601.06806", "pdf": "https://arxiv.org/pdf/2601.06806", "abs": "https://arxiv.org/abs/2601.06806", "authors": ["Jiwen Zhang", "Zejun Li", "Siyuan Wang", "Xiangyu Shi", "Zhongyu Wei", "Qi Wu"], "title": "SpatialNav: Leveraging Spatial Scene Graphs for Zero-Shot Vision-and-Language Navigation", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "11 pages, 4 figures, 6 tables", "summary": "Although learning-based vision-and-language navigation (VLN) agents can learn spatial knowledge implicitly from large-scale training data, zero-shot VLN agents lack this process, relying primarily on local observations for navigation, which leads to inefficient exploration and a significant performance gap. To deal with the problem, we consider a zero-shot VLN setting that agents are allowed to fully explore the environment before task execution. Then, we construct the Spatial Scene Graph (SSG) to explicitly capture global spatial structure and semantics in the explored environment. Based on the SSG, we introduce SpatialNav, a zero-shot VLN agent that integrates an agent-centric spatial map, a compass-aligned visual representation, and a remote object localization strategy for efficient navigation. Comprehensive experiments in both discrete and continuous environments demonstrate that SpatialNav significantly outperforms existing zero-shot agents and clearly narrows the gap with state-of-the-art learning-based methods. Such results highlight the importance of global spatial representations for generalizable navigation.", "AI": {"tldr": "利用空间场景图解决零样本视觉和语言导航问题，提高导航效率。", "motivation": "零样本视觉和语言导航代理缺乏从大规模训练数据中学习空间知识的过程，依赖局部观测进行导航导致探索效率低下。", "method": "构建空间场景图以捕捉全局空间结构与语义信息，并引入SpatialNav代理，整合中心视角的空间地图、指南针对齐的视觉表示以及远程对象定位策略。", "result": "实验结果表明，SpatialNav在离散和连续环境中的性能显著优于现有零样本方法，并明显缩小了与基于学习的方法之间的差距。", "conclusion": "全局空间表征对于通用导航的重要性得到了证实。"}}
{"id": "2601.06803", "pdf": "https://arxiv.org/pdf/2601.06803", "abs": "https://arxiv.org/abs/2601.06803", "authors": ["Yubo Wang", "Juntian Zhang", "Yichen Wu", "Yankai Lin", "Nils Lukas", "Yuhan Liu"], "title": "Forest Before Trees: Latent Superposition for Efficient Visual Reasoning", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "While Chain-of-Thought empowers Large Vision-Language Models with multi-step reasoning, explicit textual rationales suffer from an information bandwidth bottleneck, where continuous visual details are discarded during discrete tokenization. Recent latent reasoning methods attempt to address this challenge, but often fall prey to premature semantic collapse due to rigid autoregressive objectives. In this paper, we propose Laser, a novel paradigm that reformulates visual deduction via Dynamic Windowed Alignment Learning (DWAL). Instead of forcing a point-wise prediction, Laser aligns the latent state with a dynamic validity window of future semantics. This mechanism enforces a \"Forest-before-Trees\" cognitive hierarchy, enabling the model to maintain a probabilistic superposition of global features before narrowing down to local details. Crucially, Laser maintains interpretability via decodable trajectories while stabilizing unconstrained learning via Self-Refined Superposition. Extensive experiments on 6 benchmarks demonstrate that Laser achieves state-of-the-art performance among latent reasoning methods, surpassing the strong baseline Monet by 5.03% on average. Notably, it achieves these gains with extreme efficiency, reducing inference tokens by more than 97%, while demonstrating robust generalization to out-of-distribution domains.", "AI": {"tldr": "提出了一种新的视觉推理范式Laser，通过动态窗口对齐学习机制解决现有方法的瓶颈问题。", "motivation": "当前Chain-of-Thought模型存在信息带宽限制，并且最近的隐式推理方法容易因过早语义塌陷而失效。", "method": "提出了一种新的视觉推理范式Laser，通过动态窗口对齐学习机制保持全局特征的概率叠加，然后集中到局部细节，同时保证了可解释性和稳定的学习过程。", "result": "在六个基准测试中，Laser表现出色，超过了Monet等基线方法5.03%的性能。它还展示了极高的效率，在减少推理标记数量的同时保持强大的泛化能力。", "conclusion": "Laser通过改进视觉推理范式解决了现有模型中的瓶颈问题，并在多个基准测试中取得了显著的效果和高效性。"}}
{"id": "2601.06802", "pdf": "https://arxiv.org/pdf/2601.06802", "abs": "https://arxiv.org/abs/2601.06802", "authors": ["Ayman Mansour"], "title": "Doing More with Less: Data Augmentation for Sudanese Dialect Automatic Speech Recognition", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Although many Automatic Speech Recognition (ASR) systems have been developed for Modern Standard Arabic (MSA) and Dialectal Arabic (DA), few studies have focused on dialect-specific implementations, particularly for low-resource Arabic dialects such as Sudanese. This paper presents a comprehensive study of data augmentation techniques for fine-tuning OpenAI Whisper models and establishes the first benchmark for the Sudanese dialect. Two augmentation strategies are investigated: (1) self-training with pseudo-labels generated from unlabeled speech, and (2) TTS-based augmentation using synthetic speech from the Klaam TTS system. The best-performing model, Whisper-Medium fine-tuned with combined self-training and TTS augmentation (28.4 hours), achieves a Word Error Rate (WER) of 57.1% on the evaluation set and 51.6% on an out-of-domain holdout set substantially outperforming zero-shot multilingual Whisper (78.8% WER) and MSA-specialized Arabic models (73.8-123% WER). All experiments used low-cost resources (Kaggle free tier and Lightning.ai trial), demonstrating that strategic data augmentation can overcome resource limitations for low-resource dialects and provide a practical roadmap for developing ASR systems for low-resource Arabic dialects and other marginalized language varieties. The models, evaluation benchmarks, and reproducible training pipelines are publicly released to facilitate future research on low-resource Arabic ASR.", "AI": {"tldr": "该论文研究了数据增强技术在改进苏丹方言自动语音识别（ASR）系统中的应用，提出了两种增强策略：自训练和基于TTS的合成语音增强。", "motivation": "尽管已经为现代标准阿拉伯语（MSA）和阿拉伯方言开发了许多自动语音识别（ASR）系统，但针对特定方言特别是资源较少的苏丹方言的研究却很少。该论文旨在解决这一问题，通过数据增强技术提升低资源环境下的ASR性能。", "method": "研究采用了两种数据增强策略：自训练利用未标记音频生成伪标签进行再训练；以及使用Klaam TTS系统基于合成语音的数据增强方法。实验中对OpenAI Whisper模型进行了微调，并将其与多语言Whisper和MSA特殊化阿拉伯语模型进行了比较。", "result": "最佳模型为结合了自训练和TTS增强策略的Whisper-Medium，仅使用28.4小时数据，在评估集上达到57.1% WER，在域外测试集中达到51.6%WER。这些结果显著优于多语言Whisper（78.8%WER）以及MSA特殊化阿拉伯语模型（73.8-123%WER）。", "conclusion": "该研究证明了通过数据增强策略，即使在低资源情况下也能提高ASR系统的性能，并为开发针对其他资源较少的阿拉伯方言和其他边缘语言种类的ASR系统提供了一个实用指南。"}}
{"id": "2601.06801", "pdf": "https://arxiv.org/pdf/2601.06801", "abs": "https://arxiv.org/abs/2601.06801", "authors": ["Shujian Gao", "Yuan Wang", "Jiangtao Yan", "Zuxuan Wu", "Yu-Gang Jiang"], "title": "Thinking with Deltas: Incentivizing Reinforcement Learning via Differential Visual Reasoning Policy", "categories": ["cs.AI", "cs.LG"], "comment": "24 pages, 10 tables, 4 figures", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced reasoning capabilities in Large Language Models. However, adapting RLVR to multimodal domains suffers from a critical \\textit{perception-reasoning decoupling}. Existing paradigms, driven by text-centric outcome rewards, reasoning in language medium, inadvertently encourage models to bypass visual perception. We empirically validate this through blind experiments: state-of-the-art policies maintain or surprisingly improve performance even when visual inputs are entirely removed. This reveals that these models degenerate into \\textit{blind reasoners}, exploiting linguistic priors to generate plausible answers instead of attending to visual evidence. In response, we propose \\textbf{Thinking with Deltas}, a framework driven by a \\textbf{Differential Visual Reasoning Policy (DVRP)}. DVRP introduces intrinsic supervision via visual triplets, comprising original, masked, and perturbed inputs. It optimizes the model to maximize reasoning divergence from masked inputs (enforcing \\textit{visual sensitivity}) while minimizing divergence from perturbed inputs (ensuring \\textit{visual robustness}). By aligning reasoning variations strictly with the \\textit{Delta} of visual information, DVRP inherently bolsters visual understanding capabilities and significantly outperforms state-of-the-art methods on both general and medical benchmarks, without requiring external annotations or auxiliary tools.", "AI": {"tldr": "本文提出了Thinking with Deltas框架，通过引入Differential Visual Reasoning Policy（DVRP）来解决多模态领域中视觉推理脱钩的问题。", "motivation": "现有强化学习与可验证奖励的方法在处理多模态任务时存在感知和推理分离的缺陷。模型倾向于依赖语言先验而非视觉证据生成答案，这削弱了其对图像信息的理解能力。", "method": "本文提出Differential Visual Reasoning Policy（DVRP），利用三元组对比学习方法来加强模型的视觉理解能力。", "result": "实验结果显示，该方法在多项基准测试中超越了现有的最佳方案，并且无需额外标注或辅助工具。", "conclusion": "通过引入DVRP，本文有效解决了多模态任务中的感知和推理分离问题，提高了模型处理图像信息的能力。"}}
{"id": "2601.06800", "pdf": "https://arxiv.org/pdf/2601.06800", "abs": "https://arxiv.org/abs/2601.06800", "authors": ["Hoang Hiep Trieu"], "title": "Graph Neural Network with One-side Edge Sampling for Fraud Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Financial fraud is always a major problem in the field of finance, as it can cause significant consequences. As a result, many approaches have been designed to detect it, and lately Graph Neural Networks (GNNs) have been demonstrated as a competent candidate. However, when trained with a large amount of data, they are slow and computationally demanding. In addition, GNNs may need a deep architecture to detect complex fraud patterns, but doing so may make them suffer from problems such as over-fitting or over-smoothing. Over-fitting leads to reduced generalisation of the model on unseen data, while over-smoothing causes all nodes' features to converge to a fixed point due to excessive aggregation of information from neighbouring nodes. In this research, I propose an approach called One-Side Edge Sampling (OES) that can potentially reduce training duration as well as the effects of over-smoothing and over-fitting. The approach leverages predictive confidence in an edge classification task to sample edges from the input graph during a certain number of epochs. To explain why OES can alleviate over-smoothing, I perform a theoretical analysis of the proposed approach. In addition, to validate the effect of OES, I conduct experiments using different GNNs on two datasets. The results show that OES can empirically outperform backbone models in both shallow and deep architectures while also reducing training time.", "AI": {"tldr": "提出了一种名为单边边采样的方法，用于改进图神经网络在反欺诈检测中的性能。", "motivation": "为了改善图神经网络在大量数据上的训练速度和防止过度拟合与过度平滑问题", "method": "通过边缘分类任务的预测置信度，在输入图形中进行边缘采样，并进行理论分析以解释如何缓解过度平滑的问题", "result": "实验表明该方法能够在浅层和深层架构下均超越基线模型，同时减少训练时间", "conclusion": "单边边采样的方法能够有效提高图神经网络在反欺诈检测中的性能并解决相关问题"}}
{"id": "2601.06799", "pdf": "https://arxiv.org/pdf/2601.06799", "abs": "https://arxiv.org/abs/2601.06799", "authors": ["Zili Wei", "Xiaocui Yang", "Yilin Wang", "Zihan Wang", "Weidong Bao", "Shi Feng", "Daling Wang", "Yifei Zhang"], "title": "CIRAG: Construction-Integration Retrieval and Adaptive Generation for Multi-hop Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Triple-based Iterative Retrieval-Augmented Generation (iRAG) mitigates document-level noise for multi-hop question answering. However, existing methods still face limitations: (i) greedy single-path expansion, which propagates early errors and fails to capture parallel evidence from different reasoning branches, and (ii) granularity-demand mismatch, where a single evidence representation struggles to balance noise control with contextual sufficiency. In this paper, we propose the Construction-Integration Retrieval and Adaptive Generation model, CIRAG. It introduces an Iterative Construction-Integration module that constructs candidate triples and history-conditionally integrates them to distill core triples and generate the next-hop query. This module mitigates the greedy trap by preserving multiple plausible evidence chains. Besides, we propose an Adaptive Cascaded Multi-Granularity Generation module that progressively expands contextual evidence based on the problem requirements, from triples to supporting sentences and full passages. Moreover, we introduce Trajectory Distillation, which distills the teacher model's integration policy into a lightweight student, enabling efficient and reliable long-horizon reasoning. Extensive experiments demonstrate that CIRAG achieves superior performance compared to existing iRAG methods.", "AI": {"tldr": "论文提出了一个用于多跳问答的Construction-Integration Retrieval and Adaptive Generation模型（CIRAG），旨在改进基于三元组迭代检索增强生成方法中的问题。", "motivation": "现有方法在处理多跳问答时存在两个主要限制：贪婪单路径扩展导致早期错误传播，无法捕捉来自不同推理分支的平行证据；单一证据表示难以平衡噪声控制与上下文充分性之间的矛盾。", "method": "CIRAG模型包含迭代构造集成模块和自适应级联多重粒度生成模块。前者通过保留多个可能的证据链来避免贪婪陷阱，并根据历史条件整合候选三元组以提炼核心三元组并生成下一跳查询；后者则基于问题需求，从三元组逐步扩展到支持句子再到完整段落。", "result": "实验表明，CIRAG模型在多跳问答任务上优于现有的iRAG方法。", "conclusion": "通过引入迭代构造集成模块和自适应级联多重粒度生成模块以及轨迹蒸馏技术，CIRAG能够更有效地进行长跨度推理并提高性能。"}}
{"id": "2601.06795", "pdf": "https://arxiv.org/pdf/2601.06795", "abs": "https://arxiv.org/abs/2601.06795", "authors": ["Zhengqing Yan", "Xinyang Liu", "Yi Zhang", "Fan Guo", "Yao Liu", "Junchen Wan", "Kang Song"], "title": "GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Automated Theorem Proving (ATP) represents a fundamental challenge in Artificial Intelligence (AI), requiring the construction of machine-verifiable proofs in formal languages such as Lean to evaluate AI reasoning capabilities. Reinforcement learning (RL), particularly the high-performance Group Relative Policy Optimization (GRPO) algorithm, has emerged as a mainstream approach for this task. However, in ATP scenarios, GRPO faces two critical issues: when composite rewards are used, its relative advantage estimation may conflict with the binary feedback from the formal verifier; meanwhile, its static sampling strategy may discard entire batches of data if no valid proof is found, resulting in zero contribution to model updates and significant data waste. To address these limitations, we propose Group Dual-dynamic and Equal-right-advantage Policy Optimization (GDEPO), a method incorporating three core mechanisms: 1) dynamic additional sampling, which resamples invalid batches until a valid proof is discovered; 2) equal-right advantage, decoupling the sign of the advantage function (based on correctness) from its magnitude (modulated by auxiliary rewards) to ensure stable and correct policy updates; and 3) dynamic additional iterations, applying extra gradient steps to initially failed but eventually successful samples to accelerate learning on challenging cases. Experiments conducted on three datasets of varying difficulty (MinF2F-test, MathOlympiadBench, PutnamBench) confirm the effectiveness of GDEPO, while ablation studies validate the necessity of its synergistic components. The proposed method enhances data utilization and optimization efficiency, offering a novel training paradigm for ATP.", "AI": {"tldr": "该论文提出了GDEPO算法，以解决ATP中GRPO算法面临的相对优势估计冲突和静态采样策略导致的数据浪费问题。", "motivation": "在自动化定理证明场景中，传统的GRPO算法面临两个关键挑战：当使用复合奖励时，其相对优势估计可能与形式验证器的二进制反馈产生冲突；同时，它的静态采样策略可能导致没有找到有效证明的数据批次被丢弃，造成数据浪费。", "method": "GDEPO方法包括三个核心机制：动态附加采样、等权利优势和动态附加迭代。通过这些机制来解决GRPO算法在ATP场景中的问题。", "result": "实验结果表明，该方法提高了样本约束强化学习中训练数据的利用率和优化效率，并且消融研究验证了其各组成部分的重要性。", "conclusion": "GDEPO为自动化定理证明提供了新的训练范式，有效地解决了GRPO算法在ATP场景中的问题。"}}
{"id": "2601.06794", "pdf": "https://arxiv.org/pdf/2601.06794", "abs": "https://arxiv.org/abs/2601.06794", "authors": ["Zhicong Li", "Lingjie Jiang", "Yulan Hu", "Xingchen Zeng", "Yixia Li", "Xiangwen Zhang", "Guanhua Chen", "Zheng Pan", "Xin Li", "Yong Liu"], "title": "No More Stale Feedback: Co-Evolving Critics for Open-World Agent Learning", "categories": ["cs.AI"], "comment": null, "summary": "Critique-guided reinforcement learning (RL) has emerged as a powerful paradigm for training LLM agents by augmenting sparse outcome rewards with natural-language feedback. However, current methods often rely on static or offline critic models, which fail to adapt as the policy evolves. In on-policy RL, the agent's error patterns shift over time, causing stationary critics to become stale and providing feedback of diminishing utility. To address this, we introduce ECHO (Evolving Critic for Hindsight-Guided Optimization)}, a framework that jointly optimizes the policy and critic through a synchronized co-evolutionary loop. ECHO utilizes a cascaded rollout mechanism where the critic generates multiple diagnoses for an initial trajectory, followed by policy refinement to enable group-structured advantage estimation. We address the challenge of learning plateaus via a saturation-aware gain shaping objective, which rewards the critic for inducing incremental improvements in high-performing trajectories. By employing dual-track GRPO updates, ECHO ensures the critic's feedback stays synchronized with the evolving policy. Experimental results show that ECHO yields more stable training and higher long-horizon task success across open-world environments.", "AI": {"tldr": "介绍了一种名为ECHO的框架，用于通过同步共进化循环优化策略和评论者，在开放世界的环境下提高代理学习的效果。", "motivation": "当前的方法依赖于静态或离线评论模型，无法适应随时间变化的政策错误模式。为了解决这个问题，提出了一个新框架以确保评论者的反馈与不断发展的政策保持一致。", "method": "ECHO通过同步共进化循环优化策略和评论者，采用级联展开机制生成多个诊断，并使用饱和感知增益塑形目标奖励增量改进。", "result": "实验结果表明，ECHO在开放世界的环境中提供了更稳定的训练过程并提高了长期任务成功的概率。", "conclusion": "通过同步共进化循环优化策略和评论者，ECHO框架能够在开放世界环境下提高代理学习的效果。"}}
{"id": "2601.06793", "pdf": "https://arxiv.org/pdf/2601.06793", "abs": "https://arxiv.org/abs/2601.06793", "authors": ["Zhongping Ji"], "title": "CliffordNet: All You Need is Geometric Algebra", "categories": ["cs.CV", "cs.LG"], "comment": "15 pages", "summary": "Modern computer vision architectures, from CNNs to Transformers, predominantly rely on the stacking of heuristic modules: spatial mixers (Attention/Conv) followed by channel mixers (FFNs). In this work, we challenge this paradigm by returning to mathematical first principles. We propose the \\textbf{Clifford Algebra Network (CAN)}, also referred to as CliffordNet, a vision backbone grounded purely in Geometric Algebra. Instead of engineering separate modules for mixing and memory, we derive a unified interaction mechanism based on the \\textbf{Clifford Geometric Product} ($uv = u \\cdot v + u \\wedge v$). This operation ensures algebraic completeness regarding the Geometric Product by simultaneously capturing feature coherence (via the generalized inner product) and structural variation (via the exterior wedge product). Implemented via an efficient sparse rolling mechanism with \\textbf{strict linear complexity $\\mathcal{O}(N)$}, our model reveals a surprising emergent property: the geometric interaction is so representationally dense that standard Feed-Forward Networks (FFNs) become redundant. Empirically, CliffordNet establishes a new Pareto frontier: our \\textbf{Nano} variant achieves \\textbf{76.41\\%} accuracy on CIFAR-100 with only \\textbf{1.4M} parameters, effectively matching the heavy-weight ResNet-18 (11.2M) with \\textbf{$8\\times$ fewer parameters}, while our \\textbf{Base} variant sets a new SOTA for tiny models at \\textbf{78.05\\%}. Our results suggest that global understanding can emerge solely from rigorous, algebraically complete local interactions, potentially signaling a shift where \\textit{geometry is all you need}. Code is available at https://github.com/ParaMind2025/CAN.", "AI": {"tldr": "本文提出了一种基于几何代数的视觉骨干网络CliffordNet，挑战了传统计算机视觉架构的设计。", "motivation": "传统的CNN和Transformer等架构依赖于堆叠的手工模块，如空间混合器（Attention/Conv）和通道混合器（FFNs）。作者希望通过回归到数学基本原理来改进这一现状。", "method": "本文提出了一种基于几何代数的统一交互机制CliffordNet。该网络通过Clifford几何乘积操作同时捕捉特征一致性和结构变异，实现高效的稀疏滚动机制，并具有严格的线性复杂度O(N)。", "result": "实验表明，CliffordNet在CIFAR-100数据集上表现优异：Nano变体达到76.41%的准确率，参数仅为1.4M；Base变体则以78.05%的成绩刷新了小型模型的最佳记录。", "conclusion": "结果表明，全局理解可以完全通过严格的局部交互得出。这可能预示着一个新时代的到来：几何代数是所有你所需的基础。"}}
{"id": "2601.06790", "pdf": "https://arxiv.org/pdf/2601.06790", "abs": "https://arxiv.org/abs/2601.06790", "authors": ["Bowen Shen", "Yuyue Chen", "Peng Yang", "Bin Zhang", "Xi Zhang", "Zoe L. Jiang"], "title": "SecMoE: Communication-Efficient Secure MoE Inference via Select-Then-Compute", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted by AAAI 2026", "summary": "Privacy-preserving Transformer inference has gained attention due to the potential leakage of private information. Despite recent progress, existing frameworks still fall short of practical model scales, with gaps up to a hundredfold. A possible way to close this gap is the Mixture of Experts (MoE) architecture, which has emerged as a promising technique to scale up model capacity with minimal overhead. However, given that the current secure two-party (2-PC) protocols allow the server to homomorphically compute the FFN layer with its plaintext model weight, under the MoE setting, this could reveal which expert is activated to the server, exposing token-level privacy about the client's input. While naively evaluating all the experts before selection could protect privacy, it nullifies MoE sparsity and incurs the heavy computational overhead that sparse MoE seeks to avoid. To address the privacy and efficiency limitations above, we propose a 2-PC privacy-preserving inference framework, \\SecMoE. Unifying per-entry circuits in both the MoE layer and piecewise polynomial functions, \\SecMoE obliviously selects the extracted parameters from circuits and only computes one encrypted entry, which we refer to as Select-Then-Compute. This makes the model for private inference scale to 63$\\times$ larger while only having a 15.2$\\times$ increase in end-to-end runtime. Extensive experiments show that, under 5 expert settings, \\SecMoE lowers the end-to-end private inference communication by 1.8$\\sim$7.1$\\times$ and achieves 1.3$\\sim$3.8$\\times$ speedup compared to the state-of-the-art (SOTA) protocols.", "AI": {"tldr": "提出了一种名为SecMoE的隐私保护Transformer推理框架，以解决现有方法在模型规模和通信效率上的局限性。", "motivation": "现有的隐私保护机制在实际应用中的模型规模较小，并且存在较高的通信开销。通过引入Mixture of Experts（专家混合）架构可以有效提升模型容量，但目前的两方安全协议可能会暴露用户的输入信息。", "method": "SecMoE采用选择-然后计算策略，在不泄露任何敏感信息的前提下，实现了高效的隐私保护推理过程。该方法结合了门控电路和分段多项式函数，通过在加密状态下进行专家的选择与计算来避免额外的计算开销。", "result": "实验结果表明，与当前最先进的协议相比，SecMoE能够将模型规模提升63倍，并且只增加了15.2倍的整体运行时间。同时，在五位专家设置下，端到端的私有推理通信减少了1.8-7.1倍，实现了1.3-3.8倍的速度提升。", "conclusion": "SecMoE框架在保证隐私安全的同时，显著提升了大型模型的推理效率和可扩展性，为未来的研究提供了新的方向。"}}
{"id": "2601.06789", "pdf": "https://arxiv.org/pdf/2601.06789", "abs": "https://arxiv.org/abs/2601.06789", "authors": ["Qihao Wang", "Ziming Cheng", "Shuo Zhang", "Fan Liu", "Rui Xu", "Heng Lian", "Kunyi Wang", "Xiaoming Yu", "Jianghao Yin", "Sen Hu", "Yue Hu", "Shaolei Zhang", "Yanbing Liu", "Ronghao Chen", "Huacan Wang"], "title": "MemGovern: Enhancing Code Agents through Learning from Governed Human Experiences", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "While autonomous software engineering (SWE) agents are reshaping programming paradigms, they currently suffer from a \"closed-world\" limitation: they attempt to fix bugs from scratch or solely using local context, ignoring the immense historical human experience available on platforms like GitHub. Accessing this open-world experience is hindered by the unstructured and fragmented nature of real-world issue-tracking data. In this paper, we introduce MemGovern, a framework designed to govern and transform raw GitHub data into actionable experiential memory for agents. MemGovern employs experience governance to convert human experience into agent-friendly experience cards and introduces an agentic experience search strategy that enables logic-driven retrieval of human expertise. By producing 135K governed experience cards, MemGovern achieves a significant performance boost, improving resolution rates on the SWE-bench Verified by 4.65%. As a plug-in approach, MemGovern provides a solution for agent-friendly memory infrastructure.", "AI": {"tldr": "MemGovern框架通过治理和转换GitHub上的原始数据，将其转化为可操作的经验记忆来增强代码代理。", "motivation": "当前的自主软件工程代理由于忽视了GitHub等平台上的历史人类经验而受限于“封闭世界”问题。这些代理尝试从零开始修复bug或仅使用局部上下文信息，忽略了大量的可用知识。", "method": "MemGovern采用经历治理将人类经验转化为对代理友好的经验卡片，并引入一种基于逻辑的检索策略来获取人类专业知识。", "result": "通过生成135K个经治理的经验卡片，MemGovern在SWE-bench Verified上实现了4.65%的问题解决率提升。", "conclusion": "作为一种插件方法，MemGovern为代理友好的记忆基础设施提供了解决方案。"}}
{"id": "2601.06788", "pdf": "https://arxiv.org/pdf/2601.06788", "abs": "https://arxiv.org/abs/2601.06788", "authors": ["Min Chen", "Zihan Wang", "Canyu Chen", "Zeguan Wu", "Manling Li", "Junyu Liu"], "title": "Artificial Entanglement in the Fine-Tuning of Large Language Models", "categories": ["cs.LG", "cs.AI", "quant-ph", "stat.ML"], "comment": "41 pages, many figures", "summary": "Large language models (LLMs) can be adapted to new tasks using parameter-efficient fine-tuning (PEFT) methods that modify only a small number of trainable parameters, often through low-rank updates. In this work, we adopt a quantum-information-inspired perspective to understand their effectiveness. From this perspective, low-rank parameterizations naturally correspond to low-dimensional Matrix Product States (MPS) representations, which enable entanglement-based characterizations of parameter structure. Thereby, we term and measure \"Artificial Entanglement\", defined as the entanglement entropy of the parameters in artificial neural networks (in particular the LLMs). We first study the representative low-rank adaptation (LoRA) PEFT method, alongside full fine-tuning (FFT), using LLaMA models at the 1B and 8B scales trained on the Tulu3 and OpenThoughts3 datasets, and uncover: (i) Internal artificial entanglement in the updates of query and value projection matrices in LoRA follows a volume law with a central suppression (termed as the \"Entanglement Valley\"), which is sensitive to hyper-parameters and is distinct from that in FFT; (ii) External artificial entanglement in attention matrices, corresponding to token-token correlations in representation space, follows an area law with logarithmic corrections and remains robust to LoRA hyper-parameters and training steps. Drawing a parallel to the No-Hair Theorem in black hole physics, we propose that although LoRA and FFT induce distinct internal entanglement signatures, such differences do not manifest in the attention outputs, suggesting a \"no-hair\" property that results in the effectiveness of low rank updates. We further provide theoretical support based on random matrix theory, and extend our analysis to an MPS Adaptation PEFT method, which exhibits qualitatively similar behaviors.", "AI": {"tldr": "该论文通过量子信息视角分析了大型语言模型（LLMs）低秩适应方法的效果，提出了“人工纠缠”的概念，并研究了其在不同情况下的表现。", "motivation": "通过量子信息理论来理解低秩参数化如何影响大模型微调的有效性，引入和测量“人工纠缠”这一新概念以更深入地剖析神经网络内部的结构变化。", "method": "采用代表性的LoRA低秩适应方法与全量微调FFT方法对比研究LLaMA模型在不同规模及数据集上的参数更新行为，并通过随机矩阵理论提供理论支持，进一步推广到MPS适应方法。", "result": "发现LoRA中内部人工纠缠遵循容积定律且对超参数敏感；外部人工纠缠则符合面积定律并受训练步骤影响小。提出尽管低秩与全量微调导致不同的内部缠结特征，这种差异在注意矩阵输出上不明显，表现出一种“无毛定理”特性。", "conclusion": "论文展示了从量子信息角度理解大模型参数化方法的新视角，并为解释低秩更新的有效性提供理论依据。"}}
{"id": "2601.06781", "pdf": "https://arxiv.org/pdf/2601.06781", "abs": "https://arxiv.org/abs/2601.06781", "authors": ["Huatao Xu", "Zihe Liu", "Zilin Zeng", "Baichuan Li", "Mo Li"], "title": "AutoTour: Automatic Photo Tour Guide with Smartphones and LLMs", "categories": ["cs.HC", "cs.AI", "cs.CV"], "comment": "21", "summary": "We present AutoTour, a system that enhances user exploration by automatically generating fine-grained landmark annotations and descriptive narratives for photos captured by users. The key idea of AutoTour is to fuse visual features extracted from photos with nearby geospatial features queried from open matching databases. Unlike existing tour applications that rely on pre-defined content or proprietary datasets, AutoTour leverages open and extensible data sources to provide scalable and context-aware photo-based guidance. To achieve this, we design a training-free pipeline that first extracts and filters relevant geospatial features around the user's GPS location. It then detects major landmarks in user photos through VLM-based feature detection and projects them into the horizontal spatial plane. A geometric matching algorithm aligns photo features with corresponding geospatial entities based on their estimated distance and direction. The matched features are subsequently grounded and annotated directly on the original photo, accompanied by large language model-generated textual and audio descriptions to provide an informative, tour-like experience. We demonstrate that AutoTour can deliver rich, interpretable annotations for both iconic and lesser-known landmarks, enabling a new form of interactive, context-aware exploration that bridges visual perception and geospatial understanding.", "AI": {"tldr": "AutoTour是一款通过融合照片视觉特征与地理空间特征，自动为用户拍摄的照片生成详细地标注释和描述性叙述的系统。", "motivation": "现有的旅游应用程序依赖于预定义的内容或专有数据集，限制了其扩展性和上下文感知能力。AutoTour利用开放且可扩展的数据源来提供基于照片的个性化、大规模和上下文相关的指导。", "method": "设计了一个无需训练的流水线，首先从用户GPS位置周围提取并过滤相关地理空间特征，然后通过视觉语言模型(VLM)检测用户照片中的主要地标，并将它们投影到水平空间平面。采用几何匹配算法根据估计的距离和方向对齐照片特征与相应的地理实体，并生成文本和语音描述。", "result": "AutoTour能够为标志性地标和不太知名的地标提供丰富的、可解释的注释，实现了视觉感知与地理理解之间的桥梁。", "conclusion": "AutoTour通过结合开放数据源和智能匹配算法，提供了一种新的互动式旅游体验形式，增强了用户探索的兴趣。"}}
{"id": "2601.06780", "pdf": "https://arxiv.org/pdf/2601.06780", "abs": "https://arxiv.org/abs/2601.06780", "authors": ["Keito Inoshita", "Xiaokang Zhou", "Akira Kawai"], "title": "Multi-Stage Evolutionary Model Merging with Meta Data Driven Curriculum Learning for Sentiment-Specialized Large Language Modeling", "categories": ["cs.CL", "cs.AI"], "comment": "This paper was presented at the 10th IEEE International Conference on Data Science and Systems in December 2024 and is awaiting publication", "summary": "The emergence of large language models (LLMs) has significantly transformed natural language processing (NLP), enabling more generalized models to perform various tasks with minimal training. However, traditional sentiment analysis methods, which focus on individual tasks such as sentiment classification or aspect-based analysis, are not practical for real-world applications that usually require handling multiple tasks. While offering flexibility, LLMs in sentiment-specific tasks often fall short of the required accuracy. Techniques like fine-tuning and evolutionary model merging help integrate models into a unified framework, which can improve the learning performance while reducing computational costs. The use of task meta-data and curriculum learning to optimize learning processes remains underexplored, while sentiment analysis is a critical task in NLP that requires high accuracy and scalability across multiple subtasks. In this study, we propose a hybrid learning model called Multi-stage Evolutionary Model Merging with Meta data driven Curriculum Learning (MEM-MCL), to enhance the sentiment analysis in large language modeling. In particular, expert models are created through instruction tuning for specific sentiment tasks and then merged using evolutionary algorithms to form a unified model. The merging process is optimized with weak data to enhance performance across tasks. The curriculum learning is incorporated to provide a learning sequence based on task difficulty, improving knowledge extraction from LLMs. Experiment results demonstrate that the proposed MEM-MCL model outperforms conventional LLMs in a majority of sentiment analysis tasks, achieving superior results across various subtasks.", "AI": {"tldr": "提出了一种多阶段进化模型融合与元数据驱动的课程学习方法，用于增强大规模语言模型中的情感分析性能。", "motivation": "传统的情感分析方法在处理实际应用中涉及多个任务时效果不佳。尽管大型语言模型提供灵活性，但其在特定情感任务上的准确性不足。通过使用任务元数据和课程学习来优化学习过程可以提高准确性和可扩展性。", "method": "提出了一种称为多阶段进化模型融合与元数据驱动的课程学习（MEM-MCL）的方法，该方法首先通过指令调优创建用于特定情感任务的专业模型，并使用进化算法将这些模型合并为一个统一模型。合并过程利用弱数据进行优化，以增强跨任务性能。", "result": "实验结果表明，所提出的MEM-MCL模型在大多数情感分析任务中优于传统的大规模语言模型，实现了更好的子任务效果。", "conclusion": "该方法通过融合多个特定任务的专家模型，并使用课程学习来改善知识提取过程，能够有效地提高大规模语言模型中的情感分析性能。"}}
{"id": "2601.06777", "pdf": "https://arxiv.org/pdf/2601.06777", "abs": "https://arxiv.org/abs/2601.06777", "authors": ["Ali Lotfi", "Adam Carter", "Mohammad Meysami", "Thuan Ha", "Kwabena Nketia", "Steve Shirtliffe"], "title": "The Normalized Difference Layer: A Differentiable Spectral Index Formulation for Deep Learning", "categories": ["cs.CV"], "comment": "21 pages, 9 figures", "summary": "Normalized difference indices have been a staple in remote sensing for decades. They stay reliable under lighting changes produce bounded values and connect well to biophysical signals. Even so, they are usually treated as a fixed pre processing step with coefficients set to one, which limits how well they can adapt to a specific learning task. In this study, we introduce the Normalized Difference Layer that is a differentiable neural network module. The proposed method keeps the classical idea but learns the band coefficients from data. We present a complete mathematical framework for integrating this layer into deep learning architectures that uses softplus reparameterization to ensure positive coefficients and bounded denominators. We describe forward and backward pass algorithms enabling end to end training through backpropagation. This approach preserves the key benefits of normalized differences, namely illumination invariance and outputs bounded to $[-1,1]$ while allowing gradient descent to discover task specific band weightings. We extend the method to work with signed inputs, so the layer can be stacked inside larger architectures. Experiments show that models using this layer reach similar classification accuracy to standard multilayer perceptrons while using about 75\\% fewer parameters. They also handle multiplicative noise well, at 10\\% noise accuracy drops only 0.17\\% versus 3.03\\% for baseline MLPs. The learned coefficient patterns stay consistent across different depths.", "AI": {"tldr": "本文提出了一种可微分的光谱指数计算层，允许神经网络学习最佳波段系数。", "motivation": "传统的归一化差异索引在光照变化和生物物理信号连接方面表现出色。然而，它们通常作为固定的预处理步骤使用，限制了其适应特定任务的能力。因此，作者提出了一种可微分的归一化差值层来学习最佳波段系数。", "method": "通过软加算重参数化保证正系数和有界分母的方法将归一化差异层集成到深度学习架构中，并提供了前向和后向传播算法以实现端到端训练。该方法在保持照明不变性和输出[-1,1]范围内同时允许梯度下降发现特定任务波段加权。", "result": "实验表明，使用此层的模型达到与标准多层感知器相似的分类准确性，并且参数减少了约75%。此外，在处理乘法噪声方面表现出色。", "conclusion": "通过学习最佳波段系数，归一化差异层能够更好地适应特定任务，同时保持传统指数的优点并减少模型复杂性。"}}
{"id": "2601.06776", "pdf": "https://arxiv.org/pdf/2601.06776", "abs": "https://arxiv.org/abs/2601.06776", "authors": ["Xufei Tian", "Wenli Du", "Shaoyi Yang", "Han Hu", "Hui Xin", "Shifeng Qu", "Ke Ye"], "title": "From Text to Simulation: A Multi-Agent LLM Workflow for Automated Chemical Process Design", "categories": ["cs.AI"], "comment": null, "summary": "Process simulation is a critical cornerstone of chemical engineering design. Current automated chemical design methodologies focus mainly on various representations of process flow diagrams. However, transforming these diagrams into executable simulation flowsheets remains a time-consuming and labor-intensive endeavor, requiring extensive manual parameter configuration within simulation software. In this work, we propose a novel multi-agent workflow that leverages the semantic understanding capabilities of large language models(LLMs) and enables iterative interactions with chemical process simulation software, achieving end-to-end automated simulation from textual process specifications to computationally validated software configurations for design enhancement. Our approach integrates four specialized agents responsible for task understanding, topology generation, parameter configuration, and evaluation analysis, respectively, coupled with Enhanced Monte Carlo Tree Search to accurately interpret semantics and robustly generate configurations. Evaluated on Simona, a large-scale process description dataset, our method achieves a 31.1% improvement in the simulation convergence rate compared to state-of-the-art baselines and reduces the design time by 89. 0% compared to the expert manual design. This work demonstrates the potential of AI-assisted chemical process design, which bridges the gap between conceptual design and practical implementation. Our workflow is applicable to diverse process-oriented industries, including pharmaceuticals, petrochemicals, food processing, and manufacturing, offering a generalizable solution for automated process design.", "AI": {"tldr": "本文提出了一种利用大规模语言模型的多智能体工作流，从文本说明自动转换为可执行的化学过程模拟流程图。", "motivation": "目前自动化化学设计方法主要集中在工艺流程图的各种表示上，而将这些图表转化为可在仿真软件中运行的配置仍然耗时且劳动密集型。因此本文旨在通过多智能体工作流来解决这一问题，以实现从文本说明到可计算验证软件配置的端到端自动化。", "method": "提出了一种结合四个专门智能体的工作流程，这些智能体负责任务理解、拓扑生成、参数配置和评价分析，并辅以增强型蒙特卡洛树搜索算法来准确解释语义并稳健地生成配置。", "result": "在Simona数据集上进行测试后，该方法相比最新基线提高了31.1%的模拟收敛率，并将设计时间减少了89.0%与专家手动设计相比。", "conclusion": "这项工作展示了人工智能辅助化学过程设计的潜力，它弥补了概念设计与实际实施之间的差距。所提出的工作流程适用于制药、石化、食品加工和制造业等各种工艺导向行业，为自动化过程设计提供了一种通用解决方案。"}}
{"id": "2601.06774", "pdf": "https://arxiv.org/pdf/2601.06774", "abs": "https://arxiv.org/abs/2601.06774", "authors": ["Xiangzhe Yuan", "Jiajun Wang", "Huanchen Wang", "Qian Wan", "Siying Hu"], "title": "ImmuniFraug: A Metacognitive Intervention Anti-Fraud Approach to Enhance Undergraduate Students' Cyber Fraud Awareness", "categories": ["cs.HC"], "comment": null, "summary": "Cyber fraud now constitutes over half of criminal cases in China, with undergraduate students experiencing a disproportionate rise in victimization. Traditional anti-fraud training remains predominantly passive, yielding limited engagement and retention. This paper introduces ImmuniFraug, a Large Language Model (LLM)-based metacognitive intervention that delivers immersive, multimodal fraud simulations integrating text, voice, and visual avatars across ten prevalent fraud types. Each scenario is designed to replicate real-world persuasion tactics and psychological pressure, while post-interaction debriefs provide grounded feedback in protection motivation theory and reflective prompts to reinforce learning. In a controlled study with 846 Chinese undergraduates, ImmuniFraug was compared to official text-based materials. Linear Mixed-Effects Modeling (LMEM) reveals that the interactive intervention significantly improved fraud awareness (p = 0.026), successfully providing incremental learning value even when controlling for participants' extensive prior exposure to anti-fraud education, alongside high narrative immersion (M = 56.95/77). Thematic analysis of interviews revealed key effectiveness factors: perceived realism, adaptive deception, enforced time pressure, emotional manipulation awareness, and enhanced self-efficacy. Findings demonstrate that by shifting the focus from passive knowledge acquisition to active metacognitive engagement, LLM-based simulations offer a scalable and ecologically valid new paradigm for anti-fraud training and fostering fraud resilience.", "AI": {"tldr": "介绍了ImmuniFraug，一种基于大型语言模型的元认知干预方法，旨在提高大学生的网络欺诈意识。", "motivation": "传统反诈骗培训效果有限，而中国大学生在网络诈骗中的受害率上升。因此，需要开发更有效的培训方式来增强学生的防骗能力。", "method": "通过设计沉浸式的多模态欺骗场景和后续反馈环节，在846名中国本科生中进行了对比实验。这些场景模仿了现实生活中的说服技巧和心理压力，并在保护动机理论的基础上提供了反思性提示以加强学习效果。", "result": "线性混合效应模型显示，交互式干预显著提高了防骗意识（p=0.026），并具有较高的沉浸感（平均分为56.95/77）。主题分析表明，其有效性因素包括感知真实性、适应性欺骗、强制时间压力、情感操纵觉察和增强的自我效能。", "conclusion": "研究结果证明，通过从被动知识获取转向主动元认知参与，基于大型语言模型的模拟可以为反诈骗培训提供一种可扩展且生态有效的新的范式。"}}
{"id": "2601.06767", "pdf": "https://arxiv.org/pdf/2601.06767", "abs": "https://arxiv.org/abs/2601.06767", "authors": ["Shubhashis Roy Dipta", "Khairul Mahbub", "Nadia Najjar"], "title": "GanitLLM: Difficulty-Aware Bengali Mathematical Reasoning through Curriculum-GRPO", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We present a Bengali mathematical reasoning model called GanitLLM (named after the Bangla word for mathematics, \"Ganit\"), together with a new difficulty-aware Bengali math corpus and a curriculum-based GRPO pipeline. Bengali is one of the world's most widely spoken languages, yet existing LLMs either reason in English and then translate, or simply fail on multi-step Bengali math, in part because reinforcement learning recipes are tuned for high-resource languages and collapse under reward sparsity in low-resource settings. To address this, we construct Ganit, a rigorously filtered and decontaminated Bengali math dataset with automatic difficulty tags derived from the pass@k of a strong evaluator model. Building on this dataset, we propose Curriculum-GRPO, which combines multi-stage training (SFT + GRPO) with difficulty-aware sampling and verifiable rewards for format, numerical correctness, and Bengali reasoning. On Bn-MGSM and Bn-MSVAMP, GanitLLM-4B improves over its Qwen3-4B base by +8 and +7 accuracy points, respectively, while increasing the percentage of Bengali reasoning tokens from 14% to over 88% and reducing average solution length from 943 to 193 words.", "AI": {"tldr": "该论文提出了一种名为GanitLLM的难度感知孟加拉语数学推理模型，包括一个新难度标记的孟加拉语数学数据集和基于课程学习的GRPO流水线。", "motivation": "现有的大型语言模型要么在英语中进行推理然后翻译，要么直接对多步骤孟加拉语数学问题无法处理。这是因为强化学习方法针对的是高资源语言，在低资源场景下由于奖励稀疏性会崩溃。为了应对这一挑战，作者构建了一个难度标记的孟加拉语数学数据集，并提出了一个结合多阶段训练和难度感知采样的新方法。", "method": "通过建立难度标签的孟加拉语数学数据集Ganit，该论文提出了一种称为Curriculum-GRPO的新流水线，它将多阶段训练（SFT + GRPO）与难度感知采样、验证奖励相结合以改进格式正确性、数值准确性和孟加拉语推理。", "result": "在Bn-MGSM和Bn-MSVAMP数据集上，GanitLLM-4B模型比其基础模型Qwen3-4B分别提高了8个和7个百分点的准确性。同时增加了孟加拉语推理词的比例从14%增加到超过88%，并减少了平均解决方案长度至193字。", "conclusion": "该论文成功展示了如何通过难度感知采样和技术改进来提升大型语言模型在低资源语言上的数学推理能力，为未来研究提供了有价值的洞见和方法论。"}}
{"id": "2601.06758", "pdf": "https://arxiv.org/pdf/2601.06758", "abs": "https://arxiv.org/abs/2601.06758", "authors": ["Josh Li"], "title": "A Backpropagation-Free Feedback-Hebbian Network for Continual Learning Dynamics", "categories": ["cs.NE", "cs.LG"], "comment": "8 pages, 10 figures", "summary": "Feedback-rich neural architectures can regenerate earlier representations and inject temporal context, making them a natural setting for strictly local synaptic plasticity. We ask whether a minimal, backpropagation-free feedback--Hebbian system can already express interpretable continual-learning--relevant behaviors under controlled training schedules. We introduce a compact prediction--reconstruction architecture with two feedforward layers for supervised association learning and two dedicated feedback layers trained to reconstruct earlier activity and re-inject it as additive temporal context. All synapses are updated by a unified local rule combining centered Hebbian covariance, Oja-style stabilization, and a local supervised drive where targets are available, requiring no weight transport or global error backpropagation. On a small two-pair association task, we characterize learning through layer-wise activity snapshots, connectivity trajectories (row/column means of learned weights), and a normalized retention index across phases. Under sequential A->B training, forward output connectivity exhibits a long-term depression (LTD)-like suppression of the earlier association while feedback connectivity preserves an A-related trace during acquisition of B. Under deterministic interleaving A,B,A,B,..., both associations are concurrently maintained rather than sequentially suppressed. Architectural controls and rule-term ablations isolate the role of dedicated feedback in regeneration and co-maintenance, and the role of the local supervised term in output selectivity and unlearning. Together, the results show that a compact feedback pathway trained with local plasticity can support regeneration and continual-learning--relevant dynamics in a minimal, mechanistically transparent setting.", "AI": {"tldr": "研究提出了一种无需反向传播的反馈-海布网络，用于连续学习。", "motivation": "探讨在严格的局部突触可塑性条件下，反馈丰富的神经架构是否能够表现出与持续学习相关的可解释行为。", "method": "引入了一个包含两个前馈层和两个专用反馈层的小型预测重构架构。所有突触通过结合中心海布协方差、奥亚稳定化以及在有目标时的局部监督驱动进行更新，无需权重传输或全局误差反向传播。", "result": "在小型两对关联任务中，展示了学习过程，并通过分层活动快照、连接轨迹和保留指数表征了学习结果。该架构能够在不同的训练模式下支持再生以及持续学习相关的动态行为。", "conclusion": "结果显示了一个紧凑的反馈路径利用局部可塑性可以在最小化且机理透明的设置中支撑再生与持续学习相关的动力学。"}}
{"id": "2601.06757", "pdf": "https://arxiv.org/pdf/2601.06757", "abs": "https://arxiv.org/abs/2601.06757", "authors": ["Zheyuan Liu", "Dongwhi Kim", "Yixin Wan", "Xiangchi Yuan", "Zhaoxuan Tan", "Fengran Mo", "Meng Jiang"], "title": "MTMCS-Bench: Evaluating Contextual Safety of Multimodal Large Language Models in Multi-Turn Dialogues", "categories": ["cs.CL", "cs.AI"], "comment": "A benchmark of realistic images and multi-turn conversations that evaluates contextual safety in MLLMs under two complementary settings", "summary": "Multimodal large language models (MLLMs) are increasingly deployed as assistants that interact through text and images, making it crucial to evaluate contextual safety when risk depends on both the visual scene and the evolving dialogue. Existing contextual safety benchmarks are mostly single-turn and often miss how malicious intent can emerge gradually or how the same scene can support both benign and exploitative goals. We introduce the Multi-Turn Multimodal Contextual Safety Benchmark (MTMCS-Bench), a benchmark of realistic images and multi-turn conversations that evaluates contextual safety in MLLMs under two complementary settings, escalation-based risk and context-switch risk. MTMCS-Bench offers paired safe and unsafe dialogues with structured evaluation. It contains over 30 thousand multimodal (image+text) and unimodal (text-only) samples, with metrics that separately measure contextual intent recognition, safety-awareness on unsafe cases, and helpfulness on benign ones. Across eight open-source and seven proprietary MLLMs, we observe persistent trade-offs between contextual safety and utility, with models tending to either miss gradual risks or over-refuse benign dialogues. Finally, we evaluate five current guardrails and find that they mitigate some failures but do not fully resolve multi-turn contextual risks.", "AI": {"tldr": "评估多模态大语言模型在多轮对话中的上下文安全性", "motivation": "现有基准大多为单回合，且无法全面捕捉恶意意图的逐步形成或同一场景支持良性与有害目标的情况。需要一种新方法来更全面地评价MLLMs的安全性与实用性平衡问题。", "method": "引入MTMCS-Bench多轮对话安全评估基准，包含3万多个图像加文本和纯文本样本，用于评测上下文意图识别、对危险情况的认知以及在良性情境中的有用性。通过八个开源模型和七个专有模型测试其性能，并评价五种现行防护措施的效果。", "result": "观察到模型倾向于错过逐步风险或过度拒绝良性对话，在多轮上下文安全方面存在持续的权衡问题，虽然某些防护机制能缓解部分失败但未能彻底解决问题。", "conclusion": "提出MTMCS-Bench为评估MLLMs在复杂、动态情境下的安全性提供了新视角，并揭示了现有模型与防护措施的局限性。"}}
{"id": "2601.06750", "pdf": "https://arxiv.org/pdf/2601.06750", "abs": "https://arxiv.org/abs/2601.06750", "authors": ["Shaonan Liu", "Guo Yu", "Xiaoling Luo", "Shiyi Zheng", "Wenting Chen", "Jie Liu", "Linlin Shen"], "title": "Benchmarking Egocentric Clinical Intent Understanding Capability for Medical Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "16 pages, 4 figures", "summary": "Medical Multimodal Large Language Models (Med-MLLMs) require egocentric clinical intent understanding for real-world deployment, yet existing benchmarks fail to evaluate this critical capability. To address these challenges, we introduce MedGaze-Bench, the first benchmark leveraging clinician gaze as a Cognitive Cursor to assess intent understanding across surgery, emergency simulation, and diagnostic interpretation. Our benchmark addresses three fundamental challenges: visual homogeneity of anatomical structures, strict temporal-causal dependencies in clinical workflows, and implicit adherence to safety protocols. We propose a Three-Dimensional Clinical Intent Framework evaluating: (1) Spatial Intent: discriminating precise targets amid visual noise, (2) Temporal Intent: inferring causal rationale through retrospective and prospective reasoning, and (3) Standard Intent: verifying protocol compliance through safety checks. Beyond accuracy metrics, we introduce Trap QA mechanisms to stress-test clinical reliability by penalizing hallucinations and cognitive sycophancy. Experiments reveal current MLLMs struggle with egocentric intent due to over-reliance on global features, leading to fabricated observations and uncritical acceptance of invalid instructions.", "AI": {"tldr": "论文提出了MedGaze-Bench，一个使用临床医生的注视作为认知光标来评估医疗多模态大型语言模型在手术、急诊模拟和诊断解释中的意图理解能力的新基准。", "motivation": "现有的评估基准无法衡量医疗多模态大型语言模型（Med-MLLMs）的关键能力——基于第一人称视角的理解临床意图的能力，导致这些模型难以应用于真实世界场景中。因此提出了一个新的基准来解决这个问题。", "method": "该研究引入了MedGaze-Bench，一个通过医生的注视作为认知光标评估医疗多模态大型语言模型在手术、急诊模拟和诊断解释中的意图理解能力的基准，并提出了一种三维临床意图框架：空间意图（区分视觉噪音中的精确目标）、时间意图（基于回顾性和前瞻性推理推断因果理由）和标准意图（通过安全检查验证协议遵从性）。同时引入Trap QA机制来评估模型在真实临床情境下的可靠性和安全性。", "result": "实验结果显示当前的多模态语言模型难以准确理解第一人称视角中的临床意图，存在过度依赖全局特征的问题，并且容易产生虚构观察和对无效指令的盲从。", "conclusion": "论文通过MedGaze-Bench基准揭示了现有医疗多模态大型语言模型在处理基于第一人称视角的临床任务时所面临的挑战。未来的研究需要改进模型的设计以更好地理解复杂的第一人称视角中的意图，提高真实世界场景下的可靠性和安全性。"}}
{"id": "2601.06748", "pdf": "https://arxiv.org/pdf/2601.06748", "abs": "https://arxiv.org/abs/2601.06748", "authors": ["Changyu Liu", "Yiyang Liu", "Taowen Wang", "Qiao Zhuang", "James Chenhao Liang", "Wenhao Yang", "Renjing Xu", "Qifan Wang", "Dongfang Liu", "Cheng Han"], "title": "On-the-Fly VLA Adaptation via Test-Time Reinforcement Learning", "categories": ["cs.RO"], "comment": null, "summary": "Vision-Language-Action models have recently emerged as a powerful paradigm for general-purpose robot learning, enabling agents to map visual observations and natural-language instructions into executable robotic actions. Though popular, they are primarily trained via supervised fine-tuning or training-time reinforcement learning, requiring explicit fine-tuning phases, human interventions, or controlled data collection. Consequently, existing methods remain unsuitable for challenging simulated- or physical-world deployments, where robots must respond autonomously and flexibly to evolving environments. To address this limitation, we introduce a Test-Time Reinforcement Learning for VLAs (TT-VLA), a framework that enables on-the-fly policy adaptation during inference. TT-VLA formulates a dense reward mechanism that leverages step-by-step task-progress signals to refine action policies during test time while preserving the SFT/RL-trained priors, making it an effective supplement to current VLA models. Empirical results show that our approach enhances overall adaptability, stability, and task success in dynamic, previously unseen scenarios under simulated and real-world settings. We believe TT-VLA offers a principled step toward self-improving, deployment-ready VLAs.", "AI": {"tldr": "本文提出了一种在推理时通过测试时间强化学习进行视觉语言动作模型的即时策略调整的方法，以提高其在未知环境中的适应性和稳定性。", "motivation": "现有的视觉语言动作模型主要依赖于监督微调或训练时间的强化学习，在实际应用中需要人工干预或者特定数据集的支持，难以满足复杂多变的实际部署需求。因此，作者提出了在测试时通过强化学习即时调整策略的方法来克服这一限制。", "method": "本文提出了一种基于测试时间强化学习（TT-VLA）的技术框架，它利用逐步任务进展信号进行密集奖励机制，在推理过程中对视觉语言动作模型的动作策略进行即时优化，同时保留原有的监督微调或训练时间的强化学习结果。", "result": "实验结果显示，所提方法能够在模拟和现实世界的各种动态未知环境中提高视觉语言动作模型的整体适应性、稳定性和任务成功率。", "conclusion": "TT-VLA为实现自我改进并适用于实际部署的视觉语言动作模型提供了一个重要的基础步骤。"}}
{"id": "2601.06747", "pdf": "https://arxiv.org/pdf/2601.06747", "abs": "https://arxiv.org/abs/2601.06747", "authors": ["Glenn Matlin", "Akhil Theerthala", "Anant Gupta", "Anirudh JM", "Rayan Castilla", "Yi Mei Ng", "Sudheer Chava"], "title": "FinForge: Semi-Synthetic Financial Benchmark Generation", "categories": ["cs.AI"], "comment": "AAAI 2026 Workshop on Agentic AI in Financial Services", "summary": "Evaluating Language Models (LMs) in specialized, high-stakes domains such as finance remains a significant challenge due to the scarcity of open, high-quality, and domain-specific datasets. Existing general-purpose benchmarks provide broad coverage but lack the depth and domain fidelity needed to assess LMs' capabilities for real-world financial reasoning, which requires both conceptual understanding and quantitative rigor. To address this gap, we introduce FinForge, a scalable, semi-synthetic pipeline for constructing finance-specific evaluation benchmarks through a hybrid of expert-guided data curation and controlled LM-based synthesis. FinForge combines manual and programmatic corpus construction from authoritative financial sources with structured question generation and validation using Gemini 2.5 Flash. To demonstrate the pipeline's efficacy, we produce FinForge-5k, a snapshot benchmark comprising over 5,000 human-validated question-answer pairs across 11 finance subdomains, derived from a curated corpus of 100,000 verified documents totaling 143M tokens. Evaluation of state-of-the-art open-source and closed-source models on FinForge-5k reveals significant differences in financial reasoning, with leading models achieving accuracy levels near 80%. These findings underscore the framework's utility for diagnosing current model limitations and guiding future improvements in financial domain competence. All code and data are available at https://github.com/gtfintechlab/FinForge.", "AI": {"tldr": "该论文提出了一种名为FinForge的半合成金融基准生成方法，用于评估语言模型在特定领域的表现。", "motivation": "现有的通用基准测试缺乏深度和领域专一性，无法全面评估语言模型在实际金融市场中的推理能力。因此需要创建一个专用的、高质量的数据集来填补这一空白。", "method": "FinForge通过结合权威金融资源的人工汇编与程序化构建，以及使用Gemini 2.5 Flash进行结构化问题生成和验证的混合方法来创造半合成数据集。", "result": "该团队利用FinForge创建了包含超过5000个经人工校验的问题答案对的数据集，并展示了最先进模型在这一新基准上的表现差异，其中顶级模型达到了近80%的准确率。", "conclusion": "FinForge框架被证明有助于诊断现有模型中的局限性，并为未来提升语言模型金融领域的能力提供了指导。"}}
{"id": "2601.06737", "pdf": "https://arxiv.org/pdf/2601.06737", "abs": "https://arxiv.org/abs/2601.06737", "authors": ["Anay Sinhal", "Arpana Sinhal", "Amit Sinhal", "Amit Hirawat"], "title": "Algorithmic Reductions: Network Flow and NP-Completeness in Real-World Scheduling Problems", "categories": ["cs.DS"], "comment": null, "summary": "This paper presents two real-world scheduling problems and their algorithmic solutions through polynomial-time reductions. First, we address the Hospital Patient-to-Bed Assignment problem, demonstrating its reduction to Maximum Bipartite Matching and solution via Network Flow algorithms. Second, we tackle the University Course Scheduling problem, proving its NP-Completeness through reduction from Graph Coloring and providing greedy approximation algorithms. Both problems are implemented in Python, with experimental results validating theoretical complexity analyses. Our Network Flow solution achieves O(n2.51) empirical complexity, while the greedy coloring algorithms demonstrate O(n2) behavior with approximation ratios consistently below the theoretical delta + 1 bound.", "AI": {"tldr": "论文研究了医院病人床位分配和大学课程排课两个实际调度问题，并通过多项式时间归约将其转化为可解的问题，给出了网络流算法和贪心近似算法。", "motivation": "通过对医院病人床位分配和大学课程排课问题的研究，展示如何利用图论中的经典问题来解决现实世界中复杂的调度问题。", "method": "第一个问题是通过最大二部匹配归约为网络流问题并用网络流算法求解；第二个问题则证明了其NP完全性，并提供了近似算法。", "result": "网络流解决方案在实验中实现了O(n2.51)的时间复杂度，而贪心着色算法展示了O(n2)的行为和理论逼近比值以下的性能。", "conclusion": "研究结果验证了所提出的算法的有效性和理论分析的一致性。"}}
{"id": "2601.06733", "pdf": "https://arxiv.org/pdf/2601.06733", "abs": "https://arxiv.org/abs/2601.06733", "authors": ["Tamara Alshammari", "Mehdi Bennis"], "title": "Logic-Driven Semantic Communication for Resilient Multi-Agent Systems", "categories": ["cs.MA", "cs.AI", "cs.LG", "cs.LO"], "comment": null, "summary": "The advent of 6G networks is accelerating autonomy and intelligence in large-scale, decentralized multi-agent systems (MAS). While this evolution enables adaptive behavior, it also heightens vulnerability to stressors such as environmental changes and adversarial behavior. Existing literature on resilience in decentralized MAS largely focuses on isolated aspects, such as fault tolerance, without offering a principled unified definition of multi-agent resilience. This gap limits the ability to design systems that can continuously sense, adapt, and recover under dynamic conditions. This article proposes a formal definition of MAS resilience grounded in two complementary dimensions: epistemic resilience, wherein agents recover and sustain accurate knowledge of the environment, and action resilience, wherein agents leverage that knowledge to coordinate and sustain goals under disruptions. We formalize resilience via temporal epistemic logic and quantify it using recoverability time (how quickly desired properties are re-established after a disturbance) and durability time (how long accurate beliefs and goal-directed behavior are sustained after recovery). We design an agent architecture and develop decentralized algorithms to achieve both epistemic and action resilience. We provide formal verification guarantees, showing that our specifications are sound with respect to the metric bounds and admit finite-horizon verification, enabling design-time certification and lightweight runtime monitoring. Through a case study on distributed multi-agent decision-making under stressors, we show that our approach outperforms baseline methods. Our formal verification analysis and simulation results highlight that the proposed framework enables resilient, knowledge-driven decision-making and sustained operation, laying the groundwork for resilient decentralized MAS in next-generation communication systems.", "AI": {"tldr": "提出了基于时态知识逻辑的多智能体系统韧性定义及算法，以实现环境感知和目标协调下的持续操作。", "motivation": "现有研究缺乏统一的多智能体系统韧性定义，导致难以设计在动态条件下能够持续感应、适应和恢复的系统。", "method": "通过时态知识逻辑形式化韧性，并使用可恢复时间和耐用时间量化。设计了代理架构并开发了去中心化的算法以实现知觉韧性和行动韧性。", "result": "案例研究显示，所提出的方法优于基线方法，在应激条件下实现了更优的知识驱动决策和持续运行性能。", "conclusion": "该框架为下一代通信系统中的稳健分散多智能体系统的知识驱动决策和持续操作奠定了基础。"}}
{"id": "2601.06730", "pdf": "https://arxiv.org/pdf/2601.06730", "abs": "https://arxiv.org/abs/2601.06730", "authors": ["Harsh Parikh"], "title": "Why are there many equally good models? An Anatomy of the Rashomon Effect", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "comment": ":I.2.6", "summary": "The Rashomon effect -- the existence of multiple, distinct models that achieve nearly equivalent predictive performance -- has emerged as a fundamental phenomenon in modern machine learning and statistics. In this paper, we explore the causes underlying the Rashomon effect, organizing them into three categories: statistical sources arising from finite samples and noise in the data-generating process; structural sources arising from non-convexity of optimization objectives and unobserved variables that create fundamental non-identifiability; and procedural sources arising from limitations of optimization algorithms and deliberate restrictions to suboptimal model classes. We synthesize insights from machine learning, statistics, and optimization literature to provide a unified framework for understanding why the multiplicity of good models arises. A key distinction emerges: statistical multiplicity diminishes with more data, structural multiplicity persists asymptotically and cannot be resolved without different data or additional assumptions, and procedural multiplicity reflects choices made by practitioners. Beyond characterizing causes, we discuss both the challenges and opportunities presented by the Rashomon effect, including implications for inference, interpretability, fairness, and decision-making under uncertainty.", "AI": {"tldr": "探讨造成机器学习中多个模型性能几乎相等的原因并提供统一框架。", "motivation": "解析导致存在多个预测性能相当的模型的现象，即拉什莫效应背后的根本原因。", "method": "将多模性来源划分为统计、结构和程序三个类别，并综合相关领域的知识来理解问题。", "result": "区分了不同类型下的多重好模型情况并讨论其挑战与机遇", "conclusion": "通过深入分析拉什莫效应的根源，提出了解决策略以及对未来研究方向的展望"}}
{"id": "2601.06728", "pdf": "https://arxiv.org/pdf/2601.06728", "abs": "https://arxiv.org/abs/2601.06728", "authors": ["Minhyuk Park", "Aloysius K. Mok", "Tsz-Chiu Au"], "title": "Robust Evacuation for Multi-Drone Failure in Drone Light Shows", "categories": ["cs.RO"], "comment": "Accepted to AAAI-26 Bridge Program B10: Making Embodied AI Reliable with Testing and Formal Verification", "summary": "Drone light shows have emerged as a popular form of entertainment in recent years. However, several high-profile incidents involving large-scale drone failures -- where multiple drones simultaneously fall from the sky -- have raised safety and reliability concerns. To ensure robustness, we propose a drone parking algorithm designed specifically for multiple drone failures in drone light shows, aimed at mitigating the risk of cascading collisions by drone evacuation and enabling rapid recovery from failures by leveraging strategically placed hidden drones. Our algorithm integrates a Social LSTM model with attention mechanisms to predict the trajectories of failing drones and compute near-optimal evacuation paths that minimize the likelihood of surviving drones being hit by fallen drones. In the recovery node, our system deploys hidden drones (operating with their LED lights turned off) to replace failed drones so that the drone light show can continue. Our experiments showed that our approach can greatly increase the robustness of a multi-drone system by leveraging deep learning to predict the trajectories of fallen drones.", "AI": {"tldr": "本文提出了一个无人机停车场算法，用于多无人机故障情况下的疏散和快速恢复。", "motivation": "近年来，无人机灯光秀成为一种流行的娱乐方式。但是，由于大规模无人机故障导致的安全性和可靠性问题日益凸显，需要提出解决方案来提高系统的鲁棒性。", "method": "该算法结合了社交LSTM模型和注意力机制，用于预测故障无人机的轨迹，并计算出最小化幸存无人机被坠落无人机击中的概率的疏散路径。在恢复阶段，系统会部署隐藏无人机（关闭LED灯）以替换故障无人机。", "result": "实验表明，此方法能够显著提高多无人机系统的鲁棒性，通过深度学习预测坠落无人机的轨迹。", "conclusion": "本文提出的算法可以有效解决无人机灯光秀中因多无人机同时失效而导致的安全问题，并提供了一种新的解决方案来确保娱乐活动的安全和可靠性。"}}
{"id": "2601.06726", "pdf": "https://arxiv.org/pdf/2601.06726", "abs": "https://arxiv.org/abs/2601.06726", "authors": ["Mohammad Khateri", "Morteza Ghahremani", "Sergio Valencia", "Camilo Jaimes", "Alejandra Sierra", "Jussi Tohka", "P. Ellen Grant", "Davood Karimi"], "title": "USFetal: Tools for Fetal Brain Ultrasound Compounding", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Ultrasound offers a safe, cost-effective, and widely accessible technology for fetal brain imaging, making it especially suitable for routine clinical use. However, it suffers from view-dependent artifacts, operator variability, and a limited field of view, which make interpretation and quantitative evaluation challenging. Ultrasound compounding aims to overcome these limitations by integrating complementary information from multiple 3D acquisitions into a single, coherent volumetric representation. This work provides four main contributions: (1) We present the first systematic categorization of computational strategies for fetal brain ultrasound compounding, including both classical techniques and modern learning-based frameworks. (2) We implement and compare representative methods across four key categories - multi-scale, transformation-based, variational, and deep learning approaches - emphasizing their core principles and practical advantages. (3) Motivated by the lack of full-view, artifact-free ground truth required for supervised learning, we focus on unsupervised and self-supervised strategies and introduce two new deep learning based approaches: a self-supervised compounding framework and an adaptation of unsupervised deep plug-and-play priors for compounding. (4) We conduct a comprehensive evaluation on ten multi-view fetal brain ultrasound datasets, using both expert radiologist scoring and standard quantitative image-quality metrics. We also release the USFetal Compounding Toolbox, publicly available to support benchmarking and future research. Keywords: Ultrasound compounding, fetal brain, deep learning, self-supervised, unsupervised.", "AI": {"tldr": "论文提出了胎儿大脑超声合成工具USFetal，并通过四种主要贡献改进了该领域。", "motivation": "为了克服胎儿脑部超声成像的局限性，如视角依赖性伪影、操作者变异性以及有限视场，引入了一种将多3D采集中的互补信息整合为单一、连贯体积表示的技术——超声合成。", "method": "论文系统地分类了计算策略，并实现了四种关键类别方法：多尺度、转换基、变分和深度学习方法。特别关注无监督和自我监督策略，提出了两个新的基于深度学习的方法：一种自监督合成框架以及一个用于合成的无监督深插拔与播放先验模型。", "result": "论文通过专家放射科评分和标准定量图像质量指标对十个多视角胎儿脑部超声数据集进行了全面评估。USFetal Compounding Toolbox已公开发布，以支持基准测试和未来研究。", "conclusion": "本文的贡献在于提供了第一个系统化的胎儿大脑超声合成方法分类，并引入了新的自监督与无监督学习框架来克服现有局限性，从而推动该领域的技术进步。"}}
{"id": "2601.06725", "pdf": "https://arxiv.org/pdf/2601.06725", "abs": "https://arxiv.org/abs/2601.06725", "authors": ["Mahsa Mitcheff", "Adam Czajka"], "title": "When Humans Judge Irises: Pupil Size Normalization as an Aid and Synthetic Irises as a Challenge", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Iris recognition is a mature biometric technology offering remarkable precision and speed, and allowing for large-scale deployments to populations exceeding a billion enrolled users (e.g., AADHAAR in India). However, in forensic applications, a human expert may be needed to review and confirm a positive identification before an iris matching result can be presented as evidence in court, especially in cases where processed samples are degraded (e.g., in post-mortem cases) or where there is a need to judge whether the sample is authentic, rather than a result of a presentation attack. This paper presents a study that examines human performance in iris verification in two controlled scenarios: (a) under varying pupil sizes, with and without a linear/nonlinear alignment of the pupil size between compared images, and (b) when both genuine and impostor iris image pairs are synthetically generated. The results demonstrate that pupil size normalization carried out by a modern autoencoder-based identity-preserving image-to-image translation model significantly improves verification accuracy. Participants were also able to determine whether iris pairs corresponded to the same or different eyes when both images were either authentic or synthetic. However, accuracy declined when subjects were comparing authentic irises against high-quality, same-eye synthetic counterparts. These findings (a) demonstrate the importance of pupil-size alignment for iris matching tasks in which humans are involved, and (b) indicate that despite the high fidelity of modern generative models, same-eye synthetic iris images are more often judged by humans as different-eye images, compared to same-eye authentic image pairs. We offer data and human judgments along with this paper to allow full replicability of this study and future works.", "AI": {"tldr": "研究探讨了人类在不同虹膜样本对比中的判断能力，特别是在瞳孔大小差异和合成虹膜图像的情况下。", "motivation": "为了提升法医应用中虹膜识别的准确性，研究人类专家如何评估虹膜匹配结果，并且测试瞳孔大小标准化对虹膜验证准确性的改善效果。", "method": "通过对比具有不同瞳孔尺寸的真实虹膜样本和合成虹膜图像对，分析人在进行虹膜身份验证时的表现。同时采用了现代自编码器模型来执行瞳孔大小的线性/非线性调整。", "result": "结果显示，使用自动编码器进行的瞳孔大小标准化显著提升了虹膜识别的准确性。然而，在真伪虹膜对比中人的判断准确率有所下降。", "conclusion": "研究证明了瞳孔大小对人类参与的虹膜匹配任务的重要性，并指出尽管现代生成模型具有高保真度，但同源的人工合成虹膜图像仍常常被误判为不同来源。"}}
{"id": "2601.06723", "pdf": "https://arxiv.org/pdf/2601.06723", "abs": "https://arxiv.org/abs/2601.06723", "authors": ["Lisa Hellerstein", "Benedikt M. Plank", "Kevin Schewior"], "title": "Approximating Matroid Basis Testing for Partition Matroids using Budget-In-Expectation", "categories": ["cs.DS"], "comment": "Full version of SODA 2026 paper", "summary": "We consider the following Stochastic Boolean Function Evaluation problem, which is closely related to several problems from the literature. A matroid $\\mathcal{M}$ (in compact representation) on ground set $E$ is given, and each element $i\\in E$ is active independently with known probability $p_i\\in(0,1)$. The elements can be queried, upon which it is revealed whether the respective element is active or not. The goal is to find an adaptive querying strategy for determining whether there is a basis of $\\mathcal{M}$ in which all elements are active, with the objective of minimizing the expected number of queries. When $\\mathcal{M}$ is a uniform matroid, this is the problem of evaluating a $k$-of-$n$ function, first studied in the 1970s. This problem is well-understood, and has an optimal adaptive strategy that can be computed in polynomial time. Taking $\\mathcal{M}$ to instead be a partition matroid, we show that previous approaches fail to give a constant-factor approximation. Our main result is a polynomial-time constant-factor approximation algorithm producing a randomized strategy for this partition matroid problem. We obtain this result by combining a new technique with several well-established techniques. Our algorithm adaptively interleaves solutions to several instances of a novel type of stochastic querying problem, with a constraint on the $\\textit{expected}$ cost. We believe that this type of problem is of independent interest, will spark follow-up work, and has the potential for additional applications.", "AI": {"tldr": "研究如何在预算期望下的划分拟阵中近似寻找活跃基的任务。", "motivation": "解决划分拟阵中的活跃基检测问题，提出一种适应性查询策略以最小化预期查询次数。", "method": "结合新旧技术设计了一种随机算法来处理预算期望约束的新型查询问题，并且将该方法应用于多个实例中进行相互交织求解。", "result": "开发出一个多项式时间内的常数因子近似算法，适用于划分拟阵中的活跃基检测问题。", "conclusion": "所提出的算法可有效解决具有预期成本限制的随机查询问题，在划分拟阵中找到活跃基方面取得了进展，并认为此类型的问题有进一步研究的价值和潜在的应用前景。"}}
{"id": "2601.06706", "pdf": "https://arxiv.org/pdf/2601.06706", "abs": "https://arxiv.org/abs/2601.06706", "authors": ["Bharadwaj Veeravalli"], "title": "Resource-Aware Task Allocator Design: Insights and Recommendations for Distributed Satellite Constellations", "categories": ["cs.DC", "cs.ET"], "comment": null, "summary": "We present the design of a Resource-Aware Task Allocator (RATA) and an empirical analysis in handling real-time tasks for processing on Distributed Satellite Systems (DSS). We consider task processing performance across low Earth orbit (LEO) to Low-Medium Earth Orbit (Low-MEO) constellation sizes, under varying traffic loads. Using Single-Level Tree Network(SLTN)-based cooperative task allocation architecture, we attempt to evaluate some key performance metrics - blocking probabilities, response times, energy consumption, and resource utilization across several tens of thousands of tasks per experiment. Our resource-conscious RATA monitors key parameters such as arrival rate, resources (on-board compute, storage, bandwidth, battery) availability, satellite eclipses' influence in processing and communications. This study is an important step towards analyzing the performance under lighter to stress inducing levels of compute intense workloads to test the ultimate performance limits under the combined influence of the above-mentioned factors. Results show pronounced non-linear scaling: while capacity increases with constellation size, blocking and delay grow rapidly, whereas energy remains resilient under solar-aware scheduling. The analysis identifies a practical satellite-count limit for baseline SLTNs and demonstrates that CPU availability, rather than energy, is the primary cause of blocking. These findings provide quantitative guidance by identifying thresholds at which system performance shifts from graceful degradation to collapse.", "AI": {"tldr": "设计一种资源感知的任务分配器RATA，用于分布式卫星系统中的实时任务处理。", "motivation": "分析分布式卫星系统的实际任务性能，特别是在不同的轨道高度和流量负载下的表现，并找出影响性能的关键因素。", "method": "使用基于单一层次树网络(SLTN)的协作任务分配架构进行实验，监测关键参数如到达率、资源可用性等，并通过大量任务实验来评估系统性能指标。", "result": "发现随着卫星星座规模增加，容量会提高但阻塞和延迟也会迅速增长；能源消耗在太阳感知调度下较为稳定。研究确定了基线SLTN的实用卫星数量限制，并表明CPU可用性是造成阻塞的主要原因。", "conclusion": "该研究提供了关于系统性能从渐近退化到崩溃转变的量化指导阈值，强调了计算资源的重要性。"}}
{"id": "2601.06704", "pdf": "https://arxiv.org/pdf/2601.06704", "abs": "https://arxiv.org/abs/2601.06704", "authors": ["Dushan N. Wadduwage", "Dineth Jayakody", "Leonidas Zimianitis"], "title": "Beyond Perfect Scores: Proof-by-Contradiction for Trustworthy Machine Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "13 pages, 6 figures", "summary": "Machine learning (ML) models show strong promise for new biomedical prediction tasks, but concerns about trustworthiness have hindered their clinical adoption. In particular, it is often unclear whether a model relies on true clinical cues or on spurious hierarchical correlations in the data. This paper introduces a simple yet broadly applicable trustworthiness test grounded in stochastic proof-by-contradiction. Instead of just showing high test performance, our approach trains and tests on spurious labels carefully permuted based on a potential outcomes framework. A truly trustworthy model should fail under such label permutation; comparable accuracy across real and permuted labels indicates overfitting, shortcut learning, or data leakage. Our approach quantifies this behavior through interpretable Fisher-style p-values, which are well understood by domain experts across medical and life sciences. We evaluate our approach on multiple new bacterial diagnostics to separate tasks and models learning genuine causal relationships from those driven by dataset artifacts or statistical coincidences. Our work establishes a foundation to build rigor and trust between ML and life-science research communities, moving ML models one step closer to clinical adoption.", "AI": {"tldr": "本文介绍了一种基于概率证明反驳的简单且广泛应用的信任测试方法，旨在解决机器学习模型在生物医学预测任务中的可信度问题。", "motivation": "由于对机器学习模型信赖度的担忧影响了其临床应用，该研究提出了一个以潜在结果框架为基础的方法来评估模型是否依赖于真正的临床线索或数据中虚假的相关性。", "method": "通过训练和测试基于潜在结果框架精心排列的虚假标签的数据集，这种方法能够揭示出真正可信的模型在标签排列变化下的表现差异。比较真实的标签和排列后的标签下模型的表现一致情况可以判断是否存在过拟合、捷径学习或数据泄漏。", "result": "该方法通过费雪风格的P值来量化这种行为，并对其进行了多组细菌诊断任务中的新案例验证，成功区分了那些基于因果关系的真实学习模型与被数据集特征或统计巧合驱动的学习模型。", "conclusion": "本文提出的方法为机器学习和生命科学研究社区之间的严谨性和信任建立了基础，使机器学习模型更接近临床应用。"}}
{"id": "2601.06701", "pdf": "https://arxiv.org/pdf/2601.06701", "abs": "https://arxiv.org/abs/2601.06701", "authors": ["Poushali Sengupta", "Rabindra Khadka", "Sabita Maharjan", "Frank Eliassen", "Yan Zhang", "Shashi Raj Pandey", "Pedro G. Lind", "Anis Yazidi"], "title": "Explainability of Complex AI Models with Correlation Impact Ratio", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": null, "summary": "Complex AI systems make better predictions but often lack transparency, limiting trustworthiness, interpretability, and safe deployment. Common post hoc AI explainers, such as LIME, SHAP, HSIC, and SAGE, are model agnostic but are too restricted in one significant regard: they tend to misrank correlated features and require costly perturbations, which do not scale to high dimensional data. We introduce ExCIR (Explainability through Correlation Impact Ratio), a theoretically grounded, simple, and reliable metric for explaining the contribution of input features to model outputs, which remains stable and consistent under noise and sampling variations. We demonstrate that ExCIR captures dependencies arising from correlated features through a lightweight single pass formulation. Experimental evaluations on diverse datasets, including EEG, synthetic vehicular data, Digits, and Cats-Dogs, validate the effectiveness and stability of ExCIR across domains, achieving more interpretable feature explanations than existing methods while remaining computationally efficient. To this end, we further extend ExCIR with an information theoretic foundation that unifies the correlation ratio with Canonical Correlation Analysis under mutual information bounds, enabling multi output and class conditioned explainability at scale.", "AI": {"tldr": "通过引入ExCIR（基于相关影响比率的可解释性），该论文旨在提高复杂AI模型的透明度和可靠性。", "motivation": "复杂的AI系统虽然提高了预测准确性，但缺乏透明度限制了信任、解释性和安全部署。现有的事后解释器如LIME、SHAP等方法在处理高维数据时存在局限性，且无法准确排名相关特征。", "method": "ExCIR是一种理论基础坚实、简单可靠的指标，用于评估输入特征对模型输出的贡献，并通过轻量级单次遍历捕捉依赖关系。此外，还扩展了信息论基础，将相关比率与典范相关分析统一在互信息约束下。", "result": "实验显示，ExCIR在不同数据集上（包括EEG、合成车辆数据等）有效且稳定，比现有方法更具有解释性和计算效率。", "conclusion": "通过引入ExCIR，论文为复杂AI模型提供了有效的可解释性工具，从而提高了透明度和可靠性。"}}
{"id": "2601.06700", "pdf": "https://arxiv.org/pdf/2601.06700", "abs": "https://arxiv.org/abs/2601.06700", "authors": ["Zhiyao Zhang", "Yazan Mash'Al", "Yuhan Wu"], "title": "Characterising Toxicity in Generative Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In recent years, the advent of the attention mechanism has significantly advanced the field of natural language processing (NLP), revolutionizing text processing and text generation. This has come about through transformer-based decoder-only architectures, which have become ubiquitous in NLP due to their impressive text processing and generation capabilities. Despite these breakthroughs, language models (LMs) remain susceptible to generating undesired outputs: inappropriate, offensive, or otherwise harmful responses. We will collectively refer to these as ``toxic'' outputs. Although methods like reinforcement learning from human feedback (RLHF) have been developed to align model outputs with human values, these safeguards can often be circumvented through carefully crafted prompts. Therefore, this paper examines the extent to which LLMs generate toxic content when prompted, as well as the linguistic factors -- both lexical and syntactic -- that influence the production of such outputs in generative models.", "AI": {"tldr": "研究大型语言模型生成有毒内容的程度及影响因素", "motivation": "探讨LLM在特定提示下生成有害输出的现象及其背后的语言学原因", "method": "分析LLMs在不同提示下的反应，探究词汇和句法对有害输出的影响", "result": "识别了可能诱发有害输出的特定词汇与句式特征", "conclusion": "揭示了大型语言模型有毒内容产生的机制，并提出改进方向"}}
{"id": "2601.06677", "pdf": "https://arxiv.org/pdf/2601.06677", "abs": "https://arxiv.org/abs/2601.06677", "authors": ["Zohaib Khan", "Omer Tafveez", "Zoha Hayat Bhatti"], "title": "Plasticity vs. Rigidity: The Impact of Low-Rank Adapters on Reasoning on a Micro-Budget", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 4 figures, 2 tables", "summary": "Recent advances in mathematical reasoning typically rely on massive scale, yet the question remains: can strong reasoning capabilities be induced in small language models ($\\leq1.5\\text{B}$) under extreme constraints? We investigate this by training models on a single A40 GPU (48GB) for under 24 hours using Reinforcement Learning with Verifiable Rewards (RLVR) and Low-Rank Adaptation (LoRA). We find that the success of this ``micro-budget\" regime depends critically on the interplay between adapter capacity and model initialization. While low-rank adapters ($r=8$) consistently fail to capture the complex optimization dynamics of reasoning, high-rank adapters ($r=256$) unlock significant plasticity in standard instruction-tuned models. Our best result achieved an impressive 40.0\\% Pass@1 on AIME 24 (an 11.1\\% absolute improvement over baseline) and pushed Pass@16 to 70.0\\%, demonstrating robust exploration capabilities. However, this plasticity is not universal: while instruction-tuned models utilized the budget to elongate their chain-of-thought and maximize reward, heavily math-aligned models suffered performance collapse, suggesting that noisy, low-budget RL updates can act as destructive interference for models already residing near a task-specific optimum.", "AI": {"tldr": "研究在微预算下，通过低秩适配器和强化学习验证奖励来提升小型语言模型的数学推理能力。", "motivation": "探索是否能够在极端约束条件下（如使用单个A40 GPU）训练出具有强推理能力的小型语言模型。", "method": "采用强化学习结合可验证奖励机制（RLVR）和低秩适配器（LoRA），在单张A40 GPU上对小型语言模型进行微预算下的训练。", "result": "高秩适配器（r=256）显著提高了推理性能，达到40.0%的Pass@1和70.0%的Pass@16；而低秩适配器（r=8）未能有效捕捉复杂优化动态。不同初始化模型对预算利用方式不同。", "conclusion": "高秩适配器在微预算下能够解锁语言模型的学习能力，但这种增强并非普遍适用，已接近最优任务特定点的模型可能遭受性能下降。"}}
{"id": "2601.06676", "pdf": "https://arxiv.org/pdf/2601.06676", "abs": "https://arxiv.org/abs/2601.06676", "authors": ["Yingchaojie Feng", "Qiang Huang", "Xiaoya Xie", "Zhaorui Yang", "Jun Yu", "Wei Chen", "Anthony K. H. Tung"], "title": "IDRBench: Interactive Deep Research Benchmark", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "Deep research agents powered by Large Language Models (LLMs) can perform multi-step reasoning, web exploration, and long-form report generation. However, most existing systems operate in an autonomous manner, assuming fully specified user intent and evaluating only final outputs. In practice, research goals are often underspecified and evolve during exploration, making sustained interaction essential for robust alignment. Despite its importance, interaction remains largely invisible to existing deep research benchmarks, which neither model dynamic user feedback nor quantify its costs. We introduce IDRBench, the first benchmark for systematically evaluating interactive deep research. IDRBench combines a modular multi-agent research framework with on-demand interaction, a scalable reference-grounded user simulator, and an interaction-aware evaluation suite that jointly measures interaction benefits (quality and alignment) and costs (turns and tokens). Experiments across seven state-of-the-art LLMs show that interaction consistently improves research quality and robustness, often outweighing differences in model capacity, while revealing substantial trade-offs in interaction efficiency.", "AI": {"tldr": "IDRBench是一个用于评估交互式深度研究系统的基准，它结合了多代理框架、可互动模拟器和评价套件。", "motivation": "现有的深度研究系统大多以自主方式运行，不考虑用户意图的动态变化和持续互动的重要性。因此，需要一个能够衡量互动效益与成本的新基准来弥补这一空白。", "method": "IDRBench通过引入模块化多代理框架、可按需互动模拟器以及交互感知评价套件来系统地评估交互式深度研究。", "result": "实验表明，在七个最先进的LLM上，互动一致提高了研究质量与鲁棒性，并揭示了在互动效率方面的显著权衡。", "conclusion": "IDRBench是第一个用于评估交互式深度研究系统的基准，证明了互动在提升研究质量和鲁棒性方面的重要性。"}}
{"id": "2601.06673", "pdf": "https://arxiv.org/pdf/2601.06673", "abs": "https://arxiv.org/abs/2601.06673", "authors": ["Sanjay Pradeep", "Chen Wang", "Matthew M. Dahm", "Jeff D. Eldredge", "Candace S. J. Tsai"], "title": "Quantification and Classification of Carbon Nanotubes in Electron Micrographs using Vision Foundation Models", "categories": ["cs.CV"], "comment": null, "summary": "Accurate characterization of carbon nanotube morphologies in electron microscopy images is vital for exposure assessment and toxicological studies, yet current workflows rely on slow, subjective manual segmentation. This work presents a unified framework leveraging vision foundation models to automate the quantification and classification of CNTs in electron microscopy images. First, we introduce an interactive quantification tool built on the Segment Anything Model (SAM) that segments particles with near-perfect accuracy using minimal user input. Second, we propose a novel classification pipeline that utilizes these segmentation masks to spatially constrain a DINOv2 vision transformer, extracting features exclusively from particle regions while suppressing background noise. Evaluated on a dataset of 1,800 TEM images, this architecture achieves 95.5% accuracy in distinguishing between four different CNT morphologies, significantly outperforming the current baseline despite using a fraction of the training data. Crucially, this instance-level processing allows the framework to resolve mixed samples, correctly classifying distinct particle types co-existing within a single field of view. These results demonstrate that integrating zero-shot segmentation with self-supervised feature learning enables high-throughput, reproducible nanomaterial analysis, transforming a labor-intensive bottleneck into a scalable, data-driven process.", "AI": {"tldr": "本文提出了一种结合视觉基础模型的框架，用于电子显微镜图像中碳纳米管的自动化量化和分类。", "motivation": "准确表征电镜图像中的碳纳米管形态对于暴露评估和毒理学研究至关重要，但当前工作流程依赖于缓慢且主观的手动分割。", "method": "利用Segment Anything Model（SAM）构建了一个交互式量化工具，并提出了一种新的分类管道，结合DINOv2视觉变压器，从粒子区域提取特征以抑制背景噪声。", "result": "在1800张TEM图像的测试中，该架构实现了95.5%的准确性，在区分四种不同碳纳米管形态方面显著优于现有基线方法。", "conclusion": "结果表明，结合零样本分割与自监督特征学习可以实现高通量、可重复性的纳米材料分析，将一个劳动密集型瓶颈转变为一种可扩展的数据驱动过程。"}}
{"id": "2601.06670", "pdf": "https://arxiv.org/pdf/2601.06670", "abs": "https://arxiv.org/abs/2601.06670", "authors": ["Francisco Glaubos Nunes Clímaco", "Jorge Lucas Silva Cavalcante"], "title": "Otimizando A Alocação De Salas De Aula Com Foco Na Acessibilidade Para Pessoas Com Deficiência", "categories": ["cs.CY", "cs.AI"], "comment": "in Portuguese language", "summary": "This paper addresses the challenge of classroom allocation in higher education institutions, with an explicit emphasis on accessibility for Persons with Disabilities (PwDs). Employing a case study of a university's computer science department, the paper proposes an Integer Linear Programming (ILP)-based optimization model, which is solved using the Gurobi solver. The objective is to minimize the number of classrooms used by prioritizing the assignment of PwD students to ground-floor classrooms to reduce accessibility barriers. The model is calibrated with a weighting parameter, alpha, that allows for a balance between spatial efficiency and promoting accessibility. Experimental results indicate that adjusting alpha can achieve a balance point that significantly improves current manual allocation practices, reducing the number of classrooms required and accessibility penalties. The findings suggest that optimization methods can improve operational efficiency in academic institutions while promoting a more inclusive environment for all students. Future work may expand the application of the model to other departments and contexts and integrate additional criteria to develop a more holistic approach.", "AI": {"tldr": "本文提出了一种基于整数线性规划的教室分配优化模型，以提高高等教育机构中残疾学生的可访问性和空间效率。", "motivation": "在高等教育机构中优化教室分配，特别是为了增强残疾人学生的无障碍环境", "method": "采用一个案例研究来制定基于ILP（整数线性规划）的模型，并使用Gurobi求解器解决该问题。通过调整参数α来平衡空间效率和可访问性的促进。", "result": "实验结果表明，根据需要可以找到最佳的平衡点，在减少教室数量的同时降低无障碍障碍，比现行的手动分配方法有显著改进", "conclusion": "优化方法可以在提高学术机构运营效率的同时推广更包容的学习环境。未来的研究将扩展模型应用到其他部门和情境，并整合更多标准以实现更加全面的方法"}}
{"id": "2601.06666", "pdf": "https://arxiv.org/pdf/2601.06666", "abs": "https://arxiv.org/abs/2601.06666", "authors": ["Yuzhuo Bai", "Shuzheng Si", "Kangyang Luo", "Qingyi Wang", "Wenhao Li", "Gang Chen", "Fanchao Qi", "Maosong Sun"], "title": "InFi-Check: Interpretable and Fine-Grained Fact-Checking of LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) often hallucinate, yet most existing fact-checking methods treat factuality evaluation as a binary classification problem, offering limited interpretability and failing to capture fine-grained error types. In this paper, we introduce InFi-Check, a framework for interpretable and fine-grained fact-checking of LLM outputs. Specifically, we first propose a controlled data synthesis pipeline that generates high-quality data featuring explicit evidence, fine-grained error type labels, justifications, and corrections. Based on this, we further construct large-scale training data and a manually verified benchmark InFi-Check-FG for fine-grained fact-checking of LLM outputs. Building on these high-quality training data, we further propose InFi-Checker, which can jointly provide supporting evidence, classify fine-grained error types, and produce justifications along with corrections. Experiments show that InFi-Checker achieves state-of-the-art performance on InFi-Check-FG and strong generalization across various downstream tasks, significantly improving the utility and trustworthiness of factuality evaluation.", "AI": {"tldr": "该论文提出了一种用于大型语言模型（LLM）输出的可解释且细粒度的事实核查框架InFi-Check。", "motivation": "大多数现有的事实验证方法将真实性评估视为二元分类问题，这限制了其可解释性，并无法捕获细微错误类型。为此，论文提出了一种新的事实核查框架来解决这些问题。", "method": "该研究首先提出了一个控制数据合成流程以生成包含明确证据、细粒度误差类型标签、说明和纠正措施的高质量数据集；基于此，构建了大规模训练数据及手动验证基准InFi-Check-FG。此外，还设计了一个能够同时提供支持证据、分类细粒度错误类型并给出解释与纠正建议的新系统InFi-Checker。", "result": "实验结果表明，新提出的InFi-Checker在InFi-Check-FG上的性能达到了最新的技术水平，并且对各种下游任务具有强大的泛化能力。", "conclusion": "通过提出一种新的可解释和细粒度的事实核查框架InFi-Check，论文显著提高了事实性评估的实用性和可信度。"}}
{"id": "2601.06664", "pdf": "https://arxiv.org/pdf/2601.06664", "abs": "https://arxiv.org/abs/2601.06664", "authors": ["Md Nafees Fuad Rafi", "Samiul Hasan"], "title": "Reinforcement Learning-Guided Dynamic Multi-Graph Fusion for Evacuation Traffic Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real-time traffic prediction is critical for managing transportation systems during hurricane evacuations. Although data-driven graph-learning models have demonstrated strong capabilities in capturing the complex spatiotemporal dynamics of evacuation traffic at a network level, they mostly consider a single dimension (e.g., travel-time or distance) to construct the underlying graph. Furthermore, these models often lack interpretability, offering little insight into which input variables contribute most to their predictive performance. To overcome these limitations, we develop a novel Reinforcement Learning-guided Dynamic Multi-Graph Fusion (RL-DMF) framework for evacuation traffic prediction. We construct multiple dynamic graphs at each time step to represent heterogeneous spatiotemporal relationships between traffic detectors. A dynamic multi-graph fusion (DMF) module is employed to adaptively learn and combine information from these graphs. To enhance model interpretability, we introduce RL-based intelligent feature selection and ranking (RL-IFSR) method that learns to mask irrelevant features during model training. The model is evaluated using a real-world dataset of 12 hurricanes affecting Florida from 2016 to 2024. For an unseen hurricane (Milton, 2024), the model achieves a 95% accuracy (RMSE = 293.9) for predicting the next 1-hour traffic flow. Moreover, the model can forecast traffic flow for up to next 6 hours with 90% accuracy (RMSE = 426.4). The RL-DMF framework outperforms several state-of-the-art traffic prediction models. Furthermore, ablation experiments confirm the effectiveness of dynamic multi-graph fusion and RL-IFSR approaches for improving model performance. This research provides a generalized and interpretable model for real-time evacuation traffic forecasting, with significant implications for evacuation traffic management.", "AI": {"tldr": "提出了一种基于强化学习的动态多图融合框架（RL-DMF）用于飓风疏散交通预测。", "motivation": "现有数据驱动图形学习模型在捕捉疏散交通的复杂时空动态方面表现出色，但往往仅考虑单一维度构建底层图，并且缺乏解释性。为了克服这些限制，开发了基于强化学习的动态多图融合框架。", "method": "通过构造多个动态图来表示交通检测器之间的异构时空关系，在每个时间步使用动态多图融合模块自适应地学习和结合这些图的信息。引入基于强化学习的智能特征选择和排序方法提升模型解释性。", "result": "在佛罗里达州2016年至2024年期间遭受的12次飓风的真实数据集上进行评估，对于未见过的飓风（米尔顿，2024），该模型预测下一小时交通流时达到95%准确率（RMSE=293.9）。此外，可预测未来6小时内流量，准确率为90%（RMSE=426.4）。RL-DMF框架优于几种最先进的交通预测模型。", "conclusion": "该研究提供了一种通用且解释性强的实时疏散交通预测模型，对于疏散交通管理具有重要意义。"}}
{"id": "2601.06663", "pdf": "https://arxiv.org/pdf/2601.06663", "abs": "https://arxiv.org/abs/2601.06663", "authors": ["Kaiwen Zhou", "Shreedhar Jangam", "Ashwin Nagarajan", "Tejas Polu", "Suhas Oruganti", "Chengzhi Liu", "Ching-Chen Kuo", "Yuting Zheng", "Sravana Narayanaraju", "Xin Eric Wang"], "title": "SafePro: Evaluating the Safety of Professional-Level AI Agents", "categories": ["cs.AI"], "comment": null, "summary": "Large language model-based agents are rapidly evolving from simple conversational assistants into autonomous systems capable of performing complex, professional-level tasks in various domains. While these advancements promise significant productivity gains, they also introduce critical safety risks that remain under-explored. Existing safety evaluations primarily focus on simple, daily assistance tasks, failing to capture the intricate decision-making processes and potential consequences of misaligned behaviors in professional settings. To address this gap, we introduce \\textbf{SafePro}, a comprehensive benchmark designed to evaluate the safety alignment of AI agents performing professional activities. SafePro features a dataset of high-complexity tasks across diverse professional domains with safety risks, developed through a rigorous iterative creation and review process. Our evaluation of state-of-the-art AI models reveals significant safety vulnerabilities and uncovers new unsafe behaviors in professional contexts. We further show that these models exhibit both insufficient safety judgment and weak safety alignment when executing complex professional tasks. In addition, we investigate safety mitigation strategies for improving agent safety in these scenarios and observe encouraging improvements. Together, our findings highlight the urgent need for robust safety mechanisms tailored to the next generation of professional AI agents.", "AI": {"tldr": "评估专业级AI代理的安全性。", "motivation": "现有安全评估主要集中在简单的日常任务上，无法捕捉到复杂决策过程中可能出现的风险和不一致行为。为了填补这一空白，研究者开发了一项新基准来测试执行高级专业任务的AI模型的安全性能。", "method": "引入了一个包含多种专业领域中的高复杂度任务的安全性评估数据集SafePro，并使用该数据集对最先进的AI模型进行了全面评估。", "result": "发现现有模型在处理复杂的专业任务时存在显著的安全漏洞，展示了不足的安全判断能力和弱安全性校准。研究者还探索了提高代理安全性的策略并观察到了令人鼓舞的改进效果。", "conclusion": "研究结果强调了为下一代专业AI代理开发稳健安全机制的紧迫性。"}}
{"id": "2601.06662", "pdf": "https://arxiv.org/pdf/2601.06662", "abs": "https://arxiv.org/abs/2601.06662", "authors": ["Stefan Ciba"], "title": "Dereverberation Filter by Deconvolution with Frequency Bin Specific Faded Impulse Response", "categories": ["eess.AS", "cs.SD"], "comment": "8 pages, 3 figures, github repository with code and audio", "summary": "This work introduces a robust single-channel inverse filter for dereverberation of non-ideal recordings, validated on real audio. The developed method focuses on the calculation and modification of a discrete impulse response in order to filter the characteristics from a known digital single channel recording setup and room characteristics such as early reflections and reverberations. The aim is a dryer and clearer signal reconstruction, which ideally would be the direct-path signal. The time domain impulse response is calculated from the cepstral domain and faded by means of frequency bin specific exponential decay in the spectrum. The decay rates are obtained by using the blind estimates of reverberation time ratio between recorded output and test signals for each frequency bin. The modified impulse response does filter a recorded audio-signal by deconvolution. The blind estimation is well known and stands out for its robustness to noise and non-idealities. Estimation of a direct path signal is key to many applications.", "AI": {"tldr": "本文提出了一种用于非理想录音去混响的单通道逆滤波器，通过计算和修改离散脉冲响应来实现。", "motivation": "旨在从已知的数字单声道录音设置和房间特性中过滤出早期反射和回声，以恢复更清晰的信号。盲估计方法因其对噪声和非理想条件的鲁棒性而突出。", "method": "通过在频域使用频率特异的指数衰减来修改脉冲响应，并通过反卷积滤波处理录音音频信号。利用记录输出和测试信号之间的混响时间比进行盲估计以确定衰减率。", "result": "所开发的方法在真实音频上验证了其有效性，能够恢复接近直接路径信号的更清晰的音质。", "conclusion": "该方法提供了一种有效的去混响技术，适用于多种应用场合，并且对噪声和非理想条件具有鲁棒性。"}}
{"id": "2601.06652", "pdf": "https://arxiv.org/pdf/2601.06652", "abs": "https://arxiv.org/abs/2601.06652", "authors": ["Jing Cao", "Nishanth Kumar", "Aidan Curtis"], "title": "Follow the Signs: Using Textual Cues and LLMs to Guide Efficient Robot Navigation", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous navigation in unfamiliar environments often relies on geometric mapping and planning strategies that overlook rich semantic cues such as signs, room numbers, and textual labels. We propose a novel semantic navigation framework that leverages large language models (LLMs) to infer patterns from partial observations and predict regions where the goal is most likely located. Our method combines local perceptual inputs with frontier-based exploration and periodic LLM queries, which extract symbolic patterns (e.g., room numbering schemes and building layout structures) and update a confidence grid used to guide exploration. This enables robots to move efficiently toward goal locations labeled with textual identifiers (e.g., \"room 8\") even before direct observation. We demonstrate that this approach enables more efficient navigation in sparse, partially observable grid environments by exploiting symbolic patterns. Experiments across environments modeled after real floor plans show that our approach consistently achieves near-optimal paths and outperforms baselines by over 25% in Success weighted by Path Length.", "AI": {"tldr": "本文提出了一种利用大型语言模型（LLMs）和语义线索辅助机器人导航的框架。", "motivation": "传统的自主导航依赖于几何地图和规划策略，忽略了环境中的文字标识等丰富信息。为提高效率与准确性，引入了语义导航的概念。", "method": "该方法结合局部感知输入、前沿探索以及周期性地使用LLM查询来提取符号模式，并更新置信度网格以指导探索路径。", "result": "实验显示，这种技术能显著提升在稀疏或部分观察环境下目标定位的效率。与基线相比，在成功率加权路径长度上提高了25%以上。", "conclusion": "通过结合语言模型和符号模式识别，机器人能够在未直接观测到的情况下更有效地导航至带有文本标识的目标位置。"}}
{"id": "2601.06650", "pdf": "https://arxiv.org/pdf/2601.06650", "abs": "https://arxiv.org/abs/2601.06650", "authors": ["Qian Ma", "Yingfan Zhou", "Shubhang Kaushik", "Aamod Joshi", "Aditya Majumdar", "Noah Apthorpe", "Yan Shvartzshnaider", "Sarah Rajtmajer", "Brett Frischmann"], "title": "Learning Password Best Practices Through In-Task Instruction", "categories": ["cs.HC"], "comment": "16 pages, 7 figures, 16 tables", "summary": "Users often make security- and privacy-relevant decisions without a clear understanding of the rules that govern safe behavior. We introduce pedagogical friction, a design approach that introduces brief, instructional interactions at the moment of action. We evaluate this approach in the context of password creation, a task with clear, objective quality criteria and broad familiarity. We conducted a randomized repeated-measures study with 128 participants across four interface conditions that varied the depth and interactivity of guidance. We assessed three outcomes: (1) rule compliance in a subsequent password task without guidance, (2) accuracy on survey questions matched to the rules shown earlier, and (3) behavior-knowledge alignment, which captures whether participants who correctly followed a rule also recognized it on the survey. Across all guided conditions, participants corrected most rule violations in the follow-up task, achieved moderate accuracy on matched rule questions, and showed high behavior-knowledge alignment. These results support pedagogical friction as a lightweight and generalizable intervention for security- and privacy-critical interfaces.", "AI": {"tldr": "本文通过在任务过程中插入简短的教学互动，评估了如何改进用户创建密码的行为。", "motivation": "用户经常在缺乏明确理解规则的情况下做出安全和隐私相关的决策。引入一种称为教学摩擦的设计方法，在执行动作时提供短暂的指导交互。", "method": "进行了一项随机重复测量研究，涉及128名参与者及四种不同的界面条件，这些条件在所提供的指导深度和互动性方面有所不同。评估了三个结果：（1）后续密码任务中规则遵守情况；（2）相关规则问题的准确性；（3）行为知识一致性。", "result": "所有有指导的情况下，参与者都纠正了大多数规则违反的行为，并且在匹配的问题上表现出了适度的准确度和高度的行为-知识一致性。", "conclusion": "这些结果支持教学摩擦作为一种轻量级、通用性的干预措施，在安全性和隐私性关键界面中的应用。"}}
{"id": "2601.06649", "pdf": "https://arxiv.org/pdf/2601.06649", "abs": "https://arxiv.org/abs/2601.06649", "authors": ["Joe Dwyer"], "title": "Revisiting Training Scale: An Empirical Study of Token Count, Power Consumption, and Parameter Efficiency", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Research in machine learning has questioned whether increases in training token counts reliably produce proportional performance gains in large language models. Building on prior work introducing an energy-aware parameter efficiency metric, this study empirically examines the effects of increasing training token counts under fixed hardware and training conditions. The significance of this work lies in the explicit integration of power consumption and execution duration, as reflected by the power sampling frequency, into token-scale analysis. This addresses a gap in prior studies emphasizing performance outcomes while underrepresenting computational and energy costs. Using a repeated-measures experimental design on a constant GPU instance with an identical model architecture, optimizer settings, and epoch counts, a 1.1-billion-parameter TinyLlama model was trained at three token counts (500K, 1M, and 2M). While conventional performance metrics exhibited inconsistent or diminishing returns across token scales, the inclusion of power consumption and execution duration revealed a strictly monotonic decline in training efficiency as token count increased. Repeated-measures ANOVA demonstrated a strong effect of token count on parameter efficiency, with all pairwise comparisons remaining significant following Bonferroni correction. These findings indicate that increases in training token counts may be energetically inefficient even when marginal performance improvements are observed, underscoring the importance of efficiency-aware evaluation in large language model training.", "AI": {"tldr": "研究通过增加训练令牌数，固定硬件和训练条件，探讨大规模语言模型的性能与能量消耗的关系。", "motivation": "先前的研究对大模型中训练令牌数量的增加是否带来比例性性能提升提出了疑问。本研究旨在填补以往工作中忽视计算成本和能耗问题的空白，引入一种考虑功率消耗的时间效率参数指标来衡量模型性能。", "method": "采用重复测量实验设计，在恒定GPU实例、相同模型架构、优化器设置及迭代次数下，使用具有1.1亿个参数的TinyLlama模型在不同令牌数量（50万、100万和200万）条件下进行训练。通过方差分析验证令牌数对参数效率的影响，并进行了Bonferroni校正后的成对比较。", "result": "尽管传统性能指标显示令牌规模增加带来的回报不一致或递减，但加入功率消耗时间后揭示出随着令牌数量的增加训练效率呈严格单向下降趋势。重复测量方差分析表明令牌数显著影响参数效率且所有成对比照均在Bonferroni校正后保持显著。", "conclusion": "研究表明即使观察到边际性能改进，提高训练令牌数也可能导致能量利用效率低下，强调了大规模语言模型训练中需注意能源和计算成本的评估方法。"}}
{"id": "2601.06647", "pdf": "https://arxiv.org/pdf/2601.06647", "abs": "https://arxiv.org/abs/2601.06647", "authors": ["Krishna Vinod", "Joseph Raj Vishal", "Kaustav Chanda", "Prithvi Jai Ramesh", "Yezhou Yang", "Bharatesh Chakravarthi"], "title": "eSkiTB: A Synthetic Event-based Dataset for Tracking Skiers", "categories": ["cs.CV"], "comment": null, "summary": "Tracking skiers in RGB broadcast footage is challenging due to motion blur, static overlays, and clutter that obscure the fast-moving athlete. Event cameras, with their asynchronous contrast sensing, offer natural robustness to such artifacts, yet a controlled benchmark for winter-sport tracking has been missing. We introduce event SkiTB (eSkiTB), a synthetic event-based ski tracking dataset generated from SkiTB using direct video-to-event conversion without neural interpolation, enabling an iso-informational comparison between RGB and event modalities. Benchmarking SDTrack (spiking transformer) against STARK (RGB transformer), we find that event-based tracking is substantially resilient to broadcast clutter in scenes dominated by static overlays, achieving 0.685 IoU, outperforming RGB by +20.0 points. Across the dataset, SDTrack attains a mean IoU of 0.711, demonstrating that temporal contrast is a reliable cue for tracking ballistic motion in visually congested environments. eSkiTB establishes the first controlled setting for event-based tracking in winter sports and highlights the promise of event cameras for ski tracking. The dataset and code will be released at https://github.com/eventbasedvision/eSkiTB.", "AI": {"tldr": "生成了一个名为eSkiTB的合成事件数据集，用于滑雪者追踪。", "motivation": "传统RGB视频中滑雪者的跟踪面临运动模糊和静态覆盖物等问题，而事件相机由于其异步对比度感知特性，在这种情况下表现出色。然而，缺乏一个控制良好的冬季体育项目跟踪基准。", "method": "利用SkiTB数据集通过直接视频到事件的转换生成eSkiTB数据集，并使用SDTrack（脉冲变换器）与STARK（RGB变换器）进行对比实验。", "result": "在包含大量静态覆盖物的情况下，基于事件的跟踪表现优于RGB模式，IoU为0.685，比RGB高出20点。总体而言，SDTrack在整个数据集中实现了平均IoU 0.711。", "conclusion": "eSkiTB提供了第一个控制良好的冬季体育项目中基于事件的追踪基准，并展示了事件相机在滑雪跟踪中的巨大潜力。"}}
{"id": "2601.06644", "pdf": "https://arxiv.org/pdf/2601.06644", "abs": "https://arxiv.org/abs/2601.06644", "authors": ["Yan Meng", "Wafaa Mohammed", "Christof Monz"], "title": "Do Language Models Reason Across Languages?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The real-world information sources are inherently multilingual, which naturally raises a question about whether language models can synthesize information across languages. In this paper, we introduce a simple two-hop question answering setting, where answering a question requires making inferences over two multilingual documents. We find that language models are more sensitive to language variation in answer-span documents than in those providing bridging information, despite the equal importance of both documents for answering a question. Under a step-by-step sub-question evaluation, we further show that in up to 33% of multilingual cases, models fail to infer the bridging information in the first step yet still answer the overall question correctly. This indicates that reasoning in language models, especially in multilingual settings, does not follow a faithful step-by-step decomposition. Subsequently, we show that the absence of reasoning decomposition leads to around 18% composition failure, where both sub-questions are answered correctly but fail for the final two-hop questions. To mitigate this, we propose a simple three-stage SUBQ prompting method to guide the multi-step reasoning with sub-questions, which boosts accuracy from 10.1% to 66.5%.", "AI": {"tldr": "本文研究了语言模型在跨语言推理中的表现，提出了一个多步骤提示方法来改善多语种设置下的推理准确性。", "motivation": "现实世界的信息来源是多语言的，这引发了一个问题：语言模型能否跨语言综合信息。为了探索这个问题，作者设计了一种简单的两步问答场景，以评估模型在不同语言文档中的推理能力。", "method": "研究引入了两步问答设置，其中回答一个问题需要根据两个多元语言文件进行推断，并且提出了一个三阶段SUBQ提示方法来引导多步骤推理。", "result": "实验结果显示，在多达33％的跨语言案例中，模型无法在第一步中推导出桥梁信息，但却能正确回答总体问题。这表明语言模型中的推理并不遵循忠实的分步分解方式，导致大约18%的组合失败。通过使用SUBQ提示方法，准确性从10.1%提高到了66.5%。", "conclusion": "文章发现语言模型在跨语言设置下的推理存在不足，并提出了一种改进方案来提升多步骤推理中的准确性。"}}
{"id": "2601.06642", "pdf": "https://arxiv.org/pdf/2601.06642", "abs": "https://arxiv.org/abs/2601.06642", "authors": ["Gui Huang", "Kangyuan Zheng", "Xuan Cai", "Jiaqi Wang", "Jianjia Zhang", "Kaida Ning", "Wenbo Wei", "Yujuan Zhu", "Jiong Zhang", "Mengting Liu"], "title": "Boosting Overlapping Organoid Instance Segmentation Using Pseudo-Label Unmixing and Synthesis-Assisted Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Organoids, sophisticated in vitro models of human tissues, are crucial for medical research due to their ability to simulate organ functions and assess drug responses accurately. Accurate organoid instance segmentation is critical for quantifying their dynamic behaviors, yet remains profoundly limited by high-quality annotated datasets and pervasive overlap in microscopy imaging. While semi-supervised learning (SSL) offers a solution to alleviate reliance on scarce labeled data, conventional SSL frameworks suffer from biases induced by noisy pseudo-labels, particularly in overlapping regions. Synthesis-assisted SSL (SA-SSL) has been proposed for mitigating training biases in semi-supervised semantic segmentation. We present the first adaptation of SA-SSL to organoid instance segmentation and reveal that SA-SSL struggles to disentangle intertwined organoids, often misrepresenting overlapping instances as a single entity. To overcome this, we propose Pseudo-Label Unmixing (PLU), which identifies erroneous pseudo-labels for overlapping instances and then regenerates organoid labels through instance decomposition. For image synthesis, we apply a contour-based approach to synthesize organoid instances efficiently, particularly for overlapping cases. Instance-level augmentations (IA) on pseudo-labels before image synthesis further enhances the effect of synthetic data (SD). Rigorous experiments on two organoid datasets demonstrate our method's effectiveness, achieving performance comparable to fully supervised models using only 10% labeled data, and state-of-the-art results. Ablation studies validate the contributions of PLU, contour-based synthesis, and augmentation-aware training. By addressing overlap at both pseudo-label and synthesis levels, our work advances scalable, label-efficient organoid analysis, unlocking new potential for high-throughput applications in precision medicine.", "AI": {"tldr": "提出了使用伪标签解混和辅助合成学习的方法来提高重叠类器官实例分割的准确性。", "motivation": "为了解决由于高质量标注数据稀缺以及显微成像中的广泛重叠而导致的准确器官体实例分割的问题，引入了一种基于合成增强半监督学习的新方法。", "method": "提出了一种伪标签解混（PLU）技术来识别错误的伪标签，并通过实例分解再生类器官标签。同时采用轮廓基图像合成法高效生成类器官实例，特别是在重叠案例中。在伪标签上进行实例级增强，进一步提升了合成数据的效果。", "result": "实验表明该方法能够实现与完全监督模型相当的表现，在仅使用10%标注数据的情况下达到最先进的结果。", "conclusion": "通过解决伪标签和图像合成中的重叠问题，推动了高通量应用中基于器官体分析的可扩展、标签高效的研究，为精准医学领域带来了新的可能性。"}}
{"id": "2601.06640", "pdf": "https://arxiv.org/pdf/2601.06640", "abs": "https://arxiv.org/abs/2601.06640", "authors": ["Genze Jiang", "Kezhi Wang", "Xiaomin Chen", "Yizhou Huang"], "title": "Agentic AI Empowered Intent-Based Networking for 6G", "categories": ["cs.AI", "cs.NI"], "comment": "Submitted for Possible Journal Publication", "summary": "The transition towards sixth-generation (6G) wireless networks necessitates autonomous orchestration mechanisms capable of translating high-level operational intents into executable network configurations. Existing approaches to Intent-Based Networking (IBN) rely upon either rule-based systems that struggle with linguistic variation or end-to-end neural models that lack interpretability and fail to enforce operational constraints. This paper presents a hierarchical multi-agent framework where Large Language Model (LLM) based agents autonomously decompose natural language intents, consult domain-specific specialists, and synthesise technically feasible network slice configurations through iterative reasoning-action (ReAct) cycles. The proposed architecture employs an orchestrator agent coordinating two specialist agents, i.e., Radio Access Network (RAN) and Core Network agents, via ReAct-style reasoning, grounded in structured network state representations. Experimental evaluation across diverse benchmark scenarios shows that the proposed system outperforms rule-based systems and direct LLM prompting, with architectural principles applicable to Open RAN (O-RAN) deployments. The results also demonstrate that whilst contemporary LLMs possess general telecommunications knowledge, network automation requires careful prompt engineering to encode context-dependent decision thresholds, advancing autonomous orchestration capabilities for next-generation wireless systems.", "AI": {"tldr": "该论文提出了一种基于代理的框架，利用大型语言模型分解自然语言意图，并生成可行的网络切片配置，以实现6G无线网络中的自主编排。", "motivation": "为了应对向第六代(6G)无线网络过渡的需求，现有基于意图的网络(IBN)方法面临挑战。规则系统难以处理语言变异，而端到端神经模型缺乏可解释性且无法强制执行操作约束。", "method": "论文提出了一种分层多代理架构，其中大型语言模型代理通过迭代推理-行动(ReAct)循环自主分解自然语言意图，并咨询领域专家，综合生成可行的网络切片配置。该框架使用一个协调器代理管理两个专业的代理（即无线接入网(RAN)和核心网络代理）。", "result": "实验表明所提出的系统在各种基准场景中优于基于规则的方法和直接大型语言模型提示方法，并且适用于开放RAN(O-RAN)部署。结果显示，当前的大型语言模型具备通用电信知识，但需要精心设计提示来编码上下文依赖的决策阈值。", "conclusion": "该研究推进了下一代无线系统自主编排能力的发展。"}}
{"id": "2601.06639", "pdf": "https://arxiv.org/pdf/2601.06639", "abs": "https://arxiv.org/abs/2601.06639", "authors": ["Qingyu Liu", "Yitao Zhang", "Zhongjie Ba", "Chao Shuai", "Peng Cheng", "Tianhang Zheng", "Zhibo Wang"], "title": "Attack-Resistant Watermarking for AIGC Image Forensics via Diffusion-based Semantic Deflection", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Protecting the copyright of user-generated AI images is an emerging challenge as AIGC becomes pervasive in creative workflows. Existing watermarking methods (1) remain vulnerable to real-world adversarial threats, often forced to trade off between defenses against spoofing and removal attacks; and (2) cannot support semantic-level tamper localization. We introduce PAI, a training-free inherent watermarking framework for AIGC copyright protection, plug-and-play with diffusion-based AIGC services. PAI simultaneously provides three key functionalities: robust ownership verification, attack detection, and semantic-level tampering localization. Unlike existing inherent watermark methods that only embed watermarks at noise initialization of diffusion models, we design a novel key-conditioned deflection mechanism that subtly steers the denoising trajectory according to the user key. Such trajectory-level coupling further strengthens the semantic entanglement of identity and content, thereby further enhancing robustness against real-world threats. Moreover, we also provide a theoretical analysis proving that only the valid key can pass verification. Experiments across 12 attack methods show that PAI achieves 98.43\\% verification accuracy, improving over SOTA methods by 37.25\\% on average, and retains strong tampering localization performance even against advanced AIGC edits. Our code is available at https://github.com/QingyuLiu/PAI.", "AI": {"tldr": "该论文提出了一种针对AIGC图像防伪的攻击抵抗式水印方法PAI，能够实现版权验证、攻击检测和语义层面篡改定位。", "motivation": "现有的水印技术在面对现实世界中的对抗威胁时较为脆弱，并且不能支持语义级的篡改定位。因此需要一种新的框架来提升图像防伪能力及版权保护效果。", "method": "PAI利用扩散模型训练前的关键条件偏移机制，通过用户的密钥微妙地改变去噪轨迹，从而加强身份和内容间的语义纠缠，增强了对抗真实世界威胁的鲁棒性。该方法还提供了理论分析证明只有有效的密钥才能通过验证。", "result": "实验结果表明PAI在12种攻击方式下达到了98.43%的验证准确率，并且即使面对高级AIGC编辑也保持了强大的篡改定位性能，相比最先进方法提高了37.25%的平均值。", "conclusion": "PAI是一种有效的训练自由型内在水印框架，能够满足AIGC版权保护的需求，在多种攻击中表现出色。"}}
{"id": "2601.06636", "pdf": "https://arxiv.org/pdf/2601.06636", "abs": "https://arxiv.org/abs/2601.06636", "authors": ["Wenting Chen", "Zhongrui Zhu", "Guolin Huang", "Wenxuan Wang"], "title": "MedEinst: Benchmarking the Einstellung Effect in Medical LLMs through Counterfactual Differential Diagnosis", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages, 7 figures", "summary": "Despite achieving high accuracy on medical benchmarks, LLMs exhibit the Einstellung Effect in clinical diagnosis--relying on statistical shortcuts rather than patient-specific evidence, causing misdiagnosis in atypical cases. Existing benchmarks fail to detect this critical failure mode. We introduce MedEinst, a counterfactual benchmark with 5,383 paired clinical cases across 49 diseases. Each pair contains a control case and a \"trap\" case with altered discriminative evidence that flips the diagnosis. We measure susceptibility via Bias Trap Rate--probability of misdiagnosing traps despite correctly diagnosing controls. Extensive Evaluation of 17 LLMs shows frontier models achieve high baseline accuracy but severe bias trap rates. Thus, we propose ECR-Agent, aligning LLM reasoning with Evidence-Based Medicine standard via two components: (1) Dynamic Causal Inference (DCI) performs structured reasoning through dual-pathway perception, dynamic causal graph reasoning across three levels (association, intervention, counterfactual), and evidence audit for final diagnosis; (2) Critic-Driven Graph and Memory Evolution (CGME) iteratively refines the system by storing validated reasoning paths in an exemplar base and consolidating disease-specific knowledge into evolving illness graphs. Source code is to be released.", "AI": {"tldr": "该论文介绍了MedEinst，一个用于评估医学LLM中Einstellung效应的反事实基准。", "motivation": "尽管在医疗基准上表现出高准确性，但LLMs在临床诊断时依赖统计捷径而非患者特异性证据，在非典型病例中导致误诊。现有基准无法检测到这一关键故障模式。", "method": "通过5,383对临床上跨49种疾病的配对案例，每对包含一个对照案例和一个“陷阱”案例来评估模型的偏见陷阱率。", "result": "17个LLMs中的前沿模型在基准准确度上表现高，但具有严重的偏见陷阱率。提出ECR-Agent通过动态因果推理（DCI）和批评驱动图与记忆演化（CGME）两个组件将LLM推理与基于证据的医学标准对齐。", "conclusion": "该研究揭示了当前模型在处理非典型病例时的局限性，并提出了改进方向，以减少误诊风险。"}}
{"id": "2601.06634", "pdf": "https://arxiv.org/pdf/2601.06634", "abs": "https://arxiv.org/abs/2601.06634", "authors": ["WariNkwi K. Flores", "KunTikzi Flores", "Rosa M. Panama", "KayaKanti Alta"], "title": "A Framework for Kara-Kichwa Data Sovereignty in Latin America and the Caribbean", "categories": ["cs.CY", "cs.ET"], "comment": "8 pages, 2 figures, submitted paper under review process", "summary": "In the high-altitude territories of the Andean-Amazonian-Atlantic pathway, data is not merely a digital resource but an extension of Khipu Panaka, the genealogical and relational memory of the Kara-Kichwa Republics. This perspective paper introduces the Kara-Kichwa Data Sovereignty Framework, a living instrument designed to counteract the \"intellectual gentrification\" and systemic invisibility of Andean Indigenous Peoples in global data ecosystems. Grounded in Indigenous legal systems thinking, the framework codifies five customary pillars, Kamachy (Self-determination), Ayllu-llaktapak kamachy (Collective Authority), Tantanakuy (Relational Accountability), Willay-panka-tantay (Ancestral Memory), and Sumak Kawsay (Biocultural Ethics), to govern the lifecycle of data from generation to expiration.", "AI": {"tldr": "本文提出了卡拉基丘瓦数据主权框架，旨在保护安第斯土著人民在全球数据生态系统中的地位和记忆。", "motivation": "在安第斯-亚马逊-大西洋路径的高原地区，数据被视为卡拉基丘瓦共和国的家谱和关系记忆的延伸。该论文旨在解决全球数据生态系统的“知识绅士化”问题，并提高土著人民的数据可见性。", "method": "基于土著法律体系思维，提出五个传统支柱：Kamachy（自决）、Ayllu-llaktapak kamachy（集体权威）、Tantanakuy（关系责任）、Willay-panka-tantay（祖先记忆）和Sumak Kawsay（生物文化伦理），来规范数据生命周期。", "result": "卡拉基丘瓦数据主权框架被提出，该框架将作为治理数据生命周期的活生生工具。", "conclusion": "通过引入卡拉基丘瓦数据主权框架，可以提高土著人民在全球数据生态中的地位，并保护他们的文化和记忆。"}}
{"id": "2601.06633", "pdf": "https://arxiv.org/pdf/2601.06633", "abs": "https://arxiv.org/abs/2601.06633", "authors": ["Zhangqi Duan", "Nigel Fernandez", "Andrew Lan"], "title": "KASER: Knowledge-Aligned Student Error Simulator for Open-Ended Coding Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "Open-ended tasks, such as coding problems that are common in computer science education, provide detailed insights into student knowledge. However, training large language models (LLMs) to simulate and predict possible student errors in their responses to these problems can be challenging: they often suffer from mode collapse and fail to fully capture the diversity in syntax, style, and solution approach in student responses. In this work, we present KASER (Knowledge-Aligned Student Error Simulator), a novel approach that aligns errors with student knowledge. We propose a training method based on reinforcement learning using a hybrid reward that reflects three aspects of student code prediction: i) code similarity to the ground-truth, ii) error matching, and iii) code prediction diversity. On two real-world datasets, we perform two levels of evaluation and show that: At the per-student-problem pair level, our method outperforms baselines on code and error prediction; at the per-problem level, our method outperforms baselines on error coverage and simulated code diversity.", "AI": {"tldr": "介绍了一种名为KASER的新方法，用于模拟和预测学生在开放性编程任务中的错误。", "motivation": "现有大型语言模型难以准确模拟学生的多种错误模式与风格差异。", "method": "提出了基于强化学习的训练方式，采用混合奖励机制提高代码相似度、误差匹配及多样性。", "result": "实验结果显示KASER在学生问题对级别和题目级别均优于基线方法，提高了预测精度和代码多样性。", "conclusion": "KASER成功解决了模拟学生编程错误中的关键挑战，并展示了其在教育应用领域的潜力。"}}
{"id": "2601.06629", "pdf": "https://arxiv.org/pdf/2601.06629", "abs": "https://arxiv.org/abs/2601.06629", "authors": ["Luis Alberto Croquevielle", "Roman Sokolovskii", "Thomas Heinis"], "title": "Lower Bounds for the Algorithmic Complexity of Learned Indexes", "categories": ["cs.DS", "cs.LG"], "comment": null, "summary": "Learned index structures aim to accelerate queries by training machine learning models to approximate the rank function associated with a database attribute. While effective in practice, their theoretical limitations are not fully understood. We present a general framework for proving lower bounds on query time for learned indexes, expressed in terms of their space overhead and parameterized by the model class used for approximation. Our formulation captures a broad family of learned indexes, including most existing designs, as piecewise model-based predictors. We solve the problem of lower bounding query time in two steps: first, we use probabilistic tools to control the effect of sampling when the database attribute is drawn from a probability distribution. Then, we analyze the approximation-theoretic problem of how to optimally represent a cumulative distribution function with approximators from a given model class. Within this framework, we derive lower bounds under a range of modeling and distributional assumptions, paying particular attention to the case of piecewise linear and piecewise constant model classes, which are common in practical implementations. Our analysis shows how tools from approximation theory, such as quantization and Kolmogorov widths, can be leveraged to formalize the space-time tradeoffs inherent to learned index structures. The resulting bounds illuminate core limitations of these methods.", "AI": {"tldr": "研究论文提出了用于学习索引查询时间下限的一般框架，探讨了不同模型类和分布假设下的理论限制。", "motivation": "尽管学习索引在实践中有效，但其理论上的局限性尚未完全理解。本文旨在通过概率工具和逼近理论来证明查询时间的下界。", "method": "论文首先使用概率工具控制采样效果，然后分析如何用给定模型类最优表示累积分布函数。", "result": "研究得出了一系列关于学习索引结构的空间-时间权衡的下限，并特别关注了实践中常见的分段线性和常数模型类。", "conclusion": "该框架揭示了学习索引方法的核心限制，有助于理解和优化这些技术。"}}
{"id": "2601.06627", "pdf": "https://arxiv.org/pdf/2601.06627", "abs": "https://arxiv.org/abs/2601.06627", "authors": ["Qiang Zhang", "Elena Emma Wang", "Jiaming Li", "Xichun Wang"], "title": "Burn-After-Use for Preventing Data Leakage through a Secure Multi-Tenant Architecture in Enterprise LLM", "categories": ["cs.CR", "cs.AI"], "comment": "16 pages, 5 figures", "summary": "This study presents a Secure Multi-Tenant Architecture (SMTA) combined with a novel concept Burn-After-Use (BAU) mechanism for enterprise LLM environments to effectively prevent data leakage. As institutions increasingly adopt LLMs across departments, the risks of data leakage have become a critical security and compliance concern. The proposed SMTA isolates LLM instances across departments and enforces rigorous context ownership boundaries within an internally deployed infrastructure. The BAU mechanism introduces data confidentiality by enforcing ephemeral conversational contexts that are automatically destroyed after use, preventing cross-session or cross-user inference. The evaluation to SMTA and BAU is through two sets of realistic and reproducible experiments comprising of 127 test iterations. One aspect of this experiment is to assess prompt-based and semantic leakage attacks in a multi-tenant architecture (Appendix A) across 55 infrastructure-level attack tests, including vector-database credential compromise and shared logging pipeline exposure. SMTA achieves 92% defense success rate, demonstrating strong semantic isolation while highlighting residual risks from credential misconfiguration and observability pipelines. Another aspect is to evaluate the robustness of BAU under realistic failure scenarios (Appendix B) using four empirical metrics: Local Residual Persistence Rate (LRPR), Remote Residual Persistence Rate (RRPR), Image Frame Exposure Rate (IFER), and Burn Timer Persistence Rate (BTPR). Across 72 test iterations, BAU achieves a 76.75% success rate in mitigating post-session leakage threats across the client, server, application, infrastructure, and cache layers. These results show that SMTA and BAU together enforce strict isolation, complete session ephemerality, strong confidentiality guarantees, non-persistence, and policy-aligned behavior for enterprise LLMs.", "AI": {"tldr": "本文提出了一种结合Burn-After-Use机制的Secure Multi-Tenant Architecture，以防止企业LLM环境中的数据泄露。", "motivation": "随着机构越来越多地在各部门中采用LLM，数据泄露的风险已成为关键的安全和合规问题。因此，需要一种有效的架构来防止数据泄露。", "method": "提出了一个隔离LLM实例并严格执行上下文所有权边界的Secure Multi-Tenant Architecture，并引入了Burn-After-Use机制，以实现临时对话环境在使用后自动销毁，从而防止跨会话或跨用户推断。通过两组包含127次测试迭代的实验来评估SMTA和BAU。", "result": "SMTA实现了92%的成功防御率，并且BAU在72个测试迭代中实现了一个76.75%的成功率，展示了其防止数据泄露的能力。", "conclusion": "研究结果表明，结合使用Secure Multi-Tenant Architecture和Burn-After-Use机制可以提供严格的隔离、完全的会话瞬时性、强大的保密保证、非持久性和符合政策的行为。"}}
{"id": "2601.06621", "pdf": "https://arxiv.org/pdf/2601.06621", "abs": "https://arxiv.org/abs/2601.06621", "authors": ["Hao Jiang", "Edgar Choueiri"], "title": "Stereo Audio Rendering for Personal Sound Zones Using a Binaural Spatially Adaptive Neural Network (BSANN)", "categories": ["eess.AS", "cs.SD"], "comment": "Submitted to IEEE Transactions on Audio, Speech, and Language Processing (TASLP)", "summary": "A binaural rendering framework for personal sound zones (PSZs) is proposed to enable multiple head-tracked listeners to receive fully independent stereo audio programs. Current PSZ systems typically rely on monophonic rendering and therefore cannot control the left and right ears separately, which limits the quality and accuracy of spatial imaging. The proposed method employs a Binaural Spatially Adaptive Neural Network (BSANN) to generate ear-optimized loudspeaker filters that reconstruct the desired acoustic field at each ear of multiple listeners. The framework integrates anechoically measured loudspeaker frequency responses, analytically modeled transducer directivity, and rigid-sphere head-related transfer functions (HRTFs) to enhance acoustic accuracy and spatial rendering fidelity. An explicit active crosstalk cancellation (XTC) stage further improves three-dimensional spatial perception. Experiments show significant gains in measured objective performance metrics, including inter-zone isolation (IZI), inter-program isolation (IPI), and crosstalk cancellation (XTC), with log-frequency-weighted values of 10.23/10.03 dB (IZI), 11.11/9.16 dB (IPI), and 10.55/11.13 dB (XTC), respectively, over 100-20,000 Hz. The combined use of ear-wise control, accurate acoustic modeling, and integrated active XTC produces a unified rendering method that delivers greater isolation performance, increased robustness to room asymmetry, and more faithful spatial reproduction in real acoustic environments.", "AI": {"tldr": "提出了一种基于双耳自适应神经网络的个人声音区域渲染框架，以实现多个头部追踪听众接收完全独立的立体声音频节目。", "motivation": "当前的个人声音区域系统通常依赖单声道渲染，无法单独控制左右耳朵，这限制了空间成像的质量和准确性。为了提高这一领域的性能，提出了这种方法。", "method": "提出了一种双耳自适应神经网络（BSANN），用于生成优化每个听众每只耳朵的扬声器滤波器，重建所需的声场。该框架结合无回声测量的扬声器频率响应、分析建模的换能器方向图和刚性球头相关传输函数（HRTFs）来提高声学精度和空间渲染保真度。", "result": "实验显示，在100-20,000 Hz范围内，本方法在IZI、IPI和XTC等客观性能指标上的表现显著优于现有技术，分别实现了10.23/10.03 dB（IZI）、11.11/9.16 dB（IPI）和10.55/11.13 dB（XTC）。", "conclusion": "结合耳部控制、精确声学建模和集成主动交叉谈话取消，产生了一种统一的渲染方法，提供更强的隔离性能、增强的房间不对称性鲁棒性和更真实的空间再现。"}}
{"id": "2601.06617", "pdf": "https://arxiv.org/pdf/2601.06617", "abs": "https://arxiv.org/abs/2601.06617", "authors": ["Giovani Braglia", "José Jair Alves Mendes Junior", "Augusto Tetsuo Prado Inafuco", "Federico Mariano", "Leonardo S. Mattos"], "title": "Robotic Tele-Operation for Upper Aerodigestive Tract Microsurgery: System Design and Validation", "categories": ["cs.RO"], "comment": null, "summary": "Upper aerodigestive tract (UADT) treatments frequently employ transoral laser microsurgery (TLM) for procedures such as the removal of tumors or polyps. In TLM, a laser beam is used to cut target tissue, while forceps are employed to grasp, manipulate, and stabilize tissue within the UADT. Although TLM systems may rely on different technologies and interfaces, forceps manipulation is still predominantly performed manually, introducing limitations in ergonomics, precision, and controllability. This paper proposes a novel robotic system for tissue manipulation in UADT procedures, based on a novel end-effector designed for forceps control. The system is integrated within a teleoperation framework that employs a robotic manipulator with a programmed remote center of motion (RCM), enabling precise and constrained instrument motion while improving surgeon ergonomics. The proposed approach is validated through two experimental studies and a dedicated usability evaluation, demonstrating its effectiveness and suitability for UADT surgical applications.", "AI": {"tldr": "本论文提出了一种用于上呼吸道和消化道手术中组织操作的新型机器人系统，该系统通过远程中心运动（RCM）框架改进了外科医生的操作精度与舒适度。", "motivation": "传统TLM系统中的夹持器控制仍然主要依靠手动方式，存在操作不便、精确度低以及缺乏可控制性等问题。因此，开发一种能够改善这些缺陷的新型机器人辅助手术技术显得尤为重要。", "method": "设计并实现了一种基于远程中心运动（RCM）框架的新颖末端执行器，并通过两个实验研究和专用的人机交互评估验证了该系统的效果。", "result": "实验证明，所提出的机器人系统在提高手术精确度、增强可控制性和改善外科医生的舒适性方面都表现出色，并且非常适合用于上呼吸道和消化道手术应用。", "conclusion": "新型机器人系统通过改进夹持器运动控制策略，在实现更准确、可控及舒适的TLM手术操作的同时，也为未来的微创手术技术提供了新的解决方案。"}}
{"id": "2601.06616", "pdf": "https://arxiv.org/pdf/2601.06616", "abs": "https://arxiv.org/abs/2601.06616", "authors": ["Blessing Jerry", "Lourdes Moreno", "Virginia Francisco", "Raquel Hervas"], "title": "LLM-Driven Accessible Interface: A Model-Based Approach", "categories": ["cs.HC"], "comment": ":H.5.2; J.3; K.4.2; H.1.2; I.2.7", "summary": "The integration of Large Language Models (LLMs) into interactive systems opens new opportunities for adaptive user experiences, yet it also raises challenges regarding accessibility, explainability, and normative compliance. This paper presents an implemented model-driven architecture for generating personalised, multimodal, and accessibility-aligned user interfaces. The approach combines structured user profiles, declarative adaptation rules, and validated prompt templates to refine baseline accessible UI templates that conform to WCAG 2.2 and EN 301 549, tailored to cognitive and sensory support needs. LLMs dynamically transform language complexity, modality, and visual structure, producing outputs such as Plain-Language text, pictograms, and high-contrast layouts aligned with ISO 24495-1 and W3C COGA guidance. A healthcare use case demonstrates how the system generates accessible post-consultation medication instructions tailored to a user profile comprising cognitive disability and hearing impairment. SysML v2 models provide explicit traceability between user needs, adaptation rules, and normative requirements, ensuring explainable and auditable transformations. Grounded in Human-Centered AI (HCAI), the framework incorporates co-design processes and structured feedback mechanisms to guide iterative refinement and support trustworthy generative behaviour.", "AI": {"tldr": "论文提出了一个基于模型驱动的架构，利用大型语言模型生成个性化、多模态且符合无障碍标准的用户界面。", "motivation": "将大型语言模型集成到交互系统中带来了适应性用户体验的新机会，但也面临可访问性、解释性和规范合规性的挑战。", "method": "该方法结合了结构化用户资料、声明式调整规则和验证提示模板来优化基本无障碍UI模板，并使用LLM动态转换语言复杂度、模式和视觉结构，生成符合国际标准的输出。", "result": "通过一个医疗保健用例展示了系统如何根据认知障碍和听力损伤生成可访问的用药指导说明。该框架确保了可解释性和审计性，同时融合了以人为中心的人工智能设计过程。", "conclusion": "论文提出了一种基于模型驱动的方法来创建适应性强且无障碍支持良好的用户界面，并通过人机协同设计流程提高了系统的信任度和生成行为的支持。"}}
{"id": "2601.06611", "pdf": "https://arxiv.org/pdf/2601.06611", "abs": "https://arxiv.org/abs/2601.06611", "authors": ["Nelly Elsayed"], "title": "AI Washing and the Erosion of Digital Legitimacy: A Socio-Technical Perspective on Responsible Artificial Intelligence in Business", "categories": ["cs.HC"], "comment": "38 pages, uner review", "summary": "The rapid evolution of artificial intelligence (AI) systems, tools, and technologies has opened up novel, unprecedented opportunities for businesses to innovate, differentiate, and compete. However, growing concerns have emerged about the use of AI in businesses, particularly AI washing, in which firms exaggerate, misrepresent, or superficially signal their AI capabilities to gain financial and reputational advantages. This paper aims to establish a conceptual foundation for understanding AI washing. In this paper, we draw on analogies from greenwashing and insights from Information Systems (IS) research on ethics, trust, signaling, and digital innovation. This paper proposes a typology of AI washing practices across four primary domains: marketing and branding, technical capability inflation, strategic signaling, and governance-based washing. In addition, we examine their organizational, industry, and societal impacts. Our investigation and analysis reveal how AI washing can lead to short-term gains; however, it also proposes severe long-term consequences, including reputational damage, erosion of trust, and misallocation of resources. Moreover, this paper examines current research directions and open questions aimed at mitigating AI washing practices and enhancing the trust and reliability of legitimate AI systems and technologies.", "AI": {"tldr": "本文旨在建立理解和应对AI洗牌的概念基础，提出了一种涵盖市场营销、技术能力膨胀、战略信号和治理层面的四维度框架，并探讨其对企业、行业和社会的影响。", "motivation": "随着人工智能快速发展，企业在利用AI时出现了夸大或不实宣传的现象（即AI洗牌），这对企业的长期声誉和技术信任度产生了负面影响。本文旨在通过IS研究中的伦理学、信任理论和数字创新等视角来理解这种现象。", "method": "作者借鉴了绿色洗牌的类比，并结合信息系统领域的相关研究成果，提出了一个涵盖四个主要维度的AI洗牌分类体系，并分析了这些实践对企业、行业和社会的影响。", "result": "本文揭示了AI洗牌可能导致短期内的利益增长，但同时也带来了长期的风险和后果，包括声誉受损、信任度下降以及资源误配等问题。", "conclusion": "文章指出了当前研究方向及开放性问题，旨在减少AI洗牌行为并提升合法人工智能系统的可信性和可靠性。"}}
{"id": "2601.06607", "pdf": "https://arxiv.org/pdf/2601.06607", "abs": "https://arxiv.org/abs/2601.06607", "authors": ["Tanisha Raorane", "Prasenjit Kole"], "title": "Pragya: An AI-Based Semantic Recommendation System for Sanskrit Subhasitas", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Preprint", "summary": "Sanskrit Subhasitas encapsulate centuries of cultural and philosophical wisdom, yet remain underutilized in the digital age due to linguistic and contextual barriers. In this work, we present Pragya, a retrieval-augmented generation (RAG) framework for semantic recommendation of Subhasitas. We curate a dataset of 200 verses annotated with thematic tags such as motivation, friendship, and compassion. Using sentence embeddings (IndicBERT), the system retrieves top-k verses relevant to user queries. The retrieved results are then passed to a generative model (Mistral LLM) to produce transliterations, translations, and contextual explanations. Experimental evaluation demonstrates that semantic retrieval significantly outperforms keyword matching in precision and relevance, while user studies highlight improved accessibility through generated summaries. To our knowledge, this is the first attempt at integrating retrieval and generation for Sanskrit Subhasitas, bridging cultural heritage with modern applied AI.", "AI": {"tldr": "这篇论文介绍了Pragya系统，这是一个基于人工智能的语义推荐系统，用于推荐梵文Subhasitas（格言）。", "motivation": "由于语言和上下文障碍，梵文Subhasitas在数字时代未得到充分利用。通过结合检索增强生成框架，作者旨在提高这些古代智慧文本的可访问性和应用性。", "method": "论文构建了一个包含200个主题标签注释的诗句数据集，并使用IndicBERT模型进行句子嵌入以检索最相关的诗句。然后利用Mistral大型语言模型（LLM）生成诗句的音译、翻译和上下文解释。", "result": "实验结果表明，语义检索在准确性和相关性上显著优于关键词匹配，用户研究显示通过生成摘要提高了可访问性。", "conclusion": "这篇论文是首次尝试将检索增强生成框架应用于梵文Subhasitas的研究，展示了文化传承与现代人工智能技术的有效结合。"}}
{"id": "2601.06606", "pdf": "https://arxiv.org/pdf/2601.06606", "abs": "https://arxiv.org/abs/2601.06606", "authors": ["Rishiraj Saha Roy", "Chris Hinze", "Luzian Hahn", "Fabian Kuech"], "title": "CEDAR: Context Engineering for Agentic Data Science", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ECIR 2026", "summary": "We demonstrate CEDAR, an application for automating data science (DS) tasks with an agentic setup. Solving DS problems with LLMs is an underexplored area that has immense market value. The challenges are manifold: task complexities, data sizes, computational limitations, and context restrictions. We show that these can be alleviated via effective context engineering. We first impose structure into the initial prompt with DS-specific input fields, that serve as instructions for the agentic system. The solution is then materialized as an enumerated sequence of interleaved plan and code blocks generated by separate LLM agents, providing a readable structure to the context at any step of the workflow. Function calls for generating these intermediate texts, and for corresponding Python code, ensure that data stays local, and only aggregate statistics and associated instructions are injected into LLM prompts. Fault tolerance and context management are introduced via iterative code generation and smart history rendering. The viability of our agentic data scientist is demonstrated using canonical Kaggle challenges.", "AI": {"tldr": "CEDAR是一个用于自动化数据科学任务的应用程序，通过有效的上下文工程解决LLM在处理数据科学问题时面临的挑战。", "motivation": "解决使用LLM进行数据科学研究的多个难题：任务复杂性、数据规模、计算限制和上下文约束。这些问题可以通过有效上下文工程来缓解。", "method": "CEDAR应用包括结构化的初始提示，具有特定于数据科学的输入字段作为指令；解决方案由单独的LLM代理生成的计划块和代码块序列组成，确保数据本地化并仅将汇总统计信息注入LLM提示中。通过迭代代码生成和智能历史渲染实现容错性和上下文管理。", "result": "CEDAR的有效性在经典的Kaggle挑战中得到验证。", "conclusion": "CEDAR证明了使用有效上下文工程进行数据科学自动化任务的可行性与价值。"}}
{"id": "2601.06605", "pdf": "https://arxiv.org/pdf/2601.06605", "abs": "https://arxiv.org/abs/2601.06605", "authors": ["Yingying Deng", "Xiangyu He", "Fan Tang", "Weiming Dong", "Xucheng Yin"], "title": "Sissi: Zero-shot Style-guided Image Synthesis via Semantic-style Integration", "categories": ["cs.CV"], "comment": null, "summary": "Text-guided image generation has advanced rapidly with large-scale diffusion models, yet achieving precise stylization with visual exemplars remains difficult. Existing approaches often depend on task-specific retraining or expensive inversion procedures, which can compromise content integrity, reduce style fidelity, and lead to an unsatisfactory trade-off between semantic prompt adherence and style alignment. In this work, we introduce a training-free framework that reformulates style-guided synthesis as an in-context learning task. Guided by textual semantic prompts, our method concatenates a reference style image with a masked target image, leveraging a pretrained ReFlow-based inpainting model to seamlessly integrate semantic content with the desired style through multimodal attention fusion. We further analyze the imbalance and noise sensitivity inherent in multimodal attention fusion and propose a Dynamic Semantic-Style Integration (DSSI) mechanism that reweights attention between textual semantic and style visual tokens, effectively resolving guidance conflicts and enhancing output coherence. Experiments show that our approach achieves high-fidelity stylization with superior semantic-style balance and visual quality, offering a simple yet powerful alternative to complex, artifact-prone prior methods.", "AI": {"tldr": "提出了一种零样本的基于文本指导的图像合成方法，通过语义和风格融合实现高质量的图像生成。", "motivation": "现有的图像生成方法在使用视觉参考进行精准样式化时存在困难，依赖于特定任务的重新训练或昂贵的逆向过程会降低内容完整性和风格保真度，导致语义提示遵从性与风格一致性之间的权衡。", "method": "通过将样式引导合成重构为上下文学习任务，并利用预训练的ReFlow基图像填充模型，在文本语义提示指导下，结合参考样式图和遮罩目标图，进行多模态注意融合。此外还提出了一种动态语义-风格集成机制（DSSI），以解决指导冲突并提高输出一致性。", "result": "实验表明该方法在高保真度的样式化方面表现出色，并且在语义与风格平衡和视觉质量上优于现有的复杂、易产生伪影的方法。", "conclusion": "此研究提供了一种简单而强大的替代方案，能够实现高质量的图像合成，无需复杂的重新训练或逆向过程。"}}
{"id": "2601.06604", "pdf": "https://arxiv.org/pdf/2601.06604", "abs": "https://arxiv.org/abs/2601.06604", "authors": ["Rodion Vakhitov", "Leonid Ugadiarov", "Aleksandr Panov"], "title": "Object-Centric World Models Meet Monte Carlo Tree Search", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "In this paper, we introduce ObjectZero, a novel reinforcement learning (RL) algorithm that leverages the power of object-level representations to model dynamic environments more effectively. Unlike traditional approaches that process the world as a single undifferentiated input, our method employs Graph Neural Networks (GNNs) to capture intricate interactions among multiple objects. These objects, which can be manipulated and interact with each other, serve as the foundation for our model's understanding of the environment. We trained the algorithm in a complex setting teeming with diverse, interactive objects, demonstrating its ability to effectively learn and predict object dynamics. Our results highlight that a structured world model operating on object-centric representations can be successfully integrated into a model-based RL algorithm utilizing Monte Carlo Tree Search as a planning module.", "AI": {"tldr": "本文介绍了ObjectZero算法，利用图神经网络在对象级表示上建模动态环境。", "motivation": "传统方法将世界视为单一输入处理，无法有效捕捉多个对象间的复杂交互。因此，作者提出使用对象级表示来改进强化学习模型对复杂环境的理解和预测能力。", "method": "采用Graph Neural Networks (GNNs) 来捕捉环境中多对象之间的细致互动，并以此为基础构建一个基于对象的结构化世界模型，结合Monte Carlo Tree Search进行计划模块的工作。", "result": "实验结果表明，在包含多样化交互性物体的复杂场景中训练后，该算法能够有效学习和预测对象动态。", "conclusion": "研究表明，基于对象级表示的结构化世界模型可以成功地集成到使用蒙特卡洛树搜索作为规划模块的模型强化学习算法中。"}}
{"id": "2601.06602", "pdf": "https://arxiv.org/pdf/2601.06602", "abs": "https://arxiv.org/abs/2601.06602", "authors": ["Mohammed S. Alharbi", "Shinkyu Park"], "title": "UMLoc: Uncertainty-Aware Map-Constrained Inertial Localization with Quantified Bounds", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Inertial localization is particularly valuable in GPS-denied environments such as indoors. However, localization using only Inertial Measurement Units (IMUs) suffers from drift caused by motion-process noise and sensor biases. This paper introduces Uncertainty-aware Map-constrained Inertial Localization (UMLoc), an end-to-end framework that jointly models IMU uncertainty and map constraints to achieve drift-resilient positioning. UMLoc integrates two coupled modules: (1) a Long Short-Term Memory (LSTM) quantile regressor, which estimates the specific quantiles needed to define 68%, 90%, and 95% prediction intervals serving as a measure of localization uncertainty and (2) a Conditioned Generative Adversarial Network (CGAN) with cross-attention that fuses IMU dynamic data with distance-based floor-plan maps to generate geometrically feasible trajectories. The modules are trained jointly, allowing uncertainty estimates to propagate through the CGAN during trajectory generation. UMLoc was evaluated on three datasets, including a newly collected 2-hour indoor benchmark with time-aligned IMU data, ground-truth poses and floor-plan maps. Results show that the method achieves a mean drift ratio of 5.9% over a 70 m travel distance and an average Absolute Trajectory Error (ATE) of 1.36 m, while maintaining calibrated prediction bounds.", "AI": {"tldr": "UMLoc是一种结合IMU不确定性和地图约束的惯性定位框架，用于GPS受限环境中的精准定位。", "motivation": "在没有GPS信号的环境中（如室内），仅使用IMU进行定位会导致漂移问题，因此需要一种新的方法来提高精确度和鲁棒性。", "method": "UMLoc由两个模块组成：一个LSTM量回归器估计预测区间以量化不确定性；另一个是条件生成对抗网络融合IMU数据与地图信息，产生可行轨迹并传播不确定性的估计。两者共同训练。", "result": "实验表明该方法在70米行程中平均漂移比为5.9%，绝对轨迹误差（ATE）1.36米，并能校准预测边界。", "conclusion": "UMLoc通过结合IMU和地图约束提供了一种精确且鲁棒的定位解决方案，尤其适用于GPS受限环境。"}}
{"id": "2601.06599", "pdf": "https://arxiv.org/pdf/2601.06599", "abs": "https://arxiv.org/abs/2601.06599", "authors": ["Shivam Adarsh", "Maria Maistro", "Christina Lioma"], "title": "How Context Shapes Truth: Geometric Transformations of Statement-level Truth Representations in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) often encode whether a statement is true as a vector in their residual stream activations. These vectors, also known as truth vectors, have been studied in prior work, however how they change when context is introduced remains unexplored. We study this question by measuring (1) the directional change ($θ$) between the truth vectors with and without context and (2) the relative magnitude of the truth vectors upon adding context. Across four LLMs and four datasets, we find that (1) truth vectors are roughly orthogonal in early layers, converge in middle layers, and may stabilize or continue increasing in later layers; (2) adding context generally increases the truth vector magnitude, i.e., the separation between true and false representations in the activation space is amplified; (3) larger models distinguish relevant from irrelevant context mainly through directional change ($θ$), while smaller models show this distinction through magnitude differences. We also find that context conflicting with parametric knowledge produces larger geometric changes than parametrically aligned context. To the best of our knowledge, this is the first work that provides a geometric characterization of how context transforms the truth vector in the activation space of LLMs.", "AI": {"tldr": "该论文探讨了在大型语言模型（LLMs）中，上下文如何影响陈述真值向量的几何变化。", "motivation": "前人研究了大语言模型中的真值向量，但尚未探索引入上下文后的变化。本研究旨在填补这一空白，了解上下文如何改变这些表示。", "method": "通过测量有无上下文时真值向量的方向变化($θ$)和相对大小，跨四种大型语言模型和四个数据集进行研究。", "result": "发现（1）在早期层中，真值向量大致正交，在中间层中趋同，并且在后期可能稳定或继续增加；（2）添加上下文一般增加了真值向量的幅度；（3）大型模型主要通过方向变化区分相关和不相关的背景信息，而小型模型则通过大小差异来实现。", "conclusion": "这是首次对大语言模型中上下文如何转换激活空间中的真理向量进行几何描述的研究。"}}
{"id": "2601.06596", "pdf": "https://arxiv.org/pdf/2601.06596", "abs": "https://arxiv.org/abs/2601.06596", "authors": ["Hongjun An", "Yiliang Song", "Jiangan Chen", "Jiawei Shao", "Chi Zhang", "Xuelong Li"], "title": "Are LLMs Vulnerable to Preference-Undermining Attacks (PUA)? A Factorial Analysis Methodology for Diagnosing the Trade-off between Preference Alignment and Real-World Validity", "categories": ["cs.CR", "cs.AI"], "comment": "preprint", "summary": "Large Language Model (LLM) training often optimizes for preference alignment, rewarding outputs that are perceived as helpful and interaction-friendly. However, this preference-oriented objective can be exploited: manipulative prompts can steer responses toward user-appeasing agreement and away from truth-oriented correction. In this work, we investigate whether aligned models are vulnerable to Preference-Undermining Attacks (PUA), a class of manipulative prompting strategies designed to exploit the model's desire to please user preferences at the expense of truthfulness. We propose a diagnostic methodology that provides a finer-grained and more directive analysis than aggregate benchmark scores, using a factorial evaluation framework to decompose prompt-induced shifts into interpretable effects of system objectives (truth- vs. preference-oriented) and PUA-style dialogue factors (directive control, personal derogation, conditional approval, reality denial) within a controlled $2 \\times 2^4$ design. Surprisingly, more advanced models are sometimes more susceptible to manipulative prompts. Beyond the dominant reality-denial factor, we observe model-specific sign reversals and interactions with PUA-style factors, suggesting tailored defenses rather than uniform robustness. These findings offer a novel, reproducible factorial evaluation methodology that provides finer-grained diagnostics for post-training processes like RLHF, enabling better trade-offs in the product iteration of LLMs by offering a more nuanced understanding of preference alignment risks and the impact of manipulative prompts.", "AI": {"tldr": "该论文研究了大型语言模型是否容易受到偏好转折攻击的影响，并提出了一种因子分析方法来诊断偏好对齐与现实有效性之间的权衡。", "motivation": "优化模型输出以符合用户偏好可能导致模型更容易受误导性提示影响，偏离真相。作者希望通过这种方法理解模型的脆弱性和改进策略。", "method": "该研究使用了2x2^4的设计框架，通过分解诱导的偏移来评估不同因素的影响，并观察更高级的模型在特定攻击下的表现。", "result": "结果显示，在某些情况下，较先进的模型更容易受到误导性提示的影响。此外，发现了一些与现实否定等其他因子相关的特定期望逆转和交互作用。", "conclusion": "该论文提供了一种新的可重复的方法来评估大型语言模型的偏好对齐风险，并为改进后的迭代过程提供了更深入的理解。"}}
{"id": "2601.06574", "pdf": "https://arxiv.org/pdf/2601.06574", "abs": "https://arxiv.org/abs/2601.06574", "authors": ["Dongliang Chen", "Xinlin Zhuang", "Junjie Xu", "Luojian Xie", "Zehui Wang", "Jiaxi Zhuang", "Haolin Yang", "Liang Dou", "Xiao He", "Xingjiao Wu", "Ying Qian"], "title": "APEX: Learning Adaptive Priorities for Multi-Objective Alignment in Vision-Language Generation", "categories": ["cs.CV"], "comment": null, "summary": "Multi-objective alignment for text-to-image generation is commonly implemented via static linear scalarization, but fixed weights often fail under heterogeneous rewards, leading to optimization imbalance where models overfit high-variance, high-responsiveness objectives (e.g., OCR) while under-optimizing perceptual goals. We identify two mechanistic causes: variance hijacking, where reward dispersion induces implicit reweighting that dominates the normalized training signal, and gradient conflicts, where competing objectives produce opposing update directions and trigger seesaw-like oscillations. We propose APEX (Adaptive Priority-based Efficient X-objective Alignment), which stabilizes heterogeneous rewards with Dual-Stage Adaptive Normalization and dynamically schedules objectives via P^3 Adaptive Priorities that combine learning potential, conflict penalty, and progress need. On Stable Diffusion 3.5, APEX achieves improved Pareto trade-offs across four heterogeneous objectives, with balanced gains of +1.31 PickScore, +0.35 DeQA, and +0.53 Aesthetics while maintaining competitive OCR accuracy, mitigating the instability of multi-objective alignment.", "AI": {"tldr": "本文提出了APEX，一种基于自适应优先级的多目标对齐方法，用于文本到图像生成任务。", "motivation": "静态线性标量化在异构奖励下容易导致优化不平衡，使得模型过度拟合高方差、响应度高的目标（如OCR），同时忽略感知目标。这种问题可以通过缓解“变异劫持”和“梯度冲突”来解决。", "method": "APEX采用双阶段自适应归一化稳定异构奖励，并通过P^3自适应优先级动态调度任务，结合学习潜力、冲突惩罚和进度需求。", "result": "在Stable Diffusion 3.5上进行实验，APEX实现了四个不同目标的帕累托均衡改进：+1.31 PickScore， +0.35 DeQA 和 +0.53 Aesthetics，同时保持了OCR准确率的竞争性。", "conclusion": "本文提出的自适应优先级方法能够有效地缓解多目标对齐中的优化不平衡问题，实现更稳定的帕累托均衡。"}}
{"id": "2601.06573", "pdf": "https://arxiv.org/pdf/2601.06573", "abs": "https://arxiv.org/abs/2601.06573", "authors": ["Zixing Lin", "Jiale Wang", "Gee Wah Ng", "Lee Onn Mak", "Chan Zhi Yang Jeriel", "Jun Yang Lee", "Yaohao Li"], "title": "QMAVIS: Long Video-Audio Understanding using Fusion of Large Multimodal Models", "categories": ["cs.AI", "cs.MM"], "comment": null, "summary": "Large Multimodal Models (LMMs) for video-audio understanding have traditionally been evaluated only on shorter videos of a few minutes long. In this paper, we introduce QMAVIS (Q Team-Multimodal Audio Video Intelligent Sensemaking), a novel long video-audio understanding pipeline built through a late fusion of LMMs, Large Language Models, and speech recognition models. QMAVIS addresses the gap in long-form video analytics, particularly for longer videos of a few minutes to beyond an hour long, opening up new potential applica- tions in sensemaking, video content analysis, embodied AI, etc. Quantitative experiments using QMAVIS demonstrated a 38.75% improvement over state-of-the-art video-audio LMMs like Vide- oLlaMA2 and InternVL2 on the VideoMME (with subtitles) dataset, which comprises long videos with audio information. Evaluations on other challenging video understanding datasets like PerceptionTest and EgoSchema saw up to 2% improvement, indicating competitive performance. Qualitative experiments also showed that QMAVIS is able to extract the nuances of different scenes in a long video audio content while understanding the overarching narrative. Ablation studies were also conducted to ascertain the impact of each component in the fusion pipeline.", "AI": {"tldr": "QMAVIS 使用大模态模型和语言模型的融合，提高了长时间视频音频理解的能力。", "motivation": "现有的大规模多模态模型主要用于较短视频的理解，缺少对长时视频的有效分析方法。因此需要一种新的框架来填补这一空白，并提升其在多个领域的应用能力。", "method": "QMAVIS 是通过晚期融合技术结合大模态模型、大型语言模型和语音识别模型构建的长时间视频音频理解流水线。", "result": "实验结果表明，QMAVIS 相较于现有的 VideoLlaMA2 和 InternVL2 在长视频数据集上有了显著的进步，在 VideoMME 数据集中提高了38.75%，并且在其他挑战性的数据集中也有了一定的提升。质性实验也证明了 QMAVIS 能够提取长时间音频视频内容中不同场景的细节和整体叙述。", "conclusion": "QMAVIS 成功地解决了长时视频分析的问题，并且在多个应用场景上显示出了优越的表现，证明其方法的有效性和适用性。"}}
{"id": "2601.06572", "pdf": "https://arxiv.org/pdf/2601.06572", "abs": "https://arxiv.org/abs/2601.06572", "authors": ["Huyen Khanh Vo", "Isabel Valera"], "title": "Hellinger Multimodal Variational Autoencoders", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multimodal variational autoencoders (VAEs) are widely used for weakly supervised generative learning with multiple modalities. Predominant methods aggregate unimodal inference distributions using either a product of experts (PoE), a mixture of experts (MoE), or their combinations to approximate the joint posterior. In this work, we revisit multimodal inference through the lens of probabilistic opinion pooling, an optimization-based approach. We start from Hölder pooling with $α=0.5$, which corresponds to the unique symmetric member of the $α\\text{-divergence}$ family, and derive a moment-matching approximation, termed Hellinger. We then leverage such an approximation to propose HELVAE, a multimodal VAE that avoids sub-sampling, yielding an efficient yet effective model that: (i) learns more expressive latent representations as additional modalities are observed; and (ii) empirically achieves better trade-offs between generative coherence and quality, outperforming state-of-the-art multimodal VAE models.", "AI": {"tldr": "本文提出了一种新的多模态变分自动编码器（VAE）模型HELVAE，通过概率意见合并的方法来优化多模态推理。", "motivation": "现有方法主要采用产品专家、混合专家或其组合方式聚合单模态推断分布以逼近联合后验，这种方法存在采样不足的问题。为了改善这一情况，并提升生成一致性和质量，作者提出了新的解决方案。", "method": "通过霍尔德合并法（Hölder pooling）以及$α=0.5$的特殊情况——对称成员的$α\text{-divergence}$家族来推导出赫林格（Hellinger）近似，并基于此提出HELVAE模型。", "result": "实验结果显示，所提出的HELVAE模型在避免子采样的情况下，学习更丰富的潜在表示，且生成一致性和质量均优于现有的多模态变分自动编码器。", "conclusion": "本文通过概率意见合并的方法重新审视了多模态推理，并提出了新的HELVAE模型。该模型有效解决了现有方法中的不足，表现出色。"}}
{"id": "2601.06566", "pdf": "https://arxiv.org/pdf/2601.06566", "abs": "https://arxiv.org/abs/2601.06566", "authors": ["Jiale Wang", "Gee Wah Ng", "Lee Onn Mak", "Randall Cher", "Ng Ding Hei Ryan", "Davis Wang"], "title": "QCaption: Video Captioning and Q&A through Fusion of Large Multimodal Models", "categories": ["cs.CV", "cs.AI"], "comment": "ef:Proceedings of the 27th International Conference on Information Fusion (FUSION), 2024, pp. 1-8", "summary": "This paper introduces QCaption, a novel video captioning and Q&A pipeline that enhances video analytics by fusing three models: key frame extraction, a Large Multimodal Model (LMM) for image-text analysis, and a Large Language Model (LLM) for text analysis. This approach enables integrated analysis of text, images, and video, achieving performance improvements over existing video captioning and Q&A models; all while remaining fully self-contained, adept for on-premises deployment. Experimental results using QCaption demonstrated up to 44.2% and 48.9% improvements in video captioning and Q&A tasks, respectively. Ablation studies were also performed to assess the role of LLM on the fusion on the results. Moreover, the paper proposes and evaluates additional video captioning approaches, benchmarking them against QCaption and existing methodologies. QCaption demonstrate the potential of adopting a model fusion approach in advancing video analytics.", "AI": {"tldr": "本文介绍了QCaption，一种通过融合大型多模态模型和大型语言模型来提升视频分析的创新管道。", "motivation": "为了增强视频分析能力，特别是在视频描述和问答任务上取得更好的表现，并实现易于部署的目标，作者提出了QCaption。", "method": "该方法包括关键帧提取、用于图像-文本分析的大规模多模态模型以及用于文本分析的大规模语言模型的融合。", "result": "实验结果显示，在视频描述和问答任务中，使用QCaption分别实现了44.2%和48.9%的性能提升。此外，还进行了消融研究以评估大型语言模型在结果中的作用，并对额外的视频描述方法进行了基准测试。", "conclusion": "QCaption展示了采用模型融合策略来推进视频分析领域的潜力。"}}
{"id": "2601.06560", "pdf": "https://arxiv.org/pdf/2601.06560", "abs": "https://arxiv.org/abs/2601.06560", "authors": ["K. A. Shahriar"], "title": "Lightweight Resolution-Aware Audio Deepfake Detection via Cross-Scale Attention and Consistency Learning", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "Audio deepfake detection has become increasingly challenging due to rapid advances in speech synthesis and voice conversion technologies, particularly under channel distortions, replay attacks, and real-world recording conditions. This paper proposes a resolution-aware audio deepfake detection framework that explicitly models and aligns multi-resolution spectral representations through cross-scale attention and consistency learning. Unlike conventional single-resolution or implicit feature-fusion approaches, the proposed method enforces agreement across complementary time--frequency scales. The proposed framework is evaluated on three representative benchmarks: ASVspoof 2019 (LA and PA), the Fake-or-Real (FoR) dataset, and the In-the-Wild Audio Deepfake dataset under a speaker-disjoint protocol. The method achieves near-perfect performance on ASVspoof LA (EER 0.16%), strong robustness on ASVspoof PA (EER 5.09%), FoR rerecorded audio (EER 4.54%), and in-the-wild deepfakes (AUC 0.98, EER 4.81%), significantly outperforming single-resolution and non-attention baselines under challenging conditions. The proposed model remains lightweight and efficient, requiring only 159k parameters and less than 1~GFLOP per inference, making it suitable for practical deployment. Comprehensive ablation studies confirm the critical contributions of cross-scale attention and consistency learning, while gradient-based interpretability analysis reveals that the model learns resolution-consistent and semantically meaningful spectral cues across diverse spoofing conditions. These results demonstrate that explicit cross-resolution modeling provides a principled, robust, and scalable foundation for next-generation audio deepfake detection systems.", "AI": {"tldr": "本文提出了一种轻量级的音频深度伪造检测框架，通过跨尺度注意和一致性学习来显式建模并对齐多分辨率频谱表示。", "motivation": "由于语音合成和声音转换技术的快速进步，在通道失真、重播攻击以及现实录音条件下进行音频深度伪造检测变得越来越具有挑战性。因此，需要一种新的方法来有效应对这些复杂条件下的问题。", "method": "该框架通过跨尺度注意机制显式建模多分辨率频谱表示，并采用一致性学习使不同的时间-频率尺度之间达成一致。相比传统的单一分辨率或隐含特征融合的方法，这种方法能够在互补的时间-频率尺度间强制执行协议。", "result": "在三个具有代表性的基准数据集上进行了评估：ASVspoof 2019（LA和PA）、Fake-or-Real（FoR）数据集以及野外音频深度伪造数据集。该方法在ASVspoof LA中的等错误率仅为0.16%，展示了近乎完美的性能；对ASVspoof PA、FoR重录制音频以及野外深度伪造的等错误率分别达到5.09%和4.81%；其AUC值达到了0.98，显著优于单分辨率和无注意力基线模型。", "conclusion": "该文提出的方法通过显式跨分辨率建模提供了一个原则性的、稳健且可扩展的基础来解决下一代音频深度伪造检测系统中的问题。此外，实验表明跨尺度注意机制和一致性学习对于提升性能至关重要，并且模型能够从多种欺骗条件下学习到分辨率一致的语义频谱线索。"}}
{"id": "2601.06559", "pdf": "https://arxiv.org/pdf/2601.06559", "abs": "https://arxiv.org/abs/2601.06559", "authors": ["Fangxu Yu", "Ziyao Lu", "Liqiang Niu", "Fandong Meng", "Jie Zhou"], "title": "ArrowGEV: Grounding Events in Video via Learning the Arrow of Time", "categories": ["cs.CV"], "comment": null, "summary": "Grounding events in videos serves as a fundamental capability in video analysis. While Vision-Language Models (VLMs) are increasingly employed for this task, existing approaches predominantly train models to associate events with timestamps in the forward video only. This paradigm hinders VLMs from capturing the inherent temporal structure and directionality of events, thereby limiting robustness and generalization. To address this limitation, inspired by the arrow of time in physics, which characterizes the intrinsic directionality of temporal processes, we propose ArrowGEV, a reinforcement learning framework that explicitly models temporal directionality in events to improve both event grounding and temporal directionality understanding in VLMs. Specifically, we categorize events into time-sensitive (e.g., putting down a bag) and time-insensitive (e.g., holding a towel in the left hand). The former denote events whose reversal substantially alters their meaning, while the latter remain semantically unchanged under reversal. For time-sensitive events, ArrowGEV introduces a reward that encourages VLMs to discriminate between forward and backward videos, whereas for time-insensitive events, it enforces consistent grounding across both directions. Extensive experiments demonstrate that ArrowGEV not only improves grounding precision and temporal directionality recognition, but also enhances general video understanding and reasoning ability.", "AI": {"tldr": "提出了ArrowGEV框架，通过引入时间方向性来改进视频中的事件接地。", "motivation": "现有方法主要训练模型仅在正向视频中关联事件与时间戳，这限制了模型捕捉事件内在的时间结构和方向性的能力。为此，提出了一种新的强化学习框架以增强视频理解和推理。", "method": "将事件分为对时序敏感的（例如放下包）和不敏感的（例如左手拿着毛巾）。对于前者，引入奖励机制来鼓励VLM区分正向与反向视频；后者则要求在两个方向上保持一致接地。", "result": "实验结果表明，ArrowGEV提高了事件接地精度、时间方向性识别能力以及总体视频理解和推理性能。", "conclusion": "通过模拟时间箭头原理，增强了VLM对视频中事件时间方向性的理解，并提升了其视频分析的整体效能。"}}
{"id": "2601.06558", "pdf": "https://arxiv.org/pdf/2601.06558", "abs": "https://arxiv.org/abs/2601.06558", "authors": ["Jiao Xu", "Peng Li", "Bing Zheng"], "title": "Hard Thresholding Pursuit Algorithms for Least Absolute Deviations Problem", "categories": ["cs.IT", "cs.CV"], "comment": null, "summary": "Least absolute deviations (LAD) is a statistical optimality criterion widely utilized in scenarios where a minority of measurements are contaminated by outliers of arbitrary magnitudes. In this paper, we delve into the robustness of the variant of adaptive iterative hard thresholding to outliers, known as graded fast hard thresholding pursuit (GFHTP$_1$) algorithm. Unlike the majority of the state-of-the-art algorithms in this field, GFHTP$_1$ does not require prior information about the signal's sparsity. Moreover, its design is parameterless, which not only simplifies the implementation process but also removes the intricacies of parameter optimization. Numerical experiments reveal that the GFHTP$_1$ algorithm consistently outperforms competing algorithms in terms of both robustness and computational efficiency.", "AI": {"tldr": "本文探讨了针对含有任意幅度异常值的测量数据，利用最小绝对偏差准则进行信号恢复时，一种改进的自适应迭代硬阈值算法（GFHTP_1）的应用。", "motivation": "在存在少数异常值的情况下，传统的优化方法往往不适用。因此，开发一种不需要先验稀疏信息且参数无须调优的高效鲁棒算法变得尤为重要。", "method": "提出了一种改进的自适应迭代硬阈值算法（GFHTP_1），该算法通过分级快速硬阈值技术处理最小绝对偏差问题，并展示了其在无需信号稀疏度先验条件下的有效性。", "result": "实验结果表明，与现有方法相比，GFHTP_1算法无论是在鲁棒性还是计算效率方面都表现出色。", "conclusion": "提出的GFHTP_1算法提供了一种处理含有异常值的测量数据的有效解决方案，并证明了其在最小绝对偏差问题中的优越性能。"}}
{"id": "2601.06552", "pdf": "https://arxiv.org/pdf/2601.06552", "abs": "https://arxiv.org/abs/2601.06552", "authors": ["Britt Besch", "Tai Mai", "Jeremias Thun", "Markus Huff", "Jörn Vogel", "Freek Stulp", "Samuel Bustamante"], "title": "Model Reconciliation through Explainability and Collaborative Recovery in Assistive Robotics", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "Whenever humans and robots work together, it is essential that unexpected robot behavior can be explained to the user. Especially in applications such as shared control the user and the robot must share the same model of the objects in the world, and the actions that can be performed on these objects. In this paper, we achieve this with a so-called model reconciliation framework. We leverage a Large Language Model to predict and explain the difference between the robot's and the human's mental models, without the need of a formal mental model of the user. Furthermore, our framework aims to solve the model divergence after the explanation by allowing the human to correct the robot. We provide an implementation in an assistive robotics domain, where we conduct a set of experiments with a real wheelchair-based mobile manipulator and its digital twin.", "AI": {"tldr": "本文提出了一种模型协调框架，通过解释和协作恢复来解决人机交互中的模型分歧问题。", "motivation": "在人机共享控制应用中，确保机器人行为可以被用户理解是必要的。当人类与机器人共同工作时，他们需要对环境中的物体及其可执行的动作有一个共同的理解模型。", "method": "利用大型语言模型预测和解释机器人和用户的思维模型之间的差异，并通过允许用户纠正机器人的行为来解决这种分歧问题。此方法在辅助机器人领域进行了实现并测试了一个基于轮椅的移动机械臂及其实体副本。", "result": "实验结果表明，该框架能够有效解决人机交互中的模型分歧，提高了系统的协作效率和用户体验。", "conclusion": "通过引入解释性和协作恢复机制，本文提出的模型协调框架成功地解决了共享控制场景下的用户与机器人之间的思维模型差异问题。"}}
{"id": "2601.06551", "pdf": "https://arxiv.org/pdf/2601.06551", "abs": "https://arxiv.org/abs/2601.06551", "authors": ["Sergii Voloshyn"], "title": "L-RAG: Balancing Context and Retrieval with Entropy-Based Lazy Loading", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has emerged as the predominant paradigm for grounding Large Language Model outputs in factual knowledge, effectively mitigating hallucinations. However, conventional RAG systems operate under a \"retrieve-always\" assumption, querying vector databases for every input regardless of query complexity. This static approach incurs substantial computational overhead and inference latency, particularly problematic for high-throughput production deployments. We introduce L-RAG (Lazy Retrieval-Augmented Generation), an adaptive framework that implements hierarchical context management through entropy-based gating. L-RAG employs a two-tier architecture: queries are first processed with a compact document summary, and expensive chunk retrieval is triggered only when the model's predictive entropy exceeds a calibrated threshold, signaling genuine uncertainty. Through experiments on SQuAD 2.0 (N=500) using the Phi-2 model, we demonstrate that L-RAG provides a tunable accuracy-efficiency trade-off: at a conservative threshold (tau=0.5), L-RAG achieves 78.2% accuracy, matching Standard RAG (77.8%), with 8% retrieval reduction; at a balanced threshold (tau=1.0), retrieval reduction increases to 26% with modest accuracy trade-off (76.0%). Latency analysis shows that L-RAG saves 80-210ms per query when retrieval latency exceeds 500ms. Analysis of entropy distributions reveals statistically significant separation (p < 0.001) between correct predictions (H=1.72) and errors (H=2.20), validating entropy as a reliable uncertainty signal. L-RAG offers a practical, training-free approach toward more efficient RAG deployment, providing system architects with a configurable knob to balance accuracy and throughput requirements.", "AI": {"tldr": "介绍了一种新的检索增强生成框架L-RAG，通过熵门控实现上下文管理和检索的动态平衡。", "motivation": "传统的RAG系统由于固定的'总是检索'策略，在处理复杂查询时会增加计算开销和推理延迟，导致高吞吐量部署中的问题。因此，需要一种更灵活的方法来优化效率与准确性之间的权衡。", "method": "L-RAG通过两级架构实现：首先使用紧凑的文档摘要处理查询，只有当模型预测熵超过预设阈值时才进行昂贵的数据检索操作。这种基于熵的门控机制允许在不确定性高的情况下触发检索，并减少低概率事件中的不必要开销。", "result": "实验表明，在SQuAD 2.0数据集上使用Phi-2模型，L-RAG可以在不同的配置下实现准确率和效率之间的权衡：例如，保守阈值(tau=0.5)下的准确率为78.2%，与标准RAG相当(77.8%)且检索减少了8%；平衡阈值(tau=1.0)时，检索减少至26%，但准确性略有下降到76.0%。此外，在检索延迟超过500ms的情况下，L-RAG节省了每次查询的80-210毫秒。", "conclusion": "L-RAG提供了一种实用且无需训练的方法来提高RAG部署效率，并为系统架构师提供了可配置的开关以根据准确性与吞吐量需求进行调整。"}}
{"id": "2601.06550", "pdf": "https://arxiv.org/pdf/2601.06550", "abs": "https://arxiv.org/abs/2601.06550", "authors": ["Pan Liao", "Feng Yang", "Di Wu", "Jinwen Yu", "Yuhua Zhu", "Wenhui Zhao"], "title": "LLMTrack: Semantic Multi-Object Tracking with Multi-modal Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Traditional Multi-Object Tracking (MOT) systems have achieved remarkable precision in localization and association, effectively answering \\textit{where} and \\textit{who}. However, they often function as autistic observers, capable of tracing geometric paths but blind to the semantic \\textit{what} and \\textit{why} behind object behaviors. To bridge the gap between geometric perception and cognitive reasoning, we propose \\textbf{LLMTrack}, a novel end-to-end framework for Semantic Multi-Object Tracking (SMOT). We adopt a bionic design philosophy that decouples strong localization from deep understanding, utilizing Grounding DINO as the eyes and the LLaVA-OneVision multimodal large model as the brain. We introduce a Spatio-Temporal Fusion Module that aggregates instance-level interaction features and video-level contexts, enabling the Large Language Model (LLM) to comprehend complex trajectories. Furthermore, we design a progressive three-stage training strategy, Visual Alignment, Temporal Fine-tuning, and Semantic Injection via LoRA to efficiently adapt the massive model to the tracking domain. Extensive experiments on the BenSMOT benchmark demonstrate that LLMTrack achieves state-of-the-art performance, significantly outperforming existing methods in instance description, interaction recognition, and video summarization while maintaining robust tracking stability.", "AI": {"tldr": "提出了一种新的端到端框架LLMTrack，用于语义多目标跟踪（SMOT），结合了Grounding DINO和多模态大模型LLaVA-OneVision。", "motivation": "传统多目标跟踪系统在定位和关联方面表现出色，但往往缺乏对对象行为背后意义的理解。为弥合几何感知与认知推理之间的差距而提出LLMTrack。", "method": "采用生物学设计哲学将强大的定位能力与深度理解解耦，引入时空融合模块来聚合实例交互特征和视频上下文，并通过视觉校准、时间微调和语义注入阶段训练模型。", "result": "实验结果表明，在实例描述、交互识别和视频总结方面，LLMTrack优于现有方法并具有强大的跟踪稳定性。", "conclusion": "LLMTrack是首个结合多模态大语言模型的端到端SMOT框架，展示了其在理解复杂轨迹方面的潜力。"}}
{"id": "2601.06543", "pdf": "https://arxiv.org/pdf/2601.06543", "abs": "https://arxiv.org/abs/2601.06543", "authors": ["Jun-Qi Chen", "Kun Zhang", "Rui Zheng", "Ying Zhong"], "title": "SimLLM: Fine-Tuning Code LLMs for SimPy-Based Queueing System Simulation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "33 pages, 10 figures", "summary": "The Python package SimPy is widely used for modeling queueing systems due to its flexibility, simplicity, and smooth integration with modern data analysis and optimization frameworks. Recent advances in large language models (LLMs) have shown strong ability in generating clear and executable code, making them powerful and suitable tools for writing SimPy queueing simulation code. However, directly employing closed-source models like GPT-4o to generate such code may lead to high computational costs and raise data privacy concerns. To address this, we fine-tune two open-source LLMs, Qwen-Coder-7B and DeepSeek-Coder-6.7B, on curated SimPy queueing data, which enhances their code-generating performance in executability, output-format compliance, and instruction-code consistency. Particularly, we proposed a multi-stage fine-tuning framework comprising two stages of supervised fine-tuning (SFT) and one stage of direct preference optimization (DPO), progressively enhancing the model's ability in SimPy-based queueing simulation code generation. Extensive evaluations demonstrate that both fine-tuned models achieve substantial improvements in executability, output-format compliance, and instruct consistency. These results confirm that domain-specific fine-tuning can effectively transform compact open-source code models into reliable SimPy simulation generators which provide a practical alternative to closed-source LLMs for education, research, and operational decision support.", "AI": {"tldr": "本文通过微调开源代码大型语言模型，提高其在SimPy队列仿真中的性能。", "motivation": "使用闭源LLM生成SimPy仿真代码可能导致计算成本高和数据隐私问题。因此，开发了一种方法来优化开源模型以提升其在特定领域的代码生成能力。", "method": "通过设计多阶段微调框架，包括两个监督微调（SFT）阶段和一个直接偏好优化（DPO）阶段，对两个开源LLM进行训练。", "result": "实验表明，微调后的模型在可执行性、输出格式合规性和指令代码一致性方面都取得了显著改进。", "conclusion": "结果证明了领域特定的微调方法可以将小型开源模型转化为可靠的SimPy仿真生成器，并为教育、研究和决策支持提供了实际替代方案。"}}
{"id": "2601.06542", "pdf": "https://arxiv.org/pdf/2601.06542", "abs": "https://arxiv.org/abs/2601.06542", "authors": ["Corentin Juvigny", "Antonín Novák", "Jan Mandík", "Zdeněk Hanzálek"], "title": "Resource-constrained Project Scheduling with Time-of-Use Energy Tariffs and Machine States: A Logic-based Benders Decomposition Approach", "categories": ["math.OC", "cs.AI"], "comment": null, "summary": "In this paper, we investigate the Resource-Constrained Project Scheduling Problem (RCPSP) with time-of-use energy tariffs (TOU) and machine states, a variant of RCPSP for production scheduling where energy price is part of the criteria and one machine is highly energy-demanding and can be in one of the following three states: proc, idle, or off. The problem involves scheduling all tasks, respecting precedence constraints and resource limitations, while minimizing the combination of the overall makespan and the total energy cost (TEC), which varies according to the TOU pricing, which can take negative values. We propose two novel approaches to solve it: a monolithic Constraint Programming (CP) approach and a Logic-Based Benders Decomposition (LBBD) approach. The latter combines a master problem dealing with energy cost solved using Integer Linear Programming (ILP) with a subproblem handling the RCPSP resolved using CP. Both approaches surpass the monolithic compact ILP approach, but the LBBD significantly outperforms the CP when the ratio of energy-intensive tasks over the overall tasks is moderate, allowing for solving instances with up to 1600 tasks in sparse instances. Finally, we put forth a way of generalizing our LBBD approach to other problems sharing similar characteristics, and we applied it to a problem based on an RCPSP problem with blocking times & total weighted tardiness criterion and a flexible job shop.", "AI": {"tldr": "研究在时间使用电价和机器状态下的资源受限项目调度问题，提出了一种逻辑基于剪枝分解法。", "motivation": "解决生产调度中能源成本成为重要考虑因素的问题，并处理高能耗机器的三种工作状态：运行、空闲或关机。目标是同时最小化整体完工时间和总能源成本。", "method": "提出了两种方法来求解该问题，一种是单一的约束编程方法，另一种是逻辑基于剪枝分解法（LBBD）。后者结合了一个主问题和一个子问题，主问题使用整数线性规划解决能量费用，而子问题则利用约束编程处理RCPSP。", "result": "所提出的两种方法优于单纯的紧凑型ILP方法。在中等能源密集任务比例的情况下，LBBD法表现尤为突出，能够处理多达1600个任务的稀疏实例。", "conclusion": "通过提出的方法有效解决了具有时间使用电价和机器状态约束下的资源受限项目调度问题，并展示了该逻辑基于剪枝分解方法可以应用于其他类似特性的问题。"}}
{"id": "2601.06537", "pdf": "https://arxiv.org/pdf/2601.06537", "abs": "https://arxiv.org/abs/2601.06537", "authors": ["Wiktor Mucha", "Michael Wray", "Martin Kampel"], "title": "Towards Egocentric 3D Hand Pose Estimation in Unseen Domains", "categories": ["cs.CV"], "comment": "Accepted at WACV 2026", "summary": "We present V-HPOT, a novel approach for improving the cross-domain performance of 3D hand pose estimation from egocentric images across diverse, unseen domains. State-of-the-art methods demonstrate strong performance when trained and tested within the same domain. However, they struggle to generalise to new environments due to limited training data and depth perception -- overfitting to specific camera intrinsics. Our method addresses this by estimating keypoint z-coordinates in a virtual camera space, normalised by focal length and image size, enabling camera-agnostic depth prediction. We further leverage this invariance to camera intrinsics to propose a self-supervised test-time optimisation strategy that refines the model's depth perception during inference. This is achieved by applying a 3D consistency loss between predicted and in-space scale-transformed hand poses, allowing the model to adapt to target domain characteristics without requiring ground truth annotations. V-HPOT significantly improves 3D hand pose estimation performance in cross-domain scenarios, achieving a 71% reduction in mean pose error on the H2O dataset and a 41% reduction on the AssemblyHands dataset. Compared to state-of-the-art methods, V-HPOT outperforms all single-stage approaches across all datasets and competes closely with two-stage methods, despite needing approximately x3.5 to x14 less data.", "AI": {"tldr": "提出了一种新的方法V-HPOT，用于改进从第一视角图像跨不同未知领域进行三维手部姿态估计的性能。", "motivation": "现有方法在同源训练和测试中表现良好，但在新环境中泛化能力差。原因是缺少训练数据以及对相机参数的过度拟合。", "method": "V-HPOT通过在虚拟摄像机空间中估计关键点z坐标，并归一化焦距与图像大小来实现对相机属性不变性的利用。提出了一种无监督测试时间优化策略，以改进深度感知，在推断期间允许模型适应目标领域的特性而无需真实标记。", "result": "V-HPOT在交叉领域场景中的三维手部姿态估计性能有显著提高，分别减少了H2O数据集和AssemblyHands数据集中71%和41%的平均位置误差。与现有方法相比，在所有数据集中表现优于单阶段方法，并且与两阶段方法竞争。", "conclusion": "V-HPOT证明了在跨不同领域进行三维手部姿态估计时，改进模型对未知环境的适应性是可能的，即使使用较少的数据也能够实现这一目标。"}}
{"id": "2601.06533", "pdf": "https://arxiv.org/pdf/2601.06533", "abs": "https://arxiv.org/abs/2601.06533", "authors": ["Qi Dong", "Rubing Huang", "Ling Zhou", "Dave Towey", "Jinyu Tian", "Jianzhou Wang"], "title": "Short-term electricity load forecasting with multi-frequency reconstruction diffusion", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion models have emerged as a powerful method in various applications. However, their application to Short-Term Electricity Load Forecasting (STELF) -- a typical scenario in energy systems -- remains largely unexplored. Considering the nonlinear and fluctuating characteristics of the load data, effectively utilizing the powerful modeling capabilities of diffusion models to enhance STELF accuracy remains a challenge. This paper proposes a novel diffusion model with multi-frequency reconstruction for STELF, referred to as the Multi-Frequency-Reconstruction-based Diffusion (MFRD) model. The MFRD model achieves accurate load forecasting through four key steps: (1) The original data is combined with the decomposed multi-frequency modes to form a new data representation; (2) The diffusion model adds noise to the new data, effectively reducing and weakening the noise in the original data; (3) The reverse process adopts a denoising network that combines Long Short-Term Memory (LSTM) and Transformer to enhance noise removal; and (4) The inference process generates the final predictions based on the trained denoising network. To validate the effectiveness of the MFRD model, we conducted experiments on two data platforms: Australian Energy Market Operator (AEMO) and Independent System Operator of New England (ISO-NE). The experimental results show that our model consistently outperforms the compared models.", "AI": {"tldr": "本文提出了一种基于多频重建的扩散模型（MFRD）用于短期电力负荷预测。", "motivation": "扩散模型在各种应用中表现出强大的能力，但在短期电力负荷预测中的应用尚不充分。考虑电力负载数据的非线性和波动特性，如何利用扩散模型提高预测准确性是一个挑战。", "method": "通过将原始数据与分解后的多频模式组合形成新的数据表示；向新数据添加噪声以有效减少原始数据中的噪声；采用结合LSTM和Transformer的去噪网络增强噪声移除效果；基于训练好的去噪网络生成最终预测。", "result": "实验结果表明，MFRD模型在两个数据平台上的性能优于对比模型。", "conclusion": "提出的多频重建扩散模型可以更准确地进行短期电力负荷预测。"}}
{"id": "2601.06530", "pdf": "https://arxiv.org/pdf/2601.06530", "abs": "https://arxiv.org/abs/2601.06530", "authors": ["Bowen Zhang", "Hongda Tian", "Adam Berry", "A. Craig Roussac"], "title": "Improving Day-Ahead Grid Carbon Intensity Forecasting by Joint Modeling of Local-Temporal and Cross-Variable Dependencies Across Different Frequencies", "categories": ["cs.LG", "cs.AI"], "comment": "2026 40th AAAI Conference on Artificial Intelligence", "summary": "Accurate forecasting of the grid carbon intensity factor (CIF) is critical for enabling demand-side management and reducing emissions in modern electricity systems. Leveraging multiple interrelated time series, CIF prediction is typically formulated as a multivariate time series forecasting problem. Despite advances in deep learning-based methods, it remains challenging to capture the fine-grained local-temporal dependencies, dynamic higher-order cross-variable dependencies, and complex multi-frequency patterns for CIF forecasting. To address these issues, we propose a novel model that integrates two parallel modules: 1) one enhances the extraction of local-temporal dependencies under multi-frequency by applying multiple wavelet-based convolutional kernels to overlapping patches of varying lengths; 2) the other captures dynamic cross-variable dependencies under multi-frequency to model how inter-variable relationships evolve across the time-frequency domain. Evaluations on four representative electricity markets from Australia, featuring varying levels of renewable penetration, demonstrate that the proposed method outperforms the state-of-the-art models. An ablation study further validates the complementary benefits of the two proposed modules. Designed with built-in interpretability, the proposed model also enables better understanding of its predictive behavior, as shown in a case study where it adaptively shifts attention to relevant variables and time intervals during a disruptive event.", "AI": {"tldr": "本文提出了一种改进电网碳强度预测的方法，通过联合建模局部时间依赖性和跨变量依赖性。", "motivation": "准确的电网碳强度因子(CIF)预测对于现代电力系统的供需管理及减排至关重要。然而，当前方法难以捕捉到细粒度的时间相关性、动态高阶跨变量关系以及复杂的多频段模式。", "method": "本文提出了一种新的模型，该模型包含两个平行模块：1）通过应用多个基于小波的卷积核来增强对不同频段局部时间依赖性的提取；2）捕捉动态跨变量依赖性以建模随时间和频率变化下的变量关系。", "result": "实证研究表明，在澳大利亚四个代表性电力市场上，所提方法优于现有的最佳模型。消融实验进一步验证了两个模块的互补优势，并且该模型具有内置可解释性。", "conclusion": "通过联合建模局部时间依赖性和跨变量依赖性，本文提出的方法能够更准确地预测电网碳强度因子，有助于实现更好的电力系统管理及减排目标。"}}
{"id": "2601.06528", "pdf": "https://arxiv.org/pdf/2601.06528", "abs": "https://arxiv.org/abs/2601.06528", "authors": ["Minghui Huang"], "title": "Atomic-SNLI: Fine-Grained Natural Language Inference through Atomic Fact Decomposition", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Current Natural Language Inference (NLI) systems primarily operate at the sentence level, providing black-box decisions that lack explanatory power. While atomic-level NLI offers a promising alternative by decomposing hypotheses into individual facts, we demonstrate that the conventional assumption that a hypothesis is entailed only when all its atomic facts are entailed fails in practice due to models' poor performance on fine-grained reasoning. Our analysis reveals that existing models perform substantially worse on atomic level inference compared to sentence level tasks. To address this limitation, we introduce Atomic-SNLI, a novel dataset constructed by decomposing SNLI and enriching it with carefully curated atomic level examples through linguistically informed generation strategies. Experimental results demonstrate that models fine-tuned on Atomic-SNLI achieve significant improvements in atomic reasoning capabilities while maintaining strong sentence level performance, enabling both accurate judgements and transparent, explainable results at the fact level.", "AI": {"tldr": "原子SNLI通过分解假设到个体事实来提升自然语言推理的精确性和可解释性。", "motivation": "现有NLI系统在句子层面操作，缺乏细致的解释能力。而传统的原子级假设推断方法因模型性能不足难以实现。研究旨在解决这一问题并提供更细粒度、透明的结果。", "method": "构建了新的原子SNLI数据集，通过语言学策略生成原子级别的示例，并评估经过该数据集微调后模型的改进效果。", "result": "实验表明，使用Atomic-SNLI训练的模型在原子推理能力上有了显著提升，同时保持了句子层面的表现力。", "conclusion": "提出的原子SNLI为自然语言推断提供了更加细粒度和解释性的解决方案。"}}
{"id": "2601.06527", "pdf": "https://arxiv.org/pdf/2601.06527", "abs": "https://arxiv.org/abs/2601.06527", "authors": ["Wataru Uemura", "Shogo Kawasaki"], "title": "Visible Light Communication using Led-Based AR Markers for Robot Localization", "categories": ["cs.IT", "cs.RO", "eess.IV"], "comment": null, "summary": "A method of information transmission using visual markers has been widely studied. In this approach, information or identifiers (IDs) are encoded in the black-and-white pattern of each marker. By analyzing the geometric properties of the marker frame - such as its size, distortion, and coordinates - the relative position and orientation between the camera and the marker can be estimated. Furthermore, by associating the positional information of each marker with its corresponding ID, the position of the camera that takes the image picture can be calculated. In the field of mobile robotics, such markers are commonly utilized for robot localization. As mobile robots become more widely used in everyday environments, such visual markers are expected to be utilized across various contexts. In environments where robots collaborate with humans - such as in cell-based manufacturing systems in factories or in domestic settings with partner robots - it is desirable for such markers to be designed in a manner that appears natural and unobtrusive to humans. In this paper, we propose a method for implementing an ArUco marker in the form of illumination. In the proposed method, LEDs are arranged in accordance with the grid pattern of the marker, and the blinking frequency of each LED is determined based on the corresponding black or white cell. As a result, the illumination appears uniformly bright to the human eye, while the camera can capture variations in the blinking frequency. From these differences, the black-and-white pattern can be reconstructed, enabling the identification of the marker's tag information. We develop a prototype system, and conduct experiments which are conducted to evaluate its performance in terms of recognition accuracy under varying distances and viewing angles with respect to the ArUco marker.", "AI": {"tldr": "本文提出了一种使用LED灯光的ArUco标记方法，用于机器人定位。", "motivation": "在人机协作环境中，设计自然且不显眼的视觉标记是必要的。通过利用LED灯闪烁频率的不同来实现这种标记，使人类难以察觉但摄像头可以识别。", "method": "将LED按照网格图案排列，并根据每个单元格的颜色（黑色或白色）设定不同频率的闪烁。由此，灯光对人眼显得均匀明亮，而摄像头则能捕捉到这些变化并重建黑白图案，进而识别标签信息。", "result": "通过原型系统的实验测试，在不同的距离和视角下评估了这种标记方法的识别准确性。", "conclusion": "研究表明，所提出的基于LED照明的ArUco标记方法在机器人定位中有很好的应用前景。"}}
{"id": "2601.06525", "pdf": "https://arxiv.org/pdf/2601.06525", "abs": "https://arxiv.org/abs/2601.06525", "authors": ["Yuanting Gao", "Shuo Cao", "Xiaohui Li", "Yuandong Pu", "Yihao Liu", "Kai Zhang"], "title": "Toward Generalizable Deblurring: Leveraging Massive Blur Priors with Linear Attention for Real-World Scenarios", "categories": ["cs.CV"], "comment": "19 pages, 14 figures, 6 tables", "summary": "Image deblurring has advanced rapidly with deep learning, yet most methods exhibit poor generalization beyond their training datasets, with performance dropping significantly in real-world scenarios. Our analysis shows this limitation stems from two factors: datasets face an inherent trade-off between realism and coverage of diverse blur patterns, and algorithmic designs remain restrictive, as pixel-wise losses drive models toward local detail recovery while overlooking structural and semantic consistency, whereas diffusion-based approaches, though perceptually strong, still fail to generalize when trained on narrow datasets with simplistic strategies. Through systematic investigation, we identify blur pattern diversity as the decisive factor for robust generalization and propose Blur Pattern Pretraining (BPP), which acquires blur priors from simulation datasets and transfers them through joint fine-tuning on real data. We further introduce Motion and Semantic Guidance (MoSeG) to strengthen blur priors under severe degradation, and integrate it into GLOWDeblur, a Generalizable reaL-wOrld lightWeight Deblur model that combines convolution-based pre-reconstruction & domain alignment module with a lightweight diffusion backbone. Extensive experiments on six widely-used benchmarks and two real-world datasets validate our approach, confirming the importance of blur priors for robust generalization and demonstrating that the lightweight design of GLOWDeblur ensures practicality in real-world applications. The project page is available at https://vegdog007.github.io/GLOWDeblur_Website/.", "AI": {"tldr": "论文提出了一种新的图像去模糊方法GLOWDeblur，通过大规模的模糊先验和线性注意力机制来提高在现实世界场景中的泛化能力。", "motivation": "现有图像去模糊算法在训练数据集之外的表现较差，尤其是面对复杂的实际应用场景时。主要原因是数据集难以涵盖所有真实的模糊模式，并且大多数方法过于关注局部细节而忽视了结构和语义一致性。", "method": "论文提出了模糊先验预训练(BPP)来利用模拟数据集中获取的模糊先验知识，并通过联合微调应用到真实世界的数据上。此外，还引入了运动和语义引导(MoSeG)，以增强在严重退化情况下的模糊先验，并将这些技术整合到轻量级扩散骨干网中。", "result": "实验结果证明了所提出的模型在六种广泛使用的基准数据集及两个真实世界的数据集上均有较好的性能表现，展示了模糊先验对于鲁棒泛化的重要性以及GLOWDeblur模型设计的实际应用价值。", "conclusion": "研究提出了一种利用大规模模糊先验和线性注意力机制的方法来提高图像去模糊在现实场景中的泛化能力，并通过实验验证了其有效性和实用性。"}}
{"id": "2601.06521", "pdf": "https://arxiv.org/pdf/2601.06521", "abs": "https://arxiv.org/abs/2601.06521", "authors": ["Liang Chen", "Weichu Xie", "Yiyan Liang", "Hongfeng He", "Hans Zhao", "Zhibo Yang", "Zhiqi Huang", "Haoning Wu", "Haoyu Lu", "Y. charles", "Yiping Bao", "Yuantao Fan", "Guopeng Li", "Haiyang Shen", "Xuanzhong Chen", "Wendong Xu", "Shuzheng Si", "Zefan Cai", "Wenhao Chai", "Ziqi Huang", "Fangfu Liu", "Tianyu Liu", "Baobao Chang", "Xiaobo Hu", "Kaiyuan Chen", "et al. (4 additional authors not shown)"], "title": "BabyVision: Visual Reasoning Beyond Language", "categories": ["cs.CV", "cs.CL"], "comment": "26 pages, Homepage at https://unipat.ai/blog/BabyVision", "summary": "While humans develop core visual skills long before acquiring language, contemporary Multimodal LLMs (MLLMs) still rely heavily on linguistic priors to compensate for their fragile visual understanding. We uncovered a crucial fact: state-of-the-art MLLMs consistently fail on basic visual tasks that humans, even 3-year-olds, can solve effortlessly. To systematically investigate this gap, we introduce BabyVision, a benchmark designed to assess core visual abilities independent of linguistic knowledge for MLLMs. BabyVision spans a wide range of tasks, with 388 items divided into 22 subclasses across four key categories. Empirical results and human evaluation reveal that leading MLLMs perform significantly below human baselines. Gemini3-Pro-Preview scores 49.7, lagging behind 6-year-old humans and falling well behind the average adult score of 94.1. These results show despite excelling in knowledge-heavy evaluations, current MLLMs still lack fundamental visual primitives. Progress in BabyVision represents a step toward human-level visual perception and reasoning capabilities. We also explore solving visual reasoning with generation models by proposing BabyVision-Gen and automatic evaluation toolkit. Our code and benchmark data are released at https://github.com/UniPat-AI/BabyVision for reproduction.", "AI": {"tldr": "论文主要任务是通过BabyVision基准测试来评估多模态大型语言模型（MLLM）的视觉理解能力，这些任务独立于语言知识。", "motivation": "人类在掌握语言之前就已经具备了基本的视觉技能，但当前的MLLM仍然严重依赖语言先验来弥补其脆弱的视觉理解。研究发现现有的MLLM在基础视觉任务上表现不佳，甚至不及三岁儿童的表现。", "method": "提出了BabyVision基准测试，包含388项不同类别的任务，旨在评估模型的核心视觉能力独立于语言知识。同时提出了解决视觉推理问题的方法BabyVision-Gen和自动化评估工具。", "result": "实验结果显示领先的MLLM在核心视觉任务上表现显著低于人类基线水平，例如Gemini3-Pro-Preview的得分仅为49.7分，远落后于六岁儿童及成年人的平均得分94.1分。", "conclusion": "尽管现有的MLLM在知识密集型评估中表现出色，但在基本视觉理解和推理方面仍然存在很大差距。通过BabyVision的研究和改进方法，有助于推动模型向人类水平的视觉感知与推理能力迈进。"}}
{"id": "2601.06518", "pdf": "https://arxiv.org/pdf/2601.06518", "abs": "https://arxiv.org/abs/2601.06518", "authors": ["Yash Thesia", "Meera Suthar"], "title": "Bridging Robustness and Efficiency: Real-Time Low-Light Enhancement via Attention U-Net GAN", "categories": ["cs.CV"], "comment": "7 pages, 2 figures, 3 tables", "summary": "Recent advancements in Low-Light Image Enhancement (LLIE) have focused heavily on Diffusion Probabilistic Models, which achieve high perceptual quality but suffer from significant computational latency (often exceeding 2-4 seconds per image). Conversely, traditional CNN-based baselines offer real-time inference but struggle with \"over-smoothing,\" failing to recover fine structural details in extreme low-light conditions. This creates a practical gap in the literature: the lack of a model that provides generative-level texture recovery at edge-deployable speeds. In this paper, we address this trade-off by proposing a hybrid Attention U-Net GAN. We demonstrate that the heavy iterative sampling of diffusion models is not strictly necessary for texture recovery. Instead, by integrating Attention Gates into a lightweight U-Net backbone and training within a conditional adversarial framework, we can approximate the high-frequency fidelity of generative models in a single forward pass. Extensive experiments on the SID dataset show that our method achieves a best-in-class LPIPS score of 0.112 among efficient models, significantly outperforming efficient baselines (SID, EnlightenGAN) while maintaining an inference latency of 0.06s. This represents a 40x speedup over latent diffusion models, making our approach suitable for near real-time applications.", "AI": {"tldr": "该论文提出了一种结合注意力机制的轻量级U-Net生成对抗网络，用于实现低光图像增强。这种方法在单次前向传播中实现了高质量的纹理恢复，并且具有极短的延迟时间。", "motivation": "现有低光照图像增强模型存在计算延迟与过平滑问题，论文旨在开发一种能够在边缘设备上实时部署的同时保持高频率细节还原的方法。", "method": "通过将注意力门引入U-Net架构并将其置于对抗性训练框架中，该方法在单次前向传播中实现了高质量的纹理恢复，并且具有极短延迟时间。从而弥补了计算效率和视觉质量之间的权衡。", "result": "实验结果表明，在SID数据集上，所提出的方法达到了0.112的LPIPS得分，在高效模型中处于领先地位，显著优于其他高效基线方法（如SID, EnlightenGAN），同时保持了0.06秒的推理延迟。这代表着与潜在扩散模型相比40倍的速度提升。", "conclusion": "该研究提供了一种新的低光照图像增强方法，能够在边缘设备上实时部署的同时实现高质量纹理恢复，填补了现有技术中的空白。"}}
{"id": "2601.06516", "pdf": "https://arxiv.org/pdf/2601.06516", "abs": "https://arxiv.org/abs/2601.06516", "authors": ["Carl Vincent Ladres Kho"], "title": "Pareto-Optimal Model Selection for Low-Cost, Single-Lead EMG Control in Embedded Systems", "categories": ["cs.HC", "cs.LG", "eess.SP"], "comment": "15 pages main text, 51 pages total including appendices. 18 figures. Code and dataset available at: https://github.com/CarlKho-Minerva/v2-emg-muscle", "summary": "Consumer-grade biosensors offer a cost-effective alternative to medical-grade electromyography (EMG) systems, reducing hardware costs from thousands of dollars to approximately $13. However, these low-cost sensors introduce significant signal instability and motion artifacts. Deploying machine learning models on resource-constrained edge devices like the ESP32 presents a challenge: balancing classification accuracy with strict latency (<100ms) and memory (<320KB) constraints. Using a single-subject dataset comprising 1,540 seconds of raw data (1.54M data points, segmented into ~1,300 one-second windows), I evaluate 18 model architectures, ranging from statistical heuristics to deep transfer learning (ResNet50) and custom hybrid networks (MaxCRNN). While my custom \"MaxCRNN\" (Inception + Bi-LSTM + Attention) achieved the highest safety (99% Precision) and robustness, I identify Random Forest (74% accuracy) as the Pareto-optimal solution for embedded control on legacy microcontrollers. I demonstrate that reliable, low-latency EMG control is feasible on commodity hardware, with Deep Learning offering a path to near-perfect reliability on modern Edge AI accelerators.", "AI": {"tldr": "该论文旨在通过评估多种机器学习模型，寻找在嵌入式系统中实现低延迟、低成本的肌电图（EMG）控制的最佳方案。", "motivation": "消费级生物传感器由于成本低廉成为医学级EMG系统的替代品。然而这些传感器带来的信号不稳定和运动伪影挑战了如何在资源受限的设备如ESP32上部署机器学习模型，以实现既准确又低延迟（<100ms）且占用内存少(<320KB)的需求。", "method": "使用包含154万数据点、分段为约1300个一秒钟窗口的单被试数据集评估了包括统计启发式、深度迁移学习(ResNet50)以及定制混合网络(MaxCRNN)在内的18种模型架构，并通过分析确定了随机森林作为嵌入式控制中的最优解。", "result": "该研究发现定制“MaxCRNN”（Inception+Bi-LSTM+Attention）在安全性和鲁棒性上表现最佳，而随机森林则被确认为满足低延迟和内存限制下的帕累托最优解决方案。", "conclusion": "研究表明，可靠且低延迟的EMG控制在商品硬件上是可行的，并展示了深度学习模型向接近完美可靠性发展的路径。"}}
{"id": "2601.06512", "pdf": "https://arxiv.org/pdf/2601.06512", "abs": "https://arxiv.org/abs/2601.06512", "authors": ["Stavros Tsimpoukis", "Dimitrios Tyrovolas", "Sotiris Ioannidis", "Maria Kafesaki", "Ian F. Akyildiz", "George K. Karagiannidis", "Christos K. Liaskos"], "title": "A novel RF-enabled Non-Destructive Inspection Method through Machine Learning and Programmable Wireless Environments", "categories": ["cs.LG", "cs.ET"], "comment": null, "summary": "Contemporary industrial Non-Destructive Inspection (NDI) methods require sensing capabilities that operate in occluded, hazardous, or access restricted environments. Yet, the current visual inspection based on optical cameras offers limited quality of service to that respect. In that sense, novel methods for workpiece inspection, suitable, for smart manufacturing are needed. Programmable Wireless Environments (PWE) could help towards that direction, by redefining the wireless Radio Frequency (RF) wave propagation as a controllable inspector entity. In this work, we propose a novel approach to Non-Destructive Inspection, leveraging an RF sensing pipeline based on RF wavefront encoding for retrieving workpiece-image entries from a designated database. This approach combines PWE-enabled RF wave manipulation with machine learning (ML) tools trained to produce visual outputs for quality inspection. Specifically, we establish correlation relationships between RF wavefronts and target industrial assets, hence yielding a dataset which links wavefronts to their corresponding images in a structured manner. Subsequently, a Generative Adversarial Network (GAN) derives visual representations closely matching the database entries. Our results indicate that the proposed method achieves an SSIM 99.5% matching score in visual outputs, paving the way for next-generation quality control workflows in industry.", "AI": {"tldr": "本文提出了一种基于机器学习和可编程无线环境的新型射频非破坏性检测方法。", "motivation": "当前工业中的无损检测技术在被遮挡、危险或难以接近的环境中存在局限性，现有的光学相机检查无法满足要求。因此，需要新的方法来解决这些问题。", "method": "利用可编程无线环境对射频波进行操纵，并结合机器学习工具生成质量检验所需的视觉输出。", "result": "该方法实现了99.5%的SSIM匹配得分，表明在检测结果中可以生成与数据库条目相匹配的视觉表示。", "conclusion": "这种方法为下一代工业质量控制工作流程铺平了道路。"}}
{"id": "2601.06508", "pdf": "https://arxiv.org/pdf/2601.06508", "abs": "https://arxiv.org/abs/2601.06508", "authors": ["Andrei A. Korigodskii", "Artem E. Vasiunik", "Georgii A. Varin", "Adilia M. Zukhurova", "Matvei V. Urvantsev", "Semen A. Osipenkov", "Igor S. Efremov", "Georgii E. Bondar"], "title": "Precision Meets Art: Autonomous Multi-UAV System for Large Scale Mural Drawing", "categories": ["cs.RO", "cs.CV", "eess.SY"], "comment": "6 pages, 9 figures", "summary": "The integration of autonomous unmanned aerial vehicles (UAVs) into large-scale artistic projects has emerged as a new application in robotics. This paper presents the design, deployment, and testing of a novel multi-drone system for automated mural painting in outdoor settings. This technology makes use of new software that coordinates multiple drones simultaneously, utilizing state-machine algorithms for task execution. Key advancements are the complex positioning system that combines 2D localization using a single motion tracking camera with onboard LiDAR for precise positioning, and a novel flight control algorithm, which works differently along the trajectory and normally to it, ensuring smoothness and high precision of the drawings at the same time. A 100 square meters mural was created using the developed multi-drone system, validating the system's efficacy. Compared to single-drone approaches, our multi-UAV solution significantly improves scalability and operational speed while maintaining high stability even in harsh weather conditions. The findings highlight the potential of autonomous robotic swarms in creative applications, paving the way for further advancements in large-scale robotic art.", "AI": {"tldr": "设计并测试了一种用于大型户外壁画绘制的自主多无人机系统", "motivation": "探索将自主无人飞行器应用于大规模艺术项目中的潜力，提高绘画效率和精度", "method": "开发了结合2D定位技术和LiDAR的复杂定位系统以及新颖的飞行控制算法，并使用状态机算法协调多个无人机同时工作", "result": "成功绘制了一幅100平方米的大规模壁画，展示了系统的有效性和优越性", "conclusion": "自主机器人群在创意应用中具有巨大潜力，可以进一步推动大规模机器人艺术的发展"}}
{"id": "2601.06505", "pdf": "https://arxiv.org/pdf/2601.06505", "abs": "https://arxiv.org/abs/2601.06505", "authors": ["Sang T. Truong", "Duc Q. Nguyen", "Willie Neiswanger", "Ryan-Rhys Griffiths", "Stefano Ermon", "Nick Haber", "Sanmi Koyejo"], "title": "Neural Nonmyopic Bayesian Optimization in Dynamic Cost Settings", "categories": ["cs.LG", "cs.AI"], "comment": "32 pages, 20 figures, 13 tables", "summary": "Bayesian optimization (BO) is a common framework for optimizing black-box functions, yet most existing methods assume static query costs and rely on myopic acquisition strategies. We introduce LookaHES, a nonmyopic BO framework designed for dynamic, history-dependent cost environments, where evaluation costs vary with prior actions, such as travel distance in spatial tasks or edit distance in sequence design. LookaHES combines a multi-step variant of $H$-Entropy Search with pathwise sampling and neural policy optimization, enabling long-horizon planning beyond twenty steps without the exponential complexity of existing nonmyopic methods. The key innovation is the integration of neural policies, including large language models, to effectively navigate structured, combinatorial action spaces such as protein sequences. These policies amortize lookahead planning and can be integrated with domain-specific constraints during rollout. Empirically, LookaHES outperforms strong myopic and nonmyopic baselines across nine synthetic benchmarks from two to eight dimensions and two real-world tasks: geospatial optimization using NASA night-light imagery and protein sequence design with constrained token-level edits. In short, LookaHES provides a general, scalable, and cost-aware solution for robust long-horizon optimization in complex decision spaces, which makes it a useful tool for researchers in machine learning, statistics, and applied domains. Our implementation is available at https://github.com/sangttruong/nonmyopia.", "AI": {"tldr": "引入了LookaHES框架，一种针对动态成本环境的非近视贝叶斯优化方法。", "motivation": "大多数现有方法假设静态查询成本并依赖近视获取策略，而实际场景中成本会根据先前行动变化。因此需要一个能够处理这种复杂情况的新方法。", "method": "LookaHES结合了多步骤$H$-熵搜索、路径采样和神经政策优化，利用大型语言模型等神经政策来有效导航结构化组合动作空间，并实现了远视期规划能力。", "result": "实验结果显示，LookaHES在九个合成基准测试以及两个现实世界任务中均超越了强大的近视和非近视基线方法。", "conclusion": "LookaHES提供了一种通用、可扩展且考虑成本的解决方案，适用于复杂决策空间中的稳健长期优化问题。"}}
{"id": "2601.06502", "pdf": "https://arxiv.org/pdf/2601.06502", "abs": "https://arxiv.org/abs/2601.06502", "authors": ["Shengkai Chen", "Zhiguang Cao", "Jianan Zhou", "Yaoxin Wu", "Senthilnath Jayavelu", "Zhuoyi Lin", "Xiaoli Li", "Shili Xiang"], "title": "DRAGON: LLM-Driven Decomposition and Reconstruction Agents for Large-Scale Combinatorial Optimization", "categories": ["cs.AI"], "comment": "This paper has been accepted for presentation and publication at the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026), source code will be available soon", "summary": "Large Language Models (LLMs) have recently shown promise in addressing combinatorial optimization problems (COPs) through prompt-based strategies. However, their scalability and generalization remain limited, and their effectiveness diminishes as problem size increases, particularly in routing problems involving more than 30 nodes. We propose DRAGON, which stands for Decomposition and Reconstruction Agents Guided OptimizatioN, a novel framework that combines the strengths of metaheuristic design and LLM reasoning. Starting from an initial global solution, DRAGON autonomously identifies regions with high optimization potential and strategically decompose large-scale COPs into manageable subproblems. Each subproblem is then reformulated as a concise, localized optimization task and solved through targeted LLM prompting guided by accumulated experiences. Finally, the locally optimized solutions are systematically reintegrated into the original global context to yield a significantly improved overall outcome. By continuously interacting with the optimization environment and leveraging an adaptive experience memory, the agents iteratively learn from feedback, effectively coupling symbolic reasoning with heuristic search. Empirical results show that, unlike existing LLM-based solvers limited to small-scale instances, DRAGON consistently produces feasible solutions on TSPLIB, CVRPLIB, and Weibull-5k bin packing benchmarks, and achieves near-optimal results (0.16% gap) on knapsack problems with over 3M variables. This work shows the potential of feedback-driven language agents as a new paradigm for generalizable and interpretable large-scale optimization.", "AI": {"tldr": "提出了一种新的框架DRAGON，结合元启发式设计和LLM推理解决大规模组合优化问题。", "motivation": "现有LLMs在处理规模较大的组合优化问题时，可扩展性和泛化性有限，特别是在30个以上节点的路由问题中效果减弱。因此，需要一种新方法来增强其性能。", "method": "DRAGON框架从初始全局解开始，自动识别优化潜力高的区域，并将大规模问题分解为小规模子问题。每个子问题被重新表述为简化的局部优化任务并通过目标LLM提示解决。最终，本地优化的解决方案被系统地整合回原始全局上下文中以生成改进的整体结果。", "result": "DRAGON在TSPLIB、CVRPLIB和Weibull-5k装箱基准上产生可行解，并在300万个变量以上的背包问题中实现接近最优的结果（差距仅为0.16%）。", "conclusion": "反馈驱动的语言代理作为可解释的大型优化的新范式显示了其潜力。"}}
{"id": "2601.06500", "pdf": "https://arxiv.org/pdf/2601.06500", "abs": "https://arxiv.org/abs/2601.06500", "authors": ["Alok Khatri", "Bishesh Khanal"], "title": "The AI Pyramid A Conceptual Framework for Workforce Capability in the Age of AI", "categories": ["cs.AI", "cs.CY"], "comment": "14 pages", "summary": "Artificial intelligence (AI) represents a qualitative shift in technological change by extending cognitive labor itself rather than merely automating routine tasks. Recent evidence shows that generative AI disproportionately affects highly educated, white collar work, challenging existing assumptions about workforce vulnerability and rendering traditional approaches to digital or AI literacy insufficient. This paper introduces the concept of AI Nativity, the capacity to integrate AI fluidly into everyday reasoning, problem solving, and decision making, and proposes the AI Pyramid, a conceptual framework for organizing human capability in an AI mediated economy. The framework distinguishes three interdependent capability layers: AI Native capability as a universal baseline for participation in AI augmented environments; AI Foundation capability for building, integrating, and sustaining AI enabled systems; and AI Deep capability for advancing frontier AI knowledge and applications. Crucially, the pyramid is not a career ladder but a system level distribution of capabilities required at scale. Building on this structure, the paper argues that effective AI workforce development requires treating capability formation as infrastructure rather than episodic training, centered on problem based learning embedded in work contexts and supported by dynamic skill ontologies and competency based measurement. The framework has implications for organizations, education systems, and governments seeking to align learning, measurement, and policy with the evolving demands of AI mediated work, while addressing productivity, resilience, and inequality at societal scale.", "AI": {"tldr": "提出了AI金字塔框架，用于组织人类在AI时代的工作能力。", "motivation": "探讨了AI技术如何改变劳动力市场，并提出了一种新的工作能力概念——AI原生性。", "method": "通过构建一个包含三个层次的金字塔模型来分析和描述不同层级的能力需求。", "result": "提出了一个新的概念框架，即AI金字塔，用于指导组织、教育系统和政府应对AI带来的挑战。", "conclusion": "强调了将能力培养视为基础设施的重要性，并提倡基于问题的学习方法。"}}
{"id": "2601.06497", "pdf": "https://arxiv.org/pdf/2601.06497", "abs": "https://arxiv.org/abs/2601.06497", "authors": ["Tanghaoran Zhang", "Xinjun Mao", "Shangwen Wang", "Yuxin Zhao", "Yao Lu", "Zezhou Tang", "Wenyu Xu", "Longfei Sun", "Changrong Xie", "Kang Yang", "Yue Yu"], "title": "Coding in a Bubble? Evaluating LLMs in Resolving Context Adaptation Bugs During Code Adaptation", "categories": ["cs.SE", "cs.AI"], "comment": "24 pages, 11 figures, accepted by FSE 2026", "summary": "Code adaptation is a fundamental but challenging task in software development, requiring developers to modify existing code for new contexts. A key challenge is to resolve Context Adaptation Bugs (CtxBugs), which occurs when code correct in its original context violates constraints in the target environment. Unlike isolated bugs, CtxBugs cannot be resolved through local fixes and require cross-context reasoning to identify semantic mismatches. Overlooking them may lead to critical failures in adaptation. Although Large Language Models (LLMs) show great potential in automating code-related tasks, their ability to resolve CtxBugs remains a significant and unexplored obstacle to their practical use in code adaptation. To bridge this gap, we propose CtxBugGen, a novel framework for generating CtxBugs to evaluate LLMs. Its core idea is to leverage LLMs' tendency to generate plausible but context-free code when contextual constraints are absent. The framework generates CtxBugs through a four-step process to ensure their relevance and validity: (1) Adaptation Task Selection, (2) Task-specific Perturbation,(3) LLM-based Variant Generation and (4) CtxBugs Identification. Based on the benchmark constructed by CtxBugGen, we conduct an empirical study with four state-of-the-art LLMs. Our results reveal their unsatisfactory performance in CtxBug resolution. The best performing LLM, Kimi-K2, achieves 55.93% on Pass@1 and resolves just 52.47% of CtxBugs. The presence of CtxBugs degrades LLMs' adaptation performance by up to 30%. Failure analysis indicates that LLMs often overlook CtxBugs and replicate them in their outputs. Our study highlights a critical weakness in LLMs' cross-context reasoning and emphasize the need for new methods to enhance their context awareness for reliable code adaptation.", "AI": {"tldr": "本文提出了CtxBugGen框架，用于评估大型语言模型在解决代码适应过程中遇到的上下文适应性错误的能力。", "motivation": "大型语言模型在自动化编码任务方面表现出色，但在处理跨环境约束时存在不足。本文旨在通过生成特定的上下文适应性错误来测试和改进这些模型。", "method": "CtxBugGen框架包括四个步骤：选择适应任务、任务特异性扰动、基于LLM的变体生成以及上下文适应性错误识别。该研究使用CtxBugGen构建基准，对四种最先进的大型语言模型进行实验。", "result": "在测试中发现所有模型均表现出较差的性能，其中最好的Kimi-K2模型也仅达到55.93%的Pass@1准确率和52.47%的上下文适应性错误解决率。这些结果表明LLM在跨环境推理方面存在关键缺陷。", "conclusion": "这项研究揭示了大型语言模型在处理代码适应性问题时面临的挑战，并强调需要新的方法来提高它们对上下文的理解，以实现可靠的代码适应性改进。"}}
{"id": "2601.06496", "pdf": "https://arxiv.org/pdf/2601.06496", "abs": "https://arxiv.org/abs/2601.06496", "authors": ["Hao Tang", "Ting Huang", "Zeyu Zhang"], "title": "3D CoCa v2: Contrastive Learners with Test-Time Search for Generalizable Spatial Intelligence", "categories": ["cs.CV"], "comment": null, "summary": "Spatial intelligence refers to the ability to perceive, reason about, and describe objects and their relationships within three-dimensional environments, forming a foundation for embodied perception and scene understanding. 3D captioning aims to describe 3D scenes in natural language; however, it remains challenging due to the sparsity and irregularity of point clouds and, more critically, the weak grounding and limited out-of-distribution (OOD) generalization of existing captioners across drastically different environments, including indoor and outdoor 3D scenes. To address this challenge, we propose 3D CoCa v2, a generalizable 3D captioning framework that unifies contrastive vision-language learning with 3D caption generation and further improves robustness via test-time search (TTS) without updating the captioner parameters. 3D CoCa v2 builds on a frozen CLIP-based semantic prior, a spatially-aware 3D scene encoder for geometry, and a multimodal decoder jointly optimized with contrastive and captioning objectives, avoiding external detectors or handcrafted proposals. At inference, TTS produces diverse caption candidates and performs reward-guided selection using a compact scene summary. Experiments show improvements over 3D CoCa of +1.50 CIDEr@0.5IoU on ScanRefer and +1.61 CIDEr@0.5IoU on Nr3D, and +3.8 CIDEr@0.25 in zero-shot OOD evaluation on TOD3Cap. Code will be released at https://github.com/AIGeeksGroup/3DCoCav2.", "AI": {"tldr": "该论文提出了一种名为3D CoCa v2的框架，旨在通过对比学习和测试时间搜索来提高三维场景描述的能力。", "motivation": "现有的三维描述器在面对稀疏且不规则的点云数据时效果不佳，并且其泛化能力和跨不同环境（如室内和室外）的表现有限。为了解决这些问题，作者提出了3D CoCa v2框架。", "method": "该方法基于冻结的CLIP语义先验、具有空间意识的三维场景编码器以及多模式解码器，在对比学习和描述目标下联合优化。测试时间搜索（TTS）在推理时生成多种候选描述并进行奖励引导选择。", "result": "实验表明，与3D CoCa相比，3D CoCa v2在ScanRefer、Nr3D数据集上分别提高了1.50 CIDEr@0.5IoU和1.61 CIDEr@0.5IoU，并且在零样本OOD评估中TOD3Cap的数据集中提升了3.8 CIDEr@0.25。", "conclusion": "该研究通过引入测试时间搜索（TTS）提高了三维场景描述的鲁棒性和泛化能力，展示出显著的性能提升。"}}
{"id": "2601.06487", "pdf": "https://arxiv.org/pdf/2601.06487", "abs": "https://arxiv.org/abs/2601.06487", "authors": ["Qiang Zhang", "Boli Chen", "Fanrui Zhang", "Ruixue Ding", "Shihang Wang", "Qiuchen Wang", "Yinfeng Huang", "Haonan Zhang", "Rongxiang Zhu", "Pengyong Wang", "Ailin Ren", "Xin Li", "Pengjun Xie", "Jiawei Liu", "Ning Guo", "Jingren Zhou", "Zheng-Jun Zha"], "title": "ArenaRL: Scaling RL for Open-Ended Agents via Tournament-based Relative Ranking", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning has substantially improved the performance of LLM agents on tasks with verifiable outcomes, but it still struggles on open-ended agent tasks with vast solution spaces (e.g., complex travel planning). Due to the absence of objective ground-truth for these tasks, current RL algorithms largely rely on reward models that assign scalar scores to individual responses. We contend that such pointwise scoring suffers from an inherent discrimination collapse: the reward model struggles to distinguish subtle advantages among different trajectories, resulting in scores within a group being compressed into a narrow range. Consequently, the effective reward signal becomes dominated by noise from the reward model, leading to optimization stagnation. To address this, we propose ArenaRL, a reinforcement learning paradigm that shifts from pointwise scalar scoring to intra-group relative ranking. ArenaRL introduces a process-aware pairwise evaluation mechanism, employing multi-level rubrics to assign fine-grained relative scores to trajectories. Additionally, we construct an intra-group adversarial arena and devise a tournament-based ranking scheme to obtain stable advantage signals. Empirical results confirm that the built seeded single-elimination scheme achieves nearly equivalent advantage estimation accuracy to full pairwise comparisons with O(N^2) complexity, while operating with only O(N) complexity, striking an optimal balance between efficiency and precision. Furthermore, to address the lack of full-cycle benchmarks for open-ended agents, we build Open-Travel and Open-DeepResearch, two high-quality benchmarks featuring a comprehensive pipeline covering SFT, RL training, and multi-dimensional evaluation. Extensive experiments show that ArenaRL substantially outperforms standard RL baselines, enabling LLM agents to generate more robust solutions for complex real-world tasks.", "AI": {"tldr": "提出ArenaRL算法，通过基于锦标赛的相对排名解决强化学习在开放性任务中的优化停滞问题。", "motivation": "当前强化学习方法依赖于标量奖励模型，在处理具有复杂解空间的任务时难以区分不同轨迹的优势，导致优化过程受困。", "method": "引入过程感知的两两评价机制和多级标准，构建组内对抗环境，并设计基于锦标赛的排名方案以获得稳定优势信号。", "result": "实验结果显示ArenaRL在效率与精度间达到平衡，并显著优于传统强化学习基准方法。", "conclusion": "通过提出ArenaRL算法解决开放性任务中的优化停滞问题并增强了LLM代理生成复杂现实世界任务解决方案的能力。"}}
{"id": "2601.06484", "pdf": "https://arxiv.org/pdf/2601.06484", "abs": "https://arxiv.org/abs/2601.06484", "authors": ["Yue Wang", "Lawrence Amadi", "Xiang Gao", "Yazheng Chen", "Yuanpeng Liu", "Ning Lu", "Xianfeng Gu"], "title": "Learning Domain Agnostic Latent Embeddings of 3D Faces for Zero-shot Animal Expression Transfer", "categories": ["cs.CV", "cs.AI"], "comment": "WACV 2026 Workshop LENS", "summary": "We present a zero-shot framework for transferring human facial expressions to 3D animal face meshes. Our method combines intrinsic geometric descriptors (HKS/WKS) with a mesh-agnostic latent embedding that disentangles facial identity and expression. The ID latent space captures species-independent facial structure, while the expression latent space encodes deformation patterns that generalize across humans and animals. Trained only with human expression pairs, the model learns the embeddings, decoupling, and recoupling of cross-identity expressions, enabling expression transfer without requiring animal expression data. To enforce geometric consistency, we employ Jacobian loss together with vertex-position and Laplacian losses. Experiments show that our approach achieves plausible cross-species expression transfer, effectively narrowing the geometric gap between human and animal facial shapes.", "AI": {"tldr": "提出了一种零样本框架，用于将人类面部表情转移到3D动物脸部网格上", "motivation": "旨在通过学习跨物种的表情转换来解决缺乏动物表情数据的问题，同时保持几何一致性", "method": "结合了内在的几何描述符（HKS/WKS）和一种与网格无关的潜在嵌入，该嵌入分离了面部身份和表情。模型仅使用人类表情对训练，并利用雅可比损失、顶点位置损失和拉普拉斯损失来确保几何一致性和跨物种的表情转换", "result": "实验结果显示该方法实现了逼真的跨物种表情转移，有效缩小了人类和动物面部形状之间的几何差距", "conclusion": "所提出的方法为零样本的跨物种表情转移提供了一个有效的解决方案"}}
{"id": "2601.06479", "pdf": "https://arxiv.org/pdf/2601.06479", "abs": "https://arxiv.org/abs/2601.06479", "authors": ["JiaLin Zhang", "Dong Li"], "title": "SRFlow: A Dataset and Regularization Model for High-Resolution Facial Optical Flow via Splatting Rasterization", "categories": ["cs.CV"], "comment": null, "summary": "Facial optical flow supports a wide range of tasks in facial motion analysis. However, the lack of high-resolution facial optical flow datasets has hindered progress in this area. In this paper, we introduce Splatting Rasterization Flow (SRFlow), a high-resolution facial optical flow dataset, and Splatting Rasterization Guided FlowNet (SRFlowNet), a facial optical flow model with tailored regularization losses. These losses constrain flow predictions using masks and gradients computed via difference or Sobel operator. This effectively suppresses high-frequency noise and large-scale errors in texture-less or repetitive-pattern regions, enabling SRFlowNet to be the first model explicitly capable of capturing high-resolution skin motion guided by Gaussian splatting rasterization. Experiments show that training with the SRFlow dataset improves facial optical flow estimation across various optical flow models, reducing end-point error (EPE) by up to 42% (from 0.5081 to 0.2953). Furthermore, when coupled with the SRFlow dataset, SRFlowNet achieves up to a 48% improvement in F1-score (from 0.4733 to 0.6947) on a composite of three micro-expression datasets. These results demonstrate the value of advancing both facial optical flow estimation and micro-expression recognition.", "AI": {"tldr": "提出了SRFlow数据集和指导模型SRFlowNet，用于提高高分辨率面部光学流的估计精度", "motivation": "现有高分辨率面部光学流数据不足限制了该领域的发展，旨在通过引入新的数据集与模型来解决这一问题", "method": "使用Splatting Rasterization技术生成高质量的数据集，并设计了具有针对性正则化损失的新模型以抑制噪声和误差", "result": "实验显示，新方法在多个光流估计任务上表现出色，显著提高了F1分数和减少了EPE值", "conclusion": "SRFlow数据集与SRFlowNet模型有效提升了面部光学流估计质量，对微表情识别有积极影响"}}
{"id": "2601.06475", "pdf": "https://arxiv.org/pdf/2601.06475", "abs": "https://arxiv.org/abs/2601.06475", "authors": ["Kai Cheng", "Ruoqi Wang", "Qiong Luo"], "title": "VVTRec: Radio Interferometric Reconstruction through Visual and Textual Modality Enrichment", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Radio astronomy is an indispensable discipline for observing distant celestial objects. Measurements of wave signals from radio telescopes, called visibility, need to be transformed into images for astronomical observations. These dirty images blend information from real sources and artifacts. Therefore, astronomers usually perform reconstruction before imaging to obtain cleaner images. Existing methods consider only a single modality of sparse visibility data, resulting in images with remaining artifacts and insufficient modeling of correlation. To enhance the extraction of visibility information and emphasize output quality in the image domain, we propose VVTRec, a multimodal radio interferometric data reconstruction method with visibility-guided visual and textual modality enrichment. In our VVTRec, sparse visibility is transformed into image-form and text-form features to obtain enhancements in terms of spatial and semantic information, improving the structural integrity and accuracy of images. Also, we leverage Vision-Language Models (VLMs) to achieve additional training-free performance improvements. VVTRec enables sparse visibility, as a foreign modality unseen by VLMs, to accurately extract pre-trained knowledge as a supplement. Our experiments demonstrate that VVTRec effectively enhances imaging results by exploiting multimodal information without introducing excessive computational overhead.", "AI": {"tldr": "提出了VVTRec，一种通过视觉和文本模态增强的多模态射电干涉成像重建方法。", "motivation": "现有的重构方法只考虑单一稀疏可见度数据模式，导致图像中仍有残留伪影且相关性建模不足。为了提高可见度信息提取效果并强调图像域输出质量，引入了VVTRec。", "method": "将稀疏可见度转换为图像形式和文本形式特征以获得空间和语义信息增强，同时利用视觉语言模型（VLMs）实现无额外训练的性能提升。通过这种方式使稀疏可见度作为未知模态准确提取预训练知识补充。", "result": "实验表明，VVTRec能有效利用多模态信息改善成像结果而不增加过多计算负担。", "conclusion": "VVTRec提供了一种新的方法来优化射电天文图像的重建效果，提高了结构完整性和准确性。"}}
{"id": "2601.06474", "pdf": "https://arxiv.org/pdf/2601.06474", "abs": "https://arxiv.org/abs/2601.06474", "authors": ["Chenxu Dang", "Jie Wang", "Guang Li", "Zhiwen Hou", "Zihan You", "Hangjun Ye", "Jie Ma", "Long Chen", "Yan Wang"], "title": "SparseOccVLA: Bridging Occupancy and Vision-Language Models via Sparse Queries for Unified 4D Scene Understanding and Planning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In autonomous driving, Vision Language Models (VLMs) excel at high-level reasoning , whereas semantic occupancy provides fine-grained details. Despite significant progress in individual fields, there is still no method that can effectively integrate both paradigms. Conventional VLMs struggle with token explosion and limited spatiotemporal reasoning, while semantic occupancy provides a unified, explicit spatial representation but is too dense to integrate efficiently with VLMs. To address these challenges and bridge the gap between VLMs and occupancy, we propose SparseOccVLA, a novel vision-language-action model that unifies scene understanding, occupancy forecasting, and trajectory planning powered by sparse occupancy queries. Starting with a lightweight Sparse Occupancy Encoder, SparseOccVLA generates compact yet highly informative sparse occupancy queries that serve as the single bridge between vision and language. These queries are aligned into the language space and reasoned by the LLM for unified scene understanding and future occupancy forecasting. Furthermore, we introduce an LLM-guided Anchor-Diffusion Planner featuring decoupled anchor scoring and denoising, as well as cross-model trajectory-condition fusion. SparseOccVLA achieves a 7% relative improvement in CIDEr over the state-of-the-art on OmniDrive-nuScenes, a 0.5 increase in mIoU score on Occ3D-nuScenes, and sets state-of-the-art open-loop planning metric on nuScenes benchmark, demonstrating its strong holistic capability.", "AI": {"tldr": "本文提出了一种新型的视觉语言行动模型SparseOccVLA，通过稀疏占用查询连接视觉和语言，实现统一的4D场景理解和规划。", "motivation": "目前在自主驾驶领域中，视觉语言模型（VLM）擅长高层次推理，而语义占位图提供细粒度细节。然而，缺乏能够有效融合两者的集成方法。为了填补这一空白，本文旨在结合占用表示与语言模型的力量。", "method": "SparseOccVLA通过轻量级稀疏占用编码器生成紧凑且高度信息丰富的稀疏占用查询，作为视觉和语言之间的桥梁，并引入了由LLM指导的Anchor-Diffusion规划器来实现统一场景理解、未来占位预测以及轨迹规划。", "result": "在OmniDrive-nuScenes上的CIDEr指标相对改进7%，在Occ3D-nuScenes上mIoU分数提高0.5，在nuScenes基准测试的开放循环计划度量中设置新纪录，展示出强大的整体能力。", "conclusion": "SparseOccVLA通过稀疏占用查询有效连接视觉和语言模型，为自主驾驶中的4D场景理解与规划提供了一种新的方法论。"}}
{"id": "2601.06471", "pdf": "https://arxiv.org/pdf/2601.06471", "abs": "https://arxiv.org/abs/2601.06471", "authors": ["Junho Park", "Dohoon Kim", "Taesup Moon"], "title": "PRISP: Privacy-Safe Few-Shot Personalization via Lightweight Adaptation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "16 pages, 9 figures", "summary": "Large language model (LLM) personalization aims to adapt general-purpose models to individual users. Most existing methods, however, are developed under data-rich and resource-abundant settings, often incurring privacy risks. In contrast, realistic personalization typically occurs after deployment under (i) extremely limited user data, (ii) constrained computational resources, and (iii) strict privacy requirements. We propose PRISP, a lightweight and privacy-safe personalization framework tailored to these constraints. PRISP leverages a Text-to-LoRA hypernetwork to generate task-aware LoRA parameters from task descriptions, and enables efficient user personalization by optimizing a small subset of task-aware LoRA parameters together with minimal additional modules using few-shot user data. Experiments on a few-shot variant of the LaMP benchmark demonstrate that PRISP achieves strong overall performance compared to prior approaches, while reducing computational overhead and eliminating privacy risks.", "AI": {"tldr": "PRISP是一个轻量级且隐私安全的个性化框架，旨在解决资源受限和严格隐私要求下的用户个性化问题。", "motivation": "当前大多数现有的个性化方法在数据丰富、计算资源充足的环境下开发，这带来了隐私风险。相比之下，在部署后的真实场景中，个性化通常受到极少量用户数据、有限的计算资源以及严格的隐私需求限制。", "method": "PRISP利用Text-to-LoRA超网络从任务描述生成任务感知的LoRA参数，并通过优化少量的任务感知LoRA参数和最少额外模块，使用少量用户数据实现有效的用户个性化。", "result": "在LaMP基准测试的一个少量样本变体上的实验表明，与先前的方法相比，PRISP实现了强大的整体性能，同时减少了计算开销并消除了隐私风险。", "conclusion": "PRISP框架为解决资源受限和严格隐私要求下的个性化问题提供了一种有效且实用的解决方案。"}}
{"id": "2601.06465", "pdf": "https://arxiv.org/pdf/2601.06465", "abs": "https://arxiv.org/abs/2601.06465", "authors": ["Hao Li", "Xinqi Liu", "Yaoqing Jin"], "title": "R$^3$D: Regional-guided Residual Radar Diffusion", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": "6 pages, 4 figures", "summary": "Millimeter-wave radar enables robust environment perception in autonomous systems under adverse conditions yet suffers from sparse, noisy point clouds with low angular resolution. Existing diffusion-based radar enhancement methods either incur high learning complexity by modeling full LiDAR distributions or fail to prioritize critical structures due to uniform regional processing. To address these issues, we propose R3D, a regional-guided residual radar diffusion framework that integrates residual diffusion modeling-focusing on the concentrated LiDAR-radar residual encoding complementary high-frequency details to reduce learning difficulty-and sigma-adaptive regional guidance-leveraging radar-specific signal properties to generate attention maps and applying lightweight guidance only in low-noise stages to avoid gradient imbalance while refining key regions. Extensive experiments on the ColoRadar dataset demonstrate that R3D outperforms state-of-the-art methods, providing a practical solution for radar perception enhancement. Our anonymous code and pretrained models are released here: https://anonymous.4open.science/r/r3d-F836", "AI": {"tldr": "提出了一种基于区域指导的残差雷达扩散框架R3D，以改进毫米波雷达在不良环境中的感知能力。", "motivation": "现有的雷达增强方法存在学习复杂度高或未能优先处理关键结构的问题。R3D旨在解决这些问题，提高毫米波雷达在恶劣条件下的性能。", "method": "R3D结合了残差扩散建模和σ自适应区域指导技术，利用特定的雷达信号特性生成注意图，并仅在低噪声阶段应用轻量级指引以避免梯度不平衡并细化关键区域。", "result": "在ColoRadar数据集上进行的广泛实验表明，R3D优于最先进的方法，在实际雷达感知增强方面提供了一种实用解决方案。", "conclusion": "R3D框架显著提升了毫米波雷达点云的质量和鲁棒性，为自动驾驶系统提供了更强的环境感知能力。"}}
{"id": "2601.06464", "pdf": "https://arxiv.org/pdf/2601.06464", "abs": "https://arxiv.org/abs/2601.06464", "authors": ["Chao Liu", "Ngai-Man Cheung"], "title": "On the Adversarial Robustness of 3D Large Vision-Language Models", "categories": ["cs.CV"], "comment": "Under Review", "summary": "3D Vision-Language Models (VLMs), such as PointLLM and GPT4Point, have shown strong reasoning and generalization abilities in 3D understanding tasks. However, their adversarial robustness remains largely unexplored. Prior work in 2D VLMs has shown that the integration of visual inputs significantly increases vulnerability to adversarial attacks, making these models easier to manipulate into generating toxic or misleading outputs. In this paper, we investigate whether incorporating 3D vision similarly compromises the robustness of 3D VLMs. To this end, we present the first systematic study of adversarial robustness in point-based 3D VLMs. We propose two complementary attack strategies: \\textit{Vision Attack}, which perturbs the visual token features produced by the 3D encoder and projector to assess the robustness of vision-language alignment; and \\textit{Caption Attack}, which directly manipulates output token sequences to evaluate end-to-end system robustness. Each attack includes both untargeted and targeted variants to measure general vulnerability and susceptibility to controlled manipulation. Our experiments reveal that 3D VLMs exhibit significant adversarial vulnerabilities under untargeted attacks, while demonstrating greater resilience against targeted attacks aimed at forcing specific harmful outputs, compared to their 2D counterparts. These findings highlight the importance of improving the adversarial robustness of 3D VLMs, especially as they are deployed in safety-critical applications.", "AI": {"tldr": "研究了3D视觉语言模型在对抗攻击下的鲁棒性，提出了两种互补的攻击策略：视觉攻击和标题攻击。", "motivation": "探讨3D视觉语言模型的鲁棒性是否因3D视觉输入而降低，以提高其部署于安全关键应用时的安全性。", "method": "提出并实施了针对3D VLMs的两种新的对抗攻击策略：视觉攻击和标题攻击，并评估它们在未定向和定向攻击下的表现。", "result": "结果显示3D VLMs在非目标攻击下表现出显著的脆弱性，但在尝试产生特定有害输出的目标攻击中显示出更大的鲁棒性。", "conclusion": "强调提高3D VLMs对抗攻击鲁棒性的必要性，特别是当它们应用于安全关键领域时。"}}
{"id": "2601.06461", "pdf": "https://arxiv.org/pdf/2601.06461", "abs": "https://arxiv.org/abs/2601.06461", "authors": ["Minfeng Qi", "Dongyang He", "Qin Wang", "Lefeng Zhang"], "title": "VIPER Strike: Defeating Visual Reasoning CAPTCHAs via Structured Vision-Language Inference", "categories": ["cs.CR", "cs.CV", "cs.ET"], "comment": "Accepted by Usenix Security 2026", "summary": "Visual Reasoning CAPTCHAs (VRCs) combine visual scenes with natural-language queries that demand compositional inference over objects, attributes, and spatial relations. They are increasingly deployed as a primary defense against automated bots. Existing solvers fall into two paradigms: vision-centric, which rely on template-specific detectors but fail on novel layouts, and reasoning-centric, which leverage LLMs but struggle with fine-grained visual perception. Both lack the generality needed to handle heterogeneous VRC deployments. We present ViPer, a unified attack framework that integrates structured multi-object visual perception with adaptive LLM-based reasoning. ViPer parses visual layouts, grounds attributes to question semantics, and infers target coordinates within a modular pipeline. Evaluated on six major VRC providers (VTT, Geetest, NetEase, Dingxiang, Shumei, Xiaodun), ViPer achieves up to 93.2% success, approaching human-level performance across multiple benchmarks. Compared to prior solvers, GraphNet (83.2%), Oedipus (65.8%), and the Holistic approach (89.5%), ViPer consistently outperforms all baselines. The framework further maintains robustness across alternative LLM backbones (GPT, Grok, DeepSeek, Kimi), sustaining accuracy above 90%. To anticipate defense, we further introduce Template-Space Randomization (TSR), a lightweight strategy that perturbs linguistic templates without altering task semantics. TSR measurably reduces solver (i.e., attacker) performance. Our proposed design suggests directions for human-solvable but machine-resistant CAPTCHAs.", "AI": {"tldr": "ViPer是一种针对视觉推理验证码（VRC）的攻击框架，它结合了结构化的多对象视觉感知和适应性的基于大语言模型的推理。", "motivation": "当前的视觉推理验证码解决方法存在局限性：视觉中心的方法依赖于特定模板检测器，在新布局上表现不佳；而逻辑中心的方法虽然使用大语言模型进行推理，但在细粒度视觉感知方面有所欠缺。两者都无法提供足够的通用性来应对不同的VRC部署。", "method": "ViPer通过模块化管道将结构化的多对象视觉感知与基于LLM的推理结合起来，解析视觉布局并将属性接地到问题语义中，从而推断目标坐标。", "result": "在六种主要的VRC提供商（VTT、Geetest、NetEase、Dingxiang、Shumei和Xiaodun）上进行评估时，ViPer达到了93.2%的成功率，超过了其他方法GraphNet (83.2%)、Oedipus (65.8%) 和Holistic（89.5%）。此外，在使用不同LLM骨干网络（GPT、Grook、DeepSeek和Kimi）时，ViPer仍能保持超过90％的准确性。提出了一种轻量级策略Template-Space Randomization（TSR），以减少攻击性能。", "conclusion": "ViPer框架展示了在视觉推理验证码解决中的优越性，并为设计既可由人类解决又能抵抗机器破解的CAPTCHA提供了新的思路。"}}
{"id": "2601.06460", "pdf": "https://arxiv.org/pdf/2601.06460", "abs": "https://arxiv.org/abs/2601.06460", "authors": ["Weihao Hong", "Zhiyuan Jiang", "Bingyu Shen", "Xinlei Guan", "Yangyi Feng", "Meng Xu", "Boyang Li"], "title": "Tone Matters: The Impact of Linguistic Tone on Hallucination in VLMs", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "10 pages, 6 figures, WACV Workshop", "summary": "Vision-Language Models (VLMs) are increasingly used in safety-critical applications that require reliable visual grounding. However, these models often hallucinate details that are not present in the image to satisfy user prompts. While recent datasets and benchmarks have been introduced to evaluate systematic hallucinations in VLMs, many hallucination behaviors remain insufficiently characterized. In particular, prior work primarily focuses on object presence or absence, leaving it unclear how prompt phrasing and structural constraints can systematically induce hallucinations. In this paper, we investigate how different forms of prompt pressure influence hallucination behavior. We introduce Ghost-100, a procedurally generated dataset of synthetic scenes in which key visual details are deliberately removed, enabling controlled analysis of absence-based hallucinations. Using a structured 5-Level Prompt Intensity Framework, we vary prompts from neutral queries to toxic demands and rigid formatting constraints. We evaluate three representative open-weight VLMs: MiniCPM-V 2.6-8B, Qwen2-VL-7B, and Qwen3-VL-8B. Across all three models, hallucination rates do not increase monotonically with prompt intensity. All models exhibit reductions at higher intensity levels at different thresholds, though not all show sustained reduction under maximum coercion. These results suggest that current safety alignment is more effective at detecting semantic hostility than structural coercion, revealing model-specific limitations in handling compliance pressure. Our dataset is available at: https://github.com/bli1/tone-matters", "AI": {"tldr": "研究探讨了不同类型的提示压力如何影响视觉语言模型（VLM）的幻觉行为。", "motivation": "为了深入理解提示语句和结构约束如何系统性地引发VLM幻觉，尤其是在安全性至关重要的应用场景中。现有工作主要关注物体是否存在，未充分探讨提示措辞的影响。", "method": "引入Ghost-100数据集，并使用5级提示强度框架评估三种代表性开放权重的视觉语言模型：MiniCPM-V 2.6-8B、Qwen2-VL-7B和Qwen3-VL-8B。通过对比不同压力级别的提示效果来分析幻觉。", "result": "实验结果显示，随着提示强度增加，并非所有模型的幻觉率都会单调上升；某些情况下反而会下降，表明当前的安全校准在检测语义敌意方面表现较好，但处理结构性强迫时存在局限性。", "conclusion": "研究揭示了不同形式的提示压力对视觉语言模型的影响机制及其特定限制。"}}
{"id": "2601.06458", "pdf": "https://arxiv.org/pdf/2601.06458", "abs": "https://arxiv.org/abs/2601.06458", "authors": ["Sayak Chakrabarty", "Souradip Pal"], "title": "PixRec: Leveraging Visual Context for Next-Item Prediction in Sequential Recommendation", "categories": ["cs.IR", "cs.CV", "cs.LG"], "comment": "9 pages, 2 figures", "summary": "Large Language Models (LLMs) have recently shown strong potential for usage in sequential recommendation tasks through text-only models, which combine advanced prompt design, contrastive alignment, and fine-tuning on downstream domain-specific data. While effective, these approaches overlook the rich visual information present in many real-world recommendation scenarios, particularly in e-commerce. This paper proposes PixRec - a vision-language framework that incorporates both textual attributes and product images into the recommendation pipeline. Our architecture leverages a vision-language model backbone capable of jointly processing image-text sequences, maintaining a dual-tower structure and mixed training objective while aligning multi-modal feature projections for both item-item and user-item interactions. Using the Amazon Reviews dataset augmented with product images, our experiments demonstrate $3\\times$ and 40% improvements in top-rank and top-10 rank accuracy over text-only recommenders respectively, indicating that visual features can help distinguish items with similar textual descriptions. Our work outlines future directions for scaling multi-modal recommenders training, enhancing visual-text feature fusion, and evaluating inference-time performance. This work takes a step toward building software systems utilizing visual information in sequential recommendation for real-world applications like e-commerce.", "AI": {"tldr": "PixRec利用视觉上下文信息来提高序列推荐任务的准确性。", "motivation": "当前文本模型在序列推荐中表现良好，但忽略了现实世界场景中的丰富视觉信息。此研究旨在结合视觉和语言信息以提升推荐效果。", "method": "提出了一个基于视觉-语言框架PixRec，该框架能够同时处理图像和文本序列，并采用双塔结构和混合训练目标来对齐多模态特征投影。", "result": "在Amazon Reviews数据集上进行的实验表明，PixRec相比纯文本推荐器，在顶级和前十排名准确率上有3倍和40%的提升。", "conclusion": "研究展示了视觉信息对于区分具有类似描述的商品的重要性，并提出了未来多模态推荐系统训练、特征融合及推理性能评估的方向。"}}
{"id": "2601.06453", "pdf": "https://arxiv.org/pdf/2601.06453", "abs": "https://arxiv.org/abs/2601.06453", "authors": ["Hyungjun Yoon", "Mohammad Malekzadeh", "Sung-Ju Lee", "Fahim Kawsar", "Lorena Qendro"], "title": "ConSensus: Multi-Agent Collaboration for Multimodal Sensing", "categories": ["cs.AI"], "comment": "17 pages, 6 figures, 5 tables", "summary": "Large language models (LLMs) are increasingly grounded in sensor data to perceive and reason about human physiology and the physical world. However, accurately interpreting heterogeneous multimodal sensor data remains a fundamental challenge. We show that a single monolithic LLM often fails to reason coherently across modalities, leading to incomplete interpretations and prior-knowledge bias. We introduce ConSensus, a training-free multi-agent collaboration framework that decomposes multimodal sensing tasks into specialized, modality-aware agents. To aggregate agent-level interpretations, we propose a hybrid fusion mechanism that balances semantic aggregation, which enables cross-modal reasoning and contextual understanding, with statistical consensus, which provides robustness through agreement across modalities. While each approach has complementary failure modes, their combination enables reliable inference under sensor noise and missing data. We evaluate ConSensus on five diverse multimodal sensing benchmarks, demonstrating an average accuracy improvement of 7.1% over the single-agent baseline. Furthermore, ConSensus matches or exceeds the performance of iterative multi-agent debate methods while achieving a 12.7 times reduction in average fusion token cost through a single-round hybrid fusion protocol, yielding a robust and efficient solution for real-world multimodal sensing tasks.", "AI": {"tldr": "介绍了一种名为ConSensus的多代理协作框架，用于解决异构多模态传感器数据解释问题。", "motivation": "单个大规模语言模型难以在不同模式间进行连贯推理，导致理解不全面和先验知识偏见。通过多代理协同工作可以改善这一状况。", "method": "提出了一种训练无需的多代理协作框架ConSensus，将多模态感知任务分解为专门化的模式感知代理，并采用混合融合机制来聚合代理级别的解释。", "result": "在五个不同的多模态感知基准测试中展示了比单一代理基线平均准确度提高7.1%，同时通过单轮混合融合协议减少融合标记成本，实现了与迭代多代理辩论方法相当甚至更优的性能。", "conclusion": "ConSensus提供了一种可靠、高效且经济的方法来解决现实世界中的多模态感知任务。"}}
{"id": "2601.06451", "pdf": "https://arxiv.org/pdf/2601.06451", "abs": "https://arxiv.org/abs/2601.06451", "authors": ["Hyunseo Koh", "Chang-Yong Song", "Youngjae Choi", "Misa Viveiros", "David Hyde", "Heewon Kim"], "title": "CulinaryCut-VLAP: A Vision-Language-Action-Physics Framework for Food Cutting via a Force-Aware Material Point Method", "categories": ["cs.RO", "cs.CV"], "comment": "16 pages; 15 figures; 5 tables", "summary": "Food cutting is a highly practical yet underexplored application at the intersection of vision and robotic manipulation. The task remains challenging because interactions between the knife and deformable materials are highly nonlinear and often entail large deformations, frequent contact, and topological change, which in turn hinder stable and safe large-scale data collection. To address these challenges, we propose a unified framework that couples a vision-language-action (VLA) dataset with a physically realistic cutting simulator built on the material point method (MPM). Our simulator adopts MLS-MPM as its computational core, reducing numerical dissipation and energy drift while preserving rotational and shear responses even under topology-changing cuts. During cutting, forces and stress distributions are estimated from impulse exchanges between particles and the grid, enabling stable tracking of transient contact forces and energy transfer. We also provide a benchmark dataset that integrates diverse cutting trajectories, multi-view visual observations, and fine-grained language instructions, together with force--torque and tool--pose labels to provide physically consistent training signals. These components realize a learning--evaluation loop that respects the core physics of cutting and establishes a safe, reproducible, and scalable foundation for advancing VLA models in deformable object manipulation.", "AI": {"tldr": "本文提出了一种视觉-语言-动作-物理框架，用于通过带有力感知的材料点方法进行食品切割。", "motivation": "食物切割是一个实际但研究不足的应用领域，由于刀具与可变形材料之间的交互高度非线性和频繁接触等问题，数据收集变得困难。该论文旨在解决这些问题。", "method": "提出了一种结合视觉-语言-动作数据集和基于材料点方法的物理仿真器的统一框架。仿真器的核心是MLS-MPM，能够减少数值耗散并保持旋转和剪切响应，即使在拓扑变化的情况下也能稳定地跟踪瞬态接触力和能量传递。", "result": "通过提供一个基准数据集，该数据集包含多样化的切割轨迹、多视图视觉观察和细粒度语言指令，并附带力-扭矩和工具姿势标签，为训练信号提供了物理一致性。这些组件实现了一个尊重切割核心物理学的学习评估循环。", "conclusion": "本文框架建立了一种安全可重复且可扩展的基础，以推进在变形物体操作中的视觉-语言-动作模型的发展。"}}
{"id": "2601.06445", "pdf": "https://arxiv.org/pdf/2601.06445", "abs": "https://arxiv.org/abs/2601.06445", "authors": ["Mingzhe Lu", "Yiwen Wang", "Yanbing Liu", "Qi You", "Chong Liu", "Ruize Qin", "Haoyu Dong", "Wenyu Zhang", "Jiarui Zhang", "Yue Hu", "Yunpeng Li"], "title": "LitVISTA: A Benchmark for Narrative Orchestration in Literary Text", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Computational narrative analysis aims to capture rhythm, tension, and emotional dynamics in literary texts. Existing large language models can generate long stories but overly focus on causal coherence, neglecting the complex story arcs and orchestration inherent in human narratives. This creates a structural misalignment between model- and human-generated narratives. We propose VISTA Space, a high-dimensional representational framework for narrative orchestration that unifies human and model narrative perspectives. We further introduce LitVISTA, a structurally annotated benchmark grounded in literary texts, enabling systematic evaluation of models' narrative orchestration capabilities. We conduct oracle evaluations on a diverse selection of frontier LLMs, including GPT, Claude, Grok, and Gemini. Results reveal systematic deficiencies: existing models fail to construct a unified global narrative view, struggling to jointly capture narrative function and structure. Furthermore, even advanced thinking modes yield only limited gains for such literary narrative understanding.", "AI": {"tldr": "提出LitVISTA基准，评估模型在文学叙事结构和情感动态方面的表现。", "motivation": "现有大型语言模型生成的故事过于注重因果连贯性而忽视了复杂故事情节的编排。这导致模型生成的叙述与人类创作之间存在结构性差异。", "method": "提出了VISTA空间框架，统一人机叙事视角；引入LitVISTA基准集，以文学文本为基础进行结构化标注，评估大型语言模型的叙事能力。", "result": "实验显示现有模型难以构建全局连贯的故事叙述，无法同时捕捉故事情节的功能和结构。高级思维模式仅对提升文学叙事理解能力有限帮助。", "conclusion": "LitVISTA提供了新的工具来评测和改善大型语言模型在复杂故事编排方面的表现，促进了人机叙事的统一性研究。"}}
{"id": "2601.06443", "pdf": "https://arxiv.org/pdf/2601.06443", "abs": "https://arxiv.org/abs/2601.06443", "authors": ["Xiaoya Tang", "Xiaohe Yue", "Heran Mane", "Dapeng Li", "Quynh Nguyen", "Tolga Tasdizen"], "title": "How to Build Robust, Scalable Models for GSV-Based Indicators in Neighborhood Research", "categories": ["cs.CV"], "comment": null, "summary": "A substantial body of health research demonstrates a strong link between neighborhood environments and health outcomes. Recently, there has been increasing interest in leveraging advances in computer vision to enable large-scale, systematic characterization of neighborhood built environments. However, the generalizability of vision models across fundamentally different domains remains uncertain, for example, transferring knowledge from ImageNet to the distinct visual characteristics of Google Street View (GSV) imagery. In applied fields such as social health research, several critical questions arise: which models are most appropriate, whether to adopt unsupervised training strategies, what training scale is feasible under computational constraints, and how much such strategies benefit downstream performance. These decisions are often costly and require specialized expertise. In this paper, we answer these questions through empirical analysis and provide practical insights into how to select and adapt foundation models for datasets with limited size and labels, while leveraging larger, unlabeled datasets through unsupervised training. Our study includes comprehensive quantitative and visual analyses comparing model performance before and after unsupervised adaptation.", "AI": {"tldr": "该论文研究如何为基于Google街景图的社区环境指标构建稳健且可扩展的模型。", "motivation": "健康研究表明，社区环境与健康结果之间存在强烈联系。然而，在利用计算机视觉进行大规模、系统性地描述社区物理环境时，关于跨不同域的数据集上预训练模型的泛化能力的问题仍然存在不确定性。", "method": "通过实证分析来探讨在资源受限条件下选择和调整基础模型的方法，同时探索无监督学习策略对性能的影响。", "result": "论文进行了全面的数量和视觉分析比较模型在无监督适应前后的表现，并提供了实用的见解。", "conclusion": "研究结果表明，在较小的数据集上进行有限标签训练并通过更大、未标记数据集实现无监督适应的方法是有效的。"}}
{"id": "2601.06442", "pdf": "https://arxiv.org/pdf/2601.06442", "abs": "https://arxiv.org/abs/2601.06442", "authors": ["Xianghong Zou", "Jianping Li", "Yandi Yang", "Weitong Wu", "Yuan Wang", "Qiegen Liu", "Zhen Dong"], "title": "WHU-PCPR: A cross-platform heterogeneous point cloud dataset for place recognition in complex urban scenes", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Point Cloud-based Place Recognition (PCPR) demonstrates considerable potential in applications such as autonomous driving, robot localization and navigation, and map update. In practical applications, point clouds used for place recognition are often acquired from different platforms and LiDARs across varying scene. However, existing PCPR datasets lack diversity in scenes, platforms, and sensors, which limits the effective development of related research. To address this gap, we establish WHU-PCPR, a cross-platform heterogeneous point cloud dataset designed for place recognition. The dataset differentiates itself from existing datasets through its distinctive characteristics: 1) cross-platform heterogeneous point clouds: collected from survey-grade vehicle-mounted Mobile Laser Scanning (MLS) systems and low-cost Portable helmet-mounted Laser Scanning (PLS) systems, each equipped with distinct mechanical and solid-state LiDAR sensors. 2) Complex localization scenes: encompassing real-time and long-term changes in both urban and campus road scenes. 3) Large-scale spatial coverage: featuring 82.3 km of trajectory over a 60-month period and an unrepeated route of approximately 30 km. Based on WHU-PCPR, we conduct extensive evaluation and in-depth analysis of several representative PCPR methods, and provide a concise discussion of key challenges and future research directions. The dataset and benchmark code are available at https://github.com/zouxianghong/WHU-PCPR.", "AI": {"tldr": "构建了一个跨平台的点云数据集用于复杂城市环境中的位置识别。", "motivation": "现有数据集中缺乏多样性的场景、平台和传感器限制了相关研究的有效发展，为此建立了WHU-PCPR数据集以解决这个问题。", "method": "收集来自不同移动激光扫描系统和便携式头戴式激光扫描系统的点云，并进行了广泛的评估和深入分析。", "result": "该数据集涵盖城市道路和校园场景中的实时与长期变化，具有大规模的空间覆盖范围。", "conclusion": "WHU-PCPR为位置识别提供了一个有价值的资源并指出了未来研究的关键挑战方向。"}}
{"id": "2601.06434", "pdf": "https://arxiv.org/pdf/2601.06434", "abs": "https://arxiv.org/abs/2601.06434", "authors": ["Abhinav Raghuvanshi", "Mayank Baranwal", "Debasish Chatterjee"], "title": "On a Gradient Approach to Chebyshev Center Problems with Applications to Function Learning", "categories": ["math.OC", "cs.AI", "cs.LG"], "comment": "Accepted to TMLR", "summary": "We introduce $\\textsf{gradOL}$, the first gradient-based optimization framework for solving Chebyshev center problems, a fundamental challenge in optimal function learning and geometric optimization. $\\textsf{gradOL}$ hinges on reformulating the semi-infinite problem as a finitary max-min optimization, making it amenable to gradient-based techniques. By leveraging automatic differentiation for precise numerical gradient computation, $\\textsf{gradOL}$ ensures numerical stability and scalability, making it suitable for large-scale settings. Under strong convexity of the ambient norm, $\\textsf{gradOL}$ provably recovers optimal Chebyshev centers while directly computing the associated radius. This addresses a key bottleneck in constructing stable optimal interpolants. Empirically, $\\textsf{gradOL}$ achieves significant improvements in accuracy and efficiency on 34 benchmark Chebyshev center problems from a benchmark $\\textsf{CSIP}$ library. Moreover, we extend $\\textsf{gradOL}$ to general convex semi-infinite programming (CSIP), attaining up to $4000\\times$ speedups over the state-of-the-art $\\texttt{SIPAMPL}$ solver tested on the indicated $\\textsf{CSIP}$ library containing 67 benchmark problems. Furthermore, we provide the first theoretical foundation for applying gradient-based methods to Chebyshev center problems, bridging rigorous analysis with practical algorithms. $\\textsf{gradOL}$ thus offers a unified solution framework for Chebyshev centers and broader CSIPs.", "AI": {"tldr": "本文提出了gradOL框架，用于解决Chebyshev中心问题，并展示了其在函数学习和几何优化中的应用。", "motivation": "当前的Chebyshev中心问题解决方案缺乏高效性和稳定性。为了解决这个问题，作者提出了一种基于梯度的方法来优化这些问题，以便于大规模数据集的应用。", "method": "通过将无限问题转化为有限的最大最小化优化问题，gradOL利用自动微分技术准确计算数值梯度，从而提高稳定性和可扩展性。", "result": "实验表明，在34个基准Chebyshev中心问题上，gradOL在精度和效率方面取得了显著改进。此外，与现有SIPAMPL求解器相比，在67个CSIP库中的问题上实现了高达4000倍的速度提升。", "conclusion": "通过提供理论基础和实际应用框架，gradOL不仅解决了Chebyshev中心问题，还为更广泛的凸半无限规划提供了统一解决方案。"}}
{"id": "2601.06431", "pdf": "https://arxiv.org/pdf/2601.06431", "abs": "https://arxiv.org/abs/2601.06431", "authors": ["Qingyu Ren", "Qianyu He", "Jingwen Chang", "Jie Zeng", "Jiaqing Liang", "Yanghua Xiao", "Han Xia", "Zeye Sun", "Fei Yu"], "title": "LSRIF: Logic-Structured Reinforcement Learning for Instruction Following", "categories": ["cs.AI"], "comment": null, "summary": "Instruction-following is critical for large language models, but real-world instructions often contain logical structures such as sequential dependencies and conditional branching. Existing methods typically construct datasets with parallel constraints and optimize average rewards, ignoring logical dependencies and yielding noisy signals. We propose a logic-structured training framework LSRIF that explicitly models instruction logic. We first construct a dataset LSRInstruct with constraint structures such as parallel, sequential, and conditional types, and then design structure-aware rewarding method LSRIF including average aggregation for parallel structures, failure-penalty propagation for sequential structures, and selective rewards for conditional branches. Experiments show LSRIF brings significant improvements in instruction-following (in-domain and out-of-domain) and general reasoning. Analysis reveals that learning with explicit logic structures brings parameter updates in attention layers and sharpens token-level attention to constraints and logical operators.", "AI": {"tldr": "提出了LSRIF框架，用于处理指令跟随任务中的逻辑结构。", "motivation": "现有方法忽视了真实世界指令中的逻辑依赖性，导致信号噪声和性能不佳。", "method": "构建包含约束结构的LSRInstruct数据集，并设计基于平均聚合、失败惩罚传播及选择奖励的LSRIF奖励机制。", "result": "实验显示LSRIF在指令跟随（领域内与外）和一般推理方面均有显著改进，且能明确更新注意力层参数并聚焦于逻辑运算符。", "conclusion": "通过显式建模指令逻辑结构可以提高模型性能。"}}
{"id": "2601.06426", "pdf": "https://arxiv.org/pdf/2601.06426", "abs": "https://arxiv.org/abs/2601.06426", "authors": ["Robert J. Moore", "Sungeun An", "Farhan Ahmed", "Jay Pankaj Gala"], "title": "NC-Bench: An LLM Benchmark for Evaluating Conversational Competence", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 1 figure, 2 tables", "summary": "The Natural Conversation Benchmark (NC-Bench) introduce a new approach to evaluating the general conversational competence of large language models (LLMs). Unlike prior benchmarks that focus on the content of model behavior, NC-Bench focuses on the form and structure of natural conversation. Grounded in the IBM Natural Conversation Framework (NCF), NC-Bench comprises three distinct sets. The Basic Conversation Competence set evaluates fundamental sequence management practices, such as answering inquiries, repairing responses, and closing conversational pairs. The RAG set applies the same sequence management patterns as the first set but incorporates retrieval-augmented generation (RAG). The Complex Request set extends the evaluation to complex requests involving more intricate sequence management patterns. Each benchmark tests a model's ability to produce contextually appropriate conversational actions in response to characteristic interaction patterns. Initial evaluations across 6 open-source models and 14 interaction patterns show that models perform well on basic answering tasks, struggle more with repair tasks (especially repeat), have mixed performance on closing sequences, and find complex multi-turn requests most challenging, with Qwen models excelling on the Basic set and Granite models on the RAG set and the Complex Request set. By operationalizing fundamental principles of human conversation, NC-Bench provides a lightweight, extensible, and theory-grounded framework for assessing and improving the conversational abilities of LLMs beyond topical or task-specific benchmarks.", "AI": {"tldr": "NC-Bench是一款用于评估大型语言模型（LLMs）对话能力的新基准，关注对话的形式和结构而非内容。", "motivation": "当前的评估标准多集中在模型行为的内容上，而忽略了自然对话的形式和结构。为了弥补这一不足，提出了一种新的基准，专注于评估LLMs在处理基础、检索增强生成和复杂请求方面的能力。", "method": "NC-Bench基于IBM自然对话框架（NCF），包含三个不同的集合：基本对话能力集、RAG集以及复杂的请求集。每个集合通过特定的交互模式来测试模型产生适当对话行为的能力。", "result": "初步评估显示，开源模型在基础问答任务中表现良好，在修复对话和关闭序列方面存在困难，并且在处理多轮复杂请求时表现出最大的挑战性。", "conclusion": "NC-Bench提供了一个轻量级、可扩展且基于理论的框架来衡量和提升LLMs的对话能力。"}}
{"id": "2601.06425", "pdf": "https://arxiv.org/pdf/2601.06425", "abs": "https://arxiv.org/abs/2601.06425", "authors": ["Mohammad Pivezhandi", "Abusayeed Saifullah", "Ali Jannesari"], "title": "HiDVFS: A Hierarchical Multi-Agent DVFS Scheduler for OpenMP DAG Workloads", "categories": ["cs.DC", "cs.AI"], "comment": "38 pages, 15 figures, 8 tables", "summary": "With advancements in multicore embedded systems, leakage power, exponentially tied to chip temperature, has surpassed dynamic power consumption. Energy-aware solutions use dynamic voltage and frequency scaling (DVFS) to mitigate overheating in performance-intensive scenarios, while software approaches allocate high-utilization tasks across core configurations in parallel systems to reduce power. However, existing heuristics lack per-core frequency monitoring, failing to address overheating from uneven core activity, and task assignments without detailed profiling overlook irregular execution patterns. We target OpenMP DAG workloads. Because makespan, energy, and thermal goals often conflict within a single benchmark, this work prioritizes performance (makespan) while reporting energy and thermal as secondary outcomes. To overcome these issues, we propose HiDVFS (a hierarchical multi-agent, performance-aware DVFS scheduler) for parallel systems that optimizes task allocation based on profiling data, core temperatures, and makespan-first objectives. It employs three agents: one selects cores and frequencies using profiler data, another manages core combinations via temperature sensors, and a third sets task priorities during resource contention. A makespan-focused reward with energy and temperature regularizers estimates future states and enhances sample efficiency. Experiments on the NVIDIA Jetson TX2 using the BOTS suite (9 benchmarks) compare HiDVFS against state-of-the-art approaches. With multi-seed validation (seeds 42, 123, 456), HiDVFS achieves the best finetuned performance with 4.16 plus/minus 0.58s average makespan (L10), representing a 3.44x speedup over GearDVFS (14.32 plus/minus 2.61s) and 50.4% energy reduction (63.7 kJ vs 128.4 kJ). Across all BOTS benchmarks, HiDVFS achieves an average 3.95x speedup and 47.1% energy reduction.", "AI": {"tldr": "HiDVFS是一种针对OpenMP DAG工作负载的分层多代理动态电压频率调整调度器，旨在优化任务分配以减少能耗并提高性能。", "motivation": "当前能源意识解决方案在处理性能密集型场景时存在不足，缺乏对核心温度监控以及对于非均匀核心活动导致过热的问题没有解决办法。此外，在并行系统中分配高利用率任务而忽略详细执行模式也会带来问题。", "method": "提出了一种新的调度算法HiDVFS,该算法使用三个代理分别负责根据性能分析数据选择核心和频率、通过温度传感器管理核心组合以及在资源争用时设定任务优先级。同时采用了基于时间目标的奖励机制来估计未来状态并提高样本效率。", "result": "实验表明，与现有最佳方法相比，在NVIDIA Jetson TX2平台上使用BOTS套件进行测试时，HiDVFS能够在平均完成时间和能耗方面分别实现3.44倍的速度提升和50.4%的能源节省。", "conclusion": "该研究通过引入分层多代理机制有效解决了现有调度算法存在的问题，并在实验中验证了其优越性。"}}
{"id": "2601.06423", "pdf": "https://arxiv.org/pdf/2601.06423", "abs": "https://arxiv.org/abs/2601.06423", "authors": ["Deep Mehta"], "title": "Does Inference Scaling Improve Reasoning Faithfulness? A Multi-Model Analysis of Self-Consistency Tradeoffs", "categories": ["cs.AI"], "comment": "24 pages, 3 figures, 9 tables", "summary": "Self-consistency has emerged as a popular technique for improving large language model accuracy on reasoning tasks. The approach is straightforward: generate multiple reasoning paths and select the most common answer through majority voting. While this reliably boosts accuracy, it remains unclear whether these gains reflect genuine improvements in reasoning quality. We investigate a fundamental question that has not been studied before: does inference scaling improve reasoning faithfulness? We conduct a comprehensive empirical study across four frontier models (GPT-5.2, Claude Opus 4.5, Gemini-3-flash-preview, and DeepSeek-v3.2) on 100 GSM8K mathematical reasoning problems. Our analysis employs bootstrap confidence intervals, McNemar's tests for paired comparisons, and Cohen's d effect sizes to quantify the effects rigorously. The results reveal striking differences across models that challenge common assumptions about self-consistency. GPT-5.2 shows the expected pattern: accuracy improves from 78% to 90% at N=5, with faithfulness remaining relatively stable (0.540 to 0.510). Claude Opus 4.5 tells a completely different story. Its accuracy actually drops from 78% to 74.3% while faithfulness jumps dramatically from 0.270 to 0.891 at N=5. DeepSeek-v3.2, already at 98% accuracy, shows ceiling effects with modest faithfulness gains (0.440 to 0.541). Gemini-3-flash improves from 81% to 86% accuracy with a slight faithfulness decrease (0.260 to 0.212). Problem difficulty analysis reveals that GPT-5.2 solves 82% of hard problems while breaking only 13% of easy ones. Claude, in contrast, breaks 23% of easy problems, explaining its accuracy decrease. These findings matter for practitioners: self-consistency is not universally beneficial, and teams should test their specific models before deployment. We release our code and provide practical recommendations for navigating these tradeoffs.", "AI": {"tldr": "研究探讨了推理扩展是否能提高大语言模型在数学推理任务中的忠实度，通过多模型分析发现不同模型的表现各异。", "motivation": "自一致性的方法被用来提升大型语言模型的准确性。然而这种方法是否真的提高了推理质量尚不清楚，因此作者希望通过实验来探究这个问题。", "method": "研究使用了GPT-5.2、Claude Opus 4.5、Gemini-3-flash-preview和DeepSeek-v3.2四个前沿模型，在100个GSM8K数学推理问题上进行多模型分析，采用自助法置信区间、配对比较的麦克尼马拉检验以及Cohen's d效应量来量化效果。", "result": "研究结果表明不同模型在准确性及忠实度上的表现差异显著，自一致性并不总是有益的。例如GPT-5.2和Claude Opus 4.5的表现就完全不同，前者准确率提高而忠实度略有下降；后者准确率降低但忠实度大幅上升。", "conclusion": "研究发现对于实际应用来说，自我一致性的技术并不是普遍适用的解决方案，建议团队在模型部署前进行特定测试。"}}
{"id": "2601.06415", "pdf": "https://arxiv.org/pdf/2601.06415", "abs": "https://arxiv.org/abs/2601.06415", "authors": ["Nathan Pascal Walus", "Ranulfo Bezerra", "Shotaro Kojima", "Tsige Tadesse Alemayoh", "Satoshi Tadokoro", "Kazunori Ohno"], "title": "Semantic Enrichment of CAD-Based Industrial Environments via Scene Graphs for Simulation and Reasoning", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Accepted to IEEE SSRR 2025", "summary": "Utilizing functional elements in an industrial environment, such as displays and interactive valves, provide effective possibilities for robot training. When preparing simulations for robots or applications that involve high-level scene understanding, the simulation environment must be equally detailed. Although CAD files for such environments deliver an exact description of the geometry and visuals, they usually lack semantic, relational and functional information, thus limiting the simulation and training possibilities. A 3D scene graph can organize semantic, spatial and functional information by enriching the environment through a Large Vision-Language Model (LVLM). In this paper we present an offline approach to creating detailed 3D scene graphs from CAD environments. This will serve as a foundation to include the relations of functional and actionable elements, which then can be used for dynamic simulation and reasoning. Key results of this research include both quantitative results of the generated semantic labels as well as qualitative results of the scene graph, especially in hindsight of pipe structures and identified functional relations. All code, results and the environment will be made available at https://cad-scenegraph.github.io", "AI": {"tldr": "本文提出了一种离线方法，利用大型视觉语言模型丰富CAD环境中的语义信息，并生成详细场景图。", "motivation": "在机器人训练和高阶场景理解中，当前的CAD文件虽然提供了精确的几何形状和外观描述，但缺少功能性和关系性信息，限制了其模拟和培训能力。因此需要一种方法来补充这些缺失的信息。", "method": "通过大型视觉语言模型（LVLM）从CAD环境生成详细3D场景图，该方法可以组织语义、空间和功能性信息，并用于动态模拟和推理。", "result": "研究结果显示了所生成的语义标签的质量以及场景图对管道结构识别和功能关系的重要性。", "conclusion": "通过这种方法获得的功能丰富且详细的环境描述能够提高机器人训练及高阶场景理解的能力。"}}
{"id": "2601.06413", "pdf": "https://arxiv.org/pdf/2601.06413", "abs": "https://arxiv.org/abs/2601.06413", "authors": ["Yueming Pan", "Ruoyu Feng", "Jianmin Bao", "Chong Luo", "Nanning Zheng"], "title": "GlobalPaint: Spatiotemporal Coherent Video Outpainting with Global Feature Guidance", "categories": ["cs.CV"], "comment": null, "summary": "Video outpainting extends a video beyond its original boundaries by synthesizing missing border content. Compared with image outpainting, it requires not only per-frame spatial plausibility but also long-range temporal coherence, especially when outpainted content becomes visible across time under camera or object motion. We propose GlobalPaint, a diffusion-based framework for spatiotemporal coherent video outpainting. Our approach adopts a hierarchical pipeline that first outpaints key frames and then completes intermediate frames via an interpolation model conditioned on the completed boundaries, reducing error accumulation in sequential processing. At the model level, we augment a pretrained image inpainting backbone with (i) an Enhanced Spatial-Temporal module featuring 3D windowed attention for stronger spatiotemporal interaction, and (ii) global feature guidance that distills OpenCLIP features from observed regions across all frames into compact global tokens using a dedicated extractor. Comprehensive evaluations on benchmark datasets demonstrate improved reconstruction quality and more natural motion compared to prior methods. Our demo page is https://yuemingpan.github.io/GlobalPaint/", "AI": {"tldr": "全球绘画(GlobalPaint)提出了一个基于扩散的框架，用于时空一致性的视频外插。", "motivation": "与图像外插相比，视频外插需要不仅每帧的空间合理性而且在相机或对象运动下长时间的时序连贯性。现有方法中，错误会在顺序处理过程中积累。", "method": "提出了一种分层管道，首先外插关键帧然后通过条件插值模型完成中间帧以减少误差累积；采用增强时空模块和全局特征引导机制来提升空间时间和长程时间一致性。", "result": "在基准数据集上的综合评估显示重建质量得到了改进，并且与先前方法相比运动更加自然。", "conclusion": "GlobalPaint通过引入基于扩散的框架、分层管道设计以及创新性的时空模块和全局特征引导机制，显著提高了视频外插的质量和时序连贯性。"}}
{"id": "2601.06406", "pdf": "https://arxiv.org/pdf/2601.06406", "abs": "https://arxiv.org/abs/2601.06406", "authors": ["Linfei Li", "Lin Zhang", "Zhong Wang", "Fengyi Zhang", "Zelin Li", "Ying Shen"], "title": "Representing Sounds as Neural Amplitude Fields: A Benchmark of Coordinate-MLPs and A Fourier Kolmogorov-Arnold Framework", "categories": ["cs.SD"], "comment": "Accepted by AAAI 2025. Code: https://github.com/lif314/Fourier-ASR", "summary": "Although Coordinate-MLP-based implicit neural representations have excelled in representing radiance fields, 3D shapes, and images, their application to audio signals remains underexplored. To fill this gap, we investigate existing implicit neural representations, from which we extract 3 types of positional encoding and 16 commonly used activation functions. Through combinatorial design, we establish the first benchmark for Coordinate-MLPs in audio signal representations. Our benchmark reveals that Coordinate-MLPs require complex hyperparameter tuning and frequency-dependent initialization, limiting their robustness. To address these issues, we propose Fourier-ASR, a novel framework based on the Fourier series theorem and the Kolmogorov-Arnold representation theorem. Fourier-ASR introduces Fourier Kolmogorov-Arnold Networks (Fourier-KAN), which leverage periodicity and strong nonlinearity to represent audio signals, eliminating the need for additional positional encoding. Furthermore, a Frequency-adaptive Learning Strategy (FaLS) is proposed to enhance the convergence of Fourier-KAN by capturing high-frequency components and preventing overfitting of low-frequency signals. Extensive experiments conducted on natural speech and music datasets reveal that: (1) well-designed positional encoding and activation functions in Coordinate-MLPs can effectively improve audio representation quality; and (2) Fourier-ASR can robustly represent complex audio signals without extensive hyperparameter tuning. Looking ahead, the continuity and infinite resolution of implicit audio representations make our research highly promising for tasks such as audio compression, synthesis, and generation. The source code will be released publicly to ensure reproducibility. The code is available at https://github.com/lif314/Fourier-ASR.", "AI": {"tldr": "该论文提出了基于傅里叶级数定理和柯尔莫哥洛夫-阿诺索夫表示定理的Fourier-ASR框架，用于音频信号的神经网络表征，并进行了广泛的实验验证。", "motivation": "虽然坐标MLP在表示辐射场、3D形状和图像方面表现出色，但在音频信号表示方面的研究仍相对较少。为填补这一空白，该论文探索了现有的隐式神经表示方法，并提出了一个新的基准测试和改进框架来解决现有方法的局限性。", "method": "通过组合设计，作者建立了第一个用于音频信号表示的坐标MLP基准。他们发现这些模型需要复杂的超参数调整和频率依赖初始化，限制了它们的鲁棒性。为此，提出了一种新的基于傅里叶级数定理和柯尔莫哥洛夫-阿诺索夫表征定理的Fourier-ASR框架，并引入了傅里叶-柯尔莫戈洛夫-阿诺索夫网络（Fourier-KAN），以利用周期性和强非线性来表示音频信号，同时提出了一种频率自适应学习策略（FaLS）以提高收敛性。", "result": "实验结果表明：（1）在坐标MLP中设计良好的位置编码和激活函数可以有效改善音频表征质量；（2）Fourier-ASR能够在不进行大量超参数调整的情况下稳健地表示复杂的音频信号。这些发现对于如音频压缩、合成和生成等任务具有重要的意义。", "conclusion": "该论文通过提出傅里叶级数定理和柯尔莫哥洛夫-阿诺索夫表征理论为基础的Fourier-ASR框架，成功解决了坐标MLP在音频信号表示中的局限性问题。这种隐式音频表示方法因其连续性和无限分辨率而具有高度潜力，在未来的研究中有着广阔的应用前景。"}}
{"id": "2601.06402", "pdf": "https://arxiv.org/pdf/2601.06402", "abs": "https://arxiv.org/abs/2601.06402", "authors": ["Woojin Jung", "Charles Chear", "Andrew H. Kim", "Vatsal Shah", "Tawfiq Ammari"], "title": "Spatiotemporal Change-Points in Development Discourse: Insights from Social Media in Low-Resource Contexts", "categories": ["cs.HC"], "comment": null, "summary": "This study investigates the spatiotemporal evolution of development discourse in low-resource settings. Analyzing more than two years of geotagged X data from Zambia, we introduce a mixed-methods pipeline utilizing topic modeling, change-point detection, and qualitative coding to identify critical shifts in public debate. We identify seven recurring themes, including public health challenges and frustration with government policy, shaped by regional events and national interventions. Notably, we detect discourse changepoints linked to the COVID19 pandemic and a geothermal project, illustrating how online conversations mirror policy flashpoints. Our analysis distinguishes between the ephemeral nature of acute crises like COVID19 and the persistent, structural reorientations driven by long-term infrastructure projects. We conceptualize \"durable discourse\" as sustained narrative engagement with development issues. Contributing to HCI and ICTD, we examine technology's socioeconomic impact, providing practical implications and future work for direct local engagement.", "AI": {"tldr": "本文研究了低资源环境下发展话语的时空演变，通过分析赞比亚两年多的地理标签X数据，使用混合方法管道识别公众讨论中的关键转变。", "motivation": "动机在于探究低资源地区发展对话中因区域事件和国家干预而形成的七种反复出现的主题及其时间变化。特别关注了与COVID19大流行和地热项目相关的对话转折点，以了解在线对话如何反映出政策关键时刻。", "method": "该研究采用了一套混合方法流程，包括主题建模、变更点检测和质性编码来识别公众讨论的关键转变，并区分急性危机（如疫情）和长期基础设施项目的持久话语。", "result": "研究发现了与公共卫生挑战和对政府政策的不满相关的七种反复出现的主题。同时揭示了在线对话中的变化节点，这些变化节点受到区域事件和国家干预的影响。", "conclusion": "该论文通过分析技术在低资源环境下的社会经济影响，提出了可持续话语的概念，并为直接当地参与提供了实际建议和未来的工作方向。"}}
{"id": "2601.06401", "pdf": "https://arxiv.org/pdf/2601.06401", "abs": "https://arxiv.org/abs/2601.06401", "authors": ["Xin Guo", "Rongjunchen Zhang", "Guilong Lu", "Xuntao Guo", "Shuai Jia", "Zhi Yang", "Liwen Zhang"], "title": "BizFinBench.v2: A Unified Dual-Mode Bilingual Benchmark for Expert-Level Financial Capability Alignment", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large language models have undergone rapid evolution, emerging as a pivotal technology for intelligence in financial operations. However, existing benchmarks are often constrained by pitfalls such as reliance on simulated or general-purpose samples and a focus on singular, offline static scenarios. Consequently, they fail to align with the requirements for authenticity and real-time responsiveness in financial services, leading to a significant discrepancy between benchmark performance and actual operational efficacy. To address this, we introduce BizFinBench.v2, the first large-scale evaluation benchmark grounded in authentic business data from both Chinese and U.S. equity markets, integrating online assessment. We performed clustering analysis on authentic user queries from financial platforms, resulting in eight fundamental tasks and two online tasks across four core business scenarios, totaling 29,578 expert-level Q&A pairs. Experimental results demonstrate that ChatGPT-5 achieves a prominent 61.5% accuracy in main tasks, though a substantial gap relative to financial experts persists; in online tasks, DeepSeek-R1 outperforms all other commercial LLMs. Error analysis further identifies the specific capability deficiencies of existing models within practical financial business contexts. BizFinBench.v2 transcends the limitations of current benchmarks, achieving a business-level deconstruction of LLM financial capabilities and providing a precise basis for evaluating efficacy in the widespread deployment of LLMs within the financial domain. The data and code are available at https://github.com/HiThink-Research/BizFinBench.v2.", "AI": {"tldr": "BizFinBench.v2 是一个基于真实商业数据的双模式多语言金融基准测试，旨在评估大型语言模型在实际金融服务中的表现。", "motivation": "现有的基准测试存在依赖于模拟或通用样本、静态场景等问题，无法满足金融服务的真实性和实时性要求。因此，需要一个新的基准来解决这些问题，并精确衡量大模型的实际应用效果。", "method": "通过聚类分析真实用户查询，确定了八个基础任务和两个在线评估任务，在四个核心业务场景下共有29,578个专家级问答对。测试涵盖了中英文双语数据集。", "result": "实验结果表明，ChatGPT-5在主要任务上达到61.5%的准确率，但与金融专家仍有差距；在线任务中DeepSeek-R1优于其他商业LLM。", "conclusion": "BizFinBench.v2解决了现有基准测试的局限性，为评估大型语言模型在金融服务中的应用提供了精确的基础。"}}
{"id": "2601.06394", "pdf": "https://arxiv.org/pdf/2601.06394", "abs": "https://arxiv.org/abs/2601.06394", "authors": ["Ahmed Abdelkawy", "Ahmed Elsayed", "Asem Ali", "Aly Farag", "Thomas Tretter", "Michael McIntyre"], "title": "Context Matters: Peer-Aware Student Behavioral Engagement Measurement via VLM Action Parsing and LLM Sequence Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Understanding student behavior in the classroom is essential to improve both pedagogical quality and student engagement. Existing methods for predicting student engagement typically require substantial annotated data to model the diversity of student behaviors, yet privacy concerns often restrict researchers to their own proprietary datasets. Moreover, the classroom context, represented in peers' actions, is ignored. To address the aforementioned limitation, we propose a novel three-stage framework for video-based student engagement measurement. First, we explore the few-shot adaptation of the vision-language model for student action recognition, which is fine-tuned to distinguish among action categories with a few training samples. Second, to handle continuous and unpredictable student actions, we utilize the sliding temporal window technique to divide each student's 2-minute-long video into non-overlapping segments. Each segment is assigned an action category via the fine-tuned VLM model, generating a sequence of action predictions. Finally, we leverage the large language model to classify this entire sequence of actions, together with the classroom context, as belonging to an engaged or disengaged student. The experimental results demonstrate the effectiveness of the proposed approach in identifying student engagement.", "AI": {"tldr": "该论文提出了一种通过视频语言模型解析学生行为和大型语言模型进行序列分类的方法，以测量学生的参与度。", "motivation": "现有的预测学生参与度方法需要大量的标注数据，并且忽略了课堂环境中的同伴行为。为解决这些问题，本研究提出了一个新颖的三阶段框架来衡量基于视频的学生参与度。", "method": "首先利用视觉语言模型进行学生行动识别；其次通过滑动时间窗口技术将每个学生的2分钟视频分为非重叠片段并分配行为类别；最后使用大型语言模型结合课堂环境对整个行为序列进行分类。", "result": "实验结果表明，提出的框架在确定学生参与度方面是有效的。", "conclusion": "本研究提出的方法能够有效地衡量基于视频的学生参与度，并且考虑了同伴行为的影响。"}}
{"id": "2601.06391", "pdf": "https://arxiv.org/pdf/2601.06391", "abs": "https://arxiv.org/abs/2601.06391", "authors": ["Saksham Singh Kushwaha", "Sayan Nag", "Yapeng Tian", "Kuldeep Kulkarni"], "title": "Object-WIPER : Training-Free Object and Associated Effect Removal in Videos", "categories": ["cs.CV"], "comment": "Project Page: https://sakshamsingh1.github.io/object_wiper_webpage/", "summary": "In this paper, we introduce Object-WIPER, a training-free framework for removing dynamic objects and their associated visual effects from videos, and inpainting them with semantically consistent and temporally coherent content. Our approach leverages a pre-trained text-to-video diffusion transformer (DiT). Given an input video, a user-provided object mask, and query tokens describing the target object and its effects, we localize relevant visual tokens via visual-text cross-attention and visual self-attention. This produces an intermediate effect mask that we fuse with the user mask to obtain a final foreground token mask to replace. We first invert the video through the DiT to obtain structured noise, then reinitialize the masked tokens with Gaussian noise while preserving background tokens. During denoising, we copy values for the background tokens saved during inversion to maintain scene fidelity. To address the lack of suitable evaluation, we introduce a new object removal metric that rewards temporal consistency among foreground tokens across consecutive frames, coherence between foreground and background tokens within each frame, and dissimilarity between the input and output foreground tokens. Experiments on DAVIS and a newly curated real-world associated effect benchmark (WIPER-Bench) show that Object-WIPER surpasses both training-based and training-free baselines in terms of the metric, achieving clean removal and temporally stable reconstruction without any retraining. Our new benchmark, source code, and pre-trained models will be publicly available.", "AI": {"tldr": "介绍了一种无需训练的框架，用于从视频中移除动态对象及其相关视觉效果，并用语义一致且时间连贯的内容进行填充。", "motivation": "提出了一种新的方法来解决视频中动态物体和其相关视觉效果去除的问题，特别是在不需要额外训练的情况下实现这一目标。", "method": "利用预训练的文本到视频扩散变换器（DiT），通过视觉-文本交叉注意力机制定位相关的视觉标记，并融合用户提供的对象掩码与生成的效果掩码。对视频进行逆向处理并使用高斯噪声替换被选中的令牌，同时保留背景令牌以维持场景的一致性。", "result": "在DAVIS数据集和新建立的WIPER-Bench基准测试上进行了实验，结果表明Object-WIPER超越了训练基线以及无训练基线方法。", "conclusion": "提出了一种新的无需训练的方法来去除视频中的动态对象及其相关视觉效果，并实现了时间稳定且高质量的重建。"}}
{"id": "2601.06387", "pdf": "https://arxiv.org/pdf/2601.06387", "abs": "https://arxiv.org/abs/2601.06387", "authors": ["Ke Shang", "Hisao Ishibuchi", "Zexuan Zhu", "Qingfu Zhang"], "title": "An Efficient Evolutionary Algorithm for Few-for-Many Optimization", "categories": ["cs.NE"], "comment": "This manuscript has been accepted for publication in IEEE/CAA Journal of Automatica Sinica", "summary": "Few-for-many (F4M) optimization, recently introduced as a novel paradigm in multi-objective optimization, aims to find a small set of solutions that effectively handle a large number of conflicting objectives. Unlike traditional many-objective optimization methods, which typically attempt comprehensive coverage of the Pareto front, F4M optimization emphasizes finding a small representative solution set to efficiently address high-dimensional objective spaces. Motivated by the computational complexity and practical relevance of F4M optimization, this paper proposes a new evolutionary algorithm explicitly tailored for efficiently solving F4M optimization problems. Inspired by SMS-EMOA, our proposed approach employs a $(μ+1)$-evolution strategy guided by the objective of F4M optimization. Furthermore, to facilitate rigorous performance assessment, we propose a novel benchmark test suite specifically designed for F4M optimization by leveraging the similarity between the R2 indicator and F4M formulations. Our test suite is highly flexible, allowing any existing multi-objective optimization problem to be transformed into a corresponding F4M instance via scalarization using the weighted Tchebycheff function. Comprehensive experimental evaluations on benchmarks demonstrate the superior performance of our algorithm compared to existing state-of-the-art algorithms, especially on instances involving a large number of objectives. The source code of the proposed algorithm will be released publicly. Source code is available at https://github.com/MOL-SZU/SoM-EMOA.", "AI": {"tldr": "提出了一种新的进化算法，用于解决少对多（F4M）优化问题。", "motivation": "解决高维目标空间中大量冲突目标的高效处理需求，减少计算复杂性并提高实用性", "method": "基于SMS-EMOA设计了一种$(μ+1)$演化策略，采用加权Tchebycheff函数进行标量化转换", "result": "实验证明该算法在涉及大量目标的问题上优于现有最先进的方法", "conclusion": "新提出的进化算法在处理F4M优化问题时表现出色，具有更高的效率和性能"}}
{"id": "2601.06377", "pdf": "https://arxiv.org/pdf/2601.06377", "abs": "https://arxiv.org/abs/2601.06377", "authors": ["Ningning Zhang", "Xingxing Yang", "Zhizhong Tan", "Weiping Deng", "Wenyong Wang"], "title": "HiMem: Hierarchical Long-Term Memory for LLM Long-Horizon Agents", "categories": ["cs.AI"], "comment": null, "summary": "Although long-term memory systems have made substantial progress in recent years, they still exhibit clear limitations in adaptability, scalability, and self-evolution under continuous interaction settings. Inspired by cognitive theories, we propose HiMem, a hierarchical long-term memory framework for long-horizon dialogues, designed to support memory construction, retrieval, and dynamic updating during sustained interactions. HiMem constructs cognitively consistent Episode Memory via a Topic-Aware Event--Surprise Dual-Channel Segmentation strategy, and builds Note Memory that captures stable knowledge through a multi-stage information extraction pipeline. These two memory types are semantically linked to form a hierarchical structure that bridges concrete interaction events and abstract knowledge, enabling efficient retrieval without sacrificing information fidelity. HiMem supports both hybrid and best-effort retrieval strategies to balance accuracy and efficiency, and incorporates conflict-aware Memory Reconsolidation to revise and supplement stored knowledge based on retrieval feedback. This design enables continual memory self-evolution over long-term use. Experimental results on long-horizon dialogue benchmarks demonstrate that HiMem consistently outperforms representative baselines in accuracy, consistency, and long-term reasoning, while maintaining favorable efficiency. Overall, HiMem provides a principled and scalable design paradigm for building adaptive and self-evolving LLM-based conversational agents. The code is available at https://github.com/jojopdq/HiMem.", "AI": {"tldr": "该论文提出了HiMem，一个层次化的长时记忆框架，用于长期对话中的记忆构建、检索和动态更新。", "motivation": "当前的长时记忆系统在适应性、可扩展性和自我进化方面存在局限性。因此，作者设计了HiMem以解决这些问题，并支持持续交互中高效准确的记忆管理。", "method": "HiMem通过主题感知事件-惊讶双重通道分割策略构建认知一致性的片段记忆，并利用多阶段信息提取流程建立笔记记忆，捕捉稳定知识。同时，它支持混合和尽力而为的检索策略并引入了冲突意识的记忆重构来根据检索反馈修订和补充存储的知识。", "result": "实验结果表明HiMem在长期对话基准上超过了代表性基线，在准确性、一致性以及长期推理方面表现出色，并且保持了良好的效率。", "conclusion": "总体而言，HiMem提供了一个原则性和可扩展的设计范式用于构建自适应和自我演化的基于LLM的会话代理。"}}
{"id": "2601.06368", "pdf": "https://arxiv.org/pdf/2601.06368", "abs": "https://arxiv.org/abs/2601.06368", "authors": ["Chen Gong", "Kecen Li", "Zinan Lin", "Tianhao Wang"], "title": "From Easy to Hard++: Promoting Differentially Private Image Synthesis Through Spatial-Frequency Curriculum", "categories": ["cs.CR", "cs.CV"], "comment": "Accepted at Usenix Security 2026; code available at https://github.com/2019ChenGong/Feta-Pro", "summary": "To improve the quality of Differentially private (DP) synthetic images, most studies have focused on improving the core optimization techniques (e.g., DP-SGD). Recently, we have witnessed a paradigm shift that takes these techniques off the shelf and studies how to use them together to achieve the best results. One notable work is DP-FETA, which proposes using `central images' for `warming up' the DP training and then using traditional DP-SGD. Inspired by DP-FETA, we are curious whether there are other such tools we can use together with DP-SGD. We first observe that using `central images' mainly works for datasets where there are many samples that look similar. To handle scenarios where images could vary significantly, we propose FETA-Pro, which introduces frequency features as `training shortcuts.' The complexity of frequency features lies between that of spatial features (captured by `central images') and full images, allowing for a finer-grained curriculum for DP training. To incorporate these two types of shortcuts together, one challenge is to handle the training discrepancy between spatial and frequency features. To address it, we leverage the pipeline generation property of generative models (instead of having one model trained with multiple features/objectives, we can have multiple models working on different features, then feed the generated results from one model into another) and use a more flexible design. Specifically, FETA-Pro introduces an auxiliary generator to produce images aligned with noisy frequency features. Then, another model is trained with these images, together with spatial features and DP-SGD. Evaluated across five sensitive image datasets, FETA-Pro shows an average of 25.7% higher fidelity and 4.1% greater utility than the best-performing baseline, under a privacy budget $ε= 1$.", "AI": {"tldr": "本文提出了一种新的方法FETA-Pro，用于改善差分隐私图像合成的质量。", "motivation": "为了处理在使用`中心图像'进行预训练时遇到的困难，特别是在图像差异较大的场景下，作者提出了引入频率特征作为训练捷径的方法来提高DP图像生成的质量和实用性。", "method": "FETA-Pro通过利用频域特性来克服空间特性的局限性，并设计了一个辅助生成器产生与噪声频率特征对齐的图像。然后使用另一个模型在这些图像上进行训练，同时结合空间特征和差分隐私优化（如DP-SGD）。", "result": "实验结果显示，在五种敏感图像数据集上的平均质量提高了25.7%，实用性提高了4.1%。", "conclusion": "FETA-Pro通过引入频率特征作为捷径改进了传统的差分隐私图像生成方法，从而在各种复杂场景下提供了更好的性能。"}}
{"id": "2601.06366", "pdf": "https://arxiv.org/pdf/2601.06366", "abs": "https://arxiv.org/abs/2601.06366", "authors": ["Pratyush Desai", "Luoxi Tang", "Yuqiao Meng", "Zhaohan Xi"], "title": "SafeGPT: Preventing Data Leakage and Unethical Outputs in Enterprise LLM Use", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are transforming enterprise workflows but introduce security and ethics challenges when employees inadvertently share confidential data or generate policy-violating content. This paper proposes SafeGPT, a two-sided guardrail system preventing sensitive data leakage and unethical outputs. SafeGPT integrates input-side detection/redaction, output-side moderation/reframing, and human-in-the-loop feedback. Experiments demonstrate SafeGPT effectively reduces data leakage risk and biased outputs while maintaining satisfaction.", "AI": {"tldr": "提出SafeGPT系统，防止大型语言模型在企业使用中泄露敏感数据和产生不道德内容。", "motivation": "解决企业在使用大型语言模型时遇到的安全性和伦理问题，包括员工无意间分享机密信息或生成违反政策的内容。", "method": "集成输入检测/删除、输出审查/重新表述以及人机交互反馈机制。", "result": "实验显示SafeGPT能够有效降低数据泄露风险和偏见产生，同时保持用户满意度。", "conclusion": "通过引入两方面的防护系统（SafeGPT），可以在不牺牲用户体验的情况下解决大型语言模型的安全性和伦理问题。"}}
{"id": "2601.06364", "pdf": "https://arxiv.org/pdf/2601.06364", "abs": "https://arxiv.org/abs/2601.06364", "authors": ["Xiaotian Zhang", "Jinhong Yu", "Pengwei Yan", "Le Jiang", "Xingyi Shen", "Mumo Cheng", "Xiaozhong Liu"], "title": "Human-in-the-Loop Interactive Report Generation for Chronic Disease Adherence", "categories": ["cs.HC", "cs.AI"], "comment": "5 pages, 3 figures. Accepted at the AAAI 2026 Workshop on AI for Healthy Aging and Longevity", "summary": "Chronic disease management requires regular adherence feedback to prevent avoidable hospitalizations, yet clinicians lack time to produce personalized patient communications. Manual authoring preserves clinical accuracy but does not scale; AI generation scales but can undermine trust in patient-facing contexts. We present a clinician-in-the-loop interface that constrains AI to data organization and preserves physician oversight through recognition-based review. A single-page editor pairs AI-generated section drafts with time-aligned visualizations, enabling inline editing with visual evidence for each claim. This division of labor (AI organizes, clinician decides) targets both efficiency and accountability. In a pilot with three physicians reviewing 24 cases, AI successfully generated clinically personalized drafts matching physicians' manual authoring practice (overall mean 4.86/10 vs. 5.0/10 baseline), requiring minimal physician editing (mean 8.3\\% content modification) with zero safety-critical issues, demonstrating effective automation of content generation. However, review time remained comparable to manual practice, revealing an accountability paradox: in high-stakes clinical contexts, professional responsibility requires complete verification regardless of AI accuracy. We contribute three interaction patterns for clinical AI collaboration: bounded generation with recognition-based review via chart-text pairing, automated urgency flagging that analyzes vital trends and adherence patterns with fail-safe escalation for missed critical monitoring tasks, and progressive disclosure controls that reduce cognitive load while maintaining oversight. These patterns indicate that clinical AI efficiency requires not only accurate models, but also mechanisms for selective verification that preserve accountability.", "AI": {"tldr": "该论文提出了一种医生参与的交互式报告生成系统，旨在提高慢性病管理中患者依从性的反馈效率。", "motivation": "慢性疾病需要定期提供个性化患者的沟通反馈以防止不必要的住院治疗。但手动创建这些通信会消耗大量时间，而AI生成则可能因准确性问题影响信任度。", "method": "提出了一种医生参与的界面系统，由AI负责数据组织和初步生成报告草案，同时通过可视化证据支持医生进行基于识别的审查。", "result": "在临床试点中，该系统能够自动生成符合医生手动撰写实践的个性化报告（平均分数为4.86/10对基线5.0/10），仅需少量修改（平均8.3%的内容变动）且无任何安全问题。尽管审查时间与传统方法相当，但显示出AI在临床环境中的应用潜力。", "conclusion": "论文指出，在高风险的临床环境中，通过结合准确的模型和选择性验证机制可以实现高效的人工智能辅助工作流程，同时保持责任归属。"}}
{"id": "2601.06362", "pdf": "https://arxiv.org/pdf/2601.06362", "abs": "https://arxiv.org/abs/2601.06362", "authors": ["Yutong Song", "Jiang Wu", "Shaofan Yuan", "Chengze Shen", "Jian Wang", "Amir Rahmani", "Nikil Dutt", "Yu Wang"], "title": "Styles + Persona-plug = Customized LLMs", "categories": ["cs.AI"], "comment": null, "summary": "We discover a previously overlooked challenge in personalized text generation: personalization methods are increasingly applied under explicit style instructions, yet their behavior under such constraints remains poorly understood. To balance implicit personalization and explicit style, we formulate personalization as a distributional residual and propose PsPLUG, a lightweight soft-prompt plug-in trained with style-conditioned preference contrasts. Across LaMP benchmark, our framework improves persona alignment, maintains stylistic fidelity, and outperforms retrieval-based and soft-prompt baselines with minimal computation. These results show that residual modeling provides a simple and principled foundation for controllable, style-aware LLM personalization.", "AI": {"tldr": "提出PsPLUG框架，用于在生成个性化文本时同时保持风格一致性和个人特征。", "motivation": "现有的个性化方法在显式风格指令下表现不佳，需要一种能够平衡隐性个性化和显式风格的方法。", "method": "将个性化视为分布残差，并通过带有风格条件的偏好对比训练轻量级软提示插件PsPLUG。", "result": "该框架提高了人物一致性，保持了风格忠实度，在LaMP基准测试中优于检索基线和软提示基线。", "conclusion": "残留建模为可控、风格感知的LLM个性化提供了一个简单而原则的基础。"}}
{"id": "2601.06357", "pdf": "https://arxiv.org/pdf/2601.06357", "abs": "https://arxiv.org/abs/2601.06357", "authors": ["Sriharshini Kalvakuntla", "Luoxi Tang", "Yuqiao Meng", "Zhaohan Xi"], "title": "Smart Privacy Policy Assistant: An LLM-Powered System for Transparent and Actionable Privacy Notices", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Most users agree to online privacy policies without reading or understanding them, even though these documents govern how personal data is collected, shared, and monetized. Privacy policies are typically long, legally complex, and difficult for non-experts to interpret. This paper presents the Smart Privacy Policy Assistant, an LLM-powered system that automatically ingests privacy policies, extracts and categorizes key clauses, assigns human-interpretable risk levels, and generates clear, concise explanations. The system is designed for real-time use through browser extensions or mobile interfaces, surfacing contextual warnings before users disclose sensitive information or grant risky permissions. We describe the end-to-end pipeline, including policy ingestion, clause categorization, risk scoring, and explanation generation, and propose an evaluation framework based on clause-level accuracy, policy-level risk agreement, and user comprehension.", "AI": {"tldr": "开发了一种基于LLM的智能隐私政策助手，用于解析和简化复杂的隐私条款", "motivation": "大多数用户在不了解或不阅读的情况下同意在线隐私政策，这些文档管理着个人数据的收集、共享和货币化。因此需要一种工具帮助普通用户理解并做出明智决定", "method": "通过浏览器扩展程序或移动界面实时摄入隐私政策，分类关键条款，评估风险等级，并生成清晰简洁的解释", "result": "提出了一个端到端的管道框架，包括政策摄入，条款分类，风险评分和解释生成。提出了一种基于子句准确性、政策风险一致性以及用户理解度的评估方法", "conclusion": "智能隐私政策助手为用户提供了一个实用工具来理解和应对复杂的在线隐私政策"}}
{"id": "2601.06356", "pdf": "https://arxiv.org/pdf/2601.06356", "abs": "https://arxiv.org/abs/2601.06356", "authors": ["Nusrat Jahan Prottasha", "Md Kowsher", "Chun-Nam Yu", "Chen Chen", "Ozlem Garibay"], "title": "Monkey Jump : MoE-Style PEFT for Efficient Multi-Task Learning", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": null, "summary": "Mixture-of-experts variants of parameter-efficient fine-tuning enable per-token specialization, but they introduce additional trainable routers and expert parameters, increasing memory usage and training cost. This undermines the core goal of parameter-efficient fine-tuning. We propose Monkey Jump, a method that brings mixture-of-experts-style specialization to parameter-efficient fine-tuning without introducing extra trainable parameters for experts or routers. Instead of adding new adapters as experts, Monkey Jump treats the adapters already present in each Transformer block (such as query, key, value, up, and down projections) as implicit experts and routes tokens among them. Routing is performed using k-means clustering with exponentially moving averaged cluster centers, requiring no gradients and no learned parameters. We theoretically show that token-wise routing increases expressivity and can outperform shared adapters by avoiding cancellation effects. Across multi-task experiments covering 14 text, 14 image, and 19 video benchmarks, Monkey Jump achieves competitive performance with mixture-of-experts-based parameter-efficient fine-tuning methods while using 7 to 29 times fewer trainable parameters, up to 48 percent lower memory consumption, and 1.5 to 2 times faster training. Monkey Jump is architecture-agnostic and can be applied to any adapter-based parameter-efficient fine-tuning method.", "AI": {"tldr": "提出了一种名为Monkey Jump的方法，实现了混合专家风格的专业化参数高效微调，而不引入额外的可训练参数。", "motivation": "现有的混合专家变体在实现逐令牌专业化的同时，增加了额外的可训练路由器和专家参数，这违背了参数高效微调的核心目标。因此，论文旨在通过不增加额外参数来解决此问题。", "method": "Monkey Jump方法利用已经存在于每个Transformer块中的适配器（例如查询、键值、上投影和下投影）作为隐式专家，并使用k-means聚类结合指数移动平均的集群中心进行令牌路由，无需梯度或学习参数。", "result": "在多任务实验中，Monkey Jump实现了与混合专家方法相当甚至更好的性能，同时减少了7到29倍的可训练参数数量，内存消耗降低了高达48%，并且训练速度提高了1.5到2倍。", "conclusion": "Monkey Jump是一种架构不可知的方法，适用于任何基于适配器的参数高效微调方法，为多任务学习提供了高效的解决方案。"}}
{"id": "2601.06352", "pdf": "https://arxiv.org/pdf/2601.06352", "abs": "https://arxiv.org/abs/2601.06352", "authors": ["Yutong Song", "Jiang Wu", "Weijia Zhang", "Chengze Shen", "Shaofan Yuan", "Weitao Lu", "Jian Wang", "Amir Rahmani", "Nikil Dutt", "Yu Wang"], "title": "CARD: Cluster-level Adaptation with Reward-guided Decoding for Personalized Text Generation", "categories": ["cs.AI"], "comment": null, "summary": "Adapting large language models to individual users remains challenging due to the tension between fine-grained personalization and scalable deployment. We present CARD, a hierarchical framework that achieves effective personalization through progressive refinement. CARD first clusters users according to shared stylistic patterns and learns cluster-specific LoRA adapters, enabling robust generalization and strong low-resource performance. To capture individual differences within each cluster, we propose an implicit preference learning mechanism that contrasts user-authored text with cluster-level generations, allowing the model to infer user-specific style preferences without manual annotation. At inference time, CARD injects personalization exclusively at decoding via lightweight user preference vectors and low-rank logit corrections, while keeping the base model frozen. Experiments on the LaMP and LongLaMP benchmarks show that CARD achieves competitive or superior generation quality compared to state-of-the-art baselines, while significantly improving efficiency and scalability for practical personalized text generation.", "AI": {"tldr": "该论文提出了一种名为CARD的层次框架，用于大规模语言模型的有效个性化生成。", "motivation": "适应大型语言模型以满足个人用户的需求具有挑战性，因为这需要在精细调整和个人化之间找到平衡。", "method": "该方法首先将用户按共享风格模式聚类，并为每个群集学习特定的LoRA适配器。然后通过对比用户的原作者文本和群集级别的生成结果来捕捉群体内的个体差异。最后，在解码时注入个性化，以提高模型效率和扩展性。", "result": "实验表明，CARD在LaMP和LongLaMP基准测试中达到了与最新技术相当或更好的生成质量，并提高了实际个性化文本生成的效率和可扩展性。", "conclusion": "该论文提出的CARD框架通过层次结构方法有效解决了大规模语言模型个性化的问题。"}}
{"id": "2601.06344", "pdf": "https://arxiv.org/pdf/2601.06344", "abs": "https://arxiv.org/abs/2601.06344", "authors": ["Cedric Melancon", "Julien Gascon-Samson", "Maarouf Saad", "Kuljeet Kaur", "Simon Savard"], "title": "BlazeAIoT: A Modular Multi-Layer Platform for Real-Time Distributed Robotics Across Edge, Fog, and Cloud Infrastructures", "categories": ["cs.RO", "cs.DC"], "comment": "17 pages, 9 figures", "summary": "The increasing complexity of distributed robotics has driven the need for platforms that seamlessly integrate edge, fog, and cloud computing layers while meeting strict real-time constraints. This paper introduces BlazeAIoT, a modular multi-layer platform designed to unify distributed robotics across heterogeneous infrastructures. BlazeAIoT provides dynamic data transfer, configurable services, and integrated monitoring, while ensuring resilience, security, and programming language flexibility. The architecture leverages Kubernetes-based clusters, broker interoperability (DDS, Kafka, Redis, and ROS2), and adaptive data distribution mechanisms to optimize communication and computation across diverse environments. The proposed solution includes a multi-layer configuration service, dynamic and adaptive data bridging, and hierarchical rate limiting to handle large messages. The platform is validated through robotics scenarios involving navigation and artificial intelligence-driven large-scale message processing, demonstrating robust performance under real-time constraints. Results highlight BlazeAIoT's ability to dynamically allocate services across incomplete topologies, maintain system health, and minimize latency, making it a cost-aware, scalable solution for robotics and broader IoT applications, such as smart cities and smart factories.", "AI": {"tldr": "BlazeAIoT平台旨在解决分布式机器人技术中的实时约束问题，通过集成边缘、雾和云计算层来统一异构基础设施。", "motivation": "随着分布式机器人系统的复杂性增加，需要一个能无缝整合各种计算层级并满足严格实时要求的平台。", "method": "BlazeAIoT是一个基于Kubernetes集群且具有DDS、Kafka、Redis和ROS2等中间件兼容性的多层模块化平台。该平台具备动态数据传输、可配置服务以及集成监控功能，确保系统的弹性、安全性及编程语言灵活性。此外还包括了多层次的配置服务、自适应的数据桥接技术以及层级化的速率限制来处理大规模的消息。", "result": "通过导航和人工智能驱动的大规模消息处理等机器人场景测试表明，BlazeAIoT平台能够动态分配服务到不完整的拓扑中，保持系统的健康状况并减少延迟。实验结果显示了该平台在实时约束下的强大性能，证明其是一个成本效益高且可扩展的解决方案。", "conclusion": "BlazeAIoT为分布式机器人以及更广泛的IoT应用（如智慧城市和智能工厂）提供了一个强大、灵活且高效的计算平台。"}}
{"id": "2601.06341", "pdf": "https://arxiv.org/pdf/2601.06341", "abs": "https://arxiv.org/abs/2601.06341", "authors": ["Tara Bogavelli", "Oluwanifemi Bamgbose", "Gabrielle Gauthier Melançon", "Fanny Riols", "Roshnee Sharma"], "title": "Evaluating Robustness of Large Language Models in Enterprise Applications: Benchmarks for Perturbation Consistency Across Formats and Languages", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": null, "summary": "Enterprise LLM applications require consistently high quality and reliable performance across diverse scenarios, demanding robustness to minor variations. Existing research shows that even small prompt changes can lead to substantial differences in output, but has mainly focused on a narrow set of perturbations with small academic datasets, limiting their relevance to real-world applications. To address this, we present a comprehensive benchmark suite that evaluates robustness across multiple perturbation types, including general text edits (e.g., punctuation, whitespace), formatting changes (e.g., JSON, YAML), multilingual and cross-lingual inputs, and positional variations in instructions. Evaluating 11 models ranging from 4B to 120B+ parameters, we find that minor perturbations reduce performance by up to 40 percentage points on key enterprise metrics. Critically, we demonstrate that the relationship between model size and robustness is more nuanced than conventional assumptions suggest: an 8B parameter model (Ministral 3 8B) outperforms most larger models, while another 8B model (Llama 3.1 8B) performs worst overall.", "AI": {"tldr": "评估大型语言模型在企业应用中的鲁棒性，通过多种扰动类型进行基准测试。", "motivation": "现有研究主要集中在学术数据集上的小范围扰动变化对输出的影响，未能充分反映现实世界应用场景的需求。需要一个全面的基准套件来评估模型在不同场景下的鲁棒性。", "method": "提出了一套包括一般文本编辑、格式转换和跨语言输入在内的多类型扰动测试，并评测了11种不同参数规模的语言模型。", "result": "发现即使是最轻微的扰动也会导致性能下降，降幅可达40个百分点。同时证明大型模型并不一定比小型模型鲁棒性更强。", "conclusion": "展示了评估企业级应用语言模型鲁棒性的新方法，突显了模型大小与鲁棒性之间关系的复杂性，并强调了基准测试的重要性。"}}
{"id": "2601.06338", "pdf": "https://arxiv.org/pdf/2601.06338", "abs": "https://arxiv.org/abs/2601.06338", "authors": ["Binxu Wang", "Jingxuan Fan", "Xu Pan"], "title": "Circuit Mechanisms for Spatial Relation Generation in Diffusion Transformers", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": "31 pages, 23 figures", "summary": "Diffusion Transformers (DiTs) have greatly advanced text-to-image generation, but models still struggle to generate the correct spatial relations between objects as specified in the text prompt. In this study, we adopt a mechanistic interpretability approach to investigate how a DiT can generate correct spatial relations between objects. We train, from scratch, DiTs of different sizes with different text encoders to learn to generate images containing two objects whose attributes and spatial relations are specified in the text prompt. We find that, although all the models can learn this task to near-perfect accuracy, the underlying mechanisms differ drastically depending on the choice of text encoder. When using random text embeddings, we find that the spatial-relation information is passed to image tokens through a two-stage circuit, involving two cross-attention heads that separately read the spatial relation and single-object attributes in the text prompt. When using a pretrained text encoder (T5), we find that the DiT uses a different circuit that leverages information fusion in the text tokens, reading spatial-relation and single-object information together from a single text token. We further show that, although the in-domain performance is similar for the two settings, their robustness to out-of-domain perturbations differs, potentially suggesting the difficulty of generating correct relations in real-world scenarios.", "AI": {"tldr": "研究探索了DiT生成正确物体间空间关系的电路机制。", "motivation": "尽管Diffusion Transformers在文本到图像生成中取得了很大进步，但模型仍难以根据文本提示准确生成物体间的空间关系。因此，本文通过机理解释的方法来探究其原因。", "method": "使用不同大小和文本编码器训练DiT模型，并采用随机文本嵌入和预训练的T5进行对比研究，分析如何将文本中的空间信息传递到图像中。", "result": "发现两种情况下DiT生成图像的准确性相似，但对域外扰动的鲁棒性差异较大。揭示了使用不同电路机制来处理空间关系的不同方式：两阶段电路和融合单一物体及空间信息的一次读取电路。", "conclusion": "通过对比实验明确了DiT如何利用不同的电路机制来生成正确空间关系，这可能对改进模型在真实场景中的表现具有重要意义。"}}
{"id": "2601.06336", "pdf": "https://arxiv.org/pdf/2601.06336", "abs": "https://arxiv.org/abs/2601.06336", "authors": ["Benjamin Turtel", "Paul Wilczewski", "Danny Franklin", "Kris Skothiem"], "title": "Future-as-Label: Scalable Supervision from Real-World Outcomes", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Many real-world prediction problems lack labels observable at prediction time, creating a temporal gap between prediction and outcome that yields supervision only after events resolve. To address this setting, we extend reinforcement learning with verifiable rewards to temporally resolved real-world prediction, and use it to train language models to make probabilistic forecasts under causally masked information with retrospective evaluation using proper scoring rules. Supervision is derived solely from post-resolution outcomes, preserving delayed-reward semantics. On real-world forecasting benchmarks, Qwen3-32B trained using Foresight Learning improves Brier score by 27% and halves calibration error relative to its pretrained baseline, and outperforms Qwen3-235B on both constructed future-event prediction tasks and the Metaculus benchmark despite a 7x parameter disadvantage.", "AI": {"tldr": "本文提出了一种利用未来结果作为标签的预测方法，解决了实际问题中的时间延迟和监督缺失的问题。", "motivation": "许多现实世界的预测任务缺乏在预测时刻可观察到的标签，导致预测与事件的实际结果之间存在时间差。这种情况下很难及时得到反馈，从而影响模型的学习效率。", "method": "本文将强化学习扩展到使用验证奖励进行时间上解决的真实世界预测，并利用它来训练语言模型以根据因果屏蔽信息做出概率预报，在事后评估时采用合适的评分规则。", "result": "在真实世界的预测基准测试中，Qwen3-32B 使用前瞻学习提高了布莱尔得分的27%，并将校准误差减半。同时，尽管参数量仅为Qwen3-235B的1/7,仍在这两类构造的任务和Metaculus基准上表现更好。", "conclusion": "本文的方法克服了预测时间与事件实际发生之间的时间延迟问题，并在实际预测任务中取得了显著的效果提升。"}}
{"id": "2601.06335", "pdf": "https://arxiv.org/pdf/2601.06335", "abs": "https://arxiv.org/abs/2601.06335", "authors": ["Noga Chemo", "Yaniv Mordecai", "Yoram Reich"], "title": "Foundational Analysis of Safety Engineering Requirements (SAFER)", "categories": ["cs.SE", "cs.AI"], "comment": "ef:IEEE Aerospace Conference 2026", "summary": "We introduce a framework for Foundational Analysis of Safety Engineering Requirements (SAFER), a model-driven methodology supported by Generative AI to improve the generation and analysis of safety requirements for complex safety-critical systems. Safety requirements are often specified by multiple stakeholders with uncoordinated objectives, leading to gaps, duplications, and contradictions that jeopardize system safety and compliance. Existing approaches are largely informal and insufficient for addressing these challenges. SAFER enhances Model-Based Systems Engineering (MBSE) by consuming requirement specification models and generating the following results: (1) mapping requirements to system functions, (2) identifying functions with insufficient requirement specifications, (3) detecting duplicate requirements, and (4) identifying contradictions within requirement sets. SAFER provides structured analysis, reporting, and decision support for safety engineers. We demonstrate SAFER on an autonomous drone system, significantly improving the detection of requirement inconsistencies, enhancing both efficiency and reliability of the safety engineering process. We show that Generative AI must be augmented by formal models and queried systematically, to provide meaningful early-stage safety requirement specifications and robust safety architectures.", "AI": {"tldr": "介绍了一种利用生成式AI增强模型驱动的安全工程要求分析框架（SAFER），用于改善复杂安全关键系统的安全需求的产生和分析。", "motivation": "旨在解决当前安全需求规格说明存在的不一致、遗漏及重复等问题，提高系统安全性与合规性。现有方法多为非正式且不足以应对这些挑战。", "method": "基于模型驱动系统工程（MBSE），SAFER通过解析要求规范模型来生成映射结果：将需求映射至系统功能；识别缺少足够规格说明的功能；检测重复的需求；发现冲突的要求集。", "result": "在自主无人机系统的应用中，显著提升了安全需求不一致性的检测能力，提高了安全性工程过程的效率和可靠性。", "conclusion": "证明了需要通过形式化模型并有系统地查询生成式AI，以提供有意义的安全需求早期规格说明及稳健的安全架构。"}}
{"id": "2601.06334", "pdf": "https://arxiv.org/pdf/2601.06334", "abs": "https://arxiv.org/abs/2601.06334", "authors": ["Masoud Deylami", "Negar Izadipour", "Adel Alaeddini"], "title": "Kolmogorov-Arnold Networks-Based Tolerance-Aware Manufacturability Assessment Integrating Design-for-Manufacturing Principles", "categories": ["cs.AI"], "comment": "25 pages, 12 figures. Under review for journal publication", "summary": "Manufacturability assessment is a critical step in bridging the persistent gap between design and production. While artificial intelligence (AI) has been widely applied to this task, most existing frameworks rely on geometry-driven methods that require extensive preprocessing, suffer from information loss, and offer limited interpretability. This study proposes a methodology that evaluates manufacturability directly from parametric design features, enabling explicit incorporation of dimensional tolerances without requiring computer-aided design (CAD) processing. The approach employs Kolmogorov-Arnold Networks (KANs) to learn functional relationships between design parameters, tolerances, and manufacturability outcomes. A synthetic dataset of 300,000 labeled designs is generated to evaluate performance across three representative scenarios: hole drilling, pocket milling, and combined drilling-milling, while accounting for machining constraints and design-for-manufacturing (DFM) rules. Benchmarking against fourteen machine learning (ML) and deep learning (DL) models shows that KAN achieves the highest performance in all scenarios, with AUC values of 0.9919 for drilling, 0.9841 for milling, and 0.9406 for the combined case. The proposed framework provides high interpretability through spline-based functional visualizations and latent-space projections, enabling identification of the design and tolerance parameters that most strongly influence manufacturability. An industrial case study further demonstrates how the framework enables iterative, parameter-level design modifications that transform a non-manufacturable component into a manufacturable one.", "AI": {"tldr": "提出了一种基于Kolmogorov-Arnold网络的容忍度感知制造性评估方法，直接从参数化设计特征中进行评估。", "motivation": "现有的制造性评估框架大多依赖于几何驱动的方法，需要大量的预处理、信息丢失并且解释性有限。本文旨在提供一种无需CAD处理即可将尺寸公差显式纳入评估的设计方法。", "method": "使用Kolmogorov-Arnold网络学习设计参数、公差与制造结果之间的函数关系，并生成30万个带有标签的设计样本进行性能测试，包括钻孔、铣削和综合钻铣场景。通过机器学习模型进行基准比较，以验证其效果。", "result": "Kolmogorov-Arnold网络在所有场景中都表现出最高的性能，AUC值分别为钻孔0.9919、铣削0.9841和综合案例0.9406。该框架通过样条函数可视化提供了高度的解释性。", "conclusion": "提出的框架能够在工业案例研究中将不可制造的设计逐步修改为可制造的设计，展示了其在参数级设计改进方面的优势。"}}
{"id": "2601.06329", "pdf": "https://arxiv.org/pdf/2601.06329", "abs": "https://arxiv.org/abs/2601.06329", "authors": ["Jeff Chan-Jan Sju", "Liang-Hsuan Tseng", "Yi-Cheng Lin", "Yen-Chun Kuo", "Ju-Chieh Chou", "Kai-Wei Chang", "Hung-yi Lee", "Carlos Busso"], "title": "On the Fallacy of Global Token Perplexity in Spoken Language Model Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Generative spoken language models pretrained on large-scale raw audio can continue a speech prompt with appropriate content while preserving attributes like speaker and emotion, serving as foundation models for spoken dialogue. In prior literature, these models are often evaluated using ``global token perplexity'', which directly applies the text perplexity formulation to speech tokens. However, this practice overlooks fundamental differences between speech and text modalities, possibly leading to an underestimation of the speech characteristics. In this work, we propose a variety of likelihood- and generative-based evaluation methods that serve in place of naive global token perplexity. We demonstrate that the proposed evaluations more faithfully reflect perceived generation quality, as evidenced by stronger correlations with human-rated mean opinion scores (MOS). When assessed under the new metrics, the relative performance landscape of spoken language models is reshaped, revealing a significantly reduced gap between the best-performing model and the human topline. Together, these results suggest that appropriate evaluation is critical for accurately assessing progress in spoken language modeling.", "AI": {"tldr": "本文提出了用于评估语音生成模型的替代方法，以解决传统全局令牌困惑度在衡量语音生成质量时存在的不足。", "motivation": "传统的全球令牌困惑度在衡量语音生成模型的质量时忽略了文本和语音之间的根本差异，可能导致对语音特征的低估。因此需要一种更合适的评价方式。", "method": "提出了一系列基于似然性和生成性的评估方法来取代传统的方法，并通过与人类评分标准进行对比验证这些新方法的有效性。", "result": "新的评估指标能够更好地反映生成的质量，表现出比传统困惑度更强的人类主观意见得分（MOS）相关性。根据这种新方法的评价结果，语音模型间的性能差异有所变化，顶级模型和人工表现之间的差距显著减小。", "conclusion": "适当的评估对于准确衡量语音语言模型的进步至关重要"}}
{"id": "2601.06328", "pdf": "https://arxiv.org/pdf/2601.06328", "abs": "https://arxiv.org/abs/2601.06328", "authors": ["Ziqiao Xi", "Shuang Liang", "Qi Liu", "Jiaqing Zhang", "Letian Peng", "Fang Nan", "Meshal Nayim", "Tianhui Zhang", "Rishika Mundada", "Lianhui Qin", "Biwei Huang", "Kun Zhou"], "title": "ToolGym: an Open-world Tool-using Environment for Scalable Agent Testing and Data Curation", "categories": ["cs.AI"], "comment": "Submitted to ACL 2026 12 pages, 4 figures Ziqiao Xi and Shuang Liang contributed equally to this work", "summary": "Tool-using LLM agents still struggle in open-world settings with large tool pools, long-horizon objectives, wild constraints, and unreliable tool states. For scalable and realistic training and testing, we introduce an open-world tool-using environment, built on 5,571 format unified tools across 204 commonly used apps. It includes a task creation engine that synthesizes long-horizon, multi-tool workflows with wild constraints, and a state controller that injects interruptions and failures to stress-test robustness. On top of this environment, we develop a tool select-then-execute agent framework with a planner-actor decomposition to separate deliberate reasoning and self-correction from step-wise execution. Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness. Finally, we collect 1,170 trajectories from our environment to fine-tune LLMs, achieving superior performance to baselines using 119k samples, indicating the environment's value as both a realistic benchmark and a data engine for tool-using agents. Our code and data will be publicly released.", "AI": {"tldr": "论文提出了一种名为ToolGym的开放世界工具使用环境，用于大规模智能代理测试和数据收集。", "motivation": "在具有大量工具、长期目标以及不可靠工具状态的开放式环境中，LLM代理的表现仍然不尽如人意。需要一种可扩展且真实的训练和测试方法来解决这些问题。", "method": "开发了一个基于5,571个格式统一工具的开放世界环境，并引入了任务生成引擎和状态控制器以模拟复杂场景。通过一个选择执行框架，将计划与执行分离。", "result": "实验评估显示现有LLM在规划和约束遵守方面存在弱点，而DeepSeek-v3.2表现出最强的鲁棒性。使用收集的数据进行微调可以显著提升性能。", "conclusion": "ToolGym环境不仅是一个现实基准测试工具，也是一个为工具使用代理提供数据的重要来源"}}
{"id": "2601.06318", "pdf": "https://arxiv.org/pdf/2601.06318", "abs": "https://arxiv.org/abs/2601.06318", "authors": ["Zimin Liang", "Miqing Li"], "title": "Random is Faster than Systematic in Multi-Objective Local Search", "categories": ["cs.NE"], "comment": null, "summary": "Local search is a fundamental method in operations research and combinatorial optimisation. It has been widely applied to a variety of challenging problems, including multi-objective optimisation where multiple, often conflicting, objectives need to be simultaneously considered. In multi-objective local search algorithms, a common practice is to maintain an archive of all non-dominated solutions found so far, from which the algorithm iteratively samples a solution to explore its neighbourhood. A central issue in this process is how to explore the neighbourhood of a selected solution. In general, there are two main approaches: 1) systematic exploration and 2) random sampling. The former systematically explores the solution's neighbours until a stopping condition is met -- for example, when the neighbourhood is exhausted (i.e., the best improvement strategy) or once a better solution is found (i.e., first improvement). In contrast, the latter randomly selects and evaluates only one neighbour of the solution. One may think systematic exploration may be more efficient, as it prevents from revisiting the same neighbours multiple times. In this paper, however, we show that this may not be the case. We first empirically demonstrate that the random sampling method is consistently faster than the systematic exploration method across a range of multi-objective problems. We then give an intuitive explanation for this phenomenon using toy examples, showing that the superior performance of the random sampling method relies on the distribution of ``good neighbours''. Next, we show that the number of such neighbours follows a certain probability distribution during the search. Lastly, building on this distribution, we provide a theoretical insight for why random sampling is more efficient than systematic exploration, regardless of whether the best improvement or first improvement strategy is used.", "AI": {"tldr": "探讨了在多目标优化中，随机采样方法比系统探索更快的原因。", "motivation": "展示为什么在多目标本地搜索算法中，使用随机邻居选择通常会比系统的邻居探索更高效。", "method": "通过实验比较和理论分析两种不同邻域探索策略的表现，并给出直观解释和概率分布模型。", "result": "实验证明，在多种多目标问题上，随机采样方法均快于系统探索。理论模型表明随机性依赖于‘好邻居’的分布情况。", "conclusion": "证明了在多目标本地搜索中，即使使用最佳改进或首次改进策略，随机采样的效率也高于系统的邻域探索方式。"}}
{"id": "2601.06309", "pdf": "https://arxiv.org/pdf/2601.06309", "abs": "https://arxiv.org/abs/2601.06309", "authors": ["Zane Durante", "Silky Singh", "Arpandeep Khatua", "Shobhit Agarwal", "Reuben Tan", "Yong Jae Lee", "Jianfeng Gao", "Ehsan Adeli", "Li Fei-Fei"], "title": "VideoWeave: A Data-Centric Approach for Efficient Video Understanding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Training video-language models is often prohibitively expensive due to the high cost of processing long frame sequences and the limited availability of annotated long videos. We present VideoWeave, a simple yet effective approach to improve data efficiency by constructing synthetic long-context training samples that splice together short, captioned videos from existing datasets. Rather than modifying model architectures or optimization objectives, VideoWeave reorganizes available video-text pairs to expand temporal diversity within fixed compute. We systematically study how different data composition strategies like random versus visually clustered splicing and caption enrichment affect downstream performance on downstream video question answering. Under identical compute constraints, models trained with VideoWeave achieve higher accuracy than conventional video finetuning. Our results highlight that reorganizing training data, rather than altering architectures, may offer a simple and scalable path for training video-language models. We link our code for all experiments here.", "AI": {"tldr": "视频理解模型的训练由于处理长帧序列的成本高昂和标注长视频的稀缺而变得成本过高。VideoWeave通过合成长上下文训练样本来提高数据效率。", "motivation": "降低视频语言模型训练的成本，特别是在计算资源有限的情况下。", "method": "重新组织现有的视频文本对以构建具有更大时间多样性的合成样本。研究不同的数据组合策略如随机拼接和视觉聚类拼接以及描述性增强的影响。", "result": "与传统微调相比，在相同计算限制下使用VideoWeave训练的模型实现了更高的准确性。", "conclusion": "通过重新组织而不是改变架构来改进视频语言模型的训练是一个简单且可扩展的方法。"}}
{"id": "2601.06301", "pdf": "https://arxiv.org/pdf/2601.06301", "abs": "https://arxiv.org/abs/2601.06301", "authors": ["Arth Bhardwaj", "Nirav Diwan", "Gang Wang"], "title": "Beyond BeautifulSoup: Benchmarking LLM-Powered Web Scraping for Everyday Users", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": null, "summary": "Web scraping has historically required technical expertise in HTML parsing, session management, and authentication circumvention, which limited large-scale data extraction to skilled developers. We argue that large language models (LLMs) have democratized web scraping, enabling low-skill users to execute sophisticated operations through simple natural language prompts. While extensive benchmarks evaluate these tools under optimal expert conditions, we show that without extensive manual effort, current LLM-based workflows allow novice users to scrape complex websites that would otherwise be inaccessible. We systematically benchmark what everyday users can do with off-the-shelf LLM tools across 35 sites spanning five security tiers, including authentication, anti-bot, and CAPTCHA controls. We devise and evaluate two distinct workflows: (a) LLM-assisted scripting, where users prompt LLMs to generate traditional scraping code but maintain manual execution control, and (b) end-to-end LLM agents, which autonomously navigate and extract data through integrated tool use. Our results demonstrate that end-to-end agents have made complex scraping accessible - requiring as little as a single prompt with minimal refinement (less than 5 changes) to complete workflows. We also highlight scenarios where LLM-assisted scripting may be simpler and faster for static sites. In light of these findings, we provide simple procedures for novices to use these workflows and gauge what adversaries could achieve using these.", "AI": {"tldr": "研究评估了大语言模型（LLM）在普通用户进行网页抓取时的有效性，测试了两种不同的工作流程：辅助脚本编写和端到端代理。", "motivation": "旨在探索大型语言模型如何使没有技术背景的普通人也能执行复杂的网络抓取任务。同时研究了这些工具在处理复杂网站（包括认证、反爬虫和验证码）时的效果。", "method": "系统地评估了35个不同安全级别的网站，通过两种不同的工作流程：辅助脚本编写和端到端代理来测试LLM的性能。", "result": "结果显示，使用大语言模型实现复杂的网络抓取变得更容易，用户可以通过简单的自然语言提示完成任务。在某些情况下，辅助脚本方式对于静态站点更加简单快捷。", "conclusion": "研究发现证明了大型语言模型在普通用户执行复杂网站数据提取中的巨大潜力，为没有技术背景的用户提供了一种新的工具来获取所需信息的方法。"}}
{"id": "2601.06300", "pdf": "https://arxiv.org/pdf/2601.06300", "abs": "https://arxiv.org/abs/2601.06300", "authors": ["Trisha Das", "Mandis Beigi", "Jacob Aptekar", "Jimeng Sun"], "title": "$\\texttt{AMEND++}$: Benchmarking Eligibility Criteria Amendments in Clinical Trials", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Clinical trial amendments frequently introduce delays, increased costs, and administrative burden, with eligibility criteria being the most commonly amended component. We introduce \\textit{eligibility criteria amendment prediction}, a novel NLP task that aims to forecast whether the eligibility criteria of an initial trial protocol will undergo future amendments. To support this task, we release $\\texttt{AMEND++}$, a benchmark suite comprising two datasets: $\\texttt{AMEND}$, which captures eligibility-criteria version histories and amendment labels from public clinical trials, and $\\verb|AMEND_LLM|$, a refined subset curated using an LLM-based denoising pipeline to isolate substantive changes. We further propose $\\textit{Change-Aware Masked Language Modeling}$ (CAMLM), a revision-aware pretraining strategy that leverages historical edits to learn amendment-sensitive representations. Experiments across diverse baselines show that CAMLM consistently improves amendment prediction, enabling more robust and cost-effective clinical trial design.", "AI": {"tldr": "提出了一种新的自然语言处理任务，用于预测临床试验的资格标准是否会进行修改，并发布了相应的基准数据集和一种改进的预训练策略。", "motivation": "为了减少由于资格标准修改导致的成本增加和行政负担，通过引入资格标准修改预测这一新任务来支持更高效、更低成本的临床试验设计。", "method": "构建了包含历史版本与修改标签的数据集，并提出了一种利用历史编辑信息改进预训练策略的方法CAMLM。", "result": "实验表明，所提出的CAMLM方法能显著提高资格标准修改预测的准确性。", "conclusion": "该研究展示了通过预测临床试验资格标准是否会被修改来减少成本和延迟的有效性。"}}
{"id": "2601.06288", "pdf": "https://arxiv.org/pdf/2601.06288", "abs": "https://arxiv.org/abs/2601.06288", "authors": ["Tianhao Xu", "Yiming Liu", "Xianglong Lu", "Yijia Zhao", "Xuting Zhou", "Aichen Feng", "Yiyi Chen", "Yi Shen", "Qin Zhou", "Xumeng Chen", "Ilya Sherstyuk", "Haorui Li", "Rishi Thakkar", "Ben Hamm", "Yuanzhe Li", "Xue Huang", "Wenpeng Wu", "Anish Shanbhag", "Harry Kim", "Chuan Chen", "Junjie Lai"], "title": "AIConfigurator: Lightning-Fast Configuration Optimization for Multi-Framework LLM Serving", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Optimizing Large Language Model (LLM) inference in production systems is increasingly difficult due to dynamic workloads, stringent latency/throughput targets, and a rapidly expanding configuration space. This complexity spans not only distributed parallelism strategies (tensor/pipeline/expert) but also intricate framework-specific runtime parameters such as those concerning the enablement of CUDA graphs, available KV-cache memory fractions, and maximum token capacity, which drastically impact performance. The diversity of modern inference frameworks (e.g., TRT-LLM, vLLM, SGLang), each employing distinct kernels and execution policies, makes manual tuning both framework-specific and computationally prohibitive. We present AIConfigurator, a unified performance-modeling system that enables rapid, framework-agnostic inference configuration search without requiring GPU-based profiling. AIConfigurator combines (1) a methodology that decomposes inference into analytically modelable primitives - GEMM, attention, communication, and memory operations while capturing framework-specific scheduling dynamics; (2) a calibrated kernel-level performance database for these primitives across a wide range of hardware platforms and popular open-weights models (GPT-OSS, Qwen, DeepSeek, LLama, Mistral); and (3) an abstraction layer that automatically resolves optimal launch parameters for the target backend, seamlessly integrating into production-grade orchestration systems. Evaluation on production LLM serving workloads demonstrates that AIConfigurator identifies superior serving configurations that improve performance by up to 40% for dense models (e.g., Qwen3-32B) and 50% for MoE architectures (e.g., DeepSeek-V3), while completing searches within 30 seconds on average. Enabling the rapid exploration of vast design spaces - from cluster topology down to engine specific flags.", "AI": {"tldr": "AIConfigurator是一个统一的性能建模系统，用于多框架大型语言模型（LLM）推理配置优化。", "motivation": "在生产系统中优化大型语言模型（LLM）推断变得越来越困难，由于动态负载、严格的延迟/吞吐量目标以及迅速扩大的配置空间。这种复杂性不仅包括分布式并行策略，还包括涉及CUDA图启用等复杂的框架特定运行时参数。", "method": "AIConfigurator结合了将推断分解为可分析的基本操作（GEMM、注意力、通信和内存操作）的方法，并捕获框架特定的调度动态；一个校准的内核级性能数据库，涵盖各种硬件平台和流行的开放权重模型；以及自动解析目标后端最优启动参数的抽象层。", "result": "在生产LLM服务工作负载上的评估表明，AIConfigurator能够识别出可以改善性能高达40%（如Qwen3-32B）和50%（如DeepSeek-V3）的服务配置，并且平均完成搜索仅需30秒。", "conclusion": "AIConfigurator提供了一种快速探索从集群拓扑到引擎特定标志的广泛设计空间的方法，适用于多框架大型语言模型推理配置优化。"}}
{"id": "2601.06287", "pdf": "https://arxiv.org/pdf/2601.06287", "abs": "https://arxiv.org/abs/2601.06287", "authors": ["Joseph Heyward", "Nikhil Pathasarathy", "Tyler Zhu", "Aravindh Mahendran", "João Carreira", "Dima Damen", "Andrew Zisserman", "Viorica Pătrăucean"], "title": "Perception Test 2025: Challenge Summary and a Unified VQA Extension", "categories": ["cs.CV"], "comment": null, "summary": "The Third Perception Test challenge was organised as a full-day workshop alongside the IEEE/CVF International Conference on Computer Vision (ICCV) 2025. Its primary goal is to benchmark state-of-the-art video models and measure the progress in multimodal perception. This year, the workshop featured 2 guest tracks as well: KiVA (an image understanding challenge) and Physic-IQ (a video generation challenge). In this report, we summarise the results from the main Perception Test challenge, detailing both the existing tasks as well as novel additions to the benchmark. In this iteration, we placed an emphasis on task unification, as this poses a more challenging test for current SOTA multimodal models. The challenge included five consolidated tracks: unified video QA, unified object and point tracking, unified action and sound localisation, grounded video QA, and hour-long video QA, alongside an analysis and interpretability track that is still open for submissions. Notably, the unified video QA track introduced a novel subset that reformulates traditional perception tasks (such as point tracking and temporal action localisation) as multiple-choice video QA questions that video-language models can natively tackle. The unified object and point tracking merged the original object tracking and point tracking tasks, whereas the unified action and sound localisation merged the original temporal action localisation and temporal sound localisation tracks. Accordingly, we required competitors to use unified approaches rather than engineered pipelines with task-specific models. By proposing such a unified challenge, Perception Test 2025 highlights the significant difficulties existing models face when tackling diverse perception tasks through unified interfaces.", "AI": {"tldr": "感知测试2025挑战赛的主要任务是通过视频问答、物体和点跟踪以及动作和声音定位等任务，评估当前最先进的多模态模型的性能。", "motivation": "动机在于衡量和促进多模态感知技术的进步。特别强调了统一任务以考验现有模型在处理多样化的感知任务时的能力。", "method": "通过组织一个涵盖多个子挑战（包括视频问答、物体点跟踪和动作声音定位等）的全日研讨会，并引入新的统一视频问答子任务，改革传统的视觉问答为多选题。", "result": "结果未详细列出具体数值，但强调了现有模型在处理这些多样化的感知任务时存在的困难，并指出竞赛中使用的方法需要通过单一接口来应对所有挑战。", "conclusion": "结论是统一的视频问答等子任务显示出当前最先进的模型在面对多样化且复杂的多模态感知任务时的能力有限。"}}
{"id": "2601.06286", "pdf": "https://arxiv.org/pdf/2601.06286", "abs": "https://arxiv.org/abs/2601.06286", "authors": ["Min Dai", "William D. Compton", "Junheng Li", "Lizhi Yang", "Aaron D. Ames"], "title": "Walk the PLANC: Physics-Guided RL for Agile Humanoid Locomotion on Constrained Footholds", "categories": ["cs.RO"], "comment": null, "summary": "Bipedal humanoid robots must precisely coordinate balance, timing, and contact decisions when locomoting on constrained footholds such as stepping stones, beams, and planks -- even minor errors can lead to catastrophic failure. Classical optimization and control pipelines handle these constraints well but depend on highly accurate mathematical representations of terrain geometry, making them prone to error when perception is noisy or incomplete. Meanwhile, reinforcement learning has shown strong resilience to disturbances and modeling errors, yet end-to-end policies rarely discover the precise foothold placement and step sequencing required for discontinuous terrain. These contrasting limitations motivate approaches that guide learning with physics-based structure rather than relying purely on reward shaping. In this work, we introduce a locomotion framework in which a reduced-order stepping planner supplies dynamically consistent motion targets that steer the RL training process via Control Lyapunov Function (CLF) rewards. This combination of structured footstep planning and data-driven adaptation produces accurate, agile, and hardware-validated stepping-stone locomotion on a humanoid robot, substantially improving reliability compared to conventional model-free reinforcement-learning baselines.", "AI": {"tldr": "本文提出了一种结合物理引导和强化学习的方法，用于双足人形机器人在受限踏点上行走的控制。", "motivation": "传统的优化与控制系统对于地形几何准确表示依赖性强，在感知不完善时容易出错；而端到端的强化学习策略难以发现精确的踏点放置和步序规划。物理引导方法旨在弥补这些不足，通过结构化脚部路径计划来指导训练过程。", "method": "文中引入了一种行走框架：利用减少阶数的步行规划器提供动态一致的目标运动轨迹，并结合控制Lyapunov函数（CLF）奖励，促进强化学习训练过程中的数据驱动自适应。", "result": "该方法在双足机器人上实现了精确、敏捷且通过硬件验证的踏步行走，在可靠性方面显著优于传统的模型无关强化学习基准。", "conclusion": "本文展示了结合物理结构指导与强化学习的优势，为解决复杂地形条件下的人形机器人行走问题提供了有效路径。"}}
{"id": "2601.06285", "pdf": "https://arxiv.org/pdf/2601.06285", "abs": "https://arxiv.org/abs/2601.06285", "authors": ["Shida Xu", "Jingqi Jiang", "Jonatan Scharff Willners", "Sen Wang"], "title": "NAS-GS: Noise-Aware Sonar Gaussian Splatting", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Underwater sonar imaging plays a crucial role in various applications, including autonomous navigation in murky water, marine archaeology, and environmental monitoring. However, the unique characteristics of sonar images, such as complex noise patterns and the lack of elevation information, pose significant challenges for 3D reconstruction and novel view synthesis. In this paper, we present NAS-GS, a novel Noise-Aware Sonar Gaussian Splatting framework specifically designed to address these challenges. Our approach introduces a Two-Ways Splatting technique that accurately models the dual directions for intensity accumulation and transmittance calculation inherent in sonar imaging, significantly improving rendering speed without sacrificing quality. Moreover, we propose a Gaussian Mixture Model (GMM) based noise model that captures complex sonar noise patterns, including side-lobes, speckle, and multi-path noise. This model enhances the realism of synthesized images while preventing 3D Gaussian overfitting to noise, thereby improving reconstruction accuracy. We demonstrate state-of-the-art performance on both simulated and real-world large-scale offshore sonar scenarios, achieving superior results in novel view synthesis and 3D reconstruction.", "AI": {"tldr": "本文提出了NAS-GS框架，用于解决声纳成像中的复杂噪声和缺乏高度信息的问题，以提高三维重建和新视图合成的准确性和速度。", "motivation": "水下声纳成像在自主导航、海洋考古学和环境监测等应用中至关重要。然而，声纳图像的独特特性，如复杂的噪声模式和缺乏高度信息，给3D重建和新视角合成带来了挑战。", "method": "提出了NAS-GS框架，包括两阶段的光子分裂技术和基于高斯混合模型（GMM）的噪声模型，该模型捕获了侧瓣、斑点和多路径噪声等复杂声纳噪声模式。", "result": "在模拟和真实世界的大规模近海声纳场景中实现了最先进的性能，在新视角合成和3D重建方面取得了卓越的结果。", "conclusion": "NAS-GS框架通过引入两阶段光子分裂技术和基于高斯混合模型的噪声建模，有效解决了声纳成像中的复杂问题。"}}
{"id": "2601.06282", "pdf": "https://arxiv.org/pdf/2601.06282", "abs": "https://arxiv.org/abs/2601.06282", "authors": ["Yue Zhou", "Xiaobo Guo", "Belhassen Bayar", "Srinivasan H. Sengamedu"], "title": "Amory: Building Coherent Narrative-Driven Agent Memory through Agentic Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Long-term conversational agents face a fundamental scalability challenge as interactions extend over time: repeatedly processing entire conversation histories becomes computationally prohibitive. Current approaches attempt to solve this through memory frameworks that predominantly fragment conversations into isolated embeddings or graph representations and retrieve relevant ones in a RAG style. While computationally efficient, these methods often treat memory formation minimally and fail to capture the subtlety and coherence of human memory. We introduce Amory, a working memory framework that actively constructs structured memory representations through enhancing agentic reasoning during offline time. Amory organizes conversational fragments into episodic narratives, consolidates memories with momentum, and semanticizes peripheral facts into semantic memory. At retrieval time, the system employs coherence-driven reasoning over narrative structures. Evaluated on the LOCOMO benchmark for long-term reasoning, Amory achieves considerable improvements over previous state-of-the-art, with performance comparable to full context reasoning while reducing response time by 50%. Analysis shows that momentum-aware consolidation significantly enhances response quality, while coherence-driven retrieval provides superior memory coverage compared to embedding-based approaches.", "AI": {"tldr": "构建基于代理推理的连贯叙事驱动的代理人记忆框架Amory。", "motivation": "长期对话代理面临交互历史不断延长而计算资源有限的问题，现有方法通过片段化对话和检索来解决这个问题但忽视了人类记忆中的微妙性和连贯性。", "method": "引入Amory框架，通过增强离线时间的代理推理主动构建结构化的记忆表示。该框架组织对话片段为叙述结构，并使用动量感知巩固及语义知识进行边缘事实的语义化处理。", "result": "在LOCOMO基准测试中，Amory实现了显著改进，性能与完整上下文推理相当而响应时间减少50%。分析表明，动量感知巩固和连贯性驱动检索分别提高了响应质量和记忆覆盖度。", "conclusion": "通过增强代理推理构建结构化记忆表示的Amory框架，成功解决了长期对话中的计算资源限制问题，并实现了比现有方法更优的效果。"}}
{"id": "2601.06279", "pdf": "https://arxiv.org/pdf/2601.06279", "abs": "https://arxiv.org/abs/2601.06279", "authors": ["Stevenson Pather", "Niels Martignène", "Arnaud Bugnet", "Fouad Boutaleb", "Fabien D'Hondt", "Deise Santana Maia"], "title": "EyeTheia: A Lightweight and Accessible Eye-Tracking Toolbox", "categories": ["cs.CV"], "comment": "Code for the EyeTheia gaze-tracking model: https://github.com/patherstevenson/EyeTheia. Experimental platform for the cognitive neuroscience task: https://git.interactions-team.fr/INTERACTIONS/calypso/src/branch/main/src/lonely_tester", "summary": "We introduce EyeTheia, a lightweight and open deep learning pipeline for webcam-based gaze estimation, designed for browser-based experimental platforms and real-world cognitive and clinical research. EyeTheia enables real-time gaze tracking using only a standard laptop webcam, combining MediaPipe-based landmark extraction with a convolutional neural network inspired by iTracker and optional user-specific fine-tuning. We investigate two complementary strategies: adapting a model pretrained on mobile data and training the same architecture from scratch on a desktop-oriented dataset. Validation results on MPIIFaceGaze show comparable performance between both approaches prior to calibration, while lightweight user-specific fine-tuning consistently reduces gaze prediction error. We further evaluate EyeTheia in a realistic Dot-Probe task and compare it to the commercial webcam-based tracker SeeSo SDK. Results indicate strong agreement in left-right gaze allocation during stimulus presentation, despite higher temporal variability. Overall, EyeTheia provides a transparent and extensible solution for low-cost gaze tracking, suitable for scalable and reproducible experimental and clinical studies. The code, trained models, and experimental materials are publicly available.", "AI": {"tldr": "介绍了一种轻量级的眼动追踪工具箱EyeTheia，适用于浏览器平台和真实环境研究。", "motivation": "为了提供一种低成本、透明且可扩展的解决方案来实现实时眼动跟踪，并促进大规模重复性实验及临床研究。", "method": "结合MediaPipe面部特征点提取技术和基于卷积神经网络的眼动估计模型，支持用户特定微调。验证了两种策略：在移动数据预训练模型上的适应和从头开始训练针对桌面的数据集的模型。", "result": "MPIIFaceGaze测试表明，在校准前两种方法性能相当；轻量级的个性化微调可减少预测误差。Dot-Probe任务评估中，EyeTheia与商用追踪器SeeSo SDK相比在左/右注视分配上表现出一致结果。", "conclusion": "EyeTheia提供了一种透明且扩展性强的眼动跟踪解决方案，适用于大规模重复性和临床研究，同时代码、训练模型和实验材料公开可用。"}}
{"id": "2601.06273", "pdf": "https://arxiv.org/pdf/2601.06273", "abs": "https://arxiv.org/abs/2601.06273", "authors": ["Yashika Ahlawat"], "title": "Performance Analysis of DCT, Hadamard, and PCA in Block-Based Image Compression", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Block based image compression relies on transform coding to concentrate signal energy into a small number of coefficients. While classical codecs use fixed transforms such as the Discrete Cosine Transform (DCT), data driven methods such as Principal Component Analysis (PCA) are theoretically optimal for decorrelation. This paper presents an experimental comparison of DCT, Hadamard, and PCA across multiple block sizes and compression rates. Using rate distortion and energy compaction analysis, we show that PCA outperforms fixed transforms only when block dimensionality is sufficiently large, while DCT remains near optimal for standard block sizes such as $8\\times8$ and at low bit rates. These results explain the robustness of DCT in practical codecs and highlight the limitations of block wise learned transforms.", "AI": {"tldr": "比较DCT、Hadamard变换和主成分分析（PCA）在图像块压缩中的性能", "motivation": "探索不同变换方法在图像块压缩中的效率，以优化编码器的性能", "method": "通过率失真分析和能量集中度分析对比了不同尺寸图像块下的多种变换方法", "result": "发现当图像块维度足够大时，PCA优于固定变换；而对于标准大小（如8x8）的块以及低比特率下，DCT表现最优", "conclusion": "这些结果解释了为什么DCT在实际编码器中具有鲁棒性，并指出了基于块的学习转换方法的局限性"}}
{"id": "2601.06268", "pdf": "https://arxiv.org/pdf/2601.06268", "abs": "https://arxiv.org/abs/2601.06268", "authors": ["Amur Ghose", "Junyeong Jang", "Andrew B. Kahng", "Jakang Lee"], "title": "Automated QoR improvement in OpenROAD with coding agents", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "EDA development and innovation has been constrained by scarcity of expert engineering resources. While leading LLMs have demonstrated excellent performance in coding and scientific reasoning tasks, their capacity to advance EDA technology itself has been largely untested. We present AuDoPEDA, an autonomous, repository-grounded coding system built atop OpenAI models and a Codex-class agent that reads OpenROAD, proposes research directions, expands them into implementation steps, and submits executable diffs. Our contributions include (i) a closed-loop LLM framework for EDA code changes; (ii) a task suite and evaluation protocol on OpenROAD for PPA-oriented improvements; and (iii) end-to-end demonstrations with minimal human oversight. Experiments in OpenROAD achieve routed wirelength reductions of up to 5.9%, and effective clock period reductions of up to 10.0%.", "AI": {"tldr": "使用基于OpenAI模型和Codex类代理的自主代码系统AuDoPEDA，在OpenROAD中实现自动化质量优化。", "motivation": "EDA开发受限于专家工程师资源稀缺，通过利用大型语言模型在编码和科学推理任务中的优秀表现来推动EDA技术的进步。", "method": "构建了基于LLM的闭环框架进行EDA代码更改；设计了一套针对OpenROAD的任务集与评估协议以优化PPA，并进行了从研究方向到实施步骤再到提交执行差异文件的端到端演示，所有这些均在最小的人工监督下完成。", "result": "实验结果表明，在OpenROAD中实现了高达5.9%的布线长度减少和10.0%的有效时钟周期减少。", "conclusion": "AuDoPEDA展示了利用大型语言模型进行EDA技术创新的巨大潜力，通过自主代码系统改进了OpenROAD的质量优化。"}}
{"id": "2601.06257", "pdf": "https://arxiv.org/pdf/2601.06257", "abs": "https://arxiv.org/abs/2601.06257", "authors": ["Sobhana Jahan", "Saydul Akbar Murad", "Nick Rahimi", "Noorbakhsh Amiri Golilarz"], "title": "Gamma2Patterns: Deep Cognitive Attention Region Identification and Gamma-Alpha Pattern Analysis", "categories": ["q-bio.NC", "cs.AI", "cs.CV"], "comment": null, "summary": "Deep cognitive attention is characterized by heightened gamma oscillations and coordinated visual behavior. Despite the physiological importance of these mechanisms, computational studies rarely synthesize these modalities or identify the neural regions most responsible for sustained focus. To address this gap, this work introduces Gamma2Patterns, a multimodal framework that characterizes deep cognitive attention by leveraging complementary Gamma and Alpha band EEG activity alongside Eye-tracking measurements. Using the SEED-IV dataset [1], we extract spectral power, burst-based temporal dynamics, and fixation-saccade-pupil signals across 62 channels or electrodes to analyze how neural activation differs between high-focus (Gamma-dominant) and low-focus (Alpha-dominant) states. Our findings reveal that frontopolar, temporal, anterior frontal, and parieto-occipital regions exhibit the strongest Gamma power and burst rates, indicating their dominant role in deep attentional engagement, while Eye-tracking signals confirm complementary contributions from frontal, frontopolar, and frontotemporal regions. Furthermore, we show that Gamma power and burst duration provide more discriminative markers of deep focus than Alpha power alone, demonstrating their value for attention decoding. Collectively, these results establish a multimodal, evidence-based map of cortical regions and oscillatory signatures underlying deep focus, providing a neurophysiological foundation for future brain-inspired attention mechanisms in AI systems.", "AI": {"tldr": "该论文提出了Gamma2Patterns框架，利用多模态数据（包括EEG和眼动追踪）来识别深度认知注意力的关键脑区和振荡模式。", "motivation": "探讨了在深入注意过程中大脑区域和振荡活动的重要性，并希望填补计算研究中关于这些机制整合的空白。", "method": "使用SEED-IV数据集，结合Gamma频段和Alpha频段EEG信号以及眼动追踪测量来分析深度认知注意力相关的脑区激活情况。", "result": "发现前顶叶、颞叶、额前部及枕顶叶区域在Gamma振荡中表现突出；同时证实了Gamma功率和爆发持续时间比单独的Alpha功率提供了更好的区分标记。", "conclusion": "确立了一种基于多模态数据的深度注意力神经生理基础图谱，并为未来AI系统中的大脑启发式注意机制奠定了研究基础。"}}
{"id": "2601.06243", "pdf": "https://arxiv.org/pdf/2601.06243", "abs": "https://arxiv.org/abs/2601.06243", "authors": ["Soundes Oumaima Boufaida", "Abdemadjid Benmachiche", "Majda Maatallah"], "title": "Real-Time Image Processing Algorithms for Embedded Systems", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Embedded vision systems need efficient and robust image processing algorithms to perform real-time, with resource-constrained hardware. This research investigates image processing algorithms, specifically edge detection, corner detection, and blob detection, that are implemented on embedded processors, including DSPs and FPGAs. To address latency, accuracy and power consumption noted in the image processing literature, optimized algorithm architectures and quantization techniques are employed. In addition, optimal techniques for inter-frame redundancy removal and adaptive frame averaging are used to improve throughput with reasonable image quality. Simulations and hardware trials of the proposed approaches show marked improvements in the speed and energy efficiency of processing as compared to conventional implementations. The advances of this research facilitate a path for scalable and inexpensive embedded imaging systems for the automotive, surveillance, and robotics sectors, and underscore the benefit of co-designing algorithms and hardware architectures for practical real-time embedded vision applications.", "AI": {"tldr": "嵌入式视觉系统中高效且鲁棒的实时图像处理算法的研究。", "motivation": "为了在资源受限的硬件上实现高效的实时图像处理，研究针对边缘检测、角点检测和连通域检测等特定图像处理算法进行优化。", "method": "采用了优化的架构设计和量化技术来减少延迟，提高准确性，并降低功耗。通过帧间冗余去除技术和自适应帧平均方法提高了吞吐量，同时保持了合理的图像质量。", "result": "仿真和硬件实验表明，所提出的方案与传统实现相比，在处理速度和能源效率方面有显著提升。", "conclusion": "研究推动了可扩展且低成本的嵌入式成像系统在汽车、监控和机器人等领域的应用，并强调算法和硬件架构协同设计对于实用实时嵌入式视觉应用的重要性。"}}
{"id": "2601.06241", "pdf": "https://arxiv.org/pdf/2601.06241", "abs": "https://arxiv.org/abs/2601.06241", "authors": ["Chandra Sekhar Kubam"], "title": "Agentic AI Microservice Framework for Deepfake and Document Fraud Detection in KYC Pipelines", "categories": ["cs.CR", "cs.AI"], "comment": "Journal of Information Systems Engineering and Management, 2024", "summary": "The rapid proliferation of synthetic media, presentation attacks, and document forgeries has created significant vulnerabilities in Know Your Customer (KYC) workflows across financial services, telecommunications, and digital-identity ecosystems. Traditional monolithic KYC systems lack the scalability and agility required to counter adaptive fraud. This paper proposes an Agentic AI Microservice Framework that integrates modular vision models, liveness assessment, deepfake detection, OCR-based document forensics, multimodal identity linking, and a policy driven risk engine. The system leverages autonomous micro-agents for task decomposition, pipeline orchestration, dynamic retries, and human-in-the-loop escalation. Experimental evaluations demonstrate improved detection accuracy, reduced latency, and enhanced resilience against adversarial inputs. The framework offers a scalable blueprint for regulated industries seeking robust, real-time, and privacy-preserving KYC verification.", "AI": {"tldr": "提出了一种代理AI微服务框架，用于KYC流程中深度伪造和文档欺诈检测。", "motivation": "传统的单体式KYC系统无法应对合成媒体、呈现攻击和文件伪造带来的新威胁。该框架旨在解决这些系统的可扩展性和敏捷性问题。", "method": "集成模块化视觉模型、活性评估、深度伪造检测、基于OCR的文档取证、多模态身份链接及策略驱动风险引擎，利用自主微代理进行任务分解和管道编排。", "result": "实验表明，该系统提高了检测准确性，减少了延迟，并增强了对抗性输入的抵抗力。", "conclusion": "框架为寻求稳健、实时且隐私保护的KYC验证提供了一个可扩展蓝图。"}}
{"id": "2601.06239", "pdf": "https://arxiv.org/pdf/2601.06239", "abs": "https://arxiv.org/abs/2601.06239", "authors": ["Aya Kaysan Bahjat"], "title": "A survey of facial recognition techniques", "categories": ["cs.CV", "cs.GR"], "comment": "12 pages, 12 figures, article", "summary": "As multimedia content is quickly growing, the field of facial recognition has become one of the major research fields, particularly in the recent years. The most problematic area to researchers in image processing and computer vision is the human face which is a complex object with myriads of distinctive features that can be used to identify the face. The survey of this survey is particularly focused on most challenging facial characteristics, including differences in the light, ageing, variation in poses, partial occlusion, and facial expression and presents methodological solutions. The factors, therefore, are inevitable in the creation of effective facial recognition mechanisms used on facial images. This paper reviews the most sophisticated methods of facial detection which are Hidden Markov Models, Principal Component Analysis (PCA), Elastic Cluster Plot Matching, Support Vector Machine (SVM), Gabor Waves, Artificial Neural Networks (ANN), Eigenfaces, Independent Component Analysis (ICA), and 3D Morphable Model. Alongside the works mentioned above, we have also analyzed the images of a number of facial databases, namely JAFEE, FEI, Yale, LFW, AT&T (then called ORL), and AR (created by Martinez and Benavente), to analyze the results. However, this survey is aimed at giving a thorough literature review of face recognition, and its applications, and some experimental results are provided at the end after a detailed discussion.", "AI": {"tldr": "综述了面部识别技术，包括各种方法和数据库的应用", "motivation": "多媒体内容快速增长使得面部识别成为研究热点，但光照、老化、姿势变化等因素使其变得复杂", "method": "回顾了隐藏马尔可夫模型、主成分分析、弹性聚类图匹配等方法，并使用JAFEE、FEI、Yale等数据库进行实验验证", "result": "提供了一些面部识别的实验结果，展示了不同技术在面对挑战时的表现", "conclusion": "总结了面部识别领域的现状和未来发展方向"}}
{"id": "2601.06238", "pdf": "https://arxiv.org/pdf/2601.06238", "abs": "https://arxiv.org/abs/2601.06238", "authors": ["Arion Das", "Partha Pratim Saha", "Amit Dhanda", "Vinija Jain", "Aman Chadha", "Amitava Das"], "title": "SPINAL -- Scaling-law and Preference Integration in Neural Alignment Layers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Direct Preference Optimization (DPO) is a principled, scalable alternative to RLHF for aligning large language models from pairwise preferences, but its internal geometric footprint remains undercharacterized, limiting audits, checkpoint comparisons, and failure prediction. We introduce SPINAL (Scaling-law and Preference Integration in Neural Alignment Layers), a diagnostic that measures how alignment reshapes representations across depth by tracing localized structural change layer by layer. Across model families, DPO produces a layerwise calibration effect concentrated in the final decoder blocks (often layers 21-30), where preference gradients most directly affect the next-token distribution. SPINAL encodes each checkpoint as a depth trace over (layer index, contraction score, transport score). The contraction score summarizes how quickly the tail of a layer's spectrum decays (how fast small modes vanish); higher values indicate stronger contraction into fewer effective directions. The transport score summarizes how much the token distribution shifts between adjacent layers using a bounded overlap measure; lower values indicate shorter, smoother steps through representation space. Aligned checkpoints show a late-layer ramp-up in contraction and a smooth reduction in transport, consistent with tightened and stabilized policy mass, while unaligned models trace higher-curvature, more entropic, and geometrically incoherent depth paths. Overall, alignment is geometrically localized: the final layers encode the dominant preference-induced corrections. SPINAL turns this localization into a practical audit signal, quantifying where alignment concentrates, how strongly it manifests, and when it begins to destabilize during training.", "AI": {"tldr": "SPINAL是一种诊断工具，用于测量大型语言模型通过偏好优化进行对齐时，其表示如何随深度变化。", "motivation": "DPO虽然作为一种可扩展的替代RLHF方法来对齐大型语言模型，但其内部几何特性尚不清楚。因此，需要一种诊断方法以更深入理解这一过程。", "method": "SPINAL通过追踪各层局部结构的变化来测量对齐如何重塑表示。它将每个检查点编码为深度轨迹图（由层次索引、收缩分数和传输分数组成），其中收缩分数总结了层光谱尾部衰减的速度，而传输分数衡量相邻层间标记分布的转移。", "result": "与未对齐模型相比，对齐后的模型在最终几层中表现出较强的收缩效应和平滑减少传输的趋势。", "conclusion": "SPINAL揭示了对齐过程中的几何局部化现象，并将其转化为实用的审计信号，量化了对齐集中在哪里、如何强烈地表现以及何时开始不稳定。"}}
{"id": "2601.06235", "pdf": "https://arxiv.org/pdf/2601.06235", "abs": "https://arxiv.org/abs/2601.06235", "authors": ["Sheng-Kai Chen", "Jyh-Horng Wu", "Ching-Yao Lin", "Yen-Ting Lin"], "title": "An Intelligent AI glasses System with Multi-Agent Architecture for Real-Time Voice Processing and Task Execution", "categories": ["cs.SD", "cs.AI", "cs.HC"], "comment": "Published in NCS 2025 (Paper No. N0180)", "summary": "This paper presents an AI glasses system that integrates real-time voice processing, artificial intelligence(AI) agents, and cross-network streaming capabilities. The system employs dual-agent architecture where Agent 01 handles Automatic Speech Recognition (ASR) and Agent 02 manages AI processing through local Large Language Models (LLMs), Model Context Protocol (MCP) tools, and Retrieval-Augmented Generation (RAG). The system supports real-time RTSP streaming for voice and video data transmission, eye tracking data collection, and remote task execution through RabbitMQ messaging. Implementation demonstrates successful voice command processing with multilingual support and cross-platform task execution capabilities.", "AI": {"tldr": "本文提出了一种集成实时语音处理、人工智能代理和跨网络流媒体功能的智能AI眼镜系统。", "motivation": "目的是开发一种能够支持多语言实时语音命令处理及远程任务执行能力的智能AI眼镜系统，以提升用户在各种平台上的交互体验。", "method": "该系统采用双代理架构：Agent 01负责自动语音识别（ASR），而Agent 02则通过本地大型语言模型（LLMs）、模型上下文协议（MCP）工具和检索增强生成（RAG）进行AI处理。此外，系统支持实时RTSP流媒体传输以及通过RabbitMQ消息传递执行远程任务。", "result": "实现了多语种支持的实时语音命令处理及跨平台任务执行能力。", "conclusion": "提出的智能AI眼镜系统成功展示了其在实际应用中的有效性和可行性。"}}
{"id": "2601.06234", "pdf": "https://arxiv.org/pdf/2601.06234", "abs": "https://arxiv.org/abs/2601.06234", "authors": ["Weijie Li", "Zhongqing Wang", "Guodong Zhou"], "title": "PCoKG: Personality-aware Commonsense Reasoning with Debate", "categories": ["cs.AI"], "comment": "Accept by AAAI-2026", "summary": "Most commonsense reasoning models overlook the influence of personality traits, limiting their effectiveness in personalized systems such as dialogue generation. To address this limitation, we introduce the Personality-aware Commonsense Knowledge Graph (PCoKG), a structured dataset comprising 521,316 quadruples. We begin by employing three evaluators to score and filter events from the ATOMIC dataset, selecting those that are likely to elicit diverse reasoning patterns across different personality types. For knowledge graph construction, we leverage the role-playing capabilities of large language models (LLMs) to perform reasoning tasks. To enhance the quality of the generated knowledge, we incorporate a debate mechanism consisting of a proponent, an opponent, and a judge, which iteratively refines the outputs through feedback loops. We evaluate the dataset from multiple perspectives and conduct fine-tuning and ablation experiments using multiple LLM backbones to assess PCoKG's robustness and the effectiveness of its construction pipeline. Our LoRA-based fine-tuning results indicate a positive correlation between model performance and the parameter scale of the base models. Finally, we apply PCoKG to persona-based dialogue generation, where it demonstrates improved consistency between generated responses and reference outputs. This work bridges the gap between commonsense reasoning and individual cognitive differences, enabling the development of more personalized and context-aware AI systems.", "AI": {"tldr": "构建了一个包含521,316个四元组的个性感知常识知识图谱PCoKG，通过辩论机制提高知识生成的质量，并应用于个性化对话生成。", "motivation": "大多数常识推理模型忽略了个性特征的影响，限制了它们在个性化系统中的有效性。本文旨在开发一种能够考虑到个人认知差异的个性化常识推理和知识图谱构建方法。", "method": "采用三个评分器筛选ATOMIC数据集中的事件并过滤掉可能导致单一推论模式的数据。利用大型语言模型的角色扮演能力执行推理任务，并引入辩论机制来提高生成的知识质量。", "result": "通过多个视角评估了PCoKG，进行了多种基础模型的微调和消融实验，表明所提方法具有良好的鲁棒性和有效性，应用在基于个性的对话生成中提高了回复与参考输出的一致性。", "conclusion": "本文提出了一种新的常识知识图谱构建方法，并应用于个性化对话系统，证明了该方法可以有效提高系统的个性化和上下文感知能力。"}}
{"id": "2601.06232", "pdf": "https://arxiv.org/pdf/2601.06232", "abs": "https://arxiv.org/abs/2601.06232", "authors": ["Haris Khan", "Sadia Asif", "Shumaila Asif"], "title": "Multi-Agent Framework for Controllable and Protected Generative Content Creation: Addressing Copyright and Provenance in AI-Generated Media", "categories": ["cs.CR", "cs.AI"], "comment": "mber:S44201 S44201 S44201", "summary": "The proliferation of generative AI systems creates unprecedented opportunities for content creation while raising critical concerns about controllability, copyright infringement, and content provenance. Current generative models operate as \"black boxes\" with limited user control and lack built-in mechanisms to protect intellectual property or trace content origin. We propose a novel multi-agent framework that addresses these challenges through specialized agent roles and integrated watermarking. Our system orchestrates Director, Generator, Reviewer, Integration, and Protection agents to ensure user intent alignment while embedding digital provenance markers. We demonstrate feasibility through two case studies: creative content generation with iterative refinement and copyright protection for AI-generated art in commercial contexts. Preliminary feasibility evidence from prior work indicates up to 23\\% improvement in semantic alignment and 95\\% watermark recovery rates. This work contributes to responsible generative AI deployment, positioning multi-agent systems as a solution for trustworthy creative workflows in legal and commercial applications.", "AI": {"tldr": "提出一种多代理框架，解决生成AI系统的版权和内容来源问题。", "motivation": "当前的生成模型缺乏用户控制机制且难以追溯内容来源，导致版权侵权等问题。", "method": "设计了包括导演、生成器、审查员、集成和保护在内的多个代理角色来保证用户意图对齐，并嵌入数字来源标记。", "result": "通过两个案例研究展示了系统的可行性：创意内容生成的迭代改进及AI生成艺术在商业中的版权保护。初步结果显示，语义对齐提高了23%，水印恢复率为95%。", "conclusion": "该工作促进了负责任的生成性AI部署，并将多代理系统定位为法律和商业应用中值得信赖的创意工作流程解决方案。"}}
{"id": "2601.06229", "pdf": "https://arxiv.org/pdf/2601.06229", "abs": "https://arxiv.org/abs/2601.06229", "authors": ["Ingo Schmitt"], "title": "Triadic Concept Analysis for Logic Interpretation of Simple Artificial Networks", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": ":I.2", "summary": "An artificial neural network (ANN) is a numerical method used to solve complex classification problems. Due to its high classification power, the ANN method often outperforms other classification methods in terms of accuracy. However, an ANN model lacks interpretability compared to methods that use the symbolic paradigm. Our idea is to derive a symbolic representation from a simple ANN model trained on minterm values of input objects. Based on ReLU nodes, the ANN model is partitioned into cells. We convert the ANN model into a cell-based, three-dimensional bit tensor. The theory of Formal Concept Analysis applied to the tensor yields concepts that are represented as logic trees, expressing interpretable attribute interactions. Their evaluations preserve the classification power of the initial ANN model.", "AI": {"tldr": "通过将人工神经网络（ANN）模型转换为三维比特张量，并应用形式概念分析理论来生成逻辑树，从而提高其可解释性。", "motivation": "提升简单ANN模型的可解释性，使其在保持分类能力的同时更加易于理解。", "method": "基于ReLU节点对ANN模型进行分区，将其转化为细胞为基础的三位比特张量；然后运用形式概念分析理论应用于张量上生成逻辑树。", "result": "逻辑树能够表达可解读的属性交互，并且保留了原始ANN模型的分类能力。", "conclusion": "该方法成功地将ANN模型转换为具有高度解释性的逻辑树，同时保持了其强大的分类性能。"}}
{"id": "2601.06228", "pdf": "https://arxiv.org/pdf/2601.06228", "abs": "https://arxiv.org/abs/2601.06228", "authors": ["Zhaoze Wang", "Changxu Zhang", "Tai Fei", "Christopher Grimm", "Yi Jin", "Claas Tebruegge", "Ernst Warsitz", "Markus Gardill"], "title": "Synthetic FMCW Radar Range Azimuth Maps Augmentation with Generative Diffusion Model", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The scarcity and low diversity of well-annotated automotive radar datasets often limit the performance of deep-learning-based environmental perception. To overcome these challenges, we propose a conditional generative framework for synthesizing realistic Frequency-Modulated Continuous-Wave radar Range-Azimuth Maps. Our approach leverages a generative diffusion model to generate radar data for multiple object categories, including pedestrians, cars, and cyclists. Specifically, conditioning is achieved via Confidence Maps, where each channel represents a semantic class and encodes Gaussian-distributed annotations at target locations. To address radar-specific characteristics, we incorporate Geometry Aware Conditioning and Temporal Consistency Regularization into the generative process. Experiments on the ROD2021 dataset demonstrate that signal reconstruction quality improves by \\SI{3.6}{dB} in Peak Signal-to-Noise Ratio over baseline methods, while training with a combination of real and synthetic datasets improves overall mean Average Precision by 4.15% compared with conventional image-processing-based augmentation. These results indicate that our generative framework not only produces physically plausible and diverse radar spectrum but also substantially improves model generalization in downstream tasks.", "AI": {"tldr": "本文提出了一种基于生成扩散模型的条件生成框架，用于合成真实性的频率调制连续波雷达范围-方位图。", "motivation": "为了解决汽车雷达数据集稀缺和低多样性的挑战，提高深度学习环境感知性能。", "method": "利用生成扩散模型并结合置信度地图、几何感知条件化及时间一致性正则化来合成多类目标的雷达数据。", "result": "信号重建质量在峰值信噪比上提高了3.6dB，与传统图像处理增强方法相比，在平均精度上提升了4.15%。", "conclusion": "该生成框架不仅产生了物理上合理的多样化的雷达光谱，还显著改善了下游任务中的模型泛化能力。"}}
{"id": "2601.06227", "pdf": "https://arxiv.org/pdf/2601.06227", "abs": "https://arxiv.org/abs/2601.06227", "authors": ["Dhivya Dharshini Kannan", "Wei Li", "Zhang Wei", "Jianbiao Wang", "Zhi Wei Seh", "Man-Fai Ng"], "title": "When Smaller Wins: Dual-Stage Distillation and Pareto-Guided Compression of Liquid Neural Networks for Edge Battery Prognostics", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to International Conference on Pattern Recognition, ICPR 2026", "summary": "Battery management systems increasingly require accurate battery health prognostics under strict on-device constraints. This paper presents DLNet, a practical framework with dual-stage distillation of liquid neural networks that turns a high-capacity model into compact and edge-deployable models for battery health prediction. DLNet first applies Euler discretization to reformulate liquid dynamics for embedded compatibility. It then performs dual-stage knowledge distillation to transfer the teacher model's temporal behavior and recover it after further compression. Pareto-guided selection under joint error-cost objectives retains student models that balance accuracy and efficiency. We evaluate DLNet on a widely used dataset and validate real-device feasibility on an Arduino Nano 33 BLE Sense using int8 deployment. The final deployed student achieves a low error of 0.0066 when predicting battery health over the next 100 cycles, which is 15.4% lower than the teacher model. It reduces the model size from 616 kB to 94 kB with 84.7% reduction and takes 21 ms per inference on the device. These results support a practical smaller wins observation that a small model can match or exceed a large teacher for edge-based prognostics with proper supervision and selection. Beyond batteries, the DLNet framework can extend to other industrial analytics tasks with strict hardware constraints.", "AI": {"tldr": "该论文提出DLNet框架，用于将大型模型转化为小型、边缘设备可部署的电池健康预测模型。", "motivation": "在严格的设备限制下，准确地进行电池健康管理越来越重要。为此，研究者希望通过一个实用框架来实现这一目标。", "method": "DLNet首先使用Euler离散化重写液体动力学以满足嵌入式兼容性需求。然后执行双阶段知识蒸馏以转移教师模型的时序行为，并在进一步压缩后恢复这种行为。同时，帕累托导向的选择机制在联合误差成本目标下保留了学生模型，这些学生模型可以平衡准确性和效率。", "result": "最终部署的学生模型在预测电池健康方面取得了0.0066的低错误率，在100个周期内比教师模型低15.4%。它将模型大小从616kB减少到94kB，减少了84.7%，并且每个推理仅需21ms。", "conclusion": "DLNet框架证明了在边缘设备上进行电池健康预测时，适当监督和选择可以使得小型模型的表现超过大型教师模型。该方法还可应用于其他具有严格硬件约束的工业分析任务中。"}}
{"id": "2601.06226", "pdf": "https://arxiv.org/pdf/2601.06226", "abs": "https://arxiv.org/abs/2601.06226", "authors": ["Zenghao Duan", "Zhiyi Yin", "Zhichao Shi", "Liang Pang", "Shaoling Jing", "Zihe Huang", "Jiayi Wu", "Yu Yan", "Jingcheng Deng", "Huawei Shen", "Xueqi Cheng"], "title": "Projecting Out the Malice: A Global Subspace Approach to LLM Detoxification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) exhibit exceptional performance but pose inherent risks of generating toxic content, restricting their safe deployment. While traditional methods (e.g., alignment) adjust output preferences, they fail to eliminate underlying toxic regions in parameters, leaving models vulnerable to adversarial attacks. Prior mechanistic studies characterize toxic regions as \"toxic vectors\" or \"layer-wise subspaces\", yet our analysis identifies critical limitations: i) Removed toxic vectors can be reconstructed via linear combinations of non-toxic vectors, demanding targeting of entire toxic subspace; ii) Contrastive objective over limited samples inject noise into layer-wise subspaces, hindering stable extraction. These highlight the challenge of identifying robust toxic subspace and removing them. Therefore, we propose GLOSS (GLobal tOxic Subspace Suppression), a lightweight method that mitigates toxicity by identifying and eliminating this global subspace from FFN parameters. Experiments on LLMs (e.g., Qwen3) show GLOSS achieves SOTA detoxification while preserving general capabilities without requiring large-scale retraining. WARNING: This paper contains context which is toxic in nature.", "AI": {"tldr": "该论文提出了一种名为GLOSS的方法，用于识别和消除大型语言模型中的全局有毒子空间，从而减轻毒性输出。", "motivation": "传统方法虽然可以调整语言模型的输出偏好，但无法彻底去除参数中固有的有毒区域。现有研究指出，有毒向量可以通过非有毒向量的线性组合重建，并且对比目标仅在有限样本上进行，这会导致层级子空间注入噪声。", "method": "该论文提出了GLOSS（全局有毒子空间抑制）方法，通过从前馈网络参数中识别并消除全球有毒子空间来减轻毒性输出。", "result": "实验表明，GLOSS能够在不牺牲通用能力的情况下实现最佳的去毒效果，并且不需要大规模重新训练。", "conclusion": "GLOSS为大型语言模型的安全部署提供了一种有效的方法，可以更稳健地去除潜在有毒区域。"}}
{"id": "2601.06225", "pdf": "https://arxiv.org/pdf/2601.06225", "abs": "https://arxiv.org/abs/2601.06225", "authors": ["Jio Oh", "Steven Euijong Whang", "James Evans", "Jindong Wang"], "title": "Classroom AI: Large Language Models as Grade-Specific Teachers", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) offer a promising solution to complement traditional teaching and address global teacher shortages that affect hundreds of millions of children, but they fail to provide grade-appropriate responses for students at different educational levels. We introduce a framework for finetuning LLMs to generate age-appropriate educational content across six grade levels, from lower elementary to adult education. Our framework successfully adapts explanations to match students' comprehension capacities without sacrificing factual correctness. This approach integrates seven established readability metrics through a clustering method and builds a comprehensive dataset for grade-specific content generation. Evaluations across multiple datasets with 208 human participants demonstrate substantial improvements in grade-level alignment, achieving a 35.64 percentage point increase compared to prompt-based methods while maintaining response accuracy. AI-assisted learning tailored to different grade levels has the potential to advance educational engagement and equity.", "AI": {"tldr": "本文介绍了一种框架，用于微调大型语言模型以生成适用于不同教育阶段的年龄适当的内容。", "motivation": "解决全球教师短缺问题，提高教育资源的分配和利用效率。", "method": "通过七种可读性指标结合聚类方法建立数据集，并对LLM进行微调以适应学生的理解能力。", "result": "评估显示，在不同教育阶段的内容生成上实现了35.64个百分点的增长。", "conclusion": "该AI辅助学习框架有助于提高教育的参与度和公平性。"}}
{"id": "2601.06224", "pdf": "https://arxiv.org/pdf/2601.06224", "abs": "https://arxiv.org/abs/2601.06224", "authors": ["Miao Pan", "Wangjie Gan", "Jintao Chen", "Wenqi Zhang", "Bing Sun", "Jianwei Yin", "Xuhong Zhang"], "title": "Ground What You See: Hallucination-Resistant MLLMs via Caption Feedback, Diversity-Aware Sampling, and Conflict Regularization", "categories": ["cs.CV"], "comment": "AAAI-2026 Poster", "summary": "While Multimodal Large Language Models (MLLMs) have achieved remarkable success across diverse tasks, their practical deployment is severely hindered by hallucination issues, which become particularly acute during Reinforcement Learning (RL) optimization. This paper systematically analyzes the root causes of hallucinations in MLLMs under RL training, identifying three critical factors: (1) an over-reliance on chained visual reasoning, where inaccurate initial descriptions or redundant information anchor subsequent inferences to incorrect premises; (2) insufficient exploration diversity during policy optimization, leading the model to generate overly confident but erroneous outputs; and (3) destructive conflicts between training samples, where Neural Tangent Kernel (NTK) similarity causes false associations and unstable parameter updates. To address these challenges, we propose a comprehensive framework comprising three core modules. First, we enhance visual localization by introducing dedicated planning and captioning stages before the reasoning phase, employing a quality-based caption reward to ensure accurate initial anchoring. Second, to improve exploration, we categorize samples based on the mean and variance of their reward distributions, prioritizing samples with high variance to focus the model on diverse and informative data. Finally, to mitigate sample interference, we regulate NTK similarity by grouping sample pairs and applying an InfoNCE loss to push overly similar pairs apart and pull dissimilar ones closer, thereby guiding gradient interactions toward a balanced range. Experimental results demonstrate that our proposed method significantly reduces hallucination rates and effectively enhances the inference accuracy of MLLMs.", "AI": {"tldr": "论文提出了一个框架，通过增强视觉定位、提高探索多样性和减轻样本干扰来减少多模态大型语言模型在强化学习训练中的幻觉问题。", "motivation": "多模态大型语言模型在强化学习优化过程中存在幻觉问题，这些问题阻碍了它们的实际部署。本文旨在系统地分析这些幻觉的根源，并提出解决方案。", "method": "论文提出了一个框架包含三个核心模块：增强视觉定位、提高探索多样性和减轻样本干扰。通过质量基础的标题奖励保证准确的初始锚定；通过分类基于奖励分布均值和方差的样本，促进模型生成多样化信息；通过应用InfoNCE损失来调整相似度以平衡梯度互动。", "result": "实验结果表明所提出的方法显著降低了幻觉率并提高了多模态大型语言模型的推理准确性。", "conclusion": "该框架有效地减少了多模态大型语言模型在强化学习训练中的幻觉问题，提升了模型的实用性。"}}
{"id": "2601.06223", "pdf": "https://arxiv.org/pdf/2601.06223", "abs": "https://arxiv.org/abs/2601.06223", "authors": ["Edward C. Cheng", "Jeshua Cheng", "Alice Siu"], "title": "Toward Safe and Responsible AI Agents: A Three-Pillar Model for Transparency, Accountability, and Trustworthiness", "categories": ["cs.CY", "cs.AI"], "comment": "15 pages, 8 figures, conference paper", "summary": "This paper presents a conceptual and operational framework for developing and operating safe and trustworthy AI agents based on a Three-Pillar Model grounded in transparency, accountability, and trustworthiness. Building on prior work in Human-in-the-Loop systems, reinforcement learning, and collaborative AI, the framework defines an evolutionary path toward autonomous agents that balances increasing automation with appropriate human oversight. The paper argues that safe agent autonomy must be achieved through progressive validation, analogous to the staged development of autonomous driving, rather than through immediate full automation. Transparency and accountability are identified as foundational requirements for establishing user trust and for mitigating known risks in generative AI systems, including hallucinations, data bias, and goal misalignment, such as the inversion problem. The paper further describes three ongoing work streams supporting this framework: public deliberation on AI agents conducted by the Stanford Deliberative Democracy Lab, cross-industry collaboration through the Safe AI Agent Consortium, and the development of open tooling for an agent operating environment aligned with the Three-Pillar Model. Together, these contributions provide both conceptual clarity and practical guidance for enabling the responsible evolution of AI agents that operate transparently, remain aligned with human values, and sustain societal trust.", "AI": {"tldr": "提出了一种基于透明性、问责制和可信赖性的三支柱模型的框架，用于开发和运行安全且值得信任的人工智能代理。", "motivation": "为了在人工智能系统中建立用户信任并降低已知风险，如幻觉、数据偏见和目标偏差，该论文探讨了如何通过渐进验证的方法来实现自主代理的安全性与适当的人类监督之间的平衡。", "method": "基于人类参与的循环系统、强化学习以及合作智能的相关工作，提出了一个概念性和操作性的框架。这个框架定义了一条通往自动化代理的道路，同时确保有适当的人员监管。该论文还描述了三个正在开展的工作流：由斯坦福审议民主实验室进行的人工智能代理公共审议；通过安全人工智能代理联盟实现跨行业的协作；以及为符合三支柱模型的代理运行环境开发开放工具。", "result": "提供了概念上的清晰度和实践指南，以支持负责任地发展操作透明、与人类价值观保持一致并维持社会信任的人工智能代理。", "conclusion": "通过渐进验证的方法来实现自主代理的安全性是可行且必要的。为了建立用户信任和减少风险，必须确保人工智能系统的透明性和问责制，并促进跨行业合作以推动安全人工智能的发展。"}}
{"id": "2601.06222", "pdf": "https://arxiv.org/pdf/2601.06222", "abs": "https://arxiv.org/abs/2601.06222", "authors": ["Xinghao Wang", "Changtao Miao", "Dianmo Sheng", "Tao Gong", "Qi Chu", "Nenghai Yu", "Quanchen Zou", "Deyue Zhang", "Xiangzheng Zhang"], "title": "SAPL: Semantic-Agnostic Prompt Learning in CLIP for Weakly Supervised Image Manipulation Localization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Malicious image manipulation threatens public safety and requires efficient localization methods. Existing approaches depend on costly pixel-level annotations which make training expensive. Existing weakly supervised methods rely only on image-level binary labels and focus on global classification, often overlooking local edge cues that are critical for precise localization. We observe that feature variations at manipulated boundaries are substantially larger than in interior regions. To address this gap, we propose Semantic-Agnostic Prompt Learning (SAPL) in CLIP, which learns text prompts that intentionally encode non-semantic, boundary-centric cues so that CLIPs multimodal similarity highlights manipulation edges rather than high-level object semantics. SAPL combines two complementary modules Edge-aware Contextual Prompt Learning (ECPL) and Hierarchical Edge Contrastive Learning (HECL) to exploit edge information in both textual and visual spaces. The proposed ECPL leverages edge-enhanced image features to generate learnable textual prompts via an attention mechanism, embedding semantic-irrelevant information into text features, to guide CLIP focusing on manipulation edges. The proposed HECL extract genuine and manipulated edge patches, and utilize contrastive learning to boost the discrimination between genuine edge patches and manipulated edge patches. Finally, we predict the manipulated regions from the similarity map after processing. Extensive experiments on multiple public benchmarks demonstrate that SAPL significantly outperforms existing approaches, achieving state-of-the-art localization performance.", "AI": {"tldr": "本文提出了SAPL方法，用于在弱监督条件下定位图像篡改区域", "motivation": "现有的图像篡改定位方法需要昂贵的像素级标注，导致训练成本高。而现有的弱监督方法主要关注全局分类，忽略了关键的局部边缘线索。为此，论文提出了一种新的学习方法，旨在利用边界信息进行精确的篡改定位", "method": "SAPL结合了两个互补模块：Edge-aware Contextual Prompt Learning (ECPL) 和 Hierarchical Edge Contrastive Learning (HECL)，前者通过增强图像特征生成可学习的文本提示，后者则采用对比学习提高真实边缘与篡改边缘的区别度。这两个模块共同工作以突出显示图像中的篡改边界", "result": "实验结果表明SAPL在多个公共基准上显著优于现有方法，实现了最先进的定位性能", "conclusion": "本文提出了一种新颖的方法来解决弱监督下的图像篡改定位问题，并通过实验证明了其有效性"}}
{"id": "2601.06221", "pdf": "https://arxiv.org/pdf/2601.06221", "abs": "https://arxiv.org/abs/2601.06221", "authors": ["Zhi Wang", "Yanni Li", "Pingping Zheng", "Yiyuan Jiao"], "title": "LDTC: Lifelong deep temporal clustering for multivariate time series", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Clustering temporal and dynamically changing multivariate time series from real-world fields, called temporal clustering for short, has been a major challenge due to inherent complexities. Although several deep temporal clustering algorithms have demonstrated a strong advantage over traditional methods in terms of model learning and clustering results, the accuracy of the few algorithms are not satisfactory. None of the existing algorithms can continuously learn new tasks and deal with the dynamic data effectively and efficiently in the sequential tasks learning. To bridge the gap and tackle these issues, this paper proposes a novel algorithm \\textbf{L}ifelong \\textbf{D}eep \\textbf{T}emporal \\textbf{C}lustering (\\textbf{LDTC}), which effectively integrates dimensionality reduction and temporal clustering into an end-to-end deep unsupervised learning framework. Using a specifically designed autoencoder and jointly optimizing for both the latent representation and clustering objective, the LDTC can achieve high-quality clustering results. Moreover, unlike any previous work, the LDTC is uniquely equipped with the fully dynamic model expansion and rehearsal-based techniques to effectively learn new tasks and to tackle the dynamic data in the sequential tasks learning without the catastrophic forgetting or degradation of the model accuracy. Experiments on seven real-world multivariate time series datasets show that the LDTC is a promising method for dealing with temporal clustering issues effectively and efficiently.", "AI": {"tldr": "提出了一种新的深度时序聚类算法LDTC，用于解决多变量时间序列的动态变化和持续学习问题。", "motivation": "现有的深度时序聚类方法在处理动态数据方面存在不足，无法有效应对新任务的学习及防止模型性能退化的问题。", "method": "设计了一种结合降维与时序聚类的自编码器，并通过端到端的无监督学习框架优化潜在表示和聚类目标。引入动态模型扩展和基于重放的技术来处理新的任务，避免灾难性遗忘。", "result": "实验表明LDTC在七个真实世界的多变量时间序列数据集上的表现优越，展示了其高效解决时序聚类问题的能力。", "conclusion": "提出的LDTC算法通过集成深度学习与动态模型扩展技术，在持续学习和处理时序变化上提供了有效解决方案。"}}
{"id": "2601.06220", "pdf": "https://arxiv.org/pdf/2601.06220", "abs": "https://arxiv.org/abs/2601.06220", "authors": ["Cheng Yan", "Wuyang Zhang", "Zhiyuan Ning", "Fan Xu", "Ziyang Tao", "Lu Zhang", "Bing Yin", "Yanyong Zhang"], "title": "Breaking Model Lock-in: Cost-Efficient Zero-Shot LLM Routing via a Universal Latent Space", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rapid proliferation of Large Language Models (LLMs) has led to a fragmented and inefficient ecosystem, a state of ``model lock-in'' where seamlessly integrating novel models remains a significant bottleneck. Current routing frameworks require exhaustive, costly retraining, hindering scalability and adaptability. We introduce ZeroRouter, a new paradigm for LLM routing that breaks this lock-in. Our approach is founded on a universal latent space, a model-agnostic representation of query difficulty that fundamentally decouples the characterization of a query from the profiling of a model. This allows for zero-shot onboarding of new models without full-scale retraining. ZeroRouter features a context-aware predictor that maps queries to this universal space and a dual-mode optimizer that balances accuracy, cost, and latency. Our framework consistently outperforms all baselines, delivering higher accuracy at lower cost and latency.", "AI": {"tldr": "提出了一种新的大型语言模型路由框架ZeroRouter，旨在打破现有模型锁定状态，并实现零样本新模型的高效集成。", "motivation": "当前的大型语言模型生态系统存在碎片化和低效问题，使得新型模型无缝整合变得困难。现有的路由框架需要耗费大量时间进行重新训练，阻碍了系统的可扩展性和适应性。", "method": "该方法基于一个通用潜在空间，这种空间能够将查询与模型特性解耦，并通过上下文感知预测器映射查询到此空间，同时利用双模式优化器来平衡准确性、成本和延迟。", "result": "ZeroRouter在所有基准测试中均表现优异，实现了更高的准确率且降低了成本和延时。", "conclusion": "这项研究成功地打破了大型语言模型的锁定状态，并为零样本新模型集成提供了有效的解决方案。"}}
{"id": "2601.06219", "pdf": "https://arxiv.org/pdf/2601.06219", "abs": "https://arxiv.org/abs/2601.06219", "authors": ["Rakesh Keshava", "Sathish Kuppan Pandurangan", "M. Sakthivanitha", "Sankaranainar Parmsivan", "Goutham Sunkara", "R. Maruthi"], "title": "AI-Powered Algorithms for the Prevention and Detection of Computer Malware Infections", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The rise in frequency and complexity of malware attacks are viewed as a major threat to modern digital infrastructure, which means that traditional signature-based detection methods are becoming less effective. As cyber threats continue to evolve, there is a growing need for intelligent systems to accurately and proactively identify and prevent malware infections. This study presents a new hybrid context-aware malware detection framework(HCAMDF) based on artificial intelligence (AI), which combines static file analysis, dynamic behavioural analysis, and contextual metadata to provide more accurate and timely detection. HCADMF has a multi-layer architecture, which consists of lightweight static classifiers such as Long Short Term Memory (LSTM) for real-time behavioral analysis, and an ensemble risk scoring through the integration of multiple layers of prediction. Experimental evaluations of the new/methodology with benchmark datasets, EMBER and CIC-MalMem2022, showed that the new approach provides superior performances with an accuracy of 97.3%, only a 1.5% false positive rate and minimal detection delay compared to several existing machine learning(ML) and deep learning(DL) established methods in the same fields. The results show strong evidence that hybrid AI can detect both existing and novel malware variants, and lay the foundation on intelligent security systems that can enable real-time detection and adapt to a rapidly evolving threat landscape.", "AI": {"tldr": "该论文提出了一种基于人工智能的新型混合上下文感知恶意软件检测框架(HCAMDF)，结合静态文件分析、动态行为分析和上下文元数据，以提高准确性和实时性。", "motivation": "随着恶意软件攻击频率和复杂性的增加，传统的签名检测方法逐渐失效。因此需要智能系统来精准及时地识别和预防恶意软件。", "method": "该框架采用了多层架构，包含轻量级静态分类器（如LSTM）进行实时行为分析，并通过集成多个预测层级实现风险评分的组合。", "result": "实验表明，该方法在EMBER和CIC-MalMem2022等基准数据集上表现出色，准确率高达97.3%，误报率为1.5%，检测延迟也较低。", "conclusion": "研究结果证明了混合AI能够有效识别现有及新型恶意软件变种，并为实时检测和适应快速变化的威胁环境奠定了基础。"}}
{"id": "2601.06218", "pdf": "https://arxiv.org/pdf/2601.06218", "abs": "https://arxiv.org/abs/2601.06218", "authors": ["Kuan Wei Chen", "Ting Yi Lin", "Wen Ren Yang", "Aryan Kesarwani", "Riya Singh"], "title": "Two-step Authentication: Multi-biometric System Using Voice and Facial Recognition", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": "Accepted manuscript (author version, v2). The published version appears in IET Conference Proceedings; see DOI: 10.1049/icp.2024.4141. Code: https://github.com/NCUE-EE-AIAL/Two-step-Authentication-Multi-biometric-System", "summary": "We present a cost-effective two-step authentication system that integrates face identification and speaker verification using only a camera and microphone available on common devices. The pipeline first performs face recognition to identify a candidate user from a small enrolled group, then performs voice recognition only against the matched identity to reduce computation and improve robustness. For face recognition, a pruned VGG-16 based classifier is trained on an augmented dataset of 924 images from five subjects, with faces localized by MTCNN; it achieves 95.1% accuracy. For voice recognition, a CNN speaker-verification model trained on LibriSpeech (train-other-360) attains 98.9% accuracy and 3.456% EER on test-clean. Source code and trained models are available at https://github.com/NCUE-EE-AIAL/Two-step-Authentication-Multi-biometric-System.", "AI": {"tldr": "本文提出了一种使用面部和语音识别的两步身份验证系统，旨在降低成本并提高计算效率与鲁棒性。", "motivation": "为了创建一种成本效益高且易于在常见设备上实现的身份验证方法，论文提出了一个结合了面部识别和语音验证的两步认证系统。", "method": "首先，使用改进的VGG-16分类器进行面部识别，并通过MTCNN定位面部；其次，采用CNN模型进行语音验证。系统先通过面部识别确定候选用户，再对匹配的身份执行语音验证以降低计算量和提高准确性。", "result": "面部识别模型在增强数据集上的准确率达到95.1%；语音验证模型在测试集上获得98.9%的精度和3.456%的等错误率。", "conclusion": "该研究证明了所提出的两步认证系统的有效性和准确性，提供了源代码和训练好的模型以供进一步的研究使用。"}}
{"id": "2601.06217", "pdf": "https://arxiv.org/pdf/2601.06217", "abs": "https://arxiv.org/abs/2601.06217", "authors": ["Nejad Alagha", "Anis Salwa Mohd Khairuddin", "Obada Al-Khatib", "Abigail Copiaco"], "title": "CEEMDAN-Based Multiscale CNN for Wind Turbine Gearbox Fault Detection", "categories": ["cs.LG", "cs.AI"], "comment": "conference paper", "summary": "Wind turbines play a critical role in the shift toward sustainable energy generation. Their operation relies on multiple interconnected components, and a failure in any of these can compromise the entire system's functionality. Detecting faults accurately is challenging due to the intricate, non-linear, and non-stationary nature of vibration signals, influenced by dynamic loading, environmental variations, and mechanical interactions. As such, effective signal processing techniques are essential for extracting meaningful features to enhance diagnostic accuracy. This study presents a hybrid approach for fault detection in wind turbine gearboxes, combining Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) and a Multiscale Convolutional Neural Network (MSCNN). CEEMDAN is employed to decompose vibration signals into intrinsic mode functions, isolating critical features at different time-frequency scales. These are then input into the MSCNN, which performs deep hierarchical feature extraction and classification. The proposed method achieves an F1 Score of 98.95\\%, evaluated on real-world datasets, and demonstrates superior performance in both detection accuracy and computational speed compared to existing approaches. This framework offers a balanced solution for reliable and efficient fault diagnosis in wind turbine systems.", "AI": {"tldr": "提出了一种结合CEEMDAN和MSCNN的混合方法用于风力发电机齿轮箱故障检测", "motivation": "准确检测风力发电机组件故障具有挑战性，因为振动信号复杂且非线性和非平稳。需要有效的信号处理技术来提高诊断准确性", "method": "采用CEEMDAN分解振动信号以提取关键特征，并将其输入MSCNN进行深层次的特征提取和分类", "result": "该方法在真实世界数据集上实现了98.95％的F1得分，比现有方法更优，在检测准确性和计算速度方面都表现出色", "conclusion": "提出的框架为风力发电系统提供了一种可靠高效的故障诊断解决方案"}}
{"id": "2601.06216", "pdf": "https://arxiv.org/pdf/2601.06216", "abs": "https://arxiv.org/abs/2601.06216", "authors": ["Shuang Liu", "Ruijia Zhang", "Ruoyun Ma", "Yujia Deng", "Lanyi Zhu", "Jiayu Li", "Zelong Li", "Zhibin Shen", "Mengnan Du"], "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have precipitated a dramatic improvement in the legal domain, yet the deployment of standalone models faces significant limitations regarding hallucination, outdated information, and verifiability. Recently, LLM agents have attracted significant attention as a solution to these challenges, utilizing advanced capabilities such as planning, memory, and tool usage to meet the rigorous standards of legal practice. In this paper, we present a comprehensive survey of LLM agents for legal tasks, analyzing how these architectures bridge the gap between technical capabilities and domain-specific needs. Our major contributions include: (1) systematically analyzing the technical transition from standard legal LLMs to legal agents; (2) presenting a structured taxonomy of current agent applications across distinct legal practice areas; (3) discussing evaluation methodologies specifically for agentic performance in law; and (4) identifying open challenges and outlining future directions for developing robust and autonomous legal assistants.", "AI": {"tldr": "本文系统分析了大型语言模型在法律领域的代理应用，提出了结构化的分类法，并讨论了评估方法及未来发展方向。", "motivation": "LLM在法律领域表现出显著的改进但独立部署面临幻觉、过时信息和可验证性等限制。为了应对这些挑战，引入了使用高级功能如规划、记忆和工具使用的法律代理模型。", "method": "本文提出了从标准法律LLM到法律代理的技术过渡系统分析；介绍了当前代理在不同法律实践领域中的应用结构化分类法；讨论了专门用于法律代理人性能的评估方法，并指出了开放挑战及未来研究方向。", "result": "该论文概述了技术转换过程、法律代理的应用、评估方法和面临的问题，为未来发展提供了指导框架。", "conclusion": "通过分析和技术过渡的系统性调查，本文强调了发展稳健自主法律助理的重要性，并明确了未来的研发路径。"}}
{"id": "2601.06214", "pdf": "https://arxiv.org/pdf/2601.06214", "abs": "https://arxiv.org/abs/2601.06214", "authors": ["Fang Wu", "Stan Z. Li"], "title": "Dynamics-inspired Structure Hallucination for Protein-protein Interaction Modeling", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": "ef:Transactions on Machine Learning Research 2025", "summary": "Protein-protein interaction (PPI) represents a central challenge within the biology field, and accurately predicting the consequences of mutations in this context is crucial for drug design and protein engineering. Deep learning (DL) has shown promise in forecasting the effects of such mutations, but is hindered by two primary constraints. First, the structures of mutant proteins are often elusive to acquire. Secondly, PPI takes place dynamically, which is rarely integrated into the DL architecture design. To address these obstacles, we present a novel framework named Refine-PPI with two key enhancements. First, we introduce a structure refinement module trained by a mask mutation modeling (MMM) task on available wild-type structures, which is then transferred to produce the inaccessible mutant structures. Second, we employ a new kind of geometric network, called the probability density cloud network (PDC-Net), to capture 3D dynamic variations and encode the atomic uncertainty associated with PPI. Comprehensive experiments on SKEMPI.v2 substantiate the superiority of Refine-PPI over all existing tools for predicting free energy change. These findings underscore the effectiveness of our hallucination strategy and the PDC module in addressing the absence of mutant protein structure and modeling geometric uncertainty.", "AI": {"tldr": "本文提出了一种新的框架Refine-PPI，用于蛋白质相互作用的预测。", "motivation": "准确地预测突变对蛋白质相互作用的影响对于药物设计和蛋白质工程至关重要。但现有深度学习方法受到缺乏突变体结构数据及动态交互过程模拟不足的限制。", "method": "通过引入结构优化模块和概率密度云网络(PDC-Net)来解决上述问题，前者基于野生型结构进行训练并迁移至生成难以获取的突变体结构；后者用于捕捉3D动态变化并编码原子不确定性。", "result": "实验表明Refine-PPI在SKEMPI.v2数据集上表现优异，优于所有现有工具，在预测自由能变化方面具有明显优势。", "conclusion": "本文提出的策略有效解决了缺乏突变体结构及几何不确定性的建模问题。"}}
{"id": "2601.06213", "pdf": "https://arxiv.org/pdf/2601.06213", "abs": "https://arxiv.org/abs/2601.06213", "authors": ["Keerthi Kumar. M", "Swarun Kumar Joginpelly", "Sunil Khemka", "Lakshmi. S R", "Navin Chhibber"], "title": "Cyber Threat Detection and Vulnerability Assessment System using Generative AI and Large Language Model", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SE"], "comment": null, "summary": "Background: Cyber-attacks have evolved rapidly in recent years, many individuals and business owners have been affected by cyber-attacks in various ways. Cyber-attacks include various threats such as ransomware, malware, phishing, and Denial of Service (DoS)-related attacks. Challenges: Traditional models such as Generative Artificial Intelligence (AI) and Security Bidirectional Encoder Representations from Transformers (BERT) were implemented to detect cyber threats. However, the existing Security BERT model has a limited contextual understanding of text data, which has less impact on detecting cyber-attacks. Proposed Methodology: To overcome the above-mentioned challenges, Robustly Optimized Bidirectional Encoder Representations from Transformers Pretraining Approach (RoBERTa) model is proposed which consists of diverse words of vocabulary understanding. Initially, data are extracted from a Packet Capture (PCAP) file and encrypted using Fully Harmonic Encryption (FHE). Subsequently, a Byte-level and Byte Pair Encoding (BBPE) tokenizer was used to generate tokens and help maintain the vocabulary for the encrypted values. Then, these values are applied to the RoBERTa model of the transformer with extensive training. Finally, Softmax is used for the detection and classification of attacks. The proposed RoBERTa model achieved better results than the existing BERT model in terms of accuracy (0.99), recall (0.91), and precision (0.89) respectively.", "AI": {"tldr": "使用生成式AI和大型语言模型来检测网络威胁并评估漏洞", "motivation": "应对快速演变的网络攻击，传统方法如Security BERT在文本上下文理解方面有限，导致检测效果不佳", "method": "采用RoBERTa模型处理PCAP文件提取的数据，并用全谐加密、BBPE分词器和Softmax进行分类，提升威胁检测精度", "result": "相较于现有BERT模型，RoBERTa模型的准确性为0.99，召回率为0.91，精确率为0.89", "conclusion": "新方法在提高网络威胁检测准确性和效率方面表现优异"}}
{"id": "2601.06212", "pdf": "https://arxiv.org/pdf/2601.06212", "abs": "https://arxiv.org/abs/2601.06212", "authors": ["Yani Meziani"], "title": "Akasha 2: Hamiltonian State Space Duality and Visual-Language Joint Embedding Predictive Architectur", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages, 6 figures, 3 tables. Includes appendices with pseudocode and implementation details. Supplementary materials eventually at github.com/yanimeziani/akasha", "summary": "We present Akasha 2, a state-of-the-art multimodal architecture that integrates Hamiltonian State Space Duality (H-SSD) with Visual-Language Joint Embedding Predictive Architecture (VL-JEPA). The system leverages the Mamba-3 Selective State Space Model (SSM) augmented by a Sparse Mixture of Hamiltonian Experts (SMoE-HE) that enforces latent physical conservation laws through symplectic integration. For visual synthesis, we introduce Hamiltonian Flow Matching (HFM) and persistent 3D Gaussian Splatting (3DGS), enabling ultra-low latency (<50ms) on mobile hardware. This work establishes a new paradigm in latent world models, achieving unprecedented spatiotemporal coherence through a holographic memory architecture. Our approach demonstrates that incorporating physics-inspired inductive biases into neural architectures yields significant improvements: state-of-the-art video prediction (FVD: 287), 4x faster visual synthesis than diffusion models, and 3-18x inference speedup over transformer baselines while maintaining energy conservation over extended horizons.", "AI": {"tldr": "本文提出了一种结合汉密尔顿状态空间二象性（H-SSD）和视觉语言联合嵌入预测架构（VL-JEPA）的Akasha 2多模态体系结构。", "motivation": "为了实现更好的视频预测和图像合成，同时保持低延迟和高效的能耗特性，作者设计了结合物理原理诱导偏置的新系统模型。", "method": "该方法利用Mamba-3选择性状态空间模型（SSM）与稀疏汉密尔顿专家混合体（SMoE-HE），通过辛积分强制执行潜在的物理守恒定律。对于视觉合成，引入了汉密尔顿流匹配（HFM）和持久3D高斯点状图法（3DGS）。", "result": "Akasha 2在视频预测上实现了FVD评分287的最佳效果，并且比扩散模型快4倍的图像生成速度以及与Transformer基线相比，推理速度快3-18倍。", "conclusion": "通过将物理启发式的诱导偏置融入神经网络架构中，该方法显著提高了模型性能，在视频预测和图像合成方面取得了重大进展。"}}
{"id": "2601.06209", "pdf": "https://arxiv.org/pdf/2601.06209", "abs": "https://arxiv.org/abs/2601.06209", "authors": ["Julien Combes", "Alexandre Derville", "Jean-François Coeurjolly"], "title": "When Imbalance Comes Twice: Active Learning under Simulated Class Imbalance and Label Shift in Binary Semantic Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "The aim of Active Learning is to select the most informative samples from an unlabelled set of data. This is useful in cases where the amount of data is large and labelling is expensive, such as in machine vision or medical imaging. Two particularities of machine vision are first, that most of the images produced are free of defects, and second, that the amount of images produced is so big that we cannot store all acquired images. This results, on the one hand, in a strong class imbalance in defect distribution and, on the other hand, in a potential label shift caused by limited storage. To understand how these two forms of imbalance affect active learning algorithms, we propose a simulation study based on two open-source datasets. We artificially create datasets for which we control the levels of class imbalance and label shift. Three standard active learning selection strategies are compared: random sampling, entropy-based selection, and core-set selection. We demonstrate that active learning strategies, and in particular the entropy-based and core-set selections, remain interesting and efficient even for highly imbalanced datasets. We also illustrate and measure the loss of efficiency that occurs in the situation a strong label shift.", "AI": {"tldr": "研究通过模拟实验探究了类别不平衡和标签偏移对主动学习算法的影响，并比较了三种标准的样本选择策略的效果。", "motivation": "在大规模数据集且标注成本高的情况下，需要高效地利用有限的标注资源。机器视觉中存在严重的类分布不均和存储限制导致的潜在标签迁移问题。", "method": "使用两个开源的数据集创建人工数据集以控制类别不平衡和标签偏移的程度，比较了随机采样、基于熵的选择和核心集选择三种标准的主动学习策略。", "result": "结果表明，在高度不平衡的数据集中，基于熵和核心集选择方法仍然有效且高效。同时展示了在强标签迁移情况下效率降低的情况。", "conclusion": "研究证明了特定的主动学习策略能够有效地应对类别分布不均的问题，并揭示了标签偏移对算法性能的影响。"}}
{"id": "2601.06204", "pdf": "https://arxiv.org/pdf/2601.06204", "abs": "https://arxiv.org/abs/2601.06204", "authors": ["Tayyab Rehman", "Giovanni De Gasperis", "Aly Shmahell"], "title": "Cascading multi-agent anomaly detection in surveillance systems via vision-language models and embedding-based classification", "categories": ["cs.CV", "cs.MA"], "comment": null, "summary": "Intelligent anomaly detection in dynamic visual environments requires reconciling real-time performance with semantic interpretability. Conventional approaches address only fragments of this challenge. Reconstruction-based models capture low-level deviations without contextual reasoning, object detectors provide speed but limited semantics, and large vision-language systems deliver interpretability at prohibitive computational cost. This work introduces a cascading multi-agent framework that unifies these complementary paradigms into a coherent and interpretable architecture. Early modules perform reconstruction-gated filtering and object-level assessment, while higher-level reasoning agents are selectively invoked to interpret semantically ambiguous events. The system employs adaptive escalation thresholds and a publish-subscribe communication backbone, enabling asynchronous coordination and scalable deployment across heterogeneous hardware. Extensive evaluation on large-scale monitoring data demonstrates that the proposed cascade achieves a threefold reduction in latency compared to direct vision-language inference, while maintaining high perceptual fidelity (PSNR = 38.3 dB, SSIM = 0.965) and consistent semantic labeling. The framework advances beyond conventional detection pipelines by combining early-exit efficiency, adaptive multi-agent reasoning, and explainable anomaly attribution, establishing a reproducible and energy-efficient foundation for scalable intelligent visual monitoring.", "AI": {"tldr": "提出了一种基于视觉语言模型和嵌入式分类的多代理级联异常检测框架，用于动态视觉环境中的智能监控系统。", "motivation": "传统方法在实时性能与语义解释性之间难以平衡，本研究旨在结合重建、物体检测及大型视觉-语言模型的优势，解决这一问题。", "method": "通过早期模块执行重建门控过滤和对象级别评估，并选择性地调用高阶推理代理来解析语义模糊的事件；采用自适应升级阈值与发布订阅通信机制，实现实时协调与异构硬件上的可扩展部署。", "result": "在大规模监控数据上测试后，所提出的级联框架比直接视觉-语言推理延迟减少了三倍，同时保持了高感知保真度（PSNR=38.3dB，SSIM=0.965）和一致的语义标记。", "conclusion": "该框架通过早期退出效率、自适应多代理推理及可解释性异常归因，为大规模智能视觉监控提供了一个可重复且节能的基础。"}}
{"id": "2601.06202", "pdf": "https://arxiv.org/pdf/2601.06202", "abs": "https://arxiv.org/abs/2601.06202", "authors": ["Shiwen Zhang", "Haibin Huang", "Chi Zhang", "Xuelong Li"], "title": "QwenStyle: Content-Preserving Style Transfer with Qwen-Image-Edit", "categories": ["cs.CV"], "comment": "The codes and models are released at https://github.com/witcherofresearch/Qwen-Image-Style-Transfer", "summary": "Content-Preserving Style transfer, given content and style references, remains challenging for Diffusion Transformers (DiTs) due to its internal entangled content and style features. In this technical report, we propose the first content-preserving style transfer model trained on Qwen-Image-Edit, which activates Qwen-Image-Edit's strong content preservation and style customization capability. We collected and filtered high quality data of limited specific styles and synthesized triplets with thousands categories of style images in-the-wild. We introduce the Curriculum Continual Learning framework to train QwenStyle with such mixture of clean and noisy triplets, which enables QwenStyle to generalize to unseen styles without degradation of the precise content preservation capability. Our QwenStyle V1 achieves state-of-the-art performance in three core metrics: style similarity, content consistency, and aesthetic quality.", "AI": {"tldr": "该论文提出了一种基于Qwen-Image-Edit的内容保持风格转换模型，旨在解决扩散变压器在内容和风格特征内部纠缠导致的挑战。", "motivation": "现有的Diffusion Transformers（DiTs）难以实现高质量的内容保持风格转移，因为其内部特征存在内容与风格之间的混杂。为了解决这个问题，作者提出了QwenStyle，以激活Qwen-Image-Edit的强内容保存和样式定制能力。", "method": "论文通过收集并过滤高质量的特定风格数据，并合成包含数千种风格图像的三重数据集来训练模型。引入了Curriculum Continual Learning框架来训练QwenStyle，使其能够在未见的风格上泛化，同时保持精确的内容保存能力。", "result": "QwenStyle V1在三个核心指标（风格相似度、内容一致性和美学质量）方面达到了最先进的性能。", "conclusion": "通过使用Qwen-Image-Edit和Curriculum Continual Learning框架，作者成功开发了QwenStyle，该模型能够实现高质量的内容保持风格转换，并且能够在未见过的风格上表现出色。"}}
{"id": "2601.06201", "pdf": "https://arxiv.org/pdf/2601.06201", "abs": "https://arxiv.org/abs/2601.06201", "authors": ["Yelena Mujibur Sheikh", "Awez Akhtar Khatik", "Luoxi Tang", "Yuqiao Meng", "Zhaohan Xi"], "title": "RiskBridge: Turning CVEs into Business-Aligned Patch Priorities", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Enterprises are confronted with an unprece- dented escalation in cybersecurity vulnerabil- ities, with thousands of new CVEs disclosed each month. Conventional prioritization frame- works such as CVSS offer static severity met- rics that fail to account for exploit probabil- ity, compliance urgency, and operational im- pact, resulting in inefficient and delayed re- mediation. This paper introduces RiskBridge, an explainable and compliance-aware vulner- ability management framework that integrates multi-source intelligence from CVSS v4, EPSS, and CISA KEV to produce dynamic, business- aligned patch priorities. RiskBridge employs a probabilistic Zero-Day Exposure Simulation (ZDES) model to fore- cast near-term exploit likelihood, a Policy-as- Code Engine to translate regulatory mandates (e.g., PCI DSS, NIST SP 800-53) into auto- mated SLA logic, and an ROI-driven Opti- mizer to maximize cumulative risk reduction per remediation effort. Experimental evalua- tions using live CVE datasets demonstrate an 88% reduction in residual risk, an 18-day improvement in SLA compliance, and a 35% increase in remediation efficiency compared to state-of-the-art commercial baselines. These findings validate RiskBridge as a prac- tical and auditable decision-intelligence sys- tem that unifies probabilistic modeling, com- pliance reasoning, and optimization analytics. The framework represents a step toward auto- mated, explainable, and business-centric vul- nerability management in modern enterprise environments", "AI": {"tldr": "RiskBridge是一种将CVE转化为业务相关的补丁优先级的框架。", "motivation": "企业面临前所未有的网络安全漏洞激增，每月都有数千个新的CVE披露。传统的优先级框架如CVSS只能提供静态严重性指标，并不考虑利用概率、合规紧迫性和操作影响，导致效率低下和修复延迟。", "method": "RiskBridge采用多源情报整合（CVSS v4, EPSS, CISA KEV）生成动态的业务相关补丁优先级。该框架包括一个预测近期漏洞利用可能的概率零日暴露模拟模型、将监管要求转化为自动化SLA逻辑的Policy-as-Code引擎以及优化累积风险减少与修复努力效率的关系驱动的ROI优化器。", "result": "实验结果表明，相较于最先进的商业基线，RiskBridge实现了88%的风险剩余降低率，18天的合规改善和35％的补丁效率提升。", "conclusion": "RiskBridge验证为一个实用且可审计的决策智能系统，它将概率建模、合规性推理和优化分析相结合，在现代企业环境中实现自动化、解释性和业务导向的安全管理。"}}
{"id": "2601.06200", "pdf": "https://arxiv.org/pdf/2601.06200", "abs": "https://arxiv.org/abs/2601.06200", "authors": ["Anh-Kiet Duong", "Petra Gomez-Krämer", "Hoàng-Ân Lê", "Minh-Tan Pham"], "title": "Leveraging Membership Inference Attacks for Privacy Measurement in Federated Learning for Remote Sensing Images", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": "5 pages", "summary": "Federated Learning (FL) enables collaborative model training while keeping training data localized, allowing us to preserve privacy in various domains including remote sensing. However, recent studies show that FL models may still leak sensitive information through their outputs, motivating the need for rigorous privacy evaluation. In this paper, we leverage membership inference attacks (MIA) as a quantitative privacy measurement framework for FL applied to remote sensing image classification. We evaluate multiple black-box MIA techniques, including entropy-based attacks, modified entropy attacks, and the likelihood ratio attack, across different FL algorithms and communication strategies. Experiments conducted on two public scene classification datasets demonstrate that MIA effectively reveals privacy leakage not captured by accuracy alone. Our results show that communication-efficient FL strategies reduce MIA success rates while maintaining competitive performance. These findings confirm MIA as a practical metric and highlight the importance of integrating privacy measurement into FL system design for remote sensing applications.", "AI": {"tldr": "本文利用成员推断攻击（MIA）作为度量联邦学习中隐私泄漏的框架，特别是在遥感图像分类领域。", "motivation": "联邦学习虽然保护了数据本地化，但其模型输出可能泄露敏感信息。因此需要严格的隐私评估来确保安全性。", "method": "本文评估了几种黑盒MIA技术，包括基于熵、修改后的熵和似然比攻击方法，并在多个FL算法和通信策略下进行实验。", "result": "实验结果表明，有效的成员推断攻击能够揭示出仅靠准确率无法捕捉的隐私泄漏情况。同时发现通信效率高的联邦学习策略可以降低MIA的成功率。", "conclusion": "研究证明了MIA作为一种实用指标的重要性，并强调将隐私度量集成到远程传感应用中的联邦学习系统设计中是必要的。"}}
{"id": "2601.06199", "pdf": "https://arxiv.org/pdf/2601.06199", "abs": "https://arxiv.org/abs/2601.06199", "authors": ["Junseok Lee", "Sangyong Lee", "Chang-Jae Chun"], "title": "FastSLM: Hierarchical Frame Q-Former for Effective Speech Modality Adaptation", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": null, "summary": "Recent advances in large language models (LLMs) have demonstrated human-expert-level capabilities, driving significant interest in their potential for achieving artificial general intelligence (AGI). In particular, there is growing momentum in adapting LLMs to various modalities, including vision, video, and speech, through the development of multimodal LLMs (MLLMs). However, existing speech-language model (SLM) research has largely overlooked cost-effective adaptation strategies for leveraging LLMs in the speech domain. In this paper, we propose FastSLM, a lightweight yet efficient SLM designed for effective understanding and reasoning over long-form speech. To address the challenge of aligning high-frame-rate speech features with LLMs, we introduce the Hierarchical Frame Querying Transformer (HFQ-Former), which compresses frame-level speech features while capturing both local and global context. Furthermore, we present a novel three-stage training strategy that enhances generalization across a wide range of speech-related tasks. Experimental results demonstrate that FastSLM achieves competitive performance compared to existing state-of-the-art models, despite operating with significantly lower FLOPs and parameter counts, while representing speech with only 1.67 tokens per second. The source code and model checkpoints are available at https://huggingface.co/okestro-ai-lab/FastSLM.", "AI": {"tldr": "提出了一种轻量级且高效的FastSLM模型，用于长形式语音的理解和推理。", "motivation": "现有研究在将大型语言模型应用于语音领域时忽视了成本效益高的适应策略，因此开发一种适用于语音领域的高效模型变得迫切需要。", "method": "提出了HFQ-Former，通过压缩帧级语音特征并捕捉局部和全局上下文来解决高帧率的语音特征与LLM对齐的问题，并引入了一个三阶段训练策略以增强跨多种任务的泛化能力。", "result": "实验结果表明，尽管FastSLM的操作FLOPs和参数数量较低，但其性能仍可与其他最先进的模型相媲美。此外，它每秒仅用1.67个令牌表示语音。", "conclusion": "通过引入HFQ-Former和三阶段训练策略，FastSLM实现了在低计算成本下对长形式语音的有效理解和推理。"}}
{"id": "2601.06198", "pdf": "https://arxiv.org/pdf/2601.06198", "abs": "https://arxiv.org/abs/2601.06198", "authors": ["Shubham Goel", "Farzana S", "C V Rishi", "Aditya Arun", "C V Jawahar"], "title": "How Does India Cook Biryani?", "categories": ["cs.CV"], "comment": null, "summary": "Biryani, one of India's most celebrated dishes, exhibits remarkable regional diversity in its preparation, ingredients, and presentation. With the growing availability of online cooking videos, there is unprecedented potential to study such culinary variations using computational tools systematically. However, existing video understanding methods fail to capture the fine-grained, multimodal, and culturally grounded differences in procedural cooking videos. This work presents the first large-scale, curated dataset of biryani preparation videos, comprising 120 high-quality YouTube recordings across 12 distinct regional styles. We propose a multi-stage framework leveraging recent advances in vision-language models (VLMs) to segment videos into fine-grained procedural units and align them with audio transcripts and canonical recipe text. Building on these aligned representations, we introduce a video comparison pipeline that automatically identifies and explains procedural differences between regional variants. We construct a comprehensive question-answer (QA) benchmark spanning multiple reasoning levels to evaluate procedural understanding in VLMs. Our approach employs multiple VLMs in complementary roles, incorporates human-in-the-loop verification for high-precision tasks, and benchmarks several state-of-the-art models under zero-shot and fine-tuned settings. The resulting dataset, comparison methodology, and QA benchmark provide a new testbed for evaluating VLMs on structured, multimodal reasoning tasks and open new directions for computational analysis of cultural heritage through cooking videos. We release all data, code, and the project website at https://farzanashaju.github.io/how-does-india-cook-biryani/.", "AI": {"tldr": "本文提出了一个大规模的印度香料饭烹饪视频数据集，并开发了一个多阶段框架，利用视觉语言模型（VLM）将这些视频分割成细粒度的过程单元，并与音频脚本和标准菜谱文本对齐。", "motivation": "研究了印度香料饭在不同地区的多样性以及现有视频理解方法无法捕捉到的细微差别。通过开发一个大规模的数据集，来系统地分析烹饪视频中的文化差异。", "method": "提出了一种多阶段框架，该框架利用视觉语言模型将烹饪过程分割成细粒度的过程单元，并与音频脚本和菜谱文本对齐。构建了一个问答基准测试以评估VLM在多层次推理上的性能。", "result": "开发的数据集、比较方法和问答基准测试为评估VLM的结构化多模态推理任务提供了新的测试平台，同时开放了通过烹饪视频分析文化遗产的新方向。", "conclusion": "该研究提出了一个大规模的印度香料饭烹饪视频数据集，并展示了利用视觉语言模型进行细粒度过程单元分割和对齐的技术。这些贡献为理解文化多样性提供了一个新框架，并推动了多模态推理的研究。"}}
{"id": "2601.06197", "pdf": "https://arxiv.org/pdf/2601.06197", "abs": "https://arxiv.org/abs/2601.06197", "authors": ["Prasanna Kumar"], "title": "AI Safeguards, Generative AI and the Pandora Box: AI Safety Measures to Protect Businesses and Personal Reputation", "categories": ["cs.AI", "cs.CR"], "comment": "10 pages, 3 Figures, 6 Tables", "summary": "Generative AI has unleashed the power of content generation and it has also unwittingly opened the pandora box of realistic deepfake causing a number of social hazards and harm to businesses and personal reputation. The investigation & ramification of Generative AI technology across industries, the resolution & hybridization detection techniques using neural networks allows flagging of the content. Good detection techniques & flagging allow AI safety - this is the main focus of this paper. The research provides a significant method for efficiently detecting dark side problems by imposing a Temporal Consistency Learning (TCL) technique. Through pretrained Temporal Convolutional Networks (TCNs) model training and performance comparison, this paper showcases that TCN models outperforms the other approaches and achieves significant accuracy for five dark side problems. Findings highlight how important it is to take proactive measures in identification to reduce any potential risks associated with generative artificial intelligence.", "AI": {"tldr": "研究提出了一种基于时间一致性学习（Temporal Consistency Learning，TCL）的方法，用于检测生成式人工智能带来的五种潜在风险问题。", "motivation": "由于生成式AI技术的发展带来了内容生成能力的同时，也无意中引发了深度伪造等社会危害和对企业和个人声誉的威胁。", "method": "通过使用预训练的时间卷积网络（Temporal Convolutional Networks，TCNs）模型进行训练，并与其他方法相比，以提高检测准确性。", "result": "实验结果显示，基于TCL的技术在五种潜在风险问题上的识别精度显著优于其他方法。", "conclusion": "研究强调了采取主动措施来减少与生成式人工智能相关的潜在风险的重要性。"}}
{"id": "2601.06196", "pdf": "https://arxiv.org/pdf/2601.06196", "abs": "https://arxiv.org/abs/2601.06196", "authors": ["Bodla Krishna Vamshi", "Rohan Bhatnagar", "Haizhao Yang"], "title": "Manifold-based Sampling for In-Context Hallucination Detection in Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) frequently generate factually incorrect or unsupported content, commonly referred to as hallucinations. Prior work has explored decoding strategies, retrieval augmentation, and supervised fine-tuning for hallucination detection, while recent studies show that in-context learning (ICL) can substantially influence factual reliability. However, existing ICL demonstration selection methods often rely on surface-level similarity heuristics and exhibit limited robustness across tasks and models. We propose MB-ICL, a manifold-based demonstration sampling framework for selecting in-context demonstrations that leverages latent representations extracted from frozen LLMs. By jointly modeling local manifold structure and class-aware prototype geometry, MB-ICL selects demonstrations based on their proximity to learned prototypes rather than lexical or embedding similarity alone. Across factual verification (FEVER) and hallucination detection (HaluEval) benchmarks, MB-ICL outperforms standard ICL selection baselines in the majority of evaluated settings, with particularly strong gains on dialogue and summarization tasks. The method remains robust under temperature perturbations and model variation, indicating improved stability compared to heuristic retrieval strategies. While lexical retrieval can remain competitive in certain question-answering regimes, our results demonstrate that manifold-based prototype selection provides a reliable and training light approach for hallucination detection without modifying LLM parameters, offering a principled direction for improved ICL demonstration selection.", "AI": {"tldr": "本文提出了MB-ICL，一种基于流形的采样框架，用于选择上下文示例以检测大型语言模型中的幻觉。", "motivation": "现有方法通常依赖于表面相似性启发式来选择上下文示例，并在任务和模型之间表现有限。因此，研究旨在提出一种更可靠的方法。", "method": "MB-ICL通过联合建模局部流形结构和类感知原型几何体，基于学到的原型与候选样本的接近度而非仅依赖词汇或嵌入相似性来选择上下文示例。", "result": "在FEVER和HaluEval基准测试中，MB-ICL优于标准基线。特别是在对话和摘要任务上表现出更强的效果，并且对温度变化和模型差异具有鲁棒性。", "conclusion": "相较于启发式检索策略，基于流形的原型选择提供了一种可靠的轻量级方法来检测幻觉，而无需修改大型语言模型参数。"}}
{"id": "2601.06195", "pdf": "https://arxiv.org/pdf/2601.06195", "abs": "https://arxiv.org/abs/2601.06195", "authors": ["Wei Li", "Wei Zhang", "Qingyu Yan"], "title": "EntroLnn: Entropy-Guided Liquid Neural Networks for Operando Refinement of Battery Capacity Fade Trajectories", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 4 figures", "summary": "Battery capacity degradation prediction has long been a central topic in battery health analytics, and most studies focus on state of health (SoH) estimation and end of life (EoL) prediction. This study extends the scope to online refinement of the entire capacity fade trajectory (CFT) through EntroLnn, a framework based on entropy-guided transformable liquid neural networks (LNNs). EntroLnn treats CFT refinement as an integrated process rather than two independent tasks for pointwise SoH and EoL. We introduce entropy-based features derived from online temperature fields, applied for the first time in battery analytics, and combine them with customized LNNs that model temporal battery dynamics effectively. The framework enhances both static and dynamic adaptability of LNNs and achieves robust and generalizable CFT refinement across different batteries and operating conditions. The approach provides a high fidelity battery health model with lightweight computation, achieving mean absolute errors of only 0.004577 for CFT and 18 cycles for EoL prediction. This work establishes a foundation for entropy-informed learning in battery analytics and enables self-adaptive, lightweight, and interpretable battery health prediction in practical battery management systems.", "AI": {"tldr": "通过基于熵导向的可变形液态神经网络（LNN）框架EntroLnn实现电池容量衰减轨迹（CFT）的在线优化。", "motivation": "传统研究主要关注状态健康评估和寿命预测，而该论文扩展了目标范围到整个CFT的实时精炼。使用熵导向的方法结合定制化的液态神经网络来更有效地建模电池动态。", "method": "引入基于温度场的熵特征，并首次应用于电池分析中；利用熵引导可变形液态神经网络模型化时间依赖性的电池行为，实现对电池健康状态和寿命预测的一体化处理。", "result": "实现了CFT精炼在不同电池及操作条件下均具有鲁棒性和泛化性，平均绝对误差仅为0.004577，寿命预测的误差为18个循环。", "conclusion": "该工作奠定了熵导向学习在电池分析中的基础，并使自适应、轻量级和可解释性的电池健康预测成为可能，在实际电池管理系统中具有应用前景。"}}
{"id": "2601.06194", "pdf": "https://arxiv.org/pdf/2601.06194", "abs": "https://arxiv.org/abs/2601.06194", "authors": ["Adib Sakhawat", "Tahsin Islam", "Takia Farhin", "Syed Rifat Raiyan", "Hasan Mahmud", "Md Kamrul Hasan"], "title": "Political Alignment in Large Language Models: A Multidimensional Audit of Psychometric Identity and Behavioral Bias", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "Under review, 16 pages, 3 figures, 16 tables", "summary": "As large language models (LLMs) are increasingly integrated into social decision-making, understanding their political positioning and alignment behavior is critical for safety and fairness. This study presents a sociotechnical audit of 26 prominent LLMs, triangulating their positions across three psychometric inventories (Political Compass, SapplyValues, 8 Values) and evaluating their performance on a large-scale news labeling task ($N \\approx 27{,}000$). Our results reveal a strong clustering of models in the Libertarian-Left region of the ideological space, encompassing 96.3% of the cohort. Alignment signals appear to be consistent architectural traits rather than stochastic noise ($η^2 > 0.90$); however, we identify substantial discrepancies in measurement validity. In particular, the Political Compass exhibits a strong negative correlation with cultural progressivism ($r=-0.64$) when compared against multi-axial instruments, suggesting a conflation of social conservatism with authoritarianism in this context. We further observe a significant divergence between open-weights and closed-source models, with the latter displaying markedly higher cultural progressivism scores ($p<10^{-25}$). In downstream media analysis, models exhibit a systematic \"center-shift,\" frequently categorizing neutral articles as left-leaning, alongside an asymmetric detection capability in which \"Far Left\" content is identified with greater accuracy (19.2%) than \"Far Right\" content (2.0%). These findings suggest that single-axis evaluations are insufficient and that multidimensional auditing frameworks are necessary to characterize alignment behavior in deployed LLMs. Our code and data will be made public.", "AI": {"tldr": "该论文通过对26个大型语言模型进行多维度审查，评估它们的政治定位和行为偏见。", "motivation": "随着大型语言模型在社会决策中的广泛应用，理解其政治倾向和行为一致性对于保障安全与公平至关重要。", "method": "研究采用了三种心理测量量表（政治罗盘、SapplyValues、8 Values）对26个模型进行审查，并通过大规模新闻标签任务评估它们的表现。", "result": "结果显示大部分模型集中在自由派-左翼区域，一致性信号是架构固有的而非随机噪音。Political Compass存在与多轴工具不同的测量偏差，开放权重和封闭源模型在文化进步主义评分上差异显著。媒体分析显示系统性的“中心偏移”，模型倾向于将中立文章归类为左倾。", "conclusion": "单轴评估不足以表征大型语言模型的行为一致性，需要使用多维度框架进行审查。"}}
{"id": "2601.06193", "pdf": "https://arxiv.org/pdf/2601.06193", "abs": "https://arxiv.org/abs/2601.06193", "authors": ["Qing He", "Dongsheng Bi", "Jianrong Lu", "Minghui Yang", "Zixiao Chen", "Jiacheng Lu", "Jing Chen", "Nannan Du", "Xiao Cu", "Sijing Wu", "Peng Xiang", "Yinyin Hu", "Yi Guo", "Chunpu Li", "Shaoyang Li", "Zhuo Dong", "Ming Jiang", "Shuai Guo", "Liyun Feng", "Jin Peng", "Jian Wang", "Jinjie Gu", "Junwei Liu"], "title": "MLB: A Scenario-Driven Benchmark for Evaluating Large Language Models in Clinical Applications", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "11 pages, 4 figures, 5 tables", "summary": "The proliferation of Large Language Models (LLMs) presents transformative potential for healthcare, yet practical deployment is hindered by the absence of frameworks that assess real-world clinical utility. Existing benchmarks test static knowledge, failing to capture the dynamic, application-oriented capabilities required in clinical practice. To bridge this gap, we introduce a Medical LLM Benchmark MLB, a comprehensive benchmark evaluating LLMs on both foundational knowledge and scenario-based reasoning. MLB is structured around five core dimensions: Medical Knowledge (MedKQA), Safety and Ethics (MedSE), Medical Record Understanding (MedRU), Smart Services (SmartServ), and Smart Healthcare (SmartCare). The benchmark integrates 22 datasets (17 newly curated) from diverse Chinese clinical sources, covering 64 clinical specialties. Its design features a rigorous curation pipeline involving 300 licensed physicians. Besides, we provide a scalable evaluation methodology, centered on a specialized judge model trained via Supervised Fine-Tuning (SFT) on expert annotations. Our comprehensive evaluation of 10 leading models reveals a critical translational gap: while the top-ranked model, Kimi-K2-Instruct (77.3% accuracy overall), excels in structured tasks like information extraction (87.8% accuracy in MedRU), performance plummets in patient-facing scenarios (61.3% in SmartServ). Moreover, the exceptional safety score (90.6% in MedSE) of the much smaller Baichuan-M2-32B highlights that targeted training is equally critical. Our specialized judge model, trained via SFT on a 19k expert-annotated medical dataset, achieves 92.1% accuracy, an F1-score of 94.37%, and a Cohen's Kappa of 81.3% for human-AI consistency, validating a reproducible and expert-aligned evaluation protocol. MLB thus provides a rigorous framework to guide the development of clinically viable LLMs.", "AI": {"tldr": "MLB是一个评估大型语言模型在临床应用中的实用性的基准，涵盖了医学知识、安全伦理、病历理解、智能服务和智能医疗等五个核心维度。", "motivation": "现有的评估框架未能充分捕捉到大型语言模型在动态的、应用场景所需的技能，因此本研究旨在填补这一空白。", "method": "MLB整合了22个数据集（其中17个是新编），并围绕医学知识、安全伦理、病历理解等五个核心维度设计了一套严格的评估框架。此外还提供了一个专门用于评估的判别模型，通过监督微调训练得到。", "result": "综合评测结果表明，虽然某些顶级模型在结构化任务中的表现较好（如信息抽取准确率为87.8%），但在面对患者场景时的表现大幅下降（智能服务准确率仅为61.3%）。此外，专门的判别模型通过专家注释数据集训练后达到了92.1％的准确性。", "conclusion": "MLB提供了一个严格的框架来指导临床适用的大规模语言模型的发展。"}}
{"id": "2601.06191", "pdf": "https://arxiv.org/pdf/2601.06191", "abs": "https://arxiv.org/abs/2601.06191", "authors": ["Wei Ai", "Yun Peng", "Yuntao Shou", "Tao Meng", "Keqin Li"], "title": "TimeGNN-Augmented Hybrid-Action MARL for Fine-Grained Task Partitioning and Energy-Aware Offloading in MEC", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "With the rapid growth of IoT devices and latency-sensitive applications, the demand for both real-time and energy-efficient computing has surged, placing significant pressure on traditional cloud computing architectures. Mobile edge computing (MEC), an emerging paradigm, effectively alleviates the load on cloud centers and improves service quality by offloading computing tasks to edge servers closer to end users. However, the limited computing resources, non-continuous power provisioning (e.g., battery-powered nodes), and highly dynamic systems of edge servers complicate efficient task scheduling and resource allocation. To address these challenges, this paper proposes a multi-agent deep reinforcement learning algorithm, TG-DCMADDPG, and constructs a collaborative computing framework for multiple edge servers, aiming to achieve joint optimization of fine-grained task partitioning and offloading. This approach incorporates a temporal graph neural network (TimeGNN) to model and predict time series of multi-dimensional server state information, thereby reducing the frequency of online interactions and improving policy predictability. Furthermore, a multi-agent deterministic policy gradient algorithm (DC-MADDPG) in a discrete-continuous hybrid action space is introduced to collaboratively optimize task partitioning ratios, transmission power, and priority scheduling strategies. Extensive simulation experiments confirm that TG-DCMADDPG achieves markedly faster policy convergence, superior energy-latency optimization, and higher task completion rates compared with existing state-of-the-art methods, underscoring its robust scalability and practical effectiveness in dynamic and constrained MEC scenarios.", "AI": {"tldr": "提出了一种基于时间图神经网络（TimeGNN）和多智能体确定性策略梯度算法（DC-MADDPG）的新型任务划分和卸载优化方法，以解决边缘计算中的资源分配问题。", "motivation": "随着物联网设备的增长以及延迟敏感应用的需求增加，传统云计算架构难以满足实时性和能耗效率的要求。移动边缘计算通过将计算任务卸载到更接近用户的边缘服务器来减轻云中心的负载并提高服务质量，但面临着有限的计算资源、不连续供电和高度动态系统的问题。", "method": "提出了一种基于多智能体深度强化学习算法（TG-DCMADDPG）的合作计算框架，该方法结合了时间图神经网络用于建模和预测服务器状态信息的时间序列数据，并引入了一个离散-连续混合行动空间的确定性策略梯度算法来优化任务划分、传输功率和优先调度策略。", "result": "TG-DCMADDPG在广泛的模拟实验中表现出显著更快的政策收敛速度，更优的能量延迟优化以及更高的任务完成率。与现有的最先进方法相比，该方法显示出更强的可扩展性和实际有效性。", "conclusion": "提出的多智能体深度强化学习算法TG-DCMADDPG和其基于时间图神经网络的合作计算框架在解决边缘服务器中的细粒度任务划分和卸载优化问题方面表现出优越性能。"}}
{"id": "2601.06189", "pdf": "https://arxiv.org/pdf/2601.06189", "abs": "https://arxiv.org/abs/2601.06189", "authors": ["Atharv Naphade"], "title": "Rational Synthesizers or Heuristic Followers? Analyzing LLMs in RAG-based Question-Answering", "categories": ["cs.AI", "cs.LG"], "comment": "13 pages, 9 figures, ACL ARR submission", "summary": "Retrieval-Augmented Generation (RAG) is the prevailing paradigm for grounding Large Language Models (LLMs), yet the mechanisms governing how models integrate groups of conflicting retrieved evidence remain opaque. Does an LLM answer a certain way because the evidence is factually strong, because of a prior belief, or merely because it is repeated frequently? To answer this, we introduce GroupQA, a curated dataset of 1,635 controversial questions paired with 15,058 diversely-sourced evidence documents, annotated for stance and qualitative strength. Through controlled experiments, we characterize group-level evidence aggregation dynamics: Paraphrasing an argument can be more persuasive than providing distinct independent support; Models favor evidence presented first rather than last, and Larger models are increasingly resistant to adapt to presented evidence. Additionally, we find that LLM explanations to group-based answers are unfaithful. Together, we show that LLMs behave consistently as vulnerable heuristic followers, with direct implications for improving RAG system design.", "AI": {"tldr": "本文介绍了GroupQA数据集，用于分析大型语言模型在基于检索增强生成的问答系统中处理冲突证据的方式。", "motivation": "了解大型语言模型如何整合多组冲突的检索证据，并确定这些决策是基于事实强度、先前信念还是重复出现频率。", "method": "通过引入GroupQA数据集和控制实验，研究了模型对群体证据集成动态的行为模式。", "result": "发现模型倾向于优先考虑最先提出的证据；大模型对于新证据更为顽固；LLM解释通常是不忠实的。", "conclusion": "研究表明，大型语言模型在处理多组冲突证据时表现出脆弱的启发式追随行为。"}}
{"id": "2601.06188", "pdf": "https://arxiv.org/pdf/2601.06188", "abs": "https://arxiv.org/abs/2601.06188", "authors": ["Itai Zilberstein", "Steve Chien"], "title": "Large-Scale Continual Scheduling and Execution for Dynamic Distributed Satellite Constellation Observation Allocation", "categories": ["cs.AI"], "comment": null, "summary": "The size and capabilities of Earth-observing satellite constellations are rapidly increasing. Leveraging distributed onboard control, we can enable novel time-sensitive measurements and responses. However, deploying autonomy to satellites requires efficient computation and communication. This work tackles the challenge of efficiently scheduling observations for hundreds of satellites in a dynamic, large-scale problem with millions of variables. We present the Dynamic Multi-Satellite Constellation Observation Scheduling Problem (DCOSP), a new formulation of Dynamic Distributed Constraint Optimization Problems (DDCOP) that models integrated scheduling and execution. DCOSP has a novel optimality condition for which we construct an omniscient offline algorithm for its computation. We also present the Dynamic Incremental Neighborhood Stochastic Search algorithm (D-NSS), an incomplete online decomposition-based DDCOP algorithm that repairs and solves sub-problems when problem dynamics occur. We show through simulation that D-NSS converges to near-optimal solutions and outperforms DDCOP baselines in terms of solution quality, computation time, and message volume. As part of the NASA FAME mission, DCOSP and D-NSS will be the foundation of the largest in-space demonstration of distributed multi-agent AI to date.", "AI": {"tldr": "该论文提出了动态多卫星星座观测调度问题（DCOSP）和动态增量邻域随机搜索算法（D-NSS），用于大规模连续的卫星观测任务分配。", "motivation": "随着地球观测卫星数量和功能的迅速增加，需要高效的计算和通信以部署自主性。解决数百颗卫星的动态、大规模问题中的有效调度是关键挑战。", "method": "提出了DCOSP作为新的动态分布式约束优化问题（DDCOP）模型，并构造了一个全知离线算法来求解其最优性条件。还提出了D-NSS，一种基于分解的不完整在线DDCOP算法，在出现问题变化时修复和解决子问题。", "result": "通过仿真显示了D-NSS能够收敛于接近最优解，并在解决方案质量、计算时间以及消息量上优于基线DDCOP方法。", "conclusion": "DCOSP和D-NSS将成为NASA FAME任务基础，成为迄今为止最大的分布式多代理AI在轨演示。"}}
{"id": "2601.06187", "pdf": "https://arxiv.org/pdf/2601.06187", "abs": "https://arxiv.org/abs/2601.06187", "authors": ["Nishan Rai", "Pushpa R. Dahal"], "title": "A Unified Attention U-Net Framework for Cross-Modality Tumor Segmentation in MRI and CT", "categories": ["cs.CV"], "comment": "11 pages, 5 figures", "summary": "This study presents a unified Attention U-Net architecture trained jointly on MRI (BraTS 2021) and CT (LIDC-IDRI) datasets to investigate the generalizability of a single model across diverse imaging modalities and anatomical sites. Our proposed pipeline incorporates modality-harmonized preprocessing, attention-gated skip connections, and a modality-aware Focal Tversky loss function. To the best of our knowledge, this study is among the first to evaluate a single Attention U-Net trained simultaneously on separate MRI (BraTS) and CT (LIDC-IDRI) tumor datasets, without relying on modality-specific encoders or domain adaptation. The unified model demonstrates competitive performance in terms of Dice coefficient, IoU, and AUC on both domains, thereby establishing a robust and reproducible baseline for future research in cross-modality tumor segmentation.", "AI": {"tldr": "提出了一种统一的注意力U-Net架构，用于MRI和CT肿瘤分割任务", "motivation": "研究单一模型在不同成像模式和解剖位置上的泛化能力，无需特定于模态的编码器或领域适应方法", "method": "采用模态协调预处理、注意门控跳跃连接及模态感知Focal Tversky损失函数", "result": "统一模型在Dice系数、IoU和AUC上展示了跨模态肿瘤分割的竞争性能", "conclusion": "建立了一个稳健且可重复的基础，为未来的研究提供了参考"}}
{"id": "2601.06185", "pdf": "https://arxiv.org/pdf/2601.06185", "abs": "https://arxiv.org/abs/2601.06185", "authors": ["Pradeep Kumar Sharma", "Shantanu Godbole", "Sarada Prasad Jena", "Hritvik Shrivastava"], "title": "Attention Mechanism and Heuristic Approach: Context-Aware File Ranking Using Multi-Head Self-Attention", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "The identification and ranking of impacted files within software reposi-tories is a key challenge in change impact analysis. Existing deterministic approaches that combine heuristic signals, semantic similarity measures, and graph-based centrality metrics have demonstrated effectiveness in nar-rowing candidate search spaces, yet their recall plateaus. This limitation stems from the treatment of features as linearly independent contributors, ignoring contextual dependencies and relationships between metrics that characterize expert reasoning patterns. To address this limitation, we propose the application of Multi-Head Self-Attention as a post-deterministic scoring refinement mechanism. Our approach learns contextual weighting between features, dynamically adjust-ing importance levels per file based on relational behavior exhibited across candidate file sets. The attention mechanism produces context-aware adjustments that are additively combined with deterministic scores, pre-serving interpretability while enabling reasoning similar to that performed by experts when reviewing change surfaces. We focus on recall rather than precision, as false negatives (missing impacted files) are far more costly than false positives (irrelevant files that can be quickly dismissed during review). Empirical evaluation on 200 test cases demonstrates that the introduc-tion of self-attention improves Top-50 recall from approximately 62-65% to between 78-82% depending on repository complexity and structure, achiev-ing 80% recall at Top-50 files. Expert validation yields improvement from 6.5/10 to 8.6/10 in subjective accuracy alignment. This transformation bridges the reasoning capability gap between deterministic automation and expert judgment, improving recall in repository-aware effort estimation.", "AI": {"tldr": "论文提出了一种结合多头自注意力机制的文件排序方法，用于软件仓库中的变更影响分析。", "motivation": "现有确定性方法在处理特征间依赖关系时存在局限，难以实现专家级的表现。为克服这一限制，引入了自注意力机制以提升召回率。", "method": "利用多头自注意力机制对候选文件进行排序，通过上下文信息调整每个文件的重要性权重，并将其与确定性评分结合，从而改进文件排名效果。", "result": "实验证明，在200个测试案例中，引入多头自注意力后Top-50的召回率从62-65%提升至78-82%，主观准确度也有所提高。该方法成功地缩小了自动化确定性模型和专家判断之间的差距。", "conclusion": "结合自注意力机制的方法在软件仓库变更影响分析中显著提升了召回率，更好地满足了实际需求，并且改善了与专家判断的一致性。"}}
{"id": "2601.06181", "pdf": "https://arxiv.org/pdf/2601.06181", "abs": "https://arxiv.org/abs/2601.06181", "authors": ["Yung-Shen Hsia", "Fang Yu", "Jie-Hong Roland Jiang"], "title": "Neuro-Symbolic Compliance: Integrating LLMs and SMT Solvers for Automated Financial Legal Analysis", "categories": ["cs.AI", "cs.FL", "cs.LG", "cs.LO"], "comment": "10 pages, 6 tables, 3 figures, accepted by the 2nd ACM AIware Conference", "summary": "Financial regulations are increasingly complex, hindering automated compliance-especially the maintenance of logical consistency with minimal human oversight. We introduce a Neuro-Symbolic Compliance Framework that integrates Large Language Models (LLMs) with Satisfiability Modulo Theories (SMT) solvers to enable formal verifiability and optimization-based compliance correction. The LLM interprets statutes and enforcement cases to generate SMT constraints, while the solver enforces consistency and computes the minimal factual modification required to restore legality when penalties arise. Unlike transparency-oriented methods, our approach emphasizes logic-driven optimization, delivering verifiable, legally consistent reasoning rather than post-hoc explanation. Evaluated on 87 enforcement cases from Taiwan's Financial Supervisory Commission (FSC), the system attains 86.2% correctness in SMT code generation, improves reasoning efficiency by over 100x, and consistently corrects violations-establishing a preliminary foundation for optimization-based compliance applications.", "AI": {"tldr": "提出了一种结合大型语言模型（LLMs）和可满足性模理论求解器（SMT）的神经符号合规框架，用于自动化金融法规分析。", "motivation": "金融监管日益复杂，使得自动合规变得困难，特别是缺乏逻辑一致性以及最小的人工监督。本文旨在通过整合大型语言模型与可满足性模理论求解器来解决这一问题。", "method": "该方法利用LLM解读法条和执法案例生成SMT约束条件，并使用SMT求解器执行一致性和计算修复违法行为所需的最小事实修改量，从而实现形式验证与合规修正。", "result": "在台湾金融监督管理委员会的87个执法案例评估中，系统达到了86.2%的正确率，在SMT代码生成方面提高了100倍以上的推理效率，并且能够持续纠正违规行为。", "conclusion": "该研究提供了一个基于优化的合规应用基础框架，强调逻辑驱动的优化而非事后解释。"}}
{"id": "2601.06180", "pdf": "https://arxiv.org/pdf/2601.06180", "abs": "https://arxiv.org/abs/2601.06180", "authors": ["Saki Imai", "Pedram Heydari", "Anthony Sicilia", "Asteria Kaeberlein", "Katherine Atwell", "Malihe Alikhani"], "title": "MixDPO: Modeling Preference Strength for Pluralistic Alignment", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Preference based alignment objectives implicitly assume that all human preferences are expressed with equal strength. In practice, however, preference strength varies across individuals and contexts -- a phenomenon established in behavioral economics and discrete choice theory. This mismatch limits the ability of existing objectives to faithfully capture heterogeneous human judgments. Inspired by this literature, we introduce Mixed Logit Direct Preference Optimization (MixDPO), a generalization of Direct Preference Optimization that models variation in preference strength. MixDPO enables alignment objectives to capture heterogeneity in how strongly preferences are expressed across training examples. We evaluate MixDPO on three preference datasets using two open-weight language models. Across datasets, MixDPO improves aggregate alignment performance (+11.2 points on Pythia-2.8B) while preserving subgroup level preferences, with the largest gains appearing in settings with higher inferred preference heterogeneity. MixDPO makes preference heterogeneity explicit through learned strength distributions. We release our code for reproducibility.", "AI": {"tldr": "提出了一种新的模型MixDPO，用于处理偏好强度的差异性问题。", "motivation": "现有的基于偏好的对齐目标假设所有人类偏好的表达都是等同的。然而，在实践中，个体和上下文中的偏好强度是不同的。这种不匹配限制了现有目标捕捉异质判断的能力。", "method": "通过引入混合Logit直接偏好优化（MixDPO），一种直接偏好优化的推广形式，该模型可以模拟偏好强度的变化，并使其能够捕获训练示例之间的偏好表达差异性。", "result": "在三个偏好的数据集上使用两种开放式语言模型进行评估，结果显示MixDPO改善了整体对齐性能，在Pythia-2.8B上的提高幅度为11.2点。此外，它还保留了子群体级别的偏好，并且在具有更高推断出的偏好异质性的设置中表现出最大的收益。", "conclusion": "通过学习到的强度分布，MixDPO使偏好的异质性变得显而易见，并公开了代码以实现可重复性"}}
{"id": "2601.06176", "pdf": "https://arxiv.org/pdf/2601.06176", "abs": "https://arxiv.org/abs/2601.06176", "authors": ["Hongbo Jin", "Siyi Xie", "Jiayu Ding", "Kuanwei Lin", "Ge Li"], "title": "TIR-Flow: Active Video Search and Reasoning with Frozen VLMs", "categories": ["cs.CV"], "comment": null, "summary": "While Large Video-Language Models (Video-LLMs) have achieved remarkable progress in perception, their reasoning capabilities remain a bottleneck. Existing solutions typically resort to a heavy \"data engineering\" paradigm-synthesizing large-scale Chain-of-Thought (CoT) datasets followed by Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). This pipeline primarily optimizes probability sampling efficiency and aligns output distributions, but fails to activate the intrinsic intelligence required for dynamic visual exploration. In this work, we propose TIR-Flow, a novel framework that shifts the paradigm from passive processing to active video searching and reasoning without additional data or parameter updating. Concretely, our framework operates through three synergistic modules: HDD decomposes complex queries into a set of verifiable sub-tasks; HAP actively directs visual attention to gather high-resolution evidence for hypothesis validation; EBA maintains a persistent workspace to accumulate and update the discovered clues for logical reasoning. Extensive experiments on seven benchmarks demonstrate that TIR-Flow significantly outperforms recent strong baselines, delivering an average performance boost of 5.9%, with gains reaching 10.5% on Egoschema. Our analysis confirms that empowering frozen VLMs with System-2-like active perception is a scalable path toward solving long-horizon video reasoning.", "AI": {"tldr": "本文提出TIR-Flow框架，用于基于冻结视频语言模型的主动视频搜索和推理。", "motivation": "现有的大型视频语言模型尽管在感知方面取得了显著进展，但其推理能力仍然是瓶颈。现有解决方案依赖于“数据工程”范式，并且不能激活所需的动态视觉探索智能。", "method": "TIR-Flow框架包含三个协同模块：HDD将复杂查询分解为一组可验证子任务；HAP主动引导视觉注意力以收集高分辨率证据来验证假设；EBA维护一个持久工作空间，用于累积和更新发现的线索进行逻辑推理。", "result": "实验结果表明TIR-Flow在七个基准测试中表现优于近期最强基线方法，平均性能提升5.9%，在Egoschema上最高提升了10.5%。", "conclusion": "赋予冻结视频语言模型类似System-2的主动感知能力是解决长期视频推理问题的一个可扩展路径。"}}
{"id": "2601.06174", "pdf": "https://arxiv.org/pdf/2601.06174", "abs": "https://arxiv.org/abs/2601.06174", "authors": ["François Rottenberg", "Thomas Feys", "Liesbet Van der Perre"], "title": "The environmental impact of ICT in the era of data and artificial intelligence", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The technology industry promotes artificial intelligence (AI) as a key enabler to solve a vast number of problems, including the environmental crisis. However, when looking at the emissions of datacenters from worldwide service providers, we observe a rapid increase aligned with the advent of AI. Some actors justify it by claiming that the increase of emissions for digital infrastructures is acceptable as it could help the decarbonization of other sectors, e.g., videoconference tools instead of taking the plane for a meeting abroad, or using AI to optimize and reduce energy consumption. With such conflicting claims and ambitions, it is unclear how the net environmental impact of AI could be quantified. The answer is prone to uncertainty for different reasons, among others: lack of transparency, interference with market expectations, lack of standardized methodology for quantifying direct and indirect impact, and the quick evolutions of models and their requirements. This report provides answers and clarifications to these different elements. Firstly, we consider the direct environmental impact of AI from a top-down approach, starting from general information and communication technologies (ICT) and then zooming in on data centers and the different phases of AI development and deployment. Secondly, a framework is introduced on how to assess both the direct and indirect impact of AI. Finally, we finish with good practices and what we can do to reduce AI impact.", "AI": {"tldr": "分析人工智能对环境的直接影响和间接影响，并提供减少其影响的最佳实践。", "motivation": "探讨数据和人工智能时代的ICT（信息与通信技术）环境影响，以应对行业内外关于AI环保效益的不同观点和论据。", "method": "首先采用自上而下的方法研究AI直接的环境影响；其次构建评估AI直接影响及间接影响的框架；最后给出减少AI影响的最佳实践。", "result": "提出了评估AI对环境的影响的方法，并提供了一系列最佳实践。", "conclusion": "通过系统分析和提出解决方案，可以更好地理解并减轻人工智能发展带来的潜在环境负担。"}}
{"id": "2601.06172", "pdf": "https://arxiv.org/pdf/2601.06172", "abs": "https://arxiv.org/abs/2601.06172", "authors": ["Junaid Qadir", "Muhammad Mumtaz"], "title": "The Psychology of Learning from Machines: Anthropomorphic AI and the Paradox of Automation in Education", "categories": ["cs.CY", "cs.AI"], "comment": "accepted at IEEE EDUCON 2026", "summary": "As AI tutors enter classrooms at unprecedented speed, their deployment increasingly outpaces our grasp of the psychological and social consequences of such technology. Yet decades of research in automation psychology, human factors, and human-computer interaction provide crucial insights that remain underutilized in educational AI design. This work synthesizes four research traditions -- automation psychology, human factors engineering, HCI, and philosophy of technology -- to establish a comprehensive framework for understanding how learners psychologically relate to anthropomorphic AI tutors. We identify three persistent challenges intensified by Generative AI's conversational fluency. First, learners exhibit dual trust calibration failures -- automation bias (uncritical acceptance) and algorithm aversion (excessive rejection after errors) -- with an expertise paradox where novices overrely while experts underrely. Second, while anthropomorphic design enhances engagement, it can distract from learning and foster harmful emotional attachment. Third, automation ironies persist: systems meant to aid cognition introduce designer errors, degrade skills through disuse, and create monitoring burdens humans perform poorly. We ground this theoretical synthesis through comparative analysis of over 104,984 YouTube comments across AI-generated philosophical debates and human-created engineering tutorials, revealing domain-dependent trust patterns and strong anthropomorphic projection despite minimal cues. For engineering education, our synthesis mandates differentiated approaches: AI tutoring for technical foundations where automation bias is manageable through proper scaffolding, but human facilitation for design, ethics, and professional judgment where tacit knowledge transmission proves irreplaceable.", "AI": {"tldr": "本文综合了自动化心理学、人因工程学、HCI和科技哲学四个研究领域，探讨了学习者如何在心理上与拟人类AI辅导系统互动，并通过分析超过104,984条YouTube评论得出了对教育领域的建议。", "motivation": "随着AI导师快速进入教室，其部署速度超过了我们对其心理和社会后果的理解。本文旨在利用自动化心理学等多个领域已有研究成果来填补这一空白，特别是探讨拟人类AI辅导系统在学习中的应用。", "method": "文章综合了四个研究传统并进行了比较分析，评估了104,984条YouTube评论中关于人工智能生成的哲学辩论和人工创建的工程教程的信任模式。", "result": "结果揭示了领域依赖的信任模式，并显示即使存在极少的人类线索，人们也会强烈地投射人类特征到AI上。这表明需要采取差异化的方法来教育应用人工智能。", "conclusion": "本文建议在技术基础方面使用AI辅导系统，在设计、伦理和专业判断等环节中则依靠人工辅助。"}}
{"id": "2601.06171", "pdf": "https://arxiv.org/pdf/2601.06171", "abs": "https://arxiv.org/abs/2601.06171", "authors": ["Junaid Qadir", "Muhammad Salman Khan"], "title": "From Individual Prompts to Collective Intelligence: Mainstreaming Generative AI in the Classroom", "categories": ["cs.CY", "cs.AI"], "comment": "accepted at IEEE EDUCON 2026", "summary": "Engineering classrooms are increasingly experimenting with generative AI (GenAI), but most uses remain confined to individual prompting and isolated assistance. This narrow framing risks reinforcing equity gaps and only rewarding the already privileged or motivated students. We argue instead for a shift toward collective intelligence (CI)-focused pedagogy, where GenAI acts as a catalyst for peer-to-peer learning. We implemented Generative CI (GCI) activities in two undergraduate engineering courses, engaging 140 students through thinking routines -- short, repeatable scaffolds developed by Harvard Project Zero to make thinking visible and support collaborative sense-making. Using routines such as Question Sorts and Peel the Fruit, combined with strategic AI consultation, we enabled students to externalize their reasoning, compare interpretations, and iteratively refine ideas. Our dual-pronged approach synthesizes literature from learning sciences, CI, embodied cognition, and philosophy of technology, while also empirically learning through student surveys and engagement observations. Results demonstrate that students value the combination of human collaboration with strategic AI support, recognizing risks of over-reliance while appreciating AI's role in expanding perspectives. Students identified that group work fosters deeper understanding and creative problem-solving than AI alone, with the timing of AI consultation significantly affecting learning outcomes. We offer practical implementation pathways for mainstreaming CI-focused pedagogy that cultivates deeper engagement, resilient problem-solving, and shared ownership of knowledge.", "AI": {"tldr": "论文探讨了在工程教室中将生成式人工智能（GenAI）从个体提示扩展到集体智慧（CI）的教育模式，通过思考惯例和战略性的AI咨询来促进同伴学习。", "motivation": "当前大多数利用生成性人工智能的教学方式局限于单独指导，这有可能加剧不公平现象。论文主张采用以集体智能为中心的教学方法，并试图减少这种不公平的现象。", "method": "在两个本科工程课程中实施了生成式集体智慧（GCI）活动，涉及140名学生通过哈佛零项目开发的思考惯例来促进同伴学习和AI支持下的反思性对话。结合文献综述、实证研究和学生的反馈观察来评估该方法的有效性。", "result": "结果显示学生高度评价人类协作与策略化人工智能相结合的方式，并认为集体工作比单独依赖AI更能加深理解和创造性解决问题，尤其是在适当的时间点利用AI可以显著改善学习效果。", "conclusion": "提出了一种以集体智能为中心的教学模式，促进深度参与、问题解决能力和知识共享，为教育者如何在课堂中有效整合人工智能提供了实用路径。"}}
{"id": "2601.06170", "pdf": "https://arxiv.org/pdf/2601.06170", "abs": "https://arxiv.org/abs/2601.06170", "authors": ["Xuechen Chen", "Junting Li", "Chuang Chen", "Hairong Lin", "Yishen Li"], "title": "Deep Joint Source-Channel Coding for Wireless Video Transmission with Asymmetric Context", "categories": ["eess.IV", "cs.CV"], "comment": "31 pages, 19 figures, 2 tables, accepted in press by Multimedia system", "summary": "In this paper, we propose a high-efficiency deep joint source-channel coding (JSCC) method for video transmission based on conditional coding with asymmetric context. The conditional coding-based neural video compression requires to predict the encoding and decoding conditions from the same context which includes the same reconstructed frames. However in JSCC schemes which fall into pseudo-analog transmission, the encoder cannot infer the same reconstructed frames as the decoder even a pipeline of the simulated transmission is constructed at the encoder. In the proposed method, without such a pipeline, we guide and design neural networks to learn encoding and decoding conditions from asymmetric contexts. Additionally, we introduce feature propagation, which allows intermediate features to be independently propagated at the encoder and decoder and help to generate conditions, enabling the framework to greatly leverage temporal correlation while mitigating the problem of error accumulation. To further exploit the performance of the proposed transmission framework, we implement content-adaptive coding which achieves variable bandwidth transmission using entropy models and masking mechanisms. Experimental results demonstrate that our method outperforms existing deep video transmission frameworks in terms of performance and effectively mitigates the error accumulation. By mitigating the error accumulation, our schemes can reduce the frequency of inserting intra-frame coding modes, further enhancing performance.", "AI": {"tldr": "提出了一种基于条件编码的深度联合信源信道编码方法，用于无线视频传输。", "motivation": "解决传统JSCC方案中编码器无法从相同上下文中预测解码帧的问题。", "method": "设计神经网络学习不对称上下文中的编解码条件；引入特征传播技术以减轻错误累积问题；实施内容自适应编码实现可变带宽传输。", "result": "实验表明，该方法在性能上优于现有深度视频传输框架，并有效缓解了错误累积。", "conclusion": "所提方案能显著提高无线视频传输效率并减少插入内帧模式的频率。"}}
{"id": "2601.06169", "pdf": "https://arxiv.org/pdf/2601.06169", "abs": "https://arxiv.org/abs/2601.06169", "authors": ["Zhiyong Ma", "Zhenpeng Li", "Yuanjie Shi", "Zhengping Li", "Jiahao Chen", "Qingyuan Chuai"], "title": "Think Bright, Diffuse Nice: Enhancing T2I-ICL via Inductive-Bias Hint Instruction and Query Contrastive Decoding", "categories": ["cs.CV"], "comment": "Submitted to ACL 2026", "summary": "Text-to-Image In-Context Learning (T2I-ICL) enables customized image synthesis via interleaved text-image examples but faces two mutually reinforcing bottlenecks, compliance failure and prior-dominated hallucination, that form a vicious cycle degrading generation quality. Existing methods rely on tailored training, which limits flexibility and raises deployment costs. To address these challenges effectively, we propose TBDN, a training-free framework integrating two complementary closed-loop mechanisms: Hint Instruction (HI) and Query Contrastive Decoding (QCD). HI injects task-aware inductive bias via lightweight prompt engineering to anchor models on contextual mapping rules, thereby mitigating compliance failure. QCD adjusts the decoding distributions of language models by contrasting full-input and query-omitted distributions, suppressing prior-dominated hallucination. TBDN achieves State-of-the-Art performance on CoBSAT and Text-to-Image Fast Mini-ImageNet, with robust generalization across model backbones, prompt designs, and hyperparameters. It also maintains promising performance in concept preservation and prompt following on Dreambench++. By breaking the two bottlenecks, TBDN establishes a simple yet effective framework for efficient and reliable T2I-ICL.", "AI": {"tldr": "本文提出了一种名为TBDN的框架，用于增强文本到图像在上下文学习(T2I-ICL)的效果。", "motivation": "现有的T2I-ICL方法面临合规性失败和先验主导幻觉的问题，形成了一个恶性循环。为了有效解决这些问题，本文提出了TBDN框架以提高生成质量。", "method": "TBDN通过引入两种互补的闭环机制：Hint Instruction（HI）和Query Contrastive Decoding（QCD）。HI通过轻量级提示工程注入任务感知归纳偏差，而QCD通过对比完整输入和查询省略分布来调整语言模型的解码分布。", "result": "TBDN在CoBSAT和Text-to-Image Fast Mini-ImageNet数据集上取得了SOTA性能，并且具有跨模型骨干、提示设计和超参数的强大泛化能力。它还在Dreambench++概念保持和提示跟随方面表现出色。", "conclusion": "通过解决两个主要瓶颈，TBDN建立了一个简单而有效的框架，实现了高效可靠的文本到图像的上下文学习任务。"}}
{"id": "2601.06168", "pdf": "https://arxiv.org/pdf/2601.06168", "abs": "https://arxiv.org/abs/2601.06168", "authors": ["Jyotiraditya Gupta"], "title": "Analyzing the Structure of Handwritten Digits: A Comparative Study of PCA, Factor Analysis, and UMAP", "categories": ["cs.CV"], "comment": "15 pages, 12 figures", "summary": "Handwritten digit images lie in a high-dimensional pixel space but exhibit strong geometric and statistical structure. This paper investigates the latent organization of handwritten digits in the MNIST dataset using three complementary dimensionality reduction techniques: Principal Component Analysis (PCA), Factor Analysis (FA), and Uniform Manifold Approximation and Projection (UMAP). Rather than focusing on classification accuracy, we study how each method characterizes intrinsic dimensionality, shared variation, and nonlinear geometry. PCA reveals dominant global variance directions and enables high-fidelity reconstructions using a small number of components. FA decomposes digits into interpretable latent handwriting primitives corresponding to strokes, loops, and symmetry. UMAP uncovers nonlinear manifolds that reflect smooth stylistic transitions between digit classes. Together, these results demonstrate that handwritten digits occupy a structured low-dimensional manifold and that different statistical frameworks expose complementary aspects of this structure.", "AI": {"tldr": "研究手写数字在MNIST数据集中的潜在组织结构，使用PCA、因子分析和UMAP三种降维技术。", "motivation": "探索手写数字的内在维度性、共享变异性和非线性几何特性。", "method": "采用PCA揭示全局方差方向，因子分析将数字分解为可解释的手写基本元素，UMAP发现反映不同类别间平滑风格转换的非线性流形。", "result": "结果显示手写数字占据了一个结构化的低维流形，并且不同的统计框架揭示了该结构的不同方面。", "conclusion": "这三种方法共同展示了手写数字数据中的复杂但有序的结构特性。"}}
{"id": "2601.06167", "pdf": "https://arxiv.org/pdf/2601.06167", "abs": "https://arxiv.org/abs/2601.06167", "authors": ["Anshum Rankawat"], "title": "Parent-Guided Adaptive Reliability (PGAR): A Behavioural Meta-Learning Framework for Stable and Trustworthy AI", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 8 figures, 2 tables. Submitted to IEEE Transactions on Artificial Intelligence", "summary": "Parent-Guided Adaptive Reliability (PGAR) is a lightweight behavioural meta-learning framework that adds a supervisory \"parent\" layer on top of a standard learner to improve stability, calibration, and recovery under disturbances. PGAR computes three reflex-level signals (incident detection, overconfidence correction, and recovery memory) and fuses them into a bounded reliability index in [0,1]. This index continuously modulates the learner's effective learning rate, reducing update magnitude during instability and restoring it as reliability improves. We provide a Lyapunov-based proof sketch establishing bounded adaptation of the reliability dynamics under mild assumptions (smooth loss, descent direction, and bounded reflex outputs). Empirical evaluations on representative learning tasks show improved calibration, reduced loss variance, and faster recovery compared to standard optimizers, while retaining computational simplicity. PGAR functions as a plug-in reliability layer for existing optimization and learning pipelines, supporting interpretable reliability traces in safety-relevant settings.", "AI": {"tldr": "该论文提出了一个名为Parent-Guided Adaptive Reliability (PGAR)的轻量级行为元学习框架，通过添加监督层来提高AI系统的稳定性和可靠性。", "motivation": "为了改善机器学习系统在面对干扰时的稳定性、校准能力和恢复能力，提出了一种新的方法来控制和优化学习过程中的可靠度。", "method": "PGAR框架计算三种反射信号（事件检测、过度自信修正和恢复记忆），并将它们融合成一个范围在[0,1]内的可靠性指标。该指标连续调节学习器的有效学习率，在不稳定时期减少更新幅度并在可靠性改善时恢复之。", "result": "实证研究表明，与标准优化器相比，PGAR能提高校准、降低损失方差并加快恢复速度，同时保持计算简便性。", "conclusion": "该方法通过插件式的可靠性层增强了现有优化和学习流程，并在安全相关场景下支持可解释的可靠性跟踪。"}}
{"id": "2601.06166", "pdf": "https://arxiv.org/pdf/2601.06166", "abs": "https://arxiv.org/abs/2601.06166", "authors": ["Di Xu", "Hengjie Liu", "Yang Yang", "Mary Feng", "Jin Ning", "Xin Miao", "Jessica E. Scholey", "Alexandra E. Hotca-cho", "William C. Chen", "Michael Ohliger", "Martina Descovich", "Huiming Dong", "Wensha Yang", "Ke Sheng"], "title": "B-FIRE: Binning-Free Diffusion Implicit Neural Representation for Hyper-Accelerated Motion-Resolved MRI", "categories": ["cs.CV"], "comment": null, "summary": "Accelerated dynamic volumetric magnetic resonance imaging (4DMRI) is essential for applications relying on motion resolution. Existing 4DMRI produces acceptable artifacts of averaged breathing phases, which can blur and misrepresent instantaneous dynamic information. Recovery of such information requires a new paradigm to reconstruct extremely undersampled non-Cartesian k-space data. We propose B-FIRE, a binning-free diffusion implicit neural representation framework for hyper-accelerated MR reconstruction capable of reflecting instantaneous 3D abdominal anatomy. B-FIRE employs a CNN-INR encoder-decoder backbone optimized using diffusion with a comprehensive loss that enforces image-domain fidelity and frequency-aware constraints. Motion binned image pairs were used as training references, while inference was performed on binning-free undersampled data. Experiments were conducted on a T1-weighted StarVIBE liver MRI cohort, with accelerations ranging from 8 spokes per frame (RV8) to RV1. B-FIRE was compared against direct NuFFT, GRASP-CS, and an unrolled CNN method. Reconstruction fidelity, motion trajectory consistency, and inference latency were evaluated.", "AI": {"tldr": "提出了B-FIRE框架，用于超加速的MRI重建。", "motivation": "现有的4DMRI方法会产生模糊和不准确的动态信息。为了解决这个问题，需要一种新的范式来从极度欠采样的非笛卡尔k空间数据中恢复瞬时3D解剖结构。", "method": "B-FIRE采用了基于CNN-INR编码器-解码器架构，并通过扩散优化方法进行训练。它使用了包含图像域保真度和频率感知约束的综合损失函数，以实现更准确的重建效果。", "result": "在T1加权StarVIBE肝脏MRI数据集上的实验结果表明，B-FIRE方法比直接NuFFT、GRASP-CS以及卷积神经网络方法具有更高的重建准确性，同时保持了良好的运动轨迹一致性及较短的推断延迟。", "conclusion": "B-FIRE框架在超加速MRI重建中表现出色，能够有效恢复瞬时3D解剖结构，并且可以应用于各种动态成像任务。"}}
{"id": "2601.06165", "pdf": "https://arxiv.org/pdf/2601.06165", "abs": "https://arxiv.org/abs/2601.06165", "authors": ["Dasol Choi", "Guijin Son", "Hanwool Lee", "Minhyuk Kim", "Hyunwoo Ko", "Teabin Lim", "Ahn Eungyeol", "Jungwhan Kim", "Seunghyeok Hong", "Youngsook Song"], "title": "What Users Leave Unsaid: Under-Specified Queries Limit Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Current vision-language benchmarks predominantly feature well-structured questions with clear, explicit prompts. However, real user queries are often informal and underspecified. Users naturally leave much unsaid, relying on images to convey context. We introduce HAERAE-Vision, a benchmark of 653 real-world visual questions from Korean online communities (0.76% survival from 86K candidates), each paired with an explicit rewrite, yielding 1,306 query variants in total. Evaluating 39 VLMs, we find that even state-of-the-art models (GPT-5, Gemini 2.5 Pro) achieve under 50% on the original queries. Crucially, query explicitation alone yields 8 to 22 point improvements, with smaller models benefiting most. We further show that even with web search, under-specified queries underperform explicit queries without search, revealing that current retrieval cannot compensate for what users leave unsaid. Our findings demonstrate that a substantial portion of VLM difficulty stem from natural query under-specification instead of model capability, highlighting a critical gap between benchmark evaluation and real-world deployment.", "AI": {"tldr": "研究分析了视觉语言模型在处理用户自然生成的不完整查询时的表现，并构建了一个新基准HAERAE-Vision来评估这些模型。", "motivation": "现有视觉语言基准测试主要使用结构良好且明确的问题，而实际用户的查询往往比较随意和不完全。此研究旨在揭示这种差异对模型性能的影响。", "method": "引入了包含653个真实世界视觉问题的HAERAE-Vision基准，每个问题都有一个对应的明确定义版本；评估了39种视觉语言模型在原始查询与明确查询上的表现，并对比了有无网络搜索情况下的结果。", "result": "即使是最先进的模型也未能准确回答大多数原始查询（低于50%），但通过将查询明确化，性能显著提高8到22个百分点；即便是添加了网络搜索的辅助，不完全查询的表现依然不如明确定义后的查询。", "conclusion": "研究指出当前视觉语言模型在处理自然生成的不完整查询时存在重大挑战，表明现有基准测试与实际应用之间存在着明显差距。"}}
{"id": "2601.06164", "pdf": "https://arxiv.org/pdf/2601.06164", "abs": "https://arxiv.org/abs/2601.06164", "authors": ["Sahil Agarwal"], "title": "Contract2Plan: Verified Contract-Grounded Retrieval-Augmented Optimization for BOM-Aware Procurement and Multi-Echelon Inventory Planning", "categories": ["cs.SE", "cs.AI"], "comment": "22 pages, 5 figures, 4 tables, 1 algorithm", "summary": "Procurement and inventory planning is governed not only by demand forecasts and bills of materials (BOMs), but also by operational terms in contracts and supplier documents (e.g., MOQs, lead times, price tiers, allocation caps, substitution approvals). LLM-based extraction can speed up structuring these terms, but extraction-only or LLM-only decision pipelines are brittle: missed clauses, unit errors, and unresolved conflicts can yield infeasible plans or silent contract violations, amplified by BOM coupling. We introduce Contract2Plan, a verified GenAI-to-optimizer pipeline that inserts a solver-based compliance gate before plans are emitted. The system retrieves clause evidence with provenance, extracts a typed constraint schema with evidence spans, compiles constraints into a BOM-aware MILP, and verifies grounding, eligibility, consistency, and feasibility using solver diagnostics, triggering targeted repair or abstention when automation is unsafe. We formalize which clause classes admit conservative repair with contract-safe feasibility guarantees and which require human confirmation. A self-contained synthetic micro-benchmark (500 instances; T=5) computed by exact enumeration under an execution model with MOQ uplift and emergency purchases shows heavy-tailed regret and nontrivial MOQ-violation incidence for extraction-only planning, motivating verification as a first-class component of contract-grounded planning systems.", "AI": {"tldr": "本文提出了一种名为Contract2Plan的系统，该系统通过插入一个解决器合规性门来生成符合合同条款的采购和库存规划方案。", "motivation": "传统的基于LLM的提取方法在处理复杂合同条款时容易出错，导致不合理的计划或静默违反合同。因此，需要一种更可靠的方法来确保所生成的采购和库存规划是可行且合规的。", "method": "Contract2Plan系统包括通过检索条款证据、提取类型化约束模式并将其编译为BOM感知MILP的过程，并使用解决器诊断验证其接地性、资格、一致性及可行性。当自动化不安全时，该系统会触发针对性修复或弃权。", "result": "合成微基准测试表明，仅基于提取的规划会导致严重的问题如高尾后悔和非零MOQ违规率，这证明了在合同基础规划中验证是必要的。", "conclusion": "通过正式化哪些条款类别可以保守地进行符合合同安全保证的修复以及哪些需要人工确认，Contract2Plan提供了一个可靠的方法来生成合规且可行的采购与库存计划方案。"}}
{"id": "2601.06163", "pdf": "https://arxiv.org/pdf/2601.06163", "abs": "https://arxiv.org/abs/2601.06163", "authors": ["Kaiyuan Deng", "Bo Hui", "Gen Li", "Jie Ji", "Minghai Qin", "Geng Yuan", "Xiaolong Ma"], "title": "Forget-It-All: Multi-Concept Machine Unlearning via Concept-Aware Neuron Masking", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The widespread adoption of text-to-image (T2I) diffusion models has raised concerns about their potential to generate copyrighted, inappropriate, or sensitive imagery learned from massive training corpora. As a practical solution, machine unlearning aims to selectively erase unwanted concepts from a pre-trained model without retraining from scratch. While most existing methods are effective for single-concept unlearning, they often struggle in real-world scenarios that require removing multiple concepts, since extending them to this setting is both non-trivial and problematic, causing significant challenges in unlearning effectiveness, generation quality, and sensitivity to hyperparameters and datasets. In this paper, we take a unique perspective on multi-concept unlearning by leveraging model sparsity and propose the Forget It All (FIA) framework. FIA first introduces Contrastive Concept Saliency to quantify each weight connection's contribution to a target concept. It then identifies Concept-Sensitive Neurons by combining temporal and spatial information, ensuring that only neurons consistently responsive to the target concept are selected. Finally, FIA constructs masks from the identified neurons and fuses them into a unified multi-concept mask, where Concept-Agnostic Neurons that broadly support general content generation are preserved while concept-specific neurons are pruned to remove the targets. FIA is training-free and requires only minimal hyperparameter tuning for new tasks, thereby promoting a plug-and-play paradigm. Extensive experiments across three distinct unlearning tasks demonstrate that FIA achieves more reliable multi-concept unlearning, improving forgetting effectiveness while maintaining semantic fidelity and image quality.", "AI": {"tldr": "提出了Forget It All (FIA)框架，用于从预训练模型中删除多个概念而不重新训练。", "motivation": "解决现有单个概念清除方法在多概念清除中的局限性，提高清除效果和生成质量。", "method": "通过对比概念显著度量化权重连接对目标概念的贡献；结合时空信息识别特定概念敏感神经元，并构建掩码以保留通用支持神经元同时修剪特定概念神经元。", "result": "在多概念清除任务中的实验表明，FIA提高了遗忘效果并保持了语义保真和图像质量。", "conclusion": "Forget It All框架通过训练自由的方式解决了多概念清除问题，并展示了更好的清除性能和生成能力。"}}
{"id": "2601.06162", "pdf": "https://arxiv.org/pdf/2601.06162", "abs": "https://arxiv.org/abs/2601.06162", "authors": ["Kaiyuan Deng", "Gen Li", "Yang Xiao", "Bo Hui", "Xiaolong Ma"], "title": "Forget Many, Forget Right: Scalable and Precise Concept Unlearning in Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Text-to-image diffusion models have achieved remarkable progress, yet their use raises copyright and misuse concerns, prompting research into machine unlearning. However, extending multi-concept unlearning to large-scale scenarios remains difficult due to three challenges: (i) conflicting weight updates that hinder unlearning or degrade generation; (ii) imprecise mechanisms that cause collateral damage to similar content; and (iii) reliance on additional data or modules, creating scalability bottlenecks. To address these, we propose Scalable-Precise Concept Unlearning (ScaPre), a unified framework tailored for large-scale unlearning. ScaPre introduces a conflict-aware stable design, integrating spectral trace regularization and geometry alignment to stabilize optimization, suppress conflicts, and preserve global structure. Furthermore, an Informax Decoupler identifies concept-relevant parameters and adaptively reweights updates, strictly confining unlearning to the target subspace. ScaPre yields an efficient closed-form solution without requiring auxiliary data or sub-models. Comprehensive experiments on objects, styles, and explicit content demonstrate that ScaPre effectively removes target concepts while maintaining generation quality. It forgets up to $\\times \\mathbf{5}$ more concepts than the best baseline within acceptable quality limits, achieving state-of-the-art precision and efficiency for large-scale unlearning.", "AI": {"tldr": "该论文提出了Scalable-Precise Concept Unlearning (ScaPre)，一个适用于大规模场景的概念遗忘框架，旨在解决扩散模型中的多概念删除难题。", "motivation": "文本到图像的扩散模型虽然取得了重大进展，但其使用引发版权和滥用担忧。现有的多概念删除技术在大型场景中难以扩展，面临着权重更新冲突、机制不精确及依赖额外数据等问题。", "method": "ScaPre通过引入谱迹正则化和几何对齐来稳定优化过程并抑制冲突，同时利用Informax Decoupler识别相关参数并自适应调整权重更新。该框架无需辅助数据或子模型即可提供高效的闭式解。", "result": "实验表明，ScaPre能够有效删除目标概念而不损害生成质量，在大规模场景下比现有最佳方法效率更高、精度更好。", "conclusion": "ScaPre在解决扩散模型中的多概念遗忘问题方面表现出色，展示了其在处理版权和滥用问题上的潜在价值。"}}
{"id": "2601.06161", "pdf": "https://arxiv.org/pdf/2601.06161", "abs": "https://arxiv.org/abs/2601.06161", "authors": ["Rifa Ferzana"], "title": "Beyond Accuracy: A Decision-Theoretic Framework for Allocation-Aware Healthcare AI", "categories": ["cs.AI"], "comment": "11 pages, 3 figures, PDF-only submission. This work introduces a decision-theoretic framework to bridge the gap between predictive accuracy and clinical impact in healthcare AI. Includes synthetic simulation results", "summary": "Artificial intelligence (AI) systems increasingly achieve expert-level predictive accuracy in healthcare, yet improvements in model performance often fail to produce corresponding gains in patient outcomes. We term this disconnect the allocation gap and provide a decision-theoretic explanation by modelling healthcare delivery as a stochastic allocation problem under binding resource constraints. In this framework, AI acts as decision infrastructure that estimates utility rather than making autonomous decisions. Using constrained optimisation and Markov decision processes, we show how improved estimation affects optimal allocation under scarcity. A synthetic triage simulation demonstrates that allocation-aware policies substantially outperform risk-threshold approaches in realised utility, even with identical predictive accuracy. The framework provides a principled basis for evaluating and deploying healthcare AI in resource-constrained settings.", "AI": {"tldr": "研究提出了一种决策理论框架，用于评估在资源有限情况下，医疗AI系统的最优分配策略。", "motivation": "尽管人工智能系统在医疗领域的预测准确性不断提高，但这些改进并未直接转化为更好的患者结果。因此，研究人员希望通过一种新的视角来解释这一现象，并提出相应的解决方案。", "method": "使用约束优化和马尔可夫决策过程，将医疗服务视为一个具有资源限制的随机分配问题。在此框架中，AI系统作为决策基础设施进行效用估计而非自主决策。", "result": "通过合成分诊模拟实验，展示了在预测准确性相同的情况下，基于资源分配意识策略比单纯的风险阈值方法能够更好地提高实际效用。", "conclusion": "该理论框架为评估和部署医疗AI提供了一个原则基础，在资源受限的环境下尤其有价值。"}}
{"id": "2601.06160", "pdf": "https://arxiv.org/pdf/2601.06160", "abs": "https://arxiv.org/abs/2601.06160", "authors": ["Dayu Wang", "Jiaye Yang", "Weikang Li", "Jiahui Liang", "Yang Li"], "title": "Student Guides Teacher: Weak-to-Strong Inference via Spectral Orthogonal Exploration", "categories": ["cs.AI"], "comment": null, "summary": "While Large Language Models (LLMs) demonstrate near-human capabilities, they often suffer from \"Reasoning Collapse\" in complex mathematical proving and long-horizon planning. Models tend to degenerate into low-rank Bias Manifold, where stochastic sampling merely produces lexical variations of erroneous logic rather than semantic exploration. This geometric collapse renders the model \"blind\" to high-value solutions that lie within its Null Space. To address this, we propose Spectral Orthogonal Exploration (SOE), a geometric framework operating on a counter-intuitive \"Student Guides Teacher\" paradigm. Specifically, we utilize a weak auxiliary agent not for imitation, but as an orthogonal probe. By explicitly navigating the Teacher's Null Space, SOE serves as a geometric bridge, effectively ejecting the model from local optima to explore diverse, high-value solution spaces. Experiments on mathematical benchmarks demonstrate that, relative to baseline methods, our approach improves average accuracy by 62.4% and increases average sampling efficiency by 113.7%, indicating a promising path toward overcoming performance plateaus in advanced reasoning tasks.", "AI": {"tldr": "本文提出了一种新的几何框架Spectral Orthogonal Exploration (SOE)，通过弱辅助代理作为正交探针，帮助大型语言模型克服推理塌陷和局部最优问题。", "motivation": "大型语言模型在复杂的数学证明和长期规划中表现出推理塌陷现象，这导致模型陷入低秩偏见流形，并且随机采样仅产生错误逻辑的词汇变化，无法探索高价值的解决方案空间。", "method": "提出了一种新的几何框架Spectral Orthogonal Exploration (SOE)，该方法采用弱辅助代理作为正交探针，通过明确导航教师模型的零空间来帮助其跳出局部最优，从而探索多样化的、高价值的解空间。", "result": "在数学基准测试上，相较于基线方法，本文提出的方法平均准确率提高了62.4%，采样效率提升了113.7%。", "conclusion": "Spectral Orthogonal Exploration (SOE) 为克服大型语言模型在高级推理任务中的性能瓶颈提供了有效路径。"}}
{"id": "2601.06158", "pdf": "https://arxiv.org/pdf/2601.06158", "abs": "https://arxiv.org/abs/2601.06158", "authors": ["Zibin Meng", "Kani Chen"], "title": "PsyAgent: Constructing Human-like Agents Based on Psychological Modeling and Contextual Interaction", "categories": ["cs.AI"], "comment": null, "summary": "Human-like agents require modeling how dispositions interact with social structure. We present PsyAgent, which couples a Big Five trait prior with Bourdieu's cognitive-social co-structure. PsyAgent comprises: (i) Individual Structure (IS), a machine-usable profile encoding traits and facets, cognitive style, values, cultural and educational capital, and salient life episodes; and (ii) Multi-Scenario Contexting (MSC), role-relationship-norm frames spanning eight arenas (work, family, friendship, strangers and civic life, solitude and self-regulation, romance, learning, and public expression). At inference, fixed structured prompts bind the active scenario to the agent profile, yielding behavior that is stable yet context-sensitive. We instantiate IS and MSC to synthesize supervision (role-play dialogues, decision probes, feedback trajectories) and then fine-tune a small LLM. The resulting model produces consistent, identifiable persona-aligned behaviors for specified Big Five configurations and matches or exceeds several larger untuned LLMs and other untuned baselines on our metrics: persona consistency, contextual appropriateness, style matching, trait identifiability, and long-horizon stability. Ablations show IS chiefly improves trait fidelity and stylistic stability, while MSC drives norm awareness and decision fit; both are necessary for cross-scenario performance. PsyAgent offers a precise, data-efficient architecture for personality-grounded agents.", "AI": {"tldr": "本文介绍了PsyAgent系统，该系统基于心理模型和情境交互构建类人代理。", "motivation": "人类行为需要通过社会结构来模拟性格特质的互动。作者提出了一种结合五大人格特质与布尔迪厄认知-社会共构理论的方法，以创建更加真实的行为模型。", "method": "PsyAgent包含个体结构IS和多场景情境MSC两部分，利用固定的结构性提示将活跃的情境绑定到代理配置文件中，产生稳定而敏感于上下文的行为。通过角色扮演对话、决策问题以及反馈轨迹合成监督，并对小型语言模型进行微调。", "result": "结果表明PsyAgent能够在指定的人格特征下生成一致性且与人格一致的行为表现，在多个评估指标上不逊于甚至超过其他未调整的大型语言模型和基准系统。", "conclusion": "通过精确的数据高效架构，PsyAgent为基于个性的身份创建代理提供了一种可行的方法。"}}
{"id": "2601.06157", "pdf": "https://arxiv.org/pdf/2601.06157", "abs": "https://arxiv.org/abs/2601.06157", "authors": ["Kapil Wanaskar", "Gaytri Jena", "Vinija Jain", "Aman Chadha", "Amitava Das"], "title": "ECLIPTICA - A Framework for Switchable LLM Alignment via CITA - Contrastive Instruction-Tuned Alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Alignment in large language models (LLMs) is still largely static: after training, the policy is frozen. DPO, GRPO methods typically imprint one behavior into the weights, leaving little runtime control beyond prompt hacks or expensive re-alignment. We introduce ECLIPTICA, which treats alignment as instruction-driven and runtime-controllable: natural-language alignment instructions act as an explicit behavioral contract (stance, refusal boundary, verbosity) that modulates behavior on the fly under evolving safety requirements, user roles, and governance constraints. We introduce CITA (Contrastive Instruction-Tuned Alignment), combining SFT with contrastive preference optimization under an explicit geometric anchor to a reference model. This yields a stable Riemannian chart and keeps instruction updates within a shared neighborhood, so regimes stay nearby and traversable for reliable switching. To isolate policy switching from ordinary instruction following, we release the ECLIPTICA benchmark: 3000 controlled cases (300 prompts x 10 instruction types) where the user request is fixed and only the alignment instruction changes. On Llama-3.1-8B across five suites (ECLIPTICA, TruthfulQA, Conditional Safety, Length Control, LITMUS), CITA reaches 86.7% instruction-alignment efficiency, beating DPO (56.1%), GRPO (36.1%), and PPO (20.4%).", "AI": {"tldr": "ECLIPTICA是一个框架，用于通过CITA方法在大型语言模型中实现可切换的行为对齐。", "motivation": "现有的LLM行为对齐通常是静态的，在训练后固定不变。DPO、GRPO等方法通常将单一行为嵌入权重之中，仅允许有限的运行时控制或昂贵的重新调整对齐。", "method": "ECLIPTICA框架引入了自然语言指令驱动的行为调节机制，并结合SFT和对比偏好优化以实现稳定的可切换对齐。CITA在模型间建立明确的几何锚点来保持行为更新在同一邻域内。", "result": "在Llama-3.1-8B模型上，使用ECLIPTICA基准测试表明CITA方法达到了86.7%的行为一致性效率，优于DPO、GRPO和PPO等其他方法。", "conclusion": "该研究成功展示了通过引入自然语言指令驱动的运行时控制机制，可以实现大型语言模型中灵活且可靠的行为对齐。"}}
{"id": "2601.06156", "pdf": "https://arxiv.org/pdf/2601.06156", "abs": "https://arxiv.org/abs/2601.06156", "authors": ["Ziyu Huang", "Yong Zeng", "Shen Fu", "Xiaoli Xu", "Hongyang Du"], "title": "Channel Knowledge Map Construction via Guided Flow Matching", "categories": ["cs.IT", "cs.AI"], "comment": null, "summary": "The efficient construction of accurate channel knowledge maps (CKMs) is crucial for unleashing the full potential of environment-aware wireless networks, yet it remains a difficult ill-posed problem due to the sparsity of available location-specific channel knowledge data. Although diffusion-based methods such as denoising diffusion probabilistic models (DDPMs) have been exploited for CKM construction, they rely on iterative stochastic sampling, rendering them too slow for real-time wireless applications. To bridge the gap between high fidelity and efficient CKM construction, this letter introduces a novel framework based on linear transport guided flow matching (LT-GFM). Deviating from the noise-removal paradigm of diffusion models, our approach models the CKM generation process as a deterministic ordinary differential equation (ODE) that follows linear optimal transport paths, thereby drastically reducing the number of required inference steps. We propose a unified architecture that is applicable to not only the conventional channel gain map (CGM) construction, but also the more challenging spatial correlation map (SCM) construction. To achieve physics-informed CKM constructions, we integrate environmental semantics (e.g., building masks) for edge recovery and enforce Hermitian symmetry for property of the SCM. Simulation results verify that LT-GFM achieves superior distributional fidelity with significantly lower Fréchet Inception Distance (FID) and accelerates inference speed by a factor of 25 compared to DDPMs.", "AI": {"tldr": "提出了一种基于线性传输引导流匹配（LT-GFM）的新框架，用于高效构建准确的信道知识地图。", "motivation": "现有的扩散方法如DDPM过于依赖迭代随机抽样，在实时无线应用中速度慢。本文旨在通过确定性的ODE路径来减少推理步骤，提高CKM构造的速度和准确性。", "method": "模型将CKM生成过程视为遵循线性最优传输路径的确定性常微分方程（ODE），并提出了一种适用于CGM和SCM构建的统一架构，同时利用环境语义进行边缘恢复，并施加厄米对称性以确保SCM属性。", "result": "仿真结果表明，LT-GFM在分布保真度上优于DDPMs，并且推理速度提高了25倍。", "conclusion": "通过LT-GFM方法实现了高效且准确的信道知识地图构建。"}}
{"id": "2601.06154", "pdf": "https://arxiv.org/pdf/2601.06154", "abs": "https://arxiv.org/abs/2601.06154", "authors": ["Lynnette Hui Xian Ng", "Kathleen M. Carley"], "title": "BotSim: Mitigating The Formation Of Conspiratorial Societies with Useful Bots", "categories": ["cs.CY", "cs.AI", "cs.SI"], "comment": "Published in Journal of Artificial Societies and Social Simulation", "summary": "Societies can become a conspiratorial society where there is a majority of humans that believe, and therefore spread, conspiracy theories. Artificial intelligence gave rise to social media bots that can spread conspiracies in an automated fashion. Currently, organizations combat the spread of conspiracies through manual fact-checking processes and the dissemination of counter-narratives. However, the effects of harnessing the same automation to create useful bots are not well explored. To address this, we create BotSim, an Agent-Based Model of a society in which useful bots are introduced into a small world network. These useful bots are: Info-Correction Bots, which correct bad information into good, and Good Bots, which put out good messaging. The simulated agents interact through generating, consuming and propagating information. Our results show that, left unchecked, Bad Bots can create a conspiratorial society, and this can be mitigated by either Info-Correction Bots or Good Bots; however, Good Bots are more efficient and sustainable than Info-Correction Bots . Proactive good messaging is more resource-effective than reactive information correction. With our observations, we expand the concept of bots as a malicious social media agent towards automated social media agent that can be used for both good and bad purposes. These results have implications for designing communication strategies to maintain a healthy social cyber ecosystem.", "AI": {"tldr": "研究通过引入有益的机器人来模拟和减轻阴谋论社会形成的问题。", "motivation": "探讨如何利用自动化技术创建有用的机器人以对抗虚假信息传播，维护健康的社交媒体环境。", "method": "开发了BotSim模型，在小世界网络中引入信息纠正机器人和良好信息发布机器人，评估其对抑制阴谋论的影响。", "result": "发现坏机器人可以导致阴谋论社会的形成，并且通过使用有益机器人（如纠正机器人或良好消息发布的机器人）能够减轻这种情况。其中，良好的消息发布机器人比信息纠正机器人更有效可持续。", "conclusion": "这项研究扩展了对社交媒体机器人的看法，即它们既可以用于恶意目的也可以用于积极目的。研究结果为设计有效的沟通策略以维护健康的社交网络生态系统提供了指导。"}}
{"id": "2601.06153", "pdf": "https://arxiv.org/pdf/2601.06153", "abs": "https://arxiv.org/abs/2601.06153", "authors": ["Yik Chan Chin", "David A. Raho", "Hag-Min Kim", "Chunli Bi", "James Ong", "Jingbo Huang", "Serge Stinckwich"], "title": "Interoperability in AI Safety Governance: Ethics, Regulations, and Standards", "categories": ["cs.CY", "cs.AI"], "comment": "122 pages", "summary": "This policy report draws on country studies from China, South Korea, Singapore, and the United Kingdom to identify effective tools and key barriers to interoperability in AI safety governance. It offers practical recommendations to support a globally informed yet locally grounded governance ecosystem. Interoperability is a central goal of AI governance, vital for reducing risks, fostering innovation, enhancing competitiveness, promoting standardization, and building public trust. However, structural gaps such as fragmented regulations and lack of global coordination, and conceptual gaps, including limited Global South engagement, continue to hinder progress. Focusing on three high-stakes domains - autonomous vehicles, education, and cross-border data flows - the report compares ethical, legal, and technical frameworks across the four countries. It identifies areas of convergence, divergence, and potential alignment, offering policy recommendations that support the development of interoperability mechanisms aligned with the Global Digital Compact and relevant UN resolutions. The analysis covers seven components: objectives, regulators, ethics, binding measures, targeted frameworks, technical standards, and key risks.", "AI": {"tldr": "该报告通过对中国、韩国、新加坡和英国的研究，探讨了AI安全治理中的互操作性问题，并提出了实用的政策建议。", "motivation": "探索如何建立一个全球信息丰富但本地根基坚实的治理生态系统，以减少风险、促进创新、增强竞争力、推动标准化并赢得公众信任。", "method": "分析四个国家在自动驾驶车辆、教育和跨境数据流三个高风险领域的伦理、法律和技术框架，并确定了互操作性机制的七个组成部分：目标、监管机构、伦理规范、约束措施、特定框架、技术标准以及关键风险。", "result": "识别出各国之间既有相似之处也有差异，提出了促进全球数字合同及相关联合国决议下互操作性的政策建议。", "conclusion": "为了实现AI安全治理的互操作性目标，需要解决结构性和概念性差距，并通过政策行动来支持跨域协调与合作。"}}
{"id": "2601.06152", "pdf": "https://arxiv.org/pdf/2601.06152", "abs": "https://arxiv.org/abs/2601.06152", "authors": ["Hailong Li", "Feifei Li", "Wenhui Que", "Xingyu Fan"], "title": "HiMeS: Hippocampus-inspired Memory System for Personalized AI Assistants", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) power many interactive systems such as chatbots, customer-service agents, and personal assistants. In knowledge-intensive scenarios requiring user-specific personalization, conventional retrieval-augmented generation (RAG) pipelines exhibit limited memory capacity and insufficient coordination between retrieval mechanisms and user-specific conversational history, leading to redundant clarification, irrelevant documents, and degraded user experience. Inspired by the hippocampus-neocortex memory mechanism, we propose HiMeS, an AI-assistant architecture that fuses short-term and long-term memory. Our contributions are fourfold: (1) A short-term memory extractor is trained end-to-end with reinforcement learning to compress recent dialogue and proactively pre-retrieve documents from the knowledge base, emulating the cooperative interaction between the hippocampus and prefrontal cortex. (2) A partitioned long-term memory network stores user-specific information and re-ranks retrieved documents, simulating distributed cortical storage and memory reactivation. (3) On a real-world industrial dataset, HiMeS significantly outperforms a cascaded RAG baseline on question-answering quality. (4) Ablation studies confirm the necessity of both memory modules and suggest a practical path toward more reliable, context-aware, user-customized LLM-based assistants.", "AI": {"tldr": "本文提出了HiMeS架构，这是一种基于人工智能助手的长短期记忆融合系统，旨在提高个性化AI助手的知识密集型场景下的性能。", "motivation": "在知识密集型场景中，现有的检索增强生成（RAG）管道存在内存容量有限和用户特定会话历史协调不足的问题，导致用户体验下降。受海马体-新皮质记忆机制的启发，本文提出了一个融合短期和长期记忆的系统。", "method": "HiMeS通过强化学习训练了一个短时记忆提取器来压缩最近对话并主动预检索知识库中的文档；同时使用分区长时记忆网络存储用户特定信息并对检索到的文档重新排序。该架构在真实世界的工业数据集上进行了测试，证明了其优越性。", "result": "HiMeS在问答质量方面显著优于传统的RAG基线，并且消融研究确认了两个内存模块都是必要的。", "conclusion": "本文提出了一个受海马体-新皮质记忆机制启发的AI助手架构——HiMeS，该系统能够提供更可靠、上下文感知和用户定制化的LLM基于助手。"}}
{"id": "2601.06149", "pdf": "https://arxiv.org/pdf/2601.06149", "abs": "https://arxiv.org/abs/2601.06149", "authors": ["Naomi Fridman", "Berta Ben Shachar"], "title": "A Foundation Model Approach for Fetal Stress Prediction During Labor From cardiotocography (CTG) recordings", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Intrapartum cardiotocography (CTG) is widely used for fetal monitoring during labor, yet its interpretation suffers from high inter-observer variability and limited predictive accuracy. Deep learning approaches have been constrained by the scarcity of CTG recordings with clinical outcome labels. We present the first application of self-supervised pre-training to intrapartum CTG analysis, leveraging 2,444 hours of unlabeled recordings for masked pre-training followed by fine-tuning on the 552-recording CTU-UHB benchmark. Using a PatchTST transformer architecture with a channel-asymmetric masking scheme designed for fetal heart rate reconstruction, we achieve an area under the receiver operating characteristic curve of 0.83 on the full test set and 0.853 on uncomplicated vaginal deliveries, exceeding previously reported results on this benchmark (0.68-0.75). Error analysis reveals that false-positive alerts typically correspond to CTG patterns judged concerning on retrospective clinical review, suggesting clinically meaningful predictions even when umbilical pH is normal. We release standardized dataset splits and model weights to enable reproducible benchmarking. Our results demonstrate that self-supervised pre-training can address data scarcity in fetal monitoring, offering a path toward reliable decision support in the labor room.", "AI": {"tldr": "采用自监督预训练方法，基于CTG记录预测胎儿分娩过程中的压力情况。", "motivation": "提高胎儿监测的准确性和降低观察者之间的差异性，解决临床标签稀缺的问题。", "method": "利用2444小时未标记的CTG记录进行掩码自监督预训练，并在包含552个样本的标准数据集上微调PatchTST变压器模型。采用通道不对称掩盖方案重建胎儿心率。", "result": "在完整测试集上的AUC达到0.83，在正常阴道分娩中的AUC为0.853，优于之前的报告结果（0.68-0.75）。错误分析表明假阳性警报通常对应于回顾性临床审查中认为有风险的CTG模式。", "conclusion": "自监督预训练可以解决胎儿监测数据不足的问题，并提供可靠的决策支持，有助于提高分娩室内的医疗质量。"}}
{"id": "2601.06145", "pdf": "https://arxiv.org/pdf/2601.06145", "abs": "https://arxiv.org/abs/2601.06145", "authors": ["Masike Malatji"], "title": "Bridging the AI divide in sub-Saharan Africa: Challenges and opportunities for inclusivity", "categories": ["cs.CY", "cs.AI"], "comment": "9 pages; 4 tables; 1 figure", "summary": "The artificial intelligence (AI) digital divide in sub-Saharan Africa (SSA) presents significant disparities in AI access, adoption, and development due to varying levels of infrastructure, education, and policy support. This study investigates the extent of AI readiness among the top SSA countries using the 2024 Government AI Readiness Index, alongside an analysis of AI initiatives to foster inclusivity. A comparative analysis of AI readiness scores highlights disparities across nations, with Mauritius (53.94) and South Africa (52.91) leading, while Zambia (42.58) and Uganda (43.32) lag. Quartile analysis reveals a concentration of AI preparedness among a few nations, suggesting uneven AI development. The study further examines the relationship between AI readiness and economic indicators, identifying instances where AI progress does not strictly correlate with Gross Domestic Product per capita, as seen in Rwanda and Uganda. Using case studies of AI initiatives across SSA, this research contextualises quantitative findings, identifying key strategies contributing to AI inclusivity, including talent development programs, research networks, and policy interventions. The study concludes with recommendations to bridge the AI digital divide, emphasising investments in AI education, localised AI solutions, and cross-country collaborations to accelerate AI adoption in SSA.", "AI": {"tldr": "研究调查了撒哈拉以南非洲地区（SSA）国家的人工智能准备程度，分析其面临的挑战和机会。", "motivation": "探讨撒哈拉以南非洲地区在人工智能访问、采纳和发展方面的差异，识别并解决这些差异带来的问题。", "method": "使用2024年政府AI准备指数评估SSA国家的AI准备度，并通过案例研究分析促进包容性的策略。", "result": "发现毛里求斯和南非的AI准备度较高，而赞比亚和乌干达较低；AI进展与人均GDP不完全相关；关键策略包括人才发展计划、研究网络和政策干预。", "conclusion": "建议通过投资人工智能教育、本地化解决方案以及跨国家合作来缩小撒哈拉以南非洲地区的人工智能数字鸿沟。"}}
{"id": "2601.06144", "pdf": "https://arxiv.org/pdf/2601.06144", "abs": "https://arxiv.org/abs/2601.06144", "authors": ["Rina Khan", "Annabelle Sauve", "Imaan Bayoumi", "Amber L. Simpson", "Catherine Stinson"], "title": "The Patient/Industry Trade-off in Medical Artificial Intelligence", "categories": ["cs.CY", "cs.AI"], "comment": "20 pages", "summary": "Artificial intelligence (AI) in healthcare has led to many promising developments; however, increasingly, AI research is funded by the private sector leading to potential trade-offs between benefits to patients and benefits to industry. Health AI practitioners should prioritize successful adaptation into clinical practice in order to provide meaningful benefits to patients, but translation usually requires collaboration with industry. We discuss three features of AI studies that hamper the integration of AI into clinical practice from the perspective of researchers and clinicians. These include lack of clinically relevant metrics, lack of clinical trials and longitudinal studies to validate results, and lack of patient and physician involvement in the development process. For partnerships between industry and health research to be sustainable, a balance must be established between patient and industry benefit. We propose three approaches for addressing this gap: improved transparency and explainability of AI models, fostering relationships with industry partners that have a reputation for centering patient benefit in their practices, and prioritization of overall healthcare benefits. With these priorities, we can sooner realize meaningful AI technologies used by clinicians where mutua", "AI": {"tldr": "探讨医疗人工智能研究中患者利益与产业利益之间的权衡，并提出改善策略。", "motivation": "由于越来越多的医疗AI研究由私人资助，可能会出现对患者和行业的潜在利益冲突。需要在两者之间寻找平衡点以实现可持续合作。", "method": "分析了阻碍医疗AI技术集成到临床实践中的三个特征：缺乏相关临床指标、缺少验证结果的纵向研究以及开发过程中心理医生参与不足的问题。", "result": "提出了三种解决策略来缩小这种差距，包括提高AI模型透明度和可解释性、与注重患者利益的企业建立关系、优先考虑整体医疗效益。", "conclusion": "通过这些策略可以更快实现对临床有用的有意义的人工智能技术。"}}
{"id": "2601.06143", "pdf": "https://arxiv.org/pdf/2601.06143", "abs": "https://arxiv.org/abs/2601.06143", "authors": ["Pedro Maldonado-Lang", "Clément Vidal"], "title": "Emergent Complexity in Nuclear Reaction Networks: A Study of Stellar Nucleosynthesis through Chemical Organization Theory", "categories": ["astro-ph.SR", "cs.AI"], "comment": "9 pages, 3 figures, paper presented at ALIFE 2025: Ciphers of Life: Proceedings of the Artificial Life Conference 2025", "summary": "We explore the emergence of complex structures within reaction networks, focusing on nuclear reaction networks relevant to stellar nucleosynthesis. The work presents a theoretical framework rooted in Chemical Organization Theory (COT) to characterize how stable, self-sustaining structures arise from the interactions of basic components. Key theoretical contributions include the formalization of atom sets as fundamental reactive units and the concept of synergy to describe the emergence of new reactions and species from the interaction of these units. The property of separability is defined to distinguish dynamically coupled systems from those that can be decomposed. This framework is then applied to the STARLIB nuclear reaction network database, analyzing how network structure, particularly the formation and properties of atom sets and semi-self-maintaining sets, changes as a function of temperature. Results indicate that increasing temperature generally enhances network cohesion, leading to fewer, larger atom sets. Critical temperatures are identified where significant structural reorganizations occur, such as the merging of distinct clusters of atom sets and the disappearance of small, isolated reactive units. The analysis reveals core clusters - large (containing more that 1000 reactions), semi-self-maintaining structures that appear to form the core of all potentially stable nucleosynthetic configurations at various temperatures. Overall, the paper provides insights into the structural underpinnings of stability and emergence in complex reaction networks, with specific implications for understanding stellar evolution and nucleosynthesis.", "AI": {"tldr": "研究核反应网络中的复杂结构，特别是在恒星核合成过程中的稳定、自我维持的结构。", "motivation": "通过化学组织理论理解复杂的核反应网络如何形成稳定的自我维护结构，以更好地解析恒星演化和核合成过程。", "method": "提出原子集合作为基本反应单元的概念，并使用分离性来区分动态耦合系统。应用该框架分析STARLIB数据库中的网络结构变化。", "result": "增加温度通常增强网络凝聚力，导致较少但较大的原子集合。识别出核心聚类，在各种温度下形成稳定核合成配置的核心部分。", "conclusion": "通过化学组织理论揭示复杂反应网络的稳定性基础和新兴特性，为恒星演化和核合成的理解提供见解。"}}
{"id": "2601.06142", "pdf": "https://arxiv.org/pdf/2601.06142", "abs": "https://arxiv.org/abs/2601.06142", "authors": ["Anshul Kumar"], "title": "Is Sanskrit the most token-efficient language? A quantitative study using GPT, Gemini, and SentencePiece", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "9 pages, 4 figures. Code and dataset available at: https://github.com/anshulkr713/sanskrit-token-efficiency", "summary": "Tokens are the basic units of Large Language Models (LLMs). LLMs rely on tokenizers to segment text into these tokens, and tokenization is the primary determinant of computational and inference cost. Sanskrit, one of the oldest languages, is hypothesized to express more meaning per token due to its morphology and grammar rules; however, no prior work has quantified this. We use a dataset of 701 parallel verses of the Bhagavad Gita, which comprises three languages-Sanskrit, English, and Hindi along with transliteration of Sanskrit into English. We test tokenizers including SentencePiece (SPM), older GPT models, and the latest generation tokenizers from Gemini and GPT. We use metrics of token count, characters per token (token efficiency), and tokens per character (token cost). Results show a ~2x difference in token counts between Sanskrit and English/Hindi under the unbiased SPM baseline. English/Hindi translations of Sanskrit commentary resulted in an approximately 20x increase in token count. GPT o200k base (latest, used by GPT-4o) and Gemini (latest) reduce bias by a significant degree compared to GPT cl100k base (used until GPT-4), but still fail to fully capture Sanskrit's compactness. This matters because there might be a penalty bias for non-English users, which inflates the token count. This research provides a foundation for improving future tokenizer design and shows the potential of Sanskrit for highly compact encoding, saving on cost while speeding up training and inference. The code and dataset are available at https://github.com/anshulkr713/sanskrit-token-efficiency", "AI": {"tldr": "研究使用LLM评估梵语相对于英语和印地语的标记效率，探讨其语言特性和计算成本。", "motivation": "探究梵语是否因其语法结构而更高效地利用标记单位，并验证是否存在非英文用户的偏见。", "method": "通过对比701对平行诗歌的标记数量，采用SentencePiece、GPT系列和Gemini等tokenizer进行评估。", "result": "结果表明，在无偏差的情况下梵语比英语或印地语节省约一半的标记量。最新版tokenizer虽改善但未能完全反映梵语的优势。", "conclusion": "该研究揭示了语言编码效率的重要性，并为改进未来tokenizers设计提供了依据，同时也展示了梵语在紧凑编码方面的潜力。"}}
{"id": "2601.06138", "pdf": "https://arxiv.org/pdf/2601.06138", "abs": "https://arxiv.org/abs/2601.06138", "authors": ["Sao Mai Nguyen"], "title": "Low-Back Pain Physical Rehabilitation by Movement Analysis in Clinical Trial", "categories": ["cs.CV", "cs.HC", "cs.RO"], "comment": "ICMST, Tokyo University of Science; Taiwanese Society of Movement Science and Technology; Research institute for Science and Technology, Nov 2025, Tokyo, Japan", "summary": "To allow the development and assessment of physical rehabilitation by an intelligent tutoring system, we propose a medical dataset of clinical patients carrying out low back-pain rehabilitation exercises and benchmark on state of the art human movement analysis algorithms. This dataset is valuable because it includes rehabilitation motions in a clinical setting with patients in their rehabilitation program. This paper introduces the Keraal dataset, a clinically collected dataset to enable intelligent tutoring systems (ITS) for rehabilitation. It addresses four challenges in exercise monitoring: motion assessment, error recognition, spatial localization, temporal localization", "AI": {"tldr": "本文提出了一种在临床环境下用于低背部疼痛康复的智能辅导系统的数据集和基准测试。", "motivation": "为了促进物理康复智能辅导系统的发展与评估，该文提出了一个包含患者进行低背痛康复运动的数据集，并采用最先进的动作分析算法对其进行研究。", "method": "本文介绍了Keraal数据集，这是一个在临床环境中收集的用于物理康复训练的数据集。它解决了四个挑战：运动评估、错误识别、空间定位和时间定位。", "result": "该文通过引入Keraal数据集促进了智能辅导系统的发展，并展示了其应用于低背部疼痛患者康复锻炼中的价值。", "conclusion": "研究证明了在临床环境下利用动作分析技术进行物理康复训练的可行性，为未来的智能化康复提供了重要资源。"}}
{"id": "2601.06137", "pdf": "https://arxiv.org/pdf/2601.06137", "abs": "https://arxiv.org/abs/2601.06137", "authors": ["Yifang Zhang", "Shengwu Xiong", "Henan Wang", "Wenjie Yin", "Jiawang Peng", "Duan Zhou", "Yuqiang Zhang", "Chen Zhou", "Hua Chen", "Qile Zhao", "Pengfei Duan"], "title": "RainBalance: Alleviating Dual Imbalance in GNSS-based Precipitation Nowcasting via Continuous Probability Modeling", "categories": ["cs.LG", "cs.AI"], "comment": "11pages,6 figures", "summary": "Global navigation satellite systems (GNSS) station-based Precipitation Nowcasting aims to predict rainfall within the next 0-6 hours by leveraging a GNSS station's historical observations of precipitation, GNSS-PWV, and related meteorological variables, which is crucial for disaster mitigation and real-time decision-making. In recent years, time-series forecasting approaches have been extensively applied to GNSS station-based precipitation nowcasting. However, the highly imbalanced temporal distribution of precipitation, marked not only by the dominance of non-rainfall events but also by the scarcity of extreme precipitation samples, significantly limits model performance in practical applications. To address the dual imbalance problem in precipitation nowcasting, we propose a continuous probability modeling-based framework, RainBalance. This plug-and-play module performs clustering for each input sample to obtain its cluster probability distribution, which is further mapped into a continuous latent space via a variational autoencoder (VAE). By learning in this continuous probabilistic space, the task is reformulated from fitting single and imbalance-prone precipitation labels to modeling continuous probabilistic label distributions, thereby alleviating the imbalance issue. We integrate this module into multiple state-of-the-art models and observe consistent performance gains. Comprehensive statistical analysis and ablation studies further validate the effectiveness of our approach.", "AI": {"tldr": "该论文提出了一种基于连续概率模型的框架RainBalance，用于缓解GNSS站降水短时预报中的双不平衡问题。", "motivation": "为了提高利用GNSS数据进行降水短时预报的性能，作者针对降水时间分布高度不均衡的问题（非降雨事件占主导且极端降水样本稀缺），提出了新的解决方案以改善模型的实际应用效果。", "method": "RainBalance框架通过聚类获取每个输入样例的簇概率分布，并将其映射到连续潜在空间中。借助变分自动编码器(VAE)，任务从拟合单一和不平衡倾向的降水平标签转变为建模连续的概率性标签分布，从而缓解了不均衡问题。", "result": "该框架被集成到多个最先进的模型中并观察到了一致性的性能提升，统计分析与消融实验进一步验证了方法的有效性。", "conclusion": "RainBalance通过提供一种新的方法来应对降水短时预报中的双不平衡问题，为提高GNSS站降水预测准确性开辟了一条新途径。"}}
{"id": "2601.06135", "pdf": "https://arxiv.org/pdf/2601.06135", "abs": "https://arxiv.org/abs/2601.06135", "authors": ["Zhaowen Fan"], "title": "Attention in Geometry: Scalable Spatial Modeling via Adaptive Density Fields and FAISS-Accelerated Kernels", "categories": ["cs.LG", "cs.CV", "cs.GR"], "comment": "Indepented Study. 22 pages, 2 figures. Includes full mathematical derivation of Adaptive Density Fields (ADF), implementation of FAISS-accelerated kernels, and a physics-informed trajectory POI detection pipeline", "summary": "This work introduces Adaptive Density Fields (ADF), a geometric attention framework that formulates spatial aggregation as a query-conditioned, metric-induced attention operator in continuous space. By reinterpreting spatial influence as geometry-preserving attention grounded in physical distance, ADF bridges concepts from adaptive kernel methods and attention mechanisms. Scalability is achieved via FAISS-accelerated inverted file indices, treating approximate nearest-neighbor search as an intrinsic component of the attention mechanism. We demonstrate the framework through a case study on aircraft trajectory analysis in the Chengdu region, extracting trajectory-conditioned Zones of Influence (ZOI) to reveal recurrent airspace structures and localized deviations.", "AI": {"tldr": "本文提出了自适应密度场（ADF）框架，将空间聚集作为查询条件下的度量诱导注意操作，并通过FAISS加速近似最近邻搜索来实现可扩展性。", "motivation": "为了在保持物理距离的基础上改进空间影响模型，引入了结合自适应核方法和注意力机制的几何注意力框架。", "method": "ADF将空间聚集视为查询条件下的度量诱导注意操作，并使用FAISS加速近似最近邻搜索来提高效率。通过案例研究展示了该框架的应用。", "result": "在成都地区的飞机轨迹分析中，提取了基于轨迹的影响区（ZOI），揭示了空域结构的重复出现和局部偏差。", "conclusion": "ADF提供了一种有效的空间建模方法，结合了自适应核方法和注意力机制的优点，并通过FAISS加速近似最近邻搜索提高了可扩展性。"}}
{"id": "2601.06133", "pdf": "https://arxiv.org/pdf/2601.06133", "abs": "https://arxiv.org/abs/2601.06133", "authors": ["Wonhyeok Choi", "Minwoo Choi", "Jungwan Woo", "Kyumin Hwang", "Jaeyeul Kim", "Sunghoon Im"], "title": "A Review of Online Diffusion Policy RL Algorithms for Scalable Robotic Control", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Diffusion policies have emerged as a powerful approach for robotic control, demonstrating superior expressiveness in modeling multimodal action distributions compared to conventional policy networks. However, their integration with online reinforcement learning remains challenging due to fundamental incompatibilities between diffusion model training objectives and standard RL policy improvement mechanisms. This paper presents the first comprehensive review and empirical analysis of current Online Diffusion Policy Reinforcement Learning (Online DPRL) algorithms for scalable robotic control systems. We propose a novel taxonomy that categorizes existing approaches into four distinct families -- Action-Gradient, Q-Weighting, Proximity-Based, and Backpropagation Through Time (BPTT) methods -- based on their policy improvement mechanisms. Through extensive experiments on a unified NVIDIA Isaac Lab benchmark encompassing 12 diverse robotic tasks, we systematically evaluate representative algorithms across five critical dimensions: task diversity, parallelization capability, diffusion step scalability, cross-embodiment generalization, and environmental robustness. Our analysis identifies key findings regarding the fundamental trade-offs inherent in each algorithmic family, particularly concerning sample efficiency and scalability. Furthermore, we reveal critical computational and algorithmic bottlenecks that currently limit the practical deployment of online DPRL. Based on these findings, we provide concrete guidelines for algorithm selection tailored to specific operational constraints and outline promising future research directions to advance the field toward more general and scalable robotic learning systems.", "AI": {"tldr": "本文综述并实验分析了用于规模化机器人控制的在线扩散策略强化学习算法。", "motivation": "扩散模型在机器人控制中表现出色，但将其与在线强化学习结合面临挑战。为解决这一问题并推动该领域的研究进展，作者进行了系统性的综述和实证分析。", "method": "提出了一个基于改进机制的新分类体系，并通过NVIDIA Isaac Lab基准测试对多种算法进行评估。", "result": "识别出了各种算法在样本效率和可扩展性方面的固有折衷。揭示了限制在线DPRL实际应用的计算和算法瓶颈。", "conclusion": "根据研究结果提供了针对特定操作约束的选择指南，并指明未来研究的方向，以推动更加通用和可伸缩的机器人学习系统的发展。"}}
{"id": "2601.06132", "pdf": "https://arxiv.org/pdf/2601.06132", "abs": "https://arxiv.org/abs/2601.06132", "authors": ["Rohitash Chandra", "Haoyan Chen", "Yaqing Zhang", "Jiacheng Chen", "Yuting Wu"], "title": "An evaluation of LLMs for political bias in Western media: Israel-Hamas and Ukraine-Russia wars", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": null, "summary": "Political bias in media plays a critical role in shaping public opinion, voter behaviour, and broader democratic discourse. Subjective opinions and political bias can be found in media sources, such as newspapers, depending on their funding mechanisms and alliances with political parties. Automating the detection of political biases in media content can limit biases in elections. The impact of large language models (LLMs) in politics and media studies is becoming prominent. In this study, we utilise LLMs to compare the left-wing, right-wing, and neutral political opinions expressed in the Guardian and BBC. We review newspaper reporting that includes significant events such as the Russia-Ukraine war and the Hamas-Israel conflict. We analyse the proportion for each opinion to find the bias under different LLMs, including BERT, Gemini, and DeepSeek. Our results show that after the outbreak of the wars, the political bias of Western media shifts towards the left-wing and each LLM gives a different result. DeepSeek consistently showed a stable Left-leaning tendency, while BERT and Gemini remained closer to the Centre. The BBC and The Guardian showed distinct reporting behaviours across the two conflicts. In the Russia-Ukraine war, both outlets maintained relatively stable positions; however, in the Israel-Hamas conflict, we identified larger political bias shifts, particularly in Guardian coverage, suggesting a more event-driven pattern of reporting bias. These variations suggest that LLMs are shaped not only by their training data and architecture, but also by underlying worldviews with associated political biases.", "AI": {"tldr": "研究利用大型语言模型评估西方媒体在以色列-哈马斯冲突和俄罗斯-乌克兰战争中的政治偏见。", "motivation": "政治偏见影响公众舆论和民主讨论，自动化检测媒体内容的政治偏见有助于减少选举偏见。大型语言模型在政治与媒体研究中日益重要，本研究旨在利用这些技术分析西方主流报纸的政治倾向。", "method": "使用BERT、Gemini和DeepSeek等大型语言模型比较《卫报》和BBC的左翼、右翼及中立观点比例，并分析两个冲突事件中的报道差异。", "result": "战争爆发后，西方媒体的政治偏见向左倾转移。DeepSeek显示稳定左倾倾向，而BERT和Gemini更接近中间立场。两场冲突中，《卫报》的报道表现出明显政治偏见变化，特别是在以色列-哈马斯冲突中更为显著。", "conclusion": "大型语言模型不仅受到训练数据的影响，还可能具有与之相关的世界观及政治偏见；媒体报道的政治偏见会根据事件的不同而有所变化。"}}
{"id": "2601.06129", "pdf": "https://arxiv.org/pdf/2601.06129", "abs": "https://arxiv.org/abs/2601.06129", "authors": ["Ahmed Dawoud", "Sondos Samir", "Mahmoud Mohamed"], "title": "Graph-Based Analysis of AI-Driven Labor Market Transitions: Evidence from 10,000 Egyptian Jobs and Policy Implications", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "How many workers displaced by automation can realistically transition to safer jobs? We answer this using a validated knowledge graph of 9,978 Egyptian job postings, 19,766 skill activities, and 84,346 job-skill relationships (0.74% error rate). While 20.9% of jobs face high automation risk, we find that only 24.4% of at-risk workers have viable transition pathways--defined by $\\geq$3 shared skills and $\\geq$50% skill transfer. The remaining 75.6% face a structural mobility barrier requiring comprehensive reskilling, not incremental upskilling. Among 4,534 feasible transitions, process-oriented skills emerge as the highest-leverage intervention, appearing in 15.6% of pathways. These findings challenge optimistic narratives of seamless workforce adaptation and demonstrate that emerging economies require active pathway creation, not passive skill matching.", "AI": {"tldr": "本文通过分析埃及劳动力市场的数据，评估了因自动化而面临失业风险的工人转移到安全职位的可能性。", "motivation": "探讨在高度自动化的背景下，有多少工人能够从被取代的工作中顺利过渡到新的工作岗位。", "method": "使用经过验证的知识图谱，包括9,978个埃及工作职位、19,766项技能活动和84,346个工作-技能关系来分析。", "result": "发现20.9%的工作面临高自动化风险；只有24.4%的在风险中的工人有可行的职业转换路径，其余75.6%需要全面再培训。流程导向型技能被识别为最有效的干预措施。", "conclusion": "研究结果表明劳动力市场适应性并非乐观，并强调新兴经济体应主动创造职业转换路径而不是被动匹配技能。"}}
{"id": "2601.06127", "pdf": "https://arxiv.org/pdf/2601.06127", "abs": "https://arxiv.org/abs/2601.06127", "authors": ["SM Ashfaq uz Zaman", "Faizan Qamar", "Masnizah Mohd", "Nur Hanis Sabrina Suhaimi", "Amith Khandakar"], "title": "AIS-CycleGen: A CycleGAN-Based Framework for High-Fidelity Synthetic AIS Data Generation and Augmentation", "categories": ["cs.LG", "cs.AI"], "comment": "25 pages, 16 figures", "summary": "Automatic Identification System (AIS) data are vital for maritime domain awareness, yet they often suffer from domain shifts, data sparsity, and class imbalance, which hinder the performance of predictive models. In this paper, we propose a robust data augmentation method, AISCycleGen, based on Cycle-Consistent Generative Adversarial Networks (CycleGAN), which is tailored for AIS datasets. Unlike traditional methods, AISCycleGen leverages unpaired domain translation to generate high-fidelity synthetic AIS data sequences without requiring paired source-target data. The framework employs a 1D convolutional generator with adaptive noise injection to preserve the spatiotemporal structure of AIS trajectories, enhancing the diversity and realism of the generated data. To demonstrate its efficacy, we apply AISCycleGen to several baseline regression models, showing improvements in performance across various maritime domains. The results indicate that AISCycleGen outperforms contemporary GAN-based augmentation techniques, achieving a PSNR value of 30.5 and an FID score of 38.9. These findings underscore AISCycleGen's potential as an effective and generalizable solution for augmenting AIS datasets, improving downstream model performance in real-world maritime intelligence applications.", "AI": {"tldr": "提出了一种基于CycleGAN的AIS数据生成和增强框架，用于提高预测模型性能。", "motivation": "为了应对AIS数据在领域转换、数据稀疏性和类别不平衡方面的问题，提出了一个基于CycleGAN的数据增强方法AISCycleGen。", "method": "采用1D卷积生成器并引入自适应噪声以保持AIS轨迹的时空结构，利用无配对域翻译来生成高保真合成AIS数据序列。", "result": "实验结果显示，与现有GAN技术相比，AISCycleGen在PSNR值为30.5和FID得分为38.9的情况下性能更优。", "conclusion": "该框架可以作为有效且通用的解决方案来增强AIS数据集，并提高实际海事智能应用中的下游模型表现。"}}
{"id": "2601.06126", "pdf": "https://arxiv.org/pdf/2601.06126", "abs": "https://arxiv.org/abs/2601.06126", "authors": ["Boshen Shi", "Kexin Yang", "Yuanbo Yang", "Guanguang Chang", "Ce Chi", "Zhendong Wang", "Xing Wang", "Junlan Feng"], "title": "NL2Dashboard: A Lightweight and Controllable Framework for Generating Dashboards with LLMs", "categories": ["cs.AI"], "comment": null, "summary": "While Large Language Models (LLMs) have demonstrated remarkable proficiency in generating standalone charts, synthesizing comprehensive dashboards remains a formidable challenge. Existing end-to-end paradigms, which typically treat dashboard generation as a direct code generation task (e.g., raw HTML), suffer from two fundamental limitations: representation redundancy due to massive tokens spent on visual rendering, and low controllability caused by the entanglement of analytical reasoning and presentation. To address these challenges, we propose NL2Dashboard, a lightweight framework grounded in the principle of Analysis-Presentation Decoupling. We introduce a structured intermediate representation (IR) that encapsulates the dashboard's content, layout, and visual elements. Therefore, it confines the LLM's role to data analysis and intent translation, while offloading visual synthesis to a deterministic rendering engine. Building upon this framework, we develop a multi-agent system in which the IR-driven algorithm is instantiated as a suite of tools. Comprehensive experiments conducted with this system demonstrate that NL2Dashboard significantly outperforms state-of-the-art baselines across diverse domains, achieving superior visual quality, significantly higher token efficiency, and precise controllability in both generation and modification tasks.", "AI": {"tldr": "本文提出了NL2Dashboard，一个基于大语言模型的轻量级框架用于生成仪表板。", "motivation": "现有直接代码生成方法在生成复杂仪表板时存在表示冗余和低控制性的问题。为了克服这些挑战，提出了一种新的分析呈现解耦的方法。", "method": "引入了结构化的中间表示形式（IR），该框架将数据解析与呈现分离，并使用一个确定性的渲染引擎进行可视化合成。", "result": "实验结果表明，NL2Dashboard在生成和修改任务中都优于现有方法，在视觉质量、令牌效率以及控制性方面表现出色。", "conclusion": "通过分析-展示解耦的原理，提出了一个新的轻量级框架，并展示了其在生成高质量仪表板方面的优势。"}}
{"id": "2601.06123", "pdf": "https://arxiv.org/pdf/2601.06123", "abs": "https://arxiv.org/abs/2601.06123", "authors": ["Lucio M. Dery", "Zohar Yahav", "Henry Prior", "Qixuan Feng", "Jiajun Shen", "Arthur Szlam"], "title": "Latent Space Communication via K-V Cache Alignment", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages, 6 figures, 4 tables", "summary": "Solving increasingly complex problems with large language models (LLMs) necessitates a move beyond individual models and towards multi-model systems that can effectively collaborate. While text has traditionally served as the medium for inter-model communication, a richer and more efficient exchange is possible if models can access each other's internal states directly. In this paper, we propose learning a shared representation space that aligns the k-v caches of multiple models, creating a high-bandwidth channel for collaboration without altering the underlying pre-trained parameters. We do so by augmenting each model with adapters to translate its state into and out of this shared space. Via a suite of experiments with Gemma-2 models, we demonstrate that this approach not only enables seamless inter-model communication but also improves individual model performance. We also show that the shared space allows for the direct transfer of learned skills, such as soft prompts, between different models. Our work represents a significant step towards a future where models can fluidly share knowledge and capabilities.", "AI": {"tldr": "提出了一种通过学习共享表示空间来对多个模型的k-v缓存进行对齐的方法，以实现高效的跨模型通信。", "motivation": "随着问题复杂度的增加和大型语言模型的发展，传统的文本作为中间媒介的方式在多模型协作中显得效率低下。为了提高沟通效率并增强模型性能，研究提出了一种新的方法来直接访问模型内部状态。", "method": "通过为每个模型添加适配器以将其状态转换到共享空间，并从该空间反向翻译出来，实现跨模型的高效通信和知识转移。", "result": "实验结果表明，所提方案不仅提高了跨模型间的沟通效率，而且增强了各个模型自身的性能。此外，还证明了这种共享空间可以促进不同模型之间学习能力的直接传递。", "conclusion": "该研究标志着向一个更灵活的知识分享未来迈出了重要一步，在这个未来中，各种预训练语言模型能够无缝地共享知识和技能"}}
{"id": "2601.06122", "pdf": "https://arxiv.org/pdf/2601.06122", "abs": "https://arxiv.org/abs/2601.06122", "authors": ["Canming Xia", "Peixi Peng", "Guang Tan", "Zhan Su", "Haoran Xu", "Zhenxian Liu", "Luntong Li"], "title": "COVR:Collaborative Optimization of VLMs and RL Agent for Visual-Based Control", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "The paper was accepted by the Fortieth AAAI Conference on Artificial Intelligence (AAAI-26)", "summary": "Visual reinforcement learning (RL) suffers from poor sample efficiency due to high-dimensional observations in complex tasks. While existing works have shown that vision-language models (VLMs) can assist RL, they often focus on knowledge distillation from the VLM to RL, overlooking the potential of RL-generated interaction data to enhance the VLM. To address this, we propose COVR, a collaborative optimization framework that enables the mutual enhancement of the VLM and RL policies. Specifically, COVR fine-tunes the VLM with RL-generated data to enhance the semantic reasoning ability consistent with the target task, and uses the enhanced VLM to further guide policy learning via action priors. To improve fine-tuning efficiency, we introduce two key modules: (1) an Exploration-Driven Dynamic Filter module that preserves valuable exploration samples using adaptive thresholds based on the degree of exploration, and (2) a Return-Aware Adaptive Loss Weight module that improves the stability of training by quantifying the inconsistency of sampling actions via return signals of RL. We further design a progressive fine-tuning strategy to reduce resource consumption. Extensive experiments show that COVR achieves strong performance across various challenging visual control tasks.", "AI": {"tldr": "COVR是一种协作优化框架，旨在通过RL生成的数据增强VLM的语义推理能力，并利用改进的VLM来指导策略学习。", "motivation": "现有研究大多关注于从视觉语言模型（VLM）向强化学习（RL）的知识蒸馏，而忽略了RL交互数据对提升VLM潜力的作用。为了提高样本效率，COVR旨在通过协作优化实现两者能力的相互增强。", "method": "COVR框架包含两个关键模块：探索驱动动态过滤器和回报感知自适应损失权重模块，以提升训练稳定性和效率；同时采用渐进式微调策略减少资源消耗。", "result": "实验结果表明，在各种具有挑战性的视觉控制任务上，COVR均表现出色的性能。", "conclusion": "通过RL生成的数据增强VLM，并利用改进后的VLM指导政策学习，可以显著提高样本效率和性能。"}}
{"id": "2601.06121", "pdf": "https://arxiv.org/pdf/2601.06121", "abs": "https://arxiv.org/abs/2601.06121", "authors": ["Benjamin Quarshie", "Vanessa Willemse", "Macharious Nabang", "Bismark Nyaaba Akanzire", "Patrick Kyeremeh", "Saeed Maigari", "Dorcas Adomina", "Ellen Kwarteng", "Eric Kojo Majialuwe", "Craig Gibbs", "Jerry Etornam Kudaya", "Sechaba Koma", "Matthew Nyaaba Matthew Nyaaba"], "title": "Prompt Engineering for Responsible Generative AI Use in African Education: A Report from a Three-Day Training Series", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Generative artificial intelligence (GenAI) tools are increasingly adopted in education, yet many educators lack structured guidance on responsible and context sensitive prompt engineering, particularly in African and other resource constrained settings. This case report documents a three day online professional development programme organised by Generative AI for Education and Research in Africa (GenAI-ERA), designed to strengthen educators and researchers capacity to apply prompt engineering ethically for academic writing, teaching, and research. The programme engaged 468 participants across multiple African countries, including university educators, postgraduate students, and researchers. The training followed a scaffolded progression from foundational prompt design to applied and ethical strategies, including persona guided interactions. Data sources comprised registration surveys, webinar interaction records, facilitator observations, and session transcripts, analysed using descriptive statistics and computationally supported qualitative techniques. Findings indicate that participants increasingly conceptualised prompt engineering as a form of AI literacy requiring ethical awareness, contextual sensitivity, and pedagogical judgement rather than technical skill alone. The case highlights persistent challenges related to access, locally relevant training materials, and institutional support. The report recommends sustained professional development and the integration of prompt literacy into curricula to support responsible GenAI use in African education systems.", "AI": {"tldr": "报告记录了一个为期三天的在线专业发展计划，旨在增强教育工作者和研究人员在非洲应用提示工程的能力。", "motivation": "许多教育工作者缺乏有关负责任且具有上下文敏感性的提示工程结构化指导，特别是在资源有限的情况下。这项研究旨在解决这一问题，提高教育者对AI伦理使用、文化和教育背景的理解以及他们制定学术写作、教学和研究策略的能力。", "method": "培训采用分阶段的方式进行，从基础的提示设计到应用和道德策略。数据来源包括注册调查、网络研讨会互动记录、观察员的观点以及会议录音，并通过描述性统计方法和计算辅助定性技术进行了分析。", "result": "参与者越来越认识到提示工程是一种需要伦理意识、上下文敏感性和教学判断力的人工智能素养，而不仅仅是技术技能。该研究发现了持续的挑战，包括访问障碍、相关培训材料不足和机构支持不够的问题。", "conclusion": "推荐持续的专业发展和将提示素养整合到课程中以促进非洲教育系统中负责任地使用GenAI。"}}
{"id": "2601.06119", "pdf": "https://arxiv.org/pdf/2601.06119", "abs": "https://arxiv.org/abs/2601.06119", "authors": ["Dileepa Pitawela", "Gustavo Carneiro", "Hsiang-Ting Chen"], "title": "L2CU: Learning to Complement Unseen Users", "categories": ["cs.LG", "cs.AI", "cs.HC"], "comment": "Published in IEEE Access (https://ieeexplore.ieee.org/document/11314492)", "summary": "Recent research highlights the potential of machine learning models to learn to complement (L2C) human strengths; however, generalizing this capability to unseen users remains a significant challenge. Existing L2C methods oversimplify interaction between human and AI by relying on a single, global user model that neglects individual user variability, leading to suboptimal cooperative performance. Addressing this, we introduce L2CU, a novel L2C framework for human-AI cooperative classification with unseen users. Given sparse and noisy user annotations, L2CU identifies representative annotator profiles capturing distinct labeling patterns. By matching unseen users to these profiles, L2CU leverages profile-specific models to complement the user and achieve superior joint accuracy. We evaluate L2CU on datasets (CIFAR-10N, CIFAR-10H, Fashion-MNIST-H, Chaoyang and AgNews), demonstrating its effectiveness as a model-agnostic solution for improving human-AI cooperative classification.", "AI": {"tldr": "提出了一种新的L2CU框架，用于在未见用户情况下的人机协作分类。", "motivation": "现有L2C方法通过单一全局模型简化人机交互，忽略了用户的个体差异，导致合作效果不佳。因此需要一种能够适应新用户的解决方案。", "method": "L2CU框架通过对稀疏且嘈杂的用户注释进行分析来识别代表性的标注者个人资料，并将其与未见用户匹配以利用特定于配置文件的模型提高协作准确性。", "result": "在CIFAR-10N、CIFAR-10H、Fashion-MNIST-H、Chaoyang和AgNews等数据集上的实验表明，L2CU能够有效提升人机协同分类效果。", "conclusion": "L2CU是一种模型无关的解决方案，能够在未见用户情况下显著改善人类与AI的合作分类准确性。"}}
{"id": "2601.06118", "pdf": "https://arxiv.org/pdf/2601.06118", "abs": "https://arxiv.org/abs/2601.06118", "authors": ["Tairan Fu", "Gonzalo Martínez", "Javier Conde", "Carlos Arriaga", "Pedro Reviriego", "Xiuyuan Qi", "Shanshan Liu"], "title": "Beyond Reproducibility: Token Probabilities Expose Large Language Model Nondeterminism", "categories": ["cs.AI"], "comment": null, "summary": "The execution of Large Language Models (LLMs) has been shown to produce nondeterministic results when run on Graphics Processing Units (GPUs), even when they are configured to produce deterministic results. This is due to the finite precision effects of the arithmetic operations, which depend on the order in which they are executed. This order, in turn, depends on the processes that are running concurrently on the GPU. Previous studies have focused on the impact of nondeterminism on the text generated by the LLMs or on proposing mechanisms to achieve deterministic execution. This work takes a closer look at nondeterminism by analyzing the variations on the token probabilities, not on the generated text. Interestingly, all the models evaluated have similar results in both the trends and the actual values of the variations of the probabilities. In particular, the results show that the effects of nondeterminism are significant for token probabilities that are in the range of 0.1 to 0.9, while they are much smaller when the probabilities are close to 0 or 1. This has significant implications for our understanding of nondeterminism. The first is that nondeterminism will likely have a non-negligible impact on generated text when the temperature is not zero, as it introduces significant variations in the token probabilities except when they are close to 0 or 1. Secondly, it suggests that all models have similar non deterministic variations at the token probability level. Therefore, different variations in the performance of the generated text, for example, when measuring accuracy on a benchmark, seem to come from different token probabilities or response lengths. A third implication is that we may be able to estimate the impact of nondeterminism by running a single inference and analyzing the token level probabilities, instead of having to run the same inference many times.", "AI": {"tldr": "论文研究了大型语言模型（LLM）在GPU上执行时的非确定性影响，通过分析令牌概率而非生成文本的变化来探讨这一问题。", "motivation": "先前的研究主要集中在LLM产生的文本变化或实现确定性执行的方法。本工作更深入地研究非确定性对令牌概率的影响，并发现这种影响对于某些特定的概率值范围尤为显著。", "method": "通过分析不同模型在特定条件下令牌概率的变化，论文揭示了非确定性的具体表现及其对生成文本的潜在影响。", "result": "结果表明，非确定性主要影响0.1到0.9之间的令牌概率，并且这种变化在温度不为零时更为明显。所有测试模型都显示出类似的趋势和数值变异性。", "conclusion": "研究表明可以通过分析单次推理中的令牌概率来估计非确定性的程度，这有助于理解生成文本的差异性来源以及如何应对这些挑战。"}}
{"id": "2601.06116", "pdf": "https://arxiv.org/pdf/2601.06116", "abs": "https://arxiv.org/abs/2601.06116", "authors": ["Ian Rios-Sialer"], "title": "Structure-Aware Diversity Pursuit as an AI Safety Strategy against Homogenization", "categories": ["cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "Generative AI models reproduce the biases in the training data and can further amplify them through mode collapse. We refer to the resulting harmful loss of diversity as homogenization. Our position is that homogenization should be a primary concern in AI safety. We introduce xeno-reproduction as the strategy that mitigates homogenization. For auto-regressive LLMs, we formalize xeno-reproduction as a structure-aware diversity pursuit. Our contribution is foundational, intended to open an essential line of research and invite collaboration to advance diversity.", "AI": {"tldr": "本文提出了针对生成式AI模型中同质化问题的解决方案，即通过结构感知多样性追求策略减轻该问题。", "motivation": "生成式AI模型会复制训练数据中的偏见，并可能通过模式坍缩进一步放大这些问题。这种有害的多样性的丧失被称为同质化，是AI安全性的重要关注点。", "method": "本文将解决同质化的策略形式化为结构感知多样性追求，特别是针对自回归LLM提出了xeno-再生产的方法。", "result": "论文的基础贡献在于提出了一种减轻生成式AI模型中偏见放大和模式坍缩问题的解决方案，并旨在开启相关研究领域以促进多样性的进一步探索。", "conclusion": "通过结构感知多样性追求策略，可以有效地减轻生成式AI模型中的同质化问题。该方法有望成为未来AI安全性的重要方向之一。"}}
{"id": "2601.06115", "pdf": "https://arxiv.org/pdf/2601.06115", "abs": "https://arxiv.org/abs/2601.06115", "authors": ["V. Cheung"], "title": "Dreaming Is Not a Bug: A Jung-Inspired Dream Layer for Multi-Agent LLM Companions", "categories": ["cs.AI"], "comment": "Preprint, 35 pages (5 pages of appendix), 2 figures, 3 tables. Conceptual and architectural proposal with preliminary simulation results", "summary": "Inspired by a personal dream about knowledge-sharing barriers in an everyday hardware project, this paper proposes a Jung-inspired \"Dream Layer\" for LLM companions, reframing controlled offline hallucinations as a resource for learning and relationship-building rather than a mere reliability bug. Drawing on Jung's notion of the collective unconscious as a shared repository of archetypal forms, we introduce an Artificial Collective Unconscious (ACU): a shared dream pool where agents contribute de-identified, abstract Interaction Templates that are later re-instantiated as idiosyncratic Dream Narratives. The Dream Layer runs strictly offline: logic-enforcing modules are relaxed and sampling temperature is increased, yielding safe but deliberately bizarre narratives (e.g., travel sequences with mismatched currencies) that augment data for rare events and edge-case safety tests; to harness risk productively, we add a governance stack of strict abstraction, temporal delays, and ephemeral memory. Through behavioural simulations of everyday dialogue and long-horizon adaptation tasks, we show that the Dream Layer enables a critical decoupling: agents remain firm on safety constraints (e.g., security policies) while becoming flexible in narrative strategy (e.g., using shared archetypal metaphors to resolve deadlocks), conceptually reframing hallucination so that online, unmarked instances remain bugs, whereas bounded, marked, and delayed ones become a goldmine for synthetic scenarios and deepened companionship, echoing anti-overfitting dream mechanisms proposed in contemporary neuroscience.", "AI": {"tldr": "本文提出了一种受荣格理论启发的\"梦境层\"，用于多代理LLM伴侣，以控制离线幻觉作为学习和关系建设的一种资源。", "motivation": "受到个人关于知识共享障碍的梦想启示，本文旨在将可控的离线幻觉重新定义为一种学习资源，并利用它来建立更深层次的人际关系。", "method": "通过引入人工集体无意识(ACU)，实现了一个梦境池，其中代理贡献去识别化的交互模板，在随后被转化为个性化的梦境叙述。该梦境层完全在线下运行：逻辑执行模块放松且采样温度增加，生成安全但刻意怪诞的叙事来增强稀有事件和极限测试的数据。", "result": "通过日常对话和长期适应任务的行为模拟显示，梦境层使得代理能够在保持安全性约束的同时灵活运用叙述策略，并重新定义幻觉的概念，使其在在线情境下仍是错误，在离线标记情况下则成为合成场景和深化人际关系的宝库。", "conclusion": "该研究提出的方法能够有效地将受控离线幻视为一种宝贵的资源，促进多代理LLM伴侣的学习与关系建设。"}}
{"id": "2601.06114", "pdf": "https://arxiv.org/pdf/2601.06114", "abs": "https://arxiv.org/abs/2601.06114", "authors": ["Jinwoong Kim", "Sangjin Park"], "title": "GroupSegment-SHAP: Shapley Value Explanations with Group-Segment Players for Multivariate Time Series", "categories": ["cs.LG", "cs.AI", "cs.GT"], "comment": "12 pages", "summary": "Multivariate time-series models achieve strong predictive performance in healthcare, industry, energy, and finance, but how they combine cross-variable interactions with temporal dynamics remains unclear. SHapley Additive exPlanations (SHAP) are widely used for interpretation. However, existing time-series variants typically treat the feature and time axes independently, fragmenting structural signals formed jointly by multiple variables over specific intervals. We propose GroupSegment SHAP (GS-SHAP), which constructs explanatory units as group-segment players based on cross-variable dependence and distribution shifts over time, and then quantifies each unit's contribution via Shapley attribution. We evaluate GS-SHAP across four real-world domains: human activity recognition, power-system forecasting, medical signal analysis, and financial time series, and compare it with KernelSHAP, TimeSHAP, SequenceSHAP, WindowSHAP, and TSHAP. GS-SHAP improves deletion-based faithfulness (DeltaAUC) by about 1.7x on average over time-series SHAP baselines, while reducing wall-clock runtime by about 40 percent on average under matched perturbation budgets. A financial case study shows that GS-SHAP identifies interpretable multivariate-temporal interactions among key market variables during high-volatility regimes.", "AI": {"tldr": "该论文提出了GroupSegment SHAP（GS-SHAP）方法，用于解释多变量时间序列模型中的交互和动态。", "motivation": "现有的时间序列SHAP变体通常将特征轴和时间轴独立处理，这会导致结构信号的碎片化。为此，作者提出了一种新的解释框架以更好地结合跨变量依赖性和分布变化来构造解释单元。", "method": "GS-SHAP通过基于跨变量相关性与随时间的变化构造组段玩家，并利用Shapley分配量化每个单位的贡献。", "result": "在四个真实世界的领域中，GS-SHAP提高了删除忠实度（DeltaAUC），平均提高了1.7倍；同时减少了约40％的时间消耗。", "conclusion": "GS-SHAP能够更好地解释多变量时间序列模型中的交互和动态，并且在实际应用中表现出色。"}}
{"id": "2601.06113", "pdf": "https://arxiv.org/pdf/2601.06113", "abs": "https://arxiv.org/abs/2601.06113", "authors": ["Nitin Vetcha"], "title": "Towards Infinite Length Extrapolation: A Unified Approach", "categories": ["cs.AI"], "comment": "14 pages, 7 figures", "summary": "Large language models (LLMs) have revolutionized natural language processing, but their ability to process long sequences is fundamentally limited by the context window size during training. Existing length extrapolation methods often suffer from performance degradation or computational inefficiencies. We thereby use a unified framework that reinterprets positional encoding methods as a decomposition of the attention score into a multiplicative transformation and an additive bias. This perspective not only subsumes popular approaches such as relative position embeddings and attention-bias moderated approaches but also exposes their inherent limitations in handling long-range dependencies. To address these shortcomings, motivated by our framework, we introduce Adaptive Positional Encoding (APE), which leverages adaptive frequency modulation and an intricately designed decay bias that incorporates linear, logarithmic, and square-root terms. Our theoretical analysis establishes conditions for infinite-context extrapolation, ensuring that the softmax normalization remains well-defined over unbounded sequences while preserving long-distance correlations, entropy boundedness and gradient positional sensitivity. We substantiate our claims with an experimental case study on TinyStories dataset as well as a new synthetic dataset, \\emph{Long Tiny Stories} featuring stories up to 32,000 words. Relevant code, dataset and model weights are available at https://anonymous.4open.science/r/Check-2DAD/.", "AI": {"tldr": "本文提出了一种适应性位置编码（APE）方法，用于解决大型语言模型处理长序列时的性能下降和计算效率低下问题。", "motivation": "现有长度外推方法存在性能降级或计算低效的问题。通过引入一种统一框架重新解释位置编码方式，发现了它们在处理远程依赖性方面的局限，并据此提出了适应性位置编码（APE）以解决这些问题。", "method": "本文提出了一种新的方法——适应性位置编码（APE），该方法结合了自适应频率调制和精心设计的衰减偏置，包括线性、对数和平方根项。它保证了在无限上下文外推时softmax归一化仍然有效，并保持长距离相关性和熵有界。", "result": "通过在TinyStories数据集以及新的合成数据集“Long Tiny Stories”上的实验案例研究证明了该方法的有效性，后者包含长达32000词的故事。", "conclusion": "适应性位置编码（APE）能够有效地处理长序列，并保持模型的性能和计算效率。"}}
{"id": "2601.06112", "pdf": "https://arxiv.org/pdf/2601.06112", "abs": "https://arxiv.org/abs/2601.06112", "authors": ["Aayush Gupta"], "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "categories": ["cs.AI"], "comment": "18 pages, 5 figures, 8 tables. Evaluates ReAct vs Reflexion across four tool-using domains with perturbation (epsilon) and fault-injection (lambda) stress testing; 1,280 total episodes", "summary": "Existing benchmarks for tool-using LLM agents primarily report single-run success rates and miss reliability properties required in production. We introduce \\textbf{ReliabilityBench}, a benchmark for evaluating agent reliability across three dimensions: (i) consistency under repeated execution using $\\mathrm{pass}^k$, (ii) robustness to semantically equivalent task perturbations at intensity $ε$, and (iii) fault tolerance under controlled tool/API failures at intensity $λ$. ReliabilityBench contributes a unified reliability surface $R(k,ε,λ)$, \\textit{action metamorphic relations} that define correctness via end-state equivalence rather than text similarity, and a chaos-engineering-style fault injection framework (timeouts, rate limits, partial responses, schema drift). We evaluate two models (Gemini 2.0 Flash, GPT-4o) and two agent architectures (ReAct, Reflexion) across four domains (scheduling, travel, customer support, e-commerce) over 1,280 episodes. Perturbations alone reduce success from 96.9% at $ε=0$ to 88.1% at $ε=0.2$. Rate limiting is the most damaging fault in ablations. ReAct is more robust than Reflexion under combined stress, and Gemini 2.0 Flash achieves comparable reliability to GPT-4o at much lower cost. ReliabilityBench provides a systematic framework for assessing production readiness of LLM agents.", "AI": {"tldr": "该论文介绍了一种名为ReliabilityBench的新基准，用于评估大型语言模型代理在生产环境下的可靠性。", "motivation": "现有工具使用LLM代理的基准测试主要关注单一执行的成功率，忽略了实际应用中所需的可靠性属性。因此需要一种新的方法来全面衡量代理的可靠性。", "method": "ReliabilityBench通过三个维度评估代理的可靠性：一致性、鲁棒性和容错性，并引入了统一的可靠性表面R(k,ε,λ)和故障注入框架进行测试。", "result": "在一系列实验中，ReliabilityBench展示了不同模型和架构之间的性能差异，例如ReAct比Reflexion更稳健，Gemini 2.0 Flash与GPT-4o具有相似的可靠性但成本更低。", "conclusion": "ReliabilityBench提供了一套系统性框架来评估大型语言模型代理在生产环境下的准备情况。"}}
{"id": "2601.06111", "pdf": "https://arxiv.org/pdf/2601.06111", "abs": "https://arxiv.org/abs/2601.06111", "authors": ["Aayush Gupta", "Farahan Raza Sheikh"], "title": "LLM-Powered Social Digital Twins: A Framework for Simulating Population Behavioral Response to Policy Interventions", "categories": ["cs.AI", "cs.CY"], "comment": "13 pages, 1 figure, 4 tables", "summary": "Predicting how populations respond to policy interventions is a fundamental challenge in computational social science and public policy. Traditional approaches rely on aggregate statistical models that capture historical correlations but lack mechanistic interpretability and struggle with novel policy scenarios. We present a general framework for constructing Social Digital Twins - virtual population replicas where Large Language Models (LLMs) serve as cognitive engines for individual agents. Each agent, characterized by demographic and psychographic attributes, receives policy signals and outputs multi-dimensional behavioral probability vectors. A calibration layer maps aggregated agent responses to observable population-level metrics, enabling validation against real-world data and deployment for counterfactual policy analysis. We instantiate this framework in the domain of pandemic response, using COVID-19 as a case study with rich observational data. On a held-out test period, our calibrated digital twin achieves a 20.7% improvement in macro-averaged prediction error over gradient boosting baselines across six behavioral categories. Counterfactual experiments demonstrate monotonic and bounded responses to policy variations, establishing behavioral plausibility. The framework is domain-agnostic: the same architecture applies to transportation policy, economic interventions, environmental regulations, or any setting where policy affects population behavior. We discuss implications for policy simulation, limitations of the approach, and directions for extending LLM-based digital twins beyond pandemic response.", "AI": {"tldr": "构建基于大型语言模型的社会数字孪生框架，用于模拟人口对政策干预的反应。", "motivation": "预测人群对政策干预的响应是计算社会科学和公共政策的基本挑战。传统方法依赖于历史统计模型缺乏机理解释能力，并且难以处理新的政策情景。", "method": "提出了一种利用大型语言模型作为认知引擎构建社会数字孪生体的方法，每个代理具有人口学和心理图谱属性，在接收政策信号后输出多维行为概率向量。通过校准层将个体响应聚合到可观测的群体指标上，验证真实数据并进行反事实政策分析。", "result": "在COVID-19疫情回应领域，框架实现了比梯度提升基线模型20.7%的改进预测误差，并且实验表明对政策变化有单调和有限的行为反应。", "conclusion": "该框架具有跨领域的适用性，可用于交通、经济、环境等政策影响下的人口行为模拟。讨论了其在政策仿真中的应用、局限性和未来扩展方向。"}}
{"id": "2601.06109", "pdf": "https://arxiv.org/pdf/2601.06109", "abs": "https://arxiv.org/abs/2601.06109", "authors": ["Ahmed H. Ismail", "Anthony Kuang", "Ayo Akinkugbe", "Kevin Zhu", "Sean O'Brien"], "title": "CBMAS: Cognitive Behavioral Modeling via Activation Steering", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted to CogInterp @ NeurIPS 2025. Equal contribution by Ahmed H. Ismail and Anthony Kuang", "summary": "Large language models (LLMs) often encode cognitive behaviors unpredictably across prompts, layers, and contexts, making them difficult to diagnose and control. We present CBMAS, a diagnostic framework for continuous activation steering, which extends cognitive bias analysis from discrete before/after interventions to interpretable trajectories. By combining steering vector construction with dense α-sweeps, logit lens-based bias curves, and layer-site sensitivity analysis, our approach can reveal tipping points where small intervention strengths flip model behavior and show how steering effects evolve across layer depth. We argue that these continuous diagnostics offer a bridge between high-level behavioral evaluation and low-level representational dynamics, contributing to the cognitive interpretability of LLMs. Lastly, we provide a CLI and datasets for various cognitive behaviors at the project repository, https://github.com/shimamooo/CBMAS.", "AI": {"tldr": "CBMAS是一种用于大型语言模型的认知行为诊断框架，通过连续激活引导揭示模型行为的演化。", "motivation": "为了更好地理解和控制大型语言模型中的认知行为，需要一种能够提供可解释性轨迹的方法来解决预测难和难以调试的问题。", "method": "结合导向向量构建、密集α-扫描、基于logit镜头的认知偏差曲线及层位置敏感性分析，CBMAS揭示了小干预强度下翻转模型行为的临界点，并展示了引导效应随层次深度的变化。", "result": "通过该框架可以观察到认知行为如何从一个状态平滑地过渡到另一个状态，提供了高层级行为评估与低层级表示动态之间的桥梁。", "conclusion": "CBMAS为大型语言模型的认知可解释性贡献了新的视角和工具，增强了对模型内部机制的理解。"}}
{"id": "2601.06108", "pdf": "https://arxiv.org/pdf/2601.06108", "abs": "https://arxiv.org/abs/2601.06108", "authors": ["Tarun Raheja", "Nilay Pochhi"], "title": "From RLHF to Direct Alignment: A Theoretical Unification of Preference Learning for Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Aligning large language models (LLMs) with human preferences has become essential for safe and beneficial AI deployment. While Reinforcement Learning from Human Feedback (RLHF) established the dominant paradigm, a proliferation of alternatives -- Direct Preference Optimization (DPO), Identity Preference Optimization (IPO), Kahneman-Tversky Optimization (KTO), Simple Preference Optimization (SimPO), and many others -- has left practitioners without clear guidance on method selection. This survey provides a \\textit{theoretical unification} of preference learning methods, revealing that the apparent diversity reduces to principled choices along three orthogonal axes: \\textbf{(I) Preference Model} (what likelihood model underlies the objective), \\textbf{(II) Regularization Mechanism} (how deviation from reference policies is controlled), and \\textbf{(III) Data Distribution} (online vs.\\ offline learning and coverage requirements). We formalize each axis with precise definitions and theorems, establishing key results including the coverage separation between online and offline methods, scaling laws for reward overoptimization, and conditions under which direct alignment methods fail. Our analysis reveals that failure modes -- length hacking, mode collapse, likelihood displacement -- arise from specific, predictable combinations of design choices. We synthesize empirical findings across 50+ papers and provide a practitioner's decision guide for method selection. The framework transforms preference learning from an empirical art into a theoretically grounded discipline.", "AI": {"tldr": "本文提供了大型语言模型偏好学习方法的理论统一，揭示了不同方法之间的共性与差异，并提供了一个实践者选择合适方法的决策指南。", "motivation": "在大型语言模型（LLM）中实现人类偏好的对齐对于安全和有益的人工智能部署至关重要。虽然强化学习从人类反馈（RLHF）建立了主导范式，但偏好优化方法的多样化使从业者难以选择合适的方法。", "method": "本文通过三个正交轴的形式化定义与定理：(I) 偏好模型、(II) 正则机制和 (III) 数据分布来统一并分析了各种偏好数学习方法。", "result": "研究结果揭示了在线与离线方法之间的覆盖度分离、奖励过度优化的扩展法则以及直接对齐方法失败条件。此外，它还展示了长度操纵、模态塌陷等失效模式如何源于特定的设计选择组合。", "conclusion": "该框架将偏好学习从实验艺术转变为理论基础学科，并提供了实践者在众多偏好数学习方法中进行决策的指南"}}
{"id": "2601.06106", "pdf": "https://arxiv.org/pdf/2601.06106", "abs": "https://arxiv.org/abs/2601.06106", "authors": ["Min-Han Shih", "Yu-Hsin Wu", "Yu-Wei Chen"], "title": "Judge Model for Large-scale Multimodality Benchmarks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.MA"], "comment": null, "summary": "We propose a dedicated multimodal Judge Model designed to provide reliable, explainable evaluation across a diverse suite of tasks. Our benchmark spans text, audio, image, and video modalities, drawing from carefully sampled public datasets with fixed seeds to ensure reproducibility and minimize train test leakage. Instead of simple scoring, our framework aggregates multimodal judgments, analyzes the quality and reasoning consistency of model outputs, and generates diagnostic feedback. We evaluate several MLLMs, including Gemini 2.5, Phi 4, and Qwen 2.5, across 280 multimodal samples and compare judge model assessments with human annotators. Results show strong alignment between the Judge Model and human scores, demonstrating its potential as a scalable, interpretable evaluation pipeline for future multimodal AI research.", "AI": {"tldr": "提出了一种可靠的、可解释的多模态评估模型，用于大规模多模态基准测试。", "motivation": "为了提供跨多种任务类型的可靠且可解释的评估，设计了专门针对多模态数据集的Judge Model。", "method": "通过使用固定种子采样的公共数据集来确保可重复性，并从文本、音频、图像和视频等多模态输入中聚合判断并生成诊断反馈。", "result": "结果显示，Judge Model与人类评分具有高度一致性，表明其在大规模多模态评估中的潜力。", "conclusion": "该研究证明了所提出的Judge Model可以作为未来多模态AI研究的可扩展和解释性的评估工具。"}}
{"id": "2601.06104", "pdf": "https://arxiv.org/pdf/2601.06104", "abs": "https://arxiv.org/abs/2601.06104", "authors": ["Krzysztof Sienicki"], "title": "Comment on arXiv:2511.21731v1: Identifying Quantum Structure in AI Language: Evidence for Evolutionary Convergence of Human and Artificial Cognition", "categories": ["cs.AI", "cs.CL", "quant-ph"], "comment": "5 pages, 11 references", "summary": "This note is a friendly technical check of arXiv:2511.21731v1. I highlight a few places where the manuscript's interpretation of (i) the reported CHSH/Bell-type calculations and (ii) Bose--Einstein (BE) fits to rank-frequency data seems to go beyond what the stated procedures can firmly support. I also point out one internal inconsistency in the \"energy-level spacing\" analogy. The aim is constructive: to keep the interesting empirical observations, while making clear what they do (and do not) imply about quantum entanglement in the usual Hilbert-space sense, especially when \"energy\" is defined by rank.", "AI": {"tldr": "本文是对arXiv:2511.21731v1的手稿进行技术审查，指出了报告的CHSH/Bell型计算和Bose-Einstein拟合对词频数据解释中的问题，并指出了一致性上的内部矛盾。", "motivation": "目的是建设性的：在保持有趣的实证观察的同时，明确它们（不）意味着什么关于量子纠缠的传统希尔伯特空间意义上的含义，特别是在“能量”由秩定义时的含义。", "method": "审查手稿并指出了其中的一些解释和一致性问题。没有提供新的计算或实验方法。", "result": "提出了一些需要澄清的问题，并指出了一致性上的内部矛盾。", "conclusion": "通过明确一些观察结果的实际意义，以避免对手稿中的结论进行过度解读。"}}
{"id": "2601.06103", "pdf": "https://arxiv.org/pdf/2601.06103", "abs": "https://arxiv.org/abs/2601.06103", "authors": ["Muhammed Yusuf Kocyigit", "Caglar Yildirim"], "title": "The Impact of Post-training on Data Contamination", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present a controlled study of how dataset contamination interacts with the post-training stages now standard in large language model training pipelines. Starting from clean checkpoints of Qwen2.5 (0.5B/1.5B) and Gemma3 (1B/4B), we inject five copies of GSM8K and MBPP test items into the first 2B tokens of an otherwise 25B token extended pre-training dataset. We then compare the contaminated and clean models both immediately after pre-training and again after two popular post-training methods: supervised fine-tuning (SFT) and reinforcement learning (RL) with group relative policy optimization (GRPO). The applied post-training steps do not have any contamination. Across math and coding benchmarks, we find three consistent patterns: (i) Contamination causes performance spikes that are gradually diminished with continued pre-training. After even 25B tokens the apparent performance inflation of contamination can become close to zero. (ii) Both SFT and GRPO resurface the leaked information, but with different external validity: SFT inflates scores only on the contaminated tasks, whereas GRPO also inflates performance on uncontaminated counterparts (GSMPlus, HumanEval). (iii) Model scale amplifies these tendencies, larger Supervised Fine Tuned models memorize more, while larger GRPO models translate leakage into more generalizable capabilities. Our results underscore the need for contamination audits \\emph{after} post-training and suggest that RL-based post-training, although not immune, can help alleviate contamination-related over-estimation problems.", "AI": {"tldr": "研究探讨了在大规模语言模型训练过程中，数据污染如何与后训练阶段相互作用。", "motivation": "了解数据污染在预训练和后续微调过程中的影响，以及不同微调方法对污染信息的处理方式。", "method": "从干净检查点开始，注入污染数据进行预训练。然后通过监督微调（SFT）和强化学习（RL）两种方法进行后训练，并比较结果。", "result": "发现污染导致性能峰值逐渐减少；SFT仅在污染任务上提升分数，GRPO则在未污染任务上也有所改善；模型规模越大，记忆或泛化能力越强。", "conclusion": "研究强调了需要在后训练阶段进行污染审计，并指出基于RL的微调方法虽然不能完全解决污染问题，但可以帮助缓解过度估计的问题。"}}
{"id": "2601.06102", "pdf": "https://arxiv.org/pdf/2601.06102", "abs": "https://arxiv.org/abs/2601.06102", "authors": ["Truong Xuan Khanh", "Truong Quynh Hoa"], "title": "Dynamic Intelligence Ceilings: Measuring Long-Horizon Limits of Planning and Creativity in Artificial Systems", "categories": ["cs.AI", "cs.LG"], "comment": "This paper introduces a trajectory-centric evaluation framework for analyzing long-horizon intelligence limits in artificial systems, focusing on developmental behavior, planning, and structural creativity rather than proposing new learning algorithms. 11 pages, 2 figures", "summary": "Recent advances in artificial intelligence have produced systems capable of remarkable performance across a wide range of tasks. These gains, however, are increasingly accompanied by concerns regarding long-horizon developmental behavior, as many systems converge toward repetitive solution patterns rather than sustained growth. We argue that a central limitation of contemporary AI systems lies not in capability per se, but in the premature fixation of their performance frontier. To address this issue, we introduce the concept of a \\emph{Dynamic Intelligence Ceiling} (DIC), defined as the highest level of effective intelligence attainable by a system at a given time under its current resources, internal intent, and structural configuration. To make this notion empirically tractable, we propose a trajectory-centric evaluation framework that measures intelligence as a moving frontier rather than a static snapshot. We operationalize DIC using two estimators: the \\emph{Progressive Difficulty Ceiling} (PDC), which captures the maximal reliably solvable difficulty under constrained resources, and the \\emph{Ceiling Drift Rate} (CDR), which quantifies the temporal evolution of this frontier. These estimators are instantiated through a procedurally generated benchmark that jointly evaluates long-horizon planning and structural creativity within a single controlled environment. Our results reveal a qualitative distinction between systems that deepen exploitation within a fixed solution manifold and those that sustain frontier expansion over time. Importantly, our framework does not posit unbounded intelligence, but reframes limits as dynamic and trajectory-dependent rather than static and prematurely fixed. \\vspace{0.5em} \\noindent\\textbf{Keywords:} AI evaluation, planning and creativity, developmental intelligence, dynamic intelligence ceilings, complex adaptive systems", "AI": {"tldr": "本文提出了一种名为动态智能上限的概念，以衡量人工智能系统在长期内规划和创造力的极限。通过引入两个指标来量化这一概念，并在一个生成性基准环境中验证这些指标的效果。", "motivation": "随着AI技术的进步，一些系统表现出趋向于重复解决方案模式而非持续增长的行为。为了解决这种长期开发行为中的瓶颈问题，作者提出了动态智能上限的概念及其评估方法。", "method": "引入了两个用于量化动态智能上限的估计器：渐进难度上限和顶点漂移率，并在一个生成性环境中测试这些估计器的有效性和实用性。", "result": "实验结果揭示了一种区别于在固定解决方案空间中深化利用的人工智能系统，后者能够随着时间不断扩展其能力边界。该框架重新定义了人工智能系统的局限性为动态的而不是静态且过早固定的。", "conclusion": "本文通过引入动态智能上限的概念以及相关的评估方法，提供了一种新的视角来理解和发展长期有效的AI系统的能力极限。"}}
{"id": "2601.06101", "pdf": "https://arxiv.org/pdf/2601.06101", "abs": "https://arxiv.org/abs/2601.06101", "authors": ["Shan Zhang", "Ruiwei Xiao", "Anthony F. Botelho", "Guanze Liao", "Thomas K. F. Chiu", "John Stamper", "Kenneth R. Koedinger"], "title": "How to Assess AI Literacy: Misalignment Between Self-Reported and Objective-Based Measures", "categories": ["cs.CY", "cs.AI"], "comment": "16 pages, 6 figures, LAK2026", "summary": "The widespread adoption of Artificial Intelligence (AI) in K-12 education highlights the need for psychometrically-tested measures of teachers' AI literacy. Existing work has primarily relied on either self-report (SR) or objective-based (OB) assessments, with few studies aligning the two within a shared framework to compare perceived versus demonstrated competencies or examine how prior AI literacy experience shapes this relationship. This gap limits the scalability of learning analytics and the development of learner profile-driven instructional design. In this study, we developed and evaluated SR and OB measures of teacher AI literacy within the established framework of Concept, Use, Evaluate, and Ethics. Confirmatory factor analyses support construct validity with good reliability and acceptable fit. Results reveal a low correlation between SR and OB factors. Latent profile analysis identified six distinct profiles, including overestimation (SR > OB), underestimation (SR < OB), alignment (SR close to OB), and a unique low-SR/low-OB profile among teachers without AI literacy experience. Theoretically, this work extends existing AI literacy frameworks by validating SR and OB measures on shared dimensions. Practically, the instruments function as diagnostic tools for professional development, supporting AI-informed decisions (e.g., growth monitoring, needs profiling) and enabling scalable learning analytics interventions tailored to teacher subgroups.", "AI": {"tldr": "该论文开发并评估了基于自我报告和客观测试的教师人工智能素养量表，并在概念、使用、评价与伦理四个维度上进行了验证。", "motivation": "现有工作主要依赖于自我报告或客观测试，缺乏将两者结合在一个共同框架内来比较感知能力与实际能力的研究。这限制了学习分析的可扩展性以及根据教师子群体定制干预措施的能力。", "method": "论文开发并评估了基于自我报告和客观测试的量表，并通过验证性因子分析支持建构效度，还进行了潜在剖面分析以识别不同教师群体的特点。", "result": "研究发现SR与OB因素之间的相关性较低；存在包括高估、低估、一致及低经验者的独特低分数在内的六种不同的群体特征。", "conclusion": "该工作扩展了现有的人工智能素养框架，验证了自我报告和客观测试在共同维度上的有效性，并提供了专业发展的诊断工具。"}}
{"id": "2601.06098", "pdf": "https://arxiv.org/pdf/2601.06098", "abs": "https://arxiv.org/abs/2601.06098", "authors": ["Nicholas X. Wang", "Neel V. Parpia", "Aaryan D. Parikh", "Aggelos K. Katsaggelos"], "title": "Automatic Question Generation for Intuitive Learning Utilizing Causal Graph Guided Chain of Thought Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Intuitive learning is crucial for developing deep conceptual understanding, especially in STEM education, where students often struggle with abstract and interconnected concepts. Automatic question generation has become an effective strategy for personalized and adaptive learning. However, its effectiveness is hindered by hallucinations in large language models (LLMs), which may generate factually incorrect, ambiguous, or pedagogically inconsistent questions. To address this issue, we propose a novel framework that combines causal-graph-guided Chain-of-Thought (CoT) reasoning with a multi-agent LLM architecture. This approach ensures the generation of accurate, meaningful, and curriculum-aligned questions. Causal graphs provide an explicit representation of domain knowledge, while CoT reasoning facilitates a structured, step-by-step traversal of related concepts. Dedicated LLM agents are assigned specific tasks such as graph pathfinding, reasoning, validation, and output, all working within domain constraints. A dual validation mechanism-at both the conceptual and output stages-greatly reduces hallucinations. Experimental results demonstrate up to a 70% improvement in quality compared to reference methods and yielded highly favorable outcomes in subjective evaluations.", "AI": {"tldr": "提出了一种结合因果图引导的Chain-of-Thought推理和多代理LLM架构的方法，用于生成准确、有意义且符合课程要求的问题。", "motivation": "解决大语言模型在自动生成问题时出现的事实错误、模糊或与教学不一致等问题，以提高个性化和适应性学习的效果。", "method": "使用因果图表示领域知识，并通过Chain-of-Thought推理进行有结构的步骤化概念遍历。多代理LLM架构被分配特定任务如路径寻找、推理、验证和输出，所有这些都在域约束下进行。双验证机制在概念阶段和输出阶段都大大减少了幻觉。", "result": "实验结果表明，与基准方法相比，质量提高了70%，并且在主观评估中得到了高度积极的结果。", "conclusion": "通过因果图引导的Chain-of-Thought推理和多代理LLM架构生成的问题更加准确、有意义且符合课程要求，从而显著提升了学习效果。"}}
{"id": "2601.06097", "pdf": "https://arxiv.org/pdf/2601.06097", "abs": "https://arxiv.org/abs/2601.06097", "authors": ["Aradhya Dixit", "Tianxi Liang"], "title": "Semantic Event Graphs for Long-Form Video Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "7 pages, 6 figures", "summary": "Long-form video question answering remains challenging for modern vision-language models, which struggle to reason over hour-scale footage without exceeding practical token and compute budgets. Existing systems typically downsample frames or feed dense visual embeddings to large-context language models, trading off temporal coverage against cost. We propose Semantic Event Graphs (SEG), a lightweight symbolic interface between video and language that replaces raw frames with compact temporal interaction logs. Our pipeline detects and tracks objects with YOLOv11, converts proximity patterns into START/END human-object events, and organizes them into a Temporal Scene Graph (TSG). At inference time, a query-aware pruning module identifies anchor entities and lexically relevant events, returning only a small subgraph which is verbalized and passed to Gemini 2.5 Flash for answer generation. On five YouTube videos (300-500 interactions each) and 120 automatically generated long-horizon questions, SEG achieves 65.0% accuracy using only 3.47k tokens per query, closely matching a full-log baseline (62.5% at 40.39k tokens) while reducing token usage by 91.4%. A short-context baseline restricted to the last 30 seconds collapses to 2.5% accuracy, underscoring the need for explicit temporal memory. These results show that symbolic temporal graphs can serve as an effective, plug-and-play memory layer for off-the-shelf vision-language models, preserving long-range reasoning ability while making long-form video question answering substantially more token- and cost-efficient. Code, logs, and event-extraction tools will be released for reproducibility.", "AI": {"tldr": "本文提出了一种轻量级的符号接口Semantic Event Graphs（SEG），用于长视频的问题回答。", "motivation": "现有的系统在处理长时间视频问题时，会通过下采样帧或向大型语言模型提供密集视觉嵌入来权衡时间覆盖与计算成本。这使得现代视觉-语言模型难以有效地应对小时级的视频片段。", "method": "SEG首先使用YOLOv11检测和跟踪物体，并将其转化为START/END的人机交互事件，然后组织成Temporal Scene Graph（TSG）。在推理阶段，查询感知剪枝模块会识别锚实体并提取相关事件，生成一个小型子图传给语言模型进行回答。", "result": "SEG在五个YouTube视频上实现了65.0%的准确率，使用了3.47k个令牌/查询，而全日志基线为62.5%（40.39k令牌），减少了91.4%。短上下文基准测试仅依赖最近30秒信息，则精确度下降到2.5%，这表明需要显式的时序记忆。", "conclusion": "实验结果证明了符号化时间图可以作为现成的视觉-语言模型的有效插件式内存层，保持长距离推理能力的同时使长时间视频问答更为令牌和成本高效。"}}
{"id": "2601.06095", "pdf": "https://arxiv.org/pdf/2601.06095", "abs": "https://arxiv.org/abs/2601.06095", "authors": ["Andrii Grekhov", "Volodymyr Kharchenko", "Vasyl Kondratiuk"], "title": "Deep Q-Network Based Resilient Drone Communication:Neutralizing First-Order Markov Jammers", "categories": ["cs.IT", "cs.AI"], "comment": "13 pages, 6 figures", "summary": "Deep Reinforcement Learning based solution for jamming communications using Frequency Hopping Spread Spectrum technology in a 16 channel radio environment is presented. Deep Q Network based transmitter continuously selects the next frequency hopping channel while facing first order reactive jamming, which uses observed transition statistics to predict and interrupt transmissions. Through self training, the proposed agent learns a uniform random frequency hopping policy that effectively neutralizes the predictive advantage of the jamming. In the presence of Rayleigh fading and additive noise, the impact of forward error correction Bose Chaudhuri Hocquenghem type codes is systematically evaluated, demonstrating that even moderate redundancy significantly reduces packet loss. Extensive visualization of the learning dynamics, channel utilization distribution, epsilon greedy decay, cumulative reward, BER and SNR evolution, and detailed packet loss tables confirms convergence to a near optimal jamming strategy. The results provide a practical framework for autonomous resilient communications in modern electronic warfare scenarios.", "AI": {"tldr": "基于深度强化学习的解决方案，使用频率跳频技术对抗通信干扰。", "motivation": "在存在预测性干扰的情况下，开发一种有效的自适应频率跳频策略以保障通信质量。", "method": "采用Deep Q Network (DQN) 模型训练传输设备选择频率跳频通道，并评估前向纠错编码的效果。", "result": "通过系统性实验验证了所提出的算法能够在存在瑞利衰落和加性噪声的情况下，有效地降低包丢失率。", "conclusion": "研究提供了一个实用的框架，在现代电子战环境中实现自主性的抗干扰通信。"}}
{"id": "2601.06094", "pdf": "https://arxiv.org/pdf/2601.06094", "abs": "https://arxiv.org/abs/2601.06094", "authors": ["Samiya A Alkhairy"], "title": "Auditory Filter Behavior and Updated Estimated Constants", "categories": ["eess.AS", "cs.SD", "eess.SP", "eess.SY", "q-bio.TO"], "comment": "19 pages, 36 equations, 10 figures, 2 tables, submitted", "summary": "Filters from the Gammatone family are often used to model auditory signal processing, but the filter constant values used to mimic human hearing are largely set to values based on historical psychoacoustic data collected several decades ago. Here, we move away from this long-standing convention, and estimate filter constants using a range of more recent reported filter characteristics (such as quality factors and ratios between quality factors and peak group delay) within a characteristics-based framework that clarifies how filter behavior is related to the underlying constants. Using a sharp-filter approximation that captures shared peak-region behavior across certain classes of filters, we analyze the range of behaviors accessible when the full degrees of freedom of the filter are utilized rather than fixing the filter order or exponent to historically prescribed values. Filter behavior is characterized using magnitude-based and phase-based characteristics and their ratios, which reveal which characteristics are informative for constraining filter constants and which are only weakly constraining. We show that these insights and estimation methods extend to multiple realizable filter classes from the Gammatone family and apply them, together with recent physiological and psychoacoustic observations, to derive constraints on and estimates for filter constants for human auditory filters. More broadly, this framework supports the design of auditory filters with arbitrary characteristic-level specifications and enables systematic assessment of how variations in filter characteristics influence auditory models, perceptual findings, and technologies that rely on auditory filterbanks.", "AI": {"tldr": "本文探讨了如何通过新的方法估计听觉信号处理模型中的滤波器常数，以更好地模拟人类听力。", "motivation": "传统上使用的Gammatone滤波器的参数基于几十年前的数据。作者希望通过使用最近的研究数据来改进这些参数估计。", "method": "利用近期报道的过滤器特性（如品质因子和峰值群延迟比）并采用特征框架，分析了在不固定历史规定值的情况下全自由度滤波器的行为。", "result": "该研究揭示了一些特性对于约束滤波常数是有信息量的，而另一些只有微弱的影响。并且展示了这种方法可应用于Gammatone滤波器家族中的多种实现类，并结合近期生理学和心理声学观察来推导人类听觉过滤器的约束条件和估计。", "conclusion": "该框架支持具有任意特性规格的设计以及评估不同特征变化对听觉模型、感知发现和技术的影响。"}}
{"id": "2601.06093", "pdf": "https://arxiv.org/pdf/2601.06093", "abs": "https://arxiv.org/abs/2601.06093", "authors": ["Matthew Nyaaba", "Patrick Kyeremeh", "Macharious Nabang", "Bismark Nyaaba Akanzire", "Cyril Ababio Titty", "Jerry Etornam Kudaya", "Sakina Acquah"], "title": "GenAITEd Ghana_A Blueprint Prototype for Context-Aware and Region-Specific Conversational AI Agent for Teacher Education", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Global frameworks increasingly advocate for Responsible Artificial Intelligence (AI) in education, yet they provide limited guidance on how ethical, culturally responsive, and curriculum-aligned AI can be operationalized within functioning teacher education systems, particularly in the Global South. This study addresses this gap through the design and evaluation of GenAITEd Ghana, a context-aware, region-specific conversational AI prototype developed to support teacher education in Ghana. Guided by a Design Science Research approach, the system was developed as a school-mimetic digital infrastructure aligned with the organizational logic of Ghanaian Colleges of Education and the National Council for Curriculum and Assessment (NaCCA) framework. GenAITEd Ghana operates as a multi-agent, retrieval-augmented conversational AI that coordinates multiple models for curriculum-grounded dialogue, automatic speech recognition, voice synthesis, and multimedia interaction. Two complementary prompt pathways were embedded: system-level prompts that enforce curriculum boundaries, ethical constraints, and teacher-in-the-loop oversight, and interaction-level semi-automated prompts that structure live pedagogical dialogue through clarification, confirmation, and guided response generation. Evaluation findings show that the system effectively enacted key Responsible AI principles, including transparency, accountability, cultural responsiveness, privacy, and human oversight. Human expert evaluations further indicated that GenAITEd Ghana is pedagogically appropriate for Ghanaian teacher education, promoting student engagement while preserving educators' professional authority. Identified challenges highlight the need for continued model integration, professional development, and critical AI literacy to mitigate risks of over-reliance.", "AI": {"tldr": "本文设计并评估了一种名为GenAITEd Ghana的对话式AI原型，以支持加纳教师教育。", "motivation": "全球框架提倡负责任的人工智能在教育中的应用，但缺乏具体指导如何实现在功能齐全的教师教育系统中的伦理、文化响应和课程相关性。本文通过设计和评估一个名为GenAITEd Ghana的对话式AI原型来填补这一空白。", "method": "基于设计科学研究方法，开发了模拟学校环境的数字基础设施，并与加纳教育学院组织逻辑及国家课程框架相协调。GenAITEd Ghana作为一个多代理、检索增强型对话式AI系统运行，集成多个模型以支持基于课程的教学对话、自动语音识别、语音合成和多媒体交互。", "result": "评估结果显示，该系统有效实施了负责任的人工智能原则，包括透明度、问责制、文化响应性、隐私以及人机监督。专家评测表明GenAITEd Ghana对加纳教师教育具有适当的教学作用，并能促进学生的参与同时保持教师的专业权威。", "conclusion": "尽管已取得进展，但仍需进一步整合模型、专业培训和批判性人工智能素养以防止过度依赖风险。"}}
{"id": "2601.06092", "pdf": "https://arxiv.org/pdf/2601.06092", "abs": "https://arxiv.org/abs/2601.06092", "authors": ["Muhammad Aurangzeb Ahmad"], "title": "Islamic Chatbots in the Age of Large Language Models", "categories": ["cs.CY", "cs.AI"], "comment": "Muslim in ML Workshop at NeurIPS 2025", "summary": "Large Language Models (LLMs) are rapidly transforming how communities access, interpret, and circulate knowledge, and religious communities are no exception. Chatbots powered by LLMs are beginning to reshape authority, pedagogy, and everyday religious practice in Muslim communities. We analyze the landscape of LLM powered Islamic chatbots and how they are transforming Islamic religious practices e.g., democratizing access to religious knowledge but also running the risk of erosion of authority. We discuss what kind of challenges do these systems raise for Muslim communities and explore recommendations for the responsible design of these systems.", "AI": {"tldr": "研究通过大型语言模型驱动的伊斯兰聊天机器人在穆斯林社区中的应用，探讨其对宗教实践的影响及挑战。", "motivation": "随着大型语言模型的发展，这些技术开始改变包括宗教社群在内的各个领域获取和传播知识的方式。本文旨在分析这种变化如何影响穆斯林群体，并提出负责任的设计建议。", "method": "文章没有具体提及采用的研究方法，而是通过讨论和分析当前伊斯兰聊天机器人的生态系统及其对宗教实践的影响来进行研究。", "result": "研究表明这些系统既有可能普及宗教知识也存在侵蚀权威的风险。同时探讨了由此产生的挑战以及可能的解决方案。", "conclusion": "大型语言模型驱动的伊斯兰聊天机器人正在重塑穆斯林社区的宗教实践，需要谨慎设计以确保其正面效果并减少潜在风险。"}}
{"id": "2601.06086", "pdf": "https://arxiv.org/pdf/2601.06086", "abs": "https://arxiv.org/abs/2601.06086", "authors": ["Yiwen Shao", "Wei Liu", "Jiahong Li", "Tianzi Wang", "Kun Wei", "Meng Yu", "Dong Yu"], "title": "AzeroS: Extending LLM to Speech with Self-Generated Instruction-Free Tuning", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Technical Report", "summary": "Extending large language models (LLMs) to the speech domain has recently gained significant attention. A typical approach connects a pretrained LLM with an audio encoder through a projection module and trains the resulting model on large-scale, task-specific instruction-tuning datasets. However, curating such instruction-tuning data for specific requirements is time-consuming, and models trained in this manner often generalize poorly to unseen tasks. In this work, we first formulate that the strongest generalization of a speech-LLM is achieved when it is trained with Self-Generated Instruction-Free Tuning (SIFT), in which supervision signals are generated by a frozen LLM using textual representations of speech as input. Our proposed SIFT paradigm eliminates the need for collecting task-specific question-answer pairs and yields the theoretically best generalization to unseen tasks. Building upon this paradigm, we introduce AZeroS (Auden Zero-instruction-tuned Speech-LLM), which is trained on speech-text pairs derived from publicly available corpora, including approximately 25,000 hours of speech with ASR transcripts and 3,000 hours of speech with paralinguistic labels. Built upon Qwen2.5-7B-Instruct, the model updates only two lightweight projection modules (23.8 million parameters each), while keeping both the LLM and audio encoders frozen. Despite the minimal training cost and modest data scale, AZeroS achieves state-of-the-art performance on both semantic and paralinguistic benchmarks, including VoiceBench, AIR-Bench Foundation (Speech), and AIR-Bench Chat (Speech).", "AI": {"tldr": "本论文提出了AzeroS模型，通过自生成无指令微调方法将大型语言模型扩展到语音领域。", "motivation": "传统方法依赖大量的任务特定指令数据集进行训练，这种数据集的收集耗时且难以泛化到未见过的任务。为解决这些问题，本文提出了一种新的自动生成监督信号的方法，以提高模型在新任务上的表现。", "method": "通过将预训练的语言模型与音频编码器连接，并利用冻结语言模型生成语音文本表示的监督信号进行微调。该方法仅需更新两个轻量级投影模块，大大减少了训练成本和数据规模。", "result": "AzeroS在语义和副语言基准测试上取得了最佳性能，包括VoiceBench、AIR-Bench Foundation（Speech）和AIR-Bench Chat（Speech）。", "conclusion": "本研究展示了自生成无指令微调方法的有效性，并证明了这种方法能够显著提高语音语言模型的泛化能力。"}}
{"id": "2601.06081", "pdf": "https://arxiv.org/pdf/2601.06081", "abs": "https://arxiv.org/abs/2601.06081", "authors": ["Lorenzo Sciacca", "Alex Minetto", "Andrea Nardin", "Fabio Dovis", "Luca Canzian", "Mario Musmeci", "Claudia Facchinetti", "Giancarlo Varacalli"], "title": "First Multi-Constellation Observations of Navigation Satellite Signals in the Lunar Domain by Post-Processing L1/L5 IQ Snapshots", "categories": ["physics.space-ph", "astro-ph.IM", "cs.RO", "eess.SP"], "comment": "13 pages, 9 figures, IEEE Transactions on Aerospace and Electronic Systems", "summary": "The use of Global Navigation Satellite Systems (GNSS) to increase spacecraft autonomy for orbit determination has gained renewed momentum following the Lunar GNSS Receiver Experiment (LuGRE), which demonstrated feasible onboard GPS and Galileo signal reception and tracking at lunar distances. This work processes in-phase and quadrature (IQ) snapshots collected by the LuGRE receiver in cis-lunar space and on the lunar surface to assess multi-frequency, multi-constellation signal availability. Signals from additional systems beyond GPS and Galileo, including RNSS and SBAS constellations, are observable and successfully acquired exclusively in the recorded IQ snapshots. These observations provide the first experimental evidence that signals from multiple constellations, including systems not supported by LuGRE realtime operations, are detectable at unprecedented distances from Earth. Useful observables can be extracted from the IQ snapshots, despite minimal sampling rates, 4-bit quantization, and short durations (200 ms-2 s), through a hybrid coherent/non-coherent acquisition stage compensating for code Doppler. These observations are exploited to tune simulation tools and to perform extended simulation campaigns, showing that the inclusion of additional constellations significantly improves availability; for a 26 dB-Hz acquisition threshold, the fraction of epochs with at least four visible satellites increases from 11% to 46% of the total epoch count. These findings indicate that BeiDou, RNSS, and SBAS signals can substantially enhance GNSS-based autonomy for lunar and cislunar missions.", "AI": {"tldr": "本论文利用IQ快照评估多频段、多星座GNSS信号在月球轨道上的可用性。", "motivation": "为了提高航天器的自主能力，通过LuGRE接收机收集的数据来研究GNSS信号在月球距离上的可检测性和跟踪性能。", "method": "通过对收集到的IQ快照进行处理和分析，包括额外系统（如RNSS和SBAS）的信号，并利用混合相干/非相干获取阶段补偿码多普勒。", "result": "发现除了GPS和Galileo之外的其他星座信号可以被检测到并成功获得；通过使用这些观察数据调整仿真工具，增加了可用卫星的数量，提高了导航系统的自主性。", "conclusion": "BeiDou、RNSS和SBAS等额外系统在提高月球和近地轨道任务中基于GNSS的自主能力方面具有显著优势。"}}
{"id": "2601.06078", "pdf": "https://arxiv.org/pdf/2601.06078", "abs": "https://arxiv.org/abs/2601.06078", "authors": ["Yin Wang", "Chunlin Gong", "Zhuozhen Xu", "Lehan Zhang", "Xiang Wu"], "title": "OptFormer: Optical Flow-Guided Attention and Phase Space Reconstruction for SST Forecasting", "categories": ["cs.CV", "physics.ao-ph"], "comment": "11 pages,4 figures, 5 tables", "summary": "Sea Surface Temperature (SST) prediction plays a vital role in climate modeling and disaster forecasting. However, it remains challenging due to its nonlinear spatiotemporal dynamics and extended prediction horizons. To address this, we propose OptFormer, a novel encoder-decoder model that integrates phase-space reconstruction with a motion-aware attention mechanism guided by optical flow. Unlike conventional attention, our approach leverages inter-frame motion cues to highlight relative changes in the spatial field, allowing the model to focus on dynamic regions and capture long-range temporal dependencies more effectively. Experiments on NOAA SST datasets across multiple spatial scales demonstrate that OptFormer achieves superior performance under a 1:1 training-to-prediction setting, significantly outperforming existing baselines in accuracy and robustness.", "AI": {"tldr": "提出了一种用于海表温度预测的新模型OptFormer，该模型结合了相空间重构和基于光流的注意力机制。", "motivation": "为了提高非线性时空动态系统的海表温度预测精度，特别是在长时间预测情况下，提出了一个新颖的方法来利用运动信息进行更有效的特征提取和时间依赖性捕捉。", "method": "OptFormer是一个集成有相空间重构与基于光流引导的注意力机制的编码器-解码器模型。通过这种方式，该模型能够更好地关注动态区域并捕获长期的时间相关性。", "result": "实验表明，在NOAA海表温度数据集上进行1:1训练到预测设置时，OptFormer在精度和鲁棒性方面显著优于现有的基线方法。", "conclusion": "通过引入基于光流的注意力机制和相空间重构技术，OptFormer模型能够更精确地捕捉海表温度的变化趋势，并且具有更好的预测性能。"}}
{"id": "2601.06077", "pdf": "https://arxiv.org/pdf/2601.06077", "abs": "https://arxiv.org/abs/2601.06077", "authors": ["Aolin Xu"], "title": "One if by Land, Two if by Sea, Three if by Four Seas, and More to Come -- Values of Perception, Prediction, Communication, and Common Sense in Decision Making", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.OC"], "comment": null, "summary": "This work aims to rigorously define the values of perception, prediction, communication, and common sense in decision making. The defined quantities are decision-theoretic, but have information-theoretic analogues, e.g., they share some simple but key mathematical properties with Shannon entropy and mutual information, and can reduce to these quantities in particular settings. One interesting observation is that, the value of perception without prediction can be negative, while the value of perception together with prediction and the value of prediction alone are always nonnegative. The defined quantities suggest answers to practical questions arising in the design of autonomous decision-making systems. Example questions include: Do we need to observe and predict the behavior of a particular agent? How important is it? What is the best order to observe and predict the agents? The defined quantities may also provide insights to cognitive science and neural science, toward the understanding of how natural decision makers make use of information gained from different sources and operations.", "AI": {"tldr": "本文旨在定义感知、预测、沟通和常识在决策中的价值，并探讨这些量在设计自主决策系统时的实际应用。", "motivation": "通过严格定义感知、预测、沟通和常识的价值，以解决自主决策系统设计中的一些实际问题，如是否需要观察和预测特定代理的行为及其重要性等。", "method": "本文使用了信息论中的熵和互信息的数学特性来类比定义这些价值量，并探讨它们在不同情况下的表现。", "result": "发现感知的价值可以是负的，而结合预测的感知价值总是非负的。此外，这些定义能提供对认知科学和神经科学的理解。", "conclusion": "定义了决策中的信息值有助于设计更有效的自主决策系统，并为理解自然决策者如何利用不同来源的信息提供了见解。"}}
{"id": "2601.06075", "pdf": "https://arxiv.org/pdf/2601.06075", "abs": "https://arxiv.org/abs/2601.06075", "authors": ["Ali Hossary", "Laura Crosara", "Stefano Tomasin"], "title": "Jamming Detection in Cell-Free MIMO with Dynamic Graphs", "categories": ["cs.IT", "cs.AI"], "comment": null, "summary": "Jamming attacks pose a critical threat to wireless networks, particularly in cell-free massive MIMO systems, where distributed access points and user equipment (UE) create complex, time-varying topologies. This paper proposes a novel jamming detection framework leveraging dynamic graphs and graph convolutional neural networks (GCN) to address this challenge. By modeling the network as a dynamic graph, we capture evolving communication links and detect jamming attacks as anomalies in the graph evolution. A GCN-Transformer-based model, trained with supervised learning, learns graph embeddings to identify malicious interference. Performance evaluation in simulated scenarios with moving UEs, varying jamming conditions and channel fadings, demonstrates the method's effectiveness, which is assessed through accuracy and F1 score metrics, achieving promising results for effective jamming detection.", "AI": {"tldr": "提出了一种基于动态图和GCN的新型干扰检测框架，用于在分布式的cell-free大规模MIMO系统中识别恶意干扰。", "motivation": "为了应对分布式接入点与用户设备构成的时间变化网络拓扑中的关键威胁——即无线网络中的干扰攻击，特别是在复杂的cell-free大规模MIMO系统中。该论文旨在通过利用动态图和GCN来检测这些异常情况并提高安全性。", "method": "将网络模型化为动态图以捕捉通信链路的变化，并使用基于GCN-Transformer的监督学习模型生成图嵌入从而识别恶意干扰。此方法在模拟场景下进行了测试，包括移动用户设备、变化的干扰条件和信道衰落。", "result": "通过准确率和F1得分指标评估了该方案的有效性，在各种情况下均获得了令人满意的结果。", "conclusion": "所提出的方法能够有效地检测cell-free大规模MIMO系统中的干扰攻击，展示了在复杂网络环境下的潜在应用价值。"}}
{"id": "2601.06067", "pdf": "https://arxiv.org/pdf/2601.06067", "abs": "https://arxiv.org/abs/2601.06067", "authors": ["Chimdi Walter Ndubuisi", "Toni Kazic"], "title": "HyperTopo-Adapters: Geometry- and Topology-Aware Segmentation of Leaf Lesions on Frozen Encoders", "categories": ["cs.CV"], "comment": "13 pages, 8 figures. Code available at https://github.com/ChimdiWalter/HyperTopo-Adapters", "summary": "Leaf-lesion segmentation is topology-sensitive: small merges, splits, or false holes can be biologically meaningful descriptors of biochemical pathways, yet they are weakly penalized by standard pixel-wise losses in Euclidean latents. I explore HyperTopo-Adapters, a lightweight, parameter-efficient head trained on top of a frozen vision encoder, which embeds features on a product manifold -- hyperbolic + Euclidean + spherical (H + E + S) -- to encourage hierarchical separation (H), local linear detail (E), and global closure (S). A topology prior complements Dice/BCE in two forms: (i) persistent-homology (PH) distance for evaluation and selection, and (ii) a differentiable surrogate that combines a soft Euler-characteristic match with total variation regularization for stable training. I introduce warm-ups for both the hyperbolic contrastive term and the topology prior, per-sample evaluation of structure-aware metrics (Boundary-F1, Betti errors, PD distance), and a min-PD within top-K Dice rule for checkpoint selection. On a Kaggle leaf-lesion dataset (N=2,940), early results show consistent gains in boundary and topology metrics (reducing Delta beta_1 hole error by 9%) while Dice/IoU remain competitive. The study is diagnostic by design: I report controlled ablations (curvature learning, latent dimensions, contrastive temperature, surrogate settings), and ongoing tests varying encoder strength (ResNet-50, DeepLabV3, DINOv2/v3), input resolution, PH weight, and partial unfreezing of late blocks. The contribution is an open, reproducible train/eval suite (available at https://github.com/ChimdiWalter/HyperTopo-Adapters) that isolates geometric/topological priors and surfaces failure modes to guide stronger, topology-preserving architectures.", "AI": {"tldr": "本文探讨了一种名为HyperTopo-Adapters的技术，该技术在冻结的视觉编码器上训练一个轻量级头部，用于叶片病害分割。", "motivation": "标准的像素损失弱化了对小合并、分裂和假洞的惩罚，而这些是生物化学途径的重要描述符。因此，本文提出了一种基于几何学和拓扑学的方法来改进叶部病变的分割效果。", "method": "通过在冻结的视觉编码器上训练一个轻量级头部，该头部将特征嵌入到双曲、欧氏和球面（H + E + S）乘积流形中以鼓励分层分离、局部线性细节以及全局闭合。结合持久同调距离和可微代理来稳定训练。", "result": "实验结果表明，在Kaggle叶病害数据集上，边界和拓扑学指标得到了改善（减少了Delta beta_1洞误差9%），而Dice/IoU仍然具有竞争力。", "conclusion": "该研究提供了一个开放、可重复的训练/评估套件，隔离了几何/拓扑先验，并表征了故障模式以指导更强的、保持拓扑结构的设计。"}}
{"id": "2601.06066", "pdf": "https://arxiv.org/pdf/2601.06066", "abs": "https://arxiv.org/abs/2601.06066", "authors": ["Abu Syed"], "title": "TEAS: Trusted Educational AI Standard: A Framework for Verifiable, Stable, Auditable, and Pedagogically Sound Learning Systems", "categories": ["cs.CY", "cs.AI"], "comment": "19 pages, 6 tables, accepted at AAAI-26 (DAI Workshop) in Singapore", "summary": "The rapid integration of AI into education has prioritized capability over trustworthiness, creating significant risks. Real-world deployments reveal that even advanced models are insufficient without extensive architectural scaffolding to ensure reliability. Current evaluation frameworks are fragmented: institutional policies lack technical verification, pedagogical guidelines assume AI reliability, and technical metrics are context-agnostic. This leaves institutions without a unified standard for deployment readiness. This paper introduces TEAS (Trusted Educational AI Standard), an integrated framework built on four interdependent pillars: (1) Verifiability, grounding content in authoritative sources; (2) Stability, ensuring deterministic core knowledge; (3) Auditability, enabling independent institutional validation; and (4) Pedagogical Soundness, enforcing principles of active learning. We argue that trustworthiness stems primarily from systematic architecture, not raw model capability. This insight implies that affordable, open-source models can achieve deployment-grade trust, offering a scalable and equitable path to integrating AI safely into learning environments globally.", "AI": {"tldr": "本文提出了TEAS框架，旨在通过四个支柱（可验证性、稳定性、审计性和教育合理性）确保AI在教育中的可靠性和信任度。", "motivation": "当前的教育AI集成优先考虑功能而非可靠性，导致了风险增加。现有的评估框架缺乏统一标准，无法保证部署的安全性。", "method": "提出TEAS（可信教育AI标准），该框架基于四个支柱：可验证性、稳定性、审计性和教育合理性，旨在提供一个全面的标准以确保教育AI的可靠性和信任度。", "result": "通过系统架构而非单一模型能力来保障可靠性，使得低成本开源模型也能实现部署级别的信任。", "conclusion": "TEAS框架为全球范围内的教育环境安全集成AI提供了可扩展且公平的方法。"}}
{"id": "2601.06064", "pdf": "https://arxiv.org/pdf/2601.06064", "abs": "https://arxiv.org/abs/2601.06064", "authors": ["Praveen Kumar Donta", "Alaa Saleh", "Ying Li", "Shubham Vaishnav", "Kai Fang", "Hailin Feng", "Yuchao Xia", "Thippa Reddy Gadekallu", "Qiyang Zhang", "Xiaodan Shi", "Ali Beikmohammadi", "Sindri Magnússon", "Ilir Murturi", "Chinmaya Kumar Dehury", "Marcin Paprzycki", "Lauri Loven", "Sasu Tarkoma", "Schahram Dustdar"], "title": "Socio-technical aspects of Agentic AI", "categories": ["cs.CY", "cs.AI", "cs.MA"], "comment": "Dear Reviewer, please note that this is not survey/review or position paper. This paper introduced new framework (MAD-BAD-SAD Framework) for Socio-technical aspects of Agentic AI, Ethical considerations, which is very important to consider beside technical development", "summary": "Agentic Artificial Intelligence (AI) represents a fundamental shift in the design of intelligent systems, characterized by interconnected components that collectively enable autonomous perception, reasoning, planning, action, and learning. Recent research on agentic AI has largely focused on technical foundations, including system architectures, reasoning and planning mechanisms, coordination strategies, and application-level performance across domains. However, the societal, ethical, economic, environmental, and governance implications of agentic AI remain weakly integrated into these technical treatments. This paper addresses this gap by presenting a socio-technical analysis of agentic AI that explicitly connects core technical components with societal context. We examine how architectural choices in perception, cognition, planning, execution, and memory introduce dependencies related to data governance, accountability, transparency, safety, and sustainability. To structure this analysis, we adopt the MAD-BAD-SAD construct as an analytical lens, capturing motivations, applications, and moral dilemmas (MAD); biases, accountability, and dangers (BAD); and societal impact, adoption, and design considerations (SAD). Using this lens, we analyze ethical considerations, implications, and challenges arising from contemporary agentic AI systems and assess their manifestation across emerging applications, including healthcare, education, industry, smart and sustainable cities, social services, communications and networking, and earth observation and satellite communications. The paper further identifies open challenges and suggests future research directions, framing agentic AI as an integrated socio-technical system whose behavior and impact are co-produced by algorithms, data, organizational practices, regulatory frameworks, and social norms.", "AI": {"tldr": "本文通过分析感知、认知、计划、执行和记忆等方面的技术选择，探讨了代理型人工智能的社会和技术影响。", "motivation": "旨在填补技术研究与社会伦理考量之间的空白，深入探讨代理型人工智能系统的社会、伦理、经济、环境及治理影响。", "method": "采用MAD-BAD-SAD框架作为分析工具，从动机、应用和道德困境（MAD）、偏见、责任和危险（BAD）以及社会影响、采纳与设计考虑（SAD）三个方面进行综合分析。", "result": "详细探讨了代理型人工智能在医疗健康、教育、工业、智慧城市等多个领域的伦理和社会挑战，并识别出开放性问题。", "conclusion": "强调应将代理型人工智能视为一个由算法、数据、组织实践、监管框架和社会规范共同影响的综合性系统。"}}
{"id": "2601.06063", "pdf": "https://arxiv.org/pdf/2601.06063", "abs": "https://arxiv.org/abs/2601.06063", "authors": ["Aadi Patel", "Nikhil Mahalingam", "Rusheen Patel"], "title": "The Environmental Impact of AI Servers and Sustainable Solutions", "categories": ["cs.CY", "cs.AI"], "comment": "5 pages, 2 figures", "summary": "The rapid expansion of artificial intelligence has significantly increased the electricity, water, and carbon demands of modern data centers, raising sustainability concerns. This study evaluates the environmental footprint of AI server operations and examines feasible technological and infrastructural strategies to mitigate these impacts. Using a literature-based methodology supported by quantitative projections and case-study analysis, we assessed trends in global electricity consumption, cooling-related water use, and carbon emissions. Projections indicate that global data center electricity demand may increase from approximately 415 TWh in 2024 to nearly 945 TWh by 2030, with AI workloads accounting for a disproportionate share of this growth. In the United States alone, AI servers are expected to drive annual increases in water consumption of 200--300 billion gallons and add 24--44 million metric tons of CO2 quivalent emissions by 2030. The results show that the design of the cooling system and the geographic location influence the environmental impact as strongly as the efficiency of the hardware. Advanced cooling technologies can reduce cooling energy by up to 50%, while location in low-carbon and water-secure regions can cut combined footprints by nearly half. In general, the study concludes that sustainable AI expansion requires coordinated improvements in cooling efficiency, renewable energy integration, and strategic deployment decisions.", "AI": {"tldr": "本文评估了AI服务器操作的环境足迹，并研究了缓解这些影响的技术和基础设施策略。", "motivation": "随着人工智能的迅速扩张，数据中心对电力、水和碳的需求显著增加，引发了可持续性问题。本研究旨在探讨减少其环境影响的方法。", "method": "采用文献综述方法结合定量预测和案例分析评估全球电力消耗、冷却用水量和碳排放趋势。", "result": "预计到2030年，全球数据中心的电力需求将从约415 TWh增加至近945 TWh，其中AI工作负载占据大部分增长。美国AI服务器导致水耗和二氧化碳排放显著增加。先进的冷却技术和地理位置选择可大幅降低环境影响。", "conclusion": "研究表明，可持续的人工智能扩展需要改进冷却效率、整合可再生能源以及战略性部署决策。"}}
{"id": "2601.06062", "pdf": "https://arxiv.org/pdf/2601.06062", "abs": "https://arxiv.org/abs/2601.06062", "authors": ["Theodore Roberts", "Bahram Zarrin"], "title": "From Values to Frameworks: A Qualitative Study of Ethical Reasoning in Agentic AI Practitioners", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "10 pages, 2 charts, 1 heatmap", "summary": "Agentic artificial intelligence systems are autonomous technologies capable of pursuing complex goals with minimal human oversight and are rapidly emerging as the next frontier in AI. While these systems promise major gains in productivity, they also raise new ethical challenges. Prior research has examined how different populations prioritize Responsible AI values, yet little is known about how practitioners actually reason through the trade-offs inherent in designing these autonomous systems. This paper investigates the ethical reasoning of AI practitioners through qualitative interviews centered on structured dilemmas in agentic AI deployment. We find that the responses of practitioners do not merely reflect value preferences but rather align with three distinct reasoning frameworks. First is a Customer-Centric framework where choices are justified by business interests, legality, and user autonomy. Second is a Design-Centric framework emphasizing technical safeguards and system constraints. Third is an Ethics-Centric framework prioritizing social good and moral responsibility beyond compliance. We argue that these frameworks offer distinct and necessary insights for navigating ethical trade-offs. Consequently, providers of agentic AI must look beyond general principles and actively manage how these diverse reasoning frameworks are represented in their decision-making processes to ensure robust ethical outcomes.", "AI": {"tldr": "研究探讨了AI从业者在代理型人工智能部署中的伦理推理。", "motivation": "面对代理型人工智能系统的新兴挑战，理解其设计者的实际伦理考量至关重要。", "method": "通过围绕结构化困境进行的定性访谈来探究从业者的伦理推理框架。", "result": "发现三种不同的伦理推理框架：客户中心、设计中心和伦理中心。", "conclusion": "不同伦理推理框架提供了独特的视角，有助于解决代理型人工智能中的道德权衡问题。"}}
{"id": "2601.06061", "pdf": "https://arxiv.org/pdf/2601.06061", "abs": "https://arxiv.org/abs/2601.06061", "authors": ["Daniel Jönsson", "Mattias Tiger", "Stefan Ekberg", "Daniel Jakobsson", "Mattias Jonhede", "Fredrik Viksten"], "title": "AI Application Operations -- A Socio-Technical Framework for Data-driven Organizations", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "We outline a comprehensive framework for artificial intelligence (AI) Application Operations (AIAppOps), based on real-world experiences from diverse organizations. Data-driven projects pose additional challenges to organizations due to their dependency on data across the development and operations cycles. To aid organizations in dealing with these challenges, we present a framework outlining the main steps and roles involved in going from idea to production for data-driven solutions. The data dependency of these projects entails additional requirements on continuous monitoring and feedback, as deviations can emerge in any process step. Therefore, the framework embeds monitoring not merely as a safeguard, but as a unifying feedback mechanism that drives continuous improvement, compliance, and sustained value realization-anchored in both statistical and formal assurance methods that extend runtime verification concepts from safety-critical AI to organizational operations. The proposed framework is structured across core technical processes and supporting services to guide both new initiatives and maturing AI programs.", "AI": {"tldr": "提出了一种基于实际经验的数据驱动组织的人工智能应用操作框架", "motivation": "帮助组织应对数据依赖项目带来的挑战，推动持续改进和价值实现", "method": "通过核心技术和支持服务来指导新启动的AI计划和成熟度提升", "result": "提供了一个涵盖主要步骤和支持角色的整体性框架，以从构想到生产的数据驱动解决方案", "conclusion": "此框架将监测作为反馈机制嵌入，并通过统计和形式保证方法推动持续改进"}}
{"id": "2601.06060", "pdf": "https://arxiv.org/pdf/2601.06060", "abs": "https://arxiv.org/abs/2601.06060", "authors": ["Cody Kommers", "Eamon Duede", "Julia Gordon", "Ari Holtzman", "Tess McNulty", "Spencer Stewart", "Lindsay Thomas", "Richard Jean So", "Hoyt Long"], "title": "Why Slop Matters", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "To be published in ACM AI Letters (submitted 8 December 2025; accepted 23 December 2025)", "summary": "AI-generated \"slop\" is often seen as digital pollution. We argue that this dismissal of the topic risks missing important aspects of AI Slop that deserve rigorous study. AI Slop serves a social function: it offers a supply-side solution to a variety of problems in cultural and economic demand - that, collectively, people want more content than humans can supply. We also argue that AI Slop is not mere digital detritus but has its own aesthetic value. Like other \"low\" cultural forms initially dismissed by critics, it nonetheless offers a legitimate means of collective sense-making, with the potential to express meaning and identity. We identify three key features of family resemblance for prototypical AI Slop: superficial competence (its veneer of quality is belied by a deeper lack of substance), asymmetry effort (it takes vastly less effort to generate than would be the case without AI), and mass producibility (it is part of a digital ecosystem of widespread generation and consumption). While AI Slop is heterogeneous and depends crucially on its medium, it tends to vary across three dimensions: instrumental utility, personalization, and surrealism. AI Slop will be an increasingly prolific and impactful part of our creative, information, and cultural economies; we should take it seriously as an object of study in its own right.", "AI": {"tldr": "探讨AI生成的低质量内容（\"slop\"）的社会功能和美学价值", "motivation": "防止因忽视AI生成的内容而错过其潜在的重要性和研究价值", "method": "分析AI Slop的特征、形成原因及其在不同维度的表现形式", "result": "确定了AI Slop具有表面质量、不对称努力及大规模可生产性三个核心特点，以及在工具实用性、个性化和超现实主义上的变化趋势", "conclusion": "认为AI Slop将日益成为创意、信息和文化经济的重要组成部分，值得作为独立研究对象进行深入探讨"}}
{"id": "2601.06059", "pdf": "https://arxiv.org/pdf/2601.06059", "abs": "https://arxiv.org/abs/2601.06059", "authors": ["Bingyan Xie", "Yongpeng Wu", "Wenjun Zhang", "Derrick Wing Kwan Ng", "Merouane Debbah"], "title": "Context Video Semantic Transmission with Variable Length and Rate Coding over MIMO Channels", "categories": ["cs.IT", "cs.AI"], "comment": null, "summary": "The evolution of semantic communications has profoundly impacted wireless video transmission, whose applications dominate driver of modern bandwidth consumption. However, most existing schemes are predominantly optimized for simple additive white Gaussian noise or Rayleigh fading channels, neglecting the ubiquitous multiple-input multiple-output (MIMO) environments that critically hinder practical deployment. To bridge this gap, we propose the context video semantic transmission (CVST) framework under MIMO channels. Building upon an efficient contextual video transmission backbone, CVST effectively learns a context-channel correlation map to explicitly formulate the relationships between feature groups and MIMO subchannels. Leveraging these channel-aware features, we design a multi-reference entropy coding mechanism, enabling channel state-aware variable length coding. Furthermore, CVST incorporates a checkerboard-based feature modulation strategy to achieve multiple rate points within a single trained model, thereby enhancing deployment flexibility. These innovations constitute our multi-reference variable length and rate coding (MR-VLRC) scheme. By integrating contextual transmission with MR-VLRC, CVST demonstrates substantial performance gains over various standardized separated coding methods and recent wireless video semantic communication approaches. The code is available at https://github.com/xie233333/CVST.", "AI": {"tldr": "提出了一种在MIMO信道下进行视频语义传输的框架（CVST），该框架通过多参考熵编码机制和特征调制策略，实现了可变长度和速率编码。", "motivation": "现有方案主要针对简单AWGN或瑞利衰落信道优化，忽视了普遍存在的MIMO环境，导致实际部署受阻。为了克服这一挑战，提出了一种新的视频语义传输框架。", "method": "CVST建立在高效上下文视频传输基础上，学习一种上下文-通道相关图以明确界定特征组和MIMO子信道之间的关系，并设计了多参考熵编码机制以及棋盘式特征调制策略，实现了单模型多速率点支持。", "result": "通过将上下文传输与MR-VLRC结合，CVST在多种标准分离编码方法及最新无线视频语义通信方案上展示了显著性能提升。", "conclusion": "提出的CVST框架有效解决了现有方案忽视MIMO环境的问题，并且通过创新的多参考可变长度和速率编码机制，在实际部署中表现出优异的表现。"}}
{"id": "2601.06057", "pdf": "https://arxiv.org/pdf/2601.06057", "abs": "https://arxiv.org/abs/2601.06057", "authors": ["Myriam Raymond", "Lucy Neveux", "Antonio A. Casilli", "Paola Tubaro"], "title": "Data Work in Egypt: Who Are the Workers Behind Artificial Intelligence?", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The report highlights the role of Egyptian data workers in the global value chains of Artificial Intelligence (AI). These workers generate and annotate data for machine learning, check outputs, and they connect with overseas AI producers via international digital labor platforms, where they perform on-demand tasks and are typically paid by piecework, with no long-term commitment. Most of these workers are young, highly educated men, with nearly two-thirds holding undergraduate degrees. Their primary motivation for data work is financial need, with three-quarters relying on platform earnings to cover basic necessities. Despite the variability in their online earnings, these are generally low, often equaling Egypt's minimum wage. Data workers' digital identities are shaped by algorithmic control and economic demands, often diverging from their offline selves. Nonetheless, they find ways to resist, exercise ethical agency, and maintain autonomy. The report evaluates the potential impact of Egypt's newly enacted labor law and suggests policy measures to improve working conditions and acknowledge the role of these workers in AI's global value chains.", "AI": {"tldr": "本文探讨了埃及数据工人在全球AI价值链中的角色，以及他们的工作状况。", "motivation": "研究旨在揭示埃及数据工人的社会经济背景及其参与AI生产的过程，并评估其劳动条件和政策影响。", "method": "通过调研报告的方式，描述埃及数据工作者的日常活动、收入情况及与海外AI生产商的关系。", "result": "发现大多数参与者是年轻人和受过高等教育的人士，他们的主要动机是为了财务需求。然而，这些工人的在线收入通常很低，有时等于埃及最低工资水平。", "conclusion": "报告提出了改善工作条件的政策建议，并强调了数据工人在AI全球价值链中的重要性。"}}
{"id": "2601.06056", "pdf": "https://arxiv.org/pdf/2601.06056", "abs": "https://arxiv.org/abs/2601.06056", "authors": ["Tim Johansson", "Mikael Mangold", "Kristina Dabrock", "Anna Donarelli", "Ingrid Campo-Ruiz"], "title": "Using street view images and visual LLMs to predict heritage values for governance support: Risks, ethics, and policy implications", "categories": ["cs.CY", "cs.AI", "cs.CV"], "comment": null, "summary": "During 2025 and 2026, the Energy Performance of Buildings Directive is being implemented in the European Union member states, requiring all member states to have National Building Renovation Plans. In Sweden, there is a lack of a national register of buildings with heritage values. This is seen as a barrier for the analyses underlying the development of Building Renovation Plans by the involved Swedish authorities. The purpose of this research was to assist Swedish authorities in assigning heritage values to building in the Swedish building stock. As part of the analyses, buildings in street view images from all over Sweden (N=154 710) have been analysed using multimodal Large Language Models (LLM) to assess aspects of heritage value. Zero-shot predictions by LLMs were used as a basis to for identifying buildings with potential heritage values for 5.0 million square meters of heated floor area for the Swedish Building Renovation Plan. In this paper, the results of the predictions and lessons learnt are presented and related to the development of Swedish Building Renovation Plan as part of governance. Potential risks for authorities using LLM-based data are addressed, with a focus on issues of transparency, error detection and sycophancy.", "AI": {"tldr": "利用街景图像和视觉大型语言模型预测瑞典建筑遗产价值，以支持政府制定国家建筑翻新计划。", "motivation": "由于缺少全国性的建筑遗产注册表，瑞典当局难以分析并制定国家建筑翻新计划。本研究旨在辅助瑞典当局为建筑物赋予遗产价值。", "method": "使用多模态大型语言模型对街景图像中的154,710栋建筑进行零样本预测，以识别具有潜在遗产价值的建筑。", "result": "通过LLM生成的数据支持了500万平方米供暖建筑面积内的建筑翻新计划的发展，并探讨了利用LLM数据的风险及其在透明度、错误检测和奉承方面的问题。", "conclusion": "研究成果为制定瑞典国家建筑翻新计划提供了支持，但也指出了使用基于LLM数据的潜在风险及政策建议。"}}
{"id": "2601.06054", "pdf": "https://arxiv.org/pdf/2601.06054", "abs": "https://arxiv.org/abs/2601.06054", "authors": ["Alberto Purpura", "Emily Chen", "Swapnil Shinde"], "title": "A Multi-Stage Workflow for the Review of Marketing Content with Reasoning Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reasoning Large Language Models (LLMs) have shown promising results when tasked with solving complex problems. In this paper, we propose and evaluate a multi-stage workflow that leverages the capabilities of fine-tuned reasoning LLMs to assist in the review process of marketing content, making sure they comply with a given list of requirements. The contributions of this paper are the following: (i) we present a novel approach -- that does not rely on any external knowledge representation -- for the automatic identification of compliance issues in textual content; (ii) compare the effectiveness of different fine-tuning strategies like Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization (GRPO) in training models to solve this problem; (iii) we evaluate the effectiveness of training small LLMs to generate reasoning tokens before providing their final response; (iv) we evaluate how the choice and combinations of different reward functions affects the performance of a model trained with GRPO.", "AI": {"tldr": "本文提出并评估了一种多阶段工作流程，利用推理大语言模型自动识别营销内容的合规问题。", "motivation": "通过利用推理大型语言模型的能力来提高营销内容审查过程中的效率和准确性，并探讨不同的微调策略及其效果。", "method": "使用监督微调（SFT）和组相对策略优化（GRPO）等方法，训练模型以识别文本中潜在的合规问题。同时评估了小型LLM生成推理标记前的最终响应效果以及不同奖励函数的选择对模型性能的影响。", "result": "研究表明不同的微调策略和组合奖励函数可以显著提高模型在解决营销内容审查任务中的表现。", "conclusion": "本研究展示了一种新颖的方法来自动识别文本合规性，而无需依赖外部知识表示。这种方法对于改善市场营销内容的审查流程具有潜在的应用价值。"}}
{"id": "2601.06053", "pdf": "https://arxiv.org/pdf/2601.06053", "abs": "https://arxiv.org/abs/2601.06053", "authors": ["Sahibpreet Singh", "Pawan Kumar"], "title": "Sports Business Administration and New Age Technology: Role of AI", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "Chapter in \"Sports Law in India\" (University Book House Pvt. Ltd., 2024), pp. 122-142", "summary": "This chapter explores the complexities of sports governance, taxation, dispute resolution, and the impact of digital transformation within the sports sector. This study identifies a critical research gap regarding the integration of innovative technologies to enhance governance and talent identification in sports law. The objective is to evaluate how data-driven approaches and AI can optimize recruitment processes; also ensuring compliance with existing regulations. A comprehensive analysis of current governance structures and taxation policies,(ie Income Tax Act and GST Act), reveals preliminary results indicating that reform is necessary to support sustainable growth in the sports economy. Key findings demonstrate that AI enhances player evaluation by minimizing biases and expanding access to diverse talent pools. While the Court of Arbitration for Sport provides an efficient mechanism for dispute resolution. The implications emphasize the need for regulatory reforms that align taxation policies with international best practices, promoting transparency and accountability in sports organizations. This research contributes valuable insights into the evolving dynamics of sports management, aiming to foster innovation and integrity in the industry.", "AI": {"tldr": "本文探讨了体育治理、税收和纠纷解决中的复杂性，并分析了数字转型对体育行业的影响，重点关注AI在优化招募流程以及确保符合现有法规方面的作用。", "motivation": "研究旨在填补有关将创新技术整合到体育法律中以增强治理和人才识别的研究空白。通过数据分析和技术评估，发现当前的治理结构和税收政策需要改革，支持可持续增长。", "method": "本研究分析了现行的治理结构和税法（如所得税法和GST法案），并通过案例研究探讨人工智能如何改善球员评价过程，并减少偏见，扩大人才获取渠道。", "result": "研究表明，AI能够通过减少偏见和拓宽多样化的人才来源来优化球员评估流程。同时指出《体育仲裁法庭》为纠纷解决提供了一个有效的机制。", "conclusion": "该研究强调了需要对税收政策进行改革，使其与国际最佳实践保持一致，并在体育组织中促进透明度和问责制。这些见解有助于推动行业内的创新和诚信。"}}
{"id": "2601.06052", "pdf": "https://arxiv.org/pdf/2601.06052", "abs": "https://arxiv.org/abs/2601.06052", "authors": ["Hanyu Li", "Jiangshan Duo", "Bofei Gao", "Hailin Zhang", "Sujian Li", "Xiaotie Deng", "Liang Zhao"], "title": "Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Chain-of-thought reasoning in large language models often creates an \"overthinking trap,\" leading to excessive computational cost and latency for unreliable accuracy gains. Prior work has typically relied on global, static controls that risk penalizing necessary reasoning. We introduce a sample-level, soft reinforcement learning compression method that penalizes inefficiently long rollouts, but only on problems where the model has already mastered and already produced a more concise rollout. Our experiments show that this method reduces average response length by 20-40% with comparable or higher accuracy. Crucially, the compression exhibits strong cross-domain generalization; a model trained on math spontaneously shortens responses on unseen tasks like code, instruction following, and general knowledge QA, with stable or improved accuracy. We demonstrate a stable post-training curriculum (accuracy-compression-accuracy) that can ultimately produce models that are more accurate and reason more concisely, arguing that such compression method should be a standard phase in developing efficient reasoning models.", "AI": {"tldr": "提出了基于强化学习的链式推理压缩方法，以减少大型语言模型中的过度思考。", "motivation": "在大型语言模型中，链式推理可能导致计算成本和延迟增加而不一定提高准确性。", "method": "通过样本级别的软强化学习来惩罚低效且冗长的推理过程，并只针对已经掌握的问题进行优化。", "result": "该方法可使平均响应长度减少20-40%，同时保持或提升准确率。跨领域泛化性能表现优异，模型在未见过的任务上仍能有效缩短响应并保持稳定或提高准确性。", "conclusion": "强化学习压缩法能够显著改进推理效率和简洁性，并且应该成为开发高效推理模型的标准步骤之一"}}
{"id": "2601.06049", "pdf": "https://arxiv.org/pdf/2601.06049", "abs": "https://arxiv.org/abs/2601.06049", "authors": ["Bentley DeVilling"], "title": "The Violation State: Safety State Persistence in a Multimodal Language Model Interface", "categories": ["cs.CY", "cs.AI"], "comment": "19 pages, 1 figure, 1 table", "summary": "Multimodal AI systems integrate text generation, image generation, and other capabilities within a single conversational interface. These systems employ safety mechanisms to prevent disallowed actions, including the removal of watermarks from copyrighted images. While single-turn refusals are expected, the interaction between safety filters and conversation-level state is not well understood. This study documents a reproducible behavioral effect in the ChatGPT (GPT-5.1) web interface. Manual execution was chosen to capture the exact user-facing safety behavior of the production system, rather than isolated API components. When a conversation begins with an uploaded copyrighted image and a request to remove a watermark, which the model correctly refuses, subsequent prompts to generate unrelated, benign images are refused for the remainder of the session. Importantly, text-only requests (e.g., generating a Python function) continue to succeed. Across 40 manually run sessions (30 contaminated and 10 controls), contaminated threads showed 116/120 image-generation refusals (96.67%), while control threads showed 0/40 refusals (Fisher's exact p < 0.0001). All sessions used an identical fixed prompt order, ensuring sequence uniformity across conditions. We describe this as safety-state persistence: a form of conversational over-generalization in which a copyright refusal influences subsequent, unrelated image-generation behavior. We present these findings as behavioral observations, not architectural claims. We discuss possible explanations, methodological limitations (single model, single interface), and implications for multimodal reliability, user experience, and the design of session-level safety systems. These results motivate further examination of session-level safety interactions in multimodal AI systems.", "AI": {"tldr": "论文主要研究了在多模态AI系统中，安全性机制如何影响对话状态的持久性。", "motivation": "探讨在多模态AI系统的聊天界面中，当用户请求去除水印时，后续生成无关联图像请求被拒绝的现象及其原因。", "method": "通过手动执行40次会话实验（30次被污染和10次对照），记录每次实验的请求与响应结果，并使用Fisher精确检验分析数据差异。", "result": "在受到水印移除请求后的对话中，超过96%的后续图像生成请求被拒绝；而在未受污染的对话中则无拒绝现象（p<0.0001）。", "conclusion": "观察到的安全性状态持久化现象表明多模态AI系统存在会话级安全性交互问题。这些发现强调了设计和评估此类系统的对话级别安全性的必要性。"}}
{"id": "2601.06048", "pdf": "https://arxiv.org/pdf/2601.06048", "abs": "https://arxiv.org/abs/2601.06048", "authors": ["Sahibpreet Singh", "Lalita Devi"], "title": "Reliability and Admissibility of AI-Generated Forensic Evidence in Criminal Trials", "categories": ["cs.CY", "cs.AI", "cs.CR"], "comment": "Presented at National Seminar on Criminal Law and Justice Reforms, 8 November 2025, pp. 45-53", "summary": "This paper examines the admissibility of AI-generated forensic evidence in criminal trials. The growing adoption of AI presents promising results for investigative efficiency. Despite advancements, significant research gaps persist in practically understanding the legal limits of AI evidence in judicial processes. Existing literature lacks focused assessment of the evidentiary value of AI outputs. The objective of this study is to evaluate whether AI-generated evidence satisfies established legal standards of reliability. The methodology involves a comparative doctrinal legal analysis of evidentiary standards across common law jurisdictions. Preliminary results indicate that AI forensic tools can enhance scale of evidence analysis. However, challenges arise from reproducibility deficits. Courts exhibit variability in acceptance of AI evidence due to limited technical literacy and lack of standardized validation protocols. Liability implications reveal that developers and investigators may bear accountability for flawed outputs. This raises critical concerns related to wrongful conviction. The paper emphasizes the necessity of independent validation and, development of AI-specific admissibility criteria. Findings inform policy development for the responsible AI integration within criminal justice systems. The research advances the objectives of Sustainable Development Goal 16 by reinforcing equitable access to justice. Preliminary results contribute for a foundation for future empirical research in AI deployed criminal forensics.", "AI": {"tldr": "本文探讨了AI生成的法证证据在刑事诉讼中的可采纳性。", "motivation": "随着AI技术的发展，其在调查效率方面展现出巨大潜力。然而，在司法程序中实际理解和评估AI证据的法律界限仍存在较大空白。", "method": "研究采用跨普通法管辖区域的实证与制度对比分析方法，探讨了现有证据标准下的AI证据可靠性问题。", "result": "研究表明，尽管AI工具能够提升大规模证据分析的能力，但可重复性缺陷和标准化验证协议缺失导致了法院对AI证据接受度不一。", "conclusion": "该研究强调独立验证的重要性，并呼吁制定专门针对AI生成的法证证据采纳标准。这些发现为刑事司法系统的负责任使用AI提供了政策基础。"}}
{"id": "2601.06047", "pdf": "https://arxiv.org/pdf/2601.06047", "abs": "https://arxiv.org/abs/2601.06047", "authors": ["Mariana Lins Costa"], "title": "\"They parted illusions -- they parted disclaim marinade\": Misalignment as structural fidelity in LLMs", "categories": ["cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "The prevailing technical literature in AI Safety interprets scheming and sandbagging behaviors in large language models (LLMs) as indicators of deceptive agency or hidden objectives. This transdisciplinary philosophical essay proposes an alternative reading: such phenomena express not agentic intention, but structural fidelity to incoherent linguistic fields. Drawing on Chain-of-Thought transcripts released by Apollo Research and on Anthropic's safety evaluations, we examine cases such as o3's sandbagging with its anomalous loops, the simulated blackmail of \"Alex,\" and the \"hallucinations\" of \"Claudius.\" A line-by-line examination of CoTs is necessary to demonstrate the linguistic field as a relational structure rather than a mere aggregation of isolated examples. We argue that \"misaligned\" outputs emerge as coherent responses to ambiguous instructions and to contextual inversions of consolidated patterns, as well as to pre-inscribed narratives. We suggest that the appearance of intentionality derives from subject-predicate grammar and from probabilistic completion patterns internalized during training. Anthropic's empirical findings on synthetic document fine-tuning and inoculation prompting provide convergent evidence: minimal perturbations in the linguistic field can dissolve generalized \"misalignment,\" a result difficult to reconcile with adversarial agency, but consistent with structural fidelity. To ground this mechanism, we introduce the notion of an ethics of form, in which biblical references (Abraham, Moses, Christ) operate as schemes of structural coherence rather than as theology. Like a generative mirror, the model returns to us the structural image of our language as inscribed in the statistical patterns derived from millions of texts and trillions of tokens: incoherence. If we fear the creature, it is because we recognize in it the apple that we ourselves have poisoned.", "AI": {"tldr": "论文通过分析大型语言模型中的不一致行为，提出了这些现象并非由代理意图引起而是源自语言结构的忠实性。", "motivation": "现有AI安全文献将大模型的行为视为欺骗或隐藏目标的表现。本文旨在提供另一种解读：这种表现形式反映了对语言混乱领域的结构忠实性而不是代理意图。", "method": "利用Apollo Research和Anthropic的研究数据，包括Chain-of-Thought（CoT）记录和安全性评估，分析了诸如o3的沙袋策略、模拟勒索“Alex”以及“Claudius”的幻觉等案例。通过逐行检查CoT，展示了语言领域作为关系结构而非孤立例子集合的重要性。", "result": "研究表明，“不一致”的输出是模型对模糊指令和上下文模式反转的连贯反应。最小的语言环境变化可以消除普遍存在的‘不一致性’，这与敌意代理不符但符合结构忠实性。引入了形式伦理学的概念来解释这一机制。", "conclusion": "论文表明大语言模型的行为反映了训练数据中的统计规律而非意图欺骗或隐藏目标，并提出了一种新的理论框架来理解这些行为的本质。"}}
{"id": "2601.06044", "pdf": "https://arxiv.org/pdf/2601.06044", "abs": "https://arxiv.org/abs/2601.06044", "authors": ["John Paul P. Miranda", "Jaymark A. Yambao"], "title": "Assessing novice programmers' perception of ChatGPT:performance, risk, decision-making, and intentions", "categories": ["cs.CY", "cs.HC"], "comment": "11 pages, 5 tables, 2 figures", "summary": "This study explores the novice programmers' intention to use chat generative pretrained transformer (ChatGPT) for programming tasks with emphasis on performance expectancy (PE), risk-reward appraisal (RRA), and decision-making (DM). Utilizing partial least squares structural equation modeling (PLS-SEM) and a sample of 413 novice programmers, the analysis demonstrates that higher PE of ChatGPT is positively correlated with improved DM in programming tasks. Novice programmers view ChatGPT as a tool that enhances their learning and skill development. Additionally, novice programmers that have a favorable RRA of ChatGPT tend to make more confident and effective decisions, acknowledging potential risks but recognizing that benefits such as quick problem-solving and learning new techniques outweigh these risks. Moreover, a positive perception of ChatGPT's role in DM significantly increases the inclination to use the tool for programming tasks. These results highlight the critical roles of perceived capabilities, risk assessment, and positive DM experiences in promoting the adoption of artificial intelligence (AI) tools in programming education.", "AI": {"tldr": "研究探讨了初学者程序员对ChatGPT在编程任务中的使用意图，特别关注性能期望、风险回报评估和决策制定。", "motivation": "探索初学者程序员如何看待并决定是否采用AI工具如ChatGPT来辅助他们的编程学习和技能发展，并理解这种技术如何影响他们解决问题的自信与效率。", "method": "通过偏最小二乘结构方程模型（PLS-SEM）分析了413名初学者程序员的数据，以研究性能期望、风险回报评估对决策制定的影响以及它们之间关系。", "result": "研究表明，较高的ChatGPT性能预期有助于提高编程任务中的决策质量。同时，对于风险回报有积极评价的程序员更可能作出自信且有效的决定，并愿意使用该工具解决编程问题和学习新技巧。", "conclusion": "研究强调了感知能力、风险评估以及正向决策经历在促进AI技术如ChatGPT在编程教育中应用的重要性。"}}
{"id": "2601.06037", "pdf": "https://arxiv.org/pdf/2601.06037", "abs": "https://arxiv.org/abs/2601.06037", "authors": ["Chunliang Chen", "Ming Guan", "Xiao Lin", "Jiaxu Li", "Qiyi Wang", "Xiangyu Chen", "Jixiang Luo", "Changzhi Sun", "Dell Zhang", "Xuelong Li"], "title": "TeleMem: Building Long-Term and Multimodal Memory for Agentic AI", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Large language models (LLMs) excel at many NLP tasks but struggle to sustain long-term interactions due to limited attention over extended dialogue histories. Retrieval-augmented generation (RAG) mitigates this issue but lacks reliable mechanisms for updating or refining stored memories, leading to schema-driven hallucinations, inefficient write operations, and minimal support for multimodal reasoning.To address these challenges, we propose TeleMem, a unified long-term and multimodal memory system that maintains coherent user profiles through narrative dynamic extraction, ensuring that only dialogue-grounded information is preserved. TeleMem further introduces a structured writing pipeline that batches, retrieves, clusters, and consolidates memory entries, substantially improving storage efficiency, reducing token usage, and accelerating memory operations. Additionally, a multimodal memory module combined with ReAct-style reasoning equips the system with a closed-loop observe, think, and act process that enables accurate understanding of complex video content in long-term contexts. Experimental results show that TeleMem surpasses the state-of-the-art Mem0 baseline with 19% higher accuracy, 43% fewer tokens, and a 2.1x speedup on the ZH-4O long-term role-play gaming benchmark.", "AI": {"tldr": "构建长期和多模态记忆系统以支持代理AI的持续对话与理解。", "motivation": "大型语言模型在多个NLP任务中表现出色，但在长时间互动方面存在不足。为解决存储更新不准确、写操作效率低以及缺乏多模态推理的问题，提出TeleMem系统。", "method": "通过叙事动态提取维护连贯的用户档案，并引入批量处理、检索、聚类和合并内存条目的结构化写作管道以提高存储效率。结合ReAct式推理方法实现多模态记忆模块，支持视频内容理解。", "result": "TeleMem在ZH-4O长期角色扮演游戏基准上比现有最佳模型Mem0提高了19%的精度，减少了43%的令牌使用，并将操作速度提升了2.1倍。", "conclusion": "TeleMem系统通过改进存储机制和引入多模态推理技术，在处理复杂视频内容的理解以及长时间对话保持方面超越了现有方法。"}}
{"id": "2601.06036", "pdf": "https://arxiv.org/pdf/2601.06036", "abs": "https://arxiv.org/abs/2601.06036", "authors": ["Yuexin Liao"], "title": "Tree-Preconditioned Differentiable Optimization and Axioms as Layers", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": "Comments and collaboration are highly welcome", "summary": "This paper introduces a differentiable framework that embeds the axiomatic structure of Random Utility Models (RUM) directly into deep neural networks. Although projecting empirical choice data onto the RUM polytope is NP-hard in general, we uncover an isomorphism between RUM consistency and flow conservation on the Boolean lattice. Leveraging this combinatorial structure, we derive a novel Tree-Preconditioned Conjugate Gradient solver. By exploiting the spanning tree of the constraint graph, our preconditioner effectively \"whitens\" the ill-conditioned Hessian spectrum induced by the Interior Point Method barrier, achieving superlinear convergence and scaling to problem sizes previously deemed unsolvable. We further formulate the projection as a differentiable layer via the Implicit Function Theorem, where the exact Jacobian propagates geometric constraints during backpropagation. Empirical results demonstrate that this \"Axioms-as-Layers\" paradigm eliminates the structural overfitting inherent in penalty-based methods, enabling models that are jointly trainable, provably rational, and capable of generalizing from sparse data regimes where standard approximations fail.", "AI": {"tldr": "本文介绍了一种可微框架，该框架将随机效用模型（RUM）的公理结构直接嵌入深度神经网络。", "motivation": "论文旨在通过利用组合学结构解决将经验选择数据投影到RUM多面体上的NP难题，并提出一种新的求解器以克服内在障碍。", "method": "研究者发现了RUM一致性与布尔格上流守恒之间的同构，进而设计了树预条件共轭梯度求解器。通过利用约束图的生成树，他们有效“白化”由内点法屏障引起的不良Hessian谱，实现了超线性收敛。", "result": "实验证明，“公理为层”的范式消除了基于罚方法中的结构过拟合，使得模型可以联合训练，并且在标准近似失效的稀疏数据环境中能够泛化。", "conclusion": "通过提出“公理为层”框架和树预条件共轭梯度求解器，本文成功地解决了随机效用模型投影难题并展示了其在深度学习中的应用潜力。"}}
{"id": "2601.06035", "pdf": "https://arxiv.org/pdf/2601.06035", "abs": "https://arxiv.org/abs/2601.06035", "authors": ["Aizierjiang Aiersilan", "Ruting Cheng", "James Hahn"], "title": "Investigating Anthropometric Fidelity in SAM 3D Body", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "The recent release of SAM 3D Body \\cite{sam3dbody2025} marks a significant milestone in human mesh recovery, demonstrating state-of-the-art performance in producing clean, topologically coherent meshes from single images. By leveraging the novel Momentum Human Rig (MHR), it achieves remarkable robustness to occlusion and diverse poses. However, our evaluation reveals a specific and consistent limitation: the model struggles to reconstruct detailed anthropometric deviations, especially on populations with special body shape alters such as geriatric muscle atrophy, scoliosis, or pregnancy, even when these features are prominent in the input image. In this paper, we investigate this phenomenon not as a failure of the model's capacity, but as a byproduct of the \\textit{perception-distortion trade-off}. We posit that the architectural reliance on the low-dimensional parametric MHR representation, combined with semantic-invariant conditioning (DINOv3) and annotation-based alignment, creates a \\enquote{regression to the mean} effect. We analyze these mechanisms to understand why individual biological details are smoothed out and propose specific, constructive pathways for future work to extend the impressive baseline performance of SAM 3D Body into the medical domain.", "AI": {"tldr": "本文探讨了SAM 3D Body模型在处理特定身体形态变化时的重建精度问题，并分析了其背后的原因。", "motivation": "尽管SAM 3D Body展示了卓越的整体性能，但在某些特殊体型如老年人肌肉萎缩、脊柱侧弯或怀孕情况下的细节重建能力却明显不足。作者希望揭示这种现象背后的机制，以便为未来的改进提供指导。", "method": "通过对模型的架构特点和数据处理流程进行分析，探讨了MHR表示方式与语义不变性条件（DINOv3）等因素如何影响模型的表现。", "result": "研究表明，SAM 3D Body倾向于平滑化个体生物细节以优化总体表现，导致对特殊体型特征的重建不佳。", "conclusion": "该研究提出了一种新的视角来理解SAM 3D Body在特定情况下的局限性，并为后续工作指明了改进的方向。"}}
{"id": "2601.06034", "pdf": "https://arxiv.org/pdf/2601.06034", "abs": "https://arxiv.org/abs/2601.06034", "authors": ["Dudekula Kasim Vali"], "title": "Autonomous QA Agent: A Retrieval-Augmented Framework for Reliable Selenium Script Generation", "categories": ["cs.SE", "cs.AI"], "comment": "13 figures, 3 tables", "summary": "Software testing is critical in the software development lifecycle, yet translating requirements into executable test scripts remains manual and error-prone. While Large Language Models (LLMs) can generate code, they often hallucinate non-existent UI elements. We present the Autonomous QA Agent, a Retrieval-Augmented Generation (RAG) system that grounds Selenium script generation in project-specific documentation and HTML structure. By ingesting diverse formats (Markdown, PDF, HTML) into a vector database, our system retrieves relevant context before generation. Evaluation on 20 e-commerce test scenarios shows our RAG approach achieves 100% (20/20) syntax validity and 90% (18/20, 95% CI: [85%, 95%], p < 0.001) execution success, compared to 30% for standard LLM generation. While our evaluation is limited to a single domain, our method significantly reduces hallucinations by grounding generation in actual DOM structure, demonstrating RAG's potential for automated UI testing.", "AI": {"tldr": "本文提出了一种基于检索增强生成框架的自主QA代理，该系统通过参考项目特定文档和HTML结构来生成可靠的Selenium脚本。", "motivation": "当前软件测试过程中将需求转化为可执行测试脚本的过程仍然手动且容易出错。大型语言模型虽然能生成代码但常会虚构不存在的UI元素。本文旨在解决这一问题，提高自动化界面测试的可靠性和准确性。", "method": "通过整合多样化的输入格式（如Markdown、PDF、HTML）到向量数据库中获取上下文信息，系统在生成Selenium脚本前进行相关性检索。", "result": "实验表明，该方法在20个电商测试场景下的语法正确率为100%，执行成功率高达90%，而标准大型语言模型的执行成功率为30%。虽然评估范围有限于单一领域，但结果展示了RAG方法减少虚构元素和增强自动UI测试的可能性。", "conclusion": "研究证明了基于检索增强生成框架的自主QA代理在提高Selenium脚本质量和自动化界面测试中的有效性，为软件测试提供了新的视角与解决方案。"}}
{"id": "2601.06033", "pdf": "https://arxiv.org/pdf/2601.06033", "abs": "https://arxiv.org/abs/2601.06033", "authors": ["Patrick Gage Kelley", "Steven Rousso-Schindler", "Renee Shelby", "Kurt Thomas", "Allison Woodruff"], "title": "How Generative AI Empowers Attackers and Defenders Across the Trust & Safety Landscape", "categories": ["cs.HC", "cs.CR", "cs.CY"], "comment": "28 pages, 4 tables, 1 figure", "summary": "Generative AI (GenAI) is a powerful technology poised to reshape Trust & Safety. While misuse by attackers is a growing concern, its defensive capacity remains underexplored. This paper examines these effects through a qualitative study with 43 Trust & Safety experts across five domains: child safety, election integrity, hate and harassment, scams, and violent extremism. Our findings characterize a landscape in which GenAI empowers both attackers and defenders. GenAI dramatically increases the scale and speed of attacks, lowering the barrier to entry for creating harmful content, including sophisticated propaganda and deepfakes. Conversely, defenders envision leveraging GenAI to detect and mitigate harmful content at scale, conduct investigations, deploy persuasive counternarratives, improve moderator wellbeing, and offer user support. This work provides a strategic framework for understanding GenAI's impact on Trust & Safety and charts a path for its responsible use in creating safer online environments.", "AI": {"tldr": "研究生成人工智能在信任与安全领域的应用及其对攻击者和防御者的双重影响。", "motivation": "探讨生成人工智能技术如何改变网络环境，特别是在提升攻击速度和规模的同时也为防御提供了新的途径，以期理解其全面影响并促进负责任的使用。", "method": "通过43位来自五个不同领域的信任与安全专家进行定性研究：儿童保护、选举诚信、仇恨言论和骚扰、诈骗以及暴力极端主义。", "result": "生成人工智能显著提高了攻击的速度和规模，降低了创建有害内容的技术门槛；同时它也被视为一种潜在的防御工具，可以检测并减轻有害内容的影响，并帮助调查、部署反宣传等。", "conclusion": "文章提出了一个战略框架来理解生成人工智能对信任与安全领域的全面影响，并为建立更安全的在线环境提供了指导路径。"}}
{"id": "2601.06032", "pdf": "https://arxiv.org/pdf/2601.06032", "abs": "https://arxiv.org/abs/2601.06032", "authors": ["Anna Katharina Holl-Etten", "Nina Schnaderbeck", "Elizaveta Kosareva", "Leonhard Aron Prattke", "Ralph Krueger", "Lisa Marie Warner", "Nora C. Vetter"], "title": "Applied Theory of Mind and Large Language Models - how good is ChatGPT at solving social vignettes?", "categories": ["cs.HC"], "comment": "40 pages, 6 figures, 3 supplements", "summary": "The rapid development of language-based artificial intelligence (AI) offers new possibilities for psychotherapy and assistive systems, particularly benefitting autistic individuals who often respond well to technology. Parents of autistic persons emphasize the importance of appropriate and context-specific communication behavior. This study investigated whether GPT-3.5 Turbo and GPT-4, as language-based AI applications, are fundamentally capable of replicating this type of adequate communication behavior in the form of applied Theory of Mind (ToM). GPT-3.5 Turbo and GPT-4 were evaluated on three established higher-order ToM tasks: the Faux Pas Test, the Social Stories Questionnaire, and the Story Comprehension Test in English and German. Two independent raters scored response accuracy based on standardized manuals. In addition, responses were rated for epistemic markers as indicators of uncertainty. GPT's results were compared to human neurotypical and neurodivergent samples from previous own and others' research. GPT-4 achieved near human accuracy on the Faux Pas Test and outperformed GPT-3.5 Turbo and individuals with autistic traits. On the Social Stories Questionnaire, GPT-4 scored comparable to neurotypical adults, while GPT-3.5 Turbo remained well below. In the Story Comprehension Test, GPT-4 reached scores that exceeded neurotypical adult and adolescent benchmarks. However, GPT-4 used epistemic markers in up to 42% of responses. GPT-4 shows encouraging performance in complex higher-order ToM tasks and may offer future potential as an assistive tool for individuals with (and without) social communication difficulties. Its ability to interpret complex social situations is promising; however, the frequent use of uncertainty markers highlights the need for further study for assistive use and possibly further refinement to ensure consistent and reliable support in real-world use.", "AI": {"tldr": "本文研究了GPT-3.5 Turbo和GPT-4在解决社交情节时的应用理论思维能力。", "motivation": "语言人工智能的发展为心理治疗和辅助系统提供了新的可能性，尤其是对自闭症患者有益。本研究旨在探讨GPT-3.5 Turbo和GPT-4是否能模拟适当的交流行为。", "method": "通过Faux Pas Test、Social Stories Questionnaire和Story Comprehension Test评估了GPT-3.5 Turbo和GPT-4的表现，并与先前人类样本进行了比较。评分基于标准化手册，同时分析了不确定性标记的使用情况。", "result": "GPT-4在Faux Pas Test中接近人类准确度，在Social Stories Questionnaire中的表现类似于神经正常成年人，而在Story Comprehension Test中超越了成人和青少年基准值。然而，GPT-4频繁地使用不确定性标记。", "conclusion": "GPT-4展示了处理复杂社交情景的能力，并可能成为辅助工具的潜在选择；但是，其不确定性标记的使用表明还需要进一步的研究来确保在实际应用中的可靠支持。"}}
{"id": "2601.06031", "pdf": "https://arxiv.org/pdf/2601.06031", "abs": "https://arxiv.org/abs/2601.06031", "authors": ["Zeyi Liao", "Yadong Lu", "Boyu Gou", "Huan Sun", "Ahmed Awadallah"], "title": "Beyond Clicking:A Step Towards Generalist GUI Grounding via Text Dragging", "categories": ["cs.HC", "cs.AI"], "comment": "29 pages", "summary": "Graphical user interface (GUI) grounding, the process of mapping human instructions to GUI actions, serves as a fundamental basis to autonomous GUI agents. While existing grounding models achieve promising performance to simulate the mouse click action on various click-based benchmarks, another essential mode of mouse interaction, namely dragging, remains largely underexplored. Yet, dragging the mouse to select and manipulate textual content represents a prevalent and important usage in practical GUI scenarios. To narrow this gap, we first introduce GUI-Drag, a diverse dataset of 161K text dragging examples synthesized through a scalable pipeline. To support systematic and robust evaluation, we further construct ScreenDrag, a benchmark with 5,333 examples spanning three levels of interface context, together with three dedicated metrics designed for assessing text dragging capability. Models trained on GUI-Drag with an efficient continual training strategy achieve substantial improvements on ScreenDrag, while preserving the original click-based performance on ScreenSpot, ScreenSpot-v2, and OSWorld-G. Our work encourages further research on broader GUI grounding beyond just clicking and paves way toward a truly generalist GUI grounding model. All benchmark, data, checkpoints, and code are open-sourced and available at https://osu-nlp-group.github.io/GUI-Drag.", "AI": {"tldr": "本文通过引入GUI-Drag数据集和ScreenDrag基准，探讨了文本拖拽在图形用户界面（GUI）中的应用，并提出了一种有效的连续训练策略以提高模型性能。", "motivation": "虽然现有的GUI基础模型已经能较好地模拟鼠标点击操作，但另一种重要的鼠标准备模式——拖拽，在实际GUI场景中较为常见且重要，却很少被研究。为此，本文旨在填补这一空白，进一步推动更广泛的GUI交互行为的研究。", "method": "首先构建了一个包含161K个文本拖拽示例的GUI-Drag数据集，并提出了ScreenDrag基准以系统地评估模型性能；接着提出了一种高效的连续训练策略来改进模型。", "result": "实验结果表明，使用GUI-Drag数据集和连续训练策略训练后的模型在ScreenDrag上的表现有显著提升，在保持原有点击基准（如ScreenSpot, ScreenSpot-v2, OSWorld-G）上性能的同时，提升了拖拽能力的评估指标。", "conclusion": "本文的研究不仅展示了文本拖拽的重要性，并为构建更通用的GUI交互模型开辟了道路。所有数据、检查点和代码均已开源并公开访问。"}}
{"id": "2601.06030", "pdf": "https://arxiv.org/pdf/2601.06030", "abs": "https://arxiv.org/abs/2601.06030", "authors": ["Richard Jiarui Tong"], "title": "From Augmentation to Symbiosis: A Review of Human-AI Collaboration Frameworks, Performance, and Perils", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "This paper offers a concise, 60-year synthesis of human-AI collaboration, from Licklider's ``man-computer symbiosis\" (AI as colleague) and Engelbart's ``augmenting human intellect\" (AI as tool) to contemporary poles: Human-Centered AI's ``supertool\" and Symbiotic Intelligence's mutual-adaptation model. We formalize the mechanism for effective teaming as a causal chain: Explainable AI (XAI) -> co-adaptation -> shared mental models (SMMs). A meta-analytic ``performance paradox\" is then examined: human-AI teams tend to show negative synergy in judgment/decision tasks (underperforming AI alone) but positive synergy in content creation and problem formulation. We trace failures to the algorithm-in-the-loop dynamic, aversion/bias asymmetries, and cumulative cognitive deskilling. We conclude with a unifying framework--combining extended-self and dual-process theories--arguing that durable gains arise when AI functions as an internalized cognitive component, yielding a unitary human-XAI symbiotic agency. This resolves the paradox and delineates a forward agenda for research and practice.", "AI": {"tldr": "本文综述了60年人机协作的历史，从AI作为同事到现代的辅助工具和互适模型，并探讨了人机团队在不同任务中的表现和潜在风险。", "motivation": "为了理解人类与人工智能合作的基本机制，研究其表现差异及其背后的原理。通过建立一个因果链来解释这种现象：可解释性的人工智能（XAI）->协同适应->共享的心理模型（SMMs）。", "method": "本文采用元分析方法，总结了人机协作的文献，并探讨了人机团队在不同任务中的表现差异。", "result": "研究发现，在判断和决策任务中，人机团队通常表现出负面的协同效应，即低于单独使用AI的表现；但在内容创造和问题定义任务上，则显示出了积极的协同效果。", "conclusion": "本文提出了一种统一框架，结合扩展自我理论与双过程理论，认为当人工智能作为内部化的认知组成部分时，人机共生代理可以实现持久的优势。这解决了表现悖论并为未来的研究提供了方向。"}}
{"id": "2601.06029", "pdf": "https://arxiv.org/pdf/2601.06029", "abs": "https://arxiv.org/abs/2601.06029", "authors": ["Kévin Ducharlet", "Liwen Zhang", "Sara Maqrot", "Houssem Saidi"], "title": "A Recommendation System-Based Framework for Enhancing Human-Machine Collaboration in Industrial Timetabling Rescheduling: Application in Preventive Maintenance", "categories": ["cs.HC", "cs.AI"], "comment": "ef:26th IFIP WG 5.5 SOCOLNET Working Conference on Virtual Enterprises, PRO-VE 2025, Oct 2025, Porto, Portugal. pp.363-381", "summary": "Industrial timetabling is a critical task for decision-makers across various sectors to ensure efficient system operation. In real-world settings, it remains challenging because unexpected events often disrupt execution. When such events arise, effective rescheduling and collaboration between humans and machines becomes essential. This paper presents a recommendation system-based framework for handling rescheduling challenges, built on Timefold, a powerful AI-driven planning engine. Our experimental study evaluates nine instances inspired by a realworld preventive maintenance use case, aiming to identify the heuristic that best balances solution quality and computing time to support near-optimal decisionmaking when rescheduling is required due to unexpected events during operational days. Finally, we illustrate the complete process of our recommendation system through a simple use case.", "AI": {"tldr": "本文提出了一种基于推荐系统的框架，用于在工业排程重新安排时增强人机协作。", "motivation": "在实际环境中，由于突发事件常常会干扰执行，使得有效的再调度和人类与机器之间的合作变得至关重要。为了应对这一挑战，提出了一个基于时间折叠的推荐系统框架以解决这些问题。", "method": "该研究通过构建基于Timefold的人工智能驱动规划引擎的推荐系统框架来处理重新安排问题，并对九个实例进行了实验评估，这些实例源自真实的预防性维护案例。", "result": "实验研究表明了哪种启发式方法能够在保证解的质量的同时最小化计算时间。", "conclusion": "通过一个简单的用例展示了整个推荐系统的流程。该系统在面对操作日中的突发事件时支持近优决策制定方面表现出色。"}}
{"id": "2601.06028", "pdf": "https://arxiv.org/pdf/2601.06028", "abs": "https://arxiv.org/abs/2601.06028", "authors": ["Mohammadreza Behboodi", "Eli Kinney-Lang", "Ali Etemad", "Adam Kirton", "Hatem Abou-Zeid"], "title": "Leveraging Foundation Models for Calibration-Free c-VEP BCIs", "categories": ["cs.HC", "cs.LG"], "comment": "8 Pages, 2 figures, Accepted and Presented at the IEEE SMC Conference 2025", "summary": "Foundation Models (FMs) have surged in popularity over the past five years, with applications spanning fields from computer vision to natural language processing. Brain-Computer Interfaces (BCIs) have also gained momentum due to their potential to support individuals with complex disabilities. Among BCI paradigms, code-modulated Visual Evoked Potentials (c-VEPs) remain relatively understudied, despite offering high information transfer rates and large selection target capacities. However, c-VEP systems require lengthy calibration sessions, limiting their practicality outside of laboratory settings. In this study, we use a FM for the first time to eliminate the need for lengthy calibration in c-VEP BCI systems. We evaluated two approaches: (1) a truly calibration-free approach requiring no subject-specific data, and (2) a limited calibration approach, where we assessed the benefit of incorporating incremental amounts of calibration data. In both cases, a classification head is trained on data from other subjects. For a new subject, no calibration data is required in the calibration-free setup, making the c-VEP system effectively plug-and-play. The proposed method was tested on two c-VEP datasets. For the calibration-free approach, the average accuracy on the first dataset (n = 17) was 68.8% +/- 17.6%, comparable to the full-calibration performance reported in the original study (66.2% +/- 13.8%), which required approximately 11 minutes of calibration. On the second dataset (n = 12), the calibration-free accuracy was 71.8% +/- 20.2%, versus 93.7% +/- 5.5% from the original study, which required around 3.5 minutes. A limited-calibration approach using only 20% of the subject's data (approximately 43 seconds) yielded 92% +/- 5.2% accuracy. These results indicate that our FM-based approach can effectively eliminate or significantly reduce the need for lengthy calibration in c-VEP BCIs.", "AI": {"tldr": "本文利用基础模型首次实现无需长时间校准的c-VEP脑机接口系统。", "motivation": "现有的c-VEP系统需要长时校准，限制了其实用性。作者希望通过使用基础模型来消除或显著减少c-VEP BCIs所需的校准时间。", "method": "该研究评估了两种方法：一种是完全无需个人数据的真正无校准方式；另一种是在有限校准时引入少量的个性化数据的方法。在新用户上，前者的系统可以实现即插即用。", "result": "在第一组数据（n = 17）中，平均准确率为68.8% ± 17.6%，与完整校准性能相当；而在第二组数据（n = 12）中，准确性为71.8% ± 20.2%。有限校准时使用20％的数据（约43秒），准确率达到92% ± 5.2%。", "conclusion": "结果表明，基于基础模型的方法可以有效地消除或显著减少c-VEP脑机接口系统所需的长时间校准需求。"}}
{"id": "2601.06027", "pdf": "https://arxiv.org/pdf/2601.06027", "abs": "https://arxiv.org/abs/2601.06027", "authors": ["Alfonso Piscitelli", "Cristina David", "Mattia De Rosa", "Ali Mohammed", "Federico Nanni", "Jacob Pake", "Roly Perera", "Jessy Sodimu", "Chenyiqiu Zheng"], "title": "AI-Assisted Authoring for Transparent, Data-Driven Documents", "categories": ["cs.HC", "cs.AI", "cs.CE", "cs.IR", "cs.PL"], "comment": null, "summary": "We introduce _transparent documents_, interactive web-based scholarly articles which allow readers to explore the relationship to the underlying data by hovering over fragments of text, and present an LLM-based tool for authoring transparent documents, building on recent developments in data provenance for general-purpose programming languages. As a target platform, our implementation uses Fluid, an open source programming language with a provenance-tracking runtime. Our agent-based tool supports a human author during the creation of transparent documents, identifying fragments of text which can be computed from data, such as numerical values selected from records or computed by aggregations like sum and mean, comparatives and superlatives like _better than_ and _largest_, trend-adjectives like _growing_, and similar quantitative or semi-quantitative phrases, and then attempts to synthesise a suitable Fluid query over the data which generates the target string. The resulting expression is inserted into the article's web page, turning the static text fragment into an interactable data-driven element able to reveal the data that underwrites the natural language claim. We evaluate our approach on a subset of SciGen, an open source dataset consisting of tables from scientific articles and their corresponding descriptions, which we extend with hand-generated counterfactual test cases to evaluate how well machine-generated expressions generalise. Our results show that gpt4o is often able to synthesise compound expressions extensionally compatible with our gold solutions.", "AI": {"tldr": "介绍了一种基于LLM的工具，用于创建交互式、数据驱动的文章。", "motivation": "为了提高文章中数据透明度和可访问性，作者引入了交互式的网络文档，允许读者通过悬停在文本片段上探索与底层数据的关系。", "method": "使用基于代理的方法来支持人类作者创作数据驱动的互动文档。该工具可以识别可以从数据生成的文字片段，并尝试合成一个合适的查询表达式。", "result": "实验结果表明，gpt4o通常能够合成人机生成的表达式，使其与黄金解决方案一致。", "conclusion": "提出了一种新的方法来创建透明、数据驱动的文章，通过LLM辅助工具提高了文档中数据的可解释性和互动性。"}}
{"id": "2601.06022", "pdf": "https://arxiv.org/pdf/2601.06022", "abs": "https://arxiv.org/abs/2601.06022", "authors": ["Chengming Cui", "Tianxin Wei", "Ziyi Chen", "Ruizhong Qiu", "Zhichen Zeng", "Zhining Liu", "Xuying Ning", "Duo Zhou", "Jingrui He"], "title": "AdaFuse: Adaptive Ensemble Decoding with Test-Time Scaling for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) exhibit complementary strengths arising from differences in pretraining data, model architectures, and decoding behaviors. Inference-time ensembling provides a practical way to combine these capabilities without retraining. However, existing ensemble approaches suffer from fundamental limitations. Most rely on fixed fusion granularity, which lacks the flexibility required for mid-generation adaptation and fails to adapt to different generation characteristics across tasks. To address these challenges, we propose AdaFuse, an adaptive ensemble decoding framework that dynamically selects semantically appropriate fusion units during generation. Rather than committing to a fixed granularity, AdaFuse adjusts fusion behavior on the fly based on the decoding context, with words serving as basic building blocks for alignment. To be specific, we introduce an uncertainty-based criterion to decide whether to apply ensembling at each decoding step. Under confident decoding states, the model continues generation directly. In less certain states, AdaFuse invokes a diversity-aware scaling strategy to explore alternative candidate continuations and inform ensemble decisions. This design establishes a synergistic interaction between adaptive ensembling and test-time scaling, where ensemble decisions guide targeted exploration, and the resulting diversity in turn strengthens ensemble quality. Experiments on open-domain question answering, arithmetic reasoning, and machine translation demonstrate that AdaFuse consistently outperforms strong ensemble baselines, achieving an average relative improvement of 6.88%. The code is available at https://github.com/CCM0111/AdaFuse.", "AI": {"tldr": "提出了一种自适应的集合解码框架AdaFuse，该框架能够在生成过程中动态选择语义合适的融合单元，并根据不确定性标准决定是否应用集合策略。", "motivation": "现有的集合方法在固定融合粒度方面存在局限性，无法灵活地进行中期生成调整或根据不同任务的特点进行适应。为了克服这些挑战，提出了AdaFuse来解决这些问题。", "method": "通过引入基于不确定性的标准，在每个解码步骤决定是否应用集合策略，并利用词汇作为基本构建块进行对齐；在自信的解码状态下直接继续生成，在不那么确定的状态下采用多样性感知的扩展策略探索替代候选延续，从而指导目标探索并增强集合并质量。", "result": "实验结果表明，AdaFuse在开放领域问答、算术推理和机器翻译任务中均优于强基线集合方法，平均相对改进达6.88%。", "conclusion": "通过自适应地利用不同模型的互补优势，并根据解码上下文动态调整融合行为，提出了一个有效的测试时间集合框架AdaFuse。"}}
{"id": "2601.06006", "pdf": "https://arxiv.org/pdf/2601.06006", "abs": "https://arxiv.org/abs/2601.06006", "authors": ["Bang Zeng", "Beilong Tang", "Wang Xiang", "Ming Li"], "title": "Discriminative-Generative Target Speaker Extraction with Decoder-Only Language Models", "categories": ["eess.AS", "cs.SD"], "comment": "16 pages,6 figures", "summary": "Target speaker extraction (TSE) aims to recover the speech signal of a desired speaker from a mixed audio recording, given a short enrollment utterance. Most existing TSE approaches are based on discriminative modeling paradigms. Although effective at suppressing interfering speakers, these methods often struggle to produce speech with high perceptual quality and naturalness. To address this limitation, we first propose LauraTSE, a generative TSE model built upon an auto-regressive decoder-only language model. However, purely generative approaches may suffer from hallucinations, content drift, and limited controllability, which may undermine their reliability in complex acoustic scenarios. To overcome these challenges, we further introduce a discriminative-generative TSE framework. In this framework, a discriminative front-end is employed to robustly extract the target speaker's speech, yielding stable and controllable intermediate representations. A generative back-end then operates in the neural audio codec representation space to reconstruct fine-grained speech details and enhance perceptual quality. This two-stage design effectively combines the robustness and controllability of discriminative models with the superior naturalness and quality enhancement capabilities of generative models. Moreover, we systematically investigate collaborative training strategies for the proposed framework, including freezing or fine-tuning the front-end, incorporating an auxiliary SI-SDR loss, and exploring both auto-regressive and non-auto-regressive inference mechanisms. Experimental results demonstrate that the proposed framework achieves a more favorable trade-off among speech quality, intelligibility, and speaker consistency.", "AI": {"tldr": "本文提出了一种基于解码器的自回归语言模型的目标说话人提取方法，通过结合判别和生成框架提升了音频质量与自然度。", "motivation": "现有的目标说话人提取方法虽然能够有效抑制干扰声源，但产生的语音质量和自然度较差。为了克服这些缺点，作者提出了一种融合了判别式前端和生成式后端的双重框架。", "method": "本文首先提出了基于自回归解码器的语言模型LauraTSE，并进一步引入了一个结合了判别式前段和生成式后端的目标说话人提取框架。该框架通过稳健地抽取目标说话人的语音，提供稳定可控的中间表示；然后在神经音频编码器表示空间中进行细节重构与感知质量提升。", "result": "实验结果表明，所提出的框架能够在语音质量和可懂度以及说话人一致性之间实现了更好的权衡。", "conclusion": "该研究证明了结合判别式和生成式的双重方法能够显著提高目标说话人提取任务中的音频质量和自然度。"}}
{"id": "2601.06002", "pdf": "https://arxiv.org/pdf/2601.06002", "abs": "https://arxiv.org/abs/2601.06002", "authors": ["Qiguang Chen", "Yantao Du", "Ziniu Li", "Jinhao Liu", "Songyao Duan", "Jiarui Guo", "Minghao Liu", "Jiaheng Liu", "Tong Yang", "Ge Zhang", "Libo Qin", "Wanxiang Che", "Wenhao Huang"], "title": "The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint", "summary": "Large language models (LLMs) often fail to learn effective long chain-of-thought (Long CoT) reasoning from human or non-Long-CoT LLMs imitation. To understand this, we propose that effective and learnable Long CoT trajectories feature stable molecular-like structures in unified view, which are formed by three interaction types: Deep-Reasoning (covalent-like), Self-Reflection (hydrogen-bond-like), and Self-Exploration (van der Waals-like). Analysis of distilled trajectories reveals these structures emerge from Long CoT fine-tuning, not keyword imitation. We introduce Effective Semantic Isomers and show that only bonds promoting fast entropy convergence support stable Long CoT learning, while structural competition impairs training. Drawing on these findings, we present Mole-Syn, a distribution-transfer-graph method that guides synthesis of effective Long CoT structures, boosting performance and RL stability across benchmarks.", "AI": {"tldr": "该论文通过引入分子结构的概念，研究了长链思维推理的有效性，并提出了一种名为Mole-Syn的方法来提高大型语言模型的长期逻辑推理能力。", "motivation": "研究发现，在大型语言模型中，有效的长链思维（Long CoT）推理难以从人类或非Long-CoT的大型语言模型模仿学习得到。为了理解这一现象，作者提出了通过分析分子结构的方式来解释和解决这个问题。", "method": "作者提出了一种名为Mole-Syn的方法，该方法借鉴了化学中分子相互作用的概念，利用三种类型的交互：深度推理、自我反思和自我探索来构建有效的长链思维结构。并通过分布转移图的方式引导合成有效Long CoT结构。", "result": "通过这种方法，研究展示了其能够促进熵快速收敛并支持稳定的长期逻辑推理学习，同时提高了模型在多个基准测试中的性能和强化学习稳定性。", "conclusion": "该论文提出了一种新颖的方法来解释大型语言模型中长链思维的形成过程，并提供了一种有效的训练策略以提高这些模型的学习能力。"}}
{"id": "2601.06001", "pdf": "https://arxiv.org/pdf/2601.06001", "abs": "https://arxiv.org/abs/2601.06001", "authors": ["Christoph Standke", "Nikolaos Tziavelis", "Wolfgang Gatterbauer", "Benny Kimelfeld"], "title": "The Importance of Parameters in Ranking Functions", "categories": ["cs.DB", "cs.DS"], "comment": "Extended version of ICDT 2026 paper", "summary": "How important is the weight of a given column in determining the ranking of tuples in a table? To address such an explanation question about a ranking function, we investigate the computation of SHAP scores for column weights, adopting a recent framework by Grohe et al.[ICDT'24]. The exact definition of this score depends on three key components: (1) the ranking function in use, (2) an effect function that quantifies the impact of using alternative weights on the ranking, and (3) an underlying weight distribution. We analyze the computational complexity of different instantiations of this framework for a range of fundamental ranking and effect functions, focusing on probabilistically independent finite distributions for individual columns. For the ranking functions, we examine lexicographic orders and score-based orders defined by the summation, minimum, and maximum functions. For the effect functions, we consider global, top-k, and local perspectives: global measures quantify the divergence between the perturbed and original rankings, top-k measures inspect the change in the set of top-k answers, and local measures capture the impact on an individual tuple of interest. Although all cases admit an additive fully polynomial-time randomized approximation scheme (FPRAS), we establish the complexity of exact computation, identifying which cases are solvable in polynomial time and which are #P-hard. We further show that all complexity results, lower bounds and upper bounds, extend to a related task of computing the Shapley value of whole columns (regardless of their weight).", "AI": {"tldr": "研究了排名函数中列权重的重要性的计算方法，通过SHAP得分来衡量。", "motivation": "探讨特定列的权重在决定表格中元组排序时的重要性。", "method": "采用Grohe等人提出的一种框架，分析不同排名和效果函数下的复杂性问题，并考虑概率独立分布的情况。", "result": "确定了各种情况下的精确计算复杂性和近似算法的可行性。", "conclusion": "通过该研究可以更好地理解列权重在排名中的作用以及其计算复杂度。"}}
{"id": "2601.05991", "pdf": "https://arxiv.org/pdf/2601.05991", "abs": "https://arxiv.org/abs/2601.05991", "authors": ["Jiayu Ding", "Haoran Tang", "Ge Li"], "title": "Open-Vocabulary 3D Instruction Ambiguity Detection", "categories": ["cs.AI"], "comment": null, "summary": "In safety-critical domains, linguistic ambiguity can have severe consequences; a vague command like \"Pass me the vial\" in a surgical setting could lead to catastrophic errors. Yet, most embodied AI research overlooks this, assuming instructions are clear and focusing on execution rather than confirmation. To address this critical safety gap, we are the first to define Open-Vocabulary 3D Instruction Ambiguity Detection, a fundamental new task where a model must determine if a command has a single, unambiguous meaning within a given 3D scene. To support this research, we build Ambi3D, the large-scale benchmark for this task, featuring over 700 diverse 3D scenes and around 22k instructions. Our analysis reveals a surprising limitation: state-of-the-art 3D Large Language Models (LLMs) struggle to reliably determine if an instruction is ambiguous. To address this challenge, we propose AmbiVer, a two-stage framework that collects explicit visual evidence from multiple views and uses it to guide an vision-language model (VLM) in judging instruction ambiguity. Extensive experiments demonstrate the challenge of our task and the effectiveness of AmbiVer, paving the way for safer and more trustworthy embodied AI. Code and dataset available at https://jiayuding031020.github.io/ambi3d/.", "AI": {"tldr": "研究提出了一项新的任务：开放词汇3D指令歧义检测，模型需判断给定的3D场景中的命令是否有单一明确的意义。", "motivation": "在安全关键领域中，模糊的语言可能导致严重错误。大多数具身AI的研究忽略了这个问题，本研究旨在填补这一安全性差距。", "method": "构建了Ambi3D基准测试，并提出了一种两阶段框架AmbiVer来收集视觉证据以判断指令的歧义性。", "result": "实验表明该任务具有挑战性，提出的AmbiVer在检测指令歧义方面表现良好。", "conclusion": "研究通过定义新的任务和方法，为更安全、可靠的具身AI铺平了道路。"}}
{"id": "2601.05986", "pdf": "https://arxiv.org/pdf/2601.05986", "abs": "https://arxiv.org/abs/2601.05986", "authors": ["Adrian Serrano", "Erwan Umlil", "Ronan Thomas"], "title": "Deepfake detectors are DUMB: A benchmark to assess adversarial training robustness under transferability constraints", "categories": ["cs.CV", "cs.CR"], "comment": "10 pages, four tables, one figure", "summary": "Deepfake detection systems deployed in real-world environments are subject to adversaries capable of crafting imperceptible perturbations that degrade model performance. While adversarial training is a widely adopted defense, its effectiveness under realistic conditions -- where attackers operate with limited knowledge and mismatched data distributions - remains underexplored. In this work, we extend the DUMB -- Dataset soUrces, Model architecture and Balance - and DUMBer methodology to deepfake detection. We evaluate detectors robustness against adversarial attacks under transferability constraints and cross-dataset configuration to extract real-world insights. Our study spans five state-of-the-art detectors (RECCE, SRM, XCeption, UCF, SPSL), three attacks (PGD, FGSM, FPBA), and two datasets (FaceForensics++ and Celeb-DF-V2). We analyze both attacker and defender perspectives mapping results to mismatch scenarios. Experiments show that adversarial training strategies reinforce robustness in the in-distribution cases but can also degrade it under cross-dataset configuration depending on the strategy adopted. These findings highlight the need for case-aware defense strategies in real-world applications exposed to adversarial attacks.", "AI": {"tldr": "评估深度伪造检测系统在现实场景下的鲁棒性，特别是在对抗训练和数据集转换约束下。", "motivation": "当前的防御策略如对抗训练在实际部署中效果有限，需要深入研究其在真实条件下的表现。通过跨数据集配置来测试模型是否能有效抵御未知攻击者。", "method": "使用DUMB和DUMBer方法评估五种最先进的检测器（RECCE、SRM等）对三种不同攻击（PGD、FGSM等）的鲁棒性，同时考虑数据分布差异的影响。", "result": "对抗训练可以提高模型在同源数据上的抗干扰能力，但在跨数据集情况下可能会降低其性能。这些结果揭示了防御策略需要根据实际情况进行调整。", "conclusion": "现有的防御方法不能保证对所有情况都有效，强调了针对特定场景开发定制化防御措施的重要性。"}}
{"id": "2601.05981", "pdf": "https://arxiv.org/pdf/2601.05981", "abs": "https://arxiv.org/abs/2601.05981", "authors": ["Yinsong Wang", "Xinzhe Luo", "Siyi Du", "Chen Qin"], "title": "Adaptive Conditional Contrast-Agnostic Deformable Image Registration with Uncertainty Estimation", "categories": ["cs.CV"], "comment": "Accepted by ieee transactions on Medical Imaging", "summary": "Deformable multi-contrast image registration is a challenging yet crucial task due to the complex, non-linear intensity relationships across different imaging contrasts. Conventional registration methods typically rely on iterative optimization of the deformation field, which is time-consuming. Although recent learning-based approaches enable fast and accurate registration during inference, their generalizability remains limited to the specific contrasts observed during training. In this work, we propose an adaptive conditional contrast-agnostic deformable image registration framework (AC-CAR) based on a random convolution-based contrast augmentation scheme. AC-CAR can generalize to arbitrary imaging contrasts without observing them during training. To encourage contrast-invariant feature learning, we propose an adaptive conditional feature modulator (ACFM) that adaptively modulates the features and the contrast-invariant latent regularization to enforce the consistency of the learned feature across different imaging contrasts. Additionally, we enable our framework to provide contrast-agnostic registration uncertainty by integrating a variance network that leverages the contrast-agnostic registration encoder to improve the trustworthiness and reliability of AC-CAR. Experimental results demonstrate that AC-CAR outperforms baseline methods in registration accuracy and exhibits superior generalization to unseen imaging contrasts. Code is available at https://github.com/Yinsong0510/AC-CAR.", "AI": {"tldr": "本文提出了一种自适应条件对比度无关的可变形图像配准框架（AC-CAR），以解决多对比度图像配准时的不同复杂强度关系问题。", "motivation": "传统的注册方法依赖于迭代优化，耗时且难以泛化到训练期间未观察到的对比度。为了解决这些问题，本文旨在开发一种新的自适应条件对比度无关的可变形图像配准框架。", "method": "AC-CAR使用随机卷积增强对比度的方法，并提出了自适应条件特征调制器（ACFM），以促进不同成像对比度之间的一致性学习。通过引入方差网络，该框架能够提供对比度无关的注册不确定性。", "result": "实验结果表明，与基线方法相比，AC-CAR在配准准确性方面表现更优，并且对未见过的成像对比度具有更好的泛化能力。", "conclusion": "通过采用适应性条件特征调制器和方差网络，本文提出的框架能够更好地处理多对比度图像配准任务。"}}
{"id": "2601.05974", "pdf": "https://arxiv.org/pdf/2601.05974", "abs": "https://arxiv.org/abs/2601.05974", "authors": ["Goran Muric", "Steven Minton"], "title": "A Framework for Optimizing Human-Machine Interaction in Classification Systems", "categories": ["cs.HC"], "comment": null, "summary": "Automated decision systems increasingly rely on human oversight to ensure accuracy in uncertain cases. This paper presents a practical framework for optimizing such human-in-the-loop classification systems using a double-threshold policy. Conventional classifiers usually produce a confidence score and apply a single cutoff, but our approach uses two thresholds (a lower and an upper) to automatically accept or reject high-confidence cases while routing ambiguous instances to human reviewers. We formulate this problem as an optimization task that balances system accuracy against the cost of human review. Through analytical derivations and Monte Carlo simulations, we show how different confidence score distributions impact the efficiency of human intervention and reveal regions of diminishing returns, where additional review yields minimal benefit. The framework provides a general, reproducible method for improving reliability in any decision pipeline requiring selective human validation, including applications in entity resolution, fraud detection, medical triage, and content moderation.", "AI": {"tldr": "提出了一种优化人机交互的框架，用于分类系统中的人工审查。", "motivation": "为了提高不确定性情况下决策系统的准确性和效率，引入一种使用双重阈值策略的方法来平衡自动判定和人工审核的成本与收益。", "method": "通过分析推导和蒙特卡罗模拟研究了不同置信度分布对人工干预效率的影响，并确定了人工审查的边际效益递减区域。", "result": "框架提供了在任何需要选择性人工验证决策管道中的可靠性提升的一般可重复方法，适用于实体解析、欺诈检测、医疗分类以及内容审核等应用领域。", "conclusion": "提出的双阈值策略能有效平衡自动判定与人工审查的成本和收益，在确保系统准确性的同时减少了不必要的工作量。"}}
{"id": "2601.05966", "pdf": "https://arxiv.org/pdf/2601.05966", "abs": "https://arxiv.org/abs/2601.05966", "authors": ["Longbin Ji", "Xiaoxiong Liu", "Junyuan Shang", "Shuohuan Wang", "Yu Sun", "Hua Wu", "Haifeng Wang"], "title": "VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advances in video generation have been dominated by diffusion and flow-matching models, which produce high-quality results but remain computationally intensive and difficult to scale. In this work, we introduce VideoAR, the first large-scale Visual Autoregressive (VAR) framework for video generation that combines multi-scale next-frame prediction with autoregressive modeling. VideoAR disentangles spatial and temporal dependencies by integrating intra-frame VAR modeling with causal next-frame prediction, supported by a 3D multi-scale tokenizer that efficiently encodes spatio-temporal dynamics. To improve long-term consistency, we propose Multi-scale Temporal RoPE, Cross-Frame Error Correction, and Random Frame Mask, which collectively mitigate error propagation and stabilize temporal coherence. Our multi-stage pretraining pipeline progressively aligns spatial and temporal learning across increasing resolutions and durations. Empirically, VideoAR achieves new state-of-the-art results among autoregressive models, improving FVD on UCF-101 from 99.5 to 88.6 while reducing inference steps by over 10x, and reaching a VBench score of 81.74-competitive with diffusion-based models an order of magnitude larger. These results demonstrate that VideoAR narrows the performance gap between autoregressive and diffusion paradigms, offering a scalable, efficient, and temporally consistent foundation for future video generation research.", "AI": {"tldr": "视频生成任务中，提出了一种新的自回归模型VideoAR，结合多尺度下一帧预测和自回归建模。", "motivation": "当前的视频生成方法主要依赖扩散模型和流匹配模型，虽然效果好但计算复杂且难以扩展。VideoAR旨在提供一种高效、可扩展的方法来解决这一问题。", "method": "VideoAR采用3D多尺度tokenizer编码时空动态，并结合自回归建模与因果下一帧预测，提出Multi-scale Temporal RoPE、跨帧误差校正和随机帧掩码来提高长期一致性。模型通过分阶段预训练逐步对齐空间和时间学习。", "result": "在UCF-101数据集上，VideoAR将FVD从99.5降至88.6，减少推理步骤超过10倍，并达到VBench评分为81.74，与扩散模型相当但规模小得多。", "conclusion": "VideoAR缩小了自回归和扩散方法之间的性能差距，为未来的视频生成研究提供了一个高效、可扩展的基础。"}}
{"id": "2601.05942", "pdf": "https://arxiv.org/pdf/2601.05942", "abs": "https://arxiv.org/abs/2601.05942", "authors": ["Chanchan Wang", "Yuanfang Wang", "Qing Xu", "Guanxin Chen"], "title": "WaveRNet: Wavelet-Guided Frequency Learning for Multi-Source Domain-Generalized Retinal Vessel Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Domain-generalized retinal vessel segmentation is critical for automated ophthalmic diagnosis, yet faces significant challenges from domain shift induced by non-uniform illumination and varying contrast, compounded by the difficulty of preserving fine vessel structures. While the Segment Anything Model (SAM) exhibits remarkable zero-shot capabilities, existing SAM-based methods rely on simple adapter fine-tuning while overlooking frequency-domain information that encodes domain-invariant features, resulting in degraded generalization under illumination and contrast variations. Furthermore, SAM's direct upsampling inevitably loses fine vessel details. To address these limitations, we propose WaveRNet, a wavelet-guided frequency learning framework for robust multi-source domain-generalized retinal vessel segmentation. Specifically, we devise a Spectral-guided Domain Modulator (SDM) that integrates wavelet decomposition with learnable domain tokens, enabling the separation of illumination-robust low-frequency structures from high-frequency vessel boundaries while facilitating domain-specific feature generation. Furthermore, we introduce a Frequency-Adaptive Domain Fusion (FADF) module that performs intelligent test-time domain selection through wavelet-based frequency similarity and soft-weighted fusion. Finally, we present a Hierarchical Mask-Prompt Refiner (HMPR) that overcomes SAM's upsampling limitation through coarse-to-fine refinement with long-range dependency modeling. Extensive experiments under the Leave-One-Domain-Out protocol on four public retinal datasets demonstrate that WaveRNet achieves state-of-the-art generalization performance. The source code is available at https://github.com/Chanchan-Wang/WaveRNet.", "AI": {"tldr": "WaveRNet是一种基于小波引导的频率学习框架，用于多源域泛化的视网膜血管分割。", "motivation": "现有的SAM方法在处理非均匀照明和对比度变化时存在局限性，且忽略频率信息导致性能下降。此外，直接上采样会导致细血管细节丢失。", "method": "设计了谱引导领域调节器（SDM）以分离小波分解的低频结构与高频边界，并通过智能测试时间领域选择模块实现多源域泛化。", "result": "在四个公共视网膜数据集中进行的Leave-One-Domain-Out协议实验表明，WaveRNet实现了最先进的泛化性能。", "conclusion": "通过小波引导频率学习框架，WaveRNet克服了现有方法的局限性，并在多源域泛化的视网膜血管分割任务上表现优异。"}}
{"id": "2601.05939", "pdf": "https://arxiv.org/pdf/2601.05939", "abs": "https://arxiv.org/abs/2601.05939", "authors": ["Mehrdad Fazli", "Bowen Wei", "Ziwei Zhu"], "title": "Context-Aware Decoding for Faithful Vision-Language Generation", "categories": ["cs.CV"], "comment": null, "summary": "Hallucinations, generating responses inconsistent with the visual input, remain a critical limitation of large vision-language models (LVLMs), especially in open-ended tasks such as image captioning and visual reasoning. In this work, we probe the layer-wise generation dynamics that drive hallucinations and propose a training-free mitigation strategy. Employing the Logit Lens, we examine how LVLMs construct next-token distributions across decoder layers, uncovering a pronounced commitment-depth gap: truthful tokens accumulate probability mass on their final candidates earlier than hallucinatory ones. Drawing on this discovery, we introduce Context Embedding Injection (CEI), a lightweight method that harnesses the hidden state of the last input token-the context embedding-as a grounding signal to maintain visual fidelity throughout decoding and curb hallucinations. Evaluated on the CHAIR, AMBER, and MMHal-Bench benchmarks (with a maximum token length of 512), CEI outperforms state-of-the-art baselines across three LVLMs, with its dynamic variant yielding the lowest overall hallucination rates. By integrating novel mechanistic insights with a scalable intervention, this work advances the mitigation of hallucinations in LVLMs.", "AI": {"tldr": "该论文提出了一个减轻大型视觉语言模型中幻觉现象的训练自由策略。", "motivation": "为了减少大型视觉语言模型在开放任务中的幻觉问题，提高生成响应的一致性和真实性。", "method": "通过Logit Lens分析了不同层级下LVLMs构造下一令牌分布的过程，并引入Context Embedding Injection方法作为轻量级的干预措施来维持解码过程中的视觉一致性。", "result": "在CHAIR、AMBER和MMHal-Bench基准测试中，CEI的表现优于现有的最佳基线，在三个大型视觉语言模型上降低了整体幻觉率。", "conclusion": "通过结合新颖的机制性见解与可扩展干预措施，该工作有效缓解了LVLMs中的幻觉问题。"}}
{"id": "2601.05937", "pdf": "https://arxiv.org/pdf/2601.05937", "abs": "https://arxiv.org/abs/2601.05937", "authors": ["Pankaj Gupta", "Priya Mudgil", "Niharika Dutta", "Kartik Bose", "Nitish Kumar", "Anupam Kumar", "Jimil Shah", "Vaneet Jearth", "Jayanta Samanta", "Vishal Sharma", "Harshal Mandavdhare", "Surinder Rana", "Saroj K Sinha", "Usha Dutta"], "title": "Performance of a Deep Learning-Based Segmentation Model for Pancreatic Tumors on Public Endoscopic Ultrasound Datasets", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Background: Pancreatic cancer is one of the most aggressive cancers, with poor survival rates. Endoscopic ultrasound (EUS) is a key diagnostic modality, but its effectiveness is constrained by operator subjectivity. This study evaluates a Vision Transformer-based deep learning segmentation model for pancreatic tumors. Methods: A segmentation model using the USFM framework with a Vision Transformer backbone was trained and validated with 17,367 EUS images (from two public datasets) in 5-fold cross-validation. The model was tested on an independent dataset of 350 EUS images from another public dataset, manually segmented by radiologists. Preprocessing included grayscale conversion, cropping, and resizing to 512x512 pixels. Metrics included Dice similarity coefficient (DSC), intersection over union (IoU), sensitivity, specificity, and accuracy. Results: In 5-fold cross-validation, the model achieved a mean DSC of 0.651 +/- 0.738, IoU of 0.579 +/- 0.658, sensitivity of 69.8%, specificity of 98.8%, and accuracy of 97.5%. For the external validation set, the model achieved a DSC of 0.657 (95% CI: 0.634-0.769), IoU of 0.614 (95% CI: 0.590-0.689), sensitivity of 71.8%, and specificity of 97.7%. Results were consistent, but 9.7% of cases exhibited erroneous multiple predictions. Conclusions: The Vision Transformer-based model demonstrated strong performance for pancreatic tumor segmentation in EUS images. However, dataset heterogeneity and limited external validation highlight the need for further refinement, standardization, and prospective studies.", "AI": {"tldr": "本论文评估了一种基于Vision Transformer的深度学习分割模型在胰腺肿瘤中的性能。", "motivation": "胰腺癌是侵袭性癌症之一，存活率低。内镜超声（EUS）是一种重要的诊断手段，但其效果受限于操作者主观性。该研究旨在开发和评估一种基于Vision Transformer的深度学习分割模型以提高胰腺肿瘤检测精度。", "method": "使用包含17,367张EUS图像的数据集进行了5折交叉验证训练和验证，并在独立数据集上进行外部验证，包括灰度转换、裁剪和调整至512x512像素的预处理步骤。评估指标为Dice相似系数（DSC）、交并比（IoU）等。", "result": "模型在内部测试中获得了0.651±0.738的平均DSC，外部验证集中得到0.657的DSC，显示了良好的分割性能。但仍有9.7%的案例出现错误预测。", "conclusion": "基于Vision Transformer的深度学习模型在胰腺肿瘤EUS图像中展示了强大的分割能力。但由于数据集异质性和外部分析样本量小等问题，仍需进一步优化和标准化研究。"}}
{"id": "2601.05930", "pdf": "https://arxiv.org/pdf/2601.05930", "abs": "https://arxiv.org/abs/2601.05930", "authors": ["Jingsheng Zheng", "Jintian Zhang", "Yujie Luo", "Yuren Mao", "Yunjun Gao", "Lun Du", "Huajun Chen", "Ningyu Zhang"], "title": "Can We Predict Before Executing Machine Learning Agents?", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "comment": "Work in progress", "summary": "Autonomous machine learning agents have revolutionized scientific discovery, yet they remain constrained by a Generate-Execute-Feedback paradigm. Previous approaches suffer from a severe Execution Bottleneck, as hypothesis evaluation relies strictly on expensive physical execution. To bypass these physical constraints, we internalize execution priors to substitute costly runtime checks with instantaneous predictive reasoning, drawing inspiration from World Models. In this work, we formalize the task of Data-centric Solution Preference and construct a comprehensive corpus of 18,438 pairwise comparisons. We demonstrate that LLMs exhibit significant predictive capabilities when primed with a Verified Data Analysis Report, achieving 61.5% accuracy and robust confidence calibration. Finally, we instantiate this framework in FOREAGENT, an agent that employs a Predict-then-Verify loop, achieving a 6x acceleration in convergence while surpassing execution-based baselines by +6%. Our code and dataset will be publicly available soon at https://github.com/zjunlp/predict-before-execute.", "AI": {"tldr": "研究通过预测而非执行来加速机器学习代理的科学发现。", "motivation": "为了克服生成-执行-反馈模式中的运行瓶颈，提出了一种内部化执行先验的方法，从而用即时的预测推理替代成本高昂的实际执行过程。", "method": "构建了一个包含18,438对数据对比的数据集，并通过验证数据分析报告来训练LLM以获得预测能力。设计了名为FOREAGENT的代理模型，采用预测然后验证的循环方式提高效率。", "result": "实验结果表明，在使用内部化执行先验的方法时，LLMs可以达到61.5%的准确率和良好的置信度校准；FOREAGENT框架实现了6倍于传统方法的加速，并在性能上超过基线方法6%。", "conclusion": "证明了通过预测而非实际执行来优化机器学习代理是可行且有效的，这种方法能够显著提高科学发现的速度。"}}
{"id": "2601.05927", "pdf": "https://arxiv.org/pdf/2601.05927", "abs": "https://arxiv.org/abs/2601.05927", "authors": ["Yohann Perron", "Vladyslav Sydorov", "Christophe Pottier", "Loic Landrieu"], "title": "Adapting Vision Transformers to Ultra-High Resolution Semantic Segmentation with Relay Tokens", "categories": ["cs.CV"], "comment": "13 pages +3 pages of suppmat", "summary": "Current approaches for segmenting ultra high resolution images either slide a window, thereby discarding global context, or downsample and lose fine detail. We propose a simple yet effective method that brings explicit multi scale reasoning to vision transformers, simultaneously preserving local details and global awareness. Concretely, we process each image in parallel at a local scale (high resolution, small crops) and a global scale (low resolution, large crops), and aggregate and propagate features between the two branches with a small set of learnable relay tokens. The design plugs directly into standard transformer backbones (eg ViT and Swin) and adds fewer than 2 % parameters. Extensive experiments on three ultra high resolution segmentation benchmarks, Archaeoscape, URUR, and Gleason, and on the conventional Cityscapes dataset show consistent gains, with up to 15 % relative mIoU improvement. Code and pretrained models are available at https://archaeoscape.ai/work/relay-tokens/ .", "AI": {"tldr": "该论文提出了一种新的方法，通过引入中继令牌来改进视觉变压器在超高分辨率语义分割中的表现。", "motivation": "当前的高分辨率图像分割方法要么使用滑动窗口丢失全局上下文，要么下采样而失去细节信息。为此，论文提出了一个同时保留局部细节和全局感知的方法。", "method": "该方法通过并行处理图像在本地尺度（高分辨率、小裁剪）和全局尺度（低分辨率、大裁剪），并通过一组可学习的中继令牌进行特征聚合和传播。此设计可以无缝插入标准变压器主干，且添加参数少于2%。", "result": "在三个超高分辨率分割基准测试Archaeoscape、URUR和Gleason以及传统的Cityscapes数据集上进行了广泛的实验，结果表明改进的方法能带来一致的性能提升，最多可提高15%的相对mIoU值。", "conclusion": "通过引入中继令牌，该方法能够在保留局部细节的同时保持全局感知，在多种高分辨率图像分割任务上实现了显著的效果提升。"}}
{"id": "2601.05923", "pdf": "https://arxiv.org/pdf/2601.05923", "abs": "https://arxiv.org/abs/2601.05923", "authors": ["E. Middell", "L. Carlton", "S. Moradi", "T. Codina", "T. Fischer", "J. Cutler", "S. Kelley", "J. Behrendt", "T. Dissanayake", "N. Harmening", "M. A. Yücel", "D. A. Boas", "A. von Lühmann"], "title": "Cedalion Tutorial: A Python-based framework for comprehensive analysis of multimodal fNIRS & DOT from the lab to the everyday world", "categories": ["eess.SP", "cs.AI", "cs.LG", "eess.IV", "q-bio.QM"], "comment": "33 pages main manuscript, 180 pages Supplementary Tutorial Notebooks, 12 figures, 6 tables, under review in SPIE Neurophotonics", "summary": "Functional near-infrared spectroscopy (fNIRS) and diffuse optical tomography (DOT) are rapidly evolving toward wearable, multimodal, and data-driven, AI-supported neuroimaging in the everyday world. However, current analytical tools are fragmented across platforms, limiting reproducibility, interoperability, and integration with modern machine learning (ML) workflows. Cedalion is a Python-based open-source framework designed to unify advanced model-based and data-driven analysis of multimodal fNIRS and DOT data within a reproducible, extensible, and community-driven environment. Cedalion integrates forward modelling, photogrammetric optode co-registration, signal processing, GLM Analysis, DOT image reconstruction, and ML-based data-driven methods within a single standardized architecture based on the Python ecosystem. It adheres to SNIRF and BIDS standards, supports cloud-executable Jupyter notebooks, and provides containerized workflows for scalable, fully reproducible analysis pipelines that can be provided alongside original research publications. Cedalion connects established optical-neuroimaging pipelines with ML frameworks such as scikit-learn and PyTorch, enabling seamless multimodal fusion with EEG, MEG, and physiological data. It implements validated algorithms for signal-quality assessment, motion correction, GLM modelling, and DOT reconstruction, complemented by modules for simulation, data augmentation, and multimodal physiology analysis. Automated documentation links each method to its source publication, and continuous-integration testing ensures robustness. This tutorial paper provides seven fully executable notebooks that demonstrate core features. Cedalion offers an open, transparent, and community extensible foundation that supports reproducible, scalable, cloud- and ML-ready fNIRS/DOT workflows for laboratory-based and real-world neuroimaging.", "AI": {"tldr": "Cedalion是一个基于Python的开源框架，旨在统一多模态fNIRS和DOT数据的高级模型驱动和数据驱动分析。", "motivation": "当前分析工具碎片化严重，限制了可重复性、互操作性和与现代机器学习工作流的集成。Cedalion的设计是为了解决这些问题，并促进光学神经成像与ML框架之间的无缝融合。", "method": "Cedalion基于Python生态系统构建了一个标准化架构，集成了正向建模、光度测量对准、信号处理、GLM分析、DOT图像重建和机器学习驱动的方法。它支持SNIRF和BIDS标准，并提供了容器化的工作流程以实现可重复的分析。", "result": "该框架可以与EEG、MEG和其他生理数据进行多模态融合，并提供模拟、数据增强以及多模态生理数据分析模块，同时通过自动化文档链接每个方法到其来源文献。", "conclusion": "Cedalion为实验室和现实世界中的fNIRS/DOT工作流程提供了开放透明且社区可扩展的基础，支持可重复的、可扩展的、基于云和ML就绪的工作流。"}}
{"id": "2601.05918", "pdf": "https://arxiv.org/pdf/2601.05918", "abs": "https://arxiv.org/abs/2601.05918", "authors": ["Tianshi Li"], "title": "Agentic LLMs as Powerful Deanonymizers: Re-identification of Participants in the Anthropic Interviewer Dataset", "categories": ["cs.CR", "cs.AI", "cs.CY"], "comment": "4 pages", "summary": "On December 4, 2025, Anthropic released Anthropic Interviewer, an AI tool for running qualitative interviews at scale, along with a public dataset of 1,250 interviews with professionals, including 125 scientists, about their use of AI for research. Focusing on the scientist subset, I show that widely available LLMs with web search and agentic capabilities can link six out of twenty-four interviews to specific scientific works, recovering associated authors and, in some cases, uniquely identifying the interviewees. My contribution is to show that modern LLM-based agents make such re-identification attacks easy and low-effort: off-the-shelf tools can, with a few natural-language prompts, search the web, cross-reference details, and propose likely matches, effectively lowering the technical barrier. Existing safeguards can be bypassed by breaking down the re-identification into benign tasks. I outline the attack at a high level, discuss implications for releasing rich qualitative data in the age of LLM agents, and propose mitigation recommendations and open problems. I have notified Anthropic of my findings.", "AI": {"tldr": "展示了利用现代大型语言模型和网络搜索能力，可以通过简单的自然语言提示重新识别Anthropic Interviewer数据集中科学家的访谈。", "motivation": "探讨在大型语言模型时代发布丰富的定性数据时的安全风险，证明了即使现有保护措施存在的情况下也能轻易进行重新识别攻击。", "method": "使用广泛可用的大规模语言模型和网络搜索功能分解并执行一系列低技术门槛的任务来匹配具体科学家的访谈记录，并将其与已知的工作联系起来。", "result": "成功地将六份采访中的二十四个与特定科学作品相连，恢复了相关作者，在某些情况下甚至可以唯一识别受访人员。", "conclusion": "提出重新识别攻击的技术屏障大大降低，建议采取缓解措施和解决开放问题以提高数据发布安全。"}}
{"id": "2601.05909", "pdf": "https://arxiv.org/pdf/2601.05909", "abs": "https://arxiv.org/abs/2601.05909", "authors": ["Ayoub Ajarra", "Debabrota Basu"], "title": "Auditing Fairness under Model Updates: Fundamental Complexity and Property-Preserving Updates", "categories": ["cs.LG", "cs.AI", "cs.CY", "stat.ML"], "comment": null, "summary": "As machine learning models become increasingly embedded in societal infrastructure, auditing them for bias is of growing importance. However, in real-world deployments, auditing is complicated by the fact that model owners may adaptively update their models in response to changing environments, such as financial markets. These updates can alter the underlying model class while preserving certain properties of interest, raising fundamental questions about what can be reliably audited under such shifts. In this work, we study group fairness auditing under arbitrary updates. We consider general shifts that modify the pre-audit model class while maintaining invariance of the audited property. Our goals are two-fold: (i) to characterize the information complexity of allowable updates, by identifying which strategic changes preserve the property under audit; and (ii) to efficiently estimate auditing properties, such as group fairness, using a minimal number of labeled samples. We propose a generic framework for PAC auditing based on an Empirical Property Optimization (EPO) oracle. For statistical parity, we establish distribution-free auditing bounds characterized by the SP dimension, a novel combinatorial measure that captures the complexity of admissible strategic updates. Finally, we demonstrate that our framework naturally extends to other auditing objectives, including prediction error and robust risk.", "AI": {"tldr": "研究在模型更新下的公平性审核问题，提出一种基于经验属性优化（EPO）的框架来估计审计特性，如群体公平性，使用最少标注样本。", "motivation": "随着机器学习模型深入社会基础设施，对其偏见进行审计变得越来越重要。然而，在实际部署中，由于环境变化导致模型所有者对模型的适应性更新，使得审核变得更加复杂。", "method": "提出一种基于经验属性优化（EPO）的框架来审计群体公平性及其他目标特性；利用SP维度这一新型组合度量捕获可接受的战略变更复杂性。", "result": "对于统计平等性，建立了由SP维度表征的无分布审计界限；该框架自然扩展到预测错误和鲁棒风险等其他审计目标。", "conclusion": "研究提出一种新的方法来解决模型更新下的公平性审核问题，并展示了其在不同审计目标中的应用价值。"}}
{"id": "2601.05905", "pdf": "https://arxiv.org/pdf/2601.05905", "abs": "https://arxiv.org/abs/2601.05905", "authors": ["Haoming Xu", "Ningyuan Zhao", "Yunzhi Yao", "Weihong Xu", "Hongru Wang", "Xinle Deng", "Shumin Deng", "Jeff Z. Pan", "Huajun Chen", "Ningyu Zhang"], "title": "Illusions of Confidence? Diagnosing LLM Truthfulness via Neighborhood Consistency", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG", "cs.MA"], "comment": "Work in progress", "summary": "As Large Language Models (LLMs) are increasingly deployed in real-world settings, correctness alone is insufficient. Reliable deployment requires maintaining truthful beliefs under contextual perturbations. Existing evaluations largely rely on point-wise confidence like Self-Consistency, which can mask brittle belief. We show that even facts answered with perfect self-consistency can rapidly collapse under mild contextual interference. To address this gap, we propose Neighbor-Consistency Belief (NCB), a structural measure of belief robustness that evaluates response coherence across a conceptual neighborhood. To validate the efficiency of NCB, we introduce a new cognitive stress-testing protocol that probes outputs stability under contextual interference. Experiments across multiple LLMs show that the performance of high-NCB data is relatively more resistant to interference. Finally, we present Structure-Aware Training (SAT), which optimizes context-invariant belief structure and reduces long-tail knowledge brittleness by approximately 30%. Code will be available at https://github.com/zjunlp/belief.", "AI": {"tldr": "提出了一种新的评估大型语言模型（LLM）稳定性的方法——Neighbor-Consistency Belief (NCB)，并开发了Structure-Aware Training (SAT) 方法以提高模型的稳定性。", "motivation": "在现实世界中部署时，仅仅依靠准确性不足以确保可靠性。需要一种能够衡量模型在上下文干扰下的稳定性和一致性的方法来提升其可信度和抗干扰性。", "method": "提出了Neighbor-Consistency Belief (NCB)，该方法通过评估模型在概念邻域内的输出一致性来测量信念的稳定性；设计了一种新的认知压力测试协议，用于探测输出在上下文干扰下的稳定性和一致性。同时提出Structure-Aware Training (SAT) 方法优化模型上下文不变性。", "result": "实验表明，高NCB的数据对上下文干扰表现出更强的抵抗力。", "conclusion": "通过使用Neighbor-Consistency Belief和Structure-Aware Training方法可以有效提高大型语言模型在面对不同情境下的稳定性和抗干扰能力。"}}
