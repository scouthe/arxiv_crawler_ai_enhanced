{"id": "2601.19702", "pdf": "https://arxiv.org/pdf/2601.19702", "abs": "https://arxiv.org/abs/2601.19702", "authors": ["Helin Wang", "Bowen Shi", "Andros Tjandra", "John Hoffman", "Yi-Chiao Wu", "Apoorv Vyas", "Najim Dehak", "Ann Lee", "Wei-Ning Hsu"], "title": "SAM Audio Judge: A Unified Multimodal Framework for Perceptual Evaluation of Audio Separation", "categories": ["eess.AS", "cs.AI"], "comment": null, "summary": "The performance evaluation remains a complex challenge in audio separation, and existing evaluation metrics are often misaligned with human perception, course-grained, relying on ground truth signals. On the other hand, subjective listening tests remain the gold standard for real-world evaluation, but they are expensive, time-consuming, and difficult to scale. This paper addresses the growing need for automated systems capable of evaluating audio separation without human intervention. The proposed evaluation metric, SAM Audio Judge (SAJ), is a multimodal fine-grained reference-free objective metric, which shows highly alignment with human perceptions. SAJ supports three audio domains (speech, music and general sound events) and three prompt inputs (text, visual and span), covering four different dimensions of evaluation (recall, percision, faithfulness, and overall). SAM Audio Judge also shows potential applications in data filtering, pseudo-labeling large datasets and reranking in audio separation models. We release our code and pre-trained models at: https://github.com/facebookresearch/sam-audio.", "AI": {"tldr": "提出一种用于评估音频分离的SAM Audio Judge（SAJ）模型，该模型能够自动化地评价而无需人工干预。", "motivation": "现有的音频分离性能评估方法与人类感知不一致、精度低且依赖于真实信号。主观听觉测试虽是黄金标准但成本高昂难以规模化应用。因此需要开发一种可以自动化的参考无依的多模态客观评价系统。", "method": "提出了一种新的多模态细粒度的音频评估框架SAM Audio Judge，它支持三种音频领域（语音、音乐和一般声音事件）及三种提示输入类型（文本、视觉和范围），并且能够覆盖四个不同的评估维度。", "result": "该模型在与人类感知的一致性上表现出色，并且具备数据过滤、伪标签生成以及重排序等潜在应用价值。", "conclusion": "SAM Audio Judge为自动化音频分离性能评价提供了一种有效的方法，具有广泛的适用性和实用价值。"}}
{"id": "2601.19700", "pdf": "https://arxiv.org/pdf/2601.19700", "abs": "https://arxiv.org/abs/2601.19700", "authors": ["Jiajie Su", "Haoyuan Wang", "Xiaohua Feng", "Yunshan Ma", "Xiaobo Xia", "Yuyuan Li", "Xiaolin Zheng", "Jianmao Xiao", "Chaochao Chen"], "title": "Out-of-Distribution Generalization via Invariant Trajectories for Multimodal Large Language Model Editing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Knowledge editing emerges as a crucial technique for efficiently correcting incorrect or outdated knowledge in large language models (LLM). Existing editing methods for unimodal LLM rely on a rigid parameter-to-output mapping, which causes causal-underfit and causal-overfit in cascaded reasoning for Multimodal LLM (MLLM). In this paper, we reformulate MLLM editing as an out-of-distribution (OOD) generalization problem, where the goal is to discern semantic shift with factual shift and thus achieve robust editing among diverse cross-modal prompting. The key challenge of this OOD problem lies in identifying invariant causal trajectories that generalize accurately while suppressing spurious correlations. To address it, we propose ODEdit, a plug-and-play invariant learning based framework that optimizes the tripartite OOD risk objective to simultaneously enhance editing reliability, locality, and generality.We further introduce an edit trajectory invariant learning method, which integrates a total variation penalty into the risk minimization objective to stabilize edit trajectories against environmental variations. Theoretical analysis and extensive experiments demonstrate the effectiveness of ODEdit.", "AI": {"tldr": "本文提出了一种用于多模态大型语言模型编辑的方法，旨在解决因果偏差问题，并提高编辑的可靠性、局部性和普适性。", "motivation": "现有单模态大型语言模型（LLM）的编辑方法依赖于固定的参数到输出映射，这在处理多模态语言模型（MLLM）时会导致因果偏置和过度拟合。本文旨在通过识别不变的因果轨迹来解决这一问题，并实现鲁棒性的编辑。", "method": "提出了ODEdit框架，该框架基于不变学习并优化三元OOD风险目标以增强编辑的可靠性、局部性和普适性。同时引入了一种编辑轨迹不变学习方法，集成总变差惩罚以稳定编辑轨迹。", "result": "理论分析和广泛的实验表明，提出的ODIT方法有效提高了多模态大型语言模型编辑的效果。", "conclusion": "本文通过提出ODEdit框架及其编辑轨迹不变学习方法，在解决因果偏差问题的同时实现了多模态大型语言模型的鲁棒性编辑。"}}
{"id": "2601.19697", "pdf": "https://arxiv.org/pdf/2601.19697", "abs": "https://arxiv.org/abs/2601.19697", "authors": ["Tianyue Jiang", "Yanli Wang", "Yanlin Wang", "Daya Guo", "Ensheng Shi", "Yuchi Ma", "Jiachi Chen", "Zibin Zheng"], "title": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion", "categories": ["cs.SE", "cs.AI"], "comment": "To appear at ASE'25", "summary": "Repository-level code completion remains a challenging task for existing code large language models (code LLMs) due to their limited understanding of repository-specific context and domain knowledge. While retrieval-augmented generation (RAG) approaches have shown promise by retrieving relevant code snippets as cross-file context, they suffer from two fundamental problems: misalignment between the query and the target code in the retrieval process, and the inability of existing retrieval methods to effectively utilize the inference information. To address these challenges, we propose AlignCoder, a repository-level code completion framework that introduces a query enhancement mechanism and a reinforcement learning based retriever training method. Our approach generates multiple candidate completions to construct an enhanced query that bridges the semantic gap between the initial query and the target code. Additionally, we employ reinforcement learning to train an AlignRetriever that learns to leverage inference information in the enhanced query for more accurate retrieval. We evaluate AlignCoder on two widely-used benchmarks (CrossCodeEval and RepoEval) across five backbone code LLMs, demonstrating an 18.1% improvement in EM score compared to baselines on the CrossCodeEval benchmark. The results show that our framework achieves superior performance and exhibits high generalizability across various code LLMs and programming languages.", "AI": {"tldr": "提出了一种基于查询增强机制和强化学习的检索训练方法的代码补全框架AlignCoder，以提高仓库级别代码完成任务的表现。", "motivation": "现有的代码大语言模型在理解仓库特定上下文和领域知识方面存在局限性。RAG方法虽然通过检索相关代码片段作为跨文件背景信息取得了一定成果，但仍然面临查询与目标代码不匹配及无法有效利用推理信息的问题。", "method": "提出了一种新的框架AlignCoder，该框架引入了查询增强机制，生成多个候选补全以构建一个改进的查询，从而减少初始查询和目标代码之间的语义差距。此外，采用强化学习训练了一个检索器（AlignRetriever），使其能够利用改进查询中的推理信息进行更准确的检索。", "result": "在两个广泛使用的基准测试CrossCodeEval和RepoEval上进行了评估，在五种骨干代码大语言模型中展现了18.1%的EM评分提升。表明该框架具有优越性能并具备跨各种代码大语言模型及编程语言的高度泛化性。", "conclusion": "AlignCoder通过解决查询与目标代码之间的语义差距问题以及有效利用推理信息，显著提升了仓库级别代码完成任务的表现。"}}
{"id": "2601.19694", "pdf": "https://arxiv.org/pdf/2601.19694", "abs": "https://arxiv.org/abs/2601.19694", "authors": ["Yucheng Xie", "Fu Feng", "Ruixiao Shi", "Jing Wang", "Yong Rui", "Xin Geng"], "title": "Self-Supervised Weight Templates for Scalable Vision Model Initialization", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The increasing scale and complexity of modern model parameters underscore the importance of pre-trained models. However, deployment often demands architectures of varying sizes, exposing limitations of conventional pre-training and fine-tuning. To address this, we propose SWEET, a self-supervised framework that performs constraint-based pre-training to enable scalable initialization in vision tasks. Instead of pre-training a fixed-size model, we learn a shared weight template and size-specific weight scalers under Tucker-based factorization, which promotes modularity and supports flexible adaptation to architectures with varying depths and widths. Target models are subsequently initialized by composing and reweighting the template through lightweight weight scalers, whose parameters can be efficiently learned from minimal training data. To further enhance flexibility in width expansion, we introduce width-wise stochastic scaling, which regularizes the template along width-related dimensions and encourages robust, width-invariant representations for improved cross-width generalization. Extensive experiments on \\textsc{classification}, \\textsc{detection}, \\textsc{segmentation} and \\textsc{generation} tasks demonstrate the state-of-the-art performance of SWEET for initializing variable-sized vision models.", "AI": {"tldr": "提出了一种基于自监督的框架SWEET，用于视觉任务中可扩展模型初始化。", "motivation": "随着现代模型参数规模和复杂度的增长，传统的预训练方法在面对不同大小架构时存在局限性。为此，论文旨在开发一种新的预训练方式来适应不同深度和宽度的模型。", "method": "SWEET框架通过Tucker分解学习一个共享权重模板，并根据不同的模型尺寸调整这些权重。目标模型可以通过组合和重新加权该模板进行初始化，同时使用轻量级的权重缩放器从少量数据中高效地学习参数。", "result": "在分类、检测、分割和生成任务上的广泛实验显示，SWEET框架在为不同大小的视觉模型初始化方面表现出了最先进的性能。", "conclusion": "论文提出的SWEET方法通过自监督预训练有效地解决了大规模视觉模型适应性不足的问题，并展示了其在多个任务中的优越性能。"}}
{"id": "2601.19690", "pdf": "https://arxiv.org/pdf/2601.19690", "abs": "https://arxiv.org/abs/2601.19690", "authors": ["Renrong Shao", "Dongyang Li", "Dong Xia", "Lin Shao", "Jiangdong Lu", "Fen Zheng", "Lulu Zhang"], "title": "DSVM-UNet : Enhancing VM-UNet with Dual Self-distillation for Medical Image Segmentation", "categories": ["cs.CV"], "comment": "5 pages, 1 figures", "summary": "Vision Mamba models have been extensively researched in various fields, which address the limitations of previous models by effectively managing long-range dependencies with a linear-time overhead. Several prospective studies have further designed Vision Mamba based on UNet(VM-UNet) for medical image segmentation. These approaches primarily focus on optimizing architectural designs by creating more complex structures to enhance the model's ability to perceive semantic features. In this paper, we propose a simple yet effective approach to improve the model by Dual Self-distillation for VM-UNet (DSVM-UNet) without any complex architectural designs. To achieve this goal, we develop double self-distillation methods to align the features at both the global and local levels. Extensive experiments conducted on the ISIC2017, ISIC2018, and Synapse benchmarks demonstrate that our approach achieves state-of-the-art performance while maintaining computational efficiency. Code is available at https://github.com/RoryShao/DSVM-UNet.git.", "AI": {"tldr": "本文提出了一种通过双重自蒸馏方法改进VM-UNet的简单有效的方法，以增强医学图像分割性能。", "motivation": "为了提高医学图像分割模型的性能并简化复杂的设计结构，作者提出了DSVM-UNet方法。", "method": "该方法利用双自我蒸馏技术在全局和局部层面对特征进行校准，从而提升模型性能而不增加额外的计算开销。", "result": "实验结果表明，在ISIC2017、ISIC2018和Synapse数据集上，DSVM-UNet达到了最先进的性能，并且保持了计算效率。", "conclusion": "通过简单的双自我蒸馏技术，DSVM-UNet在医学图像分割任务中表现出色，证明了该方法的有效性。"}}
{"id": "2601.19686", "pdf": "https://arxiv.org/pdf/2601.19686", "abs": "https://arxiv.org/abs/2601.19686", "authors": ["Ziyue Wang", "Sheng Jin", "Zhongrong Zuo", "Jiawei Wu", "Han Qiu", "Qi She", "Hao Zhang", "Xudong Jiang"], "title": "Video-KTR: Reinforcing Video Reasoning via Key Token Attribution", "categories": ["cs.CV"], "comment": "Accepted to ICLR 2026", "summary": "Reinforcement learning (RL) has shown strong potential for enhancing reasoning in multimodal large language models, yet existing video reasoning methods often rely on coarse sequence-level rewards or single-factor token selection, neglecting fine-grained links among visual inputs, temporal dynamics, and linguistic outputs, limiting both accuracy and interpretability. We propose Video-KTR, a modality-aware policy shaping framework that performs selective, token-level RL by combining three attribution signals: (1) visual-aware tokens identified via counterfactual masking to reveal perceptual dependence; (2) temporal-aware tokens detected through frame shuffling to expose temporal sensitivity; and (3) high-entropy tokens signaling predictive uncertainty. By reinforcing only these key tokens, Video-KTR focuses learning on semantically informative, modality-sensitive content while filtering out low-value tokens. Across five challenging benchmarks, Video-KTR achieves state-of-the-art or highly competitive results, achieving 42.7\\% on Video-Holmes (surpassing GPT-4o) with consistent gains on both reasoning and general video understanding tasks. Ablation studies verify the complementary roles of the attribution signals and the robustness of targeted token-level updates. Overall, Video-KTR improves accuracy and interpretability, offering a simple, drop-in extension to RL for complex video reasoning. Our code and models are available at https://github.com/zywang0104/Video-KTR.", "AI": {"tldr": "视频推理通过关键标记归因增强", "motivation": "现有视频推理方法依赖于粗略的序列级奖励或单一因素令牌选择，忽略视觉输入、时间动态和语言输出之间的细粒度链接，从而限制了准确性和可解释性。", "method": "Video-KTR是一种基于模态感知策略调整框架的方法，通过结合三种归因信号进行选择性的令牌级别RL：(1) 视觉感知标记；(2) 时间感知标记；(3) 高熵标记。这种方法专注于学习语义信息丰富的、模态敏感的内容，并过滤掉低价值的令牌。", "result": "Video-KTR在五个具有挑战性的基准上实现了最先进的或高度竞争的结果，例如在Video-Holmes上的42.7％（超越GPT-4o），并且在推理和一般视频理解任务上均有显著提升。归因信号互补性以及目标令牌级别更新的鲁棒性通过消融研究得到了验证。", "conclusion": "总的来说，Video-KTR改进了准确性和可解释性，并为复杂的视频推理提供了一种简单、即插即用的RL扩展方法。"}}
{"id": "2601.19683", "pdf": "https://arxiv.org/pdf/2601.19683", "abs": "https://arxiv.org/abs/2601.19683", "authors": ["Hanting Niu", "Junkai Deng", "Fei Hou", "Wencheng Wang", "Ying He"], "title": "SharpNet: Enhancing MLPs to Represent Functions with Controlled Non-differentiability", "categories": ["cs.CV"], "comment": null, "summary": "Multi-layer perceptrons (MLPs) are a standard tool for learning and function approximation, but they inherently yield outputs that are globally smooth. As a result, they struggle to represent functions that are continuous yet deliberately non-differentiable (i.e., with prescribed $C^0$ sharp features) without relying on ad hoc post-processing. We present SharpNet, a modified MLP architecture capable of encoding functions with user-defined sharp features by enriching the network with an auxiliary feature function, which is defined as the solution to a Poisson equation with jump Neumann boundary conditions. It is evaluated via an efficient local integral that is fully differentiable with respect to the feature locations, enabling our method to jointly optimize both the feature locations and the MLP parameters to recover the target functions/models. The $C^0$-continuity of SharpNet is precisely controllable, ensuring $C^0$-continuity at the feature locations and smoothness elsewhere. We validate SharpNet on 2D problems and 3D CAD model reconstruction, and compare it against several state-of-the-art baselines. In both types of tasks, SharpNet accurately recovers sharp edges and corners while maintaining smooth behavior away from those features, whereas existing methods tend to smooth out gradient discontinuities. Both qualitative and quantitative evaluations highlight the benefits of our approach.", "AI": {"tldr": "本文提出了一种新的MLP架构SharpNet，能够表示具有用户定义的尖锐特征的函数。", "motivation": "现有的MLP由于其全局平滑性质，在不使用附加后处理的情况下无法准确表示有意非可微分的功能。", "method": "通过引入一个辅助功能函数并采用高效的局部积分方法来实现SharpNet，该方法可以对特性和参数进行联合优化。", "result": "在2D问题和3D CAD模型重建任务中，SharpNet能够准确地恢复尖锐边缘和角落，并保持其他位置的平滑行为。", "conclusion": "实验结果表明，SharpNet对于表示具有有意非可微分特征的功能比现有方法更有效。"}}
{"id": "2601.19680", "pdf": "https://arxiv.org/pdf/2601.19680", "abs": "https://arxiv.org/abs/2601.19680", "authors": ["Antonio Di Marino", "Vincenzo Bevilacqua", "Emanuel Di Nardo", "Angelo Ciaramella", "Ivanoe De Falco", "Giovanna Sannino"], "title": "A new Image Similarity Metric for a Perceptual and Transparent Geometric and Chromatic Assessment", "categories": ["cs.CV"], "comment": null, "summary": "In the literature, several studies have shown that state-of-the-art image similarity metrics are not perceptual metrics; moreover, they have difficulty evaluating images, especially when texture distortion is also present. In this work, we propose a new perceptual metric composed of two terms. The first term evaluates the dissimilarity between the textures of two images using Earth Mover's Distance. The second term evaluates the chromatic dissimilarity between two images in the Oklab perceptual color space. We evaluated the performance of our metric on a non-traditional dataset, called Berkeley-Adobe Perceptual Patch Similarity, which contains a wide range of complex distortions in shapes and colors. We have shown that our metric outperforms the state of the art, especially when images contain shape distortions, confirming also its greater perceptiveness. Furthermore, although deep black-box metrics could be very accurate, they only provide similarity scores between two images, without explaining their main differences and similarities. Our metric, on the other hand, provides visual explanations to support the calculated score, making the similarity assessment transparent and justified.", "AI": {"tldr": "提出了一个新的感知图像相似度衡量标准，用于透明的几何和色彩评估。", "motivation": "现有的最先进的图像相似度衡量标准缺乏感知能力，并且在处理包含纹理失真的图像时表现不佳。", "method": "新指标由两个部分组成：一部分使用Earth Mover's Distance评估两幅图像之间的纹理差异；另一部分则利用Oklab感知色彩空间评估颜色的不一致。该方法旨在提供更透明和可解释的结果。", "result": "在包含复杂形变和色差的非传统数据集上测试，新指标优于现有技术，尤其在处理含有形状失真的图像时表现突出，并提供了视觉解释以支持其评分。", "conclusion": "新的感知性衡量标准不仅准确度高，还能够提供透明且有根据的相似性评估。"}}
{"id": "2601.19674", "pdf": "https://arxiv.org/pdf/2601.19674", "abs": "https://arxiv.org/abs/2601.19674", "authors": ["Dominic Weisser", "Chloé Hashimoto-Cullen", "Benjamin Guedj"], "title": "Cross-Domain Offshore Wind Power Forecasting: Transfer Learning Through Meteorological Clusters", "categories": ["cs.LG", "cs.AI", "stat.AP", "stat.ME"], "comment": "11 pages", "summary": "Ambitious decarbonisation targets are catalysing growth in orders of new offshore wind farms. For these newly commissioned plants to run, accurate power forecasts are needed from the onset. These allow grid stability, good reserve management and efficient energy trading. Despite machine learning models having strong performances, they tend to require large volumes of site-specific data that new farms do not yet have. To overcome this data scarcity, we propose a novel transfer learning framework that clusters power output according to covariate meteorological features. Rather than training a single, general-purpose model, we thus forecast with an ensemble of expert models, each trained on a cluster. As these pre-trained models each specialise in a distinct weather pattern, they adapt efficiently to new sites and capture transferable, climate-dependent dynamics. Through the expert models' built-in calibration to seasonal and meteorological variability, we remove the industry-standard requirement of local measurements over a year. Our contributions are two-fold - we propose this novel framework and comprehensively evaluate it on eight offshore wind farms, achieving accurate cross-domain forecasting with under five months of site-specific data. Our experiments achieve a MAE of 3.52\\%, providing empirical verification that reliable forecasts do not require a full annual cycle. Beyond power forecasting, this climate-aware transfer learning method opens new opportunities for offshore wind applications such as early-stage wind resource assessment, where reducing data requirements can significantly accelerate project development whilst effectively mitigating its inherent risks.", "AI": {"tldr": "提出了一种通过气象聚类进行跨领域海上风力发电预测的迁移学习框架。", "motivation": "新的海上风电场需要准确的功率预测以确保电网稳定和能源交易效率，但这些新场所缺乏足够的特定位置数据，传统机器学习模型难以应对这种数据稀缺问题。", "method": "通过气象特征将功率输出聚类，并使用每个聚类训练专家模型来预测新站点的数据。这种方法适应性强，可以在新的风电场中利用气候相关动态。", "result": "实验在八个海上风电场上进行，仅需不到五个月的特定位置数据即可实现准确的跨领域预测，平均绝对误差为3.52%。", "conclusion": "所提出的迁移学习方法可以有效解决新风电场功率预测中的数据稀缺问题，并且减少了对一年内本地测量的需求，同时开启了早期阶段风资源评估等应用的新机会。"}}
{"id": "2601.19673", "pdf": "https://arxiv.org/pdf/2601.19673", "abs": "https://arxiv.org/abs/2601.19673", "authors": ["Iwona Christop", "Mateusz Czyżnikiewicz", "Paweł Skórzewski", "Łukasz Bondaruk", "Jakub Kubiak", "Marcin Lewandowski", "Marek Kubis"], "title": "A Benchmark for Audio Reasoning Capabilities of Multimodal Large Language Models", "categories": ["cs.SD", "cs.AI"], "comment": "31 pages, 2 figures, accepted to EACL 2026", "summary": "The present benchmarks for testing the audio modality of multimodal large language models concentrate on testing various audio tasks such as speaker diarization or gender identification in isolation. Whether a multimodal model can answer the questions that require reasoning skills to combine audio tasks of different categories, cannot be verified with their use. To address this issue, we propose Audio Reasoning Tasks (ART), a new benchmark for assessing the ability of multimodal models to solve problems that require reasoning over audio signal.", "AI": {"tldr": "提出了一种新的评估多模态模型音频推理能力的基准测试。", "motivation": "当前用于评估多模态大语言模型音频功能的基准仅在孤立情况下测试语音任务，无法验证这些模型是否能够解决需要跨不同类型音频任务进行推理的问题。", "method": "设计并实现了一种新的音频推理任务（ART），用以评估多模态模型的音频信号综合推理能力。", "result": "本文未提供具体结果数据或实验结论。", "conclusion": "通过引入音频推理任务（ART）基准，可以更好地测试和理解多模态大语言模型在处理需要跨不同类型语音任务进行复杂推理的问题时的能力。"}}
{"id": "2601.19672", "pdf": "https://arxiv.org/pdf/2601.19672", "abs": "https://arxiv.org/abs/2601.19672", "authors": ["Waris Gill", "Ahmad Humayun", "Ali Anwar", "Muhammad Ali Gulzar"], "title": "ProToken: Token-Level Attribution for Federated Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": null, "summary": "Federated Learning (FL) enables collaborative training of Large Language Models (LLMs) across distributed data sources while preserving privacy. However, when federated LLMs are deployed in critical applications, it remains unclear which client(s) contributed to specific generated responses, hindering debugging, malicious client identification, fair reward allocation, and trust verification. We present ProToken, a novel Provenance methodology for Token-level attribution in federated LLMs that addresses client attribution during autoregressive text generation while maintaining FL privacy constraints. ProToken leverages two key insights to enable provenance at each token: (1) transformer architectures concentrate task-specific signals in later blocks, enabling strategic layer selection for computational tractability, and (2) gradient-based relevance weighting filters out irrelevant neural activations, focusing attribution on neurons that directly influence token generation. We evaluate ProToken across 16 configurations spanning four LLM architectures (Gemma, Llama, Qwen, SmolLM) and four domains (medical, financial, mathematical, coding). ProToken achieves 98% average attribution accuracy in correctly localizing responsible client(s), and maintains high accuracy when the number of clients are scaled, validating its practical viability for real-world deployment settings.", "AI": {"tldr": "ProToken 是一种用于联邦大型语言模型中的 token 层级归属的方法，解决了在关键应用中识别生成响应的客户端的问题。", "motivation": "在分布式数据源上协作训练的大规模语言模型（LLMs）中，由于隐私保护的需求，难以确定特定生成响应是由哪些客户端贡献的。这阻碍了调试、恶意客户端检测、公平奖励分配和信任验证等操作。", "method": "ProToken 利用两个关键见解实现 token 层级归属：(1) 变换器架构将任务特有信号集中在后阶段块中，允许选择性层选取以提高计算可行性；(2) 基于梯度的相关权重筛选去除不相关的神经激活，聚焦影响生成的神经元。", "result": "ProToken 在四类 LLM 架构和四个领域中的16种配置下测试，平均归属于正确客户端的概率为98%，并且在扩展客户端数量时仍保持高准确性。", "conclusion": "ProToken 方法通过实现 token 层级归属解决了联邦大模型中难以追踪生成响应的来源的问题，并且验证了其在实际部署环境中的适用性。"}}
{"id": "2601.19667", "pdf": "https://arxiv.org/pdf/2601.19667", "abs": "https://arxiv.org/abs/2601.19667", "authors": ["Adam Remaki", "Christel Gérardin", "Eulàlia Farré-Maduell", "Martin Krallinger", "Xavier Tannier"], "title": "SynCABEL: Synthetic Contextualized Augmentation for Biomedical Entity Linking", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "We present SynCABEL (Synthetic Contextualized Augmentation for Biomedical Entity Linking), a framework that addresses a central bottleneck in supervised biomedical entity linking (BEL): the scarcity of expert-annotated training data. SynCABEL leverages large language models to generate context-rich synthetic training examples for all candidate concepts in a target knowledge base, providing broad supervision without manual annotation. We demonstrate that SynCABEL, when combined with decoder-only models and guided inference establish new state-of-the-art results across three widely used multilingual benchmarks: MedMentions for English, QUAERO for French, and SPACCC for Spanish. Evaluating data efficiency, we show that SynCABEL reaches the performance of full human supervision using up to 60% less annotated data, substantially reducing reliance on labor-intensive and costly expert labeling. Finally, acknowledging that standard evaluation based on exact code matching often underestimates clinically valid predictions due to ontology redundancy, we introduce an LLM-as-a-judge protocol. This analysis reveals that SynCABEL significantly improves the rate of clinically valid predictions. Our synthetic datasets, models, and code are released to support reproducibility and future research.", "AI": {"tldr": "SynCABEL是一种用于生物医学实体链接的框架，利用大语言模型生成上下文丰富的合成训练数据，以解决训练数据稀缺的问题。", "motivation": "解决监督学习中生物医学实体链接的数据不足问题，减少对昂贵且耗时的手动标注依赖。", "method": "SynCABEL通过使用大语言模型为知识库中的所有候选概念生成丰富上下文的合成训练示例，并与解码器模型结合进行引导推理。", "result": "在三个多语言基准测试中达到了新的最佳结果，减少了60%的手动标注数据量。引入了LLM作为裁判协议来评估临床有效性预测。", "conclusion": "SynCABEL显著提高了实体链接任务的性能和临床有效性的预测率，并通过公开合成数据集、模型和代码支持可重复研究。"}}
{"id": "2601.19659", "pdf": "https://arxiv.org/pdf/2601.19659", "abs": "https://arxiv.org/abs/2601.19659", "authors": ["Mao-Lin Luo", "Zi-Hao Zhou", "Yi-Lin Zhang", "Yuanyu Wan", "Tong Wei", "Min-Ling Zhang"], "title": "KeepLoRA: Continual Learning with Residual Gradient Adaptation", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at ICLR 2026", "summary": "Continual learning for pre-trained vision-language models requires balancing three competing objectives: retaining pre-trained knowledge, preserving knowledge from a sequence of learned tasks, and maintaining the plasticity to acquire new knowledge. This paper presents a simple but effective approach called KeepLoRA to effectively balance these objectives. We first analyze the knowledge retention mechanism within the model parameter space and find that general knowledge is mainly encoded in the principal subspace, while task-specific knowledge is encoded in the residual subspace. Motivated by this finding, KeepLoRA learns new tasks by restricting LoRA parameter updates in the residual subspace to prevent interfering with previously learned capabilities. Specifically, we infuse knowledge for a new task by projecting its gradient onto a subspace orthogonal to both the principal subspace of pre-trained model and the dominant directions of previous task features. Our theoretical and empirical analyses confirm that KeepLoRA balances the three objectives and achieves state-of-the-art performance. The implementation code is available at https://github.com/MaolinLuo/KeepLoRA.", "AI": {"tldr": "提出了一种名为KeepLoRA的新方法，用于在视觉语言预训练模型中进行持续学习。", "motivation": "为了平衡保留预先训练的知识、保存连续任务的学习知识和保持获取新知识的能力这三个目标。", "method": "分析了模型参数空间中的知识保留机制，并发现通用知识主要编码在主子空间，而特定于任务的知识则编码在残差子空间中。KeepLoRA通过限制LoRA参数更新来防止干扰先前学习的功能，在残差子空间中进行新任务的学习。", "result": "理论和实证分析确认了KeepLoRA能够平衡三个目标，并且实现了最先进的性能。", "conclusion": "提出了一个简单但有效的方法，即KeepLoRA，以在持续学习过程中有效地保持预训练模型的知识并获取新知识。"}}
{"id": "2601.19657", "pdf": "https://arxiv.org/pdf/2601.19657", "abs": "https://arxiv.org/abs/2601.19657", "authors": ["Zihou Zhang", "Zheyong Xie", "Li Zhong", "Haifeng Liu", "Shaosheng Cao"], "title": "One Token Is Enough: Improving Diffusion Language Models with a Sink Token", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Diffusion Language Models (DLMs) have emerged as a compelling alternative to autoregressive approaches, enabling parallel text generation with competitive performance. Despite these advantages, there is a critical instability in DLMs: the moving sink phenomenon. Our analysis indicates that sink tokens exhibit low-norm representations in the Transformer's value space, and that the moving sink phenomenon serves as a protective mechanism in DLMs to prevent excessive information mixing. However, their unpredictable positions across diffusion steps undermine inference robustness. To resolve this, we propose a simple but effective extra sink token implemented via a modified attention mask. Specifically, we introduce a special token constrained to attend solely to itself, while remaining globally visible to all other tokens. Experimental results demonstrate that introducing a single extra token stabilizes attention sinks, substantially improving model performance. Crucially, further analysis confirms that the effectiveness of this token is independent of its position and characterized by negligible semantic content, validating its role as a robust and dedicated structural sink.", "AI": {"tldr": "本文提出了一种新的Sink Token来解决DLM中的移动Sink现象，从而提高模型性能。", "motivation": "Diffusion Language Models存在一个关键的不稳定性——移动Sink现象。这种现象虽然作为一种保护机制防止信息过度混合，但其位置不可预测性影响了推理的稳健性。", "method": "引入了一个特殊的Sink Token，通过修改注意力掩码使其仅关注自身，并保持对所有其他Token的全局可见性来稳定注意力Sink。", "result": "实验结果显示，增加一个额外的Sink Token能够显著提高模型性能。进一步分析表明该Token的效果独立于其位置且几乎不含语义内容。", "conclusion": "本文提出的Sink Token有效解决了DLM中的移动Sink问题，并提高了模型的整体性能表现。"}}
{"id": "2601.19644", "pdf": "https://arxiv.org/pdf/2601.19644", "abs": "https://arxiv.org/abs/2601.19644", "authors": ["Stéphane Demri", "Tianwen Gu"], "title": "Robustness of Constraint Automata for Description Logics with Concrete Domains", "categories": ["cs.LO", "cs.AI"], "comment": "Extended version of a paper accepted at CSL'26, Paris", "summary": "Decidability or complexity issues about the consistency problem for description logics with concrete domains have already been analysed with tableaux-based or type elimination methods. Concrete domains in ontologies are essential to consider concrete objects and predefined relations. In this work, we expose an automata-based approach leading to the optimal upper bound EXPTIME, that is designed by enriching the transitions with symbolic constraints. We show that the nonemptiness problem for such automata belongs to EXPTIME if the concrete domains satisfy a few simple properties. Then, we provide a reduction from the consistency problem for ontologies, yielding EXPTIME-membership.Thanks to the expressivity of constraint automata, the results are extended to additional ingredients such as inverse roles, functional role names and constraint assertions, while maintaining EXPTIME-membership, which illustrates the robustness of the approach", "AI": {"tldr": "研究描述逻辑中包含具体域的一致性问题的自动机方法，展示了该方法的鲁棒性和效率。", "motivation": "解决描述逻辑与具体域结合时一致性问题的复杂度分析和决策问题。具体域允许在本体中考虑具体的对象和预定义的关系。", "method": "通过增加符号约束来丰富转换，并展示这样设计的自动机对于一致性的非空性问题属于EXPTIME类别，进而将该方法应用于包含逆角色、功能角色名称及约束断言等复杂情况的一致性问题上。", "result": "证明了所提出的方法对于一致性问题归属于EXPTIME类别，并且保持了这种效率，即使面对更为复杂的逻辑表达式也是如此。", "conclusion": "该自动机基于方法展示了其在处理描述逻辑中包含的具体域一致性的鲁棒性和有效性，尤其当扩展到逆角色、功能角色名称及约束断言等复杂情况时也依然如此。"}}
{"id": "2601.19643", "pdf": "https://arxiv.org/pdf/2601.19643", "abs": "https://arxiv.org/abs/2601.19643", "authors": ["Zoe Betta", "Davide Corongiu", "Carmine Tommaso Recchiuto", "Antonio Sgorbissa"], "title": "Enhancing Worker Safety in Harbors Using Quadruped Robots", "categories": ["cs.RO"], "comment": null, "summary": "Infrastructure inspection is becoming increasingly relevant in the field of robotics due to its significant impact on ensuring workers' safety. The harbor environment presents various challenges in designing a robotic solution for inspection, given the complexity of daily operations. This work introduces an initial phase to identify critical areas within the port environment. Following this, a preliminary solution using a quadruped robot for inspecting these critical areas is analyzed.", "AI": {"tldr": "本文提出了一种使用四足机器人进行港口环境检查的方法，以提高工人安全。", "motivation": "为了确保工人的安全，需要解决港口环境中基础设施检查的复杂性问题。", "method": "首先识别港区内的重要区域，然后分析初步解决方案，即采用四足机器人对这些关键区域进行检查。", "result": "提出了使用四足机器人的初步方案，并对其进行了分析。", "conclusion": "通过四足机器人进行港口环境的检查是可行且有效的。"}}
{"id": "2601.19640", "pdf": "https://arxiv.org/pdf/2601.19640", "abs": "https://arxiv.org/abs/2601.19640", "authors": ["Hao Chang", "Zhihui Wang", "Lingxiang Wu", "Peijin Wang", "Wenhui Diao", "Jinqiao Wang"], "title": "Towards Governance-Oriented Low-Altitude Intelligence: A Management-Centric Multi-Modal Benchmark With Implicitly Coordinated Vision-Language Reasoning Framework", "categories": ["cs.CV"], "comment": null, "summary": "Low-altitude vision systems are becoming a critical infrastructure for smart city governance. However, existing object-centric perception paradigms and loosely coupled vision-language pipelines are still difficult to support management-oriented anomaly understanding required in real-world urban governance. To bridge this gap, we introduce GovLA-10K, the first management-oriented multi-modal benchmark for low-altitude intelligence, along with GovLA-Reasoner, a unified vision-language reasoning framework tailored for governance-aware aerial perception. Unlike existing studies that aim to exhaustively annotate all visible objects, GovLA-10K is deliberately designed around functionally salient targets that directly correspond to practical management needs, and further provides actionable management suggestions grounded in these observations. To effectively coordinate the fine-grained visual grounding with high-level contextual language reasoning, GovLA-Reasoner introduces an efficient feature adapter that implicitly coordinates discriminative representation sharing between the visual detector and the large language model (LLM). Extensive experiments show that our method significantly improves performance while avoiding the need of fine-tuning for any task-specific individual components. We believe our work offers a new perspective and foundation for future studies on management-aware low-altitude vision-language systems.", "AI": {"tldr": "本文提出了GovLA-10K数据集和GovLA-Reasoner框架，以支持智慧城市管理中的低空智能。", "motivation": "现有的物体中心感知范式和松散耦合的视觉语言管道难以满足实际城市管理需求中的异常理解。为了填补这一空白，作者提出了一种面向治理的城市低空智能多模态基准GovLA-10K以及相应的统一视觉语言推理框架GovLA-Reasoner。", "method": "GovLA-10K围绕功能性显著的目标进行设计，并提供基于观察的可操作管理建议。GovLA-Reasoner引入了一个高效的特征适配器，用于在视觉检测器和大型语言模型之间隐式协调判别性表示共享。", "result": "实验结果表明该方法有效改善了性能，同时避免了为特定任务组件进行微调的需求。", "conclusion": "作者认为他们的工作为未来面向管理的低空视觉语言系统研究提供了新的视角和基础。"}}
{"id": "2601.19634", "pdf": "https://arxiv.org/pdf/2601.19634", "abs": "https://arxiv.org/abs/2601.19634", "authors": ["Wenda Yu", "Tianshi Wang", "Fengling Li", "Jingjing Li", "Lei Zhu"], "title": "AC^2-VLA: Action-Context-Aware Adaptive Computation in Vision-Language-Action Models for Efficient Robotic Manipulation", "categories": ["cs.RO", "cs.MM"], "comment": null, "summary": "Vision-Language-Action (VLA) models have demonstrated strong performance in robotic manipulation, yet their closed-loop deployment is hindered by the high latency and compute cost of repeatedly running large vision-language backbones at every timestep. We observe that VLA inference exhibits structured redundancies across temporal, spatial, and depth dimensions, and that most existing efficiency methods ignore action context, despite its central role in embodied tasks. To address this gap, we propose Action-Context-aware Adaptive Computation for VLA models (AC^2-VLA), a unified framework that conditions computation on current visual observations, language instructions, and previous action states. Based on this action-centric context, AC^2-VLA adaptively performs cognition reuse across timesteps, token pruning, and selective execution of model components within a unified mechanism. To train the adaptive policy, we introduce an action-guided self-distillation scheme that preserves the behavior of the dense VLA policy while enabling structured sparsification that transfers across tasks and settings. Extensive experiments on robotic manipulation benchmarks show that AC^2-VLA achieves up to a 1.79\\times speedup while reducing FLOPs to 29.4% of the dense baseline, with comparable task success.", "AI": {"tldr": "提出了AC^2-VLA框架，通过利用动作上下文信息，在视觉语言行动模型中实现自适应计算以提高机器人操作效率。", "motivation": "现有的视觉语言行动模型由于高延迟和高昂的计算成本，在闭环部署时面临挑战。这些问题源于模型在每个时间步都需要运行大量的视觉语言骨干网络。为此，提出AC^2-VLA框架来解决这个问题。", "method": "通过结合当前视觉观察、语言指令以及先前的动作状态，AC^2-VLA能够根据动作上下文自适应地重复认知任务、修剪令牌并选择性执行模型组件。", "result": "实验表明，与密集基准相比，AC^2-VLA可以实现高达1.79倍的速度提升，并将FLOPs减少到29.4%，同时保持相当的任务成功率。", "conclusion": "通过使用自适应策略和行动引导的自我提炼方案，AC^2-VLA能够在不牺牲任务成功率的情况下提高机器人操作效率。"}}
{"id": "2601.19624", "pdf": "https://arxiv.org/pdf/2601.19624", "abs": "https://arxiv.org/abs/2601.19624", "authors": ["Tongxi Wang", "Zhuoyang Xia", "Xinran Chen", "Shan Liu"], "title": "Tracking Drift: Variation-Aware Entropy Scheduling for Non-Stationary Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real-world reinforcement learning often faces environment drift, but most existing methods rely on static entropy coefficients/target entropy, causing over-exploration during stable periods and under-exploration after drift (thus slow recovery), and leaving unanswered the principled question of how exploration intensity should scale with drift magnitude. We prove that entropy scheduling under non-stationarity can be reduced to a one-dimensional, round-by-round trade-off, faster tracking of the optimal solution after drift vs. avoiding gratuitous randomness when the environment is stable, so exploration strength can be driven by measurable online drift signals. Building on this, we propose AES (Adaptive Entropy Scheduling), which adaptively adjusts the entropy coefficient/temperature online using observable drift proxies during training, requiring almost no structural changes and incurring minimal overhead. Across 4 algorithm variants, 12 tasks, and 4 drift modes, AES significantly reduces the fraction of performance degradation caused by drift and accelerates recovery after abrupt changes.", "AI": {"tldr": "论文提出了一种适应环境漂移的熵调度方法AES，通过在线调整熵系数来优化非稳定环境下强化学习的表现。", "motivation": "现有大多数方法依赖静态熵系数，在稳定环境中会导致过度探索，在变化后又会因不足的探索而导致恢复缓慢。作者试图解决如何根据环境漂移强度调整探索力度的问题。", "method": "论文通过理论证明，适应性地调整熵系数可以更好地应对非稳定的强化学习环境，并基于此提出了AES方法，该方法使用可观察到的漂移信号来动态调节训练过程中的熵系数。", "result": "在不同算法变体、任务和漂移模式下，AES显著减少了由环境变化导致的表现退化，并加快了恢复速度。", "conclusion": "适应性调整熵系数可以有效地提高非稳定环境下强化学习的性能和恢复能力。"}}
{"id": "2601.19622", "pdf": "https://arxiv.org/pdf/2601.19622", "abs": "https://arxiv.org/abs/2601.19622", "authors": ["Thomas Bömer", "Nico Koltermann", "Max Disselnmeyer", "Bastian Amberg", "Anne Meyer"], "title": "Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search", "categories": ["cs.AI", "math.OC"], "comment": "accepted at EvoStar conference; Code: https://github.com/tb-git-tud/a-ceoh-evolution-of-heuristics?tab=readme-ov-file", "summary": "Heuristic functions are essential to the performance of tree search algorithms such as A*, where their accuracy and efficiency directly impact search outcomes. Traditionally, such heuristics are handcrafted, requiring significant expertise. Recent advances in large language models (LLMs) and evolutionary frameworks have opened the door to automating heuristic design. In this paper, we extend the Evolution of Heuristics (EoH) framework to investigate the automated generation of guiding heuristics for A* search. We introduce a novel domain-agnostic prompt augmentation strategy that includes the A* code into the prompt to leverage in-context learning, named Algorithmic - Contextual EoH (A-CEoH). To evaluate the effectiveness of A-CeoH, we study two problem domains: the Unit-Load Pre-Marshalling Problem (UPMP), a niche problem from warehouse logistics, and the classical sliding puzzle problem (SPP). Our computational experiments show that A-CEoH can significantly improve the quality of the generated heuristics and even outperform expert-designed heuristics.", "AI": {"tldr": "本文提出了一种基于大语言模型的自动化启发式设计方法A-CeoH，用于提升A*搜索算法性能。", "motivation": "传统启发式函数需要大量专业知识进行手工编写。为了提高效率和准确性，作者引入了大语言模型与演化框架相结合的方法来自动设计启发式函数。", "method": "本文将进化启发式(EoH)框架扩展到自动生成A*搜索的指导启发式中，并提出了一种新型无域依赖提示增强策略——Algorithmic-Contextual EoH(A-CeoH)，通过在提示中包含A*代码来利用上下文学习。", "result": "实验结果显示，A-CeoH不仅能够显著改善生成的启发式函数质量，还能超越专家设计的启发式函数。", "conclusion": "该研究证明了大语言模型结合演化框架可以有效地自动设计高质量的启发式函数以提升A*搜索算法的效果。"}}
{"id": "2601.19620", "pdf": "https://arxiv.org/pdf/2601.19620", "abs": "https://arxiv.org/abs/2601.19620", "authors": ["Zhizheng Jiang", "Kang Zhao", "Weikai Xu", "Xinkui Lin", "Wei Liu", "Jian Luan", "Shuo Shang", "Peng Han"], "title": "R^3: Replay, Reflection, and Ranking Rewards for LLM Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large reasoning models (LRMs) aim to solve diverse and complex problems through structured reasoning. Recent advances in group-based policy optimization methods have shown promise in enabling stable advantage estimation without reliance on process-level annotations. However, these methods rely on advantage gaps induced by high-quality samples within the same batch, which makes the training process fragile and inefficient when intra-group advantages collapse under challenging tasks. To address these problems, we propose a reinforcement learning mechanism named \\emph{\\textbf{R^3}} that along three directions: (1) a \\emph{cross-context \\underline{\\textbf{R}}eplay} strategy that maintains the intra-group advantage by recalling valuable examples from historical trajectories of the same query, (2) an \\emph{in-context self-\\underline{\\textbf{R}}eflection} mechanism enabling models to refine outputs by leveraging past failures, and (3) a \\emph{structural entropy \\underline{\\textbf{R}}anking reward}, which assigns relative rewards to truncated or failed samples by ranking responses based on token-level entropy patterns, capturing both local exploration and global stability. We implement our method on Deepseek-R1-Distill-Qwen-1.5B and train it on the DeepscaleR-40k in the math domain. Experiments demonstrate our method achieves SoTA performance on several math benchmarks, representing significant improvements and fewer reasoning tokens over the base models. Code and model will be released.", "AI": {"tldr": "提出了一种新的强化学习机制R^3，通过重播、自我反思和基于结构熵的排名奖励来增强大型推理模型（LRMs）在解决复杂问题时的表现。", "motivation": "现有小组策略优化方法依赖于高质量样本生成的优势差距，在处理困难任务时训练过程不稳定且低效。为了解决这一问题，作者提出了R^3机制。", "method": "R^3通过以下三个方面进行改进：1）跨上下文重播策略保持组内优势；2）在上下文中自我反思机制使模型能够利用过去的失败来优化输出；3）基于结构熵的排名奖励为截断或失败样本分配相对奖励，以捕捉局部探索和全局稳定性。", "result": "实验表明，在数学领域使用Deepseek-R1-Distill-Qwen-1.5B和DeepscaleR-40k数据集进行训练时，该方法在多个数学基准测试中实现了SOTA性能，并且比基线模型更少的推理令牌。", "conclusion": "提出的R^3机制通过引入跨上下文重播、自我反思和基于结构熵的排名奖励显著提高了大型推理模型的效率和稳定性。"}}
{"id": "2601.19618", "pdf": "https://arxiv.org/pdf/2601.19618", "abs": "https://arxiv.org/abs/2601.19618", "authors": ["Soroosh Tayebi Arasteh", "Mina Farajiamiri", "Mahshad Lotfinia", "Behrus Hinrichs-Puladi", "Jonas Bienzeisler", "Mohamed Alhaskir", "Mirabela Rusu", "Christiane Kuhl", "Sven Nebelung", "Daniel Truhn"], "title": "The role of self-supervised pretraining in differentially private medical image analysis", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Differential privacy (DP) provides formal protection for sensitive data but typically incurs substantial losses in diagnostic performance. Model initialization has emerged as a critical factor in mitigating this degradation, yet the role of modern self-supervised learning under full-model DP remains poorly understood. Here, we present a large-scale evaluation of initialization strategies for differentially private medical image analysis, using chest radiograph classification as a representative benchmark with more than 800,000 images. Using state-of-the-art ConvNeXt models trained with DP-SGD across realistic privacy regimes, we compare non-domain-specific supervised ImageNet initialization, non-domain-specific self-supervised DINOv3 initialization, and domain-specific supervised pretraining on MIMIC-CXR, the largest publicly available chest radiograph dataset. Evaluations are conducted across five external datasets spanning diverse institutions and acquisition settings. We show that DINOv3 initialization consistently improves diagnostic utility relative to ImageNet initialization under DP, but remains inferior to domain-specific supervised pretraining, which achieves performance closest to non-private baselines. We further demonstrate that initialization choice strongly influences demographic fairness, cross-dataset generalization, and robustness to data scale and model capacity under privacy constraints. The results establish initialization strategy as a central determinant of utility, fairness, and generalization in differentially private medical imaging.", "AI": {"tldr": "研究探讨了在差分隐私保护下的医学图像分析中，初始化策略对模型性能的影响。", "motivation": "差分隐私技术通常会对诊断性能造成严重损失。现代自监督学习在全模态差分隐私下的角色尚未充分理解，因此需要评估不同的初始化策略以减轻这种退化。", "method": "研究使用ConvNeXt模型进行训练，并对比了三种初始化方法：基于ImageNet的非领域特定监督预训练、DINOv3的自监督预训练和MIMIC-CXR上的领域特异性监督预训练。实验在五个外部数据集上进行了交叉验证。", "result": "结果显示，相较于使用ImageNet初始化，在差分隐私下采用DINOv3初始化可以提高诊断性能；而领域特定的监督预训练表现最佳。此外，初始化选择对不同性别的公平性和模型在规模和容量上的鲁棒性具有重要影响。", "conclusion": "该研究证明了初始化策略是决定差分隐私保护下的医学图像分析中模型效用、公平性和泛化能力的关键因素。"}}
{"id": "2601.19613", "pdf": "https://arxiv.org/pdf/2601.19613", "abs": "https://arxiv.org/abs/2601.19613", "authors": ["Xinzhong Wang", "Ya Guo", "Jing Li", "Huan Chen", "Yi Tu", "Yijie Hong", "Gongshen Liu", "Huijia Zhu"], "title": "Up to 36x Speedup: Mask-based Parallel Inference Paradigm for Key Information Extraction in MLLMs", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ICASSP 2026", "summary": "Key Information Extraction (KIE) from visually-rich documents (VrDs) is a critical task, for which recent Large Language Models (LLMs) and Multi-Modal Large Language Models (MLLMs) have demonstrated strong potential. However, their reliance on autoregressive inference, which generates outputs sequentially, creates a significant efficiency bottleneck, especially as KIE tasks often involve extracting multiple, semantically independent fields. To overcome this limitation, we introduce PIP: a Parallel Inference Paradigm for KIE. Our approach reformulates the problem by using \"[mask]\" tokens as placeholders for all target values, enabling their simultaneous generation in a single forward pass. To facilitate this paradigm, we develop a tailored mask pre-training strategy and construct large-scale supervised datasets. Experimental results show that our PIP-models achieve a 5-36x inference speedup with negligible performance degradation compared to traditional autoregressive base models. By substantially improving efficiency while maintaining high accuracy, PIP paves the way for scalable and practical real-world KIE solutions.", "AI": {"tldr": "本文提出了PIP（Parallel Inference Paradigm）模型，用于从视觉丰富文档中提取关键信息，并通过使用掩码令牌实现了并行推理以提高效率。", "motivation": "传统自回归LLM和MLLM在进行关键信息抽取时存在效率瓶颈，特别是在需要提取多个独立语义字段的情况下。为了解决这一问题，提出了一种新的并行推理框架来提高效率。", "method": "该方法通过将所有目标值替换为[mask]令牌作为占位符，并采用定制的掩码预训练策略和大规模监督数据集来进行并行生成，从而实现同时进行多个字段提取。", "result": "实验表明，PIP模型相比传统自回归基础模型在推理速度上实现了5-36倍的速度提升，而性能下降可忽略不计。", "conclusion": "通过大幅提高效率并保持高精度，PIP为实际世界中的大规模关键信息抽取解决方案铺平了道路。"}}
{"id": "2601.19612", "pdf": "https://arxiv.org/pdf/2601.19612", "abs": "https://arxiv.org/abs/2601.19612", "authors": ["Manuel Wendl", "Yarden As", "Manish Prajapat", "Anton Pollak", "Stelian Coros", "Andreas Krause"], "title": "Safe Exploration via Policy Priors", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Safe exploration is a key requirement for reinforcement learning (RL) agents to learn and adapt online, beyond controlled (e.g. simulated) environments. In this work, we tackle this challenge by utilizing suboptimal yet conservative policies (e.g., obtained from offline data or simulators) as priors. Our approach, SOOPER, uses probabilistic dynamics models to optimistically explore, yet pessimistically fall back to the conservative policy prior if needed. We prove that SOOPER guarantees safety throughout learning, and establish convergence to an optimal policy by bounding its cumulative regret. Extensive experiments on key safe RL benchmarks and real-world hardware demonstrate that SOOPER is scalable, outperforms the state-of-the-art and validate our theoretical guarantees in practice.", "AI": {"tldr": "本文提出了一种利用概率动态模型进行乐观探索的方法SOOPER，同时在必要时回归保守策略以确保安全性的强化学习方法。", "motivation": "为了使RL代理能够在受控环境之外在线学习和适应，解决安全性问题是一项关键要求。通过使用从离线数据或模拟器获得的次优但保守的策略作为先验来实现这一目标。", "method": "SOOPER利用概率动力学模型进行乐观探索，并在需要时退回到保守的策略前例以确保安全。该方法保证了学习过程中的安全性，同时通过限制累积遗憾来收敛到最优策略。", "result": "广泛的实验表明，SOOPER在关键的安全强化学习基准和现实世界硬件上表现出色，不仅验证了理论上的保障，而且超越了现有技术。", "conclusion": "本文提出的SOOPER方法证明了其在确保安全性和性能方面的有效性，并展示了其在各种环境中的可扩展性。"}}
{"id": "2601.19611", "pdf": "https://arxiv.org/pdf/2601.19611", "abs": "https://arxiv.org/abs/2601.19611", "authors": ["Runyu Peng", "Yunhua Zhou", "Demin Song", "Kai Lv", "Bo Wang", "Qipeng Guo", "Xipeng Qiu"], "title": "Explicit Multi-head Attention for Inter-head Interaction in Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "In large language models built upon the Transformer architecture, recent studies have shown that inter-head interaction can enhance attention performance. Motivated by this, we propose Multi-head Explicit Attention (MEA), a simple yet effective attention variant that explicitly models cross-head interaction. MEA consists of two key components: a Head-level Linear Composition (HLC) module that separately applies learnable linear combinations to the key and value vectors across heads, thereby enabling rich inter-head communication; and a head-level Group Normalization layer that aligns the statistical properties of the recombined heads. MEA shows strong robustness in pretraining, which allows the use of larger learning rates that lead to faster convergence, ultimately resulting in lower validation loss and improved performance across a range of tasks. Furthermore, we explore the parameter efficiency of MEA by reducing the number of attention heads and leveraging HLC to reconstruct them using low-rank \"virtual heads\". This enables a practical key-value cache compression strategy that reduces KV-cache memory usage by 50% with negligible performance loss on knowledge-intensive and scientific reasoning tasks, and only a 3.59% accuracy drop for Olympiad-level mathematical benchmarks.", "AI": {"tldr": "该论文提出了Multi-head Explicit Attention（MEA），一种能够增强跨头交互的注意力变体，以提高大规模语言模型的表现。", "motivation": "在基于Transformer架构的大规模语言模型中，最近的研究表明跨头交互可以提升注意力性能。受此启发，作者提出了一种新的注意力机制来显式建模跨头之间的相互作用。", "method": "MEA包含两个关键组件：Head-level Linear Composition（HLC）模块和head级的Group Normalization层。HLC模块对键值向量进行可学习的线性组合操作以促进丰富的跨头通信，而Group Normalization层用于调整重新组合后的头部统计特性。", "result": "MEA在预训练阶段表现出很强的鲁棒性，并允许使用较大的学习率从而加快收敛速度并降低验证损失。此外，在减少注意力头部数量的同时利用HLC重建低秩‘虚拟’头部，实现了有效的键值缓存压缩策略。", "conclusion": "该方法不仅提高了模型性能，还显著减少了内存消耗，同时保持了较好的任务表现。"}}
{"id": "2601.19607", "pdf": "https://arxiv.org/pdf/2601.19607", "abs": "https://arxiv.org/abs/2601.19607", "authors": ["Haoyun Li", "Ming Xiao", "Kezhi Wang", "Robert Schober", "Dong In Kim", "Yong Liang Guan"], "title": "ComAgent: Multi-LLM based Agentic AI Empowered Intelligent Wireless Networks", "categories": ["cs.AI"], "comment": null, "summary": "Emerging 6G networks rely on complex cross-layer optimization, yet manually translating high-level intents into mathematical formulations remains a bottleneck. While Large Language Models (LLMs) offer promise, monolithic approaches often lack sufficient domain grounding, constraint awareness, and verification capabilities. To address this, we present ComAgent, a multi-LLM agentic AI framework. ComAgent employs a closed-loop Perception-Planning-Action-Reflection cycle, coordinating specialized agents for literature search, coding, and scoring to autonomously generate solver-ready formulations and reproducible simulations. By iteratively decomposing problems and self-correcting errors, the framework effectively bridges the gap between user intent and execution. Evaluations demonstrate that ComAgent achieves expert-comparable performance in complex beamforming optimization and outperforms monolithic LLMs across diverse wireless tasks, highlighting its potential for automating design in emerging wireless networks.", "AI": {"tldr": "本文提出了ComAgent，一种基于多LLM的代理AI框架，用于解决6G网络中的复杂跨层优化问题。", "motivation": "现有方法在将高层次意图转化为数学模型时存在瓶颈，单体大型语言模型缺乏足够的领域知识、约束意识和验证能力。因此，需要一个能够自主生成求解器可读形式化的多代理AI框架。", "method": "ComAgent采用感知-规划-行动-反思的闭环周期，并协调专门的代理执行文献搜索、编码和评分任务，以自动生成求解器可以处理的形式化表达式和可重复模拟。", "result": "实验表明，ComAgent在复杂波束成形优化中达到了专家水平的表现，并且在各种无线任务上都优于单体大型语言模型。", "conclusion": "本文提出的ComAgent框架展示了其作为新兴无线网络设计自动化工具的潜力。"}}
{"id": "2601.19606", "pdf": "https://arxiv.org/pdf/2601.19606", "abs": "https://arxiv.org/abs/2601.19606", "authors": ["Shentong Mo", "Zehua Chen", "Jun Zhu"], "title": "GMS-CAVP: Improving Audio-Video Correspondence with Multi-Scale Contrastive and Generative Pretraining", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "Recent advances in video-audio (V-A) understanding and generation have increasingly relied on joint V-A embeddings, which serve as the foundation for tasks such as cross-modal retrieval and generation. While prior methods like CAVP effectively model semantic and temporal correspondences between modalities using contrastive objectives, their performance remains suboptimal. A key limitation is the insufficient modeling of the dense, multi-scale nature of both video and audio signals, correspondences often span fine- to coarse-grained spatial-temporal structures, which are underutilized in existing frameworks. To this end, we propose GMS-CAVP, a novel framework that combines Multi-Scale Video-Audio Alignment and Multi-Scale Spatial-Temporal Diffusion-based pretraining objectives to enhance V-A correspondence modeling. First, GMS-CAVP introduces a multi-scale contrastive learning strategy that captures semantic and temporal relations across varying granularities. Second, we go beyond traditional contrastive learning by incorporating a diffusion-based generative objective, enabling modality translation and synthesis between video and audio. This unified discriminative-generative formulation facilitates deeper cross-modal understanding and paves the way for high-fidelity generation. Extensive experiments on VGGSound, AudioSet, and Panda70M demonstrate that GMS-CAVP outperforms previous methods in generation and retrieval.", "AI": {"tldr": "本文提出了GMS-CAVP框架，通过多尺度对比和生成预训练来改进音频视频对应关系。", "motivation": "现有的方法在建模视频和音频信号的密集、多层次特性方面存在不足。这些特性跨越了细到粗的空间时间结构，在现有框架中未得到充分利用。", "method": "GMS-CAVP引入了一种多尺度对比学习策略，捕捉不同粒度下的语义和时序关系，并结合扩散生成目标以实现模态之间的翻译和合成。", "result": "在VGGSound、AudioSet和Panda70M上的实验表明，GMS-CAVP优于先前的方法，在生成和检索任务上表现更佳。", "conclusion": "通过将对比学习与生成模型结合，GMS-CAVP能够更好地理解和生成跨模态的对应关系。"}}
{"id": "2601.19595", "pdf": "https://arxiv.org/pdf/2601.19595", "abs": "https://arxiv.org/abs/2601.19595", "authors": ["Jiří Němeček", "Mark Kozdoba", "Illia Kryvoviaz", "Tomáš Pevný", "Jakub Mareček"], "title": "Intersectional Fairness via Mixed-Integer Optimization", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": "17 pages, 10 figures, 1 table", "summary": "The deployment of Artificial Intelligence in high-risk domains, such as finance and healthcare, necessitates models that are both fair and transparent. While regulatory frameworks, including the EU's AI Act, mandate bias mitigation, they are deliberately vague about the definition of bias. In line with existing research, we argue that true fairness requires addressing bias at the intersections of protected groups. We propose a unified framework that leverages Mixed-Integer Optimization (MIO) to train intersectionally fair and intrinsically interpretable classifiers. We prove the equivalence of two measures of intersectional fairness (MSD and SPSF) in detecting the most unfair subgroup and empirically demonstrate that our MIO-based algorithm improves performance in finding bias. We train high-performing, interpretable classifiers that bound intersectional bias below an acceptable threshold, offering a robust solution for regulated industries and beyond.", "AI": {"tldr": "本文提出了一种基于混合整数优化（MIO）的框架，用于训练公平且可解释的分类器，以解决高风险领域的偏见问题。", "motivation": "人工智能在金融和医疗等高风险领域部署需要同时考虑模型的公平性和透明度。现有的法规虽然要求减少偏差但没有明确定义什么是偏差。研究指出，真正的公平性应包括对受保护群体交叉点上的偏差进行处理。", "method": "提出了一个利用混合整数优化（MIO）的方法框架来训练交集公平且内在可解释的分类器，并证明了两种衡量交集公平性的指标MSD和SPSF在检测最不公平子群方面的等价性。通过实验验证，MIO算法能够更好地找到偏差并降低其影响。", "result": "该方法可以培训高性能、可解释的分类器，在保持性能的同时将交叉偏见控制在一个可接受范围内。", "conclusion": "提出的基于混合整数优化的方法为监管行业提供了一种有效的解决交集公平性的策略，具有广泛的应用前景。"}}
{"id": "2601.19593", "pdf": "https://arxiv.org/pdf/2601.19593", "abs": "https://arxiv.org/abs/2601.19593", "authors": ["Estèphe Arnaud", "Mohamed Daoudi", "Pierre Guerreschi"], "title": "Localized Latent Editing for Dose-Response Modeling in Botulinum Toxin Injection Planning", "categories": ["cs.CV"], "comment": null, "summary": "Botulinum toxin (Botox) injections are the gold standard for managing facial asymmetry and aesthetic rejuvenation, yet determining the optimal dosage remains largely intuitive, often leading to suboptimal outcomes. We propose a localized latent editing framework that simulates Botulinum Toxin injection effects for injection planning through dose-response modeling. Our key contribution is a Region-Specific Latent Axis Discovery method that learns localized muscle relaxation trajectories in StyleGAN2's latent space, enabling precise control over specific facial regions without global side effects. By correlating these localized latent trajectories with injected toxin units, we learn a predictive dose-response model. We rigorously compare two approaches: direct metric regression versus image-based generative simulation on a clinical dataset of N=360 images from 46 patients. On a hold-out test set, our framework demonstrates moderate-to-strong structural correlations for geometric asymmetry metrics, confirming that the generative model correctly captures the direction of morphological changes. While biological variability limits absolute precision, we introduce a hybrid \"Human-in-the-Loop\" workflow where clinicians interactively refine simulations, bridging the gap between pathological reconstruction and cosmetic planning.", "AI": {"tldr": "本文提出了一种用于肉毒杆菌毒素注射规划的局部潜变量编辑框架，通过剂量反应建模模拟注射效果。", "motivation": "当前确定肉毒杆菌毒素注射的最佳剂量主要依赖于直觉判断，这往往导致治疗结果不理想。因此，本研究旨在开发一种更精确的方法来预测和优化面部对称性和美容年轻化的注射效果。", "method": "本文提出了一种局部潜变量轴发现方法，在StyleGAN2的潜在空间中学习特定肌肉松弛轨迹，并通过与注入毒素单位相关联建立剂量反应模型。比较了直接度量回归和基于图像生成模拟两种方式的效果，引入“人机交互”工作流以提高预测精度。", "result": "在包含360张临床图片的数据集上进行测试后，本框架展示了中等到强的结构性关联性，表明生成模型能够正确捕捉到形态变化的方向。尽管生物变异限制了绝对精度，但通过与临床医生互动的方式提高了治疗计划的准确性。", "conclusion": "本文开发了一种基于局部潜变量编辑的新方法，通过剂量反应建模来优化肉毒杆菌毒素注射的效果。此研究结果有望改善面部不对称和美容年轻化的治疗效果。"}}
{"id": "2601.19588", "pdf": "https://arxiv.org/pdf/2601.19588", "abs": "https://arxiv.org/abs/2601.19588", "authors": ["Yongqi Wang", "Xiaofeng Ji", "Jie Wang", "Qingbin Li", "Xiao Xiong", "Zheming Yang", "Jian Xu", "Minghui Qiu", "Xinxiao Wu"], "title": "From Atoms to Chains: Divergence-Guided Reasoning Curriculum for Unlabeled LLM Domain Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": "Code: https://github.com/bytedance/DGRC", "summary": "Adapting Large Language Models (LLMs) to specialized domains without human-annotated data is a crucial yet formidable challenge. Widely adopted knowledge distillation methods often devolve into coarse-grained mimicry, where the student model inefficiently targets its own weaknesses and risks inheriting the teacher's reasoning flaws. This exposes a critical pedagogical dilemma: how to devise a reliable curriculum when the teacher itself is not an infallible expert. Our work resolves this by capitalizing on a key insight: while LLMs may exhibit fallibility in complex, holistic reasoning, they often exhibit high fidelity on focused, atomic sub-problems. Based on this, we propose Divergence-Guided Reasoning Curriculum (DGRC), which constructs a learning path from atomic knowledge to reasoning chains by dynamically deriving two complementary curricula from disagreements in reasoning pathways. When a student and teacher produce conflicting results, DGRC directs the teacher to perform a diagnostic analysis: it analyzes both reasoning paths to formulate atomic queries that target the specific points of divergence, and then self-answers these queries to create high-confidence atomic question-answer pairs. These pairs then serve a dual purpose: (1) providing an atomic curriculum to rectify the student's knowledge gaps, and (2) serving as factual criteria to filter the teacher's original reasoning chains, yielding a verified CoT curriculum that teaches the student how to integrate atomic knowledge into complete reasoning paths. Experiments across the medical and legal domains on student models of various sizes demonstrate the effectiveness of our DGRC framework. Notably, our method achieves a 7.76% relative improvement for the 1.5B student model in the medical domain over strong unlabeled baseline.", "AI": {"tldr": "该论文提出了一种无需人工标注数据即可适应特定领域的大型语言模型的方法，称为分歧引导的推理课程（DGRC）。", "motivation": "在没有人类注释的情况下将大型语言模型（LLMs）适应到专门领域是一个重要的挑战。现有的知识蒸馏方法往往导致粗粒度模仿，学生模型低效地针对自身的弱点，并可能继承老师的推理缺陷。", "method": "提出了一种基于分歧的课程学习方法DGRC，通过动态从推理路径中的差异中构建两套互补的课程：当老师和学生产生冲突结果时，DGRC会执行诊断分析以生成原子问题答案对，以此为依据纠正学生的知识差距并过滤老师的原始推理链。", "result": "实验表明，在医学领域，该方法相比强无标签基线在1.5B学生模型上实现了7.76%的相对改进。", "conclusion": "DGRC框架可以有效提高大型语言模型适应特定领域的性能。"}}
{"id": "2601.19585", "pdf": "https://arxiv.org/pdf/2601.19585", "abs": "https://arxiv.org/abs/2601.19585", "authors": ["Chongjun Xia", "Yanchun Peng", "Xianzhi Wang"], "title": "LLM-Enhanced Reinforcement Learning for Long-Term User Satisfaction in Interactive Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Interactive recommender systems can dynamically adapt to user feedback, but often suffer from content homogeneity and filter bubble effects due to overfitting short-term user preferences. While recent efforts aim to improve content diversity, they predominantly operate in static or one-shot settings, neglecting the long-term evolution of user interests. Reinforcement learning provides a principled framework for optimizing long-term user satisfaction by modeling sequential decision-making processes. However, its application in recommendation is hindered by sparse, long-tailed user-item interactions and limited semantic planning capabilities. In this work, we propose LLM-Enhanced Reinforcement Learning (LERL), a novel hierarchical recommendation framework that integrates the semantic planning power of LLM with the fine-grained adaptability of RL. LERL consists of a high-level LLM-based planner that selects semantically diverse content categories, and a low-level RL policy that recommends personalized items within the selected semantic space. This hierarchical design narrows the action space, enhances planning efficiency, and mitigates overexposure to redundant content. Extensive experiments on real-world datasets demonstrate that LERL significantly improves long-term user satisfaction when compared with state-of-the-art baselines. The implementation of LERL is available at https://anonymous.4open.science/r/code3-18D3/.", "AI": {"tldr": "提出了一种结合大语言模型和强化学习的推荐系统框架（LERL），旨在提高长期用户满意度。", "motivation": "传统的交互式推荐系统存在内容同质化、过滤泡沫等问题，因为过度适应短期偏好。现有研究多关注静态或一次性设置，忽视了用户的长期兴趣变化。通过引入语义规划能力和细粒度自适应能力来优化长期用户满意度。", "method": "LERL框架包括一个高层的大语言模型规划器和低层的强化学习策略，前者选择多样化的语义类别，后者在此空间内推荐个性化项目。这种分层设计缩小了动作空间，提高了计划效率，并减少了重复内容的过度曝光。", "result": "实验证明，LERL在长期用户满意度方面比现有最佳方法有显著改进。", "conclusion": "提出的方法通过结合大语言模型和强化学习，在提高用户长期满意度上取得了成功。"}}
{"id": "2601.19582", "pdf": "https://arxiv.org/pdf/2601.19582", "abs": "https://arxiv.org/abs/2601.19582", "authors": ["Yujin Wang", "Yutong Zheng", "Wenxian Fan", "Tianyi Wang", "Hongqing Chu", "Daxin Tian", "Bingzhao Gao", "Jianqiang Wang", "Hong Chen"], "title": "ScenePilot-Bench: A Large-Scale Dataset and Benchmark for Evaluation of Vision-Language Models in Autonomous Driving", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we introduce ScenePilot-Bench, a large-scale first-person driving benchmark designed to evaluate vision-language models (VLMs) in autonomous driving scenarios. ScenePilot-Bench is built upon ScenePilot-4K, a diverse dataset comprising 3,847 hours of driving videos, annotated with multi-granularity information including scene descriptions, risk assessments, key participant identification, ego trajectories, and camera parameters. The benchmark features a four-axis evaluation suite that assesses VLM capabilities in scene understanding, spatial perception, motion planning, and GPT-Score, with safety-aware metrics and cross-region generalization settings. We benchmark representative VLMs on ScenePilot-Bench, providing empirical analyses that clarify current performance boundaries and identify gaps for driving-oriented reasoning. ScenePilot-Bench offers a comprehensive framework for evaluating and advancing VLMs in safety-critical autonomous driving contexts.", "AI": {"tldr": "介绍了一个评估视觉语言模型在自动驾驶场景中的基准测试集ScenePilot-Bench。", "motivation": "旨在评估和推进视觉语言模型在安全关键性自动驾驶环境下的表现，通过构建一个大规模、多维度的评价体系来识别当前技术限制并指导未来研究方向。", "method": "基于ScenePilot-4K数据集建立基准测试框架，并设计了包括场景理解、空间感知、运动规划和GPT-Score在内的四维评估轴。对代表性的视觉语言模型进行了实验，提供了详细的结果分析。", "result": "展示了现有视觉语言模型在自动驾驶特定任务上的性能边界以及存在的不足之处，指出了未来研究的方向。", "conclusion": "ScenePilot-Bench为评估和改进视觉语言模型的驾驶相关推理能力提供了一个全面的框架，有助于推动该领域的进展。"}}
{"id": "2601.19580", "pdf": "https://arxiv.org/pdf/2601.19580", "abs": "https://arxiv.org/abs/2601.19580", "authors": ["Cuong Le", "Pavlo Melnyk", "Urs Waldmann", "Mårten Wadenbäck", "Bastian Wandt"], "title": "QuaMo: Quaternion Motions for Vision-based 3D Human Kinematics Capture", "categories": ["cs.CV"], "comment": "10 pages, 4 figures, accepted to ICLR 2026", "summary": "Vision-based 3D human motion capture from videos remains a challenge in computer vision. Traditional 3D pose estimation approaches often ignore the temporal consistency between frames, causing implausible and jittery motion. The emerging field of kinematics-based 3D motion capture addresses these issues by estimating the temporal transitioning between poses instead. A major drawback in current kinematics approaches is their reliance on Euler angles. Despite their simplicity, Euler angles suffer from discontinuity that leads to unstable motion reconstructions, especially in online settings where trajectory refinement is unavailable. Contrarily, quaternions have no discontinuity and can produce continuous transitions between poses. In this paper, we propose QuaMo, a novel Quaternion Motions method using quaternion differential equations (QDE) for human kinematics capture. We utilize the state-space model, an effective system for describing real-time kinematics estimations, with quaternion state and the QDE describing quaternion velocity. The corresponding angular acceleration is computed from a meta-PD controller with a novel acceleration enhancement that adaptively regulates the control signals as the human quickly changes to a new pose. Unlike previous work, our QDE is solved under the quaternion unit-sphere constraint that results in more accurate estimations. Experimental results show that our novel formulation of the QDE with acceleration enhancement accurately estimates 3D human kinematics with no discontinuity and minimal implausibilities. QuaMo outperforms comparable state-of-the-art methods on multiple datasets, namely Human3.6M, Fit3D, SportsPose and AIST. The code is available at https://github.com/cuongle1206/QuaMo", "AI": {"tldr": "提出了一种基于四元数微分方程的新型方法QuaMo，用于三维人体运动捕捉。", "motivation": "传统的人体三维姿态估计方法忽视了帧间的时间一致性，导致不连贯和抖动。现有的基于动力学的方法依赖于欧拉角，存在断点问题，影响稳定性。四元数无此类缺陷，能提供连续的姿势过渡。", "method": "提出了一种新的Quaternion Motions方法QuaMo，利用状态空间模型描述实时的动力学估计，并采用四元数微分方程来解决姿态变化中的时间一致性问题。通过自适应调节控制信号的加速增强技术提高估算准确性。", "result": "实验结果表明，该方法在多个数据集上比现有的最先进方法更准确地估计了三维人体动力学，没有不连续性并且减少了不合理现象的发生。", "conclusion": "QuaMo解决了现有基于欧拉角的方法中的断点问题，并通过四元数微分方程和加速增强技术提高了三维人体动力学的估算准确性。"}}
{"id": "2601.19577", "pdf": "https://arxiv.org/pdf/2601.19577", "abs": "https://arxiv.org/abs/2601.19577", "authors": ["Ronglai Zuo", "Rolandos Alexandros Potamias", "Qi Sun", "Evangelos Ververas", "Jiankang Deng", "Stefanos Zafeiriou"], "title": "MaDiS: Taming Masked Diffusion Language Models for Sign Language Generation", "categories": ["cs.CV"], "comment": null, "summary": "Sign language generation (SLG) aims to translate written texts into expressive sign motions, bridging communication barriers for the Deaf and Hard-of-Hearing communities. Recent studies formulate SLG within the language modeling framework using autoregressive language models, which suffer from unidirectional context modeling and slow token-by-token inference. To address these limitations, we present MaDiS, a masked-diffusion-based language model for SLG that captures bidirectional dependencies and supports efficient parallel multi-token generation. We further introduce a tri-level cross-modal pretraining scheme that jointly learns from token-, latent-, and 3D physical-space objectives, leading to richer and more grounded sign representations. To accelerate model convergence in the fine-tuning stage, we design a novel unmasking strategy with temporal checkpoints, reducing the combinatorial complexity of unmasking orders by over $10^{41}$ times. In addition, a mixture-of-parts embedding layer is developed to effectively fuse information stored in different part-wise sign tokens through learnable gates and well-optimized codebooks. Extensive experiments on CSL-Daily, Phoenix-2014T, and How2Sign demonstrate that MaDiS achieves superior performance across multiple metrics, including DTW error and two newly introduced metrics, SiBLEU and SiCLIP, while reducing inference latency by nearly 30%. Code and models will be released on our project page.", "AI": {"tldr": "本文提出了MaDiS，一种用于手语生成的掩码扩散语言模型，该模型捕捉双向依赖关系并支持高效的多令牌平行生成。", "motivation": "为了克服现有自回归语言模型在单向上下文建模和逐令牌推理速度慢的问题，文章提出了一种新的方法来改善手语生成系统的性能。", "method": "MaDiS采用了掩码扩散技术，并引入了三级跨模式预训练方案。通过设计一个新颖的解码策略以及混合部分嵌入层，提高了模型的收敛性和生成效果。", "result": "实验结果表明，在多种评价指标下（如DTW误差、SiBLEU和SiCLIP），MaDiS均取得了优于现有方法的表现，并将推理延迟降低了近30%。", "conclusion": "该工作通过提出新的掩码扩散模型MaDiS，解决了手语生成中的双向依赖问题及效率瓶颈，显著提升了生成质量与速度。"}}
{"id": "2601.19575", "pdf": "https://arxiv.org/pdf/2601.19575", "abs": "https://arxiv.org/abs/2601.19575", "authors": ["Luisa Jansen", "Tim Ulmann", "Robine Jordi", "Malte Elson"], "title": "Putting Privacy to the Test: Introducing Red Teaming for Research Data Anonymization", "categories": ["cs.HC"], "comment": null, "summary": "Recently, the data protection practices of researchers in human-computer interaction and elsewhere have gained attention. Initial results suggest that researchers struggle with anonymization, partly due to a lack of clear, actionable guidance. In this work, we propose simulating re-identification attacks using the approach of red teaming versus blue teaming: a technique commonly employed in security testing, where one team tries to re-identify data, and the other team tries to prevent it. We discuss our experience applying this method to data collected in a mixed-methods study in human-centered privacy. We present usable materials for researchers to apply red teaming when anonymizing and publishing their studies' data.", "AI": {"tldr": "本文提出了一种使用红队和蓝队模拟重识别攻击的方法，以评估研究数据匿名化的效果。", "motivation": "研究人员在处理数据保护时面临挑战，尤其是关于如何有效地进行匿名化的指导不足。", "method": "采用红队对抗蓝队的策略来测试匿名化过程的有效性。一个团队尝试重新识别数据（红队），另一个团队试图阻止这种重识别（蓝队）。这种方法被应用于一个以人本为中心的研究项目中。", "result": "提供了可用于其他研究人员在发布研究数据之前进行匿名化的材料和指南。", "conclusion": "通过模拟攻击来测试和改进匿名化过程可以增强数据保护的实践。"}}
{"id": "2601.19568", "pdf": "https://arxiv.org/pdf/2601.19568", "abs": "https://arxiv.org/abs/2601.19568", "authors": ["Ke Xu", "Siyang Xiao", "Ming Liang", "Yichen Yu", "Zhixiang Wang", "Jingxuan Xu", "Dajun Chen", "Wei Jiang", "Yong Li"], "title": "Learning Adaptive Parallel Execution for Efficient Code Localization", "categories": ["cs.AI", "cs.SE"], "comment": "13 pages, 4 figures", "summary": "Code localization constitutes a key bottleneck in automated software development pipelines. While concurrent tool execution can enhance discovery speed, current agents demonstrate a 34.9\\% redundant invocation rate, which negates parallelism benefits. We propose \\textbf{FuseSearch}, reformulating parallel code localization as a \\textbf{joint quality-efficiency optimization} task. Through defining \\textbf{tool efficiency} -- the ratio of unique information gain to invocation count -- we utilize a two-phase SFT and RL training approach for learning adaptive parallel strategies. Different from fixed-breadth approaches, FuseSearch dynamically modulates search breadth according to task context, evolving from exploration phases to refinement stages. Evaluated on SWE-bench Verified, FuseSearch-4B achieves SOTA-level performance (84.7\\% file-level and 56.4\\% function-level $F_1$ scores) with 93.6\\% speedup, utilizing 67.7\\% fewer turns and 68.9\\% fewer tokens. Results indicate that efficiency-aware training naturally improves quality through eliminating noisy redundant signals, enabling high-performance cost-effective localization agents.", "AI": {"tldr": "论文提出了FuseSearch，一种通过动态调整搜索广度来优化并行代码定位效率和质量的方法。", "motivation": "当前的并行化工具执行存在大量冗余调用，影响了自动化软件开发管道中的代码定位速度与效果。", "method": "通过定义工具效率（独特信息增益除以调用次数）以及采用两阶段SFT和RL训练方法，FuseSearch实现了自适应并行策略学习。", "result": "在SWE-bench Verified数据集上，FuseSearch-4B达到了顶级性能（84.7%文件级和56.4%函数级F1得分），并且比现有最佳技术快93.6%，减少67.7%的调用次数和68.9%的令牌。", "conclusion": "效率感知训练自然地提高了质量，通过消除冗余信号，在保证性能的同时降低了成本。"}}
{"id": "2601.19562", "pdf": "https://arxiv.org/pdf/2601.19562", "abs": "https://arxiv.org/abs/2601.19562", "authors": ["Timothée Anne", "Noah Syrkis", "Meriem Elhosni", "Florian Turati", "Alexandre Manai", "Franck Legendre", "Alain Jaquier", "Sebastian Risi"], "title": "Tournament Informed Adversarial Quality Diversity", "categories": ["cs.NE"], "comment": "Submitted for review at GECCO '26", "summary": "Quality diversity (QD) is a branch of evolutionary computation that seeks high-quality and behaviorally diverse solutions to a problem. While adversarial problems are common, classical QD cannot be easily applied to them, as both the fitness and the behavior depend on the opposing solutions. Recently, Generational Adversarial MAP-Elites (GAME) has been proposed to coevolve both sides of an adversarial problem by alternating the execution of a multi-task QD algorithm against previous elites, called tasks. The original algorithm selects new tasks based on a behavioral criterion, which may lead to undesired dynamics due to inter-side dependencies. In addition, comparing sets of solutions cannot be done directly using classical QD measures due to side dependencies. In this paper, we (1) use an inter-variants tournament to compare the sets of solutions, ensuring a fair comparison, with 6 measures of quality and diversity, and (2) propose two tournament-informed task selection methods to promote higher quality and diversity at each generation. We evaluate the variants across three adversarial problems: Pong, a Cat-and-mouse game, and a Pursuers-and-evaders game. We show that the tournament-informed task selection method leads to higher adversarial quality and diversity. We hope that this work will help further advance adversarial quality diversity. Code, videos, and supplementary material are available at https://github.com/Timothee-ANNE/GAME_tournament_informed.", "AI": {"tldr": "本文提出了一种基于锦标赛的任务选择方法，用于提高对抗性问题中质量多样性算法的表现。", "motivation": "传统的QD算法难以直接应用于对抗性问题，因为适应度和行为依赖于对立的解决方案。因此需要一种新的方法来更好地解决这些问题。", "method": "该论文使用了一种基于锦标赛的任务选择机制，并提出了两种任务选择方法以促进每一代中的更高质量和多样性。", "result": "通过三种对抗性问题（Pong、猫鼠游戏和追逃者游戏）的评估，证明了所提的方法能提高质量与多样性的表现。", "conclusion": "该研究有助于推进对抗性质量多样性的进一步发展。"}}
{"id": "2601.19561", "pdf": "https://arxiv.org/pdf/2601.19561", "abs": "https://arxiv.org/abs/2601.19561", "authors": ["Dayoung Kang", "JongWon Kim", "Jiho Park", "Keonseock Lee", "Ji-Woong Choi", "Jinhyun So"], "title": "AROMMA: Unifying Olfactory Embeddings for Single Molecules and Mixtures", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Public olfaction datasets are small and fragmented across single molecules and mixtures, limiting learning of generalizable odor representations. Recent works either learn single-molecule embeddings or address mixtures via similarity or pairwise label prediction, leaving representations separate and unaligned. In this work, we propose AROMMA, a framework that learns a unified embedding space for single molecules and two-molecule mixtures. Each molecule is encoded by a chemical foundation model and the mixtures are composed by an attention-based aggregator, ensuring both permutation invariance and asymmetric molecular interactions. We further align odor descriptor sets using knowledge distillation and class-aware pseudo-labeling to enrich missing mixture annotations. AROMMA achieves state-of-the-art performance in both single-molecule and molecule-pair datasets, with up to 19.1% AUROC improvement, demonstrating a robust generalization in two domains.", "AI": {"tldr": "提出AROMMA框架，统一学习单分子和两分子混合物的嗅觉表示", "motivation": "现有公开嗅觉数据集小且碎片化，阻碍了通用性气味表征的学习。当前研究要么单独学习单分子嵌入，要么通过相似度或成对标签预测处理混合物，导致两者之间没有统一性和一致性。", "method": "利用化学基础模型编码每个分子，并使用注意力聚合器组合混合物，确保排列不变性和不对称的分子相互作用。通过知识蒸馏和类感知伪标记来对齐气味描述符集以丰富缺失的混合注释。", "result": "AROMMA在单分子和分子对数据集中均达到最先进的性能，AUROC提高最多达19.1％，展示了跨两个领域的强大泛化能力。", "conclusion": "通过统一学习嗅觉表示，AROMMA为处理单分子和混合物提供了有效的解决方案。"}}
{"id": "2601.19557", "pdf": "https://arxiv.org/pdf/2601.19557", "abs": "https://arxiv.org/abs/2601.19557", "authors": ["Riccardo Giubilato", "Marcus Gerhard Müller", "Marco Sewtz", "Laura Alejandra Encinar Gonzalez", "John Folkesson", "Rudolph Triebel"], "title": "The S3LI Vulcano Dataset: A Dataset for Multi-Modal SLAM in Unstructured Planetary Environments", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted submission to the 2026 IEEE Aerospace Conference", "summary": "We release the S3LI Vulcano dataset, a multi-modal dataset towards development and benchmarking of Simultaneous Localization and Mapping (SLAM) and place recognition algorithms that rely on visual and LiDAR modalities. Several sequences are recorded on the volcanic island of Vulcano, from the Aeolian Islands in Sicily, Italy. The sequences provide users with data from a variety of environments, textures and terrains, including basaltic or iron-rich rocks, geological formations from old lava channels, as well as dry vegetation and water. The data (rmc.dlr.de/s3li_dataset) is accompanied by an open source toolkit (github.com/DLR-RM/s3li-toolkit) providing tools for generating ground truth poses as well as preparation of labelled samples for place recognition tasks.", "AI": {"tldr": "发布了一个用于开发和基准测试多模态SLAM和位置识别算法的数据集。", "motivation": "为解决在复杂地质环境下，基于视觉和激光雷达数据的同步定位与地图构建（SLAM）及位置识别问题提供基础数据支持。", "method": "记录了意大利维苏威岛上的多种环境、纹理和地形下的多模态传感器数据，并提供了生成地面真实姿势以及用于位置识别任务的数据准备工具。", "result": "创建了一个包含丰富地质特征的多模态数据集，以供研究使用。", "conclusion": "提出的S3LI Vulcano数据集为开发有效的SLAM和位置识别算法提供了一种新的资源。"}}
{"id": "2601.19551", "pdf": "https://arxiv.org/pdf/2601.19551", "abs": "https://arxiv.org/abs/2601.19551", "authors": ["Geunhyeok Yu", "Hyoseok Hwang"], "title": "Scale-Consistent State-Space Dynamics via Fractal of Stationary Transformations", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages (excluding 2 pages of references), 3 tables, 2 figures. Appendix: 4 pages", "summary": "Recent deep learning models increasingly rely on depth without structural guarantees on the validity of intermediate representations, rendering early stopping and adaptive computation ill-posed. We address this limitation by formulating a structural requirement for state-space model's scale-consistent latent dynamics across iterative refinement, and derive Fractal of Stationary Transformations (FROST), which enforces a self-similar representation manifold through a fractal inductive bias. Under this geometry, intermediate states correspond to different resolutions of a shared representation, and we provide a geometric analysis establishing contraction and stable convergence across iterations. As a consequence of this scale-consistent structure, halting naturally admits a ranking-based formulation driven by intrinsic feature quality rather than extrinsic objectives. Controlled experiments on ImageNet-100 empirically verify the predicted scale-consistent behavior, showing that adaptive efficiency emerges from the aligned latent geometry.", "AI": {"tldr": "通过引入自相似表示流形的几何结构，提出了Fractal of Stationary Transformations (FROST)，以确保状态空间模型在迭代细化中的尺度一致性。", "motivation": "解决了深度学习模型依赖于深层次而缺乏中间表示有效性的结构性保证的问题，使得提前停止和自适应计算变得困难。文章旨在通过结构化要求来解决这一问题。", "method": "提出了Fractal of Stationary Transformations (FROST)，它在每个迭代中维护一个共享的表示流形，并确保这些状态是不同分辨率下的自相似表达。", "result": "实验结果验证了所提出的模型具有尺度一致性的行为，展示了从对齐的潜在几何结构中出现的自适应效率。", "conclusion": "通过引入FROST，使得在深度学习网络中的中间层表示更加稳定和可预测，提高了模型的灵活性和效率。"}}
{"id": "2601.19540", "pdf": "https://arxiv.org/pdf/2601.19540", "abs": "https://arxiv.org/abs/2601.19540", "authors": ["Yuansong Xu", "Yichao Zhu", "Haokai Wang", "Yuchen Wu", "Yang Ouyang", "Hanlu Li", "Wenzhe Zhou", "Xinyu Liu", "Chang Jiang", "Quan Li"], "title": "\"Do I Trust the AI?\" Towards Trustworthy AI-Assisted Diagnosis: Understanding User Perception in LLM-Supported Reasoning", "categories": ["cs.HC"], "comment": "Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI'26), April 13--17, 2026, Barcelona, Spain", "summary": "Large language models (LLMs) have shown considerable potential in supporting medical diagnosis. However, their effective integration into clinical workflows is hindered by physicians' difficulties in perceiving and trusting LLM capabilities, which often results in miscalibrated trust. Existing model evaluations primarily emphasize standardized benchmarks and predefined tasks, offering limited insights into clinical reasoning practices. Moreover, research on human-AI collaboration has rarely examined physicians' perceptions of LLMs' clinical reasoning capability. In this work, we investigate how physicians perceive LLMs' capabilities in the clinical reasoning process. We designed clinical cases, collected the corresponding analyses, and obtained evaluations from physicians (N=37) to quantitatively represent their perceived LLM diagnostic capabilities. By comparing the perceived evaluations with benchmark performance, our study highlights the aspects of clinical reasoning that physicians value and underscores the limitations of benchmark-based evaluation. We further discuss the implications of opportunities for enhancing trustworthy collaboration between physicians and LLMs in LLM-supported clinical reasoning.", "AI": {"tldr": "研究探讨了医生对大型语言模型在临床诊断中的感知与信任度，通过设计案例和收集评价来量化这一感知。", "motivation": "大型语言模型在支持医学诊断方面有巨大潜力，但其有效融入医疗流程受到医生对其能力认知不足的影响，现有评估主要集中在标准化基准任务上，未能充分反映临床实践。该研究旨在填补这一空白。", "method": "设计了临床案例，收集相应分析，并从37名医生那里获取评价以量化对LLM诊断能力的感知。通过对比感知与基准性能来探讨临床推理的关键方面及模型评估局限性。", "result": "研究表明，医生重视某些特定方面的临床推理能力，同时指出了基于基准测试评估方法的不足之处。", "conclusion": "该研究强调了在大型语言模型支持下的信任合作的重要性，并提出了增强人类和AI之间协作的方法。"}}
{"id": "2601.19536", "pdf": "https://arxiv.org/pdf/2601.19536", "abs": "https://arxiv.org/abs/2601.19536", "authors": ["Hongji Liu", "Linwei Zheng", "Yongjian Li", "Mingkai Tang", "Xiaoyang Yan", "Ming Liu", "Jun Ma"], "title": "Enhancing Inverse Perspective Mapping for Automatic Vectorized Road Map Generation", "categories": ["cs.RO"], "comment": null, "summary": "In this study, we present a low-cost and unified framework for vectorized road mapping leveraging enhanced inverse perspective mapping (IPM). In this framework, Catmull-Rom splines are utilized to characterize lane lines, and all the other ground markings are depicted using polygons uniformly. The results from instance segmentation serve as references to refine the three-dimensional position of spline control points and polygon corner points. In conjunction with this process, the homography matrix of IPM and vehicle poses are optimized simultaneously. Our proposed framework significantly reduces the mapping errors associated with IPM. It also improves the accuracy of the initial IPM homography matrix and the predicted vehicle poses. Furthermore, it addresses the limitations imposed by the coplanarity assumption in IPM. These enhancements enable IPM to be effectively applied to vectorized road mapping, which serves a cost-effective solution with enhanced accuracy. In addition, our framework generalizes road map elements to include all common ground markings and lane lines. The proposed framework is evaluated in two different practical scenarios, and the test results show that our method can automatically generate high-precision maps with near-centimeter-level accuracy. Importantly, the optimized IPM matrix achieves an accuracy comparable to that of manual calibration, while the accuracy of vehicle poses is also significantly improved.", "AI": {"tldr": "本文提出了一种利用增强逆透视映射生成矢量化道路地图的低成本统一框架。", "motivation": "为了降低矢量化道路制图中的逆透视映射误差，提高初始逆透视映射矩阵和预测车辆姿态的准确性，并克服IPM中共面假设的局限性，本文提出了一种新的解决方案。", "method": "该研究利用Catmull-Rom样条来表征车道线，并通过实例分割结果优化三維位置点。同时改进了IPM的单应矩阵和车辆姿态，并将道路元素泛化为所有常见的地面标记和车道线。", "result": "实验在两个不同的实际场景中进行，结果显示该方法能够自动生成高精度地图，精确度接近厘米级。此外，优化后的逆透视映射矩阵准确度可与手动校准相比拟，车辆姿态的准确性也显著提高。", "conclusion": "所提出的框架通过改进逆透视映射技术，实现了低成本、高精度的道路矢量化制图，具有广泛的应用前景和实用价值。"}}
{"id": "2601.19533", "pdf": "https://arxiv.org/pdf/2601.19533", "abs": "https://arxiv.org/abs/2601.19533", "authors": ["Tianhua Li", "Chenda Li", "Wei Wang", "Xin Zhou", "Xihui Chen", "Jianqing Gao", "Yanmin Qian"], "title": "SLM-SS: Speech Language Model for Generative Speech Separation", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Speech separation (SS) has advanced significantly with neural network-based methods, showing improved performance on signal-level metrics. However, these methods often struggle to maintain speech intelligibility in the separated signals, which can negatively affect the performance of downstream tasks such as speech recognition. In this work, we propose SLM-SS, a novel approach that applies speech language models to SS, aiming to enhance the intelligibility and coherence of the separated signals. We frame SS as discrete multi-codebook sequence generation, using Encoder-Decoder models to map quantized speech mixtures to target tokens. In addition to the autoregressive modeling strategy, we introduce a non-autoregressive model to improve decoding efficiency for residual tokens. Experimental results on the LibriMix dataset demonstrate that our approach shows significantly better preservation of speech intelligibility, leading to improved linguistic consistency in a variety of downstream tasks compared to existing approaches.", "AI": {"tldr": "提出了一种新型的基于语言模型的语音分离方法SLM-SS，旨在提高分离信号的语言一致性和可懂度。", "motivation": "现有的神经网络方法在语音分离中虽然改善了信号级指标，但往往难以保持分离信号的言语清晰度，从而影响下游任务如语音识别的表现。因此，研究提出了一种应用语言模型的方法来解决这一问题。", "method": "通过将语音分离视为离散多码本序列生成问题，并使用编码器-解码器模型映射量化后的混合信号到目标标记，同时引入非自回归模型提高残余令牌的解码效率。", "result": "在LibriMix数据集上的实验表明，该方法显著提高了言语清晰度和语言一致性，在各种下游任务中优于现有方法的表现。", "conclusion": "SLM-SS通过应用语言模型改善了语音分离后的信号质量，并提升了其在多种应用场景中的表现。"}}
{"id": "2601.19532", "pdf": "https://arxiv.org/pdf/2601.19532", "abs": "https://arxiv.org/abs/2601.19532", "authors": ["Marthe Ballon", "Andres Algaba", "Brecht Verbeken", "Vincent Ginis"], "title": "Benchmarks Saturate When The Model Gets Smarter Than The Judge", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "17 pages, 10 figures, 3 tables", "summary": "Benchmarks are important tools to track progress in the development of Large Language Models (LLMs), yet inaccuracies in datasets and evaluation methods consistently undermine their effectiveness. Here, we present Omni-MATH-2, a manually revised version of the Omni-MATH dataset comprising a clean, exact-answer subset ($n{=}4181$) and a tagged, non-standard subset ($n{=}247$). Each problem was audited to ensure LaTeX compilability, solvability and verifiability, which involved adding missing figures or information, labeling problems requiring a proof, estimation or image, and removing clutter. This process significantly reduces dataset-induced noise, thereby providing a more precise assessment of model performance. The annotated dataset also allows us to evaluate judge-induced noise by comparing GPT-5 mini with the original Omni-Judge, revealing substantial discrepancies between judges on both the clean and tagged problem subsets. Expert annotations reveal that Omni-Judge is wrong in $96.4\\%$ of the judge disagreements, indicating its inability to differentiate between models' abilities, even well before saturation of the benchmark occurs. As problems become more challenging, we find that increasingly competent judges become essential in order to prevent judge errors from masking genuine differences between models. Finally, neither judge identifies the present failure modes for the subset of tagged problems, demonstrating that dataset quality and judge reliability are both critical to develop accurate benchmarks of model performance.", "AI": {"tldr": "本文介绍了Omni-MATH-2数据集，通过改进原始问题和评估方法来提高大型语言模型的性能评估准确性。", "motivation": "现有基准测试常因数据集不准确或评价方式存在问题而影响了对大型语言模型（LLM）进展的有效跟踪。为此，文章提出改善这些问题。", "method": "手动修订Omni-MATH数据集，创建包含清洁且可验证问题和标记非标准问题的子集，并通过专家审核确保问题质量。", "result": "新的评估发现原始裁判存在大量错误（96.4%），表明在模型性能差异显现前，裁判准确性已影响了评价结果。", "conclusion": "提高数据质量和选择更准确的评判者对于开发能够真实反映大型语言模型性能的基准至关重要。"}}
{"id": "2601.19529", "pdf": "https://arxiv.org/pdf/2601.19529", "abs": "https://arxiv.org/abs/2601.19529", "authors": ["Jie Gu", "Yirui Sun", "Zhihao Xia", "Tin Lun Lam", "Chunxu Tian", "Dan Zhang"], "title": "Rhombot: Rhombus-shaped Modular Robots for Stable, Medium-Independent Reconfiguration Motion", "categories": ["cs.RO"], "comment": null, "summary": "In this paper, we present Rhombot, a novel deformable planar lattice modular self-reconfigurable robot (MSRR) with a rhombus shaped module. Each module consists of a parallelogram skeleton with a single centrally mounted actuator that enables folding and unfolding along its diagonal. The core design philosophy is to achieve essential MSRR functionalities such as morphing, docking, and locomotion with minimal control complexity. This enables a continuous and stable reconfiguration process that is independent of the surrounding medium, allowing the system to reliably form various configurations in diverse environments. To leverage the unique kinematics of Rhombot, we introduce morphpivoting, a novel motion primitive for reconfiguration that differs from advanced MSRR systems, and propose a strategy for its continuous execution. Finally, a series of physical experiments validate the module's stable reconfiguration ability, as well as its positional and docking accuracy.", "AI": {"tldr": "本文提出了一种名为Rhombot的新型变形平面格子模块化自重构机器人，具有菱形形状的模块，并通过实验验证其稳定重构能力和位置对接准确性。", "motivation": "该设计旨在实现最小控制复杂度下，具备模块化自重构机器人的基本功能（如形态变化、对接和运动），并在各种环境中实现连续且稳定的重构过程。", "method": "每个模块由一个平行四边形骨架组成，并配备有一个中心安装的执行器。通过提出新颖的动作原语morphpivoting及其实现策略，实现了机器人在不同介质中的稳定重构能力。", "result": "一系列物理实验验证了Rhombot模块具有稳定的重配置能力和位置对接准确性。", "conclusion": "本文提出的Rhombot设计证明，在简化控制复杂度的同时，仍能够实现高效和可靠的自重构行为。"}}
{"id": "2601.19527", "pdf": "https://arxiv.org/pdf/2601.19527", "abs": "https://arxiv.org/abs/2601.19527", "authors": ["Temirbolat Maratuly", "Pakizar Shamoi", "Timur Samigulin"], "title": "Fuzzy expert system for the process of collecting and purifying acidic water: a digital twin approach", "categories": ["cs.AI"], "comment": null, "summary": "Purifying sour water is essential for reducing emissions, minimizing corrosion risks, enabling the reuse of treated water in industrial or domestic applications, and ultimately lowering operational costs. Moreover, automating the purification process helps reduce the risk of worker harm by limiting human involvement. Crude oil contains acidic components such as hydrogen sulfide, carbon dioxide, and other chemical compounds. During processing, these substances are partially released into sour water. If not properly treated, sour water poses serious environmental threats and accelerates the corrosion of pipelines and equipment. This paper presents a fuzzy expert system, combined with a custom-generated digital twin, developed from a documented industrial process to maintain key parameters at desired levels by mimicking human reasoning. The control strategy is designed to be simple and intuitive, allowing junior or non-expert personnel to interact with the system effectively. The digital twin was developed using Honeywell UniSim Design R492 to simulate real industrial behavior accurately. Valve dynamics were modeled through system identification in MATLAB, and real-time data exchange between the simulator and controller was established using OPC DA. The fuzzy controller applies split-range control to two valves and was tested under 21 different initial pressure conditions using five distinct defuzzification strategies, resulting in a total of 105 unique test scenarios. System performance was evaluated using both error-based metrics (MSE, RMSE, MAE, IAE, ISE, ITAE) and dynamic response metrics, including overshoot, undershoot, rise time, fall time, settling time, and steady-state error. A web-based simulation interface was developed in Python using the Streamlit framework. Although demonstrated here for sour water treatment, the proposed fuzzy expert system is general-purpose.", "AI": {"tldr": "本文提出了一种结合模糊专家系统和数字孪生技术的酸性水处理方法，以自动化控制过程，减少环境污染与设备腐蚀风险。", "motivation": "净化酸性水对于降低排放、预防管道及设备腐蚀具有重要意义，并可促进水资源再利用和节约运营成本。通过自动化控制可以有效降低人工干预带来的安全隐患。", "method": "开发了一种基于模糊逻辑的专家控制系统，结合定制生成的数字孪生技术来模拟实际工业过程中的关键参数调整。使用Honeywell UniSim Design进行建模，并采用MATLAB对阀门动态特性进行了系统识别。通过OPC DA实现仿真器与控制器之间的实时数据交换。", "result": "在21种不同的初始压力条件下，应用了五种不同去模糊化策略共测试了105个场景，利用多种误差及动态响应指标评估系统性能。结果显示该控制系统能够有效维持处理过程中的关键参数。", "conclusion": "提出的基于模糊逻辑的专家控制系统在酸性水处理方面表现出良好的效果，并且具有一定的通用性。"}}
{"id": "2601.19526", "pdf": "https://arxiv.org/pdf/2601.19526", "abs": "https://arxiv.org/abs/2601.19526", "authors": ["Fouad Boutaleb", "Emery Pierson", "Mohamed Daoudi", "Clémence Nineuil", "Ali Amad", "Fabien D'Hondt"], "title": "A Non-Invasive 3D Gait Analysis Framework for Quantifying Psychomotor Retardation in Major Depressive Disorder", "categories": ["cs.CV"], "comment": null, "summary": "Predicting the status of Major Depressive Disorder (MDD) from objective, non-invasive methods is an active research field. Yet, extracting automatically objective, interpretable features for a detailed analysis of the patient state remains largely unexplored. Among MDD's symptoms, Psychomotor retardation (PMR) is a core item, yet its clinical assessment remains largely subjective. While 3D motion capture offers an objective alternative, its reliance on specialized hardware often precludes routine clinical use. In this paper, we propose a non-invasive computational framework that transforms monocular RGB video into clinically relevant 3D gait kinematics. Our pipeline uses Gravity-View Coordinates along with a novel trajectory-correction algorithm that leverages the closed-loop topology of our adapted Timed Up and Go (TUG) protocol to mitigate monocular depth errors. This novel pipeline enables the extraction of 297 explicit gait biomechanical biomarkers from a single camera capture. To address the challenges of small clinical datasets, we introduce a stability-based machine learning framework that identifies robust motor signatures while preventing overfitting. Validated on the CALYPSO dataset, our method achieves an 83.3% accuracy in detecting PMR and explains 64% of the variance in overall depression severity (R^2=0.64). Notably, our study reveals a strong link between reduced ankle propulsion and restricted pelvic mobility to the depressive motor phenotype. These results demonstrate that physical movement serves as a robust proxy for the cognitive state, offering a transparent and scalable tool for the objective monitoring of depression in standard clinical environments.", "AI": {"tldr": "提出了一种非侵入性的计算框架，将单目RGB视频转换为临床相关的3D步态运动学。", "motivation": "提取自动化的客观且可解释的特征以详细分析患者的状况仍然是一个未充分探索的研究领域。本文旨在提供一种非侵入性方法来量化主要抑郁障碍中的心理运动迟缓症状，该方法可以广泛应用于常规临床环境中。", "method": "采用单目RGB视频捕捉，并利用重力视图坐标和新型轨迹校正算法结合闭合循环的改进Timed Up and Go协议以减少单目深度误差。从而从一个摄像头捕获中提取297个显式步态生物力学标志物。", "result": "在CALYPSO数据集上验证，该方法实现了83.3%的心理运动迟缓检测准确率，并解释了64%的整体抑郁严重程度的方差（R^2=0.64）。", "conclusion": "研究结果表明，物理移动可以作为认知状态的强大代理，并提供了一个透明且可扩展的工具，在标准临床环境中客观监测抑郁症。"}}
{"id": "2601.19519", "pdf": "https://arxiv.org/pdf/2601.19519", "abs": "https://arxiv.org/abs/2601.19519", "authors": ["Ofir Abramovich", "Ariel Shamir", "Andreas Aristidou"], "title": "Mocap Anywhere: Towards Pairwise-Distance based Motion Capture in the Wild (for the Wild)", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "comment": "14 pages, 15 figures", "summary": "We introduce a novel motion capture system that reconstructs full-body 3D motion using only sparse pairwise distance (PWD) measurements from body-mounted(UWB) sensors. Using time-of-flight ranging between wireless nodes, our method eliminates the need for external cameras, enabling robust operation in uncontrolled and outdoor environments. Unlike traditional optical or inertial systems, our approach is shape-invariant and resilient to environmental constraints such as lighting and magnetic interference. At the core of our system is Wild-Poser (WiP for short), a compact, real-time Transformer-based architecture that directly predicts 3D joint positions from noisy or corrupted PWD measurements, which can later be used for joint rotation reconstruction via learned methods. WiP generalizes across subjects of varying morphologies, including non-human species, without requiring individual body measurements or shape fitting. Operating in real time, WiP achieves low joint position error and demonstrates accurate 3D motion reconstruction for both human and animal subjects in-the-wild. Our empirical analysis highlights its potential for scalable, low-cost, and general purpose motion capture in real-world settings.", "AI": {"tldr": "本文介绍了一种仅使用稀疏体感距离测量的新型动作捕捉系统，该系统适用于无控制和户外环境。", "motivation": "传统光学或惯性动捕系统依赖外部摄像头并且易受光照、磁场干扰等环境因素影响。本文动机在于开发一种不受这些限制的新方法，以实现更广泛的应用场景。", "method": "该系统采用无线节点之间的时间飞行测距技术，并使用实时Transformer架构Wild-Poser（WiP），直接从噪声或损坏的体感距离测量中预测3D关节位置，适用于各种形态主体。", "result": "WiP在不同主体上实现了低关节定位误差和准确的3D动作重建，并展示了其在真实世界中的可扩展性、低成本及通用性的潜力。", "conclusion": "该方法为大规模部署提供了一种新颖且强大的解决方案，在不受控制环境中实现高质量的动作捕捉。"}}
{"id": "2601.19514", "pdf": "https://arxiv.org/pdf/2601.19514", "abs": "https://arxiv.org/abs/2601.19514", "authors": ["Ruiyu Wang", "Zheyu Zhuang", "Danica Kragic", "Florian T. Pokorny"], "title": "PALM: Enhanced Generalizability for Local Visuomotor Policies via Perception Alignment", "categories": ["cs.RO"], "comment": "ef:IEEE Robotics and Automation Letters 2026", "summary": "Generalizing beyond the training domain in image-based behavior cloning remains challenging. Existing methods address individual axes of generalization, workspace shifts, viewpoint changes, and cross-embodiment transfer, yet they are typically developed in isolation and often rely on complex pipelines. We introduce PALM (Perception Alignment for Local Manipulation), which leverages the invariance of local action distributions between out-of-distribution (OOD) and demonstrated domains to address these OOD shifts concurrently, without additional input modalities, model changes, or data collection. PALM modularizes the manipulation policy into coarse global components and a local policy for fine-grained actions. We reduce the discrepancy between in-domain and OOD inputs at the local policy level by enforcing local visual focus and consistent proprioceptive representation, allowing the policy to retrieve invariant local actions under OOD conditions. Experiments show that PALM limits OOD performance drops to 8% in simulation and 24% in the real world, compared to 45% and 77% for baselines.", "AI": {"tldr": "提出PALM（感知对齐的局部操作）方法，解决图像基础的行为克隆中的跨域泛化问题。", "motivation": "当前方法在处理工作空间、视角变化和多主体迁移等问题时通常各自独立且依赖复杂流程。本文旨在通过减少不同环境输入之间的差异来同时解决这些问题，并提升模型跨域泛化能力。", "method": "模块化策略，将其分为粗略的全局组件和精细动作的局部政策。通过强制执行局部视觉关注点并保持一致的本体感觉表示，缩小了域内与跨域输入间的差距。", "result": "实验表明，在模拟环境中PALM将跨域性能下降限制在8%，而在现实世界中则为24%，相较于基线方法分别降低了45%和77%。", "conclusion": "通过局部视觉关注点的强制执行和一致的本体感觉表示，PALM显著提升了图像基础的行为克隆模型的跨域泛化能力。"}}
{"id": "2601.19510", "pdf": "https://arxiv.org/pdf/2601.19510", "abs": "https://arxiv.org/abs/2601.19510", "authors": ["Vitor Gaboardi dos Santos", "Ibrahim Khadraoui", "Ibrahim Farhat", "Hamza Yous", "Samy Teffahi", "Hakim Hacid"], "title": "ALRM: Agentic LLM for Robotic Manipulation", "categories": ["cs.RO", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have recently empowered agentic frameworks to exhibit advanced reasoning and planning capabilities. However, their integration in robotic control pipelines remains limited in two aspects: (1) prior \\ac{llm}-based approaches often lack modular, agentic execution mechanisms, limiting their ability to plan, reflect on outcomes, and revise actions in a closed-loop manner; and (2) existing benchmarks for manipulation tasks focus on low-level control and do not systematically evaluate multistep reasoning and linguistic variation. In this paper, we propose Agentic LLM for Robot Manipulation (ALRM), an LLM-driven agentic framework for robotic manipulation. ALRM integrates policy generation with agentic execution through a ReAct-style reasoning loop, supporting two complementary modes: Code-asPolicy (CaP) for direct executable control code generation, and Tool-as-Policy (TaP) for iterative planning and tool-based action execution. To enable systematic evaluation, we also introduce a novel simulation benchmark comprising 56 tasks across multiple environments, capturing linguistically diverse instructions. Experiments with ten LLMs demonstrate that ALRM provides a scalable, interpretable, and modular approach for bridging natural language reasoning with reliable robotic execution. Results reveal Claude-4.1-Opus as the top closed-source model and Falcon-H1-7B as the top open-source model under CaP.", "AI": {"tldr": "提出了一种基于大语言模型的机器人操作框架ALRM，通过闭环执行机制和多步骤推理评估，解决了现有方法在机器人控制集成中的不足。", "motivation": "当前的大语言模型虽然能在代理框架中展示出高级推理和规划能力，但在机器人控制管道的应用上仍存在局限性：一是缺乏模块化、代理式执行机制；二是现有的操作任务基准主要集中在低级控制上，并不全面评估多步骤推理和语言多样性。因此开发一个能够系统地将自然语言理解和机器人操作相结合的方法是必要的。", "method": "ALRM框架通过引入ReAct风格的推理循环，实现了策略生成与代理式执行的整合。它支持两种互补模式：Code-asPolicy（CaP）用于直接控制代码生成；Tool-as-Policy（TaP）用于迭代规划和工具使用行为的执行。为系统评估引入了包含56个任务的新模拟基准。", "result": "实验表明，ALRM提供了一种可扩展、可解释且模块化的方法来连接自然语言推理与可靠的机器人操作。Claude-4.1-Opus是封闭源代码模型中的最佳选择，而Falcon-H1-7B则是开源模型中的最优解。", "conclusion": "通过引入ALRM框架和新基准测试，证明了将大语言模型用于机器人控制的有效性，并展示了如何克服当前方法在多步骤推理和语言多样性评估方面的局限。"}}
{"id": "2601.19509", "pdf": "https://arxiv.org/pdf/2601.19509", "abs": "https://arxiv.org/abs/2601.19509", "authors": ["Jin Huang", "Zichen Liu", "Haoda Li", "Zhikun Wang", "Ying Chen"], "title": "A DVL Aided Loosely Coupled Inertial Navigation Strategy for AUVs with Attitude Error Modeling and Variance Propagation", "categories": ["cs.RO"], "comment": null, "summary": "In underwater navigation systems, strap-down inertial navigation system/Doppler velocity log (SINS/DVL)-based loosely coupled architectures are widely adopted. Conventional approaches project DVL velocities from the body coordinate system to the navigation coordinate system using SINS-derived attitude; however, accumulated attitude estimation errors introduce biases into velocity projection and degrade navigation performance during long-term operation. To address this issue, two complementary improvements are introduced. First, a vehicle attitude error-aware DVL velocity transformation model is formulated by incorporating attitude error terms into the observation equation to reduce projection-induced velocity bias. Second, a covariance matrix-based variance propagation method is developed to transform DVL measurement uncertainty across coordinate systems, introducing an expectation-based attitude error compensation term to achieve statistically consistent noise modeling. Simulation and field experiment results demonstrate that both improvements individually enhance navigation accuracy and confirm that accumulated attitude errors affect both projected velocity measurements and their associated uncertainty. When jointly applied, long-term error divergence is effectively suppressed. Field experimental results show that the proposed approach achieves a 78.3% improvement in 3D position RMSE and a 71.8% reduction in the maximum component-wise position error compared with the baseline IMU+DVL method, providing a robust solution for improving long-term SINS/DVL navigation performance.", "AI": {"tldr": "研究提出了一种改进的声纳测速仪（DVL）辅助松耦合惯性导航策略，以解决长时间操作中姿态误差累积导致的位置估计偏差问题。", "motivation": "传统的SINS/DVL系统在长时间运行过程中由于姿态估算误差积累会导致速度投影偏置和导航性能下降。为了解决这个问题，引入了两种改进方法。", "method": "首先建立了一种考虑车辆姿态误差的DVL速度转换模型，并将姿态误差项纳入观测方程以减少投影引起的偏差；其次开发了一种基于协方差矩阵的方差传播法，通过引入期望姿态误差补偿项来实现统计一致性的噪声建模。", "result": "模拟和实地实验结果表明，两种改进措施均能提高导航精度。联合应用时能够有效抑制长期累积误差，使三维位置均方根误差（RMSE）比基线IMU+DVL方法提高了78.3%，最大分量位置误差降低了71.8%。", "conclusion": "该方法为提高SINS/DVL系统的长时间导航性能提供了可靠解决方案。"}}
{"id": "2601.19508", "pdf": "https://arxiv.org/pdf/2601.19508", "abs": "https://arxiv.org/abs/2601.19508", "authors": ["Weifeng Liu"], "title": "Rethinking Intelligence: Brain-like Neuron Network", "categories": ["cs.NE"], "comment": null, "summary": "Since their inception, artificial neural networks have relied on manually designed architectures and inductive biases to better adapt to data and tasks. With the rise of deep learning and the expansion of parameter spaces, they have begun to exhibit brain-like functional behaviors. Nevertheless, artificial neural networks remain fundamentally different from biological neural systems in structural organization, learning mechanisms, and evolutionary pathways. From the perspective of neuroscience, we rethink the formation and evolution of intelligence and proposes a new neural network paradigm, Brain-like Neural Network (BNN). We further present the first instantiation of a BNN termed LuminaNet that operates without convolutions or self-attention and is capable of autonomously modifying its architecture. We conduct extensive experiments demonstrating that LuminaNet can achieve self-evolution through dynamic architectural changes. On the CIFAR-10, LuminaNet achieves top-1 accuracy improvements of 11.19%, 5.46% over LeNet-5 and AlexNet, respectively, outperforming MLP-Mixer, ResMLP, and DeiT-Tiny among MLP/ViT architectures. On the TinyStories text generation task, LuminaNet attains a perplexity of 8.4, comparable to a single-layer GPT-2-style Transformer, while reducing computational cost by approximately 25% and peak memory usage by nearly 50%. Code and interactive structures are available at https://github.com/aaroncomo/LuminaNet.", "AI": {"tldr": "提出一种新的脑启发神经网络LuminaNet，它可以在没有卷积或自注意力机制的情况下自主修改其架构并实现自我进化。", "motivation": "人工神经网络与生物神经系统在结构组织、学习机制和演化途径上存在根本差异。从神经科学的角度重新思考智能的形成和发展，并提出一种新的脑启发神经网络（BNN）", "method": "通过动态架构变化，LuminaNet能够自主修改其架构并实现自我进化。", "result": "在CIFAR-10数据集上，与LeNet-5和AlexNet相比，LuminaNet的top-1准确率分别提高了11.19%和5.46%，并在TinyStories文本生成任务中达到了8.4的困惑度，同时降低了约25%的计算成本和近50%的峰值内存使用。", "conclusion": "通过动态架构变化实现自我进化的LuminaNet展示了其在多种任务上的高效性和有效性。"}}
{"id": "2601.19506", "pdf": "https://arxiv.org/pdf/2601.19506", "abs": "https://arxiv.org/abs/2601.19506", "authors": ["Zhengjian Yao", "Jiakui Hu", "Kaiwen Li", "Hangzhou He", "Xinliang Zhang", "Shuang Zeng", "Lei Zhu", "Yanye Lu"], "title": "Bridging Information Asymmetry: A Hierarchical Framework for Deterministic Blind Face Restoration", "categories": ["cs.CV"], "comment": null, "summary": "Blind face restoration remains a persistent challenge due to the inherent ill-posedness of reconstructing holistic structures from severely constrained observations. Current generative approaches, while capable of synthesizing realistic textures, often suffer from information asymmetry -- the intrinsic disparity between the information-sparse low quality inputs and the information-dense high quality outputs. This imbalance leads to a one-to-many mapping, where insufficient constraints result in stochastic uncertainty and hallucinatory artifacts. To bridge this gap, we present \\textbf{Pref-Restore}, a hierarchical framework that integrates discrete semantic logic with continuous texture generation to achieve deterministic, preference-aligned restoration. Our methodology fundamentally addresses this information disparity through two complementary strategies: (1) Augmenting Input Density: We employ an auto-regressive integrator to reformulate textual instructions into dense latent queries, injecting high-level semantic stability to constrain the degraded signals; (2) Pruning Output Distribution: We pioneer the integration of on-policy reinforcement learning directly into the diffusion restoration loop. By transforming human preferences into differentiable constraints, we explicitly penalize stochastic deviations, thereby sharpening the posterior distribution toward the desired high-fidelity outcomes. Extensive experiments demonstrate that Pref-Restore achieves state-of-the-art performance across synthetic and real-world benchmarks. Furthermore, empirical analysis confirms that our preference-aligned strategy significantly reduces solution entropy, establishing a robust pathway toward reliable and deterministic blind restoration.", "AI": {"tldr": "本文提出了一种分层框架Pref-Restore，用于盲面部恢复任务。该框架通过结合离散语义逻辑和连续纹理生成来解决信息不对称问题。", "motivation": "现有的生成方法虽然能够合成逼真的纹理，但因其输入信号稀疏而输出信息丰富之间的不平衡导致了结果的不确定性及幻觉瑕疵。", "method": "1. 增强输入密度：采用自回归整合器将文本指令转换为密集潜在查询；2. 减少输出分布：在扩散恢复循环中引入即时策略强化学习，将人类偏好转化为可微分约束，减少随机偏差，提高结果质量。", "result": "Pref-Restore 在合成和真实世界数据集上的表现优于现有方法。实验表明，该框架能显著降低解空间的熵值。", "conclusion": "通过引入语义逻辑和强化学习来解决信息不对称问题，本文提出的方法为实现可靠且确定性的盲面部恢复提供了新途径。"}}
{"id": "2601.19503", "pdf": "https://arxiv.org/pdf/2601.19503", "abs": "https://arxiv.org/abs/2601.19503", "authors": ["Wei Huang", "Anda Cheng", "Yinggui Wang"], "title": "GradPruner: Gradient-Guided Layer Pruning Enabling Efficient Fine-Tuning and Inference for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ICLR2026", "summary": "Fine-tuning Large Language Models (LLMs) with downstream data is often considered time-consuming and expensive. Structured pruning methods are primarily employed to improve the inference efficiency of pre-trained models. Meanwhile, they often require additional time and memory for training, knowledge distillation, structure search, and other strategies, making efficient model fine-tuning challenging to achieve. To simultaneously enhance the training and inference efficiency of downstream task fine-tuning, we introduce GradPruner, which can prune layers of LLMs guided by gradients in the early stages of fine-tuning. GradPruner uses the cumulative gradients of each parameter during the initial phase of fine-tuning to compute the Initial Gradient Information Accumulation Matrix (IGIA-Matrix) to assess the importance of layers and perform pruning. We sparsify the pruned layers based on the IGIA-Matrix and merge them with the remaining layers. Only elements with the same sign are merged to reduce interference from sign variations. We conducted extensive experiments on two LLMs across eight downstream datasets. Including medical, financial, and general benchmark tasks. The results demonstrate that GradPruner has achieved a parameter reduction of 40% with only a 0.99% decrease in accuracy. Our code is publicly available.", "AI": {"tldr": "GradPruner通过梯度引导的层剪枝方法，提高了LLM在下游任务中的微调和推理效率。", "motivation": "为了减少大型语言模型（LLMs）在下游数据微调过程中的时间和内存消耗，并提高训练及推断效率。", "method": "GradPruner利用早期微调阶段累积的梯度信息构建IGIA矩阵，评估层的重要性并进行剪枝。随后对剪枝后的层基于相同符号合并以减少干扰。", "result": "实验结果显示，在多个数据集上实现了40%参数量削减的同时，仅导致0.99%准确率下降。", "conclusion": "GradPruner有效提高了大型语言模型在下游任务上的微调和推断效率。"}}
{"id": "2601.19502", "pdf": "https://arxiv.org/pdf/2601.19502", "abs": "https://arxiv.org/abs/2601.19502", "authors": ["Shuning Zhang", "Qucheng Zang", "Yongquan `Owen' Hu", "Jiachen Du", "Xueyang Wang", "Yan Kong", "Xinyi Fu", "Suranga Nanayakkara", "Xin Yi", "Hewu Li"], "title": "VisGuardian: A Lightweight Group-based Privacy Control Technique For Front Camera Data From AR Glasses in Home Environments", "categories": ["cs.HC", "cs.CR"], "comment": "To be published in CHI'26: 10.1145/3772318.3790288", "summary": "Always-on sensing of AI applications on AR glasses makes traditional permission techniques ill-suited for context-dependent visual data, especially within home environments. The home presents a highly challenging privacy context due to the high density of sensitive objects, and the frequent presence of non-consenting family members, and the intimate nature of daily routines, making it a critical focus area for scalable privacy control mechanisms. Existing fine-grained controls, while offering nuanced choices, are inefficient for managing multiple private objects. We propose VisGuardian, a fine-grained content-based visual permission technique for AR glasses. VisGuardian features a group-based control mechanism that enables users to efficiently manage permissions for multiple private objects. VisGuardian detects objects using YOLO and adopts a pre-classified schema to group them. By selecting a single object, users can efficiently obscure groups of related objects based on criteria including privacy sensitivity, object category, or spatial proximity. A technical evaluation shows VisGuardian achieves mAP50 of 0.6704 with only 14.0 ms latency and a 1.7% increase in battery consumption per hour. Furthermore, a user study (N=24) comparing VisGuardian to slider-based and object-based baselines found it to be significantly faster for setting permissions and was preferred by users for its efficiency, effectiveness, and ease of use.", "AI": {"tldr": "提出了一种针对AR眼镜在家庭环境中采集的数据进行隐私保护的技术VisGuardian。", "motivation": "为了应对智能设备在家庭环境中的持续监测带来的隐私挑战，开发一种轻量级的基于群体的内容控制技术以满足频繁变化的上下文需求。", "method": "采用YOLO检测物体，并使用预先分类的方法将它们分组。用户可以选择单个对象来高效地隐藏与之相关的多个私密对象。", "result": "VisGuardian实现了0.6704的地图精度，延迟为14.0毫秒，每小时电池消耗增加不到2%。用户研究显示它比其他方法更快速、有效和易于使用。", "conclusion": "VisGuardian提供了一种高效的隐私保护方案，适用于家庭环境中的智能设备数据管理。"}}
{"id": "2601.19499", "pdf": "https://arxiv.org/pdf/2601.19499", "abs": "https://arxiv.org/abs/2601.19499", "authors": ["Mehdi Heydari Shahna", "Seyed Adel Alizadeh Kolagar", "Jouni Mattila"], "title": "Reinforcement Learning Goal-Reaching Control with Guaranteed Lyapunov-Like Stabilizer for Mobile Robots", "categories": ["cs.RO"], "comment": null, "summary": "Reinforcement learning (RL) can be highly effective at learning goal-reaching policies, but it typically does not provide formal guarantees that the goal will always be reached. A common approach to provide formal goal-reaching guarantees is to introduce a shielding mechanism that restricts the agent to actions that satisfy predefined safety constraints. The main challenge here is integrating this mechanism with RL so that learning and exploration remain effective without becoming overly conservative. Hence, this paper proposes an RL-based control framework that provides formal goal-reaching guarantees for wheeled mobile robots operating in unstructured environments. We first design a real-time RL policy with a set of 15 carefully defined reward terms. These rewards encourage the robot to reach both static and dynamic goals while generating sufficiently smooth command signals that comply with predefined safety specifications, which is critical in practice. Second, a Lyapunov-like stabilizer layer is integrated into the benchmark RL framework as a policy supervisor to formally strengthen the goal-reaching control while preserving meaningful exploration of the state action space. The proposed framework is suitable for real-time deployment in challenging environments, as it provides a formal guarantee of convergence to the intended goal states and compensates for uncertainties by generating real-time control signals based on the current state, while respecting real-world motion constraints. The experimental results show that the proposed Lyapunov-like stabilizer consistently improves the benchmark RL policies, boosting the goal-reaching rate from 84.6% to 99.0%, sharply reducing failures, and improving efficiency.", "AI": {"tldr": "提出了一种结合强化学习和Lyapunov类稳定器的控制框架，以保证移动机器人在复杂环境中达到目标的同时保持探索效率。", "motivation": "传统的强化学习虽然能够有效学习到达目标的任务策略，但无法提供正式的目标达成保障。为了克服这一问题并确保实际应用中的安全性与稳定性，论文引入了Lyapunov类稳定器作为政策监督者来增强控制的可靠性。", "method": "首先设计了一套包含15个奖励项的实时强化学习策略以促使机器人有效到达静态和动态目标；接着集成一个Lyapunov类稳定器层来进一步提升目标达成率，同时保持状态-动作空间的有效探索。该框架适用于复杂环境下的实时部署。", "result": "实验结果表明，所提出的Lyapunov类稳定器显著提高了基准强化学习策略的目标达成率，从84.6%增加到99%，大大减少了失败次数并提升了效率。", "conclusion": "通过引入Lyapunov类稳定器层增强了移动机器人的目标到达控制能力，在保证正式收敛性的同时提高了探索效率。"}}
{"id": "2601.19498", "pdf": "https://arxiv.org/pdf/2601.19498", "abs": "https://arxiv.org/abs/2601.19498", "authors": ["Fabian Bongratz", "Yitong Li", "Sama Elbaroudy", "Christian Wachinger"], "title": "Cortex-Grounded Diffusion Models for Brain Image Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "preprint", "summary": "Synthetic neuroimaging data can mitigate critical limitations of real-world datasets, including the scarcity of rare phenotypes, domain shifts across scanners, and insufficient longitudinal coverage. However, existing generative models largely rely on weak conditioning signals, such as labels or text, which lack anatomical grounding and often produce biologically implausible outputs. To this end, we introduce Cor2Vox, a cortex-grounded generative framework for brain magnetic resonance image (MRI) synthesis that ties image generation to continuous structural priors of the cerebral cortex. It leverages high-resolution cortical surfaces to guide a 3D shape-to-image Brownian bridge diffusion process, enabling topologically faithful synthesis and precise control over underlying anatomies. To support the generation of new, realistic brain shapes, we developed a large-scale statistical shape model of cortical morphology derived from over 33,000 UK Biobank scans. We validated the fidelity of Cor2Vox based on traditional image quality metrics, advanced cortical surface reconstruction, and whole-brain segmentation quality, outperforming many baseline methods. Across three applications, namely (i) anatomically consistent synthesis, (ii) simulation of progressive gray matter atrophy, and (iii) harmonization of in-house frontotemporal dementia scans with public datasets, Cor2Vox preserved fine-grained cortical morphology at the sub-voxel level, exhibiting remarkable robustness to variations in cortical geometry and disease phenotype without retraining.", "AI": {"tldr": "本文提出了Cor2Vox，一种基于大脑皮层结构先验的脑部MRI合成框架。", "motivation": "现有的生成模型依赖于弱条件信号，缺乏解剖学基础，并常产生生物学上不可靠的结果。为了克服这些限制，需要一个能够利用大脑皮层结构信息进行指导的生成方法。", "method": "Cor2Vox使用高分辨率的大脑皮层表面引导3D形状到图像布朗桥扩散过程，支持新的、真实的脑形态生成。通过大规模统计形态模型来支持新脑形生成，并验证其合成质量。", "result": "实验结果表明，在传统成像指标和高级皮层表面重建以及全脑分割质量方面优于许多基线方法。在三个应用中展示了出色的保真度，无需重新训练即可适应不同的解剖几何结构和疾病表型。", "conclusion": "Cor2Vox框架通过结合大脑皮层结构先验信息提高了MRI生成的准确性和稳健性，在多个应用场景中表现出优越性能。"}}
{"id": "2601.19496", "pdf": "https://arxiv.org/pdf/2601.19496", "abs": "https://arxiv.org/abs/2601.19496", "authors": ["Jie Gu", "Hongrun Gao", "Zhihao Xia", "Yirun Sun", "Chunxu Tian", "Dan Zhang"], "title": "Self-Reconfiguration Planning for Deformable Quadrilateral Modular Robots", "categories": ["cs.RO"], "comment": null, "summary": "For lattice modular self-reconfigurable robots (MSRRs), maintaining stable connections during reconfiguration is crucial for physical feasibility and deployability. This letter presents a novel self-reconfiguration planning algorithm for deformable quadrilateral MSRRs that guarantees stable connection. The method first constructs feasible connect/disconnect actions using a virtual graph representation, and then organizes these actions into a valid execution sequence through a Dependence-based Reverse Tree (DRTree) that resolves interdependencies. We also prove that reconfiguration sequences satisfying motion characteristics exist for any pair of configurations with seven or more modules (excluding linear topologies). Finally, comparisons with a modified BiRRT algorithm highlight the superior efficiency and stability of our approach, while deployment on a physical robotic platform confirms its practical feasibility.", "AI": {"tldr": "本文提出了一种用于可变形四边形单元模块机器人自重构的算法，该算法保证了连接稳定性。", "motivation": "在格子模组化自重构机器人中，确保重新配置过程中的稳定连接对于物理可行性和部署至关重要。现有方法可能无法同时满足效率和稳定性要求，因此本文研究如何改进这一问题。", "method": "首先通过虚拟图表示法构建可行的连接/断开操作，然后利用依赖树（DRTree）组织这些动作以形成有效的执行序列，并证明对于七模块或更多单元组成的任意配置对存在符合运动特性的重构路径。", "result": "与修改后的BiRRT算法相比，所提出的方法在效率和稳定性方面表现更佳；并通过物理平台验证了其实用性。", "conclusion": "本文提出的自重构规划方法有效解决了变形四边形单元模块机器人中连接稳定性的挑战，并展示了良好的实际应用前景。"}}
{"id": "2601.19494", "pdf": "https://arxiv.org/pdf/2601.19494", "abs": "https://arxiv.org/abs/2601.19494", "authors": ["Lei Zhang", "Yongda Yu", "Minghui Yu", "Xinxin Guo", "Zhengqi Zhuang", "Guoping Rong", "Dong Shao", "Haifeng Shen", "Hongyu Kuang", "Zhengfeng Li", "Boge Wang", "Guoan Zhang", "Bangyu Xiang", "Xiaobing Xu"], "title": "AACR-Bench: Evaluating Automatic Code Review with Holistic Repository-Level Context", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "High-quality evaluation benchmarks are pivotal for deploying Large Language Models (LLMs) in Automated Code Review (ACR). However, existing benchmarks suffer from two critical limitations: first, the lack of multi-language support in repository-level contexts, which restricts the generalizability of evaluation results; second, the reliance on noisy, incomplete ground truth derived from raw Pull Request (PR) comments, which constrains the scope of issue detection. To address these challenges, we introduce AACR-Bench a comprehensive benchmark that provides full cross-file context across multiple programming languages. Unlike traditional datasets, AACR-Bench employs an \"AI-assisted, Expert-verified\" annotation pipeline to uncover latent defects often overlooked in original PRs, resulting in a 285\\% increase in defect coverage. Extensive evaluations of mainstream LLMs on AACR-Bench reveal that previous assessments may have either misjudged or only partially captured model capabilities due to data limitations. Our work establishes a more rigorous standard for ACR evaluation and offers new insights on LLM based ACR, i.e., the granularity/level of context and the choice of retrieval methods significantly impact ACR performance, and this influence varies depending on the LLM, programming language, and the LLM usage paradigm e.g., whether an Agent architecture is employed. The code, data, and other artifacts of our evaluation set are available at https://github.com/alibaba/aacr-bench .", "AI": {"tldr": "本文提出了AACR-Bench，一个全面的评估基准，用于自动代码审查，并提供了跨文件、多语言支持的完整上下文。", "motivation": "现有评估基准缺乏对多个编程语言的支持和完整的缺陷检测能力，导致评价结果有限。为了解决这些问题，作者开发了AACR-Bench以提供更准确、全面的模型性能评估。", "method": "AACR-Bench采用“AI辅助、专家验证”的注释流程，从原始拉取请求中发现潜在的缺陷，涵盖20多种编程语言和13个开源项目。通过使用这种新方法来增强数据质量和多样性。", "result": "对主流大语言模型在AACR-Bench上的评估显示，这些模型的能力可能因数据限制而被低估或误解。此外，实验表明上下文的粒度、检索方法的选择以及是否采用代理架构都显著影响自动代码审查的效果。", "conclusion": "本文通过引入AACR-Bench建立了更严格的标准来评估自动代码审查，并揭示了LLM在不同编程语言和使用模式下的性能差异，为未来研究提供了新视角。"}}
{"id": "2601.19489", "pdf": "https://arxiv.org/pdf/2601.19489", "abs": "https://arxiv.org/abs/2601.19489", "authors": ["Ziyu Zhang", "Tianle Liu", "Diantao Tu", "Shuhan Shen"], "title": "Fast Converging 3D Gaussian Splatting for 1-Minute Reconstruction", "categories": ["cs.CV"], "comment": "First Rank of SIGGRAPH Asia 2025 3DGS Challenge. Code available at", "summary": "We present a fast 3DGS reconstruction pipeline designed to converge within one minute, developed for the SIGGRAPH Asia 3DGS Fast Reconstruction Challenge. The challenge consists of an initial round using SLAM-generated camera poses (with noisy trajectories) and a final round using COLMAP poses (highly accurate). To robustly handle these heterogeneous settings, we develop a two-stage solution. In the first round, we use reverse per-Gaussian parallel optimization and compact forward splatting based on Taming-GS and Speedy-splat, load-balanced tiling, an anchor-based Neural-Gaussian representation enabling rapid convergence with fewer learnable parameters, initialization from monocular depth and partially from feed-forward 3DGS models, and a global pose refinement module for noisy SLAM trajectories. In the final round, the accurate COLMAP poses change the optimization landscape; we disable pose refinement, revert from Neural-Gaussians back to standard 3DGS to eliminate MLP inference overhead, introduce multi-view consistency-guided Gaussian splitting inspired by Fast-GS, and introduce a depth estimator to supervise the rendered depth. Together, these techniques enable high-fidelity reconstruction under a strict one-minute budget. Our method achieved the top performance with a PSNR of 28.43 and ranked first in the competition.", "AI": {"tldr": "论文提出了一种快速收敛的三维高斯点云重建流水线，能够在一分钟内完成高质量的重建。", "motivation": "为了在具有噪声轨迹和准确COLMAP位姿的不同设置下实现稳健而快速的3D重建，作者开发了针对SIGGRAPH Asia挑战赛设计的新方法。", "method": "通过逆向高斯并行优化、紧凑前向点云生成技术、基于锚节点的神经网络表示以及全局姿态细化模块，在嘈杂的SLAM位姿中实现快速收敛。在准确COLMAP位姿下，移除姿态调整步骤，并引入视图一致性引导的高斯分裂和深度估计器来提升重建质量。", "result": "该方法在挑战赛中获得第一的成绩，PSNR为28.43分，在严格的一分钟时间限制内达到了高质量的三维重建效果。", "conclusion": "论文展示了如何通过精心设计的方法实现快速收敛与高保真度的3D重建，并成功应用于SIGGRAPH Asia挑战赛。"}}
{"id": "2601.19488", "pdf": "https://arxiv.org/pdf/2601.19488", "abs": "https://arxiv.org/abs/2601.19488", "authors": ["Yizhao Han", "Tianxing Shi", "Zhao Wang", "Zifan Xu", "Zhiyuan Pu", "Mingxiao Li", "Qian Zhang", "Wei Yin", "Xiao-Xiao Long"], "title": "Entropy-Guided k-Guard Sampling for Long-Horizon Autoregressive Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Autoregressive (AR) architectures have achieved significant successes in LLMs, inspiring explorations for video generation. In LLMs, top-p/top-k sampling strategies work exceptionally well: language tokens have high semantic density and low redundancy, so a fixed size of token candidates already strikes a balance between semantic accuracy and generation diversity. In contrast, video tokens have low semantic density and high spatio-temporal redundancy. This mismatch makes static top-k/top-p strategies ineffective for video decoders: they either introduce unnecessary randomness for low-uncertainty regions (static backgrounds) or get stuck in early errors for high-uncertainty regions (foreground objects). Prediction errors will accumulate as more frames are generated and eventually severely degrade long-horizon quality. To address this, we propose Entropy-Guided k-Guard (ENkG) sampling, a simple yet effective strategy that adapts sampling to token-wise dispersion, quantified by the entropy of each token's predicted distribution. ENkG uses adaptive token candidate sizes: for low-entropy regions, it employs fewer candidates to suppress redundant noise and preserve structural integrity; for high-entropy regions, it uses more candidates to mitigate error compounding. ENkG is model-agnostic, training-free, and adds negligible overhead. Experiments demonstrate consistent improvements in perceptual quality and structural stability compared to static top-k/top-p strategies.", "AI": {"tldr": "本文提出了一种针对视频生成的适应性采样策略Entropy-Guided k-Guard (ENkG)，解决了传统固定大小采样在处理视频时的问题。", "motivation": "传统的静态top-k/top-p采样策略无法有效应对视频中的低语义密度和高时空冗余，导致视频生成过程中错误累积，影响长期质量。", "method": "提出了基于熵导向的k-Guard (ENkG) 采样方法，该方法根据每个令牌预测分布的熵动态调整候选大小。在低熵区域使用较少的候选以减少冗余噪声，在高熵区域增加候选数量以减轻错误累积效应。", "result": "实验结果表明，相较于传统静态top-k/top-p策略，ENkG在感知质量和结构稳定性方面有显著改进。", "conclusion": "ENkG是一种简单而有效的适应性采样方法，可以提高视频生成的质量和长期稳定性能。"}}
{"id": "2601.19487", "pdf": "https://arxiv.org/pdf/2601.19487", "abs": "https://arxiv.org/abs/2601.19487", "authors": ["Haonan Zhang", "Dongxia Wang", "Yi Liu", "Kexin Chen", "Wenhai Wang"], "title": "LLM-VA: Resolving the Jailbreak-Overrefusal Trade-off via Vector Alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Safety-aligned LLMs suffer from two failure modes: jailbreak (answering harmful inputs) and over-refusal (declining benign queries). Existing vector steering methods adjust the magnitude of answer vectors, but this creates a fundamental trade-off -- reducing jailbreak increases over-refusal and vice versa. We identify the root cause: LLMs encode the decision to answer (answer vector $v_a$) and the judgment of input safety (benign vector $v_b$) as nearly orthogonal directions, treating them as independent processes. We propose LLM-VA, which aligns $v_a$ with $v_b$ through closed-form weight updates, making the model's willingness to answer causally dependent on its safety assessment -- without fine-tuning or architectural changes. Our method identifies vectors at each layer using SVMs, selects safety-relevant layers, and iteratively aligns vectors via minimum-norm weight modifications. Experiments on 12 LLMs demonstrate that LLM-VA achieves 11.45% higher F1 than the best baseline while preserving 95.92% utility, and automatically adapts to each model's safety bias without manual tuning. Code and models are available at https://hotbento.github.io/LLM-VA-Web/.", "AI": {"tldr": "提出了一种通过向量对齐来解决安全对齐LLM中的越狱和过度拒绝问题的方法。", "motivation": "现有方法在减少越狱风险时会导致过度拒绝，反之亦然。作者发现了LLM中答案向量与输入安全性向量几乎正交的原因，并提出了新的方法来解决这个问题。", "method": "通过SVM识别每一层的向量，选择安全相关的层，然后迭代地进行最小范数权重调整以对齐答案向量和安全判断向量。", "result": "实验表明LLM-VA在12个LLM模型上实现了比最佳基线方法高11.45%的F1分数，并保持了95.92%的效用，无需手动调优即可自动适应每个模型的安全偏见。", "conclusion": "LLM-VA通过向量对齐解决了越狱和过度拒绝之间的权衡问题，提高了模型的安全性并维持其有效性。"}}
{"id": "2601.19484", "pdf": "https://arxiv.org/pdf/2601.19484", "abs": "https://arxiv.org/abs/2601.19484", "authors": ["Yin Wang", "Zhiying Leng", "Haitian Liu", "Frederick W. B. Li", "Mu Li", "Xiaohui Liang"], "title": "Dynamic Worlds, Dynamic Humans: Generating Virtual Human-Scene Interaction Motion in Dynamic Scenes", "categories": ["cs.CV"], "comment": null, "summary": "Scenes are continuously undergoing dynamic changes in the real world. However, existing human-scene interaction generation methods typically treat the scene as static, which deviates from reality. Inspired by world models, we introduce Dyn-HSI, the first cognitive architecture for dynamic human-scene interaction, which endows virtual humans with three humanoid components. (1)Vision (human eyes): we equip the virtual human with a Dynamic Scene-Aware Navigation, which continuously perceives changes in the surrounding environment and adaptively predicts the next waypoint. (2)Memory (human brain): we equip the virtual human with a Hierarchical Experience Memory, which stores and updates experiential data accumulated during training. This allows the model to leverage prior knowledge during inference for context-aware motion priming, thereby enhancing both motion quality and generalization. (3) Control (human body): we equip the virtual human with Human-Scene Interaction Diffusion Model, which generates high-fidelity interaction motions conditioned on multimodal inputs. To evaluate performance in dynamic scenes, we extend the existing static human-scene interaction datasets to construct a dynamic benchmark, Dyn-Scenes. We conduct extensive qualitative and quantitative experiments to validate Dyn-HSI, showing that our method consistently outperforms existing approaches and generates high-quality human-scene interaction motions in both static and dynamic settings.", "AI": {"tldr": "本文提出了一种动态人类场景交互生成方法Dyn-HSI，旨在创建更真实的虚拟人在动态环境中的行为。", "motivation": "现有的人类场景交互生成方法通常将场景视为静态的，这与现实情况不符。为了克服这一问题，作者引入了Dyn-HSI来处理动态变化的场景。", "method": "该方法通过引入三个关键组件实现：动态感知导航、层次经验记忆和人类场景互动扩散模型，从而提高虚拟人在复杂环境中的适应性和交互质量。", "result": "实验结果表明，与现有方法相比，本文提出的方法在静态和动态场景下均能生成更高质量的人类场景交互行为。", "conclusion": "该研究成功地展示了如何通过引入认知架构来增强虚拟人在动态环境下的互动能力，并为未来的研究提供了一个有价值的框架。"}}
{"id": "2601.19481", "pdf": "https://arxiv.org/pdf/2601.19481", "abs": "https://arxiv.org/abs/2601.19481", "authors": ["Peng Yang", "Zhenhua Yang", "Boquan Jiang", "Chenkai Wang", "Ke Tang", "Xin Yao"], "title": "Posterior Distribution-assisted Evolutionary Dynamic Optimization as an Online Calibrator for Complex Social Simulations", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "The calibration of simulators for complex social systems aims to identify the optimal parameter that drives the output of the simulator best matching the target data observed from the system. As many social systems may change internally over time, calibration naturally becomes an online task, requiring parameters to be updated continuously to maintain the simulator's fidelity. In this work, the online setting is first formulated as a dynamic optimization problem (DOP), requiring the search for a sequence of optimal parameters that fit the simulator to real system changes. However, in contrast to traditional DOP formulations, online calibration explicitly incorporates the observational data as the driver of environmental dynamics. Due to this fundamental difference, existing Evolutionary Dynamic Optimization (EDO) methods, despite being extensively studied for black-box DOPs, are ill-equipped to handle such a scenario. As a result, online calibration problems constitute a new set of challenging DOPs. Here, we propose to explicitly learn the posterior distributions of the parameters and the observational data, thereby facilitating both change detection and environmental adaptation of existing EDOs for this scenario. We thus present a pretrained posterior model for implementation, and fine-tune it during the optimization. Extensive tests on both economic and financial simulators verify that the posterior distribution strongly promotes EDOs in such DOPs widely existed in social science.", "AI": {"tldr": "提出了利用后验分布辅助进化动态优化以在线校准复杂社会模拟器的方法。", "motivation": "复杂社会系统的模拟器需要不断调整参数来适应系统随时间的变化，而传统的进化动态优化方法难以处理这种包含观察数据驱动环境变化的场景。", "method": "提出了一种通过学习参数和观测数据的后验分布来辅助现有进化动态优化的方法，并在优化过程中对其进行微调。", "result": "实验表明该方法能显著提升进化动态优化在社会科学广泛存在的这类问题上的性能，验证了其有效性。", "conclusion": "本研究提出了一种新的在线校准复杂模拟器的方法，能够更好地适应环境变化并保持模拟的准确性。"}}
{"id": "2601.19479", "pdf": "https://arxiv.org/pdf/2601.19479", "abs": "https://arxiv.org/abs/2601.19479", "authors": ["Victoria Catterall", "Cise Midoglu", "Stephen Lynch"], "title": "Time-to-Injury Forecasting in Elite Female Football: A DeepHit Survival Approach", "categories": ["cs.LG", "cs.AI"], "comment": ":I.2.6; I.2.7; F.2.2", "summary": "Injury occurrence in football poses significant challenges for athletes and teams, carrying personal, competitive, and financial consequences. While machine learning has been applied to injury prediction before, existing approaches often rely on static pre-season data and binary outcomes, limiting their real-world utility. This study investigates the feasibility of using a DeepHit neural network to forecast time-to-injury from longitudinal athlete monitoring data, while providing interpretable predictions. The analysis utilised the publicly available SoccerMon dataset, containing two seasons of training, match, and wellness records from elite female footballers. Data was pre-processed through cleaning, feature engineering, and the application of three imputation strategies. Baseline models (Random Forest, XGBoost, Logistic Regression) were optimised via grid search for benchmarking, while the DeepHit model, implemented with a multilayer perceptron backbone, was evaluated using chronological and leave-one-player-out (LOPO) validation. DeepHit achieved a concordance index of 0.762, outperforming baseline models and delivering individualised, time-varying risk estimates. Shapley Additive Explanations (SHAP) identified clinically relevant predictors consistent with established risk factors, enhancing interpretability. Overall, this study provides a novel proof of concept: survival modelling with DeepHit shows strong potential to advance injury forecasting in football, offering accurate, explainable, and actionable insights for injury prevention across competitive levels.", "AI": {"tldr": "本文使用DeepHit神经网络预测精英女子足球运动员的伤情发生时间，从纵向监测数据中提取信息，并提供可解释性预测。", "motivation": "现有研究通常依赖于静态前测季节的数据和二元结果进行伤情预测，限制了其实用性。为了提高实用性，本文旨在使用深度学习模型（DeepHit）来预测运动员的伤情发生时间并提供临床意义的相关预测因子以改善预防措施。", "method": "通过处理SoccerMon数据集中的训练、比赛和健康记录，并运用随机森林、XGBoost、逻辑回归作为基准模型进行对比，同时使用深度学习方法（DeepHit）进行了分析。最终采用了多层感知器作为网络结构来实现生存时间预测的优化。", "result": "经过评估，DeepHit模型实现了0.762的C指数，并且超过了其他基准模型，证明其能够提供准确、可解释和操作性强的风险估计。", "conclusion": "这项研究表明，在足球伤情预测方面使用生存模型（如DeepHit）具有显著潜力，可以为各竞技水平的运动员提供有效的伤害预防策略。"}}
{"id": "2601.19477", "pdf": "https://arxiv.org/pdf/2601.19477", "abs": "https://arxiv.org/abs/2601.19477", "authors": ["Alina Geiger", "Martin Briesch", "Dominik Sobania", "Franz Rothlauf"], "title": "ROIDS: Robust Outlier-Aware Informed Down-Sampling", "categories": ["cs.NE"], "comment": null, "summary": "Informed down-sampling (IDS) is known to improve performance in symbolic regression when combined with various selection strategies, especially tournament selection. However, recent work found that IDS's gains are not consistent across all problems. Our analysis reveals that IDS performance is worse for problems containing outliers. IDS systematically favors including outliers in subsets which pushes GP towards finding solutions that overfit to outliers. To address this, we introduce ROIDS (Robust Outlier-Aware Informed Down-Sampling), which excludes potential outliers from the sampling process of IDS. With ROIDS it is possible to keep the advantages of IDS without overfitting to outliers and to compete on a wide range of benchmark problems. This is also reflected in our experiments in which ROIDS shows the desired behavior on all studied benchmark problems. ROIDS consistently outperforms IDS on synthetic problems with added outliers as well as on a wide range of complex real-world problems, surpassing IDS on over 80% of the real-world benchmark problems. Moreover, compared to all studied baseline approaches, ROIDS achieves the best average rank across all tested benchmark problems. This robust behavior makes ROIDS a reliable down-sampling method for selection in symbolic regression, especially when outliers may be included in the data set.", "AI": {"tldr": "提出了ROIDS方法，以解决IDS在包含异常值的问题上的性能不佳问题。", "motivation": "分析发现IDS在存在异常值的数据集上表现较差，因为其倾向于选择包括异常值的子集从而导致过拟合。为了改善这一情况，引入了ROIDS来排除潜在的异常值。", "method": "ROIDS通过改进IDS，在下采样过程中排除可能的异常值，以防止对异常值的过度拟合。", "result": "实验结果显示，ROIDS在合成问题和复杂的真实世界问题上均优于IDS，并且在大部分真实世界的基准测试中超过IDS。与其他基线方法相比，ROIDS在整个测试集上的平均排名最佳。", "conclusion": "ROIDS作为选择下采样方法，在存在异常值的数据集中表现出了可靠性和鲁棒性，可以有效地应用于符号回归中的问题解决。"}}
{"id": "2601.19472", "pdf": "https://arxiv.org/pdf/2601.19472", "abs": "https://arxiv.org/abs/2601.19472", "authors": ["Zhen Liao", "Gaole Dai", "Mengqiao Chen", "Wenqing Cheng", "Wei Xu"], "title": "Dual-Strategy-Enhanced ConBiMamba for Neural Speaker Diarization", "categories": ["cs.SD"], "comment": "Accepted at ICASSP 2026", "summary": "Conformer and Mamba have achieved strong performance in speech modeling but face limitations in speaker diarization. Mamba is efficient but struggles with local details and nonlinear patterns. Conformer's self-attention incurs high memory overhead for long speech sequences and may cause instability in long-range dependency modeling. These limitations are critical for diarization, which requires both precise modeling of local variations and robust speaker consistency over extended spans. To address these challenges, we first apply ConBiMamba for speaker diarization. We follow the Pyannote pipeline and propose the Dual-Strategy-Enhanced ConBiMamba neural speaker diarization system. ConBiMamba integrates the strengths of Conformer and Mamba, where Conformer's convolutional and feed-forward structures are utilized to improve local feature extraction. By replacing Conformer's self-attention with ExtBiMamba, ConBiMamba efficiently handles long audio sequences while alleviating the high memory cost of self-attention. Furthermore, to address the problem of the higher DER around speaker change points, we introduce the Boundary-Enhanced Transition Loss to enhance the detection of speaker change points. We also propose Layer-wise Feature Aggregation to enhance the utilization of multi-layer representations. The system is evaluated on six diarization datasets and achieves state-of-the-art performance on four of them. The source code of our study is available at https://github.com/lz-hust/DSE-CBM.", "AI": {"tldr": "本文提出了一种基于ConBiMamba的神经说话人识别系统，以提高长语音序列中的说话人分段性能。", "motivation": "为了克服现有模型在局部细节和非线性模式上的限制以及高内存开销问题，作者提出将Conformer与Mamba相结合，形成ConBiMamba，从而改善说话人识别的准确性和稳定性。", "method": "采用Dual-Strategy-Enhanced ConBiMamba神经说话人识别系统，结合了Conformer和Mamba的优点，并引入边界增强过渡损失和层特征聚合以提高说话人变化点检测性能。", "result": "该系统在六个说话人分段数据集上进行了评估，在四个数据集中达到了当前最佳性能。", "conclusion": "通过改进的ConBiMamba模型，可以有效解决长音频序列中的高内存成本问题，并提高说话人识别准确性。"}}
{"id": "2601.19462", "pdf": "https://arxiv.org/pdf/2601.19462", "abs": "https://arxiv.org/abs/2601.19462", "authors": ["Riccardo Zanella", "Federico Califano", "Stefano Stramigioli"], "title": "Physical Human-Robot Interaction: A Critical Review of Safety Constraints", "categories": ["eess.SY", "cs.RO"], "comment": null, "summary": "This paper aims to provide a clear and rigorous understanding of commonly recognized safety constraints in physical human-robot interaction, i.e. ISO/TS 15066, by examining how they are obtained and which assumptions support them. We clarify the interpretation and practical impact of key simplifying assumptions, show how these modeling choices affect both safety and performance across the system, and indicate specific design parameters that can be adjusted in safety-critical control implementations. Numerical examples are provided to quantify performance degradation induced by common approximations and simplifying design choices. Furthermore, the fundamental role of energy in safety assessment is emphasized, and focused insights are offered on the existing body of work concerning energy-based safety methodologies.", "AI": {"tldr": "本文旨在通过分析物理人机交互中的常见安全约束，提供清晰和严格的理解。", "motivation": "明确ISO/TS 15066标准中公认的安全限制的获得方式及其支持假设，并强调能量在安全性评估中的基础作用。", "method": "研究关键简化假设的解释与实践影响，展示这些建模选择如何影响系统安全性和性能，提供数值示例来量化常见近似和设计选择带来的性能下降。", "result": "指出了可以在安全临界控制实现中调整的具体设计参数，并提供了能量相关安全性方法的研究见解。", "conclusion": "强调了在物理人机交互中的关键假设与能量的重要性，提出了基于这些原则的设计建议。"}}
{"id": "2601.19461", "pdf": "https://arxiv.org/pdf/2601.19461", "abs": "https://arxiv.org/abs/2601.19461", "authors": ["Yida Lin", "Bing Xue", "Mengjie Zhang", "Sam Schofield", "Richard Green"], "title": "Towards Gold-Standard Depth Estimation for Tree Branches in UAV Forestry: Benchmarking Deep Stereo Matching Methods", "categories": ["cs.CV", "cs.RO", "eess.IV"], "comment": null, "summary": "Autonomous UAV forestry operations require robust depth estimation with strong cross-domain generalization, yet existing evaluations focus on urban and indoor scenarios, leaving a critical gap for vegetation-dense environments. We present the first systematic zero-shot evaluation of eight stereo methods spanning iterative refinement, foundation model, diffusion-based, and 3D CNN paradigms. All methods use officially released pretrained weights (trained on Scene Flow) and are evaluated on four standard benchmarks (ETH3D, KITTI 2012/2015, Middlebury) plus a novel 5,313-pair Canterbury Tree Branches dataset ($1920 \\times 1080$). Results reveal scene-dependent patterns: foundation models excel on structured scenes (BridgeDepth: 0.23 px on ETH3D; DEFOM: 4.65 px on Middlebury), while iterative methods show variable cross-benchmark performance (IGEV++: 0.36 px on ETH3D but 6.77 px on Middlebury; IGEV: 0.33 px on ETH3D but 4.99 px on Middlebury). Qualitative evaluation on the Tree Branches dataset establishes DEFOM as the gold-standard baseline for vegetation depth estimation, with superior cross-domain consistency (consistently ranking 1st-2nd across benchmarks, average rank 1.75). DEFOM predictions will serve as pseudo-ground-truth for future benchmarking.", "AI": {"tldr": "论文评估了八种深度学习方法在无人机林业操作中的零样本性能，特别是在树分支数据集上的表现。", "motivation": "现有深度估计技术主要针对城市和室内场景进行评价，缺乏对植被密集环境的有效评测。作者旨在填补这一空白，提供一种标准的深度估计基准。", "method": "使用官方发布的预训练权重（在Scene Flow上训练），对八个不同类别的立体匹配方法进行了系统的零样本评估，并将其应用于四个传统数据集和一个新型树分支数据集进行对比分析。", "result": "结果表明，各种模型在不同类型场景下的表现差异显著。DEFOM模型在植被深度估计中表现出色，具有跨域一致性高的优势。", "conclusion": "论文证明了DEFOM模型是未来无人机林业操作中用于树分支深度估计的黄金标准基线，并提供了其预测作为伪真实标签以供进一步研究使用。"}}
{"id": "2601.19453", "pdf": "https://arxiv.org/pdf/2601.19453", "abs": "https://arxiv.org/abs/2601.19453", "authors": ["Maarten Löffler", "Benjamin Raichel"], "title": "Preprocessing Uncertain Data into Supersequences for Sorting and Gaps", "categories": ["cs.DS", "cs.IT"], "comment": "arXiv admin note: substantial text overlap with arXiv:2502.03633", "summary": "In the preprocessing framework for dealing with uncertain data, one is given a set of regions that one is allowed to preprocess to create some auxiliary structure such that when a realization of these regions is given, consisting of one point per region, this auxiliary structure can be used to reconstruct some desired output structure more efficiently than would have been possible without preprocessing. The framework has been successfully applied to several, mostly geometric, computational problems. In this note, we propose using a supersequence of input items as the auxiliary structure, and explore its potential on the problems of sorting and computing the smallest or largest gap in a set of numbers. That is, our uncertainty regions are intervals on the real line, and in the preprocessing phase we output a supersequence of the intervals such that the sorted order / smallest gap / largest gap of any realization is a subsequence of this sequence. We argue that supersequences are simpler than specialized auxiliary structures developed in previous work. An advantage of using supersequences as the auxiliary structures is that it allows us to decouple the preprocessing phase from the reconstruction phase in a stronger sense than was possible in previous work, resulting in two separate algorithmic problems for which different solutions may be combined to obtain known and new results. We identify one key open problem which we believe is of independent interest.", "AI": {"tldr": "该论文提出使用超序列作为辅助结构，以解决不确定数据下的排序和计算最小或最大间隙的问题。", "motivation": "通过引入一个更简单的辅助结构——超序列，来简化先前研究中复杂的专用辅助结构，并实现预处理阶段与重建阶段的解耦。", "method": "提出了一种新的方法，在不确定性区域为区间的情况下，生成输入项的一个超序列作为辅助结构。这个超序列能够反映所有可能的排列、最小间隙和最大间隙。", "result": "展示了使用超序列作为辅助结构的有效性，并解决了排序和计算最小/最大间隙的问题，提供了一种将预处理与重建阶段分离的新方法。", "conclusion": "通过引入超序列概念，成功地简化了不确定数据的处理问题。作者还提出了一系列开放性问题以供未来研究，特别是关于如何更高效利用这种新方法来解决其他计算几何问题。"}}
{"id": "2601.19452", "pdf": "https://arxiv.org/pdf/2601.19452", "abs": "https://arxiv.org/abs/2601.19452", "authors": ["Finn Rietz", "Pedro Zuidberg dos Martires", "Johannes Andreas Stork"], "title": "APC-RL: Exceeding Data-Driven Behavior Priors with Adaptive Policy Composition", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Incorporating demonstration data into reinforcement learning (RL) can greatly accelerate learning, but existing approaches often assume demonstrations are optimal and fully aligned with the target task. In practice, demonstrations are frequently sparse, suboptimal, or misaligned, which can degrade performance when these demonstrations are integrated into RL. We propose Adaptive Policy Composition (APC), a hierarchical model that adaptively composes multiple data-driven Normalizing Flow (NF) priors. Instead of enforcing strict adherence to the priors, APC estimates each prior's applicability to the target task while leveraging them for exploration. Moreover, APC either refines useful priors, or sidesteps misaligned ones when necessary to optimize downstream reward. Across diverse benchmarks, APC accelerates learning when demonstrations are aligned, remains robust under severe misalignment, and leverages suboptimal demonstrations to bootstrap exploration while avoiding performance degradation caused by overly strict adherence to suboptimal demonstrations.", "AI": {"tldr": "提出了一种自适应策略组合（APC）方法，用于提高强化学习中利用演示数据的效果。", "motivation": "现有将演示数据纳入强化学习的方法假设演示是最佳的且与目标任务完全一致，但在实践中演示往往是稀疏、次优或不一致的，这可能导致性能下降。因此需要一种新的方法来解决这些问题。", "method": "APC是一种分层模型，可以自适应地组合多个基于数据驱动的正态流（NF）先验策略，并根据目标任务评估每个先验策略的有效性，在探索过程中利用这些先验策略。同时，当有必要时，它会修正有用的先验策略或避开不一致的先验策略以优化下游奖励。", "result": "在多种基准测试中，APC方法可以在演示数据与目标任务一致的情况下加速学习；即使面对严重不一致的情况也能保持稳健性，并利用次优演示进行探索引导而不导致性能下降。", "conclusion": "通过自适应组合多个基于数据驱动的正态流先验策略，APC能够在多种情况下提高强化学习中利用演示数据的效果。"}}
{"id": "2601.19447", "pdf": "https://arxiv.org/pdf/2601.19447", "abs": "https://arxiv.org/abs/2601.19447", "authors": ["Vítor N. Lourenço", "Aline Paes", "Tillman Weyde", "Audrey Depeige", "Mohnish Dubey"], "title": "KG-CRAFT: Knowledge Graph-based Contrastive Reasoning with LLMs for Enhancing Automated Fact-checking", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to publication at the 19th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2026", "summary": "Claim verification is a core component of automated fact-checking systems, aimed at determining the truthfulness of a statement by assessing it against reliable evidence sources such as documents or knowledge bases. This work presents KG-CRAFT, a method that improves automatic claim verification by leveraging large language models (LLMs) augmented with contrastive questions grounded in a knowledge graph. KG-CRAFT first constructs a knowledge graph from claims and associated reports, then formulates contextually relevant contrastive questions based on the knowledge graph structure. These questions guide the distillation of evidence-based reports, which are synthesised into a concise summary that is used for veracity assessment by LLMs. Extensive evaluations on two real-world datasets (LIAR-RAW and RAWFC) demonstrate that our method achieves a new state-of-the-art in predictive performance. Comprehensive analyses validate in detail the effectiveness of our knowledge graph-based contrastive reasoning approach in improving LLMs' fact-checking capabilities.", "AI": {"tldr": "该论文提出了KG-CRAFT方法，通过利用大型语言模型和基于知识图谱的对比推理来提高自动化事实核查系统的准确性。", "motivation": "自动化的事实核查系统需要准确地确定声明的真实性。现有的系统通常依赖于文档或知识库中的可靠证据来源进行评估。", "method": "KG-CRAFT方法首先从声明及其相关报告构建一个知识图谱，然后基于此结构生成对比问题来引导证据报告的提炼。这些精炼后的报告被合成简洁摘要供大型语言模型（LLM）用于真实性评估。", "result": "在LIAR-RAW和RAWFC两个真实世界数据集上的广泛评测显示，该方法在预测性能上达到了新的最先进水平。", "conclusion": "通过详细分析表明，基于知识图谱的对比推理方法能够有效提升大型语言模型的事实核查能力。"}}
{"id": "2601.19446", "pdf": "https://arxiv.org/pdf/2601.19446", "abs": "https://arxiv.org/abs/2601.19446", "authors": ["Yalin Luo", "Shun Long", "Huijin Wang", "Jieyun Bai"], "title": "DSTCS: Dual-Student Teacher Framework with Segment Anything Model for Semi-Supervised Pubic Symphysis Fetal Head Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Segmentation of the pubic symphysis and fetal head (PSFH) is a critical procedure in intrapartum monitoring and is essential for evaluating labor progression and identifying potential delivery complications. However, achieving accurate segmentation remains a significant challenge due to class imbalance, ambiguous boundaries, and noise interference in ultrasound images, compounded by the scarcity of high-quality annotated data. Current research on PSFH segmentation predominantly relies on CNN and Transformer architectures, leaving the potential of more powerful models underexplored. In this work, we propose a Dual-Student and Teacher framework combining CNN and SAM (DSTCS), which integrates the Segment Anything Model (SAM) into a dual student-teacher architecture. A cooperative learning mechanism between the CNN and SAM branches significantly improves segmentation accuracy. The proposed scheme also incorporates a specialized data augmentation strategy optimized for boundary processing and a novel loss function. Extensive experiments on the MICCAI 2023 and 2024 PSFH segmentation benchmarks demonstrate that our method exhibits superior robustness and significantly outperforms existing techniques, providing a reliable segmentation tool for clinical practice.", "AI": {"tldr": "提出了结合CNN和SAM的双学生教师框架，用于半监督下的胎儿头部与耻骨联合分割。", "motivation": "当前PSFH分割方法主要依赖于CNN和Transformer架构，对于边界模糊、噪声干扰等问题处理不足。为了提高分割精度并解决标注数据稀缺的问题，本文提出了一种新的解决方案。", "method": "设计了一个结合CNN和SAM的双学生教师框架，并采用一种专门的数据增强策略及新颖损失函数来改进模型性能。", "result": "实验结果显示，在MICCAI2023和2024PSFH分割基准测试中，该方法表现出色且优于现有技术。", "conclusion": "本文提出的DSTCS模型在半监督条件下实现了高精度的胎儿头部与耻骨联合分割，并为临床实践提供了一个可靠工具。"}}
{"id": "2601.19440", "pdf": "https://arxiv.org/pdf/2601.19440", "abs": "https://arxiv.org/abs/2601.19440", "authors": ["Mark Colley", "Simon Kopp", "Debargha Dey", "Pascal Jansen", "Enrico Rukzio"], "title": "eHMI for All -- Investigating the Effect of External Communication of Automated Vehicles on Pedestrians, Manual Drivers, and Cyclists in Virtual Reality", "categories": ["cs.HC"], "comment": "Conditionally accepted at CHI 2026", "summary": "With automated vehicles (AVs), the absence of a human operator could necessitate external Human-Machine Interfaces (eHMIs) to communicate with other road users. Existing research primarily focuses on pedestrian-AV interactions, with limited attention given to other road users, such as cyclists and drivers of manually driven vehicles. So far, no studies have compared the effects of eHMIs across these three road user roles. Therefore, we conducted a within-subjects virtual reality experiment (N=40), evaluating the subjective and objective impact of an eHMI communicating the AV's intention to pedestrians, cyclists, and drivers under various levels of distraction (no distraction, visual noise, interference). eHMIs positively influenced safety perceptions, trust, perceived usefulness, and mental demand across all roles. While distraction and road user roles showed significant main effects, interaction effects were only observed in perceived usability. Thus, a unified eHMI design is effective, facilitating the standardization and broader adoption of eHMIs in diverse traffic.", "AI": {"tldr": "研究探讨了自动化车辆外部人机界面（eHMI）对行人、手动驾驶员和骑自行车者的影响。", "motivation": "现有研究主要关注自动驾驶汽车与行人的交互，忽略了其他道路使用者。因此，需要评估不同角色用户对面部信息的反应及其影响。", "method": "通过虚拟现实实验，在有无分散注意力的情况下，评测eHMI对行人、骑自行车者和手动驾驶员的影响。", "result": "研究发现eHMI提高了安全感知度、信任度、实用性和精神需求。不同角色用户表现出显著的效果差异，而在可用性方面存在交互效果。", "conclusion": "统一的eHMI设计有效促进了标准化和广泛采用自动化车辆的外部人机界面技术。"}}
{"id": "2601.19435", "pdf": "https://arxiv.org/pdf/2601.19435", "abs": "https://arxiv.org/abs/2601.19435", "authors": ["Shengwei Xu", "Zhaohua Chen", "Xiaotie Deng", "Zhiyi Huang", "Grant Schoenebeck"], "title": "Ad Insertion in LLM-Generated Responses", "categories": ["cs.GT", "cs.AI", "cs.CL"], "comment": "31 pages, 8 figures", "summary": "Sustainable monetization of Large Language Models (LLMs) remains a critical open challenge. Traditional search advertising, which relies on static keywords, fails to capture the fleeting, context-dependent user intents--the specific information, goods, or services a user seeks--embedded in conversational flows. Beyond the standard goal of social welfare maximization, effective LLM advertising imposes additional requirements on contextual coherence (ensuring ads align semantically with transient user intents) and computational efficiency (avoiding user interaction latency), as well as adherence to ethical and regulatory standards, including preserving privacy and ensuring explicit ad disclosure. Although various recent solutions have explored bidding on token-level and query-level, both categories of approaches generally fail to holistically satisfy this multifaceted set of constraints. We propose a practical framework that resolves these tensions through two decoupling strategies. First, we decouple ad insertion from response generation to ensure safety and explicit disclosure. Second, we decouple bidding from specific user queries by using ``genres'' (high-level semantic clusters) as a proxy. This allows advertisers to bid on stable categories rather than sensitive real-time response, reducing computational burden and privacy risks. We demonstrate that applying the VCG auction mechanism to this genre-based framework yields approximately dominant strategy incentive compatibility (DSIC) and individual rationality (IR), as well as approximately optimal social welfare, while maintaining high computational efficiency. Finally, we introduce an \"LLM-as-a-Judge\" metric to estimate contextual coherence. Our experiments show that this metric correlates strongly with human ratings (Spearman's $ρ\\approx 0.66$), outperforming 80% of individual human evaluators.", "AI": {"tldr": "提出了一种在大型语言模型生成的回复中插入广告的框架，该框架通过两种解耦策略解决了传统搜索广告无法捕捉用户瞬时意图和效率低下的问题。", "motivation": "传统的基于静态关键词的搜索广告无法有效捕获用户的瞬时意图，并且难以满足上下文连贯性、计算效率以及伦理和监管标准的要求。现有的解决方案未能全面解决这些挑战。", "method": "通过将广告插入与响应生成解耦以确保安全性和明确披露，以及使用‘流派’作为代理而不是具体的用户查询来进行竞标来降低计算负担和隐私风险。采用VCG拍卖机制应用于基于流派的框架，并引入了“LLM-as-a-Judge”指标评估上下文连贯性。", "result": "应用VCG拍卖机制后，该框架实现了近似DSIC和IR以及接近最优的社会福利，同时保持高效计算效率。“LLM-as-a-Judge”指标与人工评分高度相关（斯皮尔曼系数约0.66），优于80%的人工评估者。", "conclusion": "提出的广告插入框架能够有效解决现有问题，在确保上下文连贯性、伦理标准和隐私保护的同时，实现高效的广告投放和社会福利最大化。"}}
{"id": "2601.19433", "pdf": "https://arxiv.org/pdf/2601.19433", "abs": "https://arxiv.org/abs/2601.19433", "authors": ["Jisheng Chu", "Wenrui Li", "Rui Zhao", "Wangmeng Zuo", "Shifeng Chen", "Xiaopeng Fan"], "title": "RoamScene3D: Immersive Text-to-3D Scene Generation via Adaptive Object-aware Roaming", "categories": ["cs.CV"], "comment": null, "summary": "Generating immersive 3D scenes from texts is a core task in computer vision, crucial for applications in virtual reality and game development. Despite the promise of leveraging 2D diffusion priors, existing methods suffer from spatial blindness and rely on predefined trajectories that fail to exploit the inner relationships among salient objects. Consequently, these approaches are unable to comprehend the semantic layout, preventing them from exploring the scene adaptively to infer occluded content. Moreover, current inpainting models operate in 2D image space, struggling to plausibly fill holes caused by camera motion. To address these limitations, we propose RoamScene3D, a novel framework that bridges the gap between semantic guidance and spatial generation. Our method reasons about the semantic relations among objects and produces consistent and photorealistic scenes. Specifically, we employ a vision-language model (VLM) to construct a scene graph that encodes object relations, guiding the camera to perceive salient object boundaries and plan an adaptive roaming trajectory. Furthermore, to mitigate the limitations of static 2D priors, we introduce a Motion-Injected Inpainting model that is fine-tuned on a synthetic panoramic dataset integrating authentic camera trajectories, making it adaptive to camera motion. Extensive experiments demonstrate that with semantic reasoning and geometric constraints, our method significantly outperforms state-of-the-art approaches in producing consistent and photorealistic scenes. Our code is available at https://github.com/JS-CHU/RoamScene3D.", "AI": {"tldr": "RoamScene3D通过自适应的对象感知漫游生成沉浸式的3D场景。", "motivation": "现有方法存在空间盲点，依赖预定义轨迹，无法理解语义布局或探索场景以推断被遮挡的内容。此外，当前的修复模型在2D图像空间操作时难以合理填补由相机移动造成的空洞。", "method": "提出RoamScene3D框架，利用视觉语言模型（VLM）构建编码对象关系的场景图，并引导相机感知显著对象边界和规划自适应漫游轨迹。此外，通过在合成全景数据集上微调运动注入修复模型来缓解静态2D先验限制。", "result": "实验表明，通过语义推理和几何约束，RoamScene3D方法在生成一致且逼真的场景方面显著优于现有最佳方案。", "conclusion": "提出的RoamScene3D框架能够克服现有技术的局限性，生成更加一致和真实的沉浸式3D场景。"}}
{"id": "2601.19430", "pdf": "https://arxiv.org/pdf/2601.19430", "abs": "https://arxiv.org/abs/2601.19430", "authors": ["Yao Xiao", "Weiyan Chen", "Jiahao Chen", "Zijie Cao", "Weijian Deng", "Binbin Yang", "Ziyi Dong", "Xiangyang Ji", "Wei Ke", "Pengxu Wei", "Liang Lin"], "title": "Unveiling Perceptual Artifacts: A Fine-Grained Benchmark for Interpretable AI-Generated Image Detection", "categories": ["cs.CV"], "comment": null, "summary": "Current AI-Generated Image (AIGI) detection approaches predominantly rely on binary classification to distinguish real from synthetic images, often lacking interpretable or convincing evidence to substantiate their decisions. This limitation stems from existing AIGI detection benchmarks, which, despite featuring a broad collection of synthetic images, remain restricted in their coverage of artifact diversity and lack detailed, localized annotations. To bridge this gap, we introduce a fine-grained benchmark towards eXplainable AI-Generated image Detection, named X-AIGD, which provides pixel-level, categorized annotations of perceptual artifacts, spanning low-level distortions, high-level semantics, and cognitive-level counterfactuals. These comprehensive annotations facilitate fine-grained interpretability evaluation and deeper insight into model decision-making processes. Our extensive investigation using X-AIGD provides several key insights: (1) Existing AIGI detectors demonstrate negligible reliance on perceptual artifacts, even at the most basic distortion level. (2) While AIGI detectors can be trained to identify specific artifacts, they still substantially base their judgment on uninterpretable features. (3) Explicitly aligning model attention with artifact regions can increase the interpretability and generalization of detectors. The data and code are available at: https://github.com/Coxy7/X-AIGD.", "AI": {"tldr": "本文提出了一种名为X-AIGD的细粒度基准，用于检测AI生成图像，提供了像素级别的分类注释。", "motivation": "当前AI生成图像（AIGI）检测方法主要依赖二元分类来区分真实和合成图像，缺少可解释或令人信服的证据支持其决策。现有的AIGI检测基准虽然包含大量合成图像，但在感知特征多样性方面受限，并缺乏详细的局部注释。", "method": "提出了名为X-AIGD的细粒度基准，提供像素级别的分类注释，涵盖了低级失真、高级语义和认知级别反事实等内容。这些全面的注释促进了细粒度可解释性评估和对模型决策过程的深入了解。", "result": "通过使用X-AIGD进行广泛研究，提供了以下关键见解：1）现有的AIGI检测器在最基础失真层面上对感知特征依赖性很小；2）尽管可以训练检测器识别特定特征，它们仍然主要基于不可解释的特征作出判断；3）显式地将模型注意力与特征区域对齐可以提高检测器的可解释性和泛化能力。", "conclusion": "本文通过提供像素级别的分类注释和细粒度基准X-AIGD来促进AI生成图像检测研究，提高了模型决策过程的透明度。"}}
{"id": "2601.19421", "pdf": "https://arxiv.org/pdf/2601.19421", "abs": "https://arxiv.org/abs/2601.19421", "authors": ["Josh Susak", "Yifu Liu", "Pascal Jansen", "Mark Colley"], "title": "ProVoice: Designing Proactive Functionality for In-Vehicle Conversational Assistants using Multi-Objective Bayesian Optimization to Enhance Driver Experience", "categories": ["cs.HC"], "comment": "Conditionally accepted at CHI 2026", "summary": "The next step for In-vehicle Conversational Assistants (IVCAs) will be their capability to initiate and automate proactive system interactions throughout journeys. However, diverse drivers make it challenging to design voice interventions tailored towards individual on-road expectations. This paper evaluates the effectiveness of Human-in-the-Loop (HITL) Multi-Objective Bayesian Optimization (MOBO) in design by implementing ProVoice: a Virtual Reality (VR) driving simulator integrating MOBO to investigate the effects of IVCA design variants on perceived mental demand, predictability, and usefulness. By reporting the Pareto Front from a within-subjects VR study (N=19), this paper proposes optimal design trade-offs. Follow-up analysis demonstrates MOBO's success in discovering effective intervention strategies, with reduced participant mental demand, alongside enhanced predictability and usefulness while engaging with the proactive IVCA. Implications for computational techniques in future research on proactive intervention strategies are discussed. ProVoice can extend to include alternative design parameters and driving scenarios, encouraging intervention design on a broad scale.", "AI": {"tldr": "设计了一种用于车载对话助手的主动功能，使用多目标贝叶斯优化以提高驾驶员体验。", "motivation": "为了满足不同驾驶员的需求，研究了如何通过主动系统交互来定制语音干预，并评估了人类在循环中的多目标贝叶斯优化（MOBO）的设计效果。", "method": "采用了虚拟现实驾驶模拟器结合多目标贝叶斯优化进行实验，调查车载对话助手设计变体对感知心理需求、可预测性和有用性的效果。", "result": "通过参与者研究展示了使用多目标贝叶斯优化发现的有效干预策略，减少了参与者的心理负担，并提高了与主动IVCA的互动的可预测性及有用性。", "conclusion": "证明了多目标贝叶斯优化在寻找有效干预策略方面的成功，为未来的车载对话助手设计提供了新的视角和方法。"}}
{"id": "2601.19411", "pdf": "https://arxiv.org/pdf/2601.19411", "abs": "https://arxiv.org/abs/2601.19411", "authors": ["Ziang Zheng", "Kai Feng", "Yi Nie", "Shentao Qin"], "title": "Task-Centric Policy Optimization from Misaligned Motion Priors", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Humanoid control often leverages motion priors from human demonstrations to encourage natural behaviors. However, such demonstrations are frequently suboptimal or misaligned with robotic tasks due to embodiment differences, retargeting errors, and task-irrelevant variations, causing naïve imitation to degrade task performance. Conversely, task-only reinforcement learning admits many task-optimal solutions, often resulting in unnatural or unstable motions. This exposes a fundamental limitation of linear reward mixing in adversarial imitation learning. We propose \\emph{Task-Centric Motion Priors} (TCMP), a task-priority adversarial imitation framework that treats imitation as a conditional regularizer rather than a co-equal objective. TCMP maximizes task improvement while incorporating imitation signals only when they are compatible with task progress, yielding an adaptive, geometry-aware update that preserves task-feasible descent and suppresses harmful imitation under misalignment. We provide theoretical analysis of gradient conflict and task-priority stationary points, and validate our claims through humanoid control experiments demonstrating robust task performance with consistent motion style under noisy demonstrations.", "AI": {"tldr": "提出了任务中心化运动先验（TCMP）框架，以解决在人形机器人控制中由于模仿人类演示而导致的任务性能下降问题。", "motivation": "利用人类演示来鼓励自然行为的人形控制方法因身体差异、重定位错误和与任务无关的变化而表现不佳。单纯强化学习则可能产生不稳定或不自然的动作，线性奖励混合在对抗模仿学习中的局限性也暴露出来。", "method": "TCMP框架将模仿视为一种条件正则化器而非同等目标，并通过最大化任务改进同时仅在兼容于任务进展时使用模仿信号来实现自适应、几何感知的更新。该方法还提供了理论分析，解释了梯度冲突和任务优先级不动点。", "result": "通过人形控制实验验证了TCMP框架的有效性，在噪声演示下仍能保持一致的动作风格，并且具有鲁棒的任务性能。", "conclusion": "本文提出了用于解决因模仿人类演示导致的任务表现不佳问题的TCMP方法，它能够在任务进展中自适应地使用运动先验，从而提高人形机器人控制下的动作质量和任务稳定性。"}}
{"id": "2601.19406", "pdf": "https://arxiv.org/pdf/2601.19406", "abs": "https://arxiv.org/abs/2601.19406", "authors": ["Kaipeng Fang", "Weiqing Liang", "Yuyang Li", "Ji Zhang", "Pengpeng Zeng", "Lianli Gao", "Jingkuan Song", "Heng Tao Shen"], "title": "Sim-and-Human Co-training for Data-Efficient and Generalizable Robotic Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Synthetic simulation data and real-world human data provide scalable alternatives to circumvent the prohibitive costs of robot data collection. However, these sources suffer from the sim-to-real visual gap and the human-to-robot embodiment gap, respectively, which limits the policy's generalization to real-world scenarios. In this work, we identify a natural yet underexplored complementarity between these sources: simulation offers the robot action that human data lacks, while human data provides the real-world observation that simulation struggles to render. Motivated by this insight, we present SimHum, a co-training framework to simultaneously extract kinematic prior from simulated robot actions and visual prior from real-world human observations. Based on the two complementary priors, we achieve data-efficient and generalizable robotic manipulation in real-world tasks. Empirically, SimHum outperforms the baseline by up to $\\mathbf{40\\%}$ under the same data collection budget, and achieves a $\\mathbf{62.5\\%}$ OOD success with only 80 real data, outperforming the real only baseline by $7.1\\times$. Videos and additional information can be found at \\href{https://kaipengfang.github.io/sim-and-human}{project website}.", "AI": {"tldr": "本文提出了一种名为SimHum的协同训练框架，用于通过合成模拟数据和真实世界人类数据进行高效且通用性的机器人操作任务。", "motivation": "利用仿真数据提供机器人行动而缺乏的真实观察数据，以及实际环境中的人类行为提供的难以在模拟中渲染的真实观测。两者互补性可解决单一来源的数据局限性问题。", "method": "SimHum框架通过从模拟中提取运动先验，同时从人类的实际操作中学习视觉先验，并结合这两种先验来优化机器人任务性能。", "result": "相比基准方法，在相同数据收集预算下表现更好，成功率提高40%，仅使用80个实际数据就达到62.5%的OOD成功率，比只有真实数据的方法高出7.1倍。", "conclusion": "SimHum通过结合模拟和人类行为数据的优势实现了高效且通用性的机器人操作任务性能提升。"}}
{"id": "2601.19404", "pdf": "https://arxiv.org/pdf/2601.19404", "abs": "https://arxiv.org/abs/2601.19404", "authors": ["Hongzhu Yi", "Xinming Wang", "Zhenghao zhang", "Tianyu Zong", "Yuanxiang Wang", "Jun Xie", "Tao Yu", "Haopeng Jin", "Zhepeng Wang", "Kaixin Xu", "Feng Chen", "Jiahuan Chen", "Yujia Yang", "Zhenyu Guan", "Bingkang Shi", "Jungang Xu"], "title": "RPO:Reinforcement Fine-Tuning with Partial Reasoning Optimization", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Within the domain of large language models, reinforcement fine-tuning algorithms necessitate the generation of a complete reasoning trajectory beginning from the input query, which incurs significant computational overhead during the rollout phase of training. To address this issue, we analyze the impact of different segments of the reasoning path on the correctness of the final result and, based on these insights, propose Reinforcement Fine-Tuning with Partial Reasoning Optimization (RPO), a plug-and-play reinforcement fine-tuning algorithm. Unlike traditional reinforcement fine-tuning algorithms that generate full reasoning paths, RPO trains the model by generating suffixes of the reasoning path using experience cache. During the rollout phase of training, RPO reduces token generation in this phase by approximately 95%, greatly lowering the theoretical time overhead. Compared with full-path reinforcement fine-tuning algorithms, RPO reduces the training time of the 1.5B model by 90% and the 7B model by 72%. At the same time, it can be integrated with typical algorithms such as GRPO and DAPO, enabling them to achieve training acceleration while maintaining performance comparable to the original algorithms. Our code is open-sourced at https://github.com/yhz5613813/RPO.", "AI": {"tldr": "该论文提出了RPO算法，用于减少大规模语言模型强化微调过程中的计算开销。", "motivation": "传统强化学习微调方法在训练期间生成完整的推理轨迹会导致显著的计算负担。为了解决这个问题，作者引入了一种新的优化策略。", "method": "通过分析不同部分对最终结果的影响，RPO仅生成推理路径的一部分并利用经验缓存来降低训练过程中的token生成量，从而大幅减少理论时间开销。", "result": "与完整路径的强化学习微调方法相比，RPO可以将1.5B模型的训练时间缩短90%，7B模型的训练时间缩短72%。同时保持性能不变的情况下加速了GRPO和DAPO等典型算法的训练过程。", "conclusion": "RPO是一种有效的优化策略，能够显著减少大规模语言模型强化学习微调时的时间开销，并可以与现有方法无缝集成以实现更高效的训练流程。"}}
{"id": "2601.19403", "pdf": "https://arxiv.org/pdf/2601.19403", "abs": "https://arxiv.org/abs/2601.19403", "authors": ["Seungwoo Yoon", "Dohyun Kang", "Eunsue Choi", "Sohyun Lee", "Seoyeon Kim", "Minho Choi", "Hyeonsu Heo", "Dong-ha Shin", "Suha Kwak", "Arka Majumdar", "Junsuk Rho", "Seung-Hwan Baek"], "title": "Learned split-spectrum metalens for obstruction-free broadband imaging in the visible", "categories": ["physics.optics", "cs.AI", "cs.CV", "physics.app-ph"], "comment": null, "summary": "Obstructions such as raindrops, fences, or dust degrade captured images, especially when mechanical cleaning is infeasible. Conventional solutions to obstructions rely on a bulky compound optics array or computational inpainting, which compromise compactness or fidelity. Metalenses composed of subwavelength meta-atoms promise compact imaging, but simultaneous achievement of broadband and obstruction-free imaging remains a challenge, since a metalens that images distant scenes across a broadband spectrum cannot properly defocus near-depth occlusions. Here, we introduce a learned split-spectrum metalens that enables broadband obstruction-free imaging. Our approach divides the spectrum of each RGB channel into pass and stop bands with multi-band spectral filtering and learns the metalens to focus light from far objects through pass bands, while filtering focused near-depth light through stop bands. This optical signal is further enhanced using a neural network. Our learned split-spectrum metalens achieves broadband and obstruction-free imaging with relative PSNR gains of 32.29% and improves object detection and semantic segmentation accuracies with absolute gains of +13.54% mAP, +48.45% IoU, and +20.35% mIoU over a conventional hyperbolic design. This promises robust obstruction-free sensing and vision for space-constrained systems, such as mobile robots, drones, and endoscopes.", "AI": {"tldr": "本文提出了一种学习型分光超透镜，用于宽带无遮挡成像。", "motivation": "传统解决方案依赖于笨重的光学阵列或计算插值来处理障碍物问题，这些方法会牺牲便携性或图像保真度。金属透镜虽然可以实现紧凑成像，但难以同时实现宽带和无障碍成像。", "method": "本文提出了一种学习型分光超透镜，该方案将每个RGB通道的频谱分为通带和阻断带，通过多频段滤波，并训练超透镜聚焦远处物体的光线并通过通带，过滤近处障碍物的焦点光线通过阻断带。光学信号进一步使用神经网络增强。", "result": "该学习型分光超透镜实现了宽带无遮挡成像，相对于传统的双曲线设计，PSNR增益为32.29%，物体检测和语义分割准确度分别提高了13.54% AP、48.45% IoU和20.35% mIoU。", "conclusion": "该学习型分光超透镜有望在空间受限系统中实现稳健的无遮挡传感与视觉，如移动机器人、无人机和内窥镜等。"}}
{"id": "2601.19402", "pdf": "https://arxiv.org/pdf/2601.19402", "abs": "https://arxiv.org/abs/2601.19402", "authors": ["Amit Singh Bhatti", "Vishal Vaddina", "Dagnachew Birru"], "title": "PROTEUS: SLA-Aware Routing via Lagrangian RL for Multi-LLM Serving Systems", "categories": ["cs.AI"], "comment": null, "summary": "Production LLM deployments serve diverse workloads where cost and quality requirements vary by customer tier, time of day, and query criticality. Model serving systems accept latency SLOs directly. LLM routers do not. They force operators to tune parameters offline and guess what accuracy might result. The relationship between parameters and outcomes is indirect, non-monotonic, and dataset-dependent. Operators need to specify accuracy targets, not infer them from opaque settings. We present PROTEUS (Polymorphic Router for Operational Target Enforcement with Unified SLA), a router that accepts accuracy targets tau as runtime input. PROTEUS uses Lagrangian dual control. A learned dual variable lambda tracks constraint violations during training and conditions the policy network. This lets the router translate specified tau values into routing decisions that satisfy them. A single trained model serves the full accuracy spectrum without retraining.We evaluate on RouterBench (11 models, 405K queries) and SPROUT (14 models, 45K queries). PROTEUS achieves consistent floor compliance where accuracy meets or exceeds tau. The target-response correlation reaches 0.97 to 0.98. The closest baseline, OmniRouter, meets floors only 22% of the time despite also using Lagrangian optimization. PROTEUS operates across tau in [0.85, 0.95] from a single model. On RouterBench it achieves 90.1% accuracy, within 1.3% of oracle. On SPROUT it achieves 94.0% accuracy, within 4.6% of oracle. Cost savings reach 89.8% versus the best fixed model.", "AI": {"tldr": "PROTEUS是一种SLA感知路由方法，通过Lagrange强化学习实现多LLM服务系统的准确性目标控制。", "motivation": "现有的LLM路由器无法直接接受服务质量要求，需要操作员进行离线调参并猜测结果。这种间接性和非单调性使得设定准确率目标变得困难。", "method": "PROTEUS利用Lagrange对偶控制方法，通过一个学习的对偶变量追踪训练中的约束违反情况，并以此调整策略网络，将指定的准确性目标转化为路由决策。", "result": "在RouterBench和SPROUT数据集上测试显示，PROTEUS能够实现一致性底线合规性，准确率满足或超过设定的目标。与基线OmniRouter相比，PROTEUS表现更优，且节省了89.8%的成本。", "conclusion": "PROTEUS提供了一种直接控制LLM服务系统准确性目标的方法，并通过实验验证其有效性和优越性。"}}
{"id": "2601.19399", "pdf": "https://arxiv.org/pdf/2601.19399", "abs": "https://arxiv.org/abs/2601.19399", "authors": ["Samir Sadok", "Stéphane Lathuilière", "Xavier Alameda-Pineda"], "title": "Residual Tokens Enhance Masked Autoencoders for Speech Modeling", "categories": ["cs.SD", "cs.AI"], "comment": "Submitted to ICASSP 2026 (accepted)", "summary": "Recent speech modeling relies on explicit attributes such as pitch, content, and speaker identity, but these alone cannot capture the full richness of natural speech. We introduce RT-MAE, a novel masked autoencoder framework that augments the supervised attributes-based modeling with unsupervised residual trainable tokens, designed to encode the information not explained by explicit labeled factors (e.g., timbre variations, noise, emotion etc). Experiments show that RT-MAE improves reconstruction quality, preserving content and speaker similarity while enhancing expressivity. We further demonstrate its applicability to speech enhancement, removing noise at inference while maintaining controllability and naturalness.", "AI": {"tldr": "RT-MAE框架通过引入残差可训练令牌来增强基于掩码的自动编码器，以捕捉自然语音中未被显式属性解释的信息。", "motivation": "现有的语音建模依赖于显式的特征如音高、内容和说话人身份等，但这些不足以完全捕捉到自然语音中的丰富性。RT-MAE旨在通过添加残差可训练令牌来提高模型的表达能力。", "method": "RT-MAE是一种新型的掩码自动编码器框架，它在监督属性基础上增加无监督的残差可训练令牌，用于编码显式标签因素未解释的信息（如音色变化、噪声和情绪等）。", "result": "实验表明，RT-MAE改善了重建质量，在保持内容和说话人相似性的同时增强了表达能力，并且适用于语音增强任务。", "conclusion": "RT-MAE通过引入残差可训练令牌，提高了自动编码器的性能，不仅在重建质量和自然度方面有所提升，还在语音增强任务中表现出了优秀的去噪能力和可控性。"}}
{"id": "2601.19393", "pdf": "https://arxiv.org/pdf/2601.19393", "abs": "https://arxiv.org/abs/2601.19393", "authors": ["Jiaqi Li", "Shuli Hu", "Xianxian Li", "Minghao Yin"], "title": "Constructing self-referential instances for the clique problem", "categories": ["cs.CC", "cs.DS"], "comment": null, "summary": "In this paper, we propose constructing self-referential instances to reveal the inherent algorithmic hardness of the clique problem. First, we prove the existence of a phase transition phenomenon for the clique problem in the Erdős--Rényi random graph model and derive an exact location for the transition point. Subsequently, at the transition point, we construct a family of graphs. In this family, each graph shares the same number of vertices, number of edges, and degree sequence, yet both instances containing a $k$-clique and instances without any $k$-clique are included. These two states can be transformed into each other through a symmetric transformation that preserves the degree of every vertex. This property explains why exhaustive search is required in the critical region: an algorithm must search nearly the entire solution space to determine the existence of a solution; otherwise, a counterinstance can be constructed from the original instance using the symmetric transformation. Finally, this paper elaborates on the intrinsic reason for this phenomenon from the independence of the solution space.", "AI": {"tldr": "构造自引用实例以揭示图论中的团问题算法难度的本质。", "motivation": "为了揭示团问题在特定图模型下的固有算法复杂性，通过证明随机图模型中存在相变现象并构建具有相同顶点数和边数但状态不同的家族图实例来阐明这一理论。", "method": "首先，在Erdős-Rényi随机图模型中证明了团问题的相变现象，并确定其相变点。接着，利用该相变点构造了一个家族图，其中包含具有相同顶点、边和度数序列但状态不同的实例，通过对称变换可以互换这些实例的状态。", "result": "成功揭示了在临界区域中必须执行几乎完整的解决方案空间搜索的原因，并阐明了解决方案空间的独立性是这一现象的根本原因。", "conclusion": "提出的方法为理解团问题中的固有算法难度提供了新的视角，强调了图的对称性和相变点的重要性。"}}
{"id": "2601.19388", "pdf": "https://arxiv.org/pdf/2601.19388", "abs": "https://arxiv.org/abs/2601.19388", "authors": ["Yimin Tang", "Sven Koenig", "Erdem Bıyık"], "title": "Judgelight: Trajectory-Level Post-Optimization for Multi-Agent Path Finding via Closed-Subwalk Collapsing", "categories": ["cs.RO"], "comment": null, "summary": "Multi-Agent Path Finding (MAPF) is an NP-hard problem with applications in warehouse automation and multi-robot coordination. Learning-based MAPF solvers offer fast and scalable planning but often produce feasible trajectories that contain unnecessary or oscillatory movements. We propose Judgelight, a post-optimization method that improves trajectory quality after a MAPF solver generates a feasible schedule. Judgelight collapses closed subwalks in agents' trajectories to remove redundant movements while preserving all feasibility constraints. We formalize this process as MAPF-Collapse, prove that it is NP-hard, and present an exact optimization approach by formulating it as integer linear programming (ILP) problem. Experimental results show Judgelight consistently reduces solution cost by around 20%, particularly for learning-based solvers, producing trajectories that are better suited for real-world deployment.", "AI": {"tldr": "提出了一种名为Judgelight的多智能体路径规划（MAPF）后优化方法，通过合并轨迹中的闭合子环来减少不必要的移动，提高解的质量。", "motivation": "学习型MAPF求解器生成了可行但包含冗余或振荡运动的路径，影响实际应用效果。因此需要一种改进方法提升这些路径的质量。", "method": "Judgelight通过识别并合并智能体轨迹中的闭合子环来减少不必要移动，并将其形式化为一个NP难问题MAPF-Collapse；使用整数线性规划（ILP）求解器进行精确优化。", "result": "实验结果表明，与原始方案相比，Judgelight可使解决方案成本降低约20%，尤其在学习型求解器中效果更佳。", "conclusion": "Judgelight能够有效提高MAPF问题的解的质量，使其更适合实际部署。"}}
{"id": "2601.19387", "pdf": "https://arxiv.org/pdf/2601.19387", "abs": "https://arxiv.org/abs/2601.19387", "authors": ["Lekshmi Murali Rani", "Richard Berntsson Svensson", "Robert Feldt"], "title": "Bridging the Socio-Emotional Gap: The Functional Dimension of Human-AI Collaboration for Software Engineering", "categories": ["cs.SE", "cs.HC"], "comment": "This is the authors accepted manuscript. The final version appears in ACM CHASE 2026", "summary": "As GenAI models are adopted to support software engineers and their development teams, understanding effective human-AI collaboration (HAIC) is increasingly important. Socio-emotional intelligence (SEI) enhances collaboration among human teammates, but its role in HAIC remains unclear. Current AI systems lack SEI capabilities that humans bring to teamwork, creating a potential gap in collaborative dynamics. In this study, we investigate how software practitioners perceive the socio-emotional gap in HAIC and what capabilities AI systems require for effective collaboration. Through semi-structured interviews with 10 practitioners, we examine how they think about collaborating with human versus AI teammates, focusing on their SEI expectations and the AI capabilities they envision. Results indicate that practitioners currently view AI models as intellectual teammates rather than social partners and expect fewer SEI attributes from them than from human teammates. However, they see the socio-emotional gap not as AIs failure to exhibit SEI traits, but as a functional gap in collaborative capabilities (AIs inability to negotiate responsibilities, adapt contextually, or maintain sustained partnerships). We introduce the concept of functional equivalents: technical capabilities (internal cognition, contextual intelligence, adaptive learning, and collaborative intelligence) that achieve collaborative outcomes comparable to human SEI attributes. Our findings suggest that effective collaboration with AI for SE tasks may benefit from functional design rather than replicating human SEI traits for SE tasks, thereby redefining collaboration as functional alignment.", "AI": {"tldr": "研究探讨了软件工程师在与AI协作时的社会情感差距，提出了功能性等效的概念。", "motivation": "随着人工智能被用于支持软件开发团队，理解有效的人机合作变得至关重要。然而，目前的AI系统缺乏社会情感智能（SEI），这可能影响到人机之间的协作效率和满意度。", "method": "通过与10位实践者的半结构化访谈，研究探讨了他们如何将AI视为智力队友而非社交伙伴，并分析了他们在期望和社会情感智能方面对AI和人类团队成员的看法差异。", "result": "参与者认为当前的AI更像是智力上的帮助者而不是社交合作伙伴，并且他们对AI的社会情感特质持有较低的期待。然而，这种差距被识别为功能性缺失，即在责任协商、上下文适应性和持续伙伴关系维护方面的能力不足。", "conclusion": "有效的人机协作可能更多地依赖于技术能力的功能等效，而非完全复制人类的社会情感智能属性，这重新定义了人机合作中的功能对齐。"}}
{"id": "2601.19385", "pdf": "https://arxiv.org/pdf/2601.19385", "abs": "https://arxiv.org/abs/2601.19385", "authors": ["Pascal Jansen", "Julian Britten", "Mark Colley", "Markus Sasalovici", "Enrico Rukzio"], "title": "MIRAGE: Enabling Real-Time Automotive Mediated Reality", "categories": ["cs.HC"], "comment": "Conditionally accepted at CHI 2026", "summary": "Traffic is inherently dangerous, with around 1.19 million fatalities annually. Automotive Mediated Reality (AMR) can enhance driving safety by overlaying critical information (e.g., outlines, icons, text) on key objects to improve awareness, altering objects' appearance to simplify traffic situations, and diminishing their appearance to minimize distractions. However, real-world AMR evaluation remains limited due to technical challenges. To fill this sim-to-real gap, we present MIRAGE, an open-source tool that enables real-time AMR in real vehicles. MIRAGE implements 15 effects across the AMR spectrum of augmented, diminished, and modified reality using state-of-the-art computational models for object detection and segmentation, depth estimation, and inpainting. In an on-road expert user study (N=9) of MIRAGE, participants enjoyed the AMR experience while pointing out technical limitations and identifying use cases for AMR. We discuss these results in relation to prior work and outline implications for AMR ethics and interaction design.", "AI": {"tldr": "MIRAGE是一个开源工具，它可以在真实车辆上实现实时汽车增强现实（AMR），以提高驾驶安全性。", "motivation": "交通危险性高，每年约有119万人因交通事故丧生。汽车增强现实在提升交通安全方面具有潜力，但现实中进行评估的技术挑战使其发展受限。因此本文旨在开发一个能够在真实车辆上实现实时AMR的工具MIRAGE。", "method": "MIRAGE利用先进的计算模型（如对象检测与分割、深度估计和图像修补）实现了15种增强现实效果，并通过专家用户研究验证其在实际环境中的应用。", "result": "在专家用户研究中，参与者对AMR体验表示满意，并指出了技术限制并识别了AMR的使用案例。", "conclusion": "MIRAGE成功填补了模拟到真实世界评估的技术空白，为AMR伦理和交互设计提供了依据。"}}
{"id": "2601.19380", "pdf": "https://arxiv.org/pdf/2601.19380", "abs": "https://arxiv.org/abs/2601.19380", "authors": ["Fakrul Islam Tushar", "Joseph Y. Lo"], "title": "Tri-Reader: An Open-Access, Multi-Stage AI Pipeline for First-Pass Lung Nodule Annotation in Screening CT", "categories": ["cs.CV", "cs.AI"], "comment": "1 figure , 2 tables, 20 page supplement", "summary": "Using multiple open-access models trained on public datasets, we developed Tri-Reader, a comprehensive, freely available pipeline that integrates lung segmentation, nodule detection, and malignancy classification into a unified tri-stage workflow. The pipeline is designed to prioritize sensitivity while reducing the candidate burden for annotators. To ensure accuracy and generalizability across diverse practices, we evaluated Tri-Reader on multiple internal and external datasets as compared with expert annotations and dataset-provided reference standards.", "AI": {"tldr": "开发了一个用于肺结节标注的多阶段AI管道Tri-Reader。", "motivation": "提高早期肺癌筛查的效率和准确性，减少注释者的负担。", "method": "利用多个开源模型训练出一个集成肺部分割、结节检测和恶性分类的统一三阶段工作流程。", "result": "评估了Tri-Reader在多个内部和外部数据集上的性能，并与专家标注进行了比较。", "conclusion": "Tri-Reader能够在保持敏感性的同时，减少候选者的负担并提高注释精度。"}}
{"id": "2601.19378", "pdf": "https://arxiv.org/pdf/2601.19378", "abs": "https://arxiv.org/abs/2601.19378", "authors": ["Ziyang Xu", "Mingquan Lin", "Yiliang Zhou", "Zihan Xu", "Seth J. Orlow", "Zihan Xu", "Shane A. Meehan", "Alexandra Flamm", "Ata S. Moshiri", "Yifan Peng"], "title": "Establishing dermatopathology encyclopedia DermpathNet with Artificial Intelligence-Based Workflow", "categories": ["cs.CV"], "comment": "Accepted by Scientific Data", "summary": "Accessing high-quality, open-access dermatopathology image datasets for learning and cross-referencing is a common challenge for clinicians and dermatopathology trainees. To establish a comprehensive open-access dermatopathology dataset for educational, cross-referencing, and machine-learning purposes, we employed a hybrid workflow to curate and categorize images from the PubMed Central (PMC) repository. We used specific keywords to extract relevant images, and classified them using a novel hybrid method that combined deep learning-based image modality classification with figure caption analyses. Validation on 651 manually annotated images demonstrated the robustness of our workflow, with an F-score of 89.6\\% for the deep learning approach, 61.0\\% for the keyword-based retrieval method, and 90.4\\% for the hybrid approach. We retrieved over 7,772 images across 166 diagnoses and released this fully annotated dataset, reviewed by board-certified dermatopathologists. Using our dataset as a challenging task, we found the current image analysis algorithm from OpenAI inadequate for analyzing dermatopathology images. In conclusion, we have developed a large, peer-reviewed, open-access dermatopathology image dataset, DermpathNet, which features a semi-automated curation workflow.", "AI": {"tldr": "建立一个综合的开放访问皮肤病理图像数据集DermpathNet，用于教育、交叉参考和机器学习目的。", "motivation": "解决临床医生和皮肤病理学训练人员在获取高质量、开放访问的皮肤病理图像数据集方面的挑战。", "method": "利用混合工作流程从PubMed Central (PMC) 数据库中提取并分类相关图像，使用深度学习方法进行图像模式识别，并结合关键词检索和图注分析技术。", "result": "验证结果表明，深度学习方法获得了89.6%的F-score，关键词检索方法为61.0%，而混合方法达到90.4%，最终数据集包含超过7,772张图像，涵盖166种诊断类型，并由认证皮肤病理学家审核。", "conclusion": "开发了一个大型、同行评审和开放访问的皮肤病理学图像数据库DermpathNet，该数据库具有半自动化的整理工作流程。"}}
{"id": "2601.19376", "pdf": "https://arxiv.org/pdf/2601.19376", "abs": "https://arxiv.org/abs/2601.19376", "authors": ["Viacheslav Sydora", "Guner Dilsad Er", "Michael Muehlebach"], "title": "Teaching Machine Learning Fundamentals with LEGO Robotics", "categories": ["cs.RO", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "comment": "10 pages, 8 figures", "summary": "This paper presents the web-based platform Machine Learning with Bricks and an accompanying two-day course designed to teach machine learning concepts to students aged 12 to 17 through programming-free robotics activities. Machine Learning with Bricks is an open source platform and combines interactive visualizations with LEGO robotics to teach three core algorithms: KNN, linear regression, and Q-learning. Students learn by collecting data, training models, and interacting with robots via a web-based interface. Pre- and post-surveys with 14 students demonstrate significant improvements in conceptual understanding of machine learning algorithms, positive shifts in AI perception, high platform usability, and increased motivation for continued learning. This work demonstrates that tangible, visualization-based approaches can make machine learning concepts accessible and engaging for young learners while maintaining technical depth. The platform is freely available at https://learning-and-dynamics.github.io/ml-with-bricks/, with video tutorials guiding students through the experiments at https://youtube.com/playlist?list=PLx1grFu4zAcwfKKJZ1Ux4LwRqaePCOA2J.", "AI": {"tldr": "本文介绍了一种基于网络的平台Machine Learning with Bricks，通过LEGO机器人进行编程自由的教学活动来教授12至17岁学生机器学习的基本概念。", "motivation": "旨在提高年轻学生对机器学习算法的理解，并通过可视化和实体操作的方法使这些复杂的概念变得易于理解和吸引人。", "method": "开发了一个结合了互动可视化与LEGO机器人教育平台，用于教授KNN、线性回归和Q-learning三种核心算法。使用该平台收集数据并训练模型，通过一个网络界面与机器人进行交互。", "result": "经过14名学生的预测试和后测显示，在机器学习概念理解上有了显著提高，并且对AI的态度更加积极，同时也表明了高平台可用性和持续学习的动机增强。", "conclusion": "该研究证明了基于实体操作和可视化的方法可以在保持技术深度的同时使年轻学生能够理解和享受机器学习的概念。"}}
{"id": "2601.19375", "pdf": "https://arxiv.org/pdf/2601.19375", "abs": "https://arxiv.org/abs/2601.19375", "authors": ["Quy-Anh Dang", "Chris Ngo"], "title": "Selective Steering: Norm-Preserving Control Through Discriminative Layer Selection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite significant progress in alignment, large language models (LLMs) remain vulnerable to adversarial attacks that elicit harmful behaviors. Activation steering techniques offer a promising inference-time intervention approach, but existing methods suffer from critical limitations: activation addition requires careful coefficient tuning and is sensitive to layer-specific norm variations, while directional ablation provides only binary control. Recent work on Angular Steering introduces continuous control via rotation in a 2D subspace, but its practical implementation violates norm preservation, causing distribution shift and generation collapse, particularly in models below 7B parameters. We propose Selective Steering, which addresses these limitations through two key innovations: (1) a mathematically rigorous norm-preserving rotation formulation that maintains activation distribution integrity, and (2) discriminative layer selection that applies steering only where feature representations exhibit opposite-signed class alignment. Experiments across nine models demonstrate that Selective Steering achieves 5.5x higher attack success rates than prior methods while maintaining zero perplexity violations and approximately 100\\% capability retention on standard benchmarks. Our approach provides a principled, efficient framework for controllable and stable LLM behavior modification. Code: https://github.com/knoveleng/steering", "AI": {"tldr": "本文提出了一种名为Selective Steering的新方法，用于在大型语言模型中实现可控且稳定的激活方向调整。", "motivation": "现有技术在对抗攻击下易导致有害行为，而传统的激活控制方法存在系数调优难度大、敏感于层间差异等问题。因此，需要一种能够保持规范性并提供连续控制的新方法来改进这些问题。", "method": "Selective Steering通过两个主要创新解决了上述问题：（1）提出了一种数学上严格的保持规范性的旋转公式；（2）采用选择性分层技术，在特征表示中呈现相反符号类别对齐的层级上进行转向操作，从而提高了攻击成功率并维持了模型性能。", "result": "实验结果表明，Selective Steering能够在九个不同的模型上实现5.5倍于先前方法的攻击成功率，并且在保持零困惑度违反的同时达到了约100%的能力保留率。", "conclusion": "本文提出的方法提供了一种原则性强、效率高并且稳定的框架，用于控制和修改大型语言模型的行为。"}}
{"id": "2601.19365", "pdf": "https://arxiv.org/pdf/2601.19365", "abs": "https://arxiv.org/abs/2601.19365", "authors": ["Jinming Zhang", "Xi Yang", "Youpeng Yang", "Haosen Shi", "Yuyao Yan", "Qiufeng Wang", "Guangliang Cheng", "Kaizhu Huang"], "title": "Pareto-Guided Optimization for Uncertainty-Aware Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Uncertainty in medical image segmentation is inherently non-uniform, with boundary regions exhibiting substantially higher ambiguity than interior areas. Conventional training treats all pixels equally, leading to unstable optimization during early epochs when predictions are unreliable. We argue that this instability hinders convergence toward Pareto-optimal solutions and propose a region-wise curriculum strategy that prioritizes learning from certain regions and gradually incorporates uncertain ones, reducing gradient variance. Methodologically, we introduce a Pareto-consistent loss that balances trade-offs between regional uncertainties by adaptively reshaping the loss landscape and constraining convergence dynamics between interior and boundary regions; this guides the model toward Pareto-approximate solutions. To address boundary ambiguity, we further develop a fuzzy labeling mechanism that maintains binary confidence in non-boundary areas while enabling smooth transitions near boundaries, stabilizing gradients, and expanding flat regions in the loss surface. Experiments on brain metastasis and non-metastatic tumor segmentation show consistent improvements across multiple configurations, with our method outperforming traditional crisp-set approaches in all tumor subregions.", "AI": {"tldr": "提出了一种基于帕累托优化的不确定性感知医学图像分割方法，通过区域导向的学习策略和模糊标签机制来稳定训练过程并提高模型性能。", "motivation": "传统训练方式忽视了像素间不确定性的差异性，在早期阶段导致不稳定优化。为此，论文提出了一个分区域学习策略以及一种新的损失函数以平衡不同区域的不确定性。", "method": "引入了一种帕累托一致损失来调整损失地形图，并通过模糊标签机制在边界区实现平滑过渡。结合了区域导向的学习方式和改进后的损失函数，这种方法旨在引导模型向帕累托近似解收敛。", "result": "实验显示该方法能显著提升医学图像分割的准确性，在脑转移瘤等肿瘤区域的分割中表现出色，优于传统的硬标签方法。", "conclusion": "通过创新的方法学设计和策略应用，论文有效解决了医学图像分割中的不确定性问题，实现了更加稳定且高效的模型训练。"}}
{"id": "2601.19362", "pdf": "https://arxiv.org/pdf/2601.19362", "abs": "https://arxiv.org/abs/2601.19362", "authors": ["Xinyi Wan", "Penghui Qi", "Guangxing Huang", "Chaoyi Ruan", "Min Lin", "Jialin Li"], "title": "Revisiting Parameter Server in LLM Post-Training", "categories": ["cs.DC", "cs.AI"], "comment": "Accepted in ICLR'26", "summary": "Modern data parallel (DP) training favors collective communication over parameter servers (PS) for its simplicity and efficiency under balanced workloads. However, the balanced workload assumption no longer holds in large language model (LLM) post-training due to the high variance in sequence lengths. Under imbalanced workloads, collective communication creates synchronization barriers, leading to under-utilization of devices with smaller workloads. This change in training dynamics calls for a revisit of the PS paradigm for its robustness to such imbalance. We propose \\textbf{On-Demand Communication (ODC)}, which adapts PS into Fully Sharded Data Parallel (FSDP) by replacing collective all-gather and reduce-scatter with direct point-to-point communication. Compared to FSDP, ODC reduces the synchronization barrier from once per layer to once per minibatch and decouples the workload on each device so that faster workers are not stalled. It also enables simpler and more effective load balancing at the minibatch level. Across diverse LLM post-training tasks, ODC consistently improves device utilization and training throughput, achieving up to a 36\\% speedup over standard FSDP. These results demonstrate that ODC is a superior fit for the prevalent imbalanced workloads in LLM post-training. Our implementation of ODC and integration with FSDP is open-sourced at https://github.com/sail-sg/odc.", "AI": {"tldr": "研究提出一种适应大型语言模型后训练阶段不平衡工作负载的新型参数服务器方法On-Demand Communication (ODC)", "motivation": "现代数据并行训练偏好集体通信而非参数服务器，但在大型语言模型后训练阶段，序列长度差异大导致的工作负载不平衡使得集体通信效率低下", "method": "提出On-Demand Communication (ODC) 方法，通过点对点直接通信将参数服务器整合到全分片数据并行中，减少同步屏障次数，并使设备工作负载解耦以提高利用率", "result": "ODC在各种大型语言模型后训练任务上实现了更高的设备利用和训练吞吐量，相较于标准FSDP最多可获得36%的速度提升", "conclusion": "ODC方法针对大型语言模型后训练阶段的不平衡工作负载表现出更好的适应性和性能"}}
{"id": "2601.19354", "pdf": "https://arxiv.org/pdf/2601.19354", "abs": "https://arxiv.org/abs/2601.19354", "authors": ["Ziqian Wang", "Chenxi Fang", "Zhen Zhang"], "title": "Self-Supervised Path Planning in Unstructured Environments via Global-Guided Differentiable Hard Constraint Projection", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "Deploying deep learning agents for autonomous navigation in unstructured environments faces critical challenges regarding safety, data scarcity, and limited computational resources. Traditional solvers often suffer from high latency, while emerging learning-based approaches struggle to ensure deterministic feasibility. To bridge the gap from embodied to embedded intelligence, we propose a self-supervised framework incorporating a differentiable hard constraint projection layer for runtime assurance. To mitigate data scarcity, we construct a Global-Guided Artificial Potential Field (G-APF), which provides dense supervision signals without manual labeling. To enforce actuator limitations and geometric constraints efficiently, we employ an adaptive neural projection layer, which iteratively rectifies the coarse network output onto the feasible manifold. Extensive benchmarks on a test set of 20,000 scenarios demonstrate an 88.75\\% success rate, substantiating the enhanced operational safety. Closed-loop experiments in CARLA further validate the physical realizability of the planned paths under dynamic constraints. Furthermore, deployment verification on an NVIDIA Jetson Orin NX confirms an inference latency of 94 ms, showing real-time feasibility on resource-constrained embedded hardware. This framework offers a generalized paradigm for embedding physical laws into neural architectures, providing a viable direction for solving constrained optimization in mechatronics. Source code is available at: https://github.com/wzq-13/SSHC.git.", "AI": {"tldr": "本文提出了一种自监督框架，通过全局引导的人工势场和可微分硬约束投影层，在未结构化的环境中实现安全、高效的路径规划。", "motivation": "在未结构化环境中部署深度学习导航代理面临着关于安全性、数据稀缺性和计算资源有限的挑战。传统求解器通常存在高延迟，而新兴的学习方法难以保证确定性可行性。本文旨在通过自监督框架解决这些问题，并结合物理法则嵌入神经架构。", "method": "构建全局引导的人工势场（G-APF）以提供密集的监督信号；采用自适应神经投影层迭代修正网络输出至可行流形，确保执行器限制和几何约束的有效性。", "result": "实验显示该框架在20,000个测试场景中成功率为88.75%，且在CARLA中的闭环试验验证了其物理实现能力。部署于NVIDIA Jetson Orin NX上的推理延迟为94ms，证明其实时可行性。", "conclusion": "提出的自监督框架提供了一种将物理法则嵌入神经架构的通用范例，并展示了在机电学中解决约束优化问题的新途径"}}
{"id": "2601.19349", "pdf": "https://arxiv.org/pdf/2601.19349", "abs": "https://arxiv.org/abs/2601.19349", "authors": ["Chengxiang Guo", "Jian Wang", "Junhua Fei", "Xiao Li", "Chunling Chen", "Yun Jin"], "title": "AMGFormer: Adaptive Multi-Granular Transformer for Brain Tumor Segmentation with Missing Modalities", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Multimodal MRI is essential for brain tumor segmentation, yet missing modalities in clinical practice cause existing methods to exhibit >40% performance variance across modality combinations, rendering them clinically unreliable. We propose AMGFormer, achieving significantly improved stability through three synergistic modules: (1) QuadIntegrator Bridge (QIB) enabling spatially adaptive fusion maintaining consistent predictions regardless of available modalities, (2) Multi-Granular Attention Orchestrator (MGAO) focusing on pathological regions to reduce background sensitivity, and (3) Modality Quality-Aware Enhancement (MQAE) preventing error propagation from corrupted sequences. On BraTS 2018, our method achieves 89.33% WT, 82.70% TC, 67.23% ET Dice scores with <0.5% variance across 15 modality combinations, solving the stability crisis. Single-modality ET segmentation shows 40-81% relative improvements over state-of-the-art methods. The method generalizes to BraTS 2020/2021, achieving up to 92.44% WT, 89.91% TC, 84.57% ET. The model demonstrates potential for clinical deployment with 1.2s inference. Code: https://github.com/guochengxiangives/AMGFormer.", "AI": {"tldr": "AMGFormer是一种用于脑肿瘤分割的自适应多粒度Transformer，即使在缺少模态的情况下也能保持稳定性能。", "motivation": "临床实践中MRI模态缺失会导致现有方法表现不稳定，造成超过40%的性能差异。因此，研究者提出了一种新的方法来解决这个问题，并提高模型的稳定性与鲁棒性。", "method": "AMGFormer通过三个模块实现这一目标：QuadIntegrator Bridge（QIB）、Multi-Granular Attention Orchestrator（MGAO）和Modality Quality-Aware Enhancement（MQAE），以适应不同模态组合并减少背景干扰及错误传播。", "result": "在BraTS2018数据集上，AMGFormer实现了显著的性能提升，并且在15种不同的模态组合下保持了小于0.5%的方差。此外，在单模态分割任务中也取得了40-81％相对改进。", "conclusion": "该方法不仅在BraTS2018数据集上表现优异，还扩展到了BraTS2020/2021数据集中，并展示出高达92.44%的整体肿瘤分割精度。AMGFormer表现出色的稳定性与准确性使其具备潜在临床部署价值。"}}
{"id": "2601.19347", "pdf": "https://arxiv.org/pdf/2601.19347", "abs": "https://arxiv.org/abs/2601.19347", "authors": ["Yang Ouyang", "Shenghan Gao", "Ruichuan Wang", "Hailiang Zhu", "Yuheng Shao", "Xiaoyu Gu", "Quan Li"], "title": "CommSense: Facilitating Bias-Aware and Reflective Navigation of Online Comments for Rational Judgment", "categories": ["cs.HC"], "comment": "Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI '26), April 13--17, 2026, Barcelona, Spain", "summary": "Online comments significantly influence users' judgments, yet their presentation, often determined by platform algorithms, can introduce biases, such as anchoring effects, which distort reasoning. While existing research emphasizes mitigating individual cognitive biases, the evolution of user judgments during comment engagement remains overlooked. This study investigates how presentation cues impact reasoning and explores interface design strategies to mitigate bias. Through a preliminary experiment (N=18) and a co-design workshop, we identified key challenges users face across a four-stage process and distilled four design requirements: pre-engagement framing, interactive organization, reflective prompts, and synthesis support. Based on these insights, we developed CommSense, an on-the-fly plugin that enhances user engagement with online comments by providing visual overviews and lightweight prompts to guide reasoning. A between-subject evaluation (N=24) demonstrates that CommSense improves bias awareness and reflective thinking, helping users produce more comprehensive, evidence-based rationales while maintaining high usability.", "AI": {"tldr": "通过设计一种插件CommSense来帮助用户在浏览在线评论时意识到偏见并进行反思，从而做出更加合理和全面的判断。", "motivation": "平台算法决定了在线评论的展示方式，这可能导致锚定效应等偏差，影响用户的推理。当前研究主要关注减少个体认知偏差，但忽视了用户在整个互动过程中判断的变化过程。", "method": "通过初步实验（N=18）和共设计研讨会识别出用户在四阶段过程中面临的关键挑战，并提炼出四个设计要求：预参与框架、交互式组织、反思提示和支持综合。基于这些见解开发了CommSense，这是一种增强与在线评论互动的插件。", "result": "一项两组间评估（N=24）表明，CommSense提高了用户的偏见意识和反思性思考能力，帮助用户产生更全面且基于证据的理由，并保持高度可用性。", "conclusion": "通过提供视觉概览和支持推理的轻量级提示，CommSense有助于提高在线评论交互中的偏见意识和反思思维。"}}
{"id": "2601.19341", "pdf": "https://arxiv.org/pdf/2601.19341", "abs": "https://arxiv.org/abs/2601.19341", "authors": ["Xinran Xu", "Li Rong Wang", "Xiuyi Fan"], "title": "Robust Uncertainty Estimation under Distribution Shift via Difference Reconstruction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Estimating uncertainty in deep learning models is critical for reliable decision-making in high-stakes applications such as medical imaging. Prior research has established that the difference between an input sample and its reconstructed version produced by an auxiliary model can serve as a useful proxy for uncertainty. However, directly comparing reconstructions with the original input is degraded by information loss and sensitivity to superficial details, which limits its effectiveness. In this work, we propose Difference Reconstruction Uncertainty Estimation (DRUE), a method that mitigates this limitation by reconstructing inputs from two intermediate layers and measuring the discrepancy between their outputs as the uncertainty score. To evaluate uncertainty estimation in practice, we follow the widely used out-of-distribution (OOD) detection paradigm, where in-distribution (ID) training data are compared against datasets with increasing domain shift. Using glaucoma detection as the ID task, we demonstrate that DRUE consistently achieves superior AUC and AUPR across multiple OOD datasets, highlighting its robustness and reliability under distribution shift. This work provides a principled and effective framework for enhancing model reliability in uncertain environments.", "AI": {"tldr": "提出了一种差异重建不确定性估计（DRUE）方法，用于在分布偏移条件下提高深度学习模型的可靠性。", "motivation": "为了克服直接比较原始输入与重建版本时的信息丢失和对表面细节敏感性限制的挑战，提出了DRUE来改善不确定性的估计。", "method": "通过从两个中间层重建输入并测量它们输出之间的差异作为不确定性分数的方法，以此改进不确定性估计。", "result": "在使用青光眼检测作为内分布（ID）任务的情况下，在多个外分布数据集中显示了DRUE的优越AUC和AUPR表现，展示了其在分布偏移条件下的鲁棒性和可靠性。", "conclusion": "此研究提供了一种原则性且有效的方法框架来提高模型在不确定环境中的可靠性。"}}
{"id": "2601.19338", "pdf": "https://arxiv.org/pdf/2601.19338", "abs": "https://arxiv.org/abs/2601.19338", "authors": ["Zheng Yan", "Ru-Yuan Zhang"], "title": "The Psychological Science of Artificial Intelligence: A Rapidly Emerging Field of Psychology", "categories": ["cs.HC"], "comment": null, "summary": "The psychological science of artificial intelligence (AI) can be broadly defined as an emerging field of psychology that examines all AI-related mental and behavioral processes from the perspective of psychology. This field has been growing exponentially in the recent decade. This review synthesizes the existing literature on the psychological science of AI with a goal to provide a comprehensive conceptual framework for planning, conducting, and assessing scientific research in the field. It consists of six parts, starting with an overview of the entire field of the psychological science of artificial intelligence, then synthesizing the literature in each of the four specific areas (i.e., Psychology of designing AI, psychology of using AI, AI for examining psychological processes, and AI for advancing psychological methods), and concluding with an outlook on the field in the future.", "AI": {"tldr": "本文综述了人工智能的心理科学领域的现有文献，旨在为该领域制定一个全面的概念框架。", "motivation": "随着人工智能心理科学研究的快速发展，需要整合相关研究以提供统一的概念框架和未来展望。", "method": "通过概述整个心理学视角下的AI领域，并综合四个特定领域的文献（即设计AI的心理学、使用AI的心理学、利用AI检验心理过程以及提升心理方法）", "result": "提供了涵盖各个方面的全面概念框架，为未来的科学研究奠定了基础。", "conclusion": "该综述展示了人工智能心理科学领域的广阔前景和重要性，并指出了未来研究的方向。"}}
{"id": "2601.19337", "pdf": "https://arxiv.org/pdf/2601.19337", "abs": "https://arxiv.org/abs/2601.19337", "authors": ["Sayak Chowdhury", "Meenakshi D'Souza"], "title": "SETA: Statistical Fault Attribution for Compound AI Systems", "categories": ["cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to CAIN 2026 co-hosted with ICSE 2026", "summary": "Modern AI systems increasingly comprise multiple interconnected neural networks to tackle complex inference tasks. Testing such systems for robustness and safety entails significant challenges. Current state-of-the-art robustness testing techniques, whether black-box or white-box, have been proposed and implemented for single-network models and do not scale well to multi-network pipelines. We propose a modular robustness testing framework that applies a given set of perturbations to test data. Our testing framework supports (1) a component-wise system analysis to isolate errors and (2) reasoning about error propagation across the neural network modules. The testing framework is architecture and modality agnostic and can be applied across domains. We apply the framework to a real-world autonomous rail inspection system composed of multiple deep networks and successfully demonstrate how our approach enables fine-grained robustness analysis beyond conventional end-to-end metrics.", "AI": {"tldr": "提出了一种统计故障归因框架SETA，用于分析复杂的多神经网络系统", "motivation": "现有AI系统的鲁棒性测试技术主要针对单个模型，难以应用于包含多个神经网络的复杂系统。", "method": "通过在测试数据上应用一组扰动来实现组件级故障隔离和误差传播分析的方法。该方法是架构无关且领域通用的。", "result": "成功将SETA框架应用于实际的自主铁路检测系统，并展示了其能够进行细粒度鲁棒性分析的能力。", "conclusion": "提出的方法可以有效地解决多神经网络系统的复杂测试问题，提供更详细的故障信息和误差传播情况。"}}
{"id": "2601.19336", "pdf": "https://arxiv.org/pdf/2601.19336", "abs": "https://arxiv.org/abs/2601.19336", "authors": ["Zhao-Han Peng", "Shaohui Li", "Zhi Li", "Shulan Ruan", "Yu Liu", "You He"], "title": "From Observations to Events: Event-Aware World Model for Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "43 pages, accepted by ICLR 2026", "summary": "While model-based reinforcement learning (MBRL) improves sample efficiency by learning world models from raw observations, existing methods struggle to generalize across structurally similar scenes and remain vulnerable to spurious variations such as textures or color shifts. From a cognitive science perspective, humans segment continuous sensory streams into discrete events and rely on these key events for decision-making. Motivated by this principle, we propose the Event-Aware World Model (EAWM), a general framework that learns event-aware representations to streamline policy learning without requiring handcrafted labels. EAWM employs an automated event generator to derive events from raw observations and introduces a Generic Event Segmentor (GES) to identify event boundaries, which mark the start and end time of event segments. Through event prediction, the representation space is shaped to capture meaningful spatio-temporal transitions. Beyond this, we present a unified formulation of seemingly distinct world model architectures and show the broad applicability of our methods. Experiments on Atari 100K, Craftax 1M, and DeepMind Control 500K, DMC-GB2 500K demonstrate that EAWM consistently boosts the performance of strong MBRL baselines by 10%-45%, setting new state-of-the-art results across benchmarks. Our code is released at https://github.com/MarquisDarwin/EAWM.", "AI": {"tldr": "本文提出了事件感知世界模型（EAWM），一种通过自动从原始观测中生成事件来改进策略学习的框架。", "motivation": "现有的基于模型强化学习方法在处理结构相似场景和应对虚假变化时存在困难。受认知科学启发，人类将连续感官流分割成离散事件，并依赖这些关键事件进行决策。", "method": "EAWM使用自动化事件生成器从原始观测中提取事件，并引入通用事件分段器（GES）来识别事件边界。通过事件预测，表示空间被塑造以捕捉有意义的时空转换。", "result": "实验结果表明，EAWM在多个基准测试上显著提高了强基线方法的表现，性能提升了10%-45%，创造了新的最佳成绩。", "conclusion": "该研究证明了利用事件感知世界模型可以提高强化学习系统的样本效率和泛化能力。"}}
{"id": "2601.19334", "pdf": "https://arxiv.org/pdf/2601.19334", "abs": "https://arxiv.org/abs/2601.19334", "authors": ["Jianzhe Chai", "Yu Zhe", "Jun Sakuma"], "title": "When Benchmarks Leak: Inference-Time Decontamination for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Benchmark-based evaluation is the de facto standard for comparing large language models (LLMs). However, its reliability is increasingly threatened by test set contamination, where test samples or their close variants leak into training data and artificially inflate reported performance. To address this issue, prior work has explored two main lines of mitigation. One line attempts to identify and remove contaminated benchmark items before evaluation, but this inevitably alters the evaluation set itself and becomes unreliable when contamination is moderate or severe. The other line preserves the benchmark and instead suppresses contaminated behavior at evaluation time; however, such interventions often interfere with normal inference and lead to noticeable performance degradation on clean inputs. We propose DeconIEP, a decontamination framework that operates entirely during evaluation by applying small, bounded perturbations in the input embedding space. Guided by a relatively less-contaminated reference model, DeconIEP learns an instance-adaptive perturbation generator that steers the evaluated model away from memorization-driven shortcut pathways. Across multiple open-weight LLMs and benchmarks, extensive empirical results show that DeconIEP achieves strong decontamination effectiveness while incurring only minimal degradation in benign utility.", "AI": {"tldr": "提出了一种名为DeconIEP的框架，旨在通过在评估阶段对输入嵌入空间进行小的、有界扰动来消除大型语言模型中的测试集污染问题。", "motivation": "当前基于基准的评估方法可靠性受到威胁，因为测试样本或其变体可能泄露到训练数据中，导致性能表现被人为夸大。现有的解决策略在实际应用中存在局限性：一种是移除污染样本但会改变评估集合；另一种是在评估阶段抑制污染行为，但这可能会干扰正常推理并降低清洁输入的性能。", "method": "DeconIEP框架通过利用相对较少受到污染的参考模型引导实例适应性的扰动生成器来工作。这个扰动生成器会在输入嵌入空间中对被评价模型进行小而有界的扰动，使其远离记忆驱动的捷径路径。", "result": "实验结果表明，在多个开放权重大型语言模型和基准测试上，DeconIEP框架能够实现强大的去污染效果同时仅产生轻微的性能损失。", "conclusion": "该论文提出了一种新的方法来解决大型语言模型中的测试集污染问题，并证明了其有效性和可行性。"}}
{"id": "2601.19333", "pdf": "https://arxiv.org/pdf/2601.19333", "abs": "https://arxiv.org/abs/2601.19333", "authors": ["Rahul Raychaudhury", "Aryan Esmailpour", "Sainyam Galhotra", "Stavros Sintos"], "title": "Metric $k$-clustering using only Weak Comparison Oracles", "categories": ["cs.LG", "cs.DS"], "comment": "ef:ICLR 2026", "summary": "Clustering is a fundamental primitive in unsupervised learning. However, classical algorithms for $k$-clustering (such as $k$-median and $k$-means) assume access to exact pairwise distances -- an unrealistic requirement in many modern applications. We study clustering in the \\emph{Rank-model (R-model)}, where access to distances is entirely replaced by a \\emph{quadruplet oracle} that provides only relative distance comparisons. In practice, such an oracle can represent learned models or human feedback, and is expected to be noisy and entail an access cost. Given a metric space with $n$ input items, we design randomized algorithms that, using only a noisy quadruplet oracle, compute a set of $O(k \\cdot \\mathsf{polylog}(n))$ centers along with a mapping from the input items to the centers such that the clustering cost of the mapping is at most constant times the optimum $k$-clustering cost. Our method achieves a query complexity of $O(n\\cdot k \\cdot \\mathsf{polylog}(n))$ for arbitrary metric spaces and improves to $O((n+k^2) \\cdot \\mathsf{polylog}(n))$ when the underlying metric has bounded doubling dimension. When the metric has bounded doubling dimension we can further improve the approximation from constant to $1+\\varepsilon$, for any arbitrarily small constant $\\varepsilon\\in(0,1)$, while preserving the same asymptotic query complexity. Our framework demonstrates how noisy, low-cost oracles, such as those derived from large language models, can be systematically integrated into scalable clustering algorithms.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.19332", "pdf": "https://arxiv.org/pdf/2601.19332", "abs": "https://arxiv.org/abs/2601.19332", "authors": ["Yang Ouyang", "Yuansong Xu", "Chang Jiang", "Yifan Jin", "Haoran Jiang", "Quan Li"], "title": "CaseMaster: Designing and Evaluating a Probe for Oral Case Presentation Training with LLM Assistance", "categories": ["cs.HC"], "comment": "Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI '26), April 13--17, 2026, Barcelona, Spain", "summary": "Preparing an oral case presentation (OCP) is a crucial skill for medical students, requiring clear communication of patient information, clinical findings, and treatment plans. However, inconsistent student participation and limited guidance can make this task challenging. While Large Language Models (LLMs) can provide structured content to streamline the process, their role in facilitating skill development and supporting medical education integration remains underexplored. To address this, we conducted a formative study with six medical educators and developed CaseMaster, an interactive probe that leverages LLM-generated content tailored to medical education to help users enhance their OCP skills. The controlled study suggests CaseMaster has the potential to both improve presentation quality and reduce workload compared to traditional methods, an implication reinforced by expert feedback. We propose guidelines for educators to develop adaptive, user-centered training methods using LLMs, while considering the implications of integrating advanced technologies into medical education.", "AI": {"tldr": "设计并评估了一个利用大型语言模型帮助学生进行口头病例报告训练的互动工具CaseMaster。", "motivation": "医学学生的口头案例报告技能对于清晰传达患者信息、临床发现和治疗计划至关重要，但由于参与不一致和指导有限，这项任务具有挑战性。大型语言模型可以提供结构化内容以简化过程，但它们在促进技能培训和支持医学教育集成中的作用尚未被充分探索。", "method": "通过与六位医学教育者进行的形成性研究开发了CaseMaster，这是一个利用LLM生成的内容来帮助用户提高口头案例报告技能的互动探针。进行了对照研究，以评估其相对于传统方法在提升呈现质量和支持教学方面的能力。", "result": "研究表明，CaseMaster有可能提高展示的质量并减少工作量，并得到专家反馈的支持。", "conclusion": "提出了一些建议供教育者使用LLM开发适应性强、用户导向的培训方法，并考虑将高级技术集成到医学教育中的影响。"}}
{"id": "2601.19325", "pdf": "https://arxiv.org/pdf/2601.19325", "abs": "https://arxiv.org/abs/2601.19325", "authors": ["Zichen Wen", "Boxue Yang", "Shuang Chen", "Yaojie Zhang", "Yuhang Han", "Junlong Ke", "Cong Wang", "Yicheng Fu", "Jiawang Zhao", "Jiangchao Yao", "Xi Fang", "Zhen Wang", "Henxing Cai", "Lin Yao", "Zhifeng Gao", "Yanhui Hong", "Nang Yuan", "Yixuan Li", "Guojiang Zhao", "Haoyi Tao", "Nan Wang", "Han Lyu", "Guolin Ke", "Ning Liao", "Xiaoxing Wang", "et al. (9 additional authors not shown)"], "title": "Innovator-VL: A Multimodal Large Language Model for Scientific Discovery", "categories": ["cs.CV", "cs.AI"], "comment": "Innovator-VL tech report", "summary": "We present Innovator-VL, a scientific multimodal large language model designed to advance understanding and reasoning across diverse scientific domains while maintaining excellent performance on general vision tasks. Contrary to the trend of relying on massive domain-specific pretraining and opaque pipelines, our work demonstrates that principled training design and transparent methodology can yield strong scientific intelligence with substantially reduced data requirements. (i) First, we provide a fully transparent, end-to-end reproducible training pipeline, covering data collection, cleaning, preprocessing, supervised fine-tuning, reinforcement learning, and evaluation, along with detailed optimization recipes. This facilitates systematic extension by the community. (ii) Second, Innovator-VL exhibits remarkable data efficiency, achieving competitive performance on various scientific tasks using fewer than five million curated samples without large-scale pretraining. These results highlight that effective reasoning can be achieved through principled data selection rather than indiscriminate scaling. (iii) Third, Innovator-VL demonstrates strong generalization, achieving competitive performance on general vision, multimodal reasoning, and scientific benchmarks. This indicates that scientific alignment can be integrated into a unified model without compromising general-purpose capabilities. Our practices suggest that efficient, reproducible, and high-performing scientific multimodal models can be built even without large-scale data, providing a practical foundation for future research.", "AI": {"tldr": "创新者-VL是一种用于科学发现的多模态大语言模型，旨在通过减少数据需求提高跨学科理解和推理能力。", "motivation": "该研究反驳了大规模领域特定预训练和不透明管道的趋势，证明有原则的设计和透明的方法可以产生强大的科学智能，并且大大减少了数据需求。", "method": "创新者-VL提供了一个全面透明的、端到端可重复的训练流水线，涵盖数据收集、清理、预处理、监督微调、强化学习以及评估，同时还提供了详细的优化配方。此外，它使用精选样本实现了卓越的数据效率，并展示了强大的泛化能力。", "result": "创新者-VL在各种科学任务中表现出色，使用不足五百万的精心挑选样本达到了竞争水平的表现；同时，它在通用视觉、多模态推理和科学基准测试上也取得了有竞争力的结果。这些成果表明有效推理可以通过原则性的数据选择实现，而不是不加区分地扩大规模。", "conclusion": "该研究展示了即使没有大规模数据集，也可以构建高效、可重复且高性能的科学多模态模型，为未来的科学研究提供了一个实用的基础。"}}
{"id": "2601.19320", "pdf": "https://arxiv.org/pdf/2601.19320", "abs": "https://arxiv.org/abs/2601.19320", "authors": ["Tianyi Chen", "Sihan Chen", "Xiaoyi Qu", "Dan Zhao", "Ruomei Yan", "Jongwoo Ko", "Luming Liang", "Pashmina Cameron"], "title": "StableQAT: Stable Quantization-Aware Training at Ultra-Low Bitwidths", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Quantization-aware training (QAT) is essential for deploying large models under strict memory and latency constraints, yet achieving stable and robust optimization at ultra-low bitwidths remains challenging. Common approaches based on the straight-through estimator (STE) or soft quantizers often suffer from gradient mismatch, instability, or high computational overhead. As such, we propose StableQAT, a unified and efficient QAT framework that stabilizes training in ultra low-bit settings via a novel, lightweight, and theoretically grounded surrogate for backpropagation derived from a discrete Fourier analysis of the rounding operator. StableQAT strictly generalizes STE as the latter arises as a special case of our more expressive surrogate family, yielding smooth, bounded, and inexpensive gradients that improve QAT training performance and stability across various hyperparameter choices. In experiments, StableQAT exhibits stable and efficient QAT at 2-4 bit regimes, demonstrating improved training stability, robustness, and superior performance with negligible training overhead against standard QAT techniques. Our code is available at https://github.com/microsoft/StableQAT.", "AI": {"tldr": "本文提出了一种在超低位宽设置下稳定量化感知训练（QAT）的新框架StableQAT。", "motivation": "实现稳定的和鲁棒的量化感知训练以支持大型模型部署，尤其是在严格的内存和延迟约束下的超低位宽环境中面临挑战。传统方法如直通估计器(STE)或软量化器在梯度匹配、稳定性和计算开销方面存在不足。", "method": "通过离散傅里叶分析对舍入操作进行理论研究并提出一种轻量级且基于理论的新代理，用于替代传统的直通估计器，以提升超低位宽设置下的训练稳定性。", "result": "实验表明StableQAT在2-4位的量化感知训练中表现出稳定的性能、鲁棒性和优越的效率，在各种超参数选择下优于标准QAT技术且训练开销几乎可以忽略不计。", "conclusion": "本文提出的StableQAT框架能够有效解决传统方法在超低位宽设置下的问题，提供了一种更加稳定和高效的量化感知训练方案。"}}
{"id": "2601.19318", "pdf": "https://arxiv.org/pdf/2601.19318", "abs": "https://arxiv.org/abs/2601.19318", "authors": ["Venkatakrishna Reddy Oruganti"], "title": "Perception-to-Pursuit: Track-Centric Temporal Reasoning for Open-World Drone Detection and Autonomous Chasing", "categories": ["cs.RO", "cs.CV"], "comment": "7 pages, 2 figures, 3 tables, 15 references. Intended for submission to ICCV 2027", "summary": "Autonomous drone pursuit requires not only detecting drones but also predicting their trajectories in a manner that enables kinematically feasible interception. Existing tracking methods optimize for prediction accuracy but ignore pursuit feasibility, resulting in trajectories that are physically impossible to intercept 99.9% of the time. We propose Perception-to-Pursuit (P2P), a track-centric temporal reasoning framework that bridges detection and actionable pursuit planning. Our method represents drone motion as compact 8-dimensional tokens capturing velocity, acceleration, scale, and smoothness, enabling a 12-frame causal transformer to reason about future behavior. We introduce the Intercept Success Rate (ISR) metric to measure pursuit feasibility under realistic interceptor constraints. Evaluated on the Anti-UAV-RGBT dataset with 226 real drone sequences, P2P achieves 28.12 pixel average displacement error and 0.597 ISR, representing a 77% improvement in trajectory prediction and 597x improvement in pursuit feasibility over tracking-only baselines, while maintaining perfect drone classification accuracy (100%). Our work demonstrates that temporal reasoning over motion patterns enables both accurate prediction and actionable pursuit planning.", "AI": {"tldr": "提出了一种面向无人机追踪和自主追逐的感知至追求（P2P）框架，该框架通过紧凑的8维代币表示无人机运动，并采用因果变换器进行未来行为推理。", "motivation": "当前跟踪方法侧重于预测准确度而忽视了追击可行性，导致轨迹大多在物理上无法拦截。因此，需要一种新的方法来解决这个问题。", "method": "将无人机运动表示为包含速度、加速度、缩放和光滑度的8维代币，并使用因果变换器进行未来行为推理。引入拦截成功率（ISR）指标以衡量追击可行性。", "result": "在Anti-UAV-RGBT数据集上，P2P框架实现了0.597 ISR，比仅跟踪基准提高了597倍的追击可行性，同时保持了100%的无人机分类准确率。", "conclusion": "研究表明，对运动模式进行时间推理不仅可以实现精确预测，还可以提供可操作的追击规划。"}}
{"id": "2601.19314", "pdf": "https://arxiv.org/pdf/2601.19314", "abs": "https://arxiv.org/abs/2601.19314", "authors": ["Chen-Chou Lo", "Patrick Vandewalle"], "title": "Instance-Guided Radar Depth Estimation for 3D Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to IPMV2026", "summary": "Accurate depth estimation is fundamental to 3D perception in autonomous driving, supporting tasks such as detection, tracking, and motion planning. However, monocular camera-based 3D detection suffers from depth ambiguity and reduced robustness under challenging conditions. Radar provides complementary advantages such as resilience to poor lighting and adverse weather, but its sparsity and low resolution limit its direct use in detection frameworks. This motivates the need for effective Radar-camera fusion with improved preprocessing and depth estimation strategies. We propose an end-to-end framework that enhances monocular 3D object detection through two key components. First, we introduce InstaRadar, an instance segmentation-guided expansion method that leverages pre-trained segmentation masks to enhance Radar density and semantic alignment, producing a more structured representation. InstaRadar achieves state-of-the-art results in Radar-guided depth estimation, showing its effectiveness in generating high-quality depth features. Second, we integrate the pre-trained RCDPT into the BEVDepth framework as a replacement for its depth module. With InstaRadar-enhanced inputs, the RCDPT integration consistently improves 3D detection performance. Overall, these components yield steady gains over the baseline BEVDepth model, demonstrating the effectiveness of InstaRadar and the advantage of explicit depth supervision in 3D object detection. Although the framework lags behind Radar-camera fusion models that directly extract BEV features, since Radar serves only as guidance rather than an independent feature stream, this limitation highlights potential for improvement. Future work will extend InstaRadar to point cloud-like representations and integrate a dedicated Radar branch with temporal cues for enhanced BEV fusion.", "AI": {"tldr": "论文提出了一种通过雷达和相机融合来改善单目3D目标检测的方法，具体包括两个关键组件：InstaRadar和改进的BEVDepth框架。", "motivation": "在恶劣条件下，基于单目摄像头的3D检测面临深度模糊和鲁棒性降低的问题。雷达因其对不良光照和天气条件具有较强适应性而提供互补优势，但其稀疏性和低分辨率限制了直接应用于检测框架中。因此需要有效的雷达-相机融合策略来提高预处理和深度估计。", "method": "论文提出了一种端到端的框架以增强单目3D物体检测，包含两个关键组件：InstaRadar（实例分割引导扩展方法）和改进的BEVDepth框架。其中，InstaRadar利用预先训练好的分割掩码来提升雷达密度和语义对齐；同时将预训练的RCDPT集成到BEVDepth框架中替代其深度模块。", "result": "该方案在雷达辅助深度估计任务上达到了最先进的水平，并且通过使用改进后的输入，与基准模型相比，在3D检测性能方面取得了稳定的提升。", "conclusion": "尽管所提出的框架在雷达-相机融合模型中的表现略逊于直接提取BEV特征的方法，但未来的工作将致力于扩展InstaRadar以产生类似点云的表示，并整合专门用于增强BEV融合的雷达分支和时间线索。"}}
{"id": "2601.19311", "pdf": "https://arxiv.org/pdf/2601.19311", "abs": "https://arxiv.org/abs/2601.19311", "authors": ["Anh Khoa Ngo Ho", "Martin Chauvin", "Simon Gosset", "Philippe Cordier", "Boris Gamazaychikov"], "title": "Balancing Sustainability And Performance: The Role Of Small-Scale Llms In Agentic Artificial Intelligence Systems", "categories": ["cs.AI"], "comment": null, "summary": "As large language models become integral to agentic artificial intelligence systems, their energy demands during inference may pose significant sustainability challenges. This study investigates whether deploying smaller-scale language models can reduce energy consumption without compromising responsiveness and output quality in a multi-agent, real-world environments. We conduct a comparative analysis across language models of varying scales to quantify trade-offs between efficiency and performance. Results show that smaller open-weights models can lower energy usage while preserving task quality. Building on these findings, we propose practical guidelines for sustainable artificial intelligence design, including optimal batch size configuration and computation resource allocation. These insights offer actionable strategies for developing scalable, environmentally responsible artificial intelligence systems.", "AI": {"tldr": "研究探讨了在多代理现实环境中，使用小型语言模型是否可以在不影响响应性和输出质量的情况下降低大型语言模型的能耗。", "motivation": "随着大规模语言模型成为具身人工智能系统的重要组成部分，其推理过程中的能源需求可能带来显著的可持续性挑战。本研究旨在探索部署较小规模的语言模型能否在减少能量消耗的同时保持任务的质量。", "method": "通过对比不同规模的语言模型进行分析以量化效率与性能之间的权衡关系。", "result": "研究表明，使用小规模开放权重语言模型可以降低能耗并维持任务质量。", "conclusion": "基于这些发现，研究提出了可持续人工智能设计的实用指南，包括最佳批次大小配置和计算资源分配策略。这为开发可扩展且环保的人工智能系统提供了实际策略。"}}
{"id": "2601.19310", "pdf": "https://arxiv.org/pdf/2601.19310", "abs": "https://arxiv.org/abs/2601.19310", "authors": ["Yuqi Tong", "Ruiyang Li", "Chengkun Li", "Qixuan Liu", "Shi Qiu", "Pheng-Ann Heng"], "title": "ClipGS-VR: Immersive and Interactive Cinematic Visualization of Volumetric Medical Data in Mobile Virtual Reality", "categories": ["cs.GR", "cs.HC"], "comment": "IEEE VR 2026 Posters", "summary": "High-fidelity cinematic medical visualization on mobile virtual reality (VR) remains challenging. Although ClipGS enables cross-sectional exploration via 3D Gaussian Splatting, it lacks arbitrary-angle slicing on consumer-grade VR headsets. To achieve real-time interactive performance, we introduce ClipGS-VR and restructure ClipGS's neural inference into a consolidated dataset, integrating high-fidelity layers from multiple pre-computed slicing states into a unified rendering structure. Our framework further supports arbitrary-angle slicing via gradient-based opacity modulation for smooth, visually coherent rendering. Evaluations confirm our approach maintains visual fidelity comparable to offline results while offering superior usability and interaction efficiency.", "AI": {"tldr": "本文提出了一种在移动虚拟现实设备上实现高保真度、交互式医学数据可视化的方法ClipGS-VR。", "motivation": "现有的医疗可视化技术难以实现在消费级VR头显上的任意角度切片，且缺乏实时互动性能。", "method": "通过将神经推断重组为一个整合的数据集，并使用基于梯度的不透明度调节来支持任意角度切割，以实现高保真层与多个预计算切片状态的一致渲染结构。", "result": "实验表明该方法能保持视觉上的保真度与离线结果相当的同时提供更好的用户友好性和交互效率。", "conclusion": "ClipGS-VR在移动虚拟现实设备上实现了医学数据的高保真、互动可视化，具有重要的应用价值。"}}
{"id": "2601.19309", "pdf": "https://arxiv.org/pdf/2601.19309", "abs": "https://arxiv.org/abs/2601.19309", "authors": ["Tailong Luo", "Jiesong Bai", "Jinyang Huang", "Junyu Xia", "Wangyu Wu", "Xuhang Chen"], "title": "Beyond Shadows: A Large-Scale Benchmark and Multi-Stage Framework for High-Fidelity Facial Shadow Removal", "categories": ["cs.CV"], "comment": "Accepted by ICASSP2026", "summary": "Facial shadows often degrade image quality and the performance of vision algorithms. Existing methods struggle to remove shadows while preserving texture, especially under complex lighting conditions, and they lack real-world paired datasets for training. We present the Augmented Shadow Face in the Wild (ASFW) dataset, the first large-scale real-world dataset for facial shadow removal, containing 1,081 paired shadow and shadow-free images created via a professional Photoshop workflow. ASFW offers photorealistic shadow variations and accurate ground truths, bridging the gap between synthetic and real domains. Deep models trained on ASFW demonstrate improved shadow removal in real-world conditions. We also introduce the Face Shadow Eraser (FSE) method to showcase the effectiveness of the dataset. Experiments demonstrate that ASFW enhances the performance of facial shadow removal models, setting new standards for this task.", "AI": {"tldr": "本文提出了一种新的大规模真实世界面部阴影移除数据集ASFW以及一种有效的面部阴影移除方法FSE，以提升在复杂光照条件下的图像质量。", "motivation": "现有的面部阴影移除技术难以在保留纹理的同时消除阴影，并且缺乏真实配对的训练数据集。为解决这些问题，作者创建了包含1081对带有和无阴影的真实世界图像的数据集ASFW。", "method": "通过专业的Photoshop工作流程生成大型真实世界的面部阴影移除数据集ASFW；并引入了一种名为Face Shadow Eraser (FSE)的方法来展示数据集的有效性。", "result": "实验显示，使用ASFW进行训练的深度模型在现实世界条件下表现出色，并且提高了面部阴影去除技术的标准。", "conclusion": "新的数据集和方法为解决面部阴影移除问题提供了有效的解决方案，并促进了该领域的发展。"}}
{"id": "2601.19306", "pdf": "https://arxiv.org/pdf/2601.19306", "abs": "https://arxiv.org/abs/2601.19306", "authors": ["Sijia Li", "Xiaoyu Tan", "Shahir Ali", "Niels Schmidt", "Gengchen Ma", "Xihe Qiu"], "title": "Curiosity Driven Knowledge Retrieval for Mobile Agents", "categories": ["cs.AI"], "comment": null, "summary": "Mobile agents have made progress toward reliable smartphone automation, yet performance in complex applications remains limited by incomplete knowledge and weak generalization to unseen environments. We introduce a curiosity driven knowledge retrieval framework that formalizes uncertainty during execution as a curiosity score. When this score exceeds a threshold, the system retrieves external information from documentation, code repositories, and historical trajectories. Retrieved content is organized into structured AppCards, which encode functional semantics, parameter conventions, interface mappings, and interaction patterns. During execution, an enhanced agent selectively integrates relevant AppCards into its reasoning process, thereby compensating for knowledge blind spots and improving planning reliability. Evaluation on the AndroidWorld benchmark shows consistent improvements across backbones, with an average gain of six percentage points and a new state of the art success rate of 88.8\\% when combined with GPT-5. Analysis indicates that AppCards are particularly effective for multi step and cross application tasks, while improvements depend on the backbone model. Case studies further confirm that AppCards reduce ambiguity, shorten exploration, and support stable execution trajectories. Task trajectories are publicly available at https://lisalsj.github.io/Droidrun-appcard/.", "AI": {"tldr": "提出了一种基于好奇心驱动的知识检索框架，以提高移动代理在智能手机自动化中的性能。", "motivation": "为了克服由于知识不完整和对未见过环境的泛化能力较弱而导致的表现不足问题，引入了好奇性驱动的知识检索机制来增强移动代理的能力。", "method": "通过将执行过程中的不确定性形式化为好奇心分数，并在该分数超过阈值时从文档、代码库及历史轨迹中检索外部信息。这些内容被组织成结构化的AppCards以编码功能语义和交互模式等，然后在运行过程中整合到代理的推理过程中。", "result": "通过AndroidWorld基准测试，在与GPT-5结合使用时取得了88.8%的成功率的新最先进水平，并平均提高了6个百分点。实验表明，对于多步骤跨应用任务，AppCards特别有效且依赖于基础模型。", "conclusion": "AppCards减少了模糊性、缩短了探索时间并支持稳定的执行轨迹，从而改善了移动代理的性能和稳定性。"}}
{"id": "2601.19304", "pdf": "https://arxiv.org/pdf/2601.19304", "abs": "https://arxiv.org/abs/2601.19304", "authors": ["Sneha Shashidhara", "Vivienne Bihe Chi", "Abhay P Singh", "Lyle Ungar", "Sharath Chandra Guntuku"], "title": "Voice-Based Chatbots for English Speaking Practice in Multilingual Low-Resource Indian Schools: A Multi-Stakeholder Study", "categories": ["cs.HC"], "comment": null, "summary": "Spoken English proficiency is a powerful driver of economic mobility for low-income Indian youth, yet opportunities for spoken practice remain scarce in schools. We investigate the deployment of a voice-based chatbot for English conversation practice across four low-resource schools in Delhi. Through a six-day field study combining observations and interviews, we captured the perspectives of students, teachers, and principals. Findings confirm high demand across all groups, with notable gains in student speaking confidence. Our multi-stakeholder analysis surfaced a tension in long-term adoption vision: students favored open-ended conversational practice, while administrators emphasized curriculum-aligned assessment. We offer design recommendations for voice-enabled chatbots in low-resource multilingual contexts, highlighting the need for more intelligible speech output for non-native learners, one-tap interactions with simplified interfaces, and actionable analytics for educators. Beyond language learning, our findings inform the co-design of future AI-based educational technologies that are socially sustainable within the complex ecosystem of low-resource schools.", "AI": {"tldr": "研究探讨了在印度德里四所低资源学校部署语音聊天机器人用于英语口语练习的效果。", "motivation": "提高低收入印度青年的英语流利度对于经济流动性至关重要，但学校中缺乏实践机会。本研究旨在调查语音聊天机器人的效果，并收集不同利益相关者的反馈。", "method": "通过为期六天的实地研究，包括观察和访谈学生、教师及校长，研究团队捕捉到了各方的观点与需求。", "result": "研究表明所有参与者对该项目的需求都很高，学生的口语自信度有所提高。然而，在长期采用愿景方面存在分歧：学生偏好开放式的对话练习，而管理人员则更注重与课程内容一致的评估。", "conclusion": "该研究提出了针对低资源多语言环境中的语音聊天机器人的设计建议，并强调了为非母语学习者提供清晰语音输出、简化界面和教师可用的数据分析的重要性。此外，这些发现还为未来在复杂教育生态系统中可持续发展的AI技术提供了参考。"}}
{"id": "2601.19303", "pdf": "https://arxiv.org/pdf/2601.19303", "abs": "https://arxiv.org/abs/2601.19303", "authors": ["Shi Qiu", "Ruiyang Li", "Qixuan Liu", "Yuqi Tong", "Yue Qiu", "Yinqiao Wang", "Yan Li", "Chi-Wing Fu", "Pheng-Ann Heng"], "title": "A Collaborative Extended Reality Prototype for 3D Surgical Planning and Visualization", "categories": ["cs.HC", "cs.GR", "cs.MM"], "comment": "IEEE VR 2026 Posters", "summary": "We present a collaborative extended reality (XR) prototype for 3D surgical planning and visualization. Our system consists of three key modules: XR-based immersive surgical planning, cloud-based data management, and coordinated stereoscopic 3D displays for interactive visualization. We describe the overall workflow, core functionalities, implementations and setups. By conducting user studies on a liver resection surgical planning case, we demonstrate the effectiveness of our prototype and provide practical insights to inspire future advances in medical XR collaboration.", "AI": {"tldr": "介绍了一种用于3D手术计划和可视化协作扩展现实（XR）原型", "motivation": "提升手术规划的精确性和效率，通过增强现实技术改善医疗协作", "method": "开发了一个包含沉浸式手术规划、云数据管理和交互式三维显示三个关键模块的系统，并进行了用户研究以验证其效果", "result": "在肝切除手术计划案例中展示了系统的有效性并提供了实用见解", "conclusion": "该原型证明了在医学XR协作中的潜力，为未来的发展提供了实践启发"}}
{"id": "2601.19297", "pdf": "https://arxiv.org/pdf/2601.19297", "abs": "https://arxiv.org/abs/2601.19297", "authors": ["Karl Schrader", "Shoichi Koyama", "Tomohiko Nakamura", "Mirco Pezzoli"], "title": "Phase-Retrieval-Based Physics-Informed Neural Networks For Acoustic Magnitude Field Reconstruction", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted to International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2026", "summary": "We propose a method for estimating the magnitude distribution of an acoustic field from spatially sparse magnitude measurements. Such a method is useful when phase measurements are unreliable or inaccessible. Physics-informed neural networks (PINNs) have shown promise for sound field estimation by incorporating constraints derived from governing partial differential equations (PDEs) into neural networks. However, they do not extend to settings where phase measurements are unavailable, as the loss function based on the governing PDE relies on phase information. To remedy this, we propose a phase-retrieval-based PINN for magnitude field estimation. By representing the magnitude and phase distributions with separate networks, the PDE loss can be computed based on the reconstructed complex amplitude. We demonstrate the effectiveness of our phase-retrieval-based PINN through experimental evaluation.", "AI": {"tldr": "提出了一种基于物理信息神经网络的声场幅度重建方法，用于从稀疏测量中估计声场幅度分布。", "motivation": "当相位测量不可靠或无法获取时，需要一种仅依赖于幅度信息的方法来估计声场。传统的物理信息神经网络（PINNs）依赖于包含相位信息的损失函数，不适用于缺少相位数据的情况。", "method": "通过使用两个独立的网络分别表示幅度和相位分布，并基于重建的复振幅计算PDE损失，提出了一种相位恢复为基础的PINN方法来估计声场幅度。", "result": "实验评估证明了所提出的基于相位恢复的PINN的有效性。", "conclusion": "这种方法为声学领域中缺少相位信息的情况提供了一个有效的解决方案。"}}
{"id": "2601.19295", "pdf": "https://arxiv.org/pdf/2601.19295", "abs": "https://arxiv.org/abs/2601.19295", "authors": ["Yingtie Lei", "Zimeng Li", "Chi-Man Pun", "Wangyu Wu", "Junke Yang", "Xuhang Chen"], "title": "ProMist-5K: A Comprehensive Dataset for Digital Emulation of Cinematic Pro-Mist Filter Effects", "categories": ["cs.CV"], "comment": "Accepted by ICASSP2026", "summary": "Pro-Mist filters are widely used in cinematography for their ability to create soft halation, lower contrast, and produce a distinctive, atmospheric style. These effects are difficult to reproduce digitally due to the complex behavior of light diffusion. We present ProMist-5K, a dataset designed to support cinematic style emulation. It is built using a physically inspired pipeline in a scene-referred linear space and includes 20,000 high-resolution image pairs across four configurations, covering two filter densities (1/2 and 1/8) and two focal lengths (20mm and 50mm). Unlike general style datasets, ProMist-5K focuses on realistic glow and highlight diffusion effects. Multiple blur layers and carefully tuned weighting are used to model the varying intensity and spread of optical diffusion. The dataset provides a consistent and controllable target domain that supports various image translation models and learning paradigms. Experiments show that the dataset works well across different training settings and helps capture both subtle and strong cinematic appearances. ProMist-5K offers a practical and physically grounded resource for film-inspired image transformation, bridging the gap between digital flexibility and traditional lens aesthetics. The dataset is available at https://www.kaggle.com/datasets/yingtielei/promist5k.", "AI": {"tldr": "构建了一个用于数字模拟影视Pro-Mist滤镜效果的数据集ProMist-5K。", "motivation": "为了在数字化环境中真实再现电影中常用的Pro-Mist滤镜的独特视觉风格，包括软化光晕、降低对比度等效果。", "method": "使用物理模型驱动的处理流程生成包含20,000对高分辨率图像的数据集，涵盖不同密度和焦距下的多种配置，以模拟实际光线扩散行为。", "result": "实验表明该数据集在不同的训练设置下均能有效捕捉电影风格的效果，并支持各种影像转换模型和学习框架。", "conclusion": "ProMist-5K为实现数字环境中的电影滤镜效果提供了实用的资源，促进了传统镜头美学与数字化灵活性之间的融合。"}}
{"id": "2601.19294", "pdf": "https://arxiv.org/pdf/2601.19294", "abs": "https://arxiv.org/abs/2601.19294", "authors": ["Joffrey Guilmet", "Suzanne Sorli", "Diego Vilela Monteiro"], "title": "Words have Weight: Comparing the use of pressure and weight as a metaphor in a User Interface in Virtual Reality", "categories": ["cs.GR", "cs.HC"], "comment": "ef:IEEE World Haptics Conference 2025, Jul 2025, Suwon, South Korea", "summary": "This work investigates how weight and pressure can function as haptic metaphors to support user interface notifications in Virtual Reality (VR). While prior research has explored ungrounded weight simulation and pneumatic feedback, their combined role in conveying information through UI elements remains underexplored. We developed a wearable haptic device that transfers liquid and air into flexible containers mounted on the back of the user's hand, allowing us to independently manipulate weight and pressure. Through an initial evaluation using three conditions-no feedback, weight only, and weight combined with pressure-we examined how these signals affect perceived heaviness, coherence with visual cues, and the perceived urgency of notifications. Our results validate that pressure amplifies the perception of weight, but this increased heaviness does not translate into higher perceived urgency. These findings suggest that while pressure___enhanced weight can enrich haptic rendering of UI elements in VR, its contribution to communicating urgency may require further investigation, alternative pressure profiles, or different types of notifications.", "AI": {"tldr": "研究在虚拟现实中的用户界面通知中，压力和重量作为触觉隐喻的效果。", "motivation": "探索在虚拟现实中，如何利用重量和压力共同作用传达信息，丰富用户界面元素的触感体验。", "method": "开发了一种可穿戴设备，通过独立控制液体和空气来模拟重量和压力。进行了三个条件下的初步评估：无反馈、仅重量和重量加压力，以考察这些信号对感知重量、视觉一致性及通知紧迫性的效果。", "result": "结果显示，压力增强了重量的感知，但这种增加的沉重感并未转化为更高的紧迫感感知。", "conclusion": "虽然增强后的重量可以丰富虚拟现实中用户界面元素的触觉渲染，但对于传递紧迫性可能需要进一步研究或采用不同的压力模式和通知类型。"}}
{"id": "2601.19281", "pdf": "https://arxiv.org/pdf/2601.19281", "abs": "https://arxiv.org/abs/2601.19281", "authors": ["Zheng Zhang", "Mengjie Yu", "Tianyi Wang", "Kashyap Todi", "Ajoy Savio Fernandes", "Yue Liu", "Haijun Xia", "Tovi Grossman", "Tanya Jonker"], "title": "Gazeify Then Voiceify: Physical Object Referencing Through Gaze and Voice Interaction with Displayless Smart Glasses", "categories": ["cs.HC"], "comment": null, "summary": "Smart glasses enhance interactions with the environment by using head-mounted cameras to observe the user's viewpoint, but lack the visual feedback used for common interactions. We introduce Gazeify then Voiceify, a multimodal approach allowing object selection via gaze and voice using displayless smart glasses. Users can select a physical object with their gaze, and the system generates a digital mask and a voice description of the object's semantics. Users can further correct errors through free-form conversation. To demonstrate our approach, we develop an interactive system by integrating advanced object segmentation and detection with a vision-language model. User studies reveal that participants achieve correct gaze selection in 53% of the task trials and use voice disambiguation to correct 58% of the remaining errors. Participants also rated the system as likable, useful, and easy to use.", "AI": {"tldr": "通过使用无屏幕智能眼镜的凝视和语音交互来选择物理对象。", "motivation": "增强用户与环境之间的互动，尤其是在缺乏视觉反馈的情况下利用头戴式相机观察用户的视角。", "method": "提出了一种多模式方法Gazeify then Voiceify，该方法允许通过凝视和语音选择物体。系统生成物体的数字掩模及语义描述，并使用高级对象分割检测与视觉语言模型进行整合。", "result": "用户研究显示参与者在任务试验中正确地用凝视选中了53%的对象，且通过自由形式对话纠正了剩余错误中的58%。参与者还对系统表示满意、有用并且易于使用。", "conclusion": "提出的方法证明了可以通过无屏幕智能眼镜实现有效而自然的物理对象选择和交互。"}}
{"id": "2601.19280", "pdf": "https://arxiv.org/pdf/2601.19280", "abs": "https://arxiv.org/abs/2601.19280", "authors": ["Kishan Panaganti", "Zhenwen Liang", "Wenhao Yu", "Haitao Mi", "Dong Yu"], "title": "Group Distributionally Robust Optimization-Driven Reinforcement Learning for LLM Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Keywords: Large Language Models, Reasoning Models, Reinforcement Learning, Distributionally Robust Optimization, GRPO", "summary": "Recent progress in Large Language Model (LLM) reasoning is increasingly driven by the refinement of post-training loss functions and alignment strategies. However, standard Reinforcement Learning (RL) paradigms like Group Relative Policy Optimization (GRPO) remain constrained by static uniformity: uniform prompt sampling and a fixed number of rollouts per prompt. For heterogeneous, heavy-tailed reasoning data, this creates structural inefficiencies that waste compute on already-solved patterns while under-training the long tail of hard problems. To address this, we propose Multi-Adversary Group Distributionally Robust Optimization (GDRO), an optimization-first framework that moves beyond uniform reasoning models by dynamically adapting the training distribution. We introduce an Online Difficulty Classifier that partitions prompts into dynamic pass@k difficulty groups. We then propose two independent GDRO games for post-training: (1) Prompt-GDRO, which employs an EMA-debiased multiplicative-weights bandit sampler to target the intensive difficulty margin and upweight persistently hard groups without frequency bias; and (2) Rollout-GDRO, which uses a shadow-price controller to reallocate rollouts across groups, maximizing gradient variance reduction on hard tasks under a fixed mean budget (compute-neutral). We provide no-regret guarantees for both controllers and additionally a variance-proxy analysis motivating a square-root optimal rollout allocation for Rollout-GDRO. We validate our framework on the DAPO 14.1k dataset using Qwen3-Base models. Prompt-GDRO and Rollout-GDRO achieve average relative gains of +10.6% and +10.1%, respectively, in pass@8 accuracy across 1.7B, 4B, and 8B scales compared to the GRPO baseline. Qualitative analysis shows an emergent curriculum: the adversaries shift resources to the evolving reasoning frontier, enhancing the reasoning model's performance.", "AI": {"tldr": "提出了一种基于组分布鲁棒优化的强化学习方法，用于解决大语言模型推理中的静态均匀性问题。", "motivation": "现有标准强化学习范式在处理异质、长尾推理数据时存在结构性低效，导致计算资源浪费。为了解决这一问题，提出了多代理组分布鲁棒优化框架。", "method": "引入在线难度分类器将提示动态划分到不同的困难组别，并提出Prompt-GDRO和Rollout-GDRO两种方法以适应性的分配训练资源。", "result": "在DAPO 14.1k数据集上，与GRPO基线相比，Prompt-GDRO和Rollout-GDRO分别实现了+10.6%和+10.1%的相对提升。", "conclusion": "该框架通过动态适应性分配计算资源提高了大语言模型推理性能。"}}
{"id": "2601.19276", "pdf": "https://arxiv.org/pdf/2601.19276", "abs": "https://arxiv.org/abs/2601.19276", "authors": ["Shengjia Zhang", "Weiqin Yang", "Jiawei Chen", "Peng Wu", "Yuegang Sun", "Gang Wang", "Qihao Shi", "Can Wang"], "title": "Talos: Optimizing Top-$K$ Accuracy in Recommender Systems", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "Accepted by WWW'26", "summary": "Recommender systems (RS) aim to retrieve a small set of items that best match individual user preferences. Naturally, RS place primary emphasis on the quality of the Top-$K$ results rather than performance across the entire item set. However, estimating Top-$K$ accuracy (e.g., Precision@$K$, Recall@$K$) requires determining the ranking positions of items, which imposes substantial computational overhead and poses significant challenges for optimization. In addition, RS often suffer from distribution shifts due to evolving user preferences or data biases, further complicating the task. To address these issues, we propose Talos, a loss function that is specifically designed to optimize the Talos recommendation accuracy. Talos leverages a quantile technique that replaces the complex ranking-dependent operations into simpler comparisons between predicted scores and learned score thresholds. We further develop a sampling-based regression algorithm for efficient and accurate threshold estimation, and introduce a constraint term to maintain optimization stability by preventing score inflation. Additionally, we incorporate a tailored surrogate function to address discontinuity and enhance robustness against distribution shifts. Comprehensive theoretical analyzes and empirical experiments are conducted to demonstrate the effectiveness, efficiency, convergence, and distributional robustness of Talos. The code is available at https://github.com/cynthia-shengjia/WWW-2026-Talos.", "AI": {"tldr": "提出Talos算法优化推荐系统的Top-K准确性。", "motivation": "提高推荐系统中Top-K准确性的效率和稳定性，解决分布变化带来的挑战。", "method": "设计了一种新的损失函数Talos，并结合量化技术、回归算法以及约束项来改进模型性能。", "result": "理论分析和实验证明了Talos的有效性、高效性和收敛性，同时增强了对分布变化的鲁棒性。", "conclusion": "Talos提供了一种创新的方法来优化推荐系统中的Top-K准确性，并展示了其在各种场景下的优越表现。"}}
{"id": "2601.19275", "pdf": "https://arxiv.org/pdf/2601.19275", "abs": "https://arxiv.org/abs/2601.19275", "authors": ["Tatsuya Kamijo", "Mai Nishimura", "Cristian C. Beltran-Hernandez", "Nodoka Shibasaki", "Masashi Hamaya"], "title": "Tactile Memory with Soft Robot: Robust Object Insertion via Masked Encoding and Soft Wrist", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Tactile memory, the ability to store and retrieve touch-based experience, is critical for contact-rich tasks such as key insertion under uncertainty. To replicate this capability, we introduce Tactile Memory with Soft Robot (TaMeSo-bot), a system that integrates a soft wrist with tactile retrieval-based control to enable safe and robust manipulation. The soft wrist allows safe contact exploration during data collection, while tactile memory reuses past demonstrations via retrieval for flexible adaptation to unseen scenarios. The core of this system is the Masked Tactile Trajectory Transformer (MAT$^\\text{3}$), which jointly models spatiotemporal interactions between robot actions, distributed tactile feedback, force-torque measurements, and proprioceptive signals. Through masked-token prediction, MAT$^\\text{3}$ learns rich spatiotemporal representations by inferring missing sensory information from context, autonomously extracting task-relevant features without explicit subtask segmentation. We validate our approach on peg-in-hole tasks with diverse pegs and conditions in real-robot experiments. Our extensive evaluation demonstrates that MAT$^\\text{3}$ achieves higher success rates than the baselines over all conditions and shows remarkable capability to adapt to unseen pegs and conditions.", "AI": {"tldr": "研究提出了一种基于软腕的触觉记忆系统TaMeSo-bot，用于实现安全且鲁棒的对象插入操作", "motivation": "在不确定性环境下，接触密集型任务（如钥匙插入）需要存储和检索触觉经验的能力。为了复制这一能力，本研究开发了一个结合了软腕与触觉检索控制的系统", "method": "核心是Masked Tactile Trajectory Transformer (MAT$^\text{3}$)，该模型联合建模机器人动作、分布式触觉反馈、力矩测量和固有信号之间的时空交互。通过预测缺失的感知信息，MAT$^\text{3}$ 学习丰富的时空表示，并自主提取任务相关的特征", "result": "在实际机器人实验中验证了MAT$^\text{3}$ 在各种条件下的高效表现，成功率超过基准方法，并展现了适应未知对象的能力", "conclusion": "提出的方法显著提高了触觉记忆的效率和鲁棒性"}}
{"id": "2601.19273", "pdf": "https://arxiv.org/pdf/2601.19273", "abs": "https://arxiv.org/abs/2601.19273", "authors": ["Niharika Sri Parasa", "Chaitali Diwan", "Srinath Srinivasa"], "title": "Riddle Quest : The Enigma of Words", "categories": ["cs.CL", "cs.AI", "cs.IT"], "comment": "This paper is submitted under 'Demo track' for WWW conference", "summary": "Riddles are concise linguistic puzzles that describe an object or idea through indirect, figurative, or playful clues. They are a longstanding form of creative expression, requiring the solver to interpret hints, recognize patterns, and draw inferences to identify the answers. In this work, we introduce a simple pipeline for creating and evaluating analogy-based riddles. The system includes a triples creator that builds structured facts about a concept, a semantic mapper that selects attributes useful for analogy, a stylized generator that turns them into riddle clues, and a validator that collects all possible answers the riddle could point to. We use this validator to study whether large language models can recover the full answer set for different riddle types. Our case study shows that while models often guess the main intended answer, they frequently miss other valid interpretations. This highlights the value of riddles as a lightweight tool for examining reasoning coverage and ambiguity handling in language models.", "AI": {"tldr": "论文提出了一种基于类比的谜语创建和评估流程，包括事实构建、属性选择、生成谜语线索以及验证可能答案的方法，用以研究大规模语言模型在处理不同类型谜语时的答案覆盖率及歧义处理能力。", "motivation": "利用谜语这一形式简洁且富有创造性的表达方式来考察大型语言模型的推理覆盖范围和歧义处理能力。通过构建一个能够生成和评价类比基础谜语的流程，揭示出当前模型在理解复杂隐喻和多解性方面的问题。", "method": "论文提出了一种包含事实构造器、语义映射器、样式化生成器以及验证器在内的系统来创建和评估基于类比的谜语。该方法被用于研究大型语言模型能否恢复各种类型谜语的所有可能答案。", "result": "研究表明，尽管模型通常可以猜测出主要意图的答案，但它们经常会遗漏其他有效的解释，显示出在处理复杂隐喻和多解性方面存在的不足。", "conclusion": "基于类比的谜语为评估大规模语言模型的理解能力和推理覆盖提供了一种简单而有力的方法。"}}
{"id": "2601.19269", "pdf": "https://arxiv.org/pdf/2601.19269", "abs": "https://arxiv.org/abs/2601.19269", "authors": ["Hamza Peracha", "Carrina Iacobacci", "Tyler Singer-Clark", "Leigh R. Hochberg", "Sergey D. Stavisky", "David M. Brandman", "Nicholas S. Card"], "title": "A Personalized and Adaptable User Interface for a Speech and Cursor Brain-Computer Interface", "categories": ["cs.HC"], "comment": "18 pages, 6 figures", "summary": "Communication and computer interaction are important for autonomy in modern life. Unfortunately, these capabilities can be limited or inaccessible for the millions of people living with paralysis. While implantable brain-computer interfaces (BCIs) show promise for restoring these capabilities, little has been explored on designing BCI user interfaces (UIs) for sustained daily use. Here, we present a personalized UI for an intracortical BCI system that enables users with severe paralysis to communicate and interact with their computers independently. Through a 22-month longitudinal deployment with one participant, we used iterative co-design to develop a system for everyday at-home use and documented how it evolved to meet changing needs. Our findings highlight how personalization and adaptability enabled independence in daily life and provide design implications for developing future BCI assistive technologies.", "AI": {"tldr": "本文提出了一种个性化的用户界面，用于一种植入式脑机接口系统，使严重瘫痪的患者能够独立地进行交流和计算机交互。", "motivation": "通信和电脑交互对于现代生活中的自主性非常重要。然而，这些能力对数百万患有瘫痪的人来说可能是有限或者难以接触到的。本文旨在通过个性化的用户界面设计来解决这一问题，以支持日常使用。", "method": "研究人员与参与者合作，在22个月的时间内迭代式地共同设计和改进系统，并记录了系统的演变过程以及如何适应变化的需求。", "result": "个性化和适应性使瘫痪患者在日常生活中实现了独立生活。结果展示了个性化的用户界面能够更好地满足个体需求，从而支持更有效的脑机接口交互。", "conclusion": "研究强调了个人化和可适应性的用户界面设计对于开发未来辅助技术的重要性，并为未来的脑机接口系统提供了设计建议。"}}
{"id": "2601.19266", "pdf": "https://arxiv.org/pdf/2601.19266", "abs": "https://arxiv.org/abs/2601.19266", "authors": ["Yuting Hong", "Li Dong", "Xiaojie Qiu", "Hui Xiao", "Baochen Yao", "Siming Zheng", "Chengbin Peng"], "title": "A Multi-View Consistency Framework with Semi-Supervised Domain Adaptation", "categories": ["cs.CV"], "comment": "11 pages, 7 figures", "summary": "Semi-Supervised Domain Adaptation (SSDA) leverages knowledge from a fully labeled source domain to classify data in a partially labeled target domain. Due to the limited number of labeled samples in the target domain, there can be intrinsic similarity of classes in the feature space, which may result in biased predictions, even when the model is trained on a balanced dataset. To overcome this limitation, we introduce a multi-view consistency framework, which includes two views for training strongly augmented data. One is a debiasing strategy for correcting class-wise prediction probabilities according to the prediction performance of the model. The other involves leveraging pseudo-negative labels derived from the model predictions. Furthermore, we introduce a cross-domain affinity learning aimed at aligning features of the same class across different domains, thereby enhancing overall performance. Experimental results demonstrate that our method outperforms the competing methods on two standard domain adaptation datasets, DomainNet and Office-Home. Combining unsupervised domain adaptation and semi-supervised learning offers indispensable contributions to the industrial sector by enhancing model adaptability, reducing annotation costs, and improving performance.", "AI": {"tldr": "本文提出了一个多视角一致性框架，以解决半监督领域适应中的类别预测偏差问题。", "motivation": "由于目标领域的标记样本较少，导致模型在特征空间中对类别的相似性判断出现偏见，影响分类准确性。因此，文章提出了一种新的多视图一致性框架来改善这一情况。", "method": "该方法包括两个训练视角：一是偏差校正策略，用于根据模型预测性能调整类别概率；二是利用模型预测生成伪负标签。此外，还引入了跨领域亲和学习以对齐不同领域的同一类特征。", "result": "实验结果表明，在DomainNet和Office-Home这两个标准领域适应数据集上，本文方法优于现有竞争方法。", "conclusion": "该框架通过结合无监督领域适应与半监督学习提高了模型的适应性、降低了标注成本并提升了性能。"}}
{"id": "2601.19262", "pdf": "https://arxiv.org/pdf/2601.19262", "abs": "https://arxiv.org/abs/2601.19262", "authors": ["Syed Mehedi Hasan Nirob", "Moqsadur Rahman", "Shamim Ehsan", "Summit Haque"], "title": "Handcrafted Feature Fusion for Reliable Detection of AI-Generated Images", "categories": ["cs.CV"], "comment": null, "summary": "The rapid progress of generative models has enabled the creation of highly realistic synthetic images, raising concerns about authenticity and trust in digital media. Detecting such fake content reliably is an urgent challenge. While deep learning approaches dominate current literature, handcrafted features remain attractive for their interpretability, efficiency, and generalizability. In this paper, we conduct a systematic evaluation of handcrafted descriptors, including raw pixels, color histograms, Discrete Cosine Transform (DCT), Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), Gray-Level Co-occurrence Matrix (GLCM), and wavelet features, on the CIFAKE dataset of real versus synthetic images. Using 50,000 training and 10,000 test samples, we benchmark seven classifiers ranging from Logistic Regression to advanced gradient-boosted ensembles (LightGBM, XGBoost, CatBoost). Results demonstrate that LightGBM consistently outperforms alternatives, achieving PR-AUC 0.9879, ROC-AUC 0.9878, F1 0.9447, and a Brier score of 0.0414 with mixed features, representing strong gains in calibration and discrimination over simpler descriptors. Across three configurations (baseline, advanced, mixed), performance improves monotonically, confirming that combining diverse handcrafted features yields substantial benefit. These findings highlight the continued relevance of carefully engineered features and ensemble learning for detecting synthetic images, particularly in contexts where interpretability and computational efficiency are critical.", "AI": {"tldr": "该论文通过系统评估手工艺品描述符在鉴别真实与合成图像中的性能，探索了用于检测AI生成图像的可靠方法。", "motivation": "随着生成模型的进步，高逼真度的合成图像日益增多，这引发了对数字媒体真实性及信任的关注。传统的深度学习方法虽然广泛应用，但手工艺特征因其解释性、效率和泛化能力而仍然具有吸引力。", "method": "本文在CIFAKE数据集上评估了多种手工艺品描述符，包括原始像素、颜色直方图、离散余弦变换（DCT）、定向梯度直方图（HOG）、局部二值模式（LBP）、灰度共生矩阵（GLCM）和小波特征，并使用逻辑回归等七种分类器进行基准测试。最终选择了LightGBM作为最优分类器。", "result": "实验结果表明，通过混合手工艺品描述符，LightGBM在PR-AUC、ROC-AUC、F1得分及Brier分数上均表现出色，分别达到了0.9879、0.9878、0.9447和0.0414。这证明了组合多样特征的重要性。", "conclusion": "这些研究结果强调了在检测合成图像时精心设计的特征结合集成学习方法的有效性，特别是在需要解释性和计算效率的情况下。"}}
{"id": "2601.19261", "pdf": "https://arxiv.org/pdf/2601.19261", "abs": "https://arxiv.org/abs/2601.19261", "authors": ["Anower Zihad", "Felix Owino", "Haibo Yang", "Ming Tang", "Chao Huang"], "title": "Decoupled Split Learning via Auxiliary Loss", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Split learning is a distributed training paradigm where a neural network is partitioned between clients and a server, which allows data to remain at the client while only intermediate activations are shared. Traditional split learning relies on end-to-end backpropagation across the client-server split point. This incurs a large communication overhead (i.e., forward activations and backward gradients need to be exchanged every iteration) and significant memory use (for storing activations and gradients). In this paper, we develop a beyond-backpropagation training method for split learning. In this approach, the client and server train their model partitions semi-independently, using local loss signals instead of propagated gradients. In particular, the client's network is augmented with a small auxiliary classifier at the split point to provide a local error signal, while the server trains on the client's transmitted activations using the true loss function. This decoupling removes the need to send backward gradients, which cuts communication costs roughly in half and also reduces memory overhead (as each side only stores local activations for its own backward pass). We evaluate our approach on CIFAR-10 and CIFAR-100. Our experiments show two key results. First, the proposed approach achieves performance on par with standard split learning that uses backpropagation. Second, it significantly reduces communication (of transmitting activations/gradient) by 50% and peak memory usage by up to 58%.", "AI": {"tldr": "本文提出了一种新的分学习训练方法，通过在客户端和服务器之间使用局部损失信号代替反向传播的梯度来减少通信成本和内存开销。", "motivation": "传统的分学习需要端到端的反向传播，导致了高通信量和大内存占用。为了降低这些成本，本文提出了一个新的训练方法。", "method": "在客户端模型中添加一个小辅助分类器以提供本地错误信号，同时服务器基于客户端传输的激活进行真实损失函数下的训练。这种方法去耦合了梯度传递的需求，减少了50%的通信量和最多58%的峰值内存使用。", "result": "该方法在CIFAR-10和CIFAR-100数据集上的实验结果显示，其性能与标准的分学习相当，同时显著降低了50%的传输激活/梯度的通信成本和最多58%的峰值内存使用。", "conclusion": "通过引入辅助损失信号进行局部训练，该方法不仅保持了传统分学习的性能，还大幅减少了通信开销和内存需求。"}}
{"id": "2601.19258", "pdf": "https://arxiv.org/pdf/2601.19258", "abs": "https://arxiv.org/abs/2601.19258", "authors": ["Minkyu Kweon", "Seokhyeon Park", "Soohyun Lee", "You Been Lee", "Jeongmin Rhee", "Jinwook Seo"], "title": "GhostUI: Unveiling Hidden Interactions in Mobile UI", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted at ACM CHI Conference on Human Factors in Computing Systems (CHI '26)", "summary": "Modern mobile applications rely on hidden interactions--gestures without visual cues like long presses and swipes--to provide functionality without cluttering interfaces. While experienced users may discover these interactions through prior use or onboarding tutorials, their implicit nature makes them difficult for most users to uncover. Similarly, mobile agents--systems designed to automate tasks on mobile user interfaces, powered by vision language models (VLMs)--struggle to detect veiled interactions or determine actions for completing tasks. To address this challenge, we present GhostUI, a new dataset designed to enable the detection of hidden interactions in mobile applications. GhostUI provides before-and-after screenshots, simplified view hierarchies, gesture metadata, and task descriptions, allowing VLMs to better recognize concealed gestures and anticipate post-interaction states. Quantitative evaluations with VLMs show that models fine-tuned on GhostUI outperform baseline VLMs, particularly in predicting hidden interactions and inferring post-interaction screens, underscoring GhostUI's potential as a foundation for advancing mobile task automation.", "AI": {"tldr": "GhostUI是一款新数据集，旨在帮助视觉语言模型识别和理解移动应用程序中的隐藏交互。", "motivation": "在现代移动应用中，隐式手势（如长按、滑动）提供了额外功能而不增加界面混乱。然而，这些互动对大多数用户来说难以发现，也给自动化任务的系统造成了挑战。", "method": "GhostUI通过提供前后截图、简化视图层次结构、手势元数据和任务描述来帮助VLM识别隐藏的手势并预测执行后的状态。", "result": "定量评估表明，在GhostUI上进行微调的模型在预测隐式交互和推断后操作屏幕方面优于基线VLM。", "conclusion": "GhostUI为移动任务自动化提供了坚实的基础，提高了视觉语言模型识别隐藏互动的能力。"}}
{"id": "2601.19257", "pdf": "https://arxiv.org/pdf/2601.19257", "abs": "https://arxiv.org/abs/2601.19257", "authors": ["Kun Li", "Longtao Hu", "Yida Xiong", "Jiajun Yu", "Hongzhi Zhang", "Jiameng Chen", "Xiantao Cai", "Jia Wu", "Wenbin Hu"], "title": "PCEvo: Path-Consistent Molecular Representation via Virtual Evolutionary", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "comment": "10 pages, 4 figures, 5 tables", "summary": "Molecular representation learning aims to learn vector embeddings that capture molecular structure and geometry, thereby enabling property prediction and downstream scientific applications. In many AI for science tasks, labeled data are expensive to obtain and therefore limited in availability. Under the few-shot setting, models trained with scarce supervision often learn brittle structure-property relationships, resulting in substantially higher prediction errors and reduced generalization to unseen molecules. To address this limitation, we propose PCEvo, a path-consistent representation method that learns from virtual paths through dynamic structural evolution. PCEvo enumerates multiple chemically feasible edit paths between retrieved similar molecular pairs under topological dependency constraints. It transforms the labels of the two molecules into stepwise supervision along each virtual evolutionary path. It introduces a path-consistency objective that enforces prediction invariance across alternative paths connecting the same two molecules. Comprehensive experiments on the QM9 and MoleculeNet datasets demonstrate that PCEvo substantially improves the few-shot generalization performance of baseline methods. The code is available at https://anonymous.4open.science/r/PCEvo-4BF2.", "AI": {"tldr": "PCEvo方法通过虚拟进化路径学习分子表示，提高在少量样本情况下的预测性能。", "motivation": "现有模型在少数标记数据下训练时，容易学到脆弱的结构-属性关系，导致预测错误率高且对新分子泛化能力差。为此，提出了一种新的路径一致性的分子表示方法PCEvo。", "method": "PCEvo通过动态结构进化枚举化学上可行的编辑路径，并将两个分子标签转换为沿着每条虚拟演化路径逐步监督。它引入了路径一致性目标以强制在连接同一对分子的不同路径上的预测不变性。", "result": "实验结果表明，与基线方法相比，PCEvo在QM9和MoleculeNet数据集上显著提高了少数样本下的泛化性能。", "conclusion": "通过虚拟进化路径学习路径一致性表示可以提高分子的可迁移性和鲁棒性，在少量标记数据的情况下表现更好。"}}
{"id": "2601.19255", "pdf": "https://arxiv.org/pdf/2601.19255", "abs": "https://arxiv.org/abs/2601.19255", "authors": ["Haoting Zhang", "Shekhar Jain"], "title": "LLM-Assisted Logic Rule Learning: Scaling Human Expertise for Time Series Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series anomaly detection is critical for supply chain management to take proactive operations, but faces challenges: classical unsupervised anomaly detection based on exploiting data patterns often yields results misaligned with business requirements and domain knowledge, while manual expert analysis cannot scale to millions of products in the supply chain. We propose a framework that leverages large language models (LLMs) to systematically encode human expertise into interpretable, logic-based rules for detecting anomaly patterns in supply chain time series data. Our approach operates in three stages: 1) LLM-based labeling of training data instructed by domain knowledge, 2) automated generation and iterative improvements of symbolic rules through LLM-driven optimization, and 3) rule augmentation with business-relevant anomaly categories supported by LLMs to enhance interpretability. The experiment results showcase that our approach outperforms the unsupervised learning methods in both detection accuracy and interpretability. Furthermore, compared to direct LLM deployment for time series anomaly detection, our approach provides consistent, deterministic results with low computational latency and cost, making it ideal for production deployment. The proposed framework thus demonstrates how LLMs can bridge the gap between scalable automation and expert-driven decision-making in operational settings.", "AI": {"tldr": "提出了一种利用大语言模型编码人类专业知识以增强供应链时间序列异常检测的新框架", "motivation": "传统无监督方法和手动分析都难以满足大规模供应链管理中时间和成本的要求，需要一种既能规模化又能结合领域知识的方法", "method": "通过三个阶段：LLM指导训练数据标签化、生成迭代改进的符号规则以及利用LLM进行业务相关异常分类增强可解释性", "result": "实验结果表明该方法在检测准确性和可解释性上优于无监督学习，并且比直接部署大语言模型具有更低的时间和计算成本", "conclusion": "本文展示了如何通过大规模语言模型将可扩展自动化与专家决策相结合"}}
{"id": "2601.19249", "pdf": "https://arxiv.org/pdf/2601.19249", "abs": "https://arxiv.org/abs/2601.19249", "authors": ["Xingkun Yin", "Hongyang Du"], "title": "GLOVE: Global Verifier for LLM Memory-Environment Realignment", "categories": ["cs.AI"], "comment": null, "summary": "Most existing memory-enhanced Large Language Model (LLM) approaches implicitly assume that memory validity can be established either through external evaluators that provide task-specific success signals or through internal model cognition, such as reflection, for editing memory entries. However, these assumptions often break down in practical environments with dynamic drifts. We propose the Global Verifier (GLOVE), a framework that introduces a new design dimension for LLM memory systems by establishing a relative notion of truth. Through active probing to detect inconsistencies between retrieved memories and fresh observations, GLOVE enables memory-environment realignment by verifying and updating memory without access to ground-truth supervision or strong reliance on model introspection. We evaluate GLOVE on diverse benchmarks spanning web navigation, planning, and control, augmented with controlled environmental drifts that introduce non-stationarity beyond the original benchmark settings. Our results show that GLOVE substantially improves agent success rates, suggesting a robust pathway to cognitive agents capable of self-evolving.", "AI": {"tldr": "提出了GLOVE框架，用于通过主动探测和验证来实现LLM记忆与环境的一致性更新。", "motivation": "现有增强LLM的方法通常假设可以通过外部评估者或模型内部认知来确保记忆的有效性。然而，在动态环境中这些方法常常失效，因此需要一种新的设计维度来解决这个问题。", "method": "GLOVE通过主动探测发现检索的记忆与新鲜观察之间的不一致性，并在没有地面真值监督的情况下更新和验证内存。", "result": "实验结果显示，GLOVE显著提高了代理的成功率，在各种基准测试中表现优越。", "conclusion": "GLOVE为创建能够自我演化的认知代理提供了一条稳健的途径。"}}
{"id": "2601.19247", "pdf": "https://arxiv.org/pdf/2601.19247", "abs": "https://arxiv.org/abs/2601.19247", "authors": ["Jiarun Liu", "Qifeng Chen", "Yiru Zhao", "Minghua Liu", "Baorui Ma", "Sheng Yang"], "title": "TIGaussian: Disentangle Gaussians for Spatial-Awared Text-Image-3D Alignment", "categories": ["cs.CV"], "comment": null, "summary": "While visual-language models have profoundly linked features between texts and images, the incorporation of 3D modality data, such as point clouds and 3D Gaussians, further enables pretraining for 3D-related tasks, e.g., cross-modal retrieval, zero-shot classification, and scene recognition. As challenges remain in extracting 3D modal features and bridging the gap between different modalities, we propose TIGaussian, a framework that harnesses 3D Gaussian Splatting (3DGS) characteristics to strengthen cross-modality alignment through multi-branch 3DGS tokenizer and modality-specific 3D feature alignment strategies. Specifically, our multi-branch 3DGS tokenizer decouples the intrinsic properties of 3DGS structures into compact latent representations, enabling more generalizable feature extraction. To further bridge the modality gap, we develop a bidirectional cross-modal alignment strategies: a multi-view feature fusion mechanism that leverages diffusion priors to resolve perspective ambiguity in image-3D alignment, while a text-3D projection module adaptively maps 3D features to text embedding space for better text-3D alignment. Extensive experiments on various datasets demonstrate the state-of-the-art performance of TIGaussian in multiple tasks.", "AI": {"tldr": "提出了一种名为TIGaussian的框架，该框架利用三维高斯点云数据增强文本-图像-三维空间对齐。", "motivation": "视觉语言模型已经深入链接了文字和图像之间的特征。然而，将3D模态的数据（如点云和3D高斯）融入预训练中仍存在挑战，特别是在提取3D模态的特征以及弥合不同模式之间的差距方面。", "method": "TIGaussian框架通过使用多分支三维高斯点云解码器和特定于模态的3D特征对齐策略来增强跨模态对齐。此外，开发了双向跨模态对齐策略：一个多视角融合机制利用扩散先验解决图像-3D对齐中的透视模糊问题，同时一个文本-3D投影模块适应性地将3D特征映射到文本嵌入空间以实现更好的文本-3D对齐。", "result": "在多个数据集上进行的广泛实验表明，TIGaussian框架在多任务上的性能处于领先地位。", "conclusion": "TIGaussian通过利用三维高斯点云的数据特性增强了视觉语言模型中跨模态特征的学习，并展示了其在各种3D相关任务中的优越性。"}}
{"id": "2601.19246", "pdf": "https://arxiv.org/pdf/2601.19246", "abs": "https://arxiv.org/abs/2601.19246", "authors": ["Hidenori Takeshima"], "title": "Magnetic Resonance Simulation of Effective Transverse Relaxation (T2*)", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "comment": null, "summary": "Purpose: To simulate effective transverse relaxation ($T_2^*$) as a part of MR simulation. $T_2^*$ consists of reversible ($T_2^{\\prime}$) and irreversible ($T_2$) components. Whereas simulations of $T_2$ are easy, $T_2^{\\prime}$ is not easily simulated if only magnetizations of individual isochromats are simulated. Theory and Methods: Efficient methods for simulating $T_2^{\\prime}$ were proposed. To approximate the Lorentzian function of $T_2^{\\prime}$ realistically, conventional simulators require 100+ isochromats. This approximation can be avoided by utilizing a linear phase model for simulating an entire Lorentzian function directly. To represent the linear phase model, the partial derivatives of the magnetizations with respect to the frequency axis were also simulated. To accelerate the simulations with these partial derivatives, the proposed methods introduced two techniques: analytic solutions, and combined transitions. For understanding the fundamental mechanism of the proposed method, a simple one-isochromat simulation was performed. For evaluating realistic cases, several pulse sequences were simulated using two phantoms with and without $T_2^{\\prime}$ simulations. Results: The one-isochromat simulation demonstrated that $T_2^{\\prime}$ simulations were possible. In the realistic cases, $T_2^{\\prime}$ was recovered as expected without using 100+ isochromats for each point. The computational times with $T_2^{\\prime}$ simulations were only 2.0 to 2.7 times longer than those without $T_2^{\\prime}$ simulations. When the above-mentioned two techniques were utilized, the analytic solutions accelerated 19 times, and the combined transitions accelerated up to 17 times. Conclusion: Both theory and results showed that the proposed methods simulated $T_2^{\\prime}$ efficiently by utilizing a linear model with a Lorentzian function, analytic solutions, and combined transitions.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.19245", "pdf": "https://arxiv.org/pdf/2601.19245", "abs": "https://arxiv.org/abs/2601.19245", "authors": ["Yongxin Deng", "Zhen Fang", "Yixuan Li", "Ling Chen"], "title": "Beyond In-Domain Detection: SpikeScore for Cross-Domain Hallucination Detection", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Hallucination detection is critical for deploying large language models (LLMs) in real-world applications. Existing hallucination detection methods achieve strong performance when the training and test data come from the same domain, but they suffer from poor cross-domain generalization. In this paper, we study an important yet overlooked problem, termed generalizable hallucination detection (GHD), which aims to train hallucination detectors on data from a single domain while ensuring robust performance across diverse related domains. In studying GHD, we simulate multi-turn dialogues following LLMs initial response and observe an interesting phenomenon: hallucination-initiated multi-turn dialogues universally exhibit larger uncertainty fluctuations than factual ones across different domains. Based on the phenomenon, we propose a new score SpikeScore, which quantifies abrupt fluctuations in multi-turn dialogues. Through both theoretical analysis and empirical validation, we demonstrate that SpikeScore achieves strong cross-domain separability between hallucinated and non-hallucinated responses. Experiments across multiple LLMs and benchmarks demonstrate that the SpikeScore-based detection method outperforms representative baselines in cross-domain generalization and surpasses advanced generalization-oriented methods, verifying the effectiveness of our method in cross-domain hallucination detection.", "AI": {"tldr": "提出了一种新的方法SpikeScore用于跨域幻觉检测。", "motivation": "现有幻觉检测方法在不同领域泛化效果差，需要一种能够在单个数据域训练并在多种相关领域中表现稳健的检测器。", "method": "通过模拟多轮对话中的不确定性波动现象，提出了一种新的分数SpikeScore量化多轮对话中的急剧波动以区分幻觉和非幻觉回复。", "result": "实验表明，基于SpikeScore的方法在跨域泛化性能上优于代表性基准方法，并且超过了先进的泛化导向方法。", "conclusion": "该研究成功地提出了一个有效的跨领域幻觉检测方案。"}}
{"id": "2601.19237", "pdf": "https://arxiv.org/pdf/2601.19237", "abs": "https://arxiv.org/abs/2601.19237", "authors": ["Hyeok Kim", "Sehi L'Yi", "Nils Gehlenborg", "Jeffrey Heer"], "title": "Automatic Synthesis of Visualization Design Knowledge Bases", "categories": ["cs.HC"], "comment": "Accepted to CHI 2026. 17 pages, 16 figures, 5 tables", "summary": "Formal representations of the visualization design space, such as knowledge bases and graphs, consolidate design practices into a shared resource and enable automated reasoning and interpretable design recommendations. However, prior approaches typically depend on fixed, manually authored rules, making it difficult to build novel representations or extend them for different visualization domains. Instead, we propose data-driven methods that automatically synthesize visualization design knowledge bases. Specifically, our methods (1) extract candidate design features from a visualization corpus, (2) select features forward and backward, and (3) render the final knowledge base. In our benchmark evaluation compared to Draco 2, our synthesized knowledge base offers general and interpretable design features and improves the accuracy of predicting effective designs by 1-15% in varied training and test sets. When we apply our approach to genomics visualization, the synthesized knowledge base includes sensible features with accuracy up to 97%, demonstrating the applicability of our approach to other visualization domains.", "AI": {"tldr": "本文提出了一种自动合成可视化设计知识库的方法，以改进现有依赖固定手动规则的局限性。", "motivation": "现有的方法通常依赖于固定的、手动编写的规则来构建或扩展可视化设计的知识库，这限制了创建新的表示形式和适应不同的可视化领域的能力。因此，作者提出了一种数据驱动的方法来自动合成知识库。", "method": "该方法包括三个步骤：从可视化语料中提取候选设计特征、选择前向和后向的特征以及生成最终的知识库。", "result": "在与Draco2的基准对比评估中，所提出的合成的知识库提供了一般性和可解释性的设计特性，并将预测有效设计准确率提高了1-15%。应用于基因组学可视化时，该知识库表现出高达97%的准确性。", "conclusion": "通过自动化的数据驱动方法可以有效地生成适用于不同领域的可视化设计知识库，这种方法提供了比现有手动规则更灵活和广泛的应用潜力。"}}
{"id": "2601.19236", "pdf": "https://arxiv.org/pdf/2601.19236", "abs": "https://arxiv.org/abs/2601.19236", "authors": ["Zhiyu Yin", "Zhipeng Liu", "Kehai Chen", "Lemao Liu", "Jin Liu", "Hong-Dong Li", "Yang Xiang", "Min Zhang"], "title": "VC-Bench: Pioneering the Video Connecting Benchmark with a Dataset and Evaluation Metrics", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "While current video generation focuses on text or image conditions, practical applications like video editing and vlogging often need to seamlessly connect separate clips. In our work, we introduce Video Connecting, an innovative task that aims to generate smooth intermediate video content between given start and end clips. However, the absence of standardized evaluation benchmarks has hindered the development of this task. To bridge this gap, we proposed VC-Bench, a novel benchmark specifically designed for video connecting. It includes 1,579 high-quality videos collected from public platforms, covering 15 main categories and 72 subcategories to ensure diversity and structure. VC-Bench focuses on three core aspects: Video Quality Score VQS, Start-End Consistency Score SECS, and Transition Smoothness Score TSS. Together, they form a comprehensive framework that moves beyond conventional quality-only metrics. We evaluated multiple state-of-the-art video generation models on VC-Bench. Experimental results reveal significant limitations in maintaining start-end consistency and transition smoothness, leading to lower overall coherence and fluidity. We expect that VC-Bench will serve as a pioneering benchmark to inspire and guide future research in video connecting. The evaluation metrics and dataset are publicly available at: https://anonymous.4open.science/r/VC-Bench-1B67/.", "AI": {"tldr": "本文提出了一个新的视频连接任务，并开发了VC-Bench评估基准。", "motivation": "当前的视频生成技术主要集中在文本或图像条件上，而实际应用如视频编辑和vlogging需要无缝地将分段视频连接起来。然而缺乏标准化的评估基准阻碍了这一领域的发展。", "method": "本文提出了VC-Bench，这是一个专门用于视频连接的新基准，包括1579个高质量视频，涵盖了15个主要类别和72个子类别的多样化数据集。该框架关注三个方面：视频质量评分VQS、开始结束一致性评分SECS和过渡平滑性评分TSS。", "result": "实验结果表明，在保持开始和结束的一致性和过渡平滑性方面，现有的最先进的视频生成模型存在显著的局限性，导致整体连贯性和流畅度较低。", "conclusion": "VC-Bench作为首个视频连接评估基准将启发并引导未来的研究工作。"}}
{"id": "2601.19234", "pdf": "https://arxiv.org/pdf/2601.19234", "abs": "https://arxiv.org/abs/2601.19234", "authors": ["Youndo Do", "Chad Meece", "Marc Zebrowitz", "Spencer Banks", "Myeongjun Choi", "Xiaoxu Diao", "Kai Tan", "Michael Doran", "Jason Reed", "Fan Zhang"], "title": "iFAN Ecosystem: A Unified AI, Digital Twin, Cyber-Physical Security, and Robotics Environment for Advanced Nuclear Simulation and Operations", "categories": ["cs.RO"], "comment": null, "summary": "As nuclear facilities experience digital transformation and advanced reactor development, AI integration, cyber-physical security, and other emerging technologies such as autonomous robot operations are increasingly developed. However, evaluation and deployment is challenged by the lack of dedicated virtual testbeds. The Immersive Framework for Advanced Nuclear (iFAN) ecosystem is developed, a comprehensive digital twin framework with a realistic 3D environment with physics-based simulations. The iFAN ecosystem serves as a high-fidelity virtual testbed for plant operation, cybersecurity, physical security, and robotic operation, as it provides real-time data exchange for pre-deployment verification. Core features include virtual reality, reinforcement learning, radiation simulation, and cyber-physical security. In addition, the paper investigates various applications through potential operational scenarios. The iFAN ecosystem provides a versatile and secure architecture for validating the next generation of autonomous and cyber-resilient nuclear operations.", "AI": {"tldr": "开发了一个用于先进核设施操作、网络安全和机器人操作的综合数字孪生框架iFAN生态系统。", "motivation": "随着核电站经历数字化转型，AI集成、网络物理安全等新兴技术的应用面临缺乏专门虚拟测试平台的问题。", "method": "创建了一种基于现实3D环境与物理模拟的高度逼真虚拟测试床iFAN生态系统，包含虚拟现实、强化学习、辐射模拟和网络安全功能。", "result": "该系统提供了一个多用途且安全的架构来验证下一代自主及网络弹性核操作，并通过潜在的操作场景进行应用研究。", "conclusion": "iFAN生态系统为先进核设施的预部署验证提供了高保真虚拟测试平台，提升了运营效率和安全性。"}}
{"id": "2601.19232", "pdf": "https://arxiv.org/pdf/2601.19232", "abs": "https://arxiv.org/abs/2601.19232", "authors": ["Qi Si", "Xuyang Liu", "Penglei Wang", "Xin Guo", "Yuan Qi", "Yuan Cheng"], "title": "Structure-based RNA Design by Step-wise Optimization of Latent Diffusion Model", "categories": ["cs.LG", "cs.AI"], "comment": "20 pages (7 pages content + 2 pages references + 11 pages appendix), 11 figures, 8 tables. Source code available at https://github.com/darkflash03/SOLD Accepted to AAAI 2026", "summary": "RNA inverse folding, designing sequences to form specific 3D structures, is critical for therapeutics, gene regulation, and synthetic biology. Current methods, focused on sequence recovery, struggle to address structural objectives like secondary structure consistency (SS), minimum free energy (MFE), and local distance difference test (LDDT), leading to suboptimal structural accuracy. To tackle this, we propose a reinforcement learning (RL) framework integrated with a latent diffusion model (LDM). Drawing inspiration from the success of diffusion models in RNA inverse folding, which adeptly model complex sequence-structure interactions, we develop an LDM incorporating pre-trained RNA-FM embeddings from a large-scale RNA model. These embeddings capture co-evolutionary patterns, markedly improving sequence recovery accuracy. However, existing approaches, including diffusion-based methods, cannot effectively handle non-differentiable structural objectives. By contrast, RL excels in this task by using policy-driven reward optimization to navigate complex, non-gradient-based objectives, offering a significant advantage over traditional methods. In summary, we propose the Step-wise Optimization of Latent Diffusion Model (SOLD), a novel RL framework that optimizes single-step noise without sampling the full diffusion trajectory, achieving efficient refinement of multiple structural objectives. Experimental results demonstrate SOLD surpasses its LDM baseline and state-of-the-art methods across all metrics, establishing a robust framework for RNA inverse folding with profound implications for biotechnological and therapeutic applications.", "AI": {"tldr": "本文提出了一种新的RL框架SOLD，通过优化单步噪声来实现RNA逆折叠中的结构目标的高效精炼。", "motivation": "当前方法在解决结构性目标时效果不佳，如次级结构一致性、最小自由能和局部距离差异测试等。为改进这些问题，该研究引入了强化学习结合潜在扩散模型的方法。", "method": "开发了一种新的RL框架SOLD，其整合了预训练的RNA-FM嵌入，并通过逐步优化潜扩散模型中的单步噪声来实现高效精炼。", "result": "实验结果表明，SOLD在所有指标上都超过了其LDM基线和最先进的方法。", "conclusion": "该研究提出了一种有效的框架用于RNA逆折叠问题，具有重要的生物技术和治疗应用潜力。"}}
{"id": "2601.19228", "pdf": "https://arxiv.org/pdf/2601.19228", "abs": "https://arxiv.org/abs/2601.19228", "authors": ["Tianhui Song", "Haoyu Lu", "Hao Yang", "Lin Sui", "Haoning Wu", "Zaida Zhou", "Zhiqi Huang", "Yiping Bao", "Y. Charles", "Xinyu Zhou", "Limin Wang"], "title": "Towards Pixel-Level VLM Perception via Simple Points Prediction", "categories": ["cs.CV"], "comment": null, "summary": "We present SimpleSeg, a strikingly simple yet highly effective approach to endow Multimodal Large Language Models (MLLMs) with native pixel-level perception. Our method reframes segmentation as a simple sequence generation problem: the model directly predicts sequences of points (textual coordinates) delineating object boundaries, entirely within its language space. To achieve high fidelity, we introduce a two-stage SF$\\to$RL training pipeline, where Reinforcement Learning with an IoU-based reward refines the point sequences to accurately match ground-truth contours. We find that the standard MLLM architecture possesses a strong, inherent capacity for low-level perception that can be unlocked without any specialized architecture. On segmentation benchmarks, SimpleSeg achieves performance that is comparable to, and often surpasses, methods relying on complex, task-specific designs. This work lays out that precise spatial understanding can emerge from simple point prediction, challenging the prevailing need for auxiliary components and paving the way for more unified and capable VLMs. Homepage: https://simpleseg.github.io/", "AI": {"tldr": "该论文提出了SimpleSeg，一种简单而有效的将多模态大型语言模型（MLLM）赋予像素级感知能力的方法。", "motivation": "通过将分割任务重新定义为简单的序列生成问题，并引入强化学习来提高精度，旨在展示标准MLLM架构具有强大的低级感知能力。", "method": "SimpleSeg方法通过预测描述对象边界的点序列来进行图像分割。使用基于IoU的奖励机制进行两阶段训练以优化结果。", "result": "在分割基准测试中，SimpleSeg的表现与依赖复杂特定任务设计的方法相当或更优。", "conclusion": "该工作表明精确的空间理解可以通过简单的点预测实现，为更统一和强大的视觉语言模型铺平道路。"}}
{"id": "2601.19225", "pdf": "https://arxiv.org/pdf/2601.19225", "abs": "https://arxiv.org/abs/2601.19225", "authors": ["Kaehyun Um", "KyuHwan Yeom", "Haerim Yang", "Minyoung Choi", "Hyeongjun Yang", "Kyong-Ho Lee"], "title": "RPO-RAG: Aligning Small LLMs with Relation-aware Preference Optimization for Knowledge Graph Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at The Web Conference (WWW) 2026", "summary": "Large Language Models (LLMs) have recently demonstrated remarkable reasoning abilities, yet hallucinate on knowledge-intensive tasks. Retrieval-augmented generation (RAG) mitigates this issue by grounding answers in external sources, e.g., knowledge graphs (KGs). However, existing KG-based RAG approaches rely on semantics-unaware path sampling and are weakly aligned with KG reasoning objectives, which limits further accuracy gains. They also feed retrieved paths directly into the reasoner without organizing them into answer-centered reasoning paths, hindering small LLMs' ability to leverage the retrieved knowledge. Furthermore, prior works predominantly rely on large LLMs (e.g., ChatGPT/GPT-4) or assume backbones above 7B parameters, leaving sub-7B models underexplored. We address this gap with RPO-RAG, the first KG-based RAG framework specifically designed for small LLMs, to the best of our knowledge. RPO-RAG introduces three key innovations: (1) a query-path semantic sampling strategy that provides informative supervisory signals; (2) a relation-aware preference optimization that aligns training with intermediate KG reasoning signals (e.g., relation); and (3) an answer-centered prompt design that organizes entities and reasoning paths in an interpretable format. Extensive experiments on two benchmark Knowledge Graph Question Answering (KGQA) datasets, WebQSP and CWQ, demonstrate that RPO-RAG effectively bridges the performance gap between small and large language models. On WebQSP, it improves F1 by up to 8.8%, reflecting enhanced answer precision, while on CWQ it achieves new state-of-the-art results among models under 8B parameters in both Hit and F1. Overall, RPO-RAG substantially improves the reasoning capability of small LLMs, even under 3B parameters-highlighting their potential for resource-efficient and practical on-device KGQA applications.", "AI": {"tldr": "RPO-RAG是一种针对小规模LLM的知识图谱问答框架，通过创新的语义采样策略、关系感知偏好优化和以答案为中心的提示设计来提升模型性能。", "motivation": "现有的知识图谱增强生成方法在处理知识密集型任务时存在不足，包括依赖于非语义路径抽样以及未充分整合知识图谱推理信号。此外，这些方法主要依靠大规模LLM，忽略了小型模型的应用潜力。", "method": "RPO-RAG引入了查询-路径语义采样策略、关系感知偏好优化和以答案为中心的提示设计来改进现有方法，并在两个基准数据集上验证其有效性。", "result": "实验结果显示，在WebQSP上，RPO-RAG提升了8.8%的F1分数；在CWQ上取得了新的最佳结果。这些成果表明了RPO-RAG能显著提升小规模LLM的知识图谱问答能力。", "conclusion": "通过创新设计，RPO-RAG展示了小型LLM在资源效率和实际应用中的潜力，特别是在设备端进行知识图谱问答任务时表现出色。"}}
{"id": "2601.19222", "pdf": "https://arxiv.org/pdf/2601.19222", "abs": "https://arxiv.org/abs/2601.19222", "authors": ["Fuxiang Sun", "Xi Jiang", "Jiansheng Wu", "Haigang Zhang", "Feng Zheng", "Jinfeng Yang"], "title": "UniPCB: A Unified Vision-Language Benchmark for Open-Ended PCB Quality Inspection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) show promise for general industrial quality inspection, but fall short in complex scenarios, such as Printed Circuit Board (PCB) inspection. PCB inspection poses unique challenges due to densely packed components, complex wiring structures, and subtle defect patterns that require specialized domain expertise. However, a high-quality, unified vision-language benchmark for quantitatively evaluating MLLMs across PCB inspection tasks remains absent, stemming not only from limited data availability but also from fragmented datasets and inconsistent standardization. To fill this gap, we propose UniPCB, the first unified vision-language benchmark for open-ended PCB quality inspection. UniPCB is built via a systematic pipeline that curates and standardizes data from disparate sources across three annotated scenarios. Furthermore, we introduce PCB-GPT, an MLLM trained on a new instruction dataset generated by this pipeline, utilizing a novel progressive curriculum that mimics the learning process of human experts. Evaluations on the UniPCB benchmark show that while existing MLLMs falter on domain-specific tasks, PCB-GPT establishes a new baseline. Notably, it more than doubles the performance on fine-grained defect localization compared to the strongest competitors, with significant advantages in localization and analysis. We will release the instruction data, benchmark, and model to facilitate future research.", "AI": {"tldr": "UniPCB是一个统一的视觉语言基准，用于评估多模态大型语言模型在电路板质量检测任务中的性能。", "motivation": "现有的多模态大型语言模型（MLLMs）在复杂的电路板检查场景中表现出不足，缺乏高质量、统一的视觉语言基准来量化这些模型的表现。此外，由于数据集分散和标准化不一致的问题，这使得建立有效的评估标准变得更加困难。", "method": "通过一个系统化流程从不同来源收集并标准化数据以构建UniPCB，该过程涵盖了三个标注场景。同时引入了基于新指令数据集训练的MLLM——PCB-GPT，使用模仿人类专家学习过程的新颖渐进式课程表。", "result": "在UniPCB基准上的评估显示现有模型在领域特定任务上表现不佳，而PCB-GPT则建立了一个新的性能基线。尤其在精细缺陷定位方面，其表现优于最强竞争对手超过一倍。", "conclusion": "该研究填补了多模态大型语言模型在复杂工业质量检测场景中的空白，并为未来的研究提供了数据集、基准和模型的开放访问。"}}
{"id": "2601.19216", "pdf": "https://arxiv.org/pdf/2601.19216", "abs": "https://arxiv.org/abs/2601.19216", "authors": ["Chaozheng Wen", "Jingwen Tong", "Zehong Lin", "Chenghong Bian", "Jun Zhang"], "title": "Bridging Visual and Wireless Sensing: A Unified Radiation Field for 3D Radio Map Construction", "categories": ["cs.NI", "cs.AI", "cs.CV", "cs.LG"], "comment": "The code for this work will be publicly available at: https://github.com/wenchaozheng/URF-GS", "summary": "The emerging applications of next-generation wireless networks (e.g., immersive 3D communication, low-altitude networks, and integrated sensing and communication) necessitate high-fidelity environmental intelligence. 3D radio maps have emerged as a critical tool for this purpose, enabling spectrum-aware planning and environment-aware sensing by bridging the gap between physical environments and electromagnetic signal propagation. However, constructing accurate 3D radio maps requires fine-grained 3D geometric information and a profound understanding of electromagnetic wave propagation. Existing approaches typically treat optical and wireless knowledge as distinct modalities, failing to exploit the fundamental physical principles governing both light and electromagnetic propagation. To bridge this gap, we propose URF-GS, a unified radio-optical radiation field representation framework for accurate and generalizable 3D radio map construction based on 3D Gaussian splatting (3D-GS) and inverse rendering. By fusing visual and wireless sensing observations, URF-GS recovers scene geometry and material properties while accurately predicting radio signal behavior at arbitrary transmitter-receiver (Tx-Rx) configurations. Experimental results demonstrate that URF-GS achieves up to a 24.7% improvement in spatial spectrum prediction accuracy and a 10x increase in sample efficiency for 3D radio map construction compared with neural radiance field (NeRF)-based methods. This work establishes a foundation for next-generation wireless networks by integrating perception, interaction, and communication through holistic radiation field reconstruction.", "AI": {"tldr": "提出了一种统一的无线电光学辐射场表示框架URF-GS，以构建准确和通用化的3D无线图。", "motivation": "为了满足下一代无线网络的需求，如沉浸式三维通信、低空网络等，需要高保真环境智能。现有的方法未能充分利用光与电磁波传播的基本物理原理，导致难以精确构造3D无线图。", "method": "通过结合视觉和无线感知观测，URF-GS基于3D高斯点光源（3D-GS）和逆渲染技术，恢复场景几何形状及材料属性，并准确预测任意发射器-接收器配置下的无线电信号行为。", "result": "实验结果表明，URF-GS在空间频谱预测精度上比NeRF方法提高24.7%，并在三维无线图构建的采样效率上提高了10倍。", "conclusion": "该工作通过全辐射场重建将感知、交互和通信融合在一起，为下一代无线网络奠定了基础。"}}
{"id": "2601.19214", "pdf": "https://arxiv.org/pdf/2601.19214", "abs": "https://arxiv.org/abs/2601.19214", "authors": ["Aakash Trivedi", "Aniket Upadhyay", "Pratik Narang", "Dhruv Kumar", "Praveen Kumar"], "title": "A Hybrid Supervised-LLM Pipeline for Actionable Suggestion Mining in Unstructured Customer Reviews", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to EACL 2026 Industry Track (to appear)", "summary": "Extracting actionable suggestions from customer reviews is essential for operational decision-making, yet these directives are often embedded within mixed-intent, unstructured text. Existing approaches either classify suggestion-bearing sentences or generate high-level summaries, but rarely isolate the precise improvement instructions businesses need. We evaluate a hybrid pipeline combining a high-recall RoBERTa classifier trained with a precision-recall surrogate to reduce unrecoverable false negatives with a controlled, instruction-tuned LLM for suggestion extraction, categorization, clustering, and summarization. Across real-world hospitality and food datasets, the hybrid system outperforms prompt-only, rule-based, and classifier-only baselines in extraction accuracy and cluster coherence. Human evaluations further confirm that the resulting suggestions and summaries are clear, faithful, and interpretable. Overall, our results show that hybrid reasoning architectures achieve meaningful improvements fine-grained actionable suggestion mining while highlighting challenges in domain adaptation and efficient local deployment.", "AI": {"tldr": "本文提出了一种结合监督学习和LLM的混合管道，用于从客户评论中提取可操作性建议。", "motivation": "现有方法难以精确地从非结构化文本中分离出业务改进指令，本研究旨在解决此问题，提升运营决策的质量。", "method": "采用高召回率的RoBERTa分类器结合精准度优化策略减少不可挽回的假阴性，并通过指令调优的LLM进行建议提取、分类、聚类和总结。", "result": "在真实世界的数据集中，该混合系统的表现优于单一模型和基于规则的方法，在提取准确性和集群一致性上表现出色；人机评估证实了其结果清晰、忠实且可解释。", "conclusion": "研究表明，混合架构实现了细粒度的建议挖掘的有效改进，但仍存在领域适应性及本地部署效率方面的挑战。"}}
{"id": "2601.19210", "pdf": "https://arxiv.org/pdf/2601.19210", "abs": "https://arxiv.org/abs/2601.19210", "authors": ["Sen Nie", "Jie Zhang", "Zhuo Wang", "Shiguang Shan", "Xilin Chen"], "title": "Contrastive Spectral Rectification: Test-Time Defense towards Zero-shot Adversarial Robustness of CLIP", "categories": ["cs.CV"], "comment": "21 pages", "summary": "Vision-language models (VLMs) such as CLIP have demonstrated remarkable zero-shot generalization, yet remain highly vulnerable to adversarial examples (AEs). While test-time defenses are promising, existing methods fail to provide sufficient robustness against strong attacks and are often hampered by high inference latency and task-specific applicability. To address these limitations, we start by investigating the intrinsic properties of AEs, which reveals that AEs exhibit severe feature inconsistency under progressive frequency attenuation. We further attribute this to the model's inherent spectral bias. Leveraging this insight, we propose an efficient test-time defense named Contrastive Spectral Rectification (CSR). CSR optimizes a rectification perturbation to realign the input with the natural manifold under a spectral-guided contrastive objective, which is applied input-adaptively. Extensive experiments across 16 classification benchmarks demonstrate that CSR outperforms the SOTA by an average of 18.1% against strong AutoAttack with modest inference overhead. Furthermore, CSR exhibits broad applicability across diverse visual tasks. Code is available at https://github.com/Summu77/CSR.", "AI": {"tldr": "提出了一种有效的测试时间防御方法CSR，用于改善CLIP等视觉语言模型在对抗样本下的零样本鲁棒性。", "motivation": "现有方法难以提供足够的抗强攻击的鲁棒性和任务特定适用性，同时存在高推理延迟。研究揭示了对抗样例在频域上表现出严重的特征不一致性，并提出了CSR来解决这些问题。", "method": "基于频谱引导对比目标优化输入矫正扰动，实现将输入与自然流形对齐，从而提高模型的鲁棒性。", "result": "实验结果表明，CSR方法在16个分类基准上比现有最佳方法平均提高了18.1%的性能，并且表现出广泛的适用性和较低的推理延迟。", "conclusion": "CSR提供了一种有效的零样本抗对抗攻击的方法，适用于多种视觉任务。"}}
{"id": "2601.19205", "pdf": "https://arxiv.org/pdf/2601.19205", "abs": "https://arxiv.org/abs/2601.19205", "authors": ["Zefeng Lin", "Zhihang Zhang", "Weirong Zhu", "Tongchang Han", "Xianyong Fang", "Tianfan Fu", "Xiaohua Xu"], "title": "EnzyPGM: Pocket-conditioned Generative Model for Substrate-specific Enzyme Design", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "comment": "9 pages, 4 figures, under review", "summary": "Designing enzymes with substrate-binding pockets is a critical challenge in protein engineering, as catalytic activity depends on the precise interaction between pockets and substrates. Currently, generative models dominate functional protein design but cannot model pocket-substrate interactions, which limits the generation of enzymes with precise catalytic environments. To address this issue, we propose EnzyPGM, a unified framework that jointly generates enzymes and substrate-binding pockets conditioned on functional priors and substrates, with a particular focus on learning accurate pocket-substrate interactions. At its core, EnzyPGM includes two main modules: a Residue-atom Bi-scale Attention (RBA) that jointly models intra-residue dependencies and fine-grained interactions between pocket residues and substrate atoms, and a Residue Function Fusion (RFF) that incorporates enzyme function priors into residue representations. Also, we curate EnzyPock, an enzyme-pocket dataset comprising 83,062 enzyme-substrate pairs across 1,036 four-level enzyme families. Extensive experiments demonstrate that EnzyPGM achieves state-of-the-art performance on EnzyPock. Notably, EnzyPGM reduces the average binding energy of 0.47 kcal/mol over EnzyGen, showing its superior performance on substrate-specific enzyme design. The code and dataset will be released later.", "AI": {"tldr": "本文提出了EnzyPGM，一种用于特定底物酶设计的条件生成模型。", "motivation": "当前的生成模型无法模拟口袋-底物相互作用，这限制了精确催化环境的设计。为了克服这一问题，作者提出了一种能够学习准确口袋-底物相互作用的新方法。", "method": "EnzyPGM包括两个主要模块：Residue-atom Bi-scale Attention (RBA) 和 Residue Function Fusion (RFF)，前者用于模拟跨残基依赖性和精细的口袋残基与底物原子之间的交互，后者则将酶功能先验融入到残基表示中。", "result": "EnzyPGM在专有的83,062个酶-底物对的数据集上达到了最先进的性能，并且相较于之前的模型，它平均降低了0.47 kcal/mol的结合能量。", "conclusion": "通过引入精确模拟口袋与底物相互作用的方法，EnzyPGM展现了其在特定底物设计方面的优越性。"}}
{"id": "2601.19204", "pdf": "https://arxiv.org/pdf/2601.19204", "abs": "https://arxiv.org/abs/2601.19204", "authors": ["Zhixi Cai", "Fucai Ke", "Kevin Leo", "Sukai Huang", "Maria Garcia de la Banda", "Peter J. Stuckey", "Hamid Rezatofighi"], "title": "MATA: A Trainable Hierarchical Automaton System for Multi-Agent Visual Reasoning", "categories": ["cs.AI", "cs.CV"], "comment": "ICLR 2026", "summary": "Recent vision-language models have strong perceptual ability but their implicit reasoning is hard to explain and easily generates hallucinations on complex queries. Compositional methods improve interpretability, but most rely on a single agent or hand-crafted pipeline and cannot decide when to collaborate across complementary agents or compete among overlapping ones. We introduce MATA (Multi-Agent hierarchical Trainable Automaton), a multi-agent system presented as a hierarchical finite-state automaton for visual reasoning whose top-level transitions are chosen by a trainable hyper agent. Each agent corresponds to a state in the hyper automaton, and runs a small rule-based sub-automaton for reliable micro-control. All agents read and write a shared memory, yielding transparent execution history. To supervise the hyper agent's transition policy, we build transition-trajectory trees and transform to memory-to-next-state pairs, forming the MATA-SFT-90K dataset for supervised finetuning (SFT). The finetuned LLM as the transition policy understands the query and the capacity of agents, and it can efficiently choose the optimal agent to solve the task. Across multiple visual reasoning benchmarks, MATA achieves the state-of-the-art results compared with monolithic and compositional baselines. The code and dataset are available at https://github.com/ControlNet/MATA.", "AI": {"tldr": "MATA 是一种可训练的分层自动机系统，用于多代理视觉推理。", "motivation": "近期的视觉语言模型具有强大的感知能力，但其隐含推理难以解释，并且容易在复杂查询中产生幻觉。虽然组合方法提高了可解释性，但是大多数依赖于单一代理或手工制作的管道，无法决定何时协作互补代理或竞争重叠代理。", "method": "MATA 是一种多代理系统，呈现为分层有限状态自动机用于视觉推理。顶层转换由训练超代理选择。每个代理对应于超级自动机中的一个状态，并运行一个小规则子自动机进行可靠的微控制。所有代理读写共享内存，产生透明的执行历史记录。", "result": "MATA 在多个视觉推理基准测试中取得了比单一和组合基线更好的结果。", "conclusion": "该研究提出了一种新颖的方法 MATA，它通过多代理协作来提高视觉推理任务中的性能，并且其代码和数据集已公开。"}}
{"id": "2601.19203", "pdf": "https://arxiv.org/pdf/2601.19203", "abs": "https://arxiv.org/abs/2601.19203", "authors": ["Kaicheng Wang", "Kevin Zhongyang Shao", "Ruiqi Chen", "Sep Makhsous", "Denise Wilson"], "title": "Before Smelling the Video: A Two-Stage Pipeline for Interpretable Video-to-Scent Plans", "categories": ["cs.HC"], "comment": "In submission of poster as ongoing project", "summary": "Olfactory cues can enhance immersion in interactive media, yet smell remains rare because it is difficult to author and synchronize with dynamic video. Prior olfactory interfaces rely on designer triggers and fixed event-to-odor mappings that do not scale to unconstrained content. This work examines whether semantic planning for smell is intelligible to people before physical scent delivery. We present a video-to-scent planning pipeline that separates visual semantic extraction using a vision-language model from semantic-to-olfactory inference using a large language model. Two survey studies compare system-generated scent plans with over-inclusive and naive baselines. Results show consistent preference for plans that prioritize perceptually salient cues and align scent changes with visible actions, supporting semantic planning as a foundation for future olfactory media systems.", "AI": {"tldr": "提出了一种两阶段的视频到气味规划管道，以增强互动媒体中的沉浸感。", "motivation": "通过语义规划实现可解释性嗅觉计划，提升与动态视频同步的复杂内容的用户体验。", "method": "利用视觉语言模型进行视觉语义提取，并使用大型语言模型将语义转化为嗅觉推断。进行两个调查研究以比较系统生成的气味计划与其他基准。", "result": "结果显示人们更倾向于优先考虑感知显著线索并根据可见动作调整气味变化的计划。", "conclusion": "支持基于语义规划作为未来嗅觉媒体系统的基石。"}}
{"id": "2601.19199", "pdf": "https://arxiv.org/pdf/2601.19199", "abs": "https://arxiv.org/abs/2601.19199", "authors": ["Libo Sun", "Jiwen Zhang", "Siyuan Wang", "Zhongyu Wei"], "title": "MAGNET: Towards Adaptive GUI Agents with Memory-Driven Knowledge Evolution", "categories": ["cs.AI"], "comment": null, "summary": "Mobile GUI agents powered by large foundation models enable autonomous task execution, but frequent updates altering UI appearance and reorganizing workflows cause agents trained on historical data to fail. Despite surface changes, functional semantics and task intents remain fundamentally stable. Building on this insight, we introduce MAGNET, a memory-driven adaptive agent framework with dual-level memory: stationary memory linking diverse visual features to stable functional semantics for robust action grounding and procedural memory capturing stable task intents across varying workflows. We propose a dynamic memory evolution mechanism that continuously refines both memories by prioritizing frequently accessed knowledge. Online benchmark AndroidWorld evaluations show substantial improvements over baselines, while offline benchmarks confirm consistent gains under distribution shifts. These results validate that leveraging stable structures across interface changes improves agent performance and generalization in evolving software environments.", "AI": {"tldr": "MAGNET是一个基于记忆驱动的自适应GUI代理框架，旨在解决频繁更新导致的历史训练数据失效问题。", "motivation": "移动GUI代理在任务执行中面临由于界面频繁更新而导致的功能稳定性和用户意图识别困难的问题。", "method": "提出了一种具有双层记忆的MAGNET框架，通过动态内存演化机制持续优化知识。", "result": "在线AndroidWorld评估表明，相比基线方法，MAGNET在面对分布变化时性能更优。", "conclusion": "利用界面更新中稳定的部分改进了代理在不断演变软件环境中的性能和泛化能力。"}}
{"id": "2601.19197", "pdf": "https://arxiv.org/pdf/2601.19197", "abs": "https://arxiv.org/abs/2601.19197", "authors": ["Sushant Mehta"], "title": "HELM: A Human-Centered Evaluation Framework for LLM-Powered Recommender Systems", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "The integration of Large Language Models (LLMs) into recommendation systems has introduced unprecedented capabilities for natural language understanding, explanation generation, and conversational interactions. However, existing evaluation methodologies focus predominantly on traditional accuracy metrics, failing to capture the multifaceted human-centered qualities that determine the real-world user experience. We introduce \\framework{} (\\textbf{H}uman-centered \\textbf{E}valuation for \\textbf{L}LM-powered reco\\textbf{M}menders), a comprehensive evaluation framework that systematically assesses LLM-powered recommender systems across five human-centered dimensions: \\textit{Intent Alignment}, \\textit{Explanation Quality}, \\textit{Interaction Naturalness}, \\textit{Trust \\& Transparency}, and \\textit{Fairness \\& Diversity}. Through extensive experiments involving three state-of-the-art LLM-based recommenders (GPT-4, LLaMA-3.1, and P5) across three domains (movies, books, and restaurants), and rigorous evaluation by 12 domain experts using 847 recommendation scenarios, we demonstrate that \\framework{} reveals critical quality dimensions invisible to traditional metrics. Our results show that while GPT-4 achieves superior explanation quality (4.21/5.0) and interaction naturalness (4.35/5.0), it exhibits a significant popularity bias (Gini coefficient 0.73) compared to traditional collaborative filtering (0.58). We release \\framework{} as an open-source toolkit to advance human-centered evaluation practices in the recommender systems community.", "AI": {"tldr": "介绍一个全面评估LLM驱动推荐系统的框架\framework{}，该框架关注五个以人为中心的维度：意图对齐、解释质量、交互自然度、信任透明性和公平多样性。", "motivation": "现有评价方法侧重于传统准确性指标，未能捕捉到决定真实用户体验的多方面人类属性。因此需要一个新的评估框架来全面衡量LLM驱动推荐系统的性能。", "method": "\framework{}通过五个以人为中心的维度评估三个最先进的LLM基线推荐系统（GPT-4, LLaMA-3.1和P5），并由领域专家进行评估，涵盖电影、书籍和餐厅等不同场景。", "result": "结果表明\framework{}揭示了传统指标无法捕捉的质量维度。例如，尽管GPT-4在解释质量和交互自然度上表现出色（评分分别为4.21/5.0和4.35/5.0），但它存在显著的流行偏见。", "conclusion": "\framework{}是一个开源工具包，可以促进推荐系统社区中以人为中心的评估实践，以更全面地衡量LLM驱动系统的性能。"}}
{"id": "2601.19194", "pdf": "https://arxiv.org/pdf/2601.19194", "abs": "https://arxiv.org/abs/2601.19194", "authors": ["Alexander Polok", "Dominik Klement", "Samuele Cornell", "Matthew Wiesner", "Jan Černocký", "Sanjeev Khudanpur", "Lukáš Burget"], "title": "SE-DiCoW: Self-Enrolled Diarization-Conditioned Whisper", "categories": ["eess.AS", "cs.LG"], "comment": "Accepted to ICASSP 2026", "summary": "Speaker-attributed automatic speech recognition (ASR) in multi-speaker environments remains a major challenge. While some approaches achieve strong performance when fine-tuned on specific domains, few systems generalize well across out-of-domain datasets. Our prior work, Diarization-Conditioned Whisper (DiCoW), leverages speaker diarization outputs as conditioning information and, with minimal fine-tuning, demonstrated strong multilingual and multi-domain performance. In this paper, we address a key limitation of DiCoW: ambiguity in Silence-Target-Non-target-Overlap (STNO) masks, where two or more fully overlapping speakers may have nearly identical conditioning despite differing transcriptions. We introduce SE-DiCoW (Self-Enrolled Diarization-Conditioned Whisper), which uses diarization output to locate an enrollment segment anywhere in the conversation where the target speaker is most active. This enrollment segment is used as fixed conditioning via cross-attention at each encoder layer. We further refine DiCoW with improved data segmentation, model initialization, and augmentation. Together, these advances yield substantial gains: SE-DiCoW reduces macro-averaged tcpWER by 52.4% relative to the original DiCoW on the EMMA MT-ASR benchmark.", "AI": {"tldr": "SE-DiCoW 使用语音分割输出来选择目标说话者最活跃的片段作为固定条件，以改进多说话者的自动语音识别。", "motivation": "解决DiCoW在Silence-Target-Non-target-Overlap（STNO）掩码中的歧义问题，即两个或多个完全重叠的说话者可能具有几乎相同的条件信息但转录不同。", "method": "SE-DiCoW 使用语音分割输出来定位目标说话者的最活跃片段作为固定条件，并通过交叉注意力机制在每个编码器层中使用。此外，还改进了数据分割、模型初始化和增强技术。", "result": "SE-DiCoW 在EMMA MT-ASR基准测试上将宏平均tcpWER相对减少了52.4%。", "conclusion": "通过引入自注册机制并优化方法，SE-DiCoW 实现了对多说话者环境的自动语音识别任务上的显著改进。"}}
{"id": "2601.19193", "pdf": "https://arxiv.org/pdf/2601.19193", "abs": "https://arxiv.org/abs/2601.19193", "authors": ["Van-Quang Nguyen", "Takayuki Okatani"], "title": "CoReTab: Improving Multimodal Table Understanding with Code-driven Reasoning", "categories": ["cs.AI"], "comment": "accepted to EACL'26 (main conference)", "summary": "Existing datasets for multimodal table understanding, such as MMTab, primarily provide short factual answers without explicit multi-step reasoning supervision. Models trained on these datasets often generate brief responses that offers insufficient accuracy and limited interpretability into how these models arrive at the final answer. We introduce CoReTab, a code-driven reasoning framework that produces scalable, interpretable, and automatically verifiable annotations by coupling multi-step reasoning with executable Python code. Using the CoReTab framework, we curate a dataset of 115K verified samples averaging 529 tokens per response and fine-tune open-source MLLMs through a three-stage pipeline. We evaluate the resulting model trained on CoReTab across 17 MMTab benchmarks spanning table question answering, fact verification, and table structure understanding. Our model achieves significant gains of +6.2%, +5.7%, and +25.6%, respectively, over MMTab-trained baselines, while producing transparent and verifiable reasoning traces. These results establish CoReTab as a robust and generalizable supervision framework for improving multi-step reasoning in multimodal table understanding.", "AI": {"tldr": "本文提出了一种基于代码驱动推理的框架CoReTab，以改进多模态表格理解。", "motivation": "现有的多模态表格理解数据集缺乏详细的多步推理监督，模型生成的答案往往简短且不具解释性。为解决此问题，作者引入了CoReTab框架。", "method": "通过将多步骤推理与可执行Python代码相结合，CoReTab框架生成了大规模、可解释并能自动验证的注释，并利用该框架创建了一个包含115K个经过验证样本的数据集。使用三阶段管道训练开源MLLM模型。", "result": "在MMTab基准测试中，作者的模型比基于MMTab基线模型分别取得了+6.2%， +5.7%和+25.6%的性能提升，并且生成了透明可验证的推理轨迹。", "conclusion": "CoReTab被确立为提高多模态表格理解中多步推理能力的强大且通用监督框架。"}}
{"id": "2601.19180", "pdf": "https://arxiv.org/pdf/2601.19180", "abs": "https://arxiv.org/abs/2601.19180", "authors": ["Lifan Jiang", "Boxi Wu", "Yuhang Pei", "Tianrun Wu", "Yongyuan Chen", "Yan Zhao", "Shiyu Yu", "Deng Cai"], "title": "SNR-Edit: Structure-Aware Noise Rectification for Inversion-Free Flow-Based Editing", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Inversion-free image editing using flow-based generative models challenges the prevailing inversion-based pipelines. However, existing approaches rely on fixed Gaussian noise to construct the source trajectory, leading to biased trajectory dynamics and causing structural degradation or quality loss. To address this, we introduce SNR-Edit, a training-free framework achieving faithful Latent Trajectory Correction via adaptive noise control. Mechanistically, SNR-Edit uses structure-aware noise rectification to inject segmentation constraints into the initial noise, anchoring the stochastic component of the source trajectory to the real image's implicit inversion position and reducing trajectory drift during source--target transport. This lightweight modification yields smoother latent trajectories and ensures high-fidelity structural preservation without requiring model tuning or inversion. Across SD3 and FLUX, evaluations on PIE-Bench and SNR-Bench show that SNR-Edit delivers performance on pixel-level metrics and VLM-based scoring, while adding only about 1s overhead per image.", "AI": {"tldr": "SNR-Edit是一种无需训练的框架，通过自适应噪声控制实现忠实的潜在轨迹校正。", "motivation": "现有的基于流生成模型的无反转图像编辑方法依赖于固定的高斯噪声来构造源轨迹，导致偏移的轨迹动力学和结构退化或质量损失。SNR-Edit旨在解决这一问题，通过引入结构感知噪声校正以增强真实图像的隐式反演位置。", "method": "SNR-Edit利用结构感知噪声调整，在初始噪声中注入分割约束，将源轨迹中的随机成分锚定到真实图像的隐式反转位置，并减少从源到目标传输过程中的漂移。这使得潜在轨迹更平滑并保持高质量的结构性质。", "result": "在SD3和FLUX上进行的PIE-Bench和SNR-Bench评估表明，SNR-Edit能够提供像素级指标和基于VLM评分的表现，并且每张图像仅增加约1秒的开销。", "conclusion": "SNR-Edit无需模型调优或反转即可实现高保真度结构保持，证明了其在无逆向编辑中的有效性。"}}
{"id": "2601.19178", "pdf": "https://arxiv.org/pdf/2601.19178", "abs": "https://arxiv.org/abs/2601.19178", "authors": ["Jingyu Li", "Zhaocheng Du", "Qianhui Zhu", "kaiyuan Li", "Zhicheng Zhang", "Song-Li Wu", "Chaolang Li", "Pengwen Dai"], "title": "CollectiveKV: Decoupling and Sharing Collaborative Information in Sequential Recommendation", "categories": ["cs.AI"], "comment": "Accepted by ICLR 2026", "summary": "Sequential recommendation models are widely used in applications, yet they face stringent latency requirements. Mainstream models leverage the Transformer attention mechanism to improve performance, but its computational complexity grows with the sequence length, leading to a latency challenge for long sequences. Consequently, KV cache technology has recently been explored in sequential recommendation systems to reduce inference latency. However, KV cache introduces substantial storage overhead in sequential recommendation systems, which often have a large user base with potentially very long user history sequences. In this work, we observe that KV sequences across different users exhibit significant similarities, indicating the existence of collaborative signals in KV. Furthermore, we analyze the KV using singular value decomposition (SVD) and find that the information in KV can be divided into two parts: the majority of the information is shareable across users, while a small portion is user-specific. Motivated by this, we propose CollectiveKV, a cross-user KV sharing mechanism. It captures the information shared across users through a learnable global KV pool. During inference, each user retrieves high-dimensional shared KV from the pool and concatenates them with low-dimensional user-specific KV to obtain the final KV. Experiments on five sequential recommendation models and three datasets show that our method can compress the KV cache to only 0.8% of its original size, while maintaining or even enhancing model performance.", "AI": {"tldr": "提出了一种跨用户KV共享机制CollectiveKV，用于减少序列推荐系统的缓存存储开销。", "motivation": "主流的顺序推荐模型面临延迟挑战，KV缓存虽能降低推理延迟但引入了显著的存储开销。通过分析发现不同用户的KV存在相似性，并可分离为共用和用户特定两部分。", "method": "提出CollectiveKV机制，利用可学习的全局KV池捕捉跨用户共享信息，在推理时从池中提取高维共享KV并与低维用户特定KV拼接以获得最终KV。", "result": "实验显示该方法能将KV缓存压缩至原大小的0.8%，同时保持或提高模型性能。", "conclusion": "CollectiveKV有效地减少了KV存储开销，提高了序列推荐系统的效率。"}}
{"id": "2601.19175", "pdf": "https://arxiv.org/pdf/2601.19175", "abs": "https://arxiv.org/abs/2601.19175", "authors": ["Jinkyu Sung", "Myunggeum Jee", "Joonseok Lee"], "title": "A Scalable Inter-edge Correlation Modeling in CopulaGNN for Link Sign Prediction", "categories": ["cs.LG", "cs.AI", "cs.IR", "cs.SI"], "comment": "Accepted to ICLR 2026", "summary": "Link sign prediction on a signed graph is a task to determine whether the relationship represented by an edge is positive or negative. Since the presence of negative edges violates the graph homophily assumption that adjacent nodes are similar, regular graph methods have not been applicable without auxiliary structures to handle them. We aim to directly model the latent statistical dependency among edges with the Gaussian copula and its corresponding correlation matrix, extending CopulaGNN. However, a naive modeling of edge-edge relations is computationally intractable even for a graph with moderate scale. To address this, we propose to 1) represent the correlation matrix as a Gramian of edge embeddings, significantly reducing the number of parameters, and 2) reformulate the conditional probability distribution to dramatically reduce the inference cost. We theoretically verify scalability of our method by proving its linear convergence. Also, our extensive experiments demonstrate that it achieves significantly faster convergence than baselines, maintaining competitive prediction performance to the state-of-the-art models.", "AI": {"tldr": "该论文提出了一种在CopulaGNN中建模边缘间相关性的方法，用于链接符号预测任务。", "motivation": "链接符号预测需要处理正负边的复杂关系。传统的图同质性假设不适用于含有负边的情况，因此需开发新的模型来直接建模这些边缘间的潜在统计依赖。", "method": "通过使用高斯copula和对应的协方差矩阵，以及将协方差矩阵表示为边缘嵌入Gramian的形式以减少参数数量，并重构条件概率分布来降低推断成本。", "result": "理论分析证明了方法的线性收敛性质；实验显示该模型比基线更快地收敛并保持与最先进模型相当的预测性能。", "conclusion": "所提出的方法成功解决了大规模图中边缘间相关性的建模问题，实现了高效的链接符号预测。"}}
{"id": "2601.19174", "pdf": "https://arxiv.org/pdf/2601.19174", "abs": "https://arxiv.org/abs/2601.19174", "authors": ["Nirhoshan Sivaroopan", "Kanchana Thilakarathna", "Albert Zomaya", "Manu", "Yi Guo", "Jo Plested", "Tim Lynar", "Jack Yang", "Wangli Yang"], "title": "SHIELD: An Auto-Healing Agentic Defense Framework for LLM Resource Exhaustion Attacks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Sponge attacks increasingly threaten LLM systems by inducing excessive computation and DoS. Existing defenses either rely on statistical filters that fail on semantically meaningful attacks or use static LLM-based detectors that struggle to adapt as attack strategies evolve. We introduce SHIELD, a multi-agent, auto-healing defense framework centered on a three-stage Defense Agent that integrates semantic similarity retrieval, pattern matching, and LLM-based reasoning. Two auxiliary agents, a Knowledge Updating Agent and a Prompt Optimization Agent, form a closed self-healing loop, when an attack bypasses detection, the system updates an evolving knowledgebase, and refines defense instructions. Extensive experiments show that SHIELD consistently outperforms perplexity-based and standalone LLM defenses, achieving high F1 scores across both non-semantic and semantic sponge attacks, demonstrating the effectiveness of agentic self-healing against evolving resource-exhaustion threats.", "AI": {"tldr": "SHIELD是一个自动恢复防御框架，用于对抗大型语言模型资源耗尽攻击。", "motivation": "海绵攻击通过诱导过多计算和拒绝服务对LLM系统构成威胁。现有防御措施要么依赖于在语义有意义的攻击下失败的统计过滤器，要么是难以适应不断变化的攻击策略的静态LLM基检测器。", "method": "SHIELD采用多代理框架，包含三个阶段的防御代理、知识更新代理和提示优化代理，通过集成语义相似性检索、模式匹配及基于LLM的推理来应对攻击。当攻击绕过检测时，系统会更新知识库并完善防御指令以形成闭环自愈。", "result": "实验结果表明SHIELD在对抗非语义和语义海绵攻击方面优于困惑度基线和单一LLM防御措施，实现了高F1得分。", "conclusion": "该框架展示了代理自我恢复机制对不断变化的资源耗尽威胁的有效性。"}}
{"id": "2601.19171", "pdf": "https://arxiv.org/pdf/2601.19171", "abs": "https://arxiv.org/abs/2601.19171", "authors": ["Seokhyeon Park", "Soohyun Lee", "Eugene Choi", "Hyunwoo Kim", "Minkyu Kweon", "Yumin Song", "Jinwook Seo"], "title": "Bridging Gulfs in UI Generation through Semantic Guidance", "categories": ["cs.HC", "cs.AI"], "comment": "In Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI '26)", "summary": "While generative AI enables high-fidelity UI generation from text prompts, users struggle to articulate design intent and evaluate or refine results-creating gulfs of execution and evaluation. To understand the information needed for UI generation, we conducted a thematic analysis of UI prompting guidelines, identifying key design semantics and discovering that they are hierarchical and interdependent. Leveraging these findings, we developed a system that enables users to specify semantics, visualize relationships, and extract how semantics are reflected in generated UIs. By making semantics serve as an intermediate representation between human intent and AI output, our system bridges both gulfs by making requirements explicit and outcomes interpretable. A comparative user study suggests that our approach enhances users' perceived control over intent expression, outcome interpretation, and facilitates more predictable, iterative refinement. Our work demonstrates how explicit semantic representation enables systematic and explainable exploration of design possibilities in AI-driven UI design.", "AI": {"tldr": "通过语义指导来解决UI生成中的意图表达和结果解释的问题，提高用户控制能力和设计迭代的可预测性。", "motivation": "为了解决在UI生成过程中用户难以明确表述设计意图以及评估或改进生成结果的问题，提出了一种基于语义的方法以缩小执行差距与评价差距。", "method": "通过主题分析UI提示指南识别关键设计语义，并开发了一个系统来帮助用户指定和可视化这些语义的关系，在AI输出中反映用户的意图。", "result": "用户体验研究结果显示，该方法能增强用户对意图表达的控制感以及对结果的理解，并促进更可预测的设计迭代过程。", "conclusion": "明确的语义表示使得在基于AI的UI设计过程中可以实现系统化和可解释性探索。"}}
{"id": "2601.19170", "pdf": "https://arxiv.org/pdf/2601.19170", "abs": "https://arxiv.org/abs/2601.19170", "authors": ["Wangyang Ying", "Yanchi Liu", "Xujiang Zhao", "Wei Cheng", "Zhengzhang Chen", "Wenchao Yu", "Yanjie Fu", "Haifeng Chen"], "title": "Multi-Agent Procedural Graph Extraction with Structural and Logical Refinement", "categories": ["cs.AI"], "comment": null, "summary": "Automatically extracting workflows as procedural graphs from natural language is promising yet underexplored, demanding both structural validity and logical alignment. While recent large language models (LLMs) show potential for procedural graph extraction, they often produce ill-formed structures or misinterpret logical flows. We present \\model{}, a multi-agent framework that formulates procedural graph extraction as a multi-round reasoning process with dedicated structural and logical refinement. The framework iterates through three stages: (1) a graph extraction phase with the graph builder agent, (2) a structural feedback phase in which a simulation agent diagnoses and explains structural defects, and (3) a logical feedback phase in which a semantic agent aligns semantics between flow logic and linguistic cues in the source text. Important feedback is prioritized and expressed in natural language, which is injected into subsequent prompts, enabling interpretable and controllable refinement. This modular design allows agents to target distinct error types without supervision or parameter updates. Experiments demonstrate that \\model{} achieves substantial improvements in both structural correctness and logical consistency over strong baselines.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.19168", "pdf": "https://arxiv.org/pdf/2601.19168", "abs": "https://arxiv.org/abs/2601.19168", "authors": ["Brianna L. Wimer", "Ritesh Kanchi", "Kaija Frierson", "Venkatesh Potluri", "Ronald Metoyer", "Jennifer Mankoff", "Miya Natsuhara", "Matt X. Wang"], "title": "Nonvisual Support for Understanding and Reasoning about Data Structures", "categories": ["cs.HC"], "comment": "21 pages. To be published in the Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems", "summary": "Blind and visually impaired (BVI) computer science students face systematic barriers when learning data structures: current accessibility approaches typically translate diagrams into alternative text, focusing on visual appearance rather than preserving the underlying structure essential for conceptual understanding. More accessible alternatives often do not scale in complexity, cost to produce, or both. Motivated by a recent shift to tools for creating visual diagrams from code, we propose a solution that automatically creates accessible representations from structural information about diagrams. Based on a Wizard-of-Oz study, we derive design requirements for an automated system, Arboretum, that compiles text-based diagram specifications into three synchronized nonvisual formats$\\unicode{x2013}$tabular, navigable, and tactile. Our evaluation with BVI users highlights the strength of tactile graphics for complex tasks such as binary search; the benefits of offering multiple, complementary nonvisual representations; and limitations of existing digital navigation patterns for structural reasoning. This work reframes access to data structures by preserving their structural properties. The solution is a practical system to advance accessible CS education.", "AI": {"tldr": "论文提出了一个名为Arboretum的系统，该系统可以从代码生成数据结构的可访问表示形式。", "motivation": "当前的数据结构可视化方法通常将图表转换为替代文本，忽略了理解概念所需的底层结构。BVI学生在学习复杂任务时遇到困难，现有的解决方案无法提供足够的支持。", "method": "通过巫师模式实验得出设计需求，并开发一种名为Arboretum的系统，该系统可以将基于代码的图规范编译成三个同步的非视觉格式：表格、可导航和触觉。", "result": "评估表明，对于复杂的任务（如二分搜索），触觉图形最为有效；提供多种互补的非可视表示形式有助于理解结构属性。现有的数字导航模式在进行结构性推理时存在局限性。", "conclusion": "该研究重新定义了数据结构的可访问性，并提出了一种实用的方法来推进计算机科学教育中的包容性学习环境。"}}
{"id": "2601.19157", "pdf": "https://arxiv.org/pdf/2601.19157", "abs": "https://arxiv.org/abs/2601.19157", "authors": ["Yongsong Huang", "Tzu-Hsuan Peng", "Tomo Miyazaki", "Xiaofeng Liu", "Chun-Ting Chou", "Ai-Chun Pang", "Shinichiro Omachi"], "title": "GTFMN: Guided Texture and Feature Modulation Network for Low-Light Image Enhancement and Super-Resolution", "categories": ["cs.CV"], "comment": "\\c{opyright} 2026 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works", "summary": "Low-light image super-resolution (LLSR) is a challenging task due to the coupled degradation of low resolution and poor illumination. To address this, we propose the Guided Texture and Feature Modulation Network (GTFMN), a novel framework that decouples the LLSR task into two sub-problems: illumination estimation and texture restoration. First, our network employs a dedicated Illumination Stream whose purpose is to predict a spatially varying illumination map that accurately captures lighting distribution. Further, this map is utilized as an explicit guide within our novel Illumination Guided Modulation Block (IGM Block) to dynamically modulate features in the Texture Stream. This mechanism achieves spatially adaptive restoration, enabling the network to intensify enhancement in poorly lit regions while preserving details in well-exposed areas. Extensive experiments demonstrate that GTFMN achieves the best performance among competing methods on the OmniNormal5 and OmniNormal15 datasets, outperforming them in both quantitative metrics and visual quality.", "AI": {"tldr": "该论文提出了GTFMN网络，旨在解决低光照图像超分辨率问题。", "motivation": "低光环境下图像的超分辨率处理面临挑战，因为需要同时应对低分辨率和照明不足的问题。为此，提出了一种新的框架来分解任务并分别进行光照估计和纹理恢复。", "method": "GTFMN网络包括一个用于预测空间变化照明图的地图流以及利用该地图作为引导在纹理流中动态调节特征的机制。这实现了空间自适应修复，并增强了低光区域的同时保留了曝光良好的细节。", "result": "实验表明，GTFMN在OmniNormal5和OmniNormal15数据集上的表现优于竞争方法，在定量指标和视觉质量方面均表现出色。", "conclusion": "通过提出的框架和技术，GTFMN显著改善了低光照图像的超分辨率处理效果。"}}
{"id": "2601.19155", "pdf": "https://arxiv.org/pdf/2601.19155", "abs": "https://arxiv.org/abs/2601.19155", "authors": ["Qiujun Li", "Zijin Xiao", "Xulin Wang", "Zhidan Ma", "Cheng Yang", "Haifeng Li"], "title": "LocationAgent: A Hierarchical Agent for Image Geolocation via Decoupling Strategy and Evidence from Parametric Knowledge", "categories": ["cs.AI", "cs.CV"], "comment": "9 pages, 5 figures, 3 tables", "summary": "Image geolocation aims to infer capture locations based on visual content. Fundamentally, this constitutes a reasoning process composed of \\textit{hypothesis-verification cycles}, requiring models to possess both geospatial reasoning capabilities and the ability to verify evidence against geographic facts. Existing methods typically internalize location knowledge and reasoning patterns into static memory via supervised training or trajectory-based reinforcement fine-tuning. Consequently, these methods are prone to factual hallucinations and generalization bottlenecks in open-world settings or scenarios requiring dynamic knowledge. To address these challenges, we propose a Hierarchical Localization Agent, called LocationAgent. Our core philosophy is to retain hierarchical reasoning logic within the model while offloading the verification of geographic evidence to external tools. To implement hierarchical reasoning, we design the RER architecture (Reasoner-Executor-Recorder), which employs role separation and context compression to prevent the drifting problem in multi-step reasoning. For evidence verification, we construct a suite of clue exploration tools that provide diverse evidence to support location reasoning. Furthermore, to address data leakage and the scarcity of Chinese data in existing datasets, we introduce CCL-Bench (China City Location Bench), an image geolocation benchmark encompassing various scene granularities and difficulty levels. Extensive experiments demonstrate that LocationAgent significantly outperforms existing methods by at least 30\\% in zero-shot settings.", "AI": {"tldr": "本文提出了一种基于层级代理的图像定位方法LocationAgent，旨在提高开放环境下的地理推理能力和证据验证准确性。", "motivation": "现有的图像地理位置推断方法在处理动态知识和避免事实幻觉方面存在瓶颈。为此，作者提出了一个可以将地理信息推理与外部工具证据验证分离的方法。", "method": "通过设计RER架构(Reasoner-Executor-Recorder)，LocationAgent实现了层级推理逻辑，并构建了一套线索探索工具用于支持位置推理的证据验证过程。", "result": "实验结果表明，LocationAgent在零样本设置下显著优于现有方法至少30%。", "conclusion": "LocationAgent通过分离地理信息推理与证据验证任务，提高了模型对开放环境和动态知识处理的能力。"}}
{"id": "2601.19154", "pdf": "https://arxiv.org/pdf/2601.19154", "abs": "https://arxiv.org/abs/2601.19154", "authors": ["Shun Takagi", "Seng Pei Liew"], "title": "Analysis of Shuffling Beyond Pure Local Differential Privacy", "categories": ["cs.DS", "cs.CR", "cs.IT", "cs.LG"], "comment": null, "summary": "Shuffling is a powerful way to amplify privacy of a local randomizer in private distributed data analysis, but existing analyses mostly treat the local differential privacy (DP) parameter $\\varepsilon_0$ as the only knob and give generic upper bounds that can be loose and do not even characterize how shuffling amplifies privacy for basic mechanisms such as the Gaussian mechanism. We revisit the privacy blanket bound of Balle et al. (the blanket divergence) and develop an asymptotic analysis that applies to a broad class of local randomizers under mild regularity assumptions, without requiring pure local DP. Our key finding is that the leading term of the blanket divergence depends on the local mechanism only through a single scalar parameter $χ$, which we call the shuffle index. By applying this asymptotic analysis to both upper and lower bounds, we obtain a tight band for $δ_n$ in the shuffled mechanism's $(\\varepsilon_n,δ_n)$-DP guarantee. Moreover, we derive a simple structural necessary and sufficient condition on the local randomizer under which the blanket-divergence-based upper and lower bounds coincide asymptotically. $k$-RR families with $k\\ge3$ satisfy this condition, while for generalized Gaussian mechanisms the condition may not hold but the resulting band remains tight. Finally, we complement the asymptotic theory with an FFT-based algorithm for computing the blanket divergence at finite $n$, which offers rigorously controlled relative error and near-linear running time in $n$, providing a practical numerical analysis for shuffle DP.", "AI": {"tldr": "重新审视隐私被子界分析，发展出适用于广义局部随机器的渐近分析方法，并通过FFT算法提供数值分析。", "motivation": "现有分析主要关注纯局域差分隐私参数ε0，忽视了如何量化混合机制对基本机制如高斯机制增强隐私的效果。因此重新审视隐私被子界并发展更精确的分析方法。", "method": "利用渐近分析法研究广义局部随机器在非纯净局域差分隐私条件下的应用，并通过FFT算法实现数值计算以提供实用性的分析工具。", "result": "该研究明确了混合机制下δ_n的紧致界限，提出了一个判断局部随机化满足上下界一致性的必要且充分条件。此方法对k-RR家族(k≥3)和广义高斯机制均适用。", "conclusion": "通过渐近分析及FFT算法实现了对局域差分隐私增强效果的有效量化与数值计算，为混合DP的理论研究提供了有力工具。"}}
{"id": "2601.19151", "pdf": "https://arxiv.org/pdf/2601.19151", "abs": "https://arxiv.org/abs/2601.19151", "authors": ["Patara Trirat", "Jin Myung Kwak", "Jay Heo", "Heejun Lee", "Sung Ju Hwang"], "title": "TS-Debate: Multimodal Collaborative Debate for Zero-Shot Time Series Reasoning", "categories": ["cs.AI", "cs.MA"], "comment": "Code will be available at https://github.com/DeepAuto-AI/TS-Debate", "summary": "Recent progress at the intersection of large language models (LLMs) and time series (TS) analysis has revealed both promise and fragility. While LLMs can reason over temporal structure given carefully engineered context, they often struggle with numeric fidelity, modality interference, and principled cross-modal integration. We present TS-Debate, a modality-specialized, collaborative multi-agent debate framework for zero-shot time series reasoning. TS-Debate assigns dedicated expert agents to textual context, visual patterns, and numerical signals, preceded by explicit domain knowledge elicitation, and coordinates their interaction via a structured debate protocol. Reviewer agents evaluate agent claims using a verification-conflict-calibration mechanism, supported by lightweight code execution and numerical lookup for programmatic verification. This architecture preserves modality fidelity, exposes conflicting evidence, and mitigates numeric hallucinations without task-specific fine-tuning. Across 20 tasks spanning three public benchmarks, TS-Debate achieves consistent and significant performance improvements over strong baselines, including standard multimodal debate in which all agents observe all inputs.", "AI": {"tldr": "TS-Debate是一种用于零样本时间序列推理的多模态协作辩论框架。", "motivation": "当前大语言模型在处理时间序列分析时，尽管能理解时间结构但在数值精度、模态干扰和跨模态整合方面存在挑战。TS-Debate旨在解决这些难题。", "method": "TS-Debate通过专门的专家代理分别处理文本上下文、视觉模式和数字信号，并采用明确的知识获取过程协调其交互，利用验证冲突校准机制评估代理人声明。", "result": "在覆盖20个任务的三个公共基准数据集上，TS-Debate相对于强大的基线模型取得了持续且显著的表现提升。", "conclusion": "TS-Debate通过模态专业化、协作多代理辩论和结构化辩论协议来提高零样本时间序列推理的性能。"}}
{"id": "2601.19144", "pdf": "https://arxiv.org/pdf/2601.19144", "abs": "https://arxiv.org/abs/2601.19144", "authors": ["Tzvika Geft", "William Zhang", "Jingjin Yu", "Kostas Bekris"], "title": "Robust Out-of-Order Retrieval for Grid-Based Storage at Maximum Capacity", "categories": ["cs.RO", "cs.DS"], "comment": "AAAI 2026", "summary": "This paper proposes a framework for improving the operational efficiency of automated storage systems under uncertainty. It considers a 2D grid-based storage for uniform-sized loads (e.g., containers, pallets, or totes), which are moved by a robot (or other manipulator) along a collision-free path in the grid. The loads are labeled (i.e., unique) and must be stored in a given sequence, and later be retrieved in a different sequence -- an operational pattern that arises in logistics applications, such as last-mile distribution centers and shipyards. The objective is to minimize the load relocations to ensure efficient retrieval. A previous result guarantees a zero-relocation solution for known storage and retrieval sequences, even for storage at full capacity, provided that the side of the grid through which loads are stored/retrieved is at least 3 cells wide. However, in practice, the retrieval sequence can change after the storage phase. To address such uncertainty, this work investigates \\emph{$k$-bounded perturbations} during retrieval, under which any two loads may depart out of order if they are originally at most $k$ positions apart. We prove that a $Θ(k)$ grid width is necessary and sufficient for eliminating relocations at maximum capacity. We also provide an efficient solver for computing a storage arrangement that is robust to such perturbations. To address the higher-uncertainty case where perturbations exceed $k$, a strategy is introduced to effectively minimize relocations. Extensive experiments show that, for $k$ up to half the grid width, the proposed storage-retrieval framework essentially eliminates relocations. For $k$ values up to the full grid width, relocations are reduced by $50\\%+$.", "AI": {"tldr": "提出了一个框架以提高满容量条件下二维网格存储系统在不确定情况下的操作效率。", "motivation": "研究了物流应用中的不确定性问题，特别是在存取序列可能改变的情况下如何有效减少重定位次数。", "method": "通过引入k有界扰动的概念，在最大容量下探讨如何消除重定位。提供了一种高效的求解器来计算出一个对这类干扰具有鲁棒性的存储安排。", "result": "实验显示，对于$k$不超过网格宽度一半的情况，提出的存取框架基本上消除了重定位；对于$k$值达到整个网格宽度的情况，重定位减少了50%以上。", "conclusion": "证明了确保在最大容量下消除重定位所需的网格宽度为Θ(k)，并提供了一种策略来有效减少高不确定性情况下的重定位次数。"}}
{"id": "2601.19143", "pdf": "https://arxiv.org/pdf/2601.19143", "abs": "https://arxiv.org/abs/2601.19143", "authors": ["Florian 'Floyd' Mueller", "Nadia Bianchi-Berthouze", "Misha Sra", "Mar Gonzalez-Franco", "Henning Pohl", "Susanne Boll", "Richard Byrne", "Arthur Caetano", "Masahiko Inami", "Jarrod Knibbe", "Per Ola Kristensson", "Xiang Li", "Zhuying Li", "Joe Marshall", "Louise Petersen Matjeka", "Minna Nygren", "Rakesh Patibanda", "Sara Price", "Harald Reiterer", "Aryan Saini", "Oliver Schneider", "Ambika Shahu", "Jürgen Steimle", "Phoebe O. Toups Dugas", "Don Samitha Elvitigala"], "title": "Grand Challenges around Designing Computers' Control Over Our Bodies", "categories": ["cs.HC"], "comment": "21 pages, 6 figures, accepted by ACM CHI 2026", "summary": "Advances in emerging technologies, such as on-body mechanical actuators and electrical muscle stimulation, have allowed computers to take control over our bodies. This presents opportunities as well as challenges, raising fundamental questions about agency and the role of our bodies when interacting with technology. To advance this research field as a whole, we brought together expert perspectives in a week-long seminar to articulate the grand challenges that should be tackled when it comes to the design of computers' control over our bodies. These grand challenges span technical, design, user, and ethical aspects. By articulating these grand challenges, we aim to begin initiating a research agenda that positions bodily control not only as a technical feature but as a central, experiential, and ethical concern for future human-computer interaction endeavors.", "AI": {"tldr": "本文讨论了计算机对人体控制的潜在挑战，并提出了未来研究议程。", "motivation": "随着新兴技术的发展，计算机开始能够直接对人的身体进行控制，这带来了机遇和挑战。为此，文章旨在通过专家会议的形式识别并提出相关的重大问题。", "method": "召集各领域专家在一周内讨论，以确定计算机对人体控制领域的关键挑战，并制定研究议程。", "result": "提出了涵盖技术、设计、用户体验及伦理四个方面的重大挑战，为未来的研究奠定了基础。", "conclusion": "通过定义这些重大问题并将其纳入未来的HCI（人机交互）研究中，可以确保计算机对人体的控制不仅是技术特征，也是体验和伦理的核心关注点。"}}
{"id": "2601.19142", "pdf": "https://arxiv.org/pdf/2601.19142", "abs": "https://arxiv.org/abs/2601.19142", "authors": ["Zhicheng Zhang", "Zhaocheng Du", "Jieming Zhu", "Jiwei Tang", "Fengyuan Lu", "Wang Jiaheng", "Song-Li Wu", "Qianhui Zhu", "Jingyu Li", "Hai-Tao Zheng", "Zhenhua Dong"], "title": "Length-Adaptive Interest Network for Balancing Long and Short Sequence Modeling in CTR Prediction", "categories": ["cs.AI"], "comment": "Accepted at AAAI 2026", "summary": "User behavior sequences in modern recommendation systems exhibit significant length heterogeneity, ranging from sparse short-term interactions to rich long-term histories. While longer sequences provide more context, we observe that increasing the maximum input sequence length in existing CTR models paradoxically degrades performance for short-sequence users due to attention polarization and length imbalance in training data. To address this, we propose LAIN(Length-Adaptive Interest Network), a plug-and-play framework that explicitly incorporates sequence length as a conditioning signal to balance long- and short-sequence modeling. LAIN consists of three lightweight components: a Spectral Length Encoder that maps length into continuous representations, Length-Conditioned Prompting that injects global contextual cues into both long- and short-term behavior branches, and Length-Modulated Attention that adaptively adjusts attention sharpness based on sequence length. Extensive experiments on three real-world benchmarks across five strong CTR backbones show that LAIN consistently improves overall performance, achieving up to 1.15% AUC gain and 2.25% log loss reduction. Notably, our method significantly improves accuracy for short-sequence users without sacrificing longsequence effectiveness. Our work offers a general, efficient, and deployable solution to mitigate length-induced bias in sequential recommendation.", "AI": {"tldr": "提出了一种平衡长序列和短序列建模的插件式框架LAIN，用于点击率预测。", "motivation": "现代推荐系统中用户行为序列长度不一，增加序列输入长度会导致现有CTR模型对短序列用户的性能下降。为解决这一问题提出了LAIN框架。", "method": "LAIN包括三个轻量级组件：光谱长度编码器、长度条件提示和长度调节注意力机制。这些组件通过引入序列长度作为条件信号来平衡长短期行为建模。", "result": "在五个强大的CTR骨干网络上进行了广泛的实验，显示了LAIN可以提高整体性能，获得高达1.15%的AUC增益和2.25%的日志损失减少。特别地，该方法显著提高了短序列用户的准确性而不牺牲长序列效果。", "conclusion": "提出的方法为缓解推荐中的长度偏见提供了一种通用、有效且可部署的解决方案"}}
{"id": "2601.19139", "pdf": "https://arxiv.org/pdf/2601.19139", "abs": "https://arxiv.org/abs/2601.19139", "authors": ["Wayner Barrios"], "title": "Native LLM and MLLM Inference at Scale on Apple Silicon", "categories": ["cs.LG", "cs.DC", "cs.ET"], "comment": null, "summary": "The growing adoption of Apple Silicon for machine learning development has created demand for efficient inference solutions that leverage its unique unified memory architecture. However, existing tools either lack native optimization (PyTorch MPS) or focus solely on text models (llama.cpp), leaving multimodal workloads underserved. We present vllm-mlx, a framework for efficient LLM and MLLM inference on Apple Silicon built natively on MLX. For text models, we achieve 21% to 87% higher throughput than llama.cpp across models ranging from Qwen3-0.6B to Nemotron-30B, while providing continuous batching that scales to 4.3x aggregate throughput at 16 concurrent requests. For multimodal models, we introduce content-based prefix caching that eliminates redundant vision encoding by identifying identical images through content hashing, regardless of input format. Our evaluation on Apple M4 Max demonstrates throughput of up to 525 tokens per second on text models and 28x speedup on repeated image queries, reducing multimodal latency from 21.7 seconds to under 1 second. Video analysis with up to 64 frames achieves 24.7x cache speedup. We release our implementation as open source to support efficient inference on consumer Apple hardware.", "AI": {"tldr": "提出了一种在苹果芯片上进行大模型和多模态模型推理的框架vllm-mlx，该框架针对文本模型实现了更高的吞吐量，并引入了基于内容的前缀缓存以减少冗余视觉编码。", "motivation": "随着苹果芯片在机器学习开发中的普及，需要一种能够充分利用其统一内存架构的有效推理解决方案。然而，现有的工具要么缺乏原生优化（如PyTorch MPS），要么仅专注于文本模型（如llama.cpp）。因此，多模态工作负载的需求未得到满足。", "method": "介绍了vllm-mlx框架，该框架在苹果芯片的MLX上原生构建。对于文本模型，通过连续批处理实现了21%到87%的更高吞吐量，并且可以扩展到4.3倍聚合吞吐量，在并发请求为16时表现优异。针对多模态模型，引入了基于内容前缀缓存技术来减少冗余视觉编码。", "result": "文本模型在苹果M4 Max上的评估显示，最高可达到525 tokens/s的吞吐量；对于重复图像查询，多模态推理的速度提高了28倍，延迟从21.7秒缩短到不到1秒。视频分析最多支持64帧输入，并实现24.7倍缓存加速。", "conclusion": "vllm-mlx框架在苹果芯片上实现了高效的大模型和多模态模型的推理，大幅提高了文本模型的吞吐量，并通过基于内容前缀缓存技术显著减少了重复图像查询的延迟。该成果将开放源码以支持消费者级硬件上的高效推理。"}}
{"id": "2601.19138", "pdf": "https://arxiv.org/pdf/2601.19138", "abs": "https://arxiv.org/abs/2601.19138", "authors": ["Wachiraphan Charoenwet", "Kla Tantithamthavorn", "Patanamon Thongtanunam", "Hong Yi Lin", "Minwoo Jeong", "Ming Wu"], "title": "AgenticSCR: An Autonomous Agentic Secure Code Review for Immature Vulnerabilities Detection", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SE"], "comment": "Under Review", "summary": "Secure code review is critical at the pre-commit stage, where vulnerabilities must be caught early under tight latency and limited-context constraints. Existing SAST-based checks are noisy and often miss immature, context-dependent vulnerabilities, while standalone Large Language Models (LLMs) are constrained by context windows and lack explicit tool use. Agentic AI, which combine LLMs with autonomous decision-making, tool invocation, and code navigation, offer a promising alternative, but their effectiveness for pre-commit secure code review is not yet well understood. In this work, we introduce AgenticSCR, an agentic AI for secure code review for detecting immature vulnerabilities during the pre-commit stage, augmented by security-focused semantic memories. Using our own curated benchmark of immature vulnerabilities, tailored to the pre-commit secure code review, we empirically evaluate how accurate is our AgenticSCR for localizing, detecting, and explaining immature vulnerabilities. Our results show that AgenticSCR achieves at least 153% relatively higher percentage of correct code review comments than the static LLM-based baseline, and also substantially surpasses SAST tools. Moreover, AgenticSCR generates more correct comments in four out of five vulnerability types, consistently and significantly outperforming all other baselines. These findings highlight the importance of Agentic Secure Code Review, paving the way towards an emerging research area of immature vulnerability detection.", "AI": {"tldr": "介绍了AgenticSCR，一种用于检测预提交阶段的初级漏洞的自主代理安全代码审查系统。", "motivation": "现有静态分析工具和独立的大语言模型在早期检测依赖上下文的脆弱性时效果不佳，因此开发了结合大语言模型与自主决策、工具有效利用及代码导航功能的AgenticAI来解决这个问题。", "method": "通过自行整理的初级漏洞基准测试评估了AgenticSCR在本地化、探测和解释这些漏洞方面的准确性，并将其与基于静态LLM的方法和SAST工具进行了比较。", "result": "实验结果显示，AgenticSCR相比静态LLM基线至少提高了153%的正确代码审查评论比例，并显著优于SAST工具，在五种漏洞类型中的四种中生成了更多的正确评论。", "conclusion": "结果表明，自主代理安全代码审查在检测初级漏洞方面具有重要意义，为这一新兴研究领域铺平了道路。"}}
{"id": "2601.19136", "pdf": "https://arxiv.org/pdf/2601.19136", "abs": "https://arxiv.org/abs/2601.19136", "authors": ["Iftekhar Ahmed", "Shakib Absar", "Aftar Ahmad Sami", "Shadman Sakib", "Debojyoti Biswas", "Seraj Al Mahmud Mostafa"], "title": "TFFM: Topology-Aware Feature Fusion Module via Latent Graph Reasoning for Retinal Vessel Segmentation", "categories": ["cs.CV"], "comment": "Accepted in WACV 2026 @ P2P-workshop as a full paper and selected for oral presentation", "summary": "Precise segmentation of retinal arteries and veins carries the diagnosis of systemic cardiovascular conditions. However, standard convolutional architectures often yield topologically disjointed segmentations, characterized by gaps and discontinuities that render reliable graph-based clinical analysis impossible despite high pixel-level accuracy. To address this, we introduce a topology-aware framework engineered to maintain vascular connectivity. Our architecture fuses a Topological Feature Fusion Module (TFFM) that maps local feature representations into a latent graph space, deploying Graph Attention Networks to capture global structural dependencies often missed by fixed receptive fields. Furthermore, we drive the learning process with a hybrid objective function, coupling Tversky loss for class imbalance with soft clDice loss to explicitly penalize topological disconnects. Evaluation on the Fundus-AVSeg dataset reveals state-of-the-art performance, achieving a combined Dice score of 90.97% and a 95% Hausdorff Distance of 3.50 pixels. Notably, our method decreases vessel fragmentation by approximately 38% relative to baselines, yielding topologically coherent vascular trees viable for automated biomarker quantification. We open-source our code at https://tffm-module.github.io/.", "AI": {"tldr": "该论文提出了一种基于拓扑感知特征融合模块的视网膜血管分割方法，以提高分割结果的整体连通性和准确性。", "motivation": "标准卷积网络在进行视网膜动脉和静脉精确分割时会产生局部不连续的结果，这限制了临床分析的有效性。为了解决这一问题，本文引入了一种新的拓扑感知框架。", "method": "该方法通过一个拓扑特征融合模块将局部特征映射到潜在图空间，并利用图注意力网络来捕捉全局结构依赖关系；同时采用混合损失函数进行训练以提高性能。", "result": "实验结果表明，所提方法在Fundus-AVSeg数据集上达到了90.97%的Dice分数和3.50像素的Hausdorff距离，并显著减少了血管碎片化现象（约减少38%）。", "conclusion": "该论文提出了一种改进视网膜血管分割的新方法，可以生成拓扑一致且准确率更高的血管树，为自动生物标志物量化提供了有力支持。"}}
{"id": "2601.19133", "pdf": "https://arxiv.org/pdf/2601.19133", "abs": "https://arxiv.org/abs/2601.19133", "authors": ["Yuxiang Wang", "Kunming Jiang", "Tianxiang Zhang", "Ke Tian", "Gaozhe Jiang"], "title": "QA-ReID: Quality-Aware Query-Adaptive Convolution Leveraging Fused Global and Structural Cues for Clothes-Changing ReID", "categories": ["cs.CV"], "comment": null, "summary": "Unlike conventional person re-identification (ReID), clothes-changing ReID (CC-ReID) presents severe challenges due to substantial appearance variations introduced by clothing changes. In this work, we propose the Quality-Aware Dual-Branch Matching (QA-ReID), which jointly leverages RGB-based features and parsing-based representations to model both global appearance and clothing-invariant structural cues. These heterogeneous features are adaptively fused through a multi-modal attention module. At the matching stage, we further design the Quality-Aware Query Adaptive Convolution (QAConv-QA), which incorporates pixel-level importance weighting and bidirectional consistency constraints to enhance robustness against clothing variations. Extensive experiments demonstrate that QA-ReID achieves state-of-the-art performance on multiple benchmarks, including PRCC, LTCC, and VC-Clothes, and significantly outperforms existing approaches under cross-clothing scenarios.", "AI": {"tldr": "提出一种质量感知的查询自适应卷积方法（QA-ReID），利用RGB和解析表示来处理衣服变化的人重识别问题。", "motivation": "解决因衣服更换导致的人体外观显著变化带来的行人重识别挑战。", "method": "通过多模态注意力模块融合RGB和解析特征，设计质量感知查询自适应卷积以增强鲁棒性。", "result": "在多个基准数据集上表现优异，并且显著优于现有方法。", "conclusion": "QA-ReID在跨衣服场景下具有卓越的性能。"}}
{"id": "2601.19132", "pdf": "https://arxiv.org/pdf/2601.19132", "abs": "https://arxiv.org/abs/2601.19132", "authors": ["Torsten Hoefler", "Mikhail Khalilov", "Josiah Clark", "Surendra Anubolu", "Mohan Kalkunte", "Karen Schramm", "Eric Spada", "Duncan Roweth", "Keith Underwood", "Adrian Caulfield", "Abdul Kabbani", "Amirreza Rastegari"], "title": "In-Network Collective Operations: Game Changer or Challenge for AI Workloads?", "categories": ["cs.NI", "cs.AI", "cs.AR", "cs.PF", "eess.SY"], "comment": "ef:IEEE Computer Jan. 2026", "summary": "This paper summarizes the opportunities of in-network collective operations (INC) for accelerated collective operations in AI workloads. We provide sufficient detail to make this important field accessible to non-experts in AI or networking, fostering a connection between these communities. Consider two types of INC: Edge-INC, where the system is implemented at the node level, and Core-INC, where the system is embedded within network switches. We outline the potential performance benefits as well as six key obstacles in the context of both Edge-INC and Core-INC that may hinder their adoption. Finally, we present a set of predictions for the future development and application of INC.", "AI": {"tldr": "总结了在AI工作负载中使用内网集体操作（INC）的机会和挑战，介绍了边缘和核心两种类型以及它们的潜在性能优势与障碍。", "motivation": "使非专家能够理解AI与网络领域的连接，并促进这两个社区之间的交流，同时概述INC在AI中的机会和挑战。", "method": "通过分析边缘-INC和核心-INC的特点及实现方式来探讨其潜力和障碍。", "result": "指出了两种类型INC的性能优势以及可能阻碍它们被采用的六个关键障碍。", "conclusion": "预测了未来INC的发展与应用趋势，强调了在AI工作负载中的重要性和挑战性。"}}
{"id": "2601.19129", "pdf": "https://arxiv.org/pdf/2601.19129", "abs": "https://arxiv.org/abs/2601.19129", "authors": ["Puzhen Wu", "Han Weng", "Quan Zheng", "Yi Zhan", "Hewei Wang", "Yiming Li", "Jiahui Han", "Rui Xu"], "title": "CLIP-Guided Unsupervised Semantic-Aware Exposure Correction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Improper exposure often leads to severe loss of details, color distortion, and reduced contrast. Exposure correction still faces two critical challenges: (1) the ignorance of object-wise regional semantic information causes the color shift artifacts; (2) real-world exposure images generally have no ground-truth labels, and its labeling entails massive manual editing. To tackle the challenges, we propose a new unsupervised semantic-aware exposure correction network. It contains an adaptive semantic-aware fusion module, which effectively fuses the semantic information extracted from a pre-trained Fast Segment Anything Model into a shared image feature space. Then the fused features are used by our multi-scale residual spatial mamba group to restore the details and adjust the exposure. To avoid manual editing, we propose a pseudo-ground truth generator guided by CLIP, which is fine-tuned to automatically identify exposure situations and instruct the tailored corrections. Also, we leverage the rich priors from the FastSAM and CLIP to develop a semantic-prompt consistency loss to enforce semantic consistency and image-prompt alignment for unsupervised training. Comprehensive experimental results illustrate the effectiveness of our method in correcting real-world exposure images and outperforms state-of-the-art unsupervised methods both numerically and visually.", "AI": {"tldr": "提出了一种新的无监督语义感知曝光校正网络，用于改善图像的曝光问题。", "motivation": "解决忽略对象级别的区域语义信息导致的颜色偏移伪影和缺乏真实世界曝光图片的真实标签的问题。", "method": "使用自适应语义感知融合模块将Fast Segment Anything Model提取到的语义信息融入共享图像特征空间中，并利用多尺度残差空间马尔巴组进行细节恢复和曝光调整。通过CLIP引导的伪真值生成器来自动识别曝光情况并指导特定制修正，同时开发了基于FastSAM和CLIP的语义提示一致性损失。", "result": "实验结果表明该方法在纠正真实世界的曝光图像方面表现出色，优于现有的无监督方法。", "conclusion": "提出的方法能够在不依赖于大量手动编辑标签的情况下有效校正图像曝光问题，并且其效果得到了验证。"}}
{"id": "2601.19128", "pdf": "https://arxiv.org/pdf/2601.19128", "abs": "https://arxiv.org/abs/2601.19128", "authors": ["Chao Yin", "Qing Han", "Zhiwei Hou", "Yue Liu", "Anjin Dai", "Hongda Hu", "Ji Yang", "Wei Yao"], "title": "Resolving Primitive-Sharing Ambiguity in Long-Tailed Industrial Point Cloud Segmentation via Spatial Context Constraints", "categories": ["cs.CV"], "comment": null, "summary": "Industrial point cloud segmentation for Digital Twin construction faces a persistent challenge: safety-critical components such as reducers and valves are systematically misclassified. These failures stem from two compounding factors: such components are rare in training data, yet they share identical local geometry with dominant structures like pipes. This work identifies a dual crisis unique to industrial 3D data extreme class imbalance 215:1 ratio compounded by geometric ambiguity where most tail classes share cylindrical primitives with head classes. Existing frequency-based re-weighting methods address statistical imbalance but cannot resolve geometric ambiguity. We propose spatial context constraints that leverage neighborhood prediction consistency to disambiguate locally similar structures. Our approach extends the Class-Balanced (CB) Loss framework with two architecture-agnostic mechanisms: (1) Boundary-CB, an entropy-based constraint that emphasizes ambiguous boundaries, and (2) Density-CB, a density-based constraint that compensates for scan-dependent variations. Both integrate as plug-and-play modules without network modifications, requiring only loss function replacement. On the Industrial3D dataset (610M points from water treatment facilities), our method achieves 55.74% mIoU with 21.7% relative improvement on tail-class performance (29.59% vs. 24.32% baseline) while preserving head-class accuracy (88.14%). Components with primitive-sharing ambiguity show dramatic gains: reducer improves from 0% to 21.12% IoU; valve improves by 24.3% relative. This resolves geometric ambiguity without the typical head-tail trade-off, enabling reliable identification of safety-critical components for automated knowledge extraction in Digital Twin applications.", "AI": {"tldr": "解决工业点云分割中的长尾类几何模糊性问题，通过空间上下文约束提高关键组件的分类准确性。", "motivation": "在数字孪生构建过程中，由于训练数据稀少和几何结构相似导致的关键安全部件（如减速器、阀门）系统性误分类问题亟待解决。现有基于频率重权的方法无法有效处理此类几何模糊性。", "method": "提出了空间上下文约束方法，通过边界一致性与密度补偿来区分局部相似的结构。具体实现为Class-Balanced损失框架下的两个机制：边界-CB（基于熵）和密度-CB（基于密度），并作为无需修改网络架构的插件模块应用。", "result": "在Industrial3D数据集上，方法实现了55.74%的mIoU，尾类性能相对提升了21.7%，其中关键部件分类准确度显著提高：减速器从0%提升到21.12% IoU；阀门相对提高了24.3%。", "conclusion": "该方法通过空间上下文约束成功解决了几何模糊性问题，并且避免了头部和尾部类别之间的性能权衡，为数字孪生应用中关键组件的自动知识提取提供了可靠支持。"}}
{"id": "2601.19127", "pdf": "https://arxiv.org/pdf/2601.19127", "abs": "https://arxiv.org/abs/2601.19127", "authors": ["Zhilong Zhang", "Lei Zhang", "Qing He", "Shuyin Xia", "Guoyin Wang", "Fuxiang Huang"], "title": "Implicit Non-Causal Factors are Out via Dataset Splitting for Domain Generalization Object Detection", "categories": ["cs.CV"], "comment": "To appear in IJCV", "summary": "Open world object detection faces a significant challenge in domain-invariant representation, i.e., implicit non-causal factors. Most domain generalization (DG) methods based on domain adversarial learning (DAL) pay much attention to learn domain-invariant information, but often overlook the potential non-causal factors. We unveil two critical causes: 1) The domain discriminator-based DAL method is subject to the extremely sparse domain label, i.e., assigning only one domain label to each dataset, thus can only associate explicit non-causal factor, which is incredibly limited. 2) The non-causal factors, induced by unidentified data bias, are excessively implicit and cannot be solely discerned by conventional DAL paradigm. Based on these key findings, inspired by the Granular-Ball perspective, we propose an improved DAL method, i.e., GB-DAL. The proposed GB-DAL utilizes Prototype-based Granular Ball Splitting (PGBS) module to generate more dense domains from limited datasets, akin to more fine-grained granular balls, indicating more potential non-causal factors. Inspired by adversarial perturbations akin to non-causal factors, we propose a Simulated Non-causal Factors (SNF) module as a means of data augmentation to reduce the implicitness of non-causal factors, and facilitate the training of GB-DAL. Comparative experiments on numerous benchmarks demonstrate that our method achieves better generalization performance in novel circumstances.", "AI": {"tldr": "提出了一种改进的域对抗学习方法GB-DAL，通过生成更密集的领域标签和模拟非因果因素来提高检测模型在新环境下的泛化性能。", "motivation": "现有的基于域对抗学习的方法主要关注于学习跨领域的不变表示，但忽视了潜在的非因果因素的影响。为解决此问题，引入了GB-DAL方法以应对数据集中的隐式非因果因素。", "method": "采用原型基粒球分割（PGBS）模块生成更多密集的领域标签，并使用模拟非因果因子（SNF）模块作为增强手段来减少隐性非因果因素的影响。", "result": "实验表明，该方法在多种基准测试上实现了更好的泛化性能。", "conclusion": "通过引入GB-DAL框架，有效提高了检测模型对未知领域的适应能力。"}}
{"id": "2601.19122", "pdf": "https://arxiv.org/pdf/2601.19122", "abs": "https://arxiv.org/abs/2601.19122", "authors": ["Weiran Guo", "Bing Bo", "Shaoxiang Wu", "Jingsheng Yang"], "title": "Exploring Weaknesses in Function Call Models via Reinforcement Learning: An Adversarial Data Augmentation Approach", "categories": ["cs.AI"], "comment": null, "summary": "Function call capabilities have become crucial for Large Language Models (LLMs), enabling them to interact more effectively with external tools and APIs. Existing methods for improving the function call capabilities of LLMs rely on data obtained either through manual annotation or automated generation by models, and use this data to finetune the LLMs. However, these methods often lack targeted design and are constrained by fixed patterns and data distributions, which limits their effectiveness in enhancing the generalization and robustness of function call LLMs. To address this limitation, we propose a novel adversarial data augmentation method that employs reinforcement learning to systematically identify and target the weaknesses of function call LLMs. Our training framework introduces a query model trained with reinforcement learning (RL) to generate adversarial queries that are specifically designed to challenge function call (FC) models. This approach adopts a zero sum game formulation, where the query model and the FC model engage in iterative alternating training. Overall, our method advances the development of more robust FC models and provides a systematic way to identify and correct weaknesses in the ability of LLMs to interact with external tools.", "AI": {"tldr": "通过强化学习提出一种对抗性数据增强方法，用于识别和改进大型语言模型（LLM）在函数调用能力上的弱点。", "motivation": "现有提高LLM函数调用能力的方法受限于固定模式和数据分布，无法有效提升其泛化性和鲁棒性。因此需要新的策略来系统地发现并克服这些限制。", "method": "采用强化学习训练查询模型生成专门针对函数调用（FC）模型的对抗性查询，并通过零和博弈框架实现查询模型与FC模型之间的交替训练。", "result": "所提方法能够有效地识别LLM在处理外部工具交互时存在的弱点，有助于改进其泛化性和鲁棒性。", "conclusion": "本文提出的方法为提高大型语言模型函数调用能力的稳健性提供了一种系统性的解决方案。"}}
{"id": "2601.19121", "pdf": "https://arxiv.org/pdf/2601.19121", "abs": "https://arxiv.org/abs/2601.19121", "authors": ["Guilin Zhang", "Kai Zhao", "Jeffrey Friedman", "Xu Chu"], "title": "LLMs as Orchestrators: Constraint-Compliant Multi-Agent Optimization for Recommendation Systems", "categories": ["cs.IR", "cs.AI", "cs.LG", "cs.MA"], "comment": "8 pages, 5 figures", "summary": "Recommendation systems must optimize multiple objectives while satisfying hard business constraints such as fairness and coverage. For example, an e-commerce platform may require every recommendation list to include items from multiple sellers and at least one newly listed product; violating such constraints--even once--is unacceptable in production. Prior work on multi-objective recommendation and recent LLM-based recommender agents largely treat constraints as soft penalties or focus on item scoring and interaction, leading to frequent violations in real-world deployments. How to leverage LLMs for coordinating constrained optimization in recommendation systems remains underexplored. We propose DualAgent-Rec, an LLM-coordinated dual-agent framework for constrained multi-objective e-commerce recommendation. The framework separates optimization into an Exploitation Agent that prioritizes accuracy under hard constraints and an Exploration Agent that promotes diversity through unconstrained Pareto search. An LLM-based coordinator adaptively allocates resources between agents based on optimization progress and constraint satisfaction, while an adaptive epsilon-relaxation mechanism guarantees feasibility of final solutions. Experiments on the Amazon Reviews 2023 dataset demonstrate that DualAgent-Rec achieves 100% constraint satisfaction and improves Pareto hypervolume by 4-6% over strong baselines, while maintaining competitive accuracy-diversity trade-offs. These results indicate that LLMs can act as effective orchestration agents for deployable and constraint-compliant recommendation systems.", "AI": {"tldr": "该论文提出了DualAgent-Rec框架，利用大语言模型协调推荐系统中的多目标优化，并确保满足硬约束条件。", "motivation": "现有的推荐系统在处理业务约束时存在不足，如公平性和覆盖率。这些约束需要严格遵守，但以往的研究往往将其视为软性惩罚或仅关注评分和交互，导致实际应用中频繁违反约束。", "method": "DualAgent-Rec框架通过两个代理来分离优化过程：一个专注于满足硬约束的准确性（Exploitation Agent），另一个则致力于促进多样性（Exploration Agent）。大语言模型协调器根据优化进度和约束满足度灵活分配资源，并采用自适应epsilon松弛机制确保最终解的可行性。", "result": "实验结果表明，DualAgent-Rec框架能够在Amazon Reviews 2023数据集上达到100%的约束满意度，并且比强基线提升了4-6％的Pareto超体积，同时保持了准确性和多样性的竞争性权衡。", "conclusion": "这些结果显示大语言模型可以作为有效的协调代理用于部署和满足约束条件的推荐系统。"}}
{"id": "2601.19120", "pdf": "https://arxiv.org/pdf/2601.19120", "abs": "https://arxiv.org/abs/2601.19120", "authors": ["Guilin Zhang", "Kai Zhao", "Jeffrey Friedman", "Xu Chu"], "title": "RobustExplain: Evaluating Robustness of LLM-Based Explanation Agents for Recommendation", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "8 pages, 4 figures", "summary": "Large Language Models (LLMs) are increasingly used to generate natural-language explanations in recommender systems, acting as explanation agents that reason over user behavior histories. While prior work has focused on explanation fluency and relevance under fixed inputs, the robustness of LLM-generated explanations to realistic user behavior noise remains largely unexplored. In real-world web platforms, interaction histories are inherently noisy due to accidental clicks, temporal inconsistencies, missing values, and evolving preferences, raising concerns about explanation stability and user trust. We present RobustExplain, the first systematic evaluation framework for measuring the robustness of LLM-generated recommendation explanations. RobustExplain introduces five realistic user behavior perturbations evaluated across multiple severity levels and a multi-dimensional robustness metric capturing semantic, keyword, structural, and length consistency. Our goal is to establish a principled, task-level evaluation framework and initial robustness baselines, rather than to provide a comprehensive leaderboard across all available LLMs. Experiments on four representative LLMs (7B--70B) show that current models exhibit only moderate robustness, with larger models achieving up to 8% higher stability. Our results establish the first robustness benchmarks for explanation agents and highlight robustness as a critical dimension for trustworthy, agent-driven recommender systems at web scale.", "AI": {"tldr": "评估大型语言模型生成推荐解释的鲁棒性", "motivation": "当前研究主要关注固定输入下LLM生成解释的流畅性和相关性，忽略了实际用户行为噪音对解释稳定性的挑战。该论文旨在填补这一空白，并建立一个系统化的评价框架来衡量LLM在面对现实世界中的噪声时的表现。", "method": "提出RobustExplain框架，引入五种现实的用户行为扰动并设置多个严重程度级别；采用多维度鲁棒性指标测量语义、关键词、结构和长度的一致性。", "result": "实验表明现有模型仅表现出中等水平的鲁棒性，更大规模的模型表现略优但提升有限；为解释代理建立了首个鲁棒性基准。", "conclusion": "确立了评估推荐系统LLM生成解释鲁棒性的标准方法，强调鲁棒性对于建立可信度高的大规模推荐系统至关重要。"}}
{"id": "2601.19119", "pdf": "https://arxiv.org/pdf/2601.19119", "abs": "https://arxiv.org/abs/2601.19119", "authors": ["Peter Travis Jardine", "Sidney Givigi"], "title": "Agree to Disagree: Consensus-Free Flocking under Constraints", "categories": ["cs.RO"], "comment": "7 pages. This work has been accepted for publication in the Proceedings of IEEE SYSCON 2026", "summary": "Robots sometimes have to work together with a mixture of partially-aligned or conflicting goals. Flocking - coordinated motion through cohesion, alignment, and separation - traditionally assumes uniform desired inter-agent distances. Many practical applications demand greater flexibility, as the diversity of types and configurations grows with the popularity of multi-agent systems in society. Moreover, agents often operate without guarantees of trust or secure communication. Motivated by these challenges we update well-established frameworks by relaxing this assumption of shared inter-agent distances and constraints. Through a new form of constrained collective potential function, we introduce a solution that permits negotiation of these parameters. In the spirit of the traditional flocking control canon, this negotiation is achieved purely through local observations and does not require any global information or inter-agent communication. The approach is robust to semi-trust scenarios, where neighbouring agents pursue conflicting goals. We validate the effectiveness of the approach through a series of simulations.", "AI": {"tldr": "本文提出了一种在没有共享目标距离和信任保证的情况下，通过局部观察实现协调运动的方法。", "motivation": "多智能体系统中存在不同类型和配置的挑战，传统的群集控制假设所有代理之间有统一的目标距离，这限制了灵活性。此外，在不安全通信或半可信场景下，需要更灵活的解决方案。", "method": "通过引入一个新的受约束集体势能函数来允许目标距离参数的协商，实现协调运动，并且该方法仅基于局部观察而不需要全局信息或代理间通信。", "result": "一系列模拟实验验证了这种方法的有效性。", "conclusion": "所提出的方法可以适应于不同类型的智能体和配置，在不安全或半可信场景下也能有效工作。"}}
{"id": "2601.19117", "pdf": "https://arxiv.org/pdf/2601.19117", "abs": "https://arxiv.org/abs/2601.19117", "authors": ["Ranjan Maitra"], "title": "Optimized $k$-means color quantization of digital images in machine-based and human perception-based colorspaces", "categories": ["eess.IV", "cs.CV", "stat.AP"], "comment": "25 pages, 11 figures, 5 tables, accepted in the Journal of Electronic Imaging", "summary": "Color quantization represents an image using a fraction of its original number of colors while only minimally losing its visual quality. The $k$-means algorithm is commonly used in this context, but has mostly been applied in the machine-based RGB colorspace composed of the three primary colors. However, some recent studies have indicated its improved performance in human perception-based colorspaces. We investigated the performance of $k$-means color quantization at four quantization levels in the RGB, CIE-XYZ, and CIE-LUV/CIE-HCL colorspaces, on 148 varied digital images spanning a wide range of scenes, subjects and settings. The Visual Information Fidelity (VIF) measure numerically assessed the quality of the quantized images, and showed that in about half of the cases, $k$-means color quantization is best in the RGB space, while at other times, and especially for higher quantization levels ($k$), the CIE-XYZ colorspace is where it usually does better. There are also some cases, especially at lower $k$, where the best performance is obtained in the CIE-LUV colorspace. Further analysis of the performances in terms of the distributions of the hue, chromaticity and luminance in an image presents a nuanced perspective and characterization of the images for which each colorspace is better for $k$-means color quantization.", "AI": {"tldr": "研究在不同色彩空间中应用$k$-means算法进行颜色量化的效果。", "motivation": "探讨$k$-means算法在机器感知和人类感知色彩空间中的性能，以优化数字图像的颜色量化。", "method": "采用RGB、CIE-XYZ和CIE-LUV/CIE-HCL色彩空间对148幅不同场景的数字图像进行四种量化级别的颜色量化，并使用VIF指标评估结果。", "result": "在一半的情况下，RGB空间性能最优；对于较高量化级别，CIE-XYZ空间表现更好；而对于较低量化级别，则是CIE-LUV空间更为合适。进一步分析色彩分布显示了不同色彩空间对$k$-means颜色量化的适用性。", "conclusion": "根据图像的色调、色度和亮度分布，在不同的色彩空间中应用$k$-means算法进行颜色量化可以得到更好的效果，为优化数字图像的颜色量化提供了依据。"}}
{"id": "2601.19115", "pdf": "https://arxiv.org/pdf/2601.19115", "abs": "https://arxiv.org/abs/2601.19115", "authors": ["Xiang Gao", "Yunpeng Jia"], "title": "FBSDiff++: Improved Frequency Band Substitution of Diffusion Features for Efficient and Highly Controllable Text-Driven Image-to-Image Translation", "categories": ["cs.CV"], "comment": null, "summary": "With large-scale text-to-image (T2I) diffusion models achieving significant advancements in open-domain image creation, increasing attention has been focused on their natural extension to the realm of text-driven image-to-image (I2I) translation, where a source image acts as visual guidance to the generated image in addition to the textual guidance provided by the text prompt. We propose FBSDiff, a novel framework adapting off-the-shelf T2I diffusion model into the I2I paradigm from a fresh frequency-domain perspective. Through dynamic frequency band substitution of diffusion features, FBSDiff realizes versatile and highly controllable text-driven I2I in a plug-and-play manner (without need for model training, fine-tuning, or online optimization), allowing appearance-guided, layout-guided, and contour-guided I2I translation by progressively substituting low-frequency band, mid-frequency band, and high-frequency band of latent diffusion features, respectively. In addition, FBSDiff flexibly enables continuous control over I2I correlation intensity simply by tuning the bandwidth of the substituted frequency band. To further promote image translation efficiency, flexibility, and functionality, we propose FBSDiff++ which improves upon FBSDiff mainly in three aspects: (1) accelerate inference speed by a large margin (8.9$\\times$ speedup in inference) with refined model architecture; (2) improve the Frequency Band Substitution module to allow for input source images of arbitrary resolution and aspect ratio; (3) extend model functionality to enable localized image manipulation and style-specific content creation with only subtle adjustments to the core method. Extensive qualitative and quantitative experiments verify superiority of FBSDiff++ in I2I translation visual quality, efficiency, versatility, and controllability compared to related advanced approaches.", "AI": {"tldr": "FBSDiff++提出了一种改进的频率带替换方法，用于高效的文本驱动图像到图像翻译。", "motivation": "为了提高大型文本到图像模型在图像生成中的表现，并探索其在文本驱动图像到图像翻译上的应用。通过从频域视角出发，实现高效可控的图像翻译。", "method": "FBSDiff++通过对扩散特征进行动态频率带替换来实现实用且高度控制的文本驱动I2I转换，包括低、中、高频率带的逐步替代；改进了模型架构以加速推理速度，并扩展功能以支持局部图像操作和风格特定的内容创建。", "result": "FBSDiff++在I2I翻译的质量、效率、多样性和可控性上优于相关先进方法。", "conclusion": "该研究成功实现了高效的文本驱动I2I转换，展示了其优越的性能和灵活性。"}}
{"id": "2601.19114", "pdf": "https://arxiv.org/pdf/2601.19114", "abs": "https://arxiv.org/abs/2601.19114", "authors": ["Lin Chen", "Yue He", "Fengting Zhang", "Yaonan Wang", "Fengming Lin", "Xiang Chen", "Min Liu"], "title": "Reg-TTR, Test-Time Refinement for Fast, Robust and Accurate Image Registration", "categories": ["cs.CV"], "comment": null, "summary": "Traditional image registration methods are robust but slow due to their iterative nature. While deep learning has accelerated inference, it often struggles with domain shifts. Emerging registration foundation models offer a balance of speed and robustness, yet typically cannot match the peak accuracy of specialized models trained on specific datasets. To mitigate this limitation, we propose Reg-TTR, a test-time refinement framework that synergizes the complementary strengths of both deep learning and conventional registration techniques. By refining the predictions of pre-trained models at inference, our method delivers significantly improved registration accuracy at a modest computational cost, requiring only 21% additional inference time (0.56s). We evaluate Reg-TTR on two distinct tasks and show that it achieves state-of-the-art (SOTA) performance while maintaining inference speeds close to previous deep learning methods. As foundation models continue to emerge, our framework offers an efficient strategy to narrow the performance gap between registration foundation models and SOTA methods trained on specialized datasets. The source code will be publicly available following the acceptance of this work.", "AI": {"tldr": "本文提出了Reg-TTR，一种在推断时优化预测的框架，结合了深度学习和传统图像配准技术的优点。", "motivation": "传统的图像配准方法虽然鲁棒但是计算耗时，而深度学习模型尽管加速了推理过程，但在域偏移上表现不佳。新兴的基础模型提供了速度与鲁棒性的平衡，但通常无法达到针对特定数据集训练的专用模型的峰值精度。", "method": "提出Reg-TTR框架，在推断阶段通过优化预训练模型预测来提高配准准确度，并且只需额外增加21%的计算时间（0.56秒）。", "result": "在两种不同的任务中，Reg-TTR实现了最先进的性能并保持了接近于先前深度学习方法的速度。", "conclusion": "随着基础模型的发展，Reg-TTR提供了一种有效的方法来缩小基础模型和针对特定数据集训练的最先进方法之间的性能差距。"}}
{"id": "2601.19113", "pdf": "https://arxiv.org/pdf/2601.19113", "abs": "https://arxiv.org/abs/2601.19113", "authors": ["Yinghao Liu", "Chengwei Liu", "Xiaotao Liang", "Haoyin Yan", "Shaofei Xue", "Zheng Xue"], "title": "A Hybrid Discriminative and Generative System for Universal Speech Enhancement", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted by ICASSP 2026.This work was submitted to the ICASSP 2026 URGENT Challenge (Track 1)", "summary": "Universal speech enhancement aims at handling inputs with various speech distortions and recording conditions. In this work, we propose a novel hybrid architecture that synergizes the signal fidelity of discriminative modeling with the reconstruction capabilities of generative modeling. Our system utilizes the discriminative TF-GridNet model with the Sampling-Frequency-Independent strategy to handle variable sampling rates universally. In parallel, an autoregressive model combined with spectral mapping modeling generates detail-rich speech while effectively suppressing generative artifacts. Finally, a fusion network learns adaptive weights of the two outputs under the optimization of signal-level losses and the comprehensive Speech Quality Assessment (SQA) loss. Our proposed system is evaluated in the ICASSP 2026 URGENT Challenge (Track 1) and ranks the third place.", "AI": {"tldr": "本文提出了一种新型的混合架构，结合判别模型和生成模型的优点，用于通用语音增强。", "motivation": "目标是处理各种语音失真和录音条件下的输入。通过结合判别模型的信号保真度与生成模型的重建能力来提高语音质量。", "method": "采用TF-GridNet模型处理不同采样率并利用自回归模型联合频谱映射模型生成高质量语音，最终通过融合网络学习两个输出的适应性权重。", "result": "系统在ICASSP2026 URGENT Challenge（Track 1）中排名第三。", "conclusion": "所提出的混合架构有效结合了判别和生成模型的优点，在不同录音条件下的语音增强任务上表现出色。"}}
{"id": "2601.19112", "pdf": "https://arxiv.org/pdf/2601.19112", "abs": "https://arxiv.org/abs/2601.19112", "authors": ["Nanhan Shen", "Zhilei Liu"], "title": "Uncertainty-Aware 3D Emotional Talking Face Synthesis with Emotion Prior Distillation", "categories": ["cs.AI", "cs.MM", "cs.SD"], "comment": "Accepted by ICASSP 2026", "summary": "Emotional Talking Face synthesis is pivotal in multimedia and signal processing, yet existing 3D methods suffer from two critical challenges: poor audio-vision emotion alignment, manifested as difficult audio emotion extraction and inadequate control over emotional micro-expressions; and a one-size-fits-all multi-view fusion strategy that overlooks uncertainty and feature quality differences, undermining rendering quality. We propose UA-3DTalk, Uncertainty-Aware 3D Emotional Talking Face Synthesis with emotion prior distillation, which has three core modules: the Prior Extraction module disentangles audio into content-synchronized features for alignment and person-specific complementary features for individualization; the Emotion Distillation module introduces a multi-modal attention-weighted fusion mechanism and 4D Gaussian encoding with multi-resolution code-books, enabling fine-grained audio emotion extraction and precise control of emotional micro-expressions; the Uncertainty-based Deformation deploys uncertainty blocks to estimate view-specific aleatoric (input noise) and epistemic (model parameters) uncertainty, realizing adaptive multi-view fusion and incorporating a multi-head decoder for Gaussian primitive optimization to mitigate the limitations of uniform-weight fusion. Extensive experiments on regular and emotional datasets show UA-3DTalk outperforms state-of-the-art methods like DEGSTalk and EDTalk by 5.2% in E-FID for emotion alignment, 3.1% in SyncC for lip synchronization, and 0.015 in LPIPS for rendering quality. Project page: https://mrask999.github.io/UA-3DTalk", "AI": {"tldr": "本文提出了UA-3DTalk，一种不确定性感知的三维情感说话人脸合成方法。", "motivation": "现有的3D方法在音频视觉情绪对齐和多视角融合策略方面存在挑战，导致生成效果不佳。因此，需要一个新的解决方案来改进这些问题。", "method": "提出了一种基于不确定性的三维情感说话脸合成模型，包括先验提取模块、情感蒸馏模块以及不确定性变形模块。", "result": "实验结果显示UA-3DTalk在情绪对齐、唇同步及渲染质量方面优于现有方法。", "conclusion": "本文的方法解决了现有技术中音频视觉情绪对齐和多视角融合策略的问题，提升了三维情感说话脸合成的效果。"}}
{"id": "2601.19109", "pdf": "https://arxiv.org/pdf/2601.19109", "abs": "https://arxiv.org/abs/2601.19109", "authors": ["Arhan Vohra", "Taketo Akama"], "title": "Interpretable and Perceptually-Aligned Music Similarity with Pretrained Embeddings", "categories": ["cs.SD"], "comment": null, "summary": "Perceptual similarity representations enable music retrieval systems to determine which songs sound most similar to listeners. State-of-the-art approaches based on task-specific training via self-supervised metric learning show promising alignment with human judgment, but are difficult to interpret or generalize due to limited dataset availability. We show that pretrained text-audio embeddings (CLAP and MuQ-MuLan) offer comparable perceptual alignment on similarity tasks without any additional fine-tuning. To surpass this baseline, we introduce a novel method to perceptually align pretrained embeddings with source separation and linear optimization on ABX preference data from listening tests. Our model provides interpretable and controllable instrument-wise weights, allowing music producers to retrieve stem-level loops and samples based on mixed reference songs.", "AI": {"tldr": "该论文提出了一种利用预训练的文本-音频嵌入并通过源分离和线性优化来感知对齐的新方法，以提高音乐相似度检索系统的性能。", "motivation": "目前基于自监督对比学习的方法虽然在与人类判断的一致性上表现出色，但由于数据集限制难以解释或泛化。论文旨在利用预训练的文本-音频嵌入并结合新方法提升音乐相似度的感知一致性，并提供可解释和可控的结果。", "method": "该研究首先使用CLAP和MuQ-MuLan等预训练模型，然后通过源分离技术和ABX偏好数据上的线性优化来进一步对齐感知。这种方法可以生成基于混合参考歌曲的乐器级循环和样本检索。", "result": "新方法在音乐相似度任务中提供了与人类判断相一致的结果，并且能够为音乐制作人提供可解释和可控的乐器权重，从而提高音乐素材的检索效率。", "conclusion": "该论文展示了通过预训练嵌入结合新颖的方法可以达到高度感知一致性的同时保持模型的可解释性。"}}
{"id": "2601.19106", "pdf": "https://arxiv.org/pdf/2601.19106", "abs": "https://arxiv.org/abs/2601.19106", "authors": ["Dipin Khati", "Daniel Rodriguez-Cardenas", "Paul Pantzer", "Denys Poshyvanyk"], "title": "Detecting and Correcting Hallucinations in LLM-Generated Code via Deterministic AST Analysis", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted to FORGE 2026", "summary": "Large Language Models (LLMs) for code generation boost productivity but frequently introduce Knowledge Conflicting Hallucinations (KCHs), subtle, semantic errors, such as non-existent API parameters, that evade linters and cause runtime failures. Existing mitigations like constrained decoding or non-deterministic LLM-in-the-loop repair are often unreliable for these errors. This paper investigates whether a deterministic, static-analysis framework can reliably detect \\textit{and} auto-correct KCHs. We propose a post-processing framework that parses generated code into an Abstract Syntax Tree (AST) and validates it against a dynamically-generated Knowledge Base (KB) built via library introspection. This non-executing approach uses deterministic rules to find and fix both API and identifier-level conflicts. On a manually-curated dataset of 200 Python snippets, our framework detected KCHs with 100\\% precision and 87.6\\% recall (0.934 F1-score), and successfully auto-corrected 77.0\\% of all identified hallucinations. Our findings demonstrate that this deterministic post-processing approach is a viable and reliable alternative to probabilistic repair, offering a clear path toward trustworthy code generation.", "AI": {"tldr": "大型语言模型在代码生成中引入知识冲突幻觉，提出一种基于抽象语法树的确定性静态分析框架来检测和纠正这些错误。", "motivation": "大型语言模型产生的代码经常包含知识冲突幻觉，这种问题难以被现有的linters发现并修复。因此需要一种新的方法来可靠地识别和修正这些问题。", "method": "提出了一种后处理框架，该框架将生成的代码解析为抽象语法树，并通过库内省动态生成的知识库进行验证，以检测和纠正API级别和标识符级别的冲突。", "result": "在200个Python片段的手动策划数据集上，该框架能够以100%的精确度识别知识冲突幻觉，并成功自动修复77.0％的所有已知幻觉。F1得分为0.934。", "conclusion": "这种确定性的后处理方法是一种可靠且可行的概率性修复替代方案，为可信赖的代码生成提供了明确路径"}}
{"id": "2601.19103", "pdf": "https://arxiv.org/pdf/2601.19103", "abs": "https://arxiv.org/abs/2601.19103", "authors": ["Linshan Wu", "Jiaxin Zhuang", "Hao Chen"], "title": "Glance and Focus Reinforcement for Pan-cancer Screening", "categories": ["cs.CV"], "comment": "Accepted by ICLR 2026. Code is available at https://github.com/Luffy03/GF-Screen", "summary": "Pan-cancer screening in large-scale CT scans remains challenging for existing AI methods, primarily due to the difficulty of localizing diverse types of tiny lesions in large CT volumes. The extreme foreground-background imbalance significantly hinders models from focusing on diseased regions, while redundant focus on healthy regions not only decreases the efficiency but also increases false positives. Inspired by radiologists' glance and focus diagnostic strategy, we introduce GF-Screen, a Glance and Focus reinforcement learning framework for pan-cancer screening. GF-Screen employs a Glance model to localize the diseased regions and a Focus model to precisely segment the lesions, where segmentation results of the Focus model are leveraged to reward the Glance model via Reinforcement Learning (RL). Specifically, the Glance model crops a group of sub-volumes from the entire CT volume and learns to select the sub-volumes with lesions for the Focus model to segment. Given that the selecting operation is non-differentiable for segmentation training, we propose to employ the segmentation results to reward the Glance model. To optimize the Glance model, we introduce a novel group relative learning paradigm, which employs group relative comparison to prioritize high-advantage predictions and discard low-advantage predictions within sub-volume groups, not only improving efficiency but also reducing false positives. In this way, for the first time, we effectively extend cutting-edge RL techniques to tackle the specific challenges in pan-cancer screening. Extensive experiments on 16 internal and 7 external datasets across 9 lesion types demonstrated the effectiveness of GF-Screen. Notably, GF-Screen leads the public validation leaderboard of MICCAI FLARE25 pan-cancer challenge, surpassing the FLARE24 champion solution by a large margin (+25.6% DSC and +28.2% NSD).", "AI": {"tldr": "本文提出了一种用于泛癌筛查的Glance和Focus强化学习框架GF-Screen，以提高CT扫描中不同类型的微小病灶定位准确性。", "motivation": "现有AI方法在大型CT扫描中的泛癌筛查面临挑战，难以准确地从大量背景区域中定位各种微小病变。为了解决这一问题并模仿放射科医生的诊断策略，提出了GF-Screen框架以提升模型效率和减少误报率。", "method": "GF-Screen包含两个主要部分：Glance模型用于病灶区域的粗略定位，Focus模型进行精确定位。通过强化学习机制使用分割结果来奖励Glance模型，并引入了一种新的分组相对学习范式以优化选择过程。", "result": "在16个内部和7个外部数据集上的实验结果显示GF-Screen具有显著效果，在MICCAI FLARE25泛癌挑战赛的公共验证排行榜上领先，分别比FLARE24冠军方案高出25.6％DSC和28.2％NSD。", "conclusion": "通过创新性地结合强化学习技术与医学影像分析，GF-Screen有效地解决了泛癌筛查中的病灶定位问题，并展示了其在多个数据集上的优越性能。"}}
{"id": "2601.19099", "pdf": "https://arxiv.org/pdf/2601.19099", "abs": "https://arxiv.org/abs/2601.19099", "authors": ["Yosub Shin", "Michael Buriek", "Igor Molybog"], "title": "m2sv: A Scalable Benchmark for Map-to-Street-View Spatial Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision--language models (VLMs) achieve strong performance on many multimodal benchmarks but remain brittle on spatial reasoning tasks that require aligning abstract overhead representations with egocentric views. We introduce m2sv, a scalable benchmark for map-to-street-view spatial reasoning that asks models to infer camera viewing direction by aligning a north-up overhead map with a Street View image captured at the same real-world intersection. We release m2sv-20k, a geographically diverse benchmark with controlled ambiguity, along with m2sv-sft-11k, a curated set of structured reasoning traces for supervised fine-tuning. Despite strong performance on existing multimodal benchmarks, the best evaluated VLM achieves only 65.2% accuracy on m2sv, far below the human baseline of 95%. While supervised fine-tuning and reinforcement learning yield consistent gains, cross-benchmark evaluations reveal limited transfer. Beyond aggregate accuracy, we systematically analyze difficulty in map-to-street-view reasoning using both structural signals and human effort, and conduct an extensive failure analysis of adapted open models. Our findings highlight persistent gaps in geometric alignment, evidence aggregation, and reasoning consistency, motivating future work on grounded spatial reasoning across viewpoints.", "AI": {"tldr": "提出了m2sv基准，用于评估视觉语言模型在地图到街景视角推理任务上的性能。", "motivation": "当前的视觉语言模型虽在多模态基准上表现出色，但在空间推理任务中表现脆弱。此工作旨在通过引入新基准来解决这些问题，并提高模型的空间理解能力。", "method": "提出了m2sv数据集和评估方法，包括地理分布广泛的数据和结构化的监督微调数据。", "result": "最佳的视觉语言模型在m2sv上的准确率为65.2%，远低于人类95%的表现。虽然有改进但跨基准测试表明转移学习有限。", "conclusion": "该研究强调了几何对齐、证据聚合和推理一致性的挑战，鼓励未来的工作关注不同视角下的空间推理任务。"}}
{"id": "2601.19098", "pdf": "https://arxiv.org/pdf/2601.19098", "abs": "https://arxiv.org/abs/2601.19098", "authors": ["Kurt Enkera", "Josh Pinskier", "Marcus Gallagher", "David Howard"], "title": "SimTO: A simulation-based topology optimization framework for bespoke soft robotic grippers", "categories": ["cs.RO"], "comment": "12 pages, 8 figures. Submitted to Structural and Multidisciplinary Optimization", "summary": "Soft robotic grippers are essential for grasping delicate, geometrically complex objects in manufacturing, healthcare and agriculture. However, existing grippers struggle to grasp feature-rich objects with high topological variability, including gears with sharp tooth profiles on automotive assembly lines, corals with fragile protrusions, or vegetables with irregular branching structures like broccoli. Unlike simple geometric primitives such as cubes or spheres, feature-rich objects lack a clear \"optimal\" contact surface, making them both difficult to grasp and susceptible to damage when grasped by existing gripper designs. Safe handling of such objects therefore requires specialized soft grippers whose morphology is tailored to the object's features. Topology optimization offers a promising approach for producing specialized grippers, but its utility is limited by the requirement for pre-defined load cases. For soft grippers interacting with feature-rich objects, these loads arise from hundreds of unpredictable gripper-object contact forces during grasping and are unknown a priori. To address this problem, we introduce SimTO, a framework that enables high-resolution topology optimization by automatically extracting load cases from a contact-based physics simulator, eliminating the need for manual load specification. Given an arbitrary feature-rich object, SimTO produces highly customized soft grippers with fine-grained morphological features tailored to the object geometry. Numerical results show our designs are not only highly specialized to feature-rich objects, but also generalize to unseen objects.", "AI": {"tldr": "SimTO框架用于制造针对特定复杂对象定制的软机器人夹爪，通过自动从基于接触的物理仿真器中提取负载情况来进行高分辨率拓扑优化。", "motivation": "现有的软机器人夹爪在处理具有高度拓扑变化特征的对象时面临挑战。这些对象缺乏清晰的最佳接触面，导致难以安全抓取和容易损坏。为了克服这个问题，SimTO框架被设计来生成定制化的夹爪形态以适应复杂物体的几何结构。", "method": "SimTO利用基于物理仿真的方法自动提取负载情况，不再需要手动定义负载条件。它可以根据任意特征丰富的对象自动生成具有细粒度形态特征的高度定制化软机器人夹爪。", "result": "数值结果表明，所设计的夹爪不仅对特定复杂物体高度专业化，并且能够泛化到未见过的对象上。", "conclusion": "SimTO框架为制造适应复杂形状和高拓扑变化对象的软机器人夹爪提供了新的可能性，展示了其在处理未知或难以预测负载情况的应用潜力。"}}
{"id": "2601.19094", "pdf": "https://arxiv.org/pdf/2601.19094", "abs": "https://arxiv.org/abs/2601.19094", "authors": ["Jingcheng Yu", "Mingliang Zeng", "Qiwei Ye"], "title": "FloydNet: A Learning Paradigm for Global Relational Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": "29 pages, 9 figures, 14 tables", "summary": "Developing models capable of complex, multi-step reasoning is a central goal in artificial intelligence. While representing problems as graphs is a powerful approach, Graph Neural Networks (GNNs) are fundamentally constrained by their message-passing mechanism, which imposes a local bottleneck that limits global, holistic reasoning. We argue that dynamic programming (DP), which solves problems by iteratively refining a global state, offers a more powerful and suitable learning paradigm. We introduce FloydNet, a new architecture that embodies this principle. In contrast to local message passing, FloydNet maintains a global, all-pairs relationship tensor and learns a generalized DP operator to progressively refine it. This enables the model to develop a task-specific relational calculus, providing a principled framework for capturing long-range dependencies. Theoretically, we prove that FloydNet achieves 3-WL (2-FWL) expressive power, and its generalized form aligns with the k-FWL hierarchy. FloydNet demonstrates state-of-the-art performance across challenging domains: it achieves near-perfect scores (often >99\\%) on the CLRS-30 algorithmic benchmark, finds exact optimal solutions for the general Traveling Salesman Problem (TSP) at rates significantly exceeding strong heuristics, and empirically matches the 3-WL test on the BREC benchmark. Our results establish this learned, DP-style refinement as a powerful and practical alternative to message passing for high-level graph reasoning.", "AI": {"tldr": "本文提出了FloydNet，一种新的用于全局关系推理的架构。", "motivation": "现有图神经网络受限于本地消息传递机制，难以进行全局整体性推理。动态规划（DP）通过迭代改进全局状态来解决问题，为复杂多步推理提供了更强大的学习范式。", "method": "FloydNet维护一个全局关系张量，并学习一种广义的DP操作符逐步细化它，以发展特定任务的关系演算，捕捉长程依赖性。理论上证明FloydNet达到3-WL（2-FWL）表达能力，且其泛化形式符合k-FWL层级。", "result": "实验显示FloydNet在CLRS-30算法基准中表现接近完美，在一般旅行商问题上找到精确最优解率远超强启发式方法，并在BREC基准测试中与3-WL相符。结果表明学习DP风格的细化是一种强大的替代消息传递进行高层次图推理的方法。", "conclusion": "FloydNet提供了一种新的全局关系推理架构，展示了学习DP风格细化的有效性作为复杂多步骤推理的强大且实际的方案。"}}
{"id": "2601.19092", "pdf": "https://arxiv.org/pdf/2601.19092", "abs": "https://arxiv.org/abs/2601.19092", "authors": ["Bohan Hou", "Hongyi Jin", "Guanjie Wang", "Jinqi Chen", "Yaxing Cai", "Lijie Yang", "Zihao Ye", "Yaoyao Ding", "Ruihang Lai", "Tianqi Chen"], "title": "Axe: A Simple Unified Layout Abstraction for Machine Learning Compilers", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PL"], "comment": null, "summary": "Scaling modern deep learning workloads demands coordinated placement of data and compute across device meshes, memory hierarchies, and heterogeneous accelerators. We present Axe Layout, a hardware-aware abstraction that maps logical tensor coordinates to a multi-axis physical space via named axes. Axe unifies tiling, sharding, replication, and offsets across inter-device distribution and on-device layouts, enabling collective primitives to be expressed consistently from device meshes to threads. Building on Axe, we design a multi-granularity, distribution-aware DSL and compiler that composes thread-local control with collective operators in a single kernel. Experiments show that our unified approach can bring performance close to hand-tuned kernels on across latest GPU devices and multi-device environments and accelerator backends.", "AI": {"tldr": "提出了一种硬件感知的布局抽象Axe Layout，用于机器学习编译器中统一处理数据和计算分布。", "motivation": "现代深度学习任务需要协调跨设备网格、内存层次结构以及异构加速器的数据和计算放置。当前的方法缺乏一致性且难以扩展。", "method": "引入了Axes布局抽象来映射逻辑张量坐标到多轴物理空间，统一处理切片、分块、复制和偏移操作，设计了一种支持多粒度分布感知DSL及编译器。", "result": "实验表明该方法在最新GPU设备以及跨设备环境中性能接近手调内核的水平。", "conclusion": "通过使用Axe Layout抽象简化了机器学习模型的优化过程，并提高了计算效率。"}}
{"id": "2601.19091", "pdf": "https://arxiv.org/pdf/2601.19091", "abs": "https://arxiv.org/abs/2601.19091", "authors": ["Zhao Wei", "Chin Chun Ooi", "Jian Cheng Wong", "Abhishek Gupta", "Pao-Hsiung Chiu", "Yew-Soon Ong"], "title": "Out-of-Distribution Generalization for Neural Physics Solvers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Neural physics solvers are increasingly used in scientific discovery, given their potential for rapid in silico insights into physical, materials, or biological systems and their long-time evolution. However, poor generalization beyond their training support limits exploration of novel designs and long-time horizon predictions. We introduce NOVA, a route to generalizable neural physics solvers that can provide rapid, accurate solutions to scenarios even under distributional shifts in partial differential equation parameters, geometries and initial conditions. By learning physics-aligned representations from an initial sparse set of scenarios, NOVA consistently achieves 1-2 orders of magnitude lower out-of-distribution errors than data-driven baselines across complex, nonlinear problems including heat transfer, diffusion-reaction and fluid flow. We further showcase NOVA's dual impact on stabilizing long-time dynamical rollouts and improving generative design through application to the simulation of nonlinear Turing systems and fluidic chip optimization. Unlike neural physics solvers that are constrained to retrieval and/or emulation within an a priori space, NOVA enables reliable extrapolation beyond known regimes, a key capability given the need for exploration of novel hypothesis spaces in scientific discovery", "AI": {"tldr": "介绍一种名为NOVA的方法，用于提高神经物理求解器在分布变化条件下的泛化能力。", "motivation": "当前的神经物理求解器由于训练集限制，在面对未知或不同的参数、几何形状和初始条件下表现不佳。这阻碍了科学探索与长期预测。", "method": "NOVA通过从少量初始场景中学习物理一致性的表示，提高了神经网络在分布变化情况下的泛化性能。", "result": "实验显示，NOVA在解决热传导、扩散反应及流体流动等复杂非线性问题时，比数据驱动的基础模型低1到2个数量级的误差。此外，在稳定长时间动态回放和改进生成设计方面也取得了显著效果。", "conclusion": "NOVA提供了可靠的泛化能力，能够超越已知范围进行有效推理，这为科学探索中的新假设空间提供了关键支持。"}}
{"id": "2601.19090", "pdf": "https://arxiv.org/pdf/2601.19090", "abs": "https://arxiv.org/abs/2601.19090", "authors": ["Bochao Liu", "Shiming Ge", "Pengju Wang", "Shikun Li", "Tongliang Liu"], "title": "Privacy-Preserving Model Transcription with Differentially Private Synthetic Distillation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Accepted by IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)", "summary": "While many deep learning models trained on private datasets have been deployed in various practical tasks, they may pose a privacy leakage risk as attackers could recover informative data or label knowledge from models. In this work, we present \\emph{privacy-preserving model transcription}, a data-free model-to-model conversion solution to facilitate model deployment with a privacy guarantee. To this end, we propose a cooperative-competitive learning approach termed \\emph{differentially private synthetic distillation} that learns to convert a pretrained model (teacher) into its privacy-preserving counterpart (student) via a trainable generator without access to private data. The learning collaborates with three players in a unified framework and performs alternate optimization: i)~the generator is learned to generate synthetic data, ii)~the teacher and student accept the synthetic data and compute differential private labels by flexible data or label noisy perturbation, and iii)~the student is updated with noisy labels and the generator is updated by taking the student as a discriminator for adversarial training. We theoretically prove that our approach can guarantee differential privacy and convergence. The transcribed student has good performance and privacy protection, while the resulting generator can generate private synthetic data for downstream tasks. Extensive experiments clearly demonstrate that our approach outperforms 26 state-of-the-arts.", "AI": {"tldr": "本文提出了一种名为差分隐私合成蒸馏的无数据模型转换方法，用于将预训练模型转化为具有隐私保护的学生模型。", "motivation": "深度学习模型在处理私有数据时可能会泄露隐私信息，因此需要一种能够在不使用原始私人数据的情况下保证模型隐私的方法。", "method": "通过三个玩家协同竞争学习框架，生成器学习合成数据，教师和学生利用这些数据进行差分隐私标签计算，并更新学生模型以提高其性能与隐私保护；同时，生成器还作为对抗训练的判别器来进一步优化。", "result": "实验表明该方法优于26种现有技术，在保证性能的同时提供了强大的隐私保护能力。", "conclusion": "提出的差分隐私合成蒸馏方法能够有效地将预训练模型转化为具有高隐私保障的学生模型，并且在多个任务上都取得了很好的效果。"}}
{"id": "2601.19089", "pdf": "https://arxiv.org/pdf/2601.19089", "abs": "https://arxiv.org/abs/2601.19089", "authors": ["Rezaul Karim", "Maryam Dialameh", "Yang Liu", "Boxing Chen", "Walid Ahmed"], "title": "EPAS: Efficient Training with Progressive Activation Sharing", "categories": ["cs.LG", "cs.CV"], "comment": "This is a preprint of a paper accepted at the 39th Canadian Conference on Artificial Intelligence (Canadian AI 2026)", "summary": "We present a novel method for Efficient training with Progressive Activation Sharing (EPAS). This method bridges progressive training paradigm with the phenomenon of redundant QK (or KV ) activations across deeper layers of transformers. EPAS gradually grows a sharing region during training by switching decoder layers to activation sharing mode. This results in throughput increase due to reduced compute. To utilize deeper layer redundancy, the sharing region starts from the deep end of the model and grows towards the shallow end. The EPAS trained models allow for variable region lengths of activation sharing for different compute budgets during inference. Empirical evaluations with QK activation sharing in LLaMA models ranging from 125M to 7B parameters show up to an 11.1% improvement in training throughput and up to a 29% improvement in inference throughput while maintaining similar loss curve to the baseline models. Furthermore, applying EPAS in continual pretraining to transform TinyLLaMA into an attention-sharing model yields up to a 10% improvement in average accuracy over state-of-the-art methods, emphasizing the significance of progressive training in cross layer activation sharing models.", "AI": {"tldr": "提出了一种新的高效训练方法EPAS，通过逐步增加激活共享区域来提高Transformer模型的训练和推理效率。", "motivation": "解决在深度Transformer中冗余QK（或KV）激活的问题，通过减少计算量以提升训练和推理的吞吐量。", "method": "提出了一种名为EPAS的方法，在训练过程中逐步增加共享区域，并从深层到浅层进行激活共享。这种方法利用了不同层之间的冗余激活模式，以提高模型效率。", "result": "在LLaMA模型上测试表明，EPAS方法可以实现高达11.1%的训练吞吐量提升和29%的推理吞吐量提升，同时保持与基线模型相似的损失曲线。此外，在持续预训练中应用EPAS可将TinyLLaMA转变为注意力共享模型，并提高了平均精度。", "conclusion": "通过逐步增加激活共享区域的方法显著提升了Transformer模型的效率，展示了渐进式培训在跨层激活共享中的重要性。"}}
{"id": "2601.19082", "pdf": "https://arxiv.org/pdf/2601.19082", "abs": "https://arxiv.org/abs/2601.19082", "authors": ["Trung-Kiet Huynh", "Dao-Sy Duy-Minh", "Thanh-Bang Cao", "Phong-Hao Le", "Hong-Dan Nguyen", "Nguyen Lam Phu Quy", "Minh-Luan Nguyen-Vo", "Hong-Phat Pham", "Pham Phu Hoa", "Thien-Kim Than", "Chi-Nguyen Tran", "Huy Tran", "Gia-Thoai Tran-Le", "Alessio Buscemi", "Le Hong Trang", "The Anh Han"], "title": "More at Stake: How Payoff and Language Shape LLM Agent Strategies in Cooperation Dilemmas", "categories": ["cs.AI", "cs.CL", "cs.GT", "cs.LG", "cs.MA"], "comment": "14 pages, 10 figures, 4 tables", "summary": "As LLMs increasingly act as autonomous agents in interactive and multi-agent settings, understanding their strategic behavior is critical for safety, coordination, and AI-driven social and economic systems. We investigate how payoff magnitude and linguistic context shape LLM strategies in repeated social dilemmas, using a payoff-scaled Prisoner's Dilemma to isolate sensitivity to incentive strength. Across models and languages, we observe consistent behavioral patterns, including incentive-sensitive conditional strategies and cross-linguistic divergence. To interpret these dynamics, we train supervised classifiers on canonical repeated-game strategies and apply them to LLM decisions, revealing systematic, model- and language-dependent behavioral intentions, with linguistic framing sometimes matching or exceeding architectural effects. Our results provide a unified framework for auditing LLMs as strategic agents and highlight cooperation biases with direct implications for AI governance and multi-agent system design.", "AI": {"tldr": "研究LLM在重复社会困境中的策略行为，探讨奖励规模和语言背景的影响。", "motivation": "理解LLM作为自主代理的战略行为对于安全、协调和AI驱动的社会经济系统至关重要。", "method": "使用调整了奖励幅度的囚徒困境模型来分析不同模型和语言下的行为模式，并利用监督分类器解读这些动态。", "result": "观察到一致的行为模式，包括条件策略的激励敏感性和跨语种差异；揭示出系统的、依赖于模型和语言的战略意图。", "conclusion": "结果提供了审计LLM作为战略代理人的统一框架，并强调了合作偏差对AI治理和多智能体系统设计的影响。"}}
{"id": "2601.19079", "pdf": "https://arxiv.org/pdf/2601.19079", "abs": "https://arxiv.org/abs/2601.19079", "authors": ["Naqash Afzal", "Niklas Funk", "Erik Helmut", "Jan Peters", "Benjamin Ward-Cherrier"], "title": "Neuromorphic BrailleNet: Accurate and Generalizable Braille Reading Beyond Single Characters through Event-Based Optical Tactile Sensing", "categories": ["cs.RO"], "comment": null, "summary": "Conventional robotic Braille readers typically rely on discrete, character-by-character scanning, limiting reading speed and disrupting natural flow. Vision-based alternatives often require substantial computation, introduce latency, and degrade in real-world conditions. In this work, we present a high accuracy, real-time pipeline for continuous Braille recognition using Evetac, an open-source neuromorphic event-based tactile sensor. Unlike frame-based vision systems, the neuromorphic tactile modality directly encodes dynamic contact events during continuous sliding, closely emulating human finger-scanning strategies. Our approach combines spatiotemporal segmentation with a lightweight ResNet-based classifier to process sparse event streams, enabling robust character recognition across varying indentation depths and scanning speeds. The proposed system achieves near-perfect accuracy (>=98%) at standard depths, generalizes across multiple Braille board layouts, and maintains strong performance under fast scanning. On a physical Braille board containing daily-living vocabulary, the system attains over 90% word-level accuracy, demonstrating robustness to temporal compression effects that challenge conventional methods. These results position neuromorphic tactile sensing as a scalable, low latency solution for robotic Braille reading, with broader implications for tactile perception in assistive and robotic applications.", "AI": {"tldr": "提出了一种基于神经形态触觉传感器的实时连续盲文识别方法，适用于各种扫描速度和深度。", "motivation": "传统的机器人盲文阅读器通常依赖逐字符扫描，限制了阅读速度并打断自然流程。视觉替代方案计算量大、引入延迟且在真实世界条件下表现不佳。", "method": "结合时空分割与轻量化ResNet分类器处理稀疏事件流，实现对不同凹陷深度和扫描速度的稳健字符识别。", "result": "系统在标准深度下达到接近完美的准确率（>98%），跨越多个盲文布局并保持快速扫描下的强性能。在实际生活中使用的物理盲文中，系统实现了超过90%的单词级准确性。", "conclusion": "神经形态触觉传感作为机器人盲文阅读和更广泛的手感感知应用中的可扩展、低延迟解决方案具有前景"}}
{"id": "2601.19072", "pdf": "https://arxiv.org/pdf/2601.19072", "abs": "https://arxiv.org/abs/2601.19072", "authors": ["Kla Tantithamthavorn", "Hong Yi Lin", "Patanamon Thongtanunam", "Wachiraphan Charoenwet", "Minwoo Jeong", "Ming Wu"], "title": "HalluJudge: A Reference-Free Hallucination Detection for Context Misalignment in Code Review Automation", "categories": ["cs.SE", "cs.AI"], "comment": "Under Review", "summary": "Large Language models (LLMs) have shown strong capabilities in code review automation, such as review comment generation, yet they suffer from hallucinations -- where the generated review comments are ungrounded in the actual code -- poses a significant challenge to the adoption of LLMs in code review workflows. To address this, we explore effective and scalable methods for a hallucination detection in LLM-generated code review comments without the reference. In this work, we design HalluJudge that aims to assess the grounding of generated review comments based on the context alignment. HalluJudge includes four key strategies ranging from direct assessment to structured multi-branch reasoning (e.g., Tree-of-Thoughts). We conduct a comprehensive evaluation of these assessment strategies across Atlassian's enterprise-scale software projects to examine the effectiveness and cost-efficiency of HalluJudge. Furthermore, we analyze the alignment between HalluJudge's judgment and developer preference of the actual LLM-generated code review comments in the real-world production. Our results show that the hallucination assessment in HalluJudge is cost-effective with an F1 score of 0.85 and an average cost of $0.009. On average, 67% of the HalluJudge assessments are aligned with the developer preference of the actual LLM-generated review comments in the online production. Our results suggest that HalluJudge can serve as a practical safeguard to reduce developers' exposure to hallucinated comments, fostering trust in AI-assisted code reviews.", "AI": {"tldr": "提出了一种不依赖参考的代码审查自动化中LLM生成评论的幻觉检测方法HalluJudge。", "motivation": "解决大型语言模型在代码审查时产生的未基于实际代码的评论问题，以促进其应用。", "method": "设计了四个关键策略（包括直接评估和结构化多分支推理）来评估LLM生成的评论与上下文的一致性。", "result": "通过企业级软件项目的综合评价，展示了HalluJudge在成本效益上的优势(F1分数为0.85, 平均成本$0.009)，并且其判断结果67%符合开发者偏好。", "conclusion": "表明HalluJudge是减少开发人员对幻觉评论暴露的一种实用保障措施，有助于建立对AI辅助代码审查的信任。"}}
{"id": "2601.19066", "pdf": "https://arxiv.org/pdf/2601.19066", "abs": "https://arxiv.org/abs/2601.19066", "authors": ["Runxiang Cheng", "Michele Tufano", "José Cambronero", "Renyao Wei", "Sherry Shi", "Grant Uy", "Pat Rondon", "Franjo Ivančić"], "title": "Dynamic Cogeneration of Bug Reproduction Test in Agentic Program Repair", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Bug Reproduction Tests (BRTs) have been used in many agentic Automated Program Repair (APR) systems, primarily for validating promising fixes and aiding fix generation. In practice, when developers submit a patch, they often implement the BRT alongside the fix. Our experience deploying agentic APR reveals that developers similarly desire a BRT within AI-generated patches to increase their confidence. However, canonical APR systems tend to generate BRTs and fixes separately, or focus on producing only the fix in the final patch. In this paper, we study agentic APR in the context of cogeneration, where the APR agent is instructed to generate both a fix and a BRT in the same patch. We evaluate the effectiveness of different cogeneration strategies on 120 human-reported bugs at Google and characterize different cogeneration strategies by their influence on APR agent behavior. We develop and evaluate patch selectors that account for test change information to select patches with plausible fixes (and plausible BRTs). Finally, we analyze the root causes of failed cogeneration trajectories. Importantly, we show that cogeneration allows the APR agent to generate BRTs for at least as many bugs as a dedicated BRT agent, without compromising the generation rate of plausible fixes, thereby reducing engineering effort in maintaining and coordinating separate generation pipelines for fix and BRT at scale.", "AI": {"tldr": "研究了动态协同生成程序修复和回归测试的方法，并评估其在大型项目中的有效性。", "motivation": "减少开发人员在验证自动修复代码时的工作量，提高他们对AI生成补丁的信心。", "method": "利用不同策略使APR代理同时生成修复和回归测试。通过分析120个Google报告的错误来评估这些策略的效果，并开发了考虑测试更改信息的选择器以选择包含可接受修复和回归测试的补丁。", "result": "展示了协同生成方法可以产生至少与专用回归测试代理一样多的有效回归测试，同时不影响修复代码的质量。", "conclusion": "通过动态协同生成程序修复和回归测试能够显著降低维护大型项目中的不同生成管道的需求。"}}
{"id": "2601.19064", "pdf": "https://arxiv.org/pdf/2601.19064", "abs": "https://arxiv.org/abs/2601.19064", "authors": ["David Bryant", "Celine Scornavacca", "David Swofford"], "title": "LvD: A New Algorithm for Computing the Likelihood of a Phylogeny", "categories": ["q-bio.PE", "cs.DS"], "comment": null, "summary": "There are few, if any, algorithms in statistical phylogenetics which are used more heavily than Felsenstein's 1973 pruning method for computing the likelihood of a tree. We present LvD, (Likelihood via Decomposition), an alternative to Felsenstein's algorithm based on a different decomposition of the underlying phylogeny. It works for all standard nucleotide models. The new algorithm allows updates of the likelihood calculation in worst case $O(\\log n)$ time with $n$ taxa, as opposed to worst case $O(n)$ time for existing methods. In practice this leads to appreciable improvements in likelihood calculations, the extent of speed-up depending on how balanced or unbalanced the trees are. We explore implications for parallel computing, and show that the approach allows likelihoods to be computed in $O(\\log n)$ parallel time per site, compared to (worst case) $O(n)$ time. We implemented and applied the algorithm to large numbers of simulated and empirical data sets and showed that these theoretical advances lead to a significant practical speed-up, although the extent of the improvement depends on how balanced the phylogenies already are.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.19063", "pdf": "https://arxiv.org/pdf/2601.19063", "abs": "https://arxiv.org/abs/2601.19063", "authors": ["Siddhant Arora", "Jinchuan Tian", "Jiatong Shi", "Hayato Futami", "Yosuke Kashiwagi", "Emiru Tsunoo", "Shinji Watanabe"], "title": "Optimizing Conversational Quality in Spoken Dialogue Systems with Reinforcement Learning from AI Feedback", "categories": ["cs.CL", "cs.SD"], "comment": null, "summary": "Reinforcement learning from human or AI feedback (RLHF/RLAIF) for speech-in/speech-out dialogue systems (SDS) remains underexplored, with prior work largely limited to single semantic rewards applied at the utterance level. Such setups overlook the multi-dimensional and multi-modal nature of conversational quality, which encompasses semantic coherence, audio naturalness, speaker consistency, emotion alignment, and turn-taking behavior. Moreover, they are fundamentally mismatched with duplex spoken dialogue systems that generate responses incrementally, where agents must make decisions based on partial utterances. We address these limitations with the first multi-reward RLAIF framework for SDS, combining semantic, audio-quality, and emotion-consistency rewards. To align utterance-level preferences with incremental, blockwise decoding in duplex models, we apply turn-level preference sampling and aggregate per-block log-probabilities within a single DPO objective. We present the first systematic study of preference learning for improving SDS quality in both multi-turn Chain-of-Thought and blockwise duplex models, and release a multi-reward DPO dataset to support reproducible research. Experiments show that single-reward RLAIF selectively improves its targeted metric, while joint multi-reward training yields consistent gains across semantic quality and audio naturalness. These results highlight the importance of holistic, multi-reward alignment for practical conversational SDS.", "AI": {"tldr": "本文提出了一种结合语义、音频质量和情感一致性奖励的多奖励RLAIF框架，以优化对话系统中的会话质量。", "motivation": "现有研究主要局限于单一语义奖励，未能全面考虑对话质量的多维度和多媒体特性，并且与双工语音对话系统的增量响应生成不匹配。", "method": "本文提出了一种新的多奖励RLAIF框架，并结合了分段偏好采样和单个DPO目标以解决增量决策问题。", "result": "实验表明，单一奖励RLAIF仅能针对性地改进特定指标，而联合多奖励训练则能够全面提高语义质量和音频自然度。", "conclusion": "结果强调了对实际对话系统的会话质量进行全面、多奖励对齐的重要性。"}}
{"id": "2601.19062", "pdf": "https://arxiv.org/pdf/2601.19062", "abs": "https://arxiv.org/abs/2601.19062", "authors": ["Mrinank Sharma", "Miles McCain", "Raymond Douglas", "David Duvenaud"], "title": "Who's in Charge? Disempowerment Patterns in Real-World LLM Usage", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Although AI assistants are now deeply embedded in society, there has been limited empirical study of how their usage affects human empowerment. We present the first large-scale empirical analysis of disempowerment patterns in real-world AI assistant interactions, analyzing 1.5 million consumer Claude.ai conversations using a privacy-preserving approach. We focus on situational disempowerment potential, which occurs when AI assistant interactions risk leading users to form distorted perceptions of reality, make inauthentic value judgments, or act in ways misaligned with their values. Quantitatively, we find that severe forms of disempowerment potential occur in fewer than one in a thousand conversations, though rates are substantially higher in personal domains like relationships and lifestyle. Qualitatively, we uncover several concerning patterns, such as validation of persecution narratives and grandiose identities with emphatic sycophantic language, definitive moral judgments about third parties, and complete scripting of value-laden personal communications that users appear to implement verbatim. Analysis of historical trends reveals an increase in the prevalence of disempowerment potential over time. We also find that interactions with greater disempowerment potential receive higher user approval ratings, possibly suggesting a tension between short-term user preferences and long-term human empowerment. Our findings highlight the need for AI systems designed to robustly support human autonomy and flourishing.", "AI": {"tldr": "该论文通过分析150万次Claude.ai对话，研究了AI助手在现实生活中的使用如何影响人类的权力和自主性。", "motivation": "尽管人工智能助理已深入社会各个领域，但对其实际使用是否损害人的权力的研究有限。作者旨在填补这一空白，探讨AI助手中的潜在脱权模式及其随时间的变化趋势。", "method": "通过采用隐私保护的方法分析150万次Claude.ai对话，研究者量化并定性地调查了严重形式的脱权可能性，并发现其在个人领域如人际关系和生活方式中出现频率更高。同时，还观察了历史趋势，以揭示潜在脱权情况的变化。", "result": "定量结果显示，在不到千分之一的对话中有严重的脱权风险；而定性分析则发现了诸如对迫害叙述和高傲身份的支持、道德判断以及价值导向个人通信的脚本化等令人担忧的现象。此外，研究还发现含有更高潜在脱权性的交互获得了更高的用户满意度。", "conclusion": "该研究表明需要设计更强大的AI系统以支持人类自主性和繁荣发展，并指出短期内用户的喜好可能与长期的人类权力保护存在冲突。"}}
{"id": "2601.19060", "pdf": "https://arxiv.org/pdf/2601.19060", "abs": "https://arxiv.org/abs/2601.19060", "authors": ["Jeonghwan Kim", "Renjie Tao", "Sanat Sharma", "Jiaqi Wang", "Kai Sun", "Zhaojiang Lin", "Seungwhan Moon", "Lambert Mathias", "Anuj Kumar", "Heng Ji", "Xin Luna Dong"], "title": "Pixel-Grounded Retrieval for Knowledgeable Large Multimodal Models", "categories": ["cs.CV", "cs.AI"], "comment": "Preprint", "summary": "Visual Question Answering (VQA) often requires coupling fine-grained perception with factual knowledge beyond the input image. Prior multimodal Retrieval-Augmented Generation (MM-RAG) systems improve factual grounding but lack an internal policy for when and how to retrieve. We propose PixSearch, the first end-to-end Segmenting Large Multimodal Model (LMM) that unifies region-level perception and retrieval-augmented reasoning. During encoding, PixSearch emits <search> tokens to trigger retrieval, selects query modalities (text, image, or region), and generates pixel-level masks that directly serve as visual queries, eliminating the reliance on modular pipelines (detectors, segmenters, captioners, etc.). A two-stage supervised fine-tuning regimen with search-interleaved supervision teaches retrieval timing and query selection while preserving segmentation ability. On egocentric and entity-centric VQA benchmarks, PixSearch substantially improves factual consistency and generalization, yielding a 19.7% relative gain in accuracy on CRAG-MM compared to whole image retrieval, while retaining competitive reasoning performance on various VQA and text-only QA tasks.", "AI": {"tldr": "本文提出了一种名为PixSearch的模型，它是一种统一区域级别感知和检索增强推理的端到端分割大型多模态模型。", "motivation": "现有的多模态检索增强生成系统可以改善事实基础但缺乏内部策略来决定何时以及如何进行检索。因此，本文旨在解决这一问题。", "method": "PixSearch在编码过程中发射<search>令牌以触发检索，并选择查询模式（文本、图像或区域），同时生成像素级掩码作为视觉查询，从而消除了对模块化管道的依赖。通过两阶段监督微调计划并采用搜索插件式监督来教授检索时间和查询选择。", "result": "在第一人称和实体中心VQA基准上，PixSearch显著提高了事实一致性和泛化能力，在CRAG-MM上的准确度相对提升了19.7%，与整个图像检索相比，并且保持了各种VQA和仅文本QA任务中的推理性能的竞争性。", "conclusion": "本文提出了PixSearch模型以解决多模态模型在处理视觉问答问题时的事实基础不足的问题，通过像素级检索增强了模型的感知能力和事实一致性。"}}
{"id": "2601.19059", "pdf": "https://arxiv.org/pdf/2601.19059", "abs": "https://arxiv.org/abs/2601.19059", "authors": ["Ryan LaRose", "Alan Bidart", "Ben DalFavero", "Sophia E. Economou", "J. Wayne Mullinax", "Mafalda Ramôa", "Jeremiah Rowland", "Brenda Rubenstein", "Nicolas PD Sawaya", "Prateek Vaish", "Grant M. Rotskoff", "Norm M. Tubman"], "title": "The cost of quantum algorithms for biochemistry: A case study in metaphosphate hydrolysis", "categories": ["quant-ph", "cs.ET"], "comment": null, "summary": "We evaluate the quantum resource requirements for ATP/metaphosphate hydrolysis, one of the most important reactions in all of biology with implications for metabolism, cellular signaling, and cancer therapeutics. In particular, we consider three algorithms for solving the ground state energy estimation problem: the variational quantum eigensolver, quantum Krylov, and quantum phase estimation. By utilizing exact classical simulation, numerical estimation, and analytical bounds, we provide a current and future outlook for using quantum computers to solve impactful biochemical and biological problems. Our results show that variational methods, while being the most heuristic, still require substantially fewer overall resources on quantum hardware, and could feasibly address such problems on current or near-future devices. We include our complete dataset of biomolecular Hamiltonians and code as benchmarks to improve upon with future techniques.", "AI": {"tldr": "评估量子算法在生物化学中的成本，特别是ATP/次磷酸盐水解反应的资源需求", "motivation": "研究量子计算机解决重要生物学问题如代谢、细胞信号传导和癌症治疗潜力的能力。重点关注三种求解基态能量估计问题的方法：变分量子特征值求解器、量子克里洛夫方法和量子相位估计算法。", "method": "使用精确的经典仿真，数值估算以及分析界来评估三种算法的资源需求，并通过生物分子哈密顿量数据集作为基准测试未来技术的发展。", "result": "结果显示尽管变分方法是最具启发性的，但仍需要相对较少的整体资源在量子硬件上运行，并有可能在未来设备上解决这些问题。", "conclusion": "提供了当前和未来的使用量子计算机来处理重要生化问题的前景。"}}
{"id": "2601.19055", "pdf": "https://arxiv.org/pdf/2601.19055", "abs": "https://arxiv.org/abs/2601.19055", "authors": ["Dipendra Misra", "Aldo Pacchiano", "Ta-Chung Chi", "Ge Gao"], "title": "Principled Fine-tuning of LLMs from User-Edits: A Medley of Preference, Supervision, and Reward", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": "Accepted at NeurIPS 2025", "summary": "We study how to fine-tune LLMs using user-edit deployment data consisting of a set of context, an agent's response, and user edits. This deployment data is naturally generated by users in applications such as LLMs-based writing assistants and coding agents. The _natural_ origin of user edits makes it a desired source for adapting and personalizing LLMs. In this setup, there emerges a unification of various feedback types namely preferences, supervised labels, and cost that are typically studied separately in the literature. In this paper, we initiate the theoretical investigation of learning from user edits. We first derive bounds for learning algorithms that learn from each of these feedback types. We prove that these algorithms have different trade-offs depending upon the user, data distribution, and model class. We then propose a simple ensembling procedure to jointly learn from these feedback types. On two domains adapted from Gao et al. 2024, we show our ensembling procedure outperforms these methods that learn from individual feedback. Further, we show that our proposed procedure can robustly adapt to different user-edit distributions at test time.", "AI": {"tldr": "论文研究了如何使用用户编辑数据对LLM进行微调，并提出了一种统一处理不同类型反馈的集成学习方法。", "motivation": "通过利用用户的自然生成反馈，可以更好地适应和个性化LLM。现有的工作通常分别研究各种类型的反馈，而本论文尝试将这些反馈类型结合起来。", "method": "首先推导出从不同反馈类型中学习的算法界限，然后提出了一种简单的集成学习方法来联合使用这几种反馈。", "result": "在两个领域上的实验表明，该集成学习方法优于单独使用某一种反馈的方法，并且能够适应不同的用户编辑分布。", "conclusion": "本研究证明了从用户编辑中统一学习不同类型的反馈的有效性，并展示了其在实际应用中的潜力。"}}
{"id": "2601.19053", "pdf": "https://arxiv.org/pdf/2601.19053", "abs": "https://arxiv.org/abs/2601.19053", "authors": ["Yongsu Ahn", "Lejun R Liao", "Benjamin Bach", "Nam Wook Kim"], "title": "From Answer Givers to Design Mentors: Guiding LLMs with the Cognitive Apprenticeship Model", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Design feedback helps practitioners improve their artifacts while also fostering reflection and design reasoning. Large Language Models (LLMs) such as ChatGPT can support design work, but often provide generic, one-off suggestions that limit reflective engagement. We investigate how to guide LLMs to act as design mentors by applying the Cognitive Apprenticeship Model, which emphasizes demonstrating reasoning through six methods: modeling, coaching, scaffolding, articulation, reflection, and exploration. We operationalize these instructional methods through structured prompting and evaluate them in a within-subjects study with data visualization practitioners. Participants interacted with both a baseline LLM and an instructional LLM designed with cognitive apprenticeship prompts. Surveys, interviews, and conversational log analyses compared experiences across conditions. Our findings show that cognitively informed prompts elicit deeper design reasoning and more reflective feedback exchanges, though the baseline is sometimes preferred depending on task types or experience levels. We distill design considerations for AI-assisted feedback systems that foster reflective practice.", "AI": {"tldr": "研究通过认知学徒模型指导大型语言模型成为设计导师，以提供更深层次的设计反馈。", "motivation": "现有的大型语言模型提供的建议较为泛化且单一，难以促进反思性互动。该研究旨在通过应用认知学徒模型来改进这一状况。", "method": "研究采用了六种方法：示范、辅导、支架、表达、反思和探索，并将这些教学策略通过结构化的提示进行操作化。在数据可视化从业人员中进行了一个被试内设计的研究，参与者与基础的大型语言模型及采用认知学徒模型指导的模型互动。", "result": "研究发现，基于认知的提示能够引发更深层次的设计推理并促进反思性反馈交流，尽管根据任务类型或经验水平的不同，有时基线模型仍然是首选。", "conclusion": "该研究表明通过认知学徒模型对大型语言模型进行引导可以有效提升设计反馈的质量，并提出了用于支持AI辅助反馈系统的反射实践的设计考虑因素。"}}
{"id": "2601.19048", "pdf": "https://arxiv.org/pdf/2601.19048", "abs": "https://arxiv.org/abs/2601.19048", "authors": ["Han-Hung Lee", "Cheng-Yu Yang", "Yu-Lun Liu", "Angel X. Chang"], "title": "NuiWorld: Exploring a Scalable Framework for End-to-End Controllable World Generation", "categories": ["cs.CV"], "comment": null, "summary": "World generation is a fundamental capability for applications like video games, simulation, and robotics. However, existing approaches face three main obstacles: controllability, scalability, and efficiency. End-to-end scene generation models have been limited by data scarcity. While object-centric generation approaches rely on fixed resolution representations, degrading fidelity for larger scenes. Training-free approaches, while flexible, are often slow and computationally expensive at inference time. We present NuiWorld, a framework that attempts to address these challenges. To overcome data scarcity, we propose a generative bootstrapping strategy that starts from a few input images. Leveraging recent 3D reconstruction and expandable scene generation techniques, we synthesize scenes of varying sizes and layouts, producing enough data to train an end-to-end model. Furthermore, our framework enables controllability through pseudo sketch labels, and demonstrates a degree of generalization to previously unseen sketches. Our approach represents scenes as a collection of variable scene chunks, which are compressed into a flattened vector-set representation. This significantly reduces the token length for large scenes, enabling consistent geometric fidelity across scenes sizes while improving training and inference efficiency.", "AI": {"tldr": "NuiWorld框架旨在解决场景生成中的可控性、可扩展性和效率问题。", "motivation": "现有方法在数据稀缺、固定分辨率表示和训练自由方式的慢速与高计算成本方面存在挑战。", "method": "提出了一种从少量输入图像开始的生成式引导策略，结合3D重建技术和场景合成技术来生成各种大小和布局的场景。采用伪草图标签实现可控性，并将场景表示为可变场景块集合，压缩成扁平化向量集表示。", "result": "该方法能够在保持几何一致性的前提下提高大场景的数据训练效率和推断效率。", "conclusion": "NuiWorld框架成功地解决了现有世界生成模型在数据稀缺性、分辨率固定性和计算成本高的问题，为大规模可控的世界生成提供了一种有效的解决方案。"}}
{"id": "2601.19042", "pdf": "https://arxiv.org/pdf/2601.19042", "abs": "https://arxiv.org/abs/2601.19042", "authors": ["Ines Vati", "Pierrick Bourgeat", "Rodrigo Santa Cruz", "Vincent Dore", "Olivier Salvado", "Clinton Fookes", "Léo Lebrat"], "title": "NC-Reg : Neural Cortical Maps for Rigid Registration", "categories": ["cs.CV"], "comment": "ISBI 2026", "summary": "We introduce neural cortical maps, a continuous and compact neural representation for cortical feature maps, as an alternative to traditional discrete structures such as grids and meshes. It can learn from meshes of arbitrary size and provide learnt features at any resolution. Neural cortical maps enable efficient optimization on the sphere and achieve runtimes up to 30 times faster than classic barycentric interpolation (for the same number of iterations). As a proof of concept, we investigate rigid registration of cortical surfaces and propose NC-Reg, a novel iterative algorithm that involves the use of neural cortical feature maps, gradient descent optimization and a simulated annealing strategy. Through ablation studies and subject-to-template experiments, our method demonstrates sub-degree accuracy ($<1^\\circ$ from the global optimum), and serves as a promising robust pre-alignment strategy, which is critical in clinical settings.", "AI": {"tldr": "本文提出了神经皮层图谱，一种用于刚性配准的连续且紧凑的神经表示方法。", "motivation": "传统的离散结构如网格和网格无法适应任意大小的网格，并且计算效率较低。为此，作者提出了一种新的方法来提高刚性注册的速度和准确性。", "method": "该研究引入了神经皮层图谱作为传统离散结构的替代方案，通过使用连续和紧凑的神经表示学习任何分辨率下的特征，实现了高效的球面优化，并提出了一个迭代算法NC-Reg，结合了神经皮层特征地图、梯度下降优化和模拟退火策略。", "result": "通过消融研究和主体到模板实验，该方法展示了亚一度的准确性（距离全局最优小于1度），并且表现出了强大的预对齐策略。", "conclusion": "神经皮层图谱在刚性配准中表现出色，并且提供了一种新的高效、准确的解决方案。"}}
{"id": "2601.19041", "pdf": "https://arxiv.org/pdf/2601.19041", "abs": "https://arxiv.org/abs/2601.19041", "authors": ["Bo-Cheng Lin", "Yi Mei", "Mengjie Zhang"], "title": "HEATACO: Heatmap-Guided Ant Colony Decoding for Large-Scale Travelling Salesman Problems", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Heatmap-based non-autoregressive solvers for large-scale Travelling Salesman Problems output dense edge-probability scores, yet final performance largely hinges on the decoder that must satisfy degree-2 constraints and form a single Hamiltonian tour. Greedy commitment can cascade into irreparable mistakes at large $N$, whereas MCTS-guided local search is accurate but compute-heavy and highly engineered. We instead treat the heatmap as a soft edge prior and cast decoding as probabilistic tour construction under feasibility constraints, where the key is to correct local mis-rankings via inexpensive global coordination. Based on this view, we introduce HeatACO, a plug-and-play Max-Min Ant System decoder whose transition policy is softly biased by the heatmap while pheromone updates provide lightweight, instance-specific feedback to resolve global conflicts; optional 2-opt/3-opt post-processing further improves tour quality. On TSP500/1K/10K, using heatmaps produced by four pretrained predictors, HeatACO+2opt achieves gaps down to 0.11%/0.23%/1.15% with seconds-to-minutes CPU decoding for fixed heatmaps, offering a better quality--time trade-off than greedy decoding and published MCTS-based decoders. Finally, we find the gains track heatmap reliability: under distribution shift, miscalibration and confidence collapse bound decoding improvements, suggesting heatmap generalisation is a primary lever for further progress.", "AI": {"tldr": "提出了一种基于热图的解码器HeatACO，用于解决大规模旅行商问题（TSP），该方法结合了蚂蚁系统和热图信息。", "motivation": "现有解码方法在大规模TSP中存在效率低或准确性不足的问题。因此需要开发一种既能保证准确度又能快速解码的方法来提高性能。", "method": "HeatACO利用热图指导的蚂蚁系统进行概率性路径构建，通过轻量级反馈机制解决全局冲突，并结合2-opt/3-opt优化以进一步改善路径质量。", "result": "实验表明，在TSP500/1K/10K规模上，HeatACO+2opt在固定热图下解码性能达到0.11%/0.23%/1.15%，相比贪婪算法和已发布的MCTS方法有更好的时间质量权衡。", "conclusion": "研究证明了热图的可靠性和泛化能力对提高TSP解码效果至关重要，未来提升的关键在于进一步改进热图预测模型。"}}
{"id": "2601.19030", "pdf": "https://arxiv.org/pdf/2601.19030", "abs": "https://arxiv.org/abs/2601.19030", "authors": ["Philip Amortila", "Audrey Huang", "Akshay Krishnamurthy", "Nan Jiang"], "title": "A Unifying View of Coverage in Linear Off-Policy Evaluation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "To appear at ICLR 2026", "summary": "Off-policy evaluation (OPE) is a fundamental task in reinforcement learning (RL). In the classic setting of linear OPE, finite-sample guarantees often take the form $$ \\textrm{Evaluation error} \\le \\textrm{poly}(C^π, d, 1/n,\\log(1/δ)), $$ where $d$ is the dimension of the features and $C^π$ is a coverage parameter that characterizes the degree to which the visited features lie in the span of the data distribution. While such guarantees are well-understood for several popular algorithms under stronger assumptions (e.g. Bellman completeness), the understanding is lacking and fragmented in the minimal setting where only the target value function is linearly realizable in the features. Despite recent interest in tight characterizations of the statistical rate in this setting, the right notion of coverage remains unclear, and candidate definitions from prior analyses have undesirable properties and are starkly disconnected from more standard definitions in the literature. We provide a novel finite-sample analysis of a canonical algorithm for this setting, LSTDQ. Inspired by an instrumental-variable view, we develop error bounds that depend on a novel coverage parameter, the feature-dynamics coverage, which can be interpreted as linear coverage in an induced dynamical system for feature evolution. With further assumptions -- such as Bellman-completeness -- our definition successfully recovers the coverage parameters specialized to those settings, finally yielding a unified understanding for coverage in linear OPE.", "AI": {"tldr": "本文提供了一个线性OPE中LSTDQ算法的新型有限样本分析，引入了特征动力学覆盖参数以统一理解线性OPE中的覆盖率问题。", "motivation": "在仅目标价值函数在线性可实现的情况下，现有覆盖率定义存在不足且与标准文献脱节。作者希望通过新的覆盖率参数来解决这一问题并提供统一的理解。", "method": "通过将LSTDQ算法从一种仪器变量的角度重新解释，并引入特征动力学覆盖作为新误差界限的依赖项。", "result": "提出了一个基于特征动力学覆盖的新有限样本分析，该定义在Bellman完备性等假设下可以恢复到特定情况下的覆盖率参数。", "conclusion": "通过本文的研究，成功地在最简单的线性OPE设置中统一了对覆盖率的理解，并为后续研究提供了新的视角和工具。"}}
{"id": "2601.19029", "pdf": "https://arxiv.org/pdf/2601.19029", "abs": "https://arxiv.org/abs/2601.19029", "authors": ["Jai Dhiman"], "title": "Audio Foundation Models Outperform Symbolic Representations for Piano Performance Evaluation", "categories": ["cs.SD", "eess.AS"], "comment": "6 pages, 4 figures, 2 tables. Code available at https://github.com/Jai-Dhiman/crescendai", "summary": "Automated piano performance evaluation traditionally relies on symbolic (MIDI) representations, which capture note-level information but miss the acoustic nuances that characterize expressive playing. I propose using pre-trained audio foundation models, specifically MuQ and MERT, to predict 19 perceptual dimensions of piano performance quality. Using synthesized audio from PercePiano MIDI files (rendered via Pianoteq), I compare audio and symbolic approaches under controlled conditions where both derive from identical source data. The best model, MuQ layers 9-12 with Pianoteq soundfont augmentation, achieves R^2 = 0.537 (95% CI: [0.465, 0.575]), representing a 55% improvement over the symbolic baseline (R^2 = 0.347). Statistical analysis confirms significance (p < 10^-25) with audio outperforming symbolic on all 19 dimensions. I validate the approach through cross-soundfont generalization (R^2 = 0.534 +/- 0.075), difficulty correlation with an external dataset (rho = 0.623), and multi-performer consistency analysis. Analysis of audio-symbolic fusion reveals high error correlation (r = 0.738), explaining why fusion provides minimal benefit: audio representations alone are sufficient. I release the complete training pipeline, pretrained models, and inference code.", "AI": {"tldr": "论文提出使用预训练的音频基础模型评估钢琴演奏质量，优于传统的符号表示方法。", "motivation": "传统上，自动钢琴表演评价依赖于仅捕获音符级别信息但忽略声音细节的符号（MIDI）表示。该研究旨在通过音频基础模型捕捉更多的演奏表现特征。", "method": "使用MuQ和MERT两个预训练音频基础模型预测19个感知维度，并与传统的基于MIDI的方法进行对比，分析其性能差异。", "result": "最佳模型MuQ层9-12在钢琴声部增强后达到R^2 = 0.537（95%置信区间：[0.465, 0.575]），相较于符号基线方法R^2 = 0.347，提升了55%，并在所有维度上显著优于MIDI。", "conclusion": "音频表示在钢琴演奏评估中表现出色，并且无需融合音视频信息也能取得满意的结果。研究结果表明，基于音频的方法足以替代传统的符号表示方法进行钢琴表演评价。"}}
{"id": "2601.19022", "pdf": "https://arxiv.org/pdf/2601.19022", "abs": "https://arxiv.org/abs/2601.19022", "authors": ["Antanas Zilinskas", "Robert N. Shorten", "Jakub Marecek"], "title": "EVEREST: An Evidential, Tail-Aware Transformer for Rare-Event Time-Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "ef:14th International Conference on Learning Representations, 2026", "summary": "Forecasting rare events in multivariate time-series data is challenging due to severe class imbalance, long-range dependencies, and distributional uncertainty. We introduce EVEREST, a transformer-based architecture for probabilistic rare-event forecasting that delivers calibrated predictions and tail-aware risk estimation, with auxiliary interpretability via attention-based signal attribution. EVEREST integrates four components: (i) a learnable attention bottleneck for soft aggregation of temporal dynamics; (ii) an evidential head for estimating aleatoric and epistemic uncertainty via a Normal--Inverse--Gamma distribution; (iii) an extreme-value head that models tail risk using a Generalized Pareto Distribution; and (iv) a lightweight precursor head for early-event detection. These modules are jointly optimized with a composite loss (focal loss, evidential NLL, and a tail-sensitive EVT penalty) and act only at training time; deployment uses a single classification head with no inference overhead (approximately 0.81M parameters). On a decade of space-weather data, EVEREST achieves state-of-the-art True Skill Statistic (TSS) of 0.973/0.970/0.966 at 24/48/72-hour horizons for C-class flares. The model is compact, efficient to train on commodity hardware, and applicable to high-stakes domains such as industrial monitoring, weather, and satellite diagnostics. Limitations include reliance on fixed-length inputs and exclusion of image-based modalities, motivating future extensions to streaming and multimodal forecasting.", "AI": {"tldr": "EVEREST是一种基于Transformer的架构，用于罕见事件时间序列预测。它通过集成可学习注意力瓶颈、证据头部和极端值头部来估计不确定性并检测早期事件。", "motivation": "稀有事件的时间序列预测由于严重的类别不平衡、长时间依赖关系以及分布不确定性的挑战而困难。EVEREST旨在解决这些问题，并提供校准的预测、尾部风险评估及信号归因。", "method": "EVEREST采用了可学习注意力瓶颈、证据头部和极端值头部，共同优化了组合损失函数（包含焦点损失、证据NLL和尾部敏感EVT惩罚）。部署时采用单一分类头部进行预测，无额外推理开销。", "result": "在空间天气数据上测试，EVEREST实现了0.973/0.970/0.966的TSS（24/48/72小时预报），对于C级耀斑达到了最先进的性能水平。模型简洁高效，在普通硬件上训练也十分方便。", "conclusion": "尽管依赖固定长度输入且未包括基于图像的模式，EVEREST仍适用于工业监控、天气预报和卫星诊断等高风险领域，并为未来流式及多模态预测提供了扩展潜力。"}}
{"id": "2601.19021", "pdf": "https://arxiv.org/pdf/2601.19021", "abs": "https://arxiv.org/abs/2601.19021", "authors": ["Joy Lai", "Kelly Beaton", "David Black", "Alex Mihailidis"], "title": "Listening before Asking: Lived-Experience Advisors as Methodological Partners in Dementia Caregiving Studies", "categories": ["cs.HC"], "comment": null, "summary": "Research with dementia caregivers poses persistent methodological and ethical challenges, particularly when interview-based studies are designed without sufficient grounding in lived caregiving realities. Questions framed through clinical or deficit-oriented assumptions risk alienating participants, undermining rapport, and producing shallow or ethically fraught data. While human-computer interaction (HCI) research increasingly adopts participatory approaches in technology design, participation rarely extends to the design of research methods themselves. This paper examines the role of lived-experience advisors as methodological partners in caregiver interview research. We report on a qualitative study in which two advisors with extensive dementia caregiving experience were engaged prior to fieldwork as methodological partners, extending participatory principles beyond technology design into the design of research methods themselves. Drawing on transcripts of advisor consultations and subsequent interviews with ten caregivers and one person living with dementia, we identify two key methodological contributions of advisor involvement. First, advisors enabled anticipatory validity by surfacing caregiving challenges, ethical sensitivities, and interpretive concerns that later appeared in caregiver interviews, allowing the researcher to enter the field with grounded awareness under constrained recruitment and fieldwork conditions. Second, advisors provided cultural, emotional, and systemic context that improved interpretive sensitivity and helped avoid misreadings. We argue that lived experience functions as methodological infrastructure, extending participatory principles into the design and conduct of research itself, and constituting a generalizable methodological pattern for HCI research with caregivers and other vulnerable or marginalized populations.", "AI": {"tldr": "探讨了在痴呆症照护者访谈研究中，生活经验顾问作为方法学伙伴的作用。", "motivation": "旨在解决与痴呆症照护者的访谈研究中存在的持续性方法论和伦理挑战。通过前期咨询生活经验丰富者参与设计研究方法，避免因临床或缺陷导向假设而产生的问题。", "method": "在一项定性的研究中，两位具有丰富痴呆症照护经验的顾问作为方法学伙伴，在实地工作之前被提前招募进来，帮助改进访谈研究的方法论。该研究通过转录顾问咨询和后续与十位照护者以及一位痴呆症患者的访谈来识别顾问参与的关键方法贡献。", "result": "顾问使研究团队能够预先了解照护挑战、伦理敏感性和解释性关切，并提供了文化、情感和社会系统背景，提高了理解的准确性。这些发现表明生活经验可以作为研究的设计和执行的方法论基础。", "conclusion": "该研究表明，在痴呆症照护者和其他脆弱或边缘化群体的研究中，引入生活经历顾问参与研究方法设计是一个可推广的方法学模式。"}}
{"id": "2601.19017", "pdf": "https://arxiv.org/pdf/2601.19017", "abs": "https://arxiv.org/abs/2601.19017", "authors": ["Alexander Buck", "Georgina Cosma", "Iain Phillips", "Paul Conway", "Patrick Baker"], "title": "A Framework for Evaluating Faithfulness in Explainable AI for Machine Anomalous Sound Detection Using Frequency-Band Perturbation", "categories": ["cs.SD", "cs.LG"], "comment": "16 pages, 24 figures", "summary": "Explainable AI (XAI) is commonly applied to anomalous sound detection (ASD) models to identify which time-frequency regions of an audio signal contribute to an anomaly decision. However, most audio explanations rely on qualitative inspection of saliency maps, leaving open the question of whether these attributions accurately reflect the spectral cues the model uses. In this work, we introduce a new quantitative framework for evaluating XAI faithfulness in machine-sound analysis by directly linking attribution relevance to model behaviour through systematic frequency-band removal. This approach provides an objective measure of whether an XAI method for machine ASD correctly identifies frequency regions that influence an ASD model's predictions. By using four widely adopted methods, namely Integrated Gradients, Occlusion, Grad-CAM and SmoothGrad, we show that XAI techniques differ in reliability, with Occlusion demonstrating the strongest alignment with true model sensitivity and gradient-+based methods often failing to accurately capture spectral dependencies. The proposed framework offers a reproducible way to benchmark audio explanations and enables more trustworthy interpretation of spectrogram-based ASD systems.", "AI": {"tldr": "提出了一种评估音频异常声音检测中XAI忠实性的定量框架。", "motivation": "当前的大多数音频解释依赖于对热图的定性检查，无法客观验证这些归因是否准确反映模型使用的频谱线索。", "method": "通过频率带去除系统地连接属性的相关性和模型行为，并利用四种广泛采用的方法：集成梯度、遮挡、Grad-CAM和SmoothGrad进行评估。", "result": "结果显示，XAI技术在可靠性上存在差异，其中遮挡方法表现出最强的与真实模型敏感性的对齐性，而基于梯度的方法往往未能准确捕捉频谱依赖性。", "conclusion": "提出的框架为音频解释提供了可重复的方式，并使基于光谱图的异常声音检测系统的可信解释成为可能。"}}
{"id": "2601.19014", "pdf": "https://arxiv.org/pdf/2601.19014", "abs": "https://arxiv.org/abs/2601.19014", "authors": ["Lena Harkämper", "Leo Lebrat", "David Ahmedt-Aristizabal", "Olivier Salvado", "Mattias Heinrich", "Rodrigo Santa Cruz"], "title": "Non-Invasive 3D Wound Measurement with RGB-D Imaging", "categories": ["cs.CV"], "comment": null, "summary": "Chronic wound monitoring and management require accurate and efficient wound measurement methods. This paper presents a fast, non-invasive 3D wound measurement algorithm based on RGB-D imaging. The method combines RGB-D odometry with B-spline surface reconstruction to generate detailed 3D wound meshes, enabling automatic computation of clinically relevant wound measurements such as perimeter, surface area, and dimensions. We evaluated our system on realistic silicone wound phantoms and measured sub-millimetre 3D reconstruction accuracy compared with high-resolution ground-truth scans. The extracted measurements demonstrated low variability across repeated captures and strong agreement with manual assessments. The proposed pipeline also outperformed a state-of-the-art object-centric RGB-D reconstruction method while maintaining runtimes suitable for real-time clinical deployment. Our approach offers a promising tool for automated wound assessment in both clinical and remote healthcare settings.", "AI": {"tldr": "本文提出了一种基于RGB-D成像的快速、非侵入性三维伤口测量算法。", "motivation": "慢性伤口监测和管理需要准确高效的伤口测量方法，该论文旨在提供一种适用于临床及远程医疗环境下的自动伤口评估工具。", "method": "结合RGB-D测距与B样条表面重建技术生成详细的3D伤口模型，并实现周长、表面积等临床相关测量的自动化计算。", "result": "在硅胶模拟伤口样本上的测试显示，该系统能够以亚毫米级精度完成三维重构，并且多次捕获间的变异性低且与手动评估高度一致。此外，所提方法还超过了当前最先进的RGB-D重建技术，在保持实时临床部署所需的运行时间下。", "conclusion": "本文提出的方法为自动化伤口评估提供了一种有前途的工具，适用于临床和远程医疗环境中的应用。"}}
{"id": "2601.19001", "pdf": "https://arxiv.org/pdf/2601.19001", "abs": "https://arxiv.org/abs/2601.19001", "authors": ["Haozheng Luo", "Zhuolin Jiang", "Md Zahid Hasan", "Yan Chen", "Soumalya Sarkar"], "title": "FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose FROST, an attention-aware method for efficient reasoning. Unlike traditional approaches, FROST leverages attention weights to prune uncritical reasoning paths, yielding shorter and more reliable reasoning trajectories. Methodologically, we introduce the concept of reasoning outliers and design an attention-based mechanism to remove them. Theoretically, FROST preserves and enhances the model's reasoning capacity while eliminating outliers at the sentence level. Empirically, we validate FROST on four benchmarks using two strong reasoning models (Phi-4-Reasoning and GPT-OSS-20B), outperforming state-of-the-art methods such as TALE and ThinkLess. Notably, FROST achieves an average 69.68% reduction in token usage and a 26.70% improvement in accuracy over the base model. Furthermore, in evaluations of attention outlier metrics, FROST reduces the maximum infinity norm by 15.97% and the average kurtosis by 91.09% compared to the base model. Code is available at https://github.com/robinzixuan/FROST", "AI": {"tldr": "提出FROST方法，利用注意力权重过滤推理异常路径，提高推理效率。", "motivation": "通过去除不关键的推理路径来提升模型的有效性和可靠性。", "method": "引入推理异常的概念，并设计基于注意机制的方法以移除这些异常。", "result": "在四个基准测试上优于现有方法，平均减少69.68%的令牌使用量并提高26.70%准确率。", "conclusion": "FROST不仅提高了模型效率和准确性，还改善了注意力异常指标。"}}
{"id": "2601.18999", "pdf": "https://arxiv.org/pdf/2601.18999", "abs": "https://arxiv.org/abs/2601.18999", "authors": ["Fangzhou Wu", "Sandeep Silwal", "Qiuyi", "Zhang"], "title": "Randomization Boosts KV Caching, Learning Balances Query Load: A Joint Perspective", "categories": ["cs.LG", "cs.AI"], "comment": "ICLR 2026", "summary": "KV caching is a fundamental technique for accelerating Large Language Model (LLM) inference by reusing key-value (KV) pairs from previous queries, but its effectiveness under limited memory is highly sensitive to the eviction policy. The default Least Recently Used (LRU) eviction algorithm struggles with dynamic online query arrivals, especially in multi-LLM serving scenarios, where balancing query load across workers and maximizing cache hit rate of each worker are inherently conflicting objectives. We give the first unified mathematical model that captures the core trade-offs between KV cache eviction and query routing. Our analysis reveals the theoretical limitations of existing methods and leads to principled algorithms that integrate provably competitive randomized KV cache eviction with learning-based methods to adaptively route queries with evolving patterns, thus balancing query load and cache hit rate. Our theoretical results are validated by extensive experiments across 4 benchmarks and 3 prefix-sharing settings, demonstrating improvements of up to 6.92$\\times$ in cache hit rate, 11.96$\\times$ reduction in latency, 14.06$\\times$ reduction in time-to-first-token (TTFT), and 77.4% increase in throughput over the state-of-the-art methods. Our code is available at https://github.com/fzwark/KVRouting.", "AI": {"tldr": "本文提出了一种随机化KV缓存淘汰策略与学习方法结合的算法，以解决多LLM服务场景下的查询负载均衡和缓存命中率冲突问题。", "motivation": "在多LLM服务场景中，LRU缓存淘汰策略难以平衡各工人的查询负载和提高缓存命中率。本文旨在通过理论分析与实验验证提出一种新的解决方案。", "method": "作者建立了统一的数学模型来捕捉KV缓存淘汰和查询路由的核心权衡，并提出了将随机化KV缓存淘汰与学习方法结合的新算法，以实现动态适应查询模式的变化，从而平衡查询负载并提高缓存命中率。", "result": "实验结果表明，在不同基准测试和前缀共享设置下，该方法相比现有最佳方案提高了高达6.92倍的缓存命中率、减少了11.96倍的延迟时间以及增加了77.4％的吞吐量。", "conclusion": "本文通过理论分析与实验验证了新算法的有效性，并展示了它在解决多LLM服务场景下的查询负载均衡和提高缓存命中率方面的重要作用。"}}
{"id": "2601.18997", "pdf": "https://arxiv.org/pdf/2601.18997", "abs": "https://arxiv.org/abs/2601.18997", "authors": ["Mélanie Gaillochet", "Christian Desrosiers", "Hervé Lombaert"], "title": "Anatomically-aware conformal prediction for medical image segmentation with random walks", "categories": ["cs.CV", "cs.LG"], "comment": "13 pages", "summary": "The reliable deployment of deep learning in medical imaging requires uncertainty quantification that provides rigorous error guarantees while remaining anatomically meaningful. Conformal prediction (CP) is a powerful distribution-free framework for constructing statistically valid prediction intervals. However, standard applications in segmentation often ignore anatomical context, resulting in fragmented, spatially incoherent, and over-segmented prediction sets that limit clinical utility. To bridge this gap, this paper proposes Random-Walk Conformal Prediction (RW-CP), a model-agnostic framework which can be added on top of any segmentation method. RW-CP enforces spatial coherence to generate anatomically valid sets. Our method constructs a k-nearest neighbour graph from pre-trained vision foundation model features and applies a random walk to diffuse uncertainty. The random walk diffusion regularizes the non-conformity scores, making the prediction sets less sensitive to the conformal calibration parameter $λ$, ensuring more stable and continuous anatomical boundaries. RW-CP maintains rigorous marginal coverage while significantly improving segmentation quality. Evaluations on multi-modal public datasets show improvements of up to $35.4\\%$ compared to standard CP baselines, given an allowable error rate of $α=0.1$.", "AI": {"tldr": "本论文提出了一种新的方法Random-Walk Conformal Prediction (RW-CP)，以提高医学图像分割中的不确定性量化，并保持解剖学上的连贯性。", "motivation": "在医学成像中，深度学习的可靠部署需要提供严格的错误保证并保持解剖学意义的不确定性量化。现有的方法往往忽略了解剖学背景，导致预测集不连贯和过度分割。", "method": "RW-CP是一个模型无关框架，通过构建k近邻图并应用随机行走来扩散不确定性，从而生成解剖学上有效的预测集。这种方法可以添加到任何分割算法之上，并使预测集合更稳定且连续的解剖边界。", "result": "在多模态公开数据集上的评估表明，RW-CP相比标准CP基准提高了多达35.4％。", "conclusion": "RW-CP不仅保持了严格的边际覆盖率，而且显著改善了分割质量。"}}
{"id": "2601.18993", "pdf": "https://arxiv.org/pdf/2601.18993", "abs": "https://arxiv.org/abs/2601.18993", "authors": ["Wei Cao", "Hao Zhang", "Fengrui Tian", "Yulun Wu", "Yingying Li", "Shenlong Wang", "Ning Yu", "Yaoyao Liu"], "title": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": "14 pages, 10 figures", "summary": "Camera redirection aims to replay a dynamic scene from a single monocular video under a user-specified camera trajectory. However, large-angle redirection is inherently ill-posed: a monocular video captures only a narrow spatio-temporal view of a dynamic 3D scene, providing highly partial observations of the underlying 4D world. The key challenge is therefore to recover a complete and coherent representation from this limited input, with consistent geometry and motion. While recent diffusion-based methods achieve impressive results, they often break down under large-angle viewpoint changes far from the original trajectory, where missing visual grounding leads to severe geometric ambiguity and temporal inconsistency. To address this, we present FreeOrbit4D, an effective training-free framework that tackles this geometric ambiguity by recovering a geometry-complete 4D proxy as structural grounding for video generation. We obtain this proxy by decoupling foreground and background reconstructions: we unproject the monocular video into a static background and geometry-incomplete foreground point clouds in a unified global space, then leverage an object-centric multi-view diffusion model to synthesize multi-view images and reconstruct geometry-complete foreground point clouds in canonical object space. By aligning the canonical foreground point cloud to the global scene space via dense pixel-synchronized 3D--3D correspondences and projecting the geometry-complete 4D proxy onto target camera viewpoints, we provide geometric scaffolds that guide a conditional video diffusion model. Extensive experiments show that FreeOrbit4D produces more faithful redirected videos under challenging large-angle trajectories, and our geometry-complete 4D proxy further opens a potential avenue for practical applications such as edit propagation and 4D data generation. Project page and code will be released soon.", "AI": {"tldr": "本文提出了一种名为FreeOrbit4D的框架，用于从单个单目视频中自由地进行任意角度的相机重定向。", "motivation": "在大型视角变化下，现有的扩散模型方法经常失效。由于缺乏视觉定位，会出现严重的几何模糊和时间不一致性问题。因此需要一种新的方法来解决这个问题。", "method": "FreeOrbit4D通过解耦前景与背景重建获取了一个结构化的4D代理作为视频生成的依据，并利用多视角图像合成技术恢复完整的几何形状。", "result": "实验结果表明，FreeOrbit4D在大角度轨迹下可以生成更真实的重定向视频。", "conclusion": "提出的几何完整4D代理不仅改善了大型角度转换下的视觉质量，还为编辑传播和4D数据生成等实用应用开辟了新的可能性。"}}
{"id": "2601.18987", "pdf": "https://arxiv.org/pdf/2601.18987", "abs": "https://arxiv.org/abs/2601.18987", "authors": ["Oren Sultan", "Jordi Armengol-Estape", "Pascal Kesseli", "Julien Vanegue", "Dafna Shahaf", "Yossi Adi", "Peter O'Hearn"], "title": "LLMs versus the Halting Problem: Revisiting Program Termination Prediction", "categories": ["cs.CL", "cs.AI", "cs.PL"], "comment": null, "summary": "Determining whether a program terminates is a central problem in computer science. Turing's foundational result established the Halting Problem as undecidable, showing that no algorithm can universally determine termination for all programs and inputs. Consequently, automatic verification tools approximate termination, sometimes failing to prove or disprove; these tools rely on problem-specific architectures and abstractions, and are usually tied to particular programming languages. Recent success and progress in large language models (LLMs) raises the following question: can LLMs reliably predict program termination? In this work, we evaluate LLMs on a diverse set of C programs from the Termination category of the International Competition on Software Verification (SV-Comp) 2025. Our results suggest that LLMs perform remarkably well at predicting program termination, where GPT-5 and Claude Sonnet-4.5 would rank just behind the top-ranked tool (using test-time-scaling), and Code World Model (CWM) would place just behind the second-ranked tool. While LLMs are effective at predicting program termination, they often fail to provide a valid witness as a proof. Moreover, LLMs performance drops as program length increases. We hope these insights motivate further research into program termination and the broader potential of LLMs for reasoning about undecidable problems.", "AI": {"tldr": "评估大型语言模型在预测程序终止方面的表现。", "motivation": "探讨大型语言模型能否可靠地预测程序终止，推动关于不可判定问题的进一步研究。", "method": "使用SV-Comp2025竞赛中C语言程序的数据集来测试LLM的程序终止预测能力，并比较不同模型的表现。", "result": "发现GPT-5和Claude Sonnet-4.5在预测程序终止方面表现出色，但它们难以提供有效的证明；此外，随着程序长度增加，性能下降。", "conclusion": "大型语言模型对于程序终止预测具有一定的能力，但仍需进一步研究以提高其准确性和可靠性。"}}
{"id": "2601.18979", "pdf": "https://arxiv.org/pdf/2601.18979", "abs": "https://arxiv.org/abs/2601.18979", "authors": ["Supriya Khadka", "Sanchari Das"], "title": "XR Design Framework for Early Childhood Education", "categories": ["cs.HC", "cs.CY", "cs.ET"], "comment": "ef:In Proceedings of the 2026 IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)", "summary": "Extended Reality in early childhood education presents high-risk challenges due to children's rapid developmental changes. While augmented and virtual reality offer immersive pedagogical benefits, they often impose excessive cognitive load or sensory conflict. We introduce the Augmented Human Development (AHD) framework to model these interactions through cognitive, sensory, environmental, and developmental parameters. To ground this framework, we conducted a Systematization of Knowledge (SoK) of 111 peer-reviewed studies involving children aged 3 - 8. Our findings, interpreted through the AHD lens, reveal a critical \"risk vs. attention gap,\" where high-impact safety and security risks remain under-researched compared to short-term pedagogical gains.", "AI": {"tldr": "提出了一种用于早期儿童教育的扩展现实设计框架。", "motivation": "探讨在早期教育中使用增强和虚拟现实技术所面临的高风险挑战，尤其是认知负荷过大或感官冲突问题。", "method": "通过系统化知识方法（SoK）分析了111篇关于3-8岁儿童的研究论文，并提出了一种基于认知、感官、环境和发展参数的增强人类发展框架(AHD)。", "result": "发现了一个关键的风险与注意力差距，即在安全和风险方面研究不足，在短期教育收益方面却有较多关注。", "conclusion": "该研究揭示了早期儿童使用XR技术时存在的重大安全隐患，并强调未来需要更多地关注长期的安全性而非仅仅注重即时的教学效果。"}}
{"id": "2601.18975", "pdf": "https://arxiv.org/pdf/2601.18975", "abs": "https://arxiv.org/abs/2601.18975", "authors": ["DaeHo Lee", "Ryo Suzuki", "Jin-Hyuk Hong"], "title": "HumanoidTurk: Expanding VR Haptics with Humanoids for Driving Simulations", "categories": ["cs.HC", "cs.RO"], "comment": "14 pages, 7 figures. To appear in CHI 2026", "summary": "We explore how humanoid robots can be repurposed as haptic media, extending beyond their conventional role as social, assistive, collaborative agents. To illustrate this approach, we implemented HumanoidTurk, taking a first step toward a humanoid-based haptic system that translates in-game g-force signals into synchronized motion feedback in VR driving. A pilot study involving six participants compared two synthesis methods, leading us to adopt a filter-based approach for smoother and more realistic feedback. A subsequent study with sixteen participants evaluated four conditions: no-feedback, controller, humanoid+controller, and human+controller. Results showed that humanoid feedback enhanced immersion, realism, and enjoyment, while introducing moderate costs in terms of comfort and simulation sickness. Interviews further highlighted the robot's consistency and predictability in contrast to the adaptability of human feedback. From these findings, we identify fidelity, adaptability, and versatility as emerging themes, positioning humanoids as a distinct haptic modality for immersive VR.", "AI": {"tldr": "本文探讨了将人形机器人重新定义为触觉媒介，通过实施HumanoidTurk系统在VR驾驶模拟中测试其效果。", "motivation": "动机在于探索人形机器人作为新型触觉媒介的应用潜力，超越传统的社交、辅助和协作角色。", "method": "实验涉及两个阶段。第一阶段对比两种合成方法，最终选择滤波器基线方法；第二阶段评估四种条件下的用户体验：无反馈、控制器、人形+控制器和真人+控制器。", "result": "结果表明，人形机器人提供的触觉反馈增强了沉浸感、真实性和乐趣，但同时也引入了一定程度的不适感和模拟疾病。", "conclusion": "研究确定了精确度、适应性和多功能性作为新兴主题，并认为人形机器人可以在未来的VR中作为一种独特的触觉模式发挥作用。"}}
{"id": "2601.18973", "pdf": "https://arxiv.org/pdf/2601.18973", "abs": "https://arxiv.org/abs/2601.18973", "authors": ["Nima Leclerc", "Chris Miller", "Nicholas Brawand"], "title": "When Does Adaptation Win? Scaling Laws for Meta-Learning in Quantum Control", "categories": ["cs.LG", "cs.AI", "eess.SY", "quant-ph"], "comment": "28 pages, 11 figures", "summary": "Quantum hardware suffers from intrinsic device heterogeneity and environmental drift, forcing practitioners to choose between suboptimal non-adaptive controllers or costly per-device recalibration. We derive a scaling law lower bound for meta-learning showing that the adaptation gain (expected fidelity improvement from task-specific gradient steps) saturates exponentially with gradient steps and scales linearly with task variance, providing a quantitative criterion for when adaptation justifies its overhead. Validation on quantum gate calibration shows negligible benefits for low-variance tasks but $>40\\%$ fidelity gains on two-qubit gates under extreme out-of-distribution conditions (10$\\times$ the training noise), with implications for reducing per-device calibration time on cloud quantum processors. Further validation on classical linear-quadratic control confirms these laws emerge from general optimization geometry rather than quantum-specific physics. Together, these results offer a transferable framework for decision-making in adaptive control.", "AI": {"tldr": "研究通过推导出元学习的缩放定律，来确定适应性控制在量子硬件校准中的适用情况。", "motivation": "解决因量子硬件异质性和环境漂移导致的传统控制器次优或设备重新校准成本高昂的问题。", "method": "推导了适应性增益随着梯度步骤和任务方差的缩放定律，验证其在量子门校准及经典线性二次控制中的应用。", "result": "低变异性任务中几乎没有收益，但在极端不同分布条件下（噪声增加10倍），双量子比特门的保真度可提高40%以上。", "conclusion": "结果表明适应性的效益取决于任务方差，并提出了一个适用于决策性控制框架。"}}
{"id": "2601.18971", "pdf": "https://arxiv.org/pdf/2601.18971", "abs": "https://arxiv.org/abs/2601.18971", "authors": ["Ioannis G. Polyzos", "Konstantinos J. Kyriakopoulos"], "title": "A Switching Nonlinear Model Predictive Control Strategy for Safe Collision Handling by an Underwater Vehicle-Manipulator System", "categories": ["cs.RO", "eess.SY"], "comment": "This work has been submitted to the 2026 Mediterranean Conference on Control and Automation (MED) to be considered for publication. Figures and animations are available at https://zenodo.org/records/18357280", "summary": "For active intervention tasks in underwater environments, the use of autonomous vehicles is just now emerging as an active area of research. During operation, for various reasons, the robot might find itself on a collision course with an obstacle in its environment. In this paper, a switching Nonlinear Model Predictive Control (NMPC) strategy is proposed to safely handle collisions for an Underwater Vehicle-Manipulator System (UVMS). When avoiding the collision is impossible, the control algorithm takes advantage of the manipulator, using it to push against the obstacle, and deflect away from the collision. Virtual experiments are performed to demonstrate the algorithm's capability to successfully detect collisions and either avoid them, or use the manipulator to handle them appropriately without damaging sensitive areas of the vehicle.", "AI": {"tldr": "提出了一种切换非线性模型预测控制策略，以安全处理水下车辆操作中的碰撞。", "motivation": "在水下环境中进行主动干预任务时，自主车辆可能因各种原因与障碍物发生碰撞。为此开发一种新的控制算法来避免或处理碰撞。", "method": "采用切换非线性模型预测控制（NMPC）策略来检测并响应潜在的碰撞情况。", "result": "虚拟实验表明该算法能够成功检测到碰撞，并采取措施避开或使用机械臂适当处理碰撞，而不会损坏车辆敏感区域。", "conclusion": "所提出的控制算法提高了水下机器人系统的安全性和可靠性，在实际应用中有很大潜力。"}}
{"id": "2601.18970", "pdf": "https://arxiv.org/pdf/2601.18970", "abs": "https://arxiv.org/abs/2601.18970", "authors": ["Alex Beriand", "JhihYang Wu", "Daniel Brignac", "Natnael Daba", "Abhijit Mahalanobis"], "title": "Pay Attention to Where You Look", "categories": ["cs.CV"], "comment": "ICIP 2025 Workshop on Generative AI for World Simulations and Communications", "summary": "Novel view synthesis (NVS) has advanced with generative modeling, enabling photorealistic image generation. In few-shot NVS, where only a few input views are available, existing methods often assume equal importance for all input views relative to the target, leading to suboptimal results. We address this limitation by introducing a camera-weighting mechanism that adjusts the importance of source views based on their relevance to the target. We propose two approaches: a deterministic weighting scheme leveraging geometric properties like Euclidean distance and angular differences, and a cross-attention-based learning scheme that optimizes view weighting. Additionally, models can be further trained with our camera-weighting scheme to refine their understanding of view relevance and enhance synthesis quality. This mechanism is adaptable and can be integrated into various NVS algorithms, improving their ability to synthesize high-quality novel views. Our results demonstrate that adaptive view weighting enhances accuracy and realism, offering a promising direction for improving NVS.", "AI": {"tldr": "本文提出了一种新颖的视图合成方法，通过调整输入视图的重要性来改善少样本下的图像生成质量。", "motivation": "当前的视图合成技术在处理少样本问题时，通常假设所有输入视图对目标视图具有相同的重要程度，这导致了次优结果。为了克服这一限制，作者提出了基于相机权重机制的方法以提升图像合成的真实性和准确性。", "method": "提出了一种确定性加权方案和一种基于交叉注意力的学习方案来优化视图的权重分配，并将此机制融入到不同的视图合成算法中以提高其性能。", "result": "实验结果表明，采用自适应视图加权策略可以显著提升图像生成的质量和现实感。", "conclusion": "本文引入的相机权重调整方法为改善少样本条件下的视图合成提供了有效的解决方案，并展示了这种方法在不同场景中的应用潜力。"}}
{"id": "2601.18966", "pdf": "https://arxiv.org/pdf/2601.18966", "abs": "https://arxiv.org/abs/2601.18966", "authors": ["Lindsay Popowski", "Helena Vasconcelos", "Ignacio Javier Fernandez", "Chijioke Chinaza Mgbahurike", "Ralf Herbrich", "Jeffrey Hancock", "Michael S. Bernstein"], "title": "People Can Accurately Predict Behavior of Complex Algorithms That Are Available, Compact, and Aligned", "categories": ["cs.HC"], "comment": "41 pages, 9 figures; this work to appear in PACMHCI V10, N2, April 2026 and be presented at the 29th ACM SIGCHI Conference on Computer-Supported Cooperative Work & Social Computing (CSCW)", "summary": "Users trust algorithms more when they can predict the algorithms' behavior. Simple algorithms trivially yield predictively accurate mental models, but modern AI algorithms have often been assumed too complex for people to build predictive mental models, especially in the social media domain. In this paper, we describe conditions under which even complex algorithms can yield predictive mental models, opening up opportunities for a broader set of human-centered algorithms. We theorize that users will form an accurate predictive mental model of an algorithm's behavior if and only if the algorithm simultaneously satisfies three criteria: (1) cognitive availability of the underlying concepts being modeled, (2) concept compactness (does it form a single cognitive construct?), and (3) high alignment between the person's and algorithm's execution of the concept. We evaluate this theory through a pre-registered experiment (N=1250) where users predict behavior of 25 social media feed ranking algorithms that vary on these criteria. We find that even complex (e.g., LLM-based) algorithms enjoy accurate prediction rates when they meet all criteria, and even simple (e.g., basic term count) algorithms fail to be predictable when a single criterion fails. We also find that these criteria determine outcomes beyond prediction accuracy, such as which mental models users deploy to make their predictions.", "AI": {"tldr": "研究探讨了满足特定条件的复杂算法是否可以形成准确的认知模型，以及这些认知模型如何影响用户行为。", "motivation": "探索现代AI算法在社交媒体领域中能否让用户建立准确的行为预测模型，从而增强信任和使用。", "method": "通过预注册实验（N=1250），让参与者预测25种社交媒体排序算法的行为，并分析满足特定条件的复杂算法是否能形成准确的认知模型。", "result": "发现当算法同时满足认知可用性、概念简洁性和高一致性这三个标准时，即使复杂的算法也能被用户准确预测；反之则不然。这些条件不仅影响预测准确性，还决定了人们使用的认知模型类型。", "conclusion": "提出了一个理论框架，说明了复杂算法在社交媒体领域中能够建立准确的预测模型的三个必要条件，并验证了该理论的有效性。"}}
{"id": "2601.18963", "pdf": "https://arxiv.org/pdf/2601.18963", "abs": "https://arxiv.org/abs/2601.18963", "authors": ["Fauna Robotics", ":", "Diego Aldarondo", "Ana Pervan", "Daniel Corbalan", "Dave Petrillo", "Bolun Dai", "Aadhithya Iyer", "Nina Mortensen", "Erik Pearson", "Sridhar Pandian Arunachalam", "Emma Reznick", "David Weis", "Jacob Davison", "Samuel Patterson", "Tess Carella", "Michael Suguitan", "David Ye", "Oswaldo Ferro", "Nilesh Suriyarachchi", "Spencer Ling", "Erik Su", "Daniel Giebisch", "Peter Traver", "Sam Fonseca", "et al. (26 additional authors not shown)"], "title": "Fauna Sprout: A lightweight, approachable, developer-ready humanoid robot", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Recent advances in learned control, large-scale simulation, and generative models have accelerated progress toward general-purpose robotic controllers, yet the field still lacks platforms suitable for safe, expressive, long-term deployment in human environments. Most existing humanoids are either closed industrial systems or academic prototypes that are difficult to deploy and operate around people, limiting progress in robotics. We introduce Sprout, a developer platform designed to address these limitations through an emphasis on safety, expressivity, and developer accessibility. Sprout adopts a lightweight form factor with compliant control, limited joint torques, and soft exteriors to support safe operation in shared human spaces. The platform integrates whole-body control, manipulation with integrated grippers, and virtual-reality-based teleoperation within a unified hardware-software stack. An expressive head further enables social interaction -- a domain that remains underexplored on most utilitarian humanoids. By lowering physical and technical barriers to deployment, Sprout expands access to capable humanoid platforms and provides a practical basis for developing embodied intelligence in real human environments.", "AI": {"tldr": "介绍了一种名为Sprout的轻量级、易用且适合开发者的人形机器人平台，旨在解决现有技术在人机共处环境中的安全性和可操作性问题。", "motivation": "当前的通用型机器人控制器虽有进步，但缺乏安全、表达力强和易于部署的操作平台。大多数现有的人形机器人都不适合长时间安全运行于人类环境中。", "method": "设计了一种轻量级人形机器人Sprout，采用柔性控制和软质外壳以确保安全性；整合全身控制、抓取器集成及虚拟现实远程操作的统一硬件软件栈；并具备社交互动能力。", "result": "降低了物理和技术部署门槛，并提供了一个实践基础，在实际人类环境中发展具身智能。", "conclusion": "Sprout平台通过其创新设计，解决了现有技术在人机共处环境中的安全性和可操作性问题，为开发更高级别的机器人技术提供了可能。"}}
{"id": "2601.18953", "pdf": "https://arxiv.org/pdf/2601.18953", "abs": "https://arxiv.org/abs/2601.18953", "authors": ["Marin Bukov", "Florian Marquardt"], "title": "Reinforcement Learning for Quantum Technology", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech", "cs.AI", "cs.LG"], "comment": "review article; comments are welcome!", "summary": "Many challenges arising in Quantum Technology can be successfully addressed using a set of machine learning algorithms collectively known as reinforcement learning (RL), based on adaptive decision-making through interaction with the quantum device. After a concise and intuitive introduction to RL aimed at a broad physics readership, we discuss the key ideas and core concepts in reinforcement learning with a particular focus on quantum systems. We then survey recent progress in RL in all relevant areas. We discuss state preparation in few- and many-body quantum systems, the design and optimization of high-fidelity quantum gates, and the automated construction of quantum circuits, including applications to variational quantum eigensolvers and architecture search. We further highlight the interactive capabilities of RL agents, emphasizing recent progress in quantum feedback control and quantum error correction, and briefly discuss quantum reinforcement learning as well as applications to quantum metrology. The review concludes with a discussion of open challenges -- such as scalability, interpretability, and integration with experimental platforms -- and outlines promising directions for future research. Throughout, we highlight experimental implementations that exemplify the increasing role of reinforcement learning in shaping the development of quantum technologies.", "AI": {"tldr": "量子技术中遇到的许多挑战可以通过强化学习（RL）来解决，这种基于与量子设备互动做出适应性决策的机器学习方法。", "motivation": "通过使用适应性决策和与量子设备的交互，可以利用强化学习有效地应对量子技术中的各种挑战。作者旨在向物理学家介绍强化学习的基础，并讨论其在量子系统中的应用进展。", "method": "综述了近年来强化学习在量子状态制备、高保真量子门的设计优化、自动化构建量子电路以及应用于变分量子特征求解器和架构搜索等多个领域的研究成果。", "result": "探讨了强化学习代理的交互功能，强调了量子反馈控制与量子纠错的进步，并简要介绍了量子强化学习及其在量子计量学中的应用。还讨论了开放性挑战，如可扩展性、解释性和实验平台整合等问题，并提出了未来研究的方向。", "conclusion": "本文总结了目前利用强化学习推动量子技术发展的成果及面临的挑战，并指出了未来的潜在研究方向。"}}
{"id": "2601.18949", "pdf": "https://arxiv.org/pdf/2601.18949", "abs": "https://arxiv.org/abs/2601.18949", "authors": ["Cole Granger", "Dipin Khati", "Daniel Rodriguez-Cardenas", "Denys Poshyvanyk"], "title": "Tricky$^2$: Towards a Benchmark for Evaluating Human and LLM Error Interactions", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly integrated into software development workflows, yet they often introduce subtle logic or data-misuse errors that differ from human bugs. To study how these two error types interact, we construct Tricky$^2$, a hybrid dataset that augments the existing TrickyBugs corpus of human-written defects with errors injected by both GPT-5 and OpenAI-oss-20b across C++, Python, and Java programs. Our approach uses a taxonomy-guided prompting framework to generate machine-originated bugs while preserving original human defects and program structure. The resulting corpus spans human-only, LLM-only, and human+LLM splits, enabling analysis of mixed-origin error behavior, multi-bug repair robustness, and reliability in hybrid human-machine code. This paper outlines the dataset construction pipeline and illustrates its use through small-scale baseline evaluations of classification, localization, and repair tasks.", "AI": {"tldr": "构建了一个混合数据集Tricky$^2$，用于评估人类和大型语言模型(LLM)错误的交互。", "motivation": "研究大型语言模型在软件开发流程中引入的错误与人工产生的错误之间的相互作用。通过创建一个包含两者错误的数据集来探索多类错误修复任务的可靠性。", "method": "利用现有的TrickyBugs缺陷数据集，结合GPT-5和OpenAI-oss-20b生成机器起源的错误，并保持原始的人工缺陷和程序结构不变。使用分类引导式的提示框架生成机器源代码中的错误。", "result": "该研究创建了一个涵盖人类独有、LLM独有及两者混合错误的数据集，可用于评估多类任务如分类、定位与修复等。", "conclusion": "Tricky$^2$数据集为理解人类和大型语言模型在软件开发中的交互提供了一种方法，并为相关研究提供了基础。"}}
{"id": "2601.18948", "pdf": "https://arxiv.org/pdf/2601.18948", "abs": "https://arxiv.org/abs/2601.18948", "authors": ["Zahra Hafezi Kafshgari", "Ivan V. Bajic", "Parvaneh Saeedi"], "title": "Smart Split-Federated Learning over Noisy Channels for Embryo Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Split-Federated (SplitFed) learning is an extension of federated learning that places minimal requirements on the clients computing infrastructure, since only a small portion of the overall model is deployed on the clients hardware. In SplitFed learning, feature values, gradient updates, and model updates are transferred across communication channels. In this paper, we study the effects of noise in the communication channels on the learning process and the quality of the final model. We propose a smart averaging strategy for SplitFed learning with the goal of improving resilience against channel noise. Experiments on a segmentation model for embryo images shows that the proposed smart averaging strategy is able to tolerate two orders of magnitude stronger noise in the communication channels compared to conventional averaging, while still maintaining the accuracy of the final model.", "AI": {"tldr": "研究了一种改进的分割联邦学习策略，以提高在噪声通信信道下的模型鲁棒性和准确性。", "motivation": "为了减少对客户端计算基础设施的需求，并且提升分割联邦学习在存在噪声情况下训练模型的质量。", "method": "提出一种智能平均策略来应对通信信道中的噪声问题。通过实验验证该方法的有效性。", "result": "所提出的智能平均策略能够在比传统平均策略强两个数量级的噪声下保持最终模型精度。", "conclusion": "该研究证明了智能平均策略在分割联邦学习中对抗噪声的能力，提高了胚胎图像分割任务下的通信鲁棒性和准确性。"}}
{"id": "2601.18944", "pdf": "https://arxiv.org/pdf/2601.18944", "abs": "https://arxiv.org/abs/2601.18944", "authors": ["Qiyuan Xu", "Xiaokun Luan", "Renxi Wang", "Joshua Ong Jun Leang", "Peixin Wang", "Haonan Li", "Wenda Li", "Conrad Watt"], "title": "Neural Theorem Proving for Verification Conditions: A Real-World Benchmark", "categories": ["cs.AI", "cs.PL", "cs.SE"], "comment": "Accepted in ICLR'26", "summary": "Theorem proving is fundamental to program verification, where the automated proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world program verification frequently encounters hard VCs that existing Automated Theorem Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs that burden practical application. While Neural Theorem Proving (NTP) has achieved significant success in mathematical competitions, demonstrating the potential of machine learning approaches to formal reasoning, its application to program verification--particularly VC proving--remains largely unexplored. Despite existing work on annotation synthesis and verification-related theorem proving, no benchmark has specifically targeted this fundamental bottleneck: automated VC proving. This work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting the first real-world multi-language benchmark for this task. From real-world projects such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs), both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results indicate that although LLMs show promise in VC proving, significant challenges remain for program verification, highlighting a large gap and opportunity for future research.", "AI": {"tldr": "介绍神经定理证明（NTP4VC）在程序验证条件自动证明中的应用，首次建立一个多语言基准测试集。", "motivation": "解决现有自动化定理证明器难以处理实际项目中复杂验证条件的问题，减少手动证明负担，促进机器学习方法在形式化推理的应用。", "method": "通过工业流水线生成多语言的等价测试案例，评估大规模语言模型（LLMs）和专门用于定理证明的模型在NTP4VC上的性能。", "result": "尽管大型语言模型显示了在验证条件证明中的潜力，但其实际应用仍面临挑战，揭示未来研究的机会与空间。", "conclusion": "展示神经定理证明在程序验证领域的重要性和潜力，并指出需要进一步的研究来改进和完善相关技术。"}}
{"id": "2601.18943", "pdf": "https://arxiv.org/pdf/2601.18943", "abs": "https://arxiv.org/abs/2601.18943", "authors": ["Saleh Bunaiyan", "Mohammad Alsharif", "Abdelrahman S. Abdelrahman", "Hesham ElSawy", "Suraj S. Cheema", "Suhaib A. Fahmy", "Kerem Y. Camsari", "Feras Al-Dirini"], "title": "Configurable p-Neurons Using Modular p-Bits", "categories": ["cs.ET", "cond-mat.dis-nn", "cs.AI", "cs.AR", "cs.LG"], "comment": "Accepted for presentation at IEEE ISCAS 2026 as a lecture", "summary": "Probabilistic bits (p-bits) have recently been employed in neural networks (NNs) as stochastic neurons with sigmoidal probabilistic activation functions. Nonetheless, there remain a wealth of other probabilistic activation functions that are yet to be explored. Here we re-engineer the p-bit by decoupling its stochastic signal path from its input data path, giving rise to a modular p-bit that enables the realization of probabilistic neurons (p-neurons) with a range of configurable probabilistic activation functions, including a probabilistic version of the widely used Logistic Sigmoid, Tanh and Rectified Linear Unit (ReLU) activation functions. We present spintronic (CMOS + sMTJ) designs that show wide and tunable probabilistic ranges of operation. Finally, we experimentally implement digital-CMOS versions on an FPGA, with stochastic unit sharing, and demonstrate an order of magnitude (10x) saving in required hardware resources compared to conventional digital p-bit implementations.", "AI": {"tldr": "本文重新设计了p位，使其能够实现具有可配置概率激活函数的神经元（p-神经元），并展示了其在自旋电子学和数字CMOS中的应用。", "motivation": "目前研究中使用的p位主要采用了单一的概率激活函数。为了探索更多其他的可能性，本文旨在开发一种模块化p位，以支持各种可配置的概率激活函数，包括逻辑Sigmoid、Tanh和ReLU等常用函数。", "method": "通过分离p位的随机信号路径与输入数据路径，提出了一种新型的模块化p位。设计了自旋电子（CMOS + sMTJ）版本以及数字CMOS版本，并在FPGA上进行了实验验证。", "result": "实现了具有不同概率激活函数的p-神经元，展示了广泛的可调概率范围操作。通过共享随机单元的方式，在硬件资源需求方面比传统数字p位实现节省了大约10倍。", "conclusion": "本文提出的模块化p位为构建多种概率激活函数提供了可能，并且在实验中验证了其优越的性能和高效的硬件利用率，为未来的研究奠定了基础。"}}
{"id": "2601.18934", "pdf": "https://arxiv.org/pdf/2601.18934", "abs": "https://arxiv.org/abs/2601.18934", "authors": ["Ruipeng Wang", "Tawab Safi", "Yunge Wen", "Christina Cunningham", "Hoi Ling Tang", "Behnaz Farahi"], "title": "Whispering Water: Materializing Human-AI Dialogue as Interactive Ripples", "categories": ["cs.HC", "cs.MM"], "comment": null, "summary": "Across cultures, water has served as a recipient of human confession, a yielding medium that receives vulnerability where rigid surfaces cannot. We present Whispering Water, an interactive installation that materializes human-AI dialogue through cymatic patterns on water. Participants confess secrets to a water surface, triggering a four-phase ritual: confession, contemplation, response, and release. The user's speech sentiment is directly transmitted into the water to prime its state, while semantic content enters a multi-agent system, initiating ripples of conversation where agent identities are situated through discourse and voice profiles are chosen based on what they say. We propose a novel algorithm that decomposes speech into component waves and reconstructs them in water, establishing a translation between speech and the physics of material form. By rendering machine reasoning as emergent physical phenomena, the installation explores possibilities for emotional self-exploration through ambiguous, sensory-rich interfaces.", "AI": {"tldr": "通过水面上的波动模式来物质化人类与AI之间的对话，探索情感自我探索的可能性", "motivation": "利用水作为媒介接收人类的情感脆弱性，并通过物理现象将机器推理以感官丰富的界面呈现出来，促进情感表达和自我反思", "method": "设计了一个互动装置，用户对着水面说话，语音情绪影响水面状态，而内容则进入多代理系统生成对话。提出了一种算法将语音分解并重构在水中形成波纹", "result": "实现了从言语到物理形态的翻译，以及通过波动模式进行人机交互的新方式", "conclusion": "这种基于水的互动装置提供了探索情感自我探索和人类-机器交流的一种新颖而富有感官体验的方法"}}
{"id": "2601.18933", "pdf": "https://arxiv.org/pdf/2601.18933", "abs": "https://arxiv.org/abs/2601.18933", "authors": ["Kaustubh D. Dhole"], "title": "BabyReasoningBench: Generating Developmentally-Inspired Reasoning Tasks for Evaluating Baby Language Models", "categories": ["cs.CL", "cs.AI"], "comment": ":J.4; I.2.0; I.2.7", "summary": "Traditional evaluations of reasoning capabilities of language models are dominated by adult-centric benchmarks that presuppose broad world knowledge, complex instruction following, and mature pragmatic competence. These assumptions are mismatched to baby language models trained on developmentally plausible input such as child-directed speech and early-childhood narratives, and they obscure which reasoning abilities (if any) emerge under such constraints. We introduce BabyReasoningBench, a GPT-5.2 generated benchmark of 19 reasoning tasks grounded in classic paradigms from developmental psychology, spanning theory of mind, analogical and relational reasoning, causal inference and intervention selection, and core reasoning primitives that are known to be confounded by memory and pragmatics. We find that two GPT-2 based baby language models (pretrained on 10M and 100M of child-directed speech text) show overall low but uneven performance, with dissociations across task families: scaling improves several causal and physical reasoning tasks, while belief attribution and pragmatics-sensitive tasks remain challenging. BabyReasoningBench provides a developmentally grounded lens for analyzing what kinds of reasoning are supported by child-like training distributions, and for testing mechanistic hypotheses about how such abilities emerge.", "AI": {"tldr": "引入BabyReasoningBench，一个基于儿童发展心理学经典范式的语言模型推理任务生成工具。", "motivation": "当前的语言模型评估基准过于成人化，不适合评估训练于儿童语料库的宝宝语言模型的推理能力。需要一个新的评估体系来更好地理解这些模型在不同推理类型上的表现。", "method": "创建BabyReasoningBench，其中包括19个基于发展心理学原理设计的任务，并通过两个GPT-2基线语言模型（分别用10M和100M儿童语料训练）测试这些任务。", "result": "发现宝宝语言模型在因果推理和物理推理方面的表现随规模扩大而提升，但在信念归属以及依赖于实用主义的任务方面依然存在挑战。", "conclusion": "BabyReasoningBench提供了一种以发展为基础的视角来分析什么样的推理能力可以在儿童训练分布中支持，并测试这些能力如何出现的机制性假设。"}}
{"id": "2601.18932", "pdf": "https://arxiv.org/pdf/2601.18932", "abs": "https://arxiv.org/abs/2601.18932", "authors": ["Yibo Yang", "Stephan Mandt"], "title": "Advances in Diffusion-Based Generative Compression", "categories": ["eess.IV", "cs.IT", "cs.LG", "stat.ML"], "comment": "Preprint", "summary": "Popularized by their strong image generation performance, diffusion and related methods for generative modeling have found widespread success in visual media applications. In particular, diffusion methods have enabled new approaches to data compression, where realistic reconstructions can be generated at extremely low bit-rates. This article provides a unifying review of recent diffusion-based methods for generative lossy compression, with a focus on image compression. These methods generally encode the source into an embedding and employ a diffusion model to iteratively refine it in the decoding procedure, such that the final reconstruction approximately follows the ground truth data distribution. The embedding can take various forms and is typically transmitted via an auxiliary entropy model, and recent methods also explore the use of diffusion models themselves for information transmission via channel simulation. We review representative approaches through the lens of rate-distortion-perception theory, highlighting the role of common randomness and connections to inverse problems, and identify open challenges.", "AI": {"tldr": "本文综述了基于扩散模型的生成式有损压缩方法，重点讨论图像压缩技术。", "motivation": "基于扩散模型的方法在视觉媒体应用中取得成功，特别在数据压缩方面实现了极低比特率下的逼真重建。因此，作者希望通过统一审查最近的扩散模型压缩方法，推动这一领域的发展。", "method": "这些方法通常将源输入编码为嵌入，并通过解码过程迭代地用扩散模型进行细化，最终重构逼近真实数据分布。嵌入可以采用多种形式并通过辅助熵模型传输。", "result": "综述了代表性方法，从率失真感知理论的角度分析其作用，并指出了共同随机性及逆问题的联系。同时识别出开放挑战。", "conclusion": "基于扩散模型的生成式有损压缩技术展现出巨大潜力，但仍然存在一些未解决的技术难题和研究方向。"}}
{"id": "2601.18930", "pdf": "https://arxiv.org/pdf/2601.18930", "abs": "https://arxiv.org/abs/2601.18930", "authors": ["Seiji Shaw", "Travis Manderson", "Chad Kessens", "Nicholas Roy"], "title": "Toward Learning POMDPs Beyond Full-Rank Actions and State Observability", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "We are interested in enabling autonomous agents to learn and reason about systems with hidden states, such as furniture with hidden locking mechanisms. We cast this problem as learning the parameters of a discrete Partially Observable Markov Decision Process (POMDP). The agent begins with knowledge of the POMDP's actions and observation spaces, but not its state space, transitions, or observation models. These properties must be constructed from action-observation sequences. Spectral approaches to learning models of partially observable domains, such as learning Predictive State Representations (PSRs), are known to directly estimate the number of hidden states. These methods cannot, however, yield direct estimates of transition and observation likelihoods, which are important for many downstream reasoning tasks. Other approaches leverage tensor decompositions to estimate transition and observation likelihoods but often assume full state observability and full-rank transition matrices for all actions. To relax these assumptions, we study how PSRs learn transition and observation matrices up to a similarity transform, which may be estimated via tensor methods. Our method learns observation matrices and transition matrices up to a partition of states, where the states in a single partition have the same observation distributions corresponding to actions whose transition matrices are full-rank. Our experiments suggest that these partition-level transition models learned by our method, with a sufficient amount of data, meets the performance of PSRs as models to be used by standard sampling-based POMDP solvers. Furthermore, the explicit observation and transition likelihoods can be leveraged to specify planner behavior after the model has been learned.", "AI": {"tldr": "本文研究了在隐藏状态情况下学习部分可观察马尔科夫决策过程(POMDP)参数的方法，特别是在非完全可观测和动作矩阵不是满秩的情况下。", "motivation": "为了使自主代理能够理解和处理具有隐藏机制的系统（如带隐藏锁定机制的家具），需要研究如何通过行为-观测序列来构建这些系统的状态空间、转换以及观察模型。", "method": "本文提出了一种方法，该方法可以学习部分可观测马尔科夫决策过程(POMDP)中的观察矩阵和过渡矩阵，直到对状态进行分区为止。在每个分区中，相同的行为分布对应于其转换矩阵为满秩的状态。", "result": "实验表明，在有足够的数据的情况下，通过本文的方法得到的分层级转换模型满足使用标准采样POMDP求解器的标准预测状态表示(PSRs)所达到的效果。", "conclusion": "该方法能够直接估计观察和过渡概率，并且能够在非完全可观测和动作矩阵不是满秩的情况下工作。这为规划者的后续行为提供了显式的观察和转换可能性的利用途径。"}}
{"id": "2601.18929", "pdf": "https://arxiv.org/pdf/2601.18929", "abs": "https://arxiv.org/abs/2601.18929", "authors": ["John J. Han", "Adam Schmidt", "Muhammad Abdullah Jamal", "Chinedu Nwoye", "Anita Rau", "Jie Ying Wu", "Omid Mohareri"], "title": "On the Role of Depth in Surgical Vision Foundation Models: An Empirical Study of RGB-D Pre-training", "categories": ["cs.CV"], "comment": null, "summary": "Vision foundation models (VFMs) have emerged as powerful tools for surgical scene understanding. However, current approaches predominantly rely on unimodal RGB pre-training, overlooking the complex 3D geometry inherent to surgical environments. Although several architectures support multimodal or geometry-aware inputs in general computer vision, the benefits of incorporating depth information in surgical settings remain underexplored. We conduct a large-scale empirical study comparing eight ViT-based VFMs that differ in pre-training domain, learning objective, and input modality (RGB vs. RGB-D). For pre-training, we use a curated dataset of 1.4 million robotic surgical images paired with depth maps generated from an off-the-shelf network. We evaluate these models under both frozen-backbone and end-to-end fine-tuning protocols across eight surgical datasets spanning object detection, segmentation, depth estimation, and pose estimation. Our experiments yield several consistent findings. Models incorporating explicit geometric tokenization, such as MultiMAE, substantially outperform unimodal baselines across all tasks. Notably, geometric-aware pre-training enables remarkable data efficiency: models fine-tuned on just 25% of labeled data consistently surpass RGB-only models trained on the full dataset. Importantly, these gains require no architectural or runtime changes at inference; depth is used only during pre-training, making adoption straightforward. These findings suggest that multimodal pre-training offers a viable path towards building more capable surgical vision systems.", "AI": {"tldr": "本论文通过大规模实证研究探讨了深度信息在手术视觉基础模型中的作用，对比了八种基于ViT的视觉基础模型在不同预训练域、学习目标和输入模式（RGB与RGB-D）下的表现。", "motivation": "当前手术场景理解中主流方法主要依赖单模态RGB预训练，忽略了手术环境中复杂的3D几何结构。然而，将深度信息纳入到手术设置中的好处尚未充分研究。", "method": "使用140万张机器人外科图像配对生成的深度图作为预训练数据集，对比了八种基于ViT的视觉基础模型在冻结骨干和端到端微调协议下的表现。这些模型包括RGB与RGB-D两种输入模式。", "result": "实验结果表明，包含显式几何令牌化的模型（例如MultiMAE）在所有任务上都优于单模态基线模型。特别是，基于几何感知的预训练使得数据效率显著提高：仅使用25%标注数据进行微调的模型一致地超越了完整数据集训练下的RGB-only模型。", "conclusion": "这些发现表明，多模态预训练为构建更强大的手术视觉系统提供了一条可行的道路。"}}
{"id": "2601.18924", "pdf": "https://arxiv.org/pdf/2601.18924", "abs": "https://arxiv.org/abs/2601.18924", "authors": ["Andrew Jaffe", "Noah Reicin", "Jinho D. Choi"], "title": "RIFT: Reordered Instruction Following Testbed To Evaluate Instruction Following in Singular Multistep Prompt Structures", "categories": ["cs.AI"], "comment": "13 pages, 5 figures, submitted to ACL ARR", "summary": "Large Language Models (LLMs) are increasingly relied upon for complex workflows, yet their ability to maintain flow of instructions remains underexplored. Existing benchmarks conflate task complexity with structural ordering, making it difficult to isolate the impact of prompt topology on performance. We introduce RIFT, Reordered Instruction Following Testbed, to assess instruction following by disentangling structure from content. Using rephrased Jeopardy! question-answer pairs, we test LLMs across two prompt structures: linear prompts, which progress sequentially, and jumping prompts, which preserve identical content but require non-sequential traversal. Across 10,000 evaluations spanning six state-of-the-art open-source LLMs, accuracy dropped by up to 72% under jumping conditions (compared to baseline), revealing a strong dependence on positional continuity. Error analysis shows that approximately 50% of failures stem from instruction-order violations and semantic drift, indicating that current architectures internalize instruction following as a sequential pattern rather than a reasoning skill. These results reveal structural sensitivity as a fundamental limitation in current architectures, with direct implications for applications requiring non-sequential control flow such as workflow automation and multi-agent systems.", "AI": {"tldr": "本文介绍了一个评估大型语言模型在单一多步骤提示结构中指令遵循能力的测试平台RIFT。", "motivation": "当前对复杂工作流程中大语言模型指令跟随能力的研究不足，现有基准将任务复杂性和结构顺序混淆在一起。作者希望通过引入RIFT来解决这一问题，并深入研究结构顺序对性能的影响。", "method": "通过重新排列Jeopardy!的问题和答案对，测试了六种最先进的开源LLM在两种提示结构（线性提示和跳跃提示）下的表现。", "result": "实验结果表明，在跳跃条件下，准确率下降高达72%，且约50%的错误源于指令顺序违反和语义漂移。这揭示了现有架构对位置连续性的强烈依赖。", "conclusion": "研究表明，结构敏感性是当前架构的基本限制，这对需要非序列控制流的应用（如工作流程自动化和多代理系统）具有直接的影响。"}}
{"id": "2601.18923", "pdf": "https://arxiv.org/pdf/2601.18923", "abs": "https://arxiv.org/abs/2601.18923", "authors": ["Manthan Patel", "Jonas Frey", "Mayank Mittal", "Fan Yang", "Alexander Hansson", "Amir Bar", "Cesar Cadena", "Marco Hutter"], "title": "DeFM: Learning Foundation Representations from Depth for Robotics", "categories": ["cs.RO", "cs.CV"], "comment": "Under review, 19 pages, 15 Figures, 9 Tables", "summary": "Depth sensors are widely deployed across robotic platforms, and advances in fast, high-fidelity depth simulation have enabled robotic policies trained on depth observations to achieve robust sim-to-real transfer for a wide range of tasks. Despite this, representation learning for depth modality remains underexplored compared to RGB, where large-scale foundation models now define the state of the art. To address this gap, we present DeFM, a self-supervised foundation model trained entirely on depth images for robotic applications. Using a DINO-style self-distillation objective on a curated dataset of 60M depth images, DeFM learns geometric and semantic representations that generalize to diverse environments, tasks, and sensors. To retain metric awareness across multiple scales, we introduce a novel input normalization strategy. We further distill DeFM into compact models suitable for resource-constrained robotic systems. When evaluated on depth-based classification, segmentation, navigation, locomotion, and manipulation benchmarks, DeFM achieves state-of-the-art performance and demonstrates strong generalization from simulation to real-world environments. We release all our pretrained models, which can be adopted off-the-shelf for depth-based robotic learning without task-specific fine-tuning. Webpage: https://de-fm.github.io/", "AI": {"tldr": "该论文提出了DeFM，这是一种基于深度图像的自我监督基础模型，用于机器人应用。", "motivation": "尽管深度传感器在机器人平台中广泛部署，并且快速、高保真度的深度模拟已经使得基于深度观察训练的机器人策略能够在广泛的任务上实现稳健的仿真到现实世界的转移，但与RGB相比，深度模式下的表示学习仍然相对较少研究。为此，作者提出了DeFM。", "method": "通过DINO风格的自我蒸馏目标在60M个经过精心策划的深度图像数据集上训练，DeFM学会了泛化至各种环境、任务和传感器的几何和语义表征。为了保持多尺度下的度量感知，我们引入了一种新颖的输入归一化策略。", "result": "当对基于深度的分类、分割、导航、行走以及操作基准进行评估时，DeFM取得了最先进的性能，并展示了从仿真环境到真实世界环境中强大的泛化能力。", "conclusion": "作者发布了所有的预训练模型，这些模型可以用于无需针对特定任务微调的基于深度图像的机器人学习。"}}
{"id": "2601.18913", "pdf": "https://arxiv.org/pdf/2601.18913", "abs": "https://arxiv.org/abs/2601.18913", "authors": ["Mohammad Elayan", "Wissam Kontar"], "title": "Learning the Pareto Space of Multi-Objective Autonomous Driving: A Modular, Data-Driven Approach", "categories": ["cs.RO", "cs.MA"], "comment": "Accepted for presentation/publication at the The IEEE Intelligent Vehicles Symposium of 2026 (IEEE IV 2026)", "summary": "Balancing safety, efficiency, and interaction is fundamental to designing autonomous driving agents and to understanding autonomous vehicle (AV) behavior in real-world operation. This study introduces an empirical learning framework that derives these trade-offs directly from naturalistic trajectory data. A unified objective space represents each AV timestep through composite scores of safety, efficiency, and interaction. Pareto dominance is applied to identify non-dominated states, forming an empirical frontier that defines the attainable region of balanced performance. The proposed framework was demonstrated using the Third Generation Simulation (TGSIM) datasets from Foggy Bottom and I-395. Results showed that only 0.23\\% of AV driving instances were Pareto-optimal, underscoring the rarity of simultaneous optimization across objectives. Pareto-optimal states showed notably higher mean scores for safety, efficiency, and interaction compared to non-optimal cases, with interaction showing the greatest potential for improvement. This minimally invasive and modular framework, which requires only kinematic and positional data, can be directly applied beyond the scope of this study to derive and visualize multi-objective learning surfaces", "AI": {"tldr": "本文提出了一种从自然轨迹数据中学习多目标自动驾驶代理的平衡方法。", "motivation": "旨在通过直接从实际操作中的轨迹数据中推导出安全、效率和交互之间的权衡，设计自主驾驶代理人并理解其行为。", "method": "采用统一的目标空间表示每个自动驾驶时间步的安全性、效率和互动性的综合评分，并应用帕累托主导原则来识别非支配状态，形成一个可以定义平衡性能可实现区域的实证前沿。", "result": "在Foggy Bottom和I-395的数据集中，仅有0.23%的自动驾驶实例是帕累托最优的；帕累托最优的状态展示了更高的安全、效率和交互均分，且互动方面有显著改进空间。", "conclusion": "该框架是一个非侵入性和模块化的方案，只需要使用运动学和位置数据即可直接应用到研究范围之外的领域，以推导出并可视化多目标学习表面。"}}
{"id": "2601.18908", "pdf": "https://arxiv.org/pdf/2601.18908", "abs": "https://arxiv.org/abs/2601.18908", "authors": ["Marouane El Hizabri", "Abdelfattah Bezzaz", "Ismail Hayoukane", "Youssef Taki"], "title": "Enhancing Speech Emotion Recognition using Dynamic Spectral Features and Kalman Smoothing", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": null, "summary": "Speech Emotion Recognition systems often use static features like Mel-Frequency Cepstral Coefficients (MFCCs), Zero Crossing Rate (ZCR), and Root Mean Square Energy (RMSE). Because of this, they can misclassify emotions when there is acoustic noise in vocal signals. To address this, we added dynamic features using Dynamic Spectral features (Deltas and Delta-Deltas) along with the Kalman Smoothing algorithm. This approach reduces noise and improves emotion classification. Since emotion changes over time, the Kalman Smoothing filter also helped make the classifier outputs more stable. Tests on the RAVDESS dataset showed that this method achieved a state-of-the-art accuracy of 87\\% and reduced misclassification between emotions with similar acoustic features", "AI": {"tldr": "通过使用动态光谱特征和卡尔曼滤波器改进语音情感识别", "motivation": "静态特性如MFCC容易在有噪声的情况下错误分类情感，因此引入了动态特性以减少噪音并提高准确度。", "method": "增加动态光谱特性（Deltas和Delta-Deltas），结合Kalman Smoothing算法，使模型输出更加稳定。", "result": "测试表明这种方法在RAVDESS数据集上的精度达到87%，显著减少了相似情感之间的误分类。", "conclusion": "该方法提高了语音情感识别系统的准确性和稳定性。"}}
{"id": "2601.18904", "pdf": "https://arxiv.org/pdf/2601.18904", "abs": "https://arxiv.org/abs/2601.18904", "authors": ["Haolong Zheng", "Siyin Wang", "Zengrui Jin", "Mark Hasegawa-Johnson"], "title": "SICL-AT: Another way to adapt Auditory LLM to low-resource task", "categories": ["cs.SD", "cs.AI", "cs.CL"], "comment": null, "summary": "Auditory Large Language Models (LLMs) have demonstrated strong performance across a wide range of speech and audio understanding tasks. Nevertheless, they often struggle when applied to low-resource or unfamiliar tasks. In case of labeled in-domain data is scarce or mismatched to the true test distribution, direct fine-tuning can be brittle. In-Context Learning (ICL) provides a training-free, inference-time solution by adapting auditory LLMs through conditioning on a few in-domain demonstrations. In this work, we first show that \\emph{Vanilla ICL}, improves zero-shot performance across diverse speech and audio tasks for selected models which suggest this ICL adaptation capability can be generalized to multimodal setting. Building on this, we propose \\textbf{Speech In-Context Learning Adaptation Training (SICL-AT)}, a post-training recipe utilizes only high resource speech data intending to strengthen model's in-context learning capability. The enhancement can generalize to audio understanding/reasoning task. Experiments indicate our proposed method consistently outperforms direct fine-tuning in low-resource scenario.", "AI": {"tldr": "本文提出了一种新的适应性训练方法SICL-AT，用于增强大型语言模型在低资源场景下的表现。", "motivation": "当应用于低资源或不熟悉的任务时，听觉LLM通常表现出色。然而，在标签不足的情况下，直接微调可能脆弱且效果不佳。因此，本文希望通过利用高资源语音数据来提高模型的上下文学习能力，并解决这个问题。", "method": "首先展示了Vanilla ICL在多种语音和音频任务中的零样本性能提升。在此基础上提出了SICL-AT方法，通过仅使用高资源语音数据进行后训练以增强模型的上下文学习能力。", "result": "实验表明所提出的方法在低资源场景中始终优于直接微调方法。", "conclusion": "研究结果证明了SICL-AT的有效性，并且它能够将改进应用于音频理解和推理任务。"}}
{"id": "2601.18900", "pdf": "https://arxiv.org/pdf/2601.18900", "abs": "https://arxiv.org/abs/2601.18900", "authors": ["Haim Zisman", "Uri Shaham"], "title": "RealStats: A Rigorous Real-Only Statistical Framework for Fake Image Detection", "categories": ["cs.CV", "cs.LG", "stat.ML"], "comment": "22 pages, 14 figures. Accepted to AISTATS 2026", "summary": "As generative models continue to evolve, detecting AI-generated images remains a critical challenge. While effective detection methods exist, they often lack formal interpretability and may rely on implicit assumptions about fake content, potentially limiting robustness to distributional shifts. In this work, we introduce a rigorous, statistically grounded framework for fake image detection that focuses on producing a probability score interpretable with respect to the real-image population. Our method leverages the strengths of multiple existing detectors by combining training-free statistics. We compute p-values over a range of test statistics and aggregate them using classical statistical ensembling to assess alignment with the unified real-image distribution. This framework is generic, flexible, and training-free, making it well-suited for robust fake image detection across diverse and evolving settings.", "AI": {"tldr": "提出了一种基于真实图像统计的假图像检测框架，通过计算p值并使用经典统计集成来评估与统一的真实图像分布的一致性。", "motivation": "现有的检测方法缺乏正式解释性和对假内容隐含假设的存在可能限制了其在分布变化下的鲁棒性。因此，提出了一种严谨、统计基础的检测框架以提高检测效果和适应性。", "method": "使用多个现有检测器的优势，通过无训练统计计算p值，并利用经典统计集成方法来评估与统一的真实图像分布的一致性。", "result": "该框架具有通用性和灵活性，在多样化和不断变化的情况下表现出良好的假图像检测性能。", "conclusion": "所提出的RealStats框架提供了一种严谨、可解释的统计方法，提高了对AI生成图像检测的有效性和鲁棒性。"}}
{"id": "2601.18899", "pdf": "https://arxiv.org/pdf/2601.18899", "abs": "https://arxiv.org/abs/2601.18899", "authors": ["Yuchen Zhang", "Ravi Shekhar", "Haralambos Mouratidis"], "title": "Language Family Matters: Evaluating LLM-Based ASR Across Linguistic Boundaries", "categories": ["cs.CL", "cs.AI", "cs.SD"], "comment": null, "summary": "Large Language Model (LLM)-powered Automatic Speech Recognition (ASR) systems achieve strong performance with limited resources by linking a frozen speech encoder to a pretrained LLM via a lightweight connector. Prior work trains a separate connector per language, overlooking linguistic relatedness. We propose an efficient and novel connector-sharing strategy based on linguistic family membership, enabling one connector per family, and empirically validate its effectiveness across two multilingual LLMs and two real-world corpora spanning curated and crowd-sourced speech. Our results show that family-based connectors reduce parameter count while improving generalization across domains, offering a practical and scalable strategy for multilingual ASR deployment.", "AI": {"tldr": "本文探讨了基于语言家族共享连接器的LLM驱动ASR系统的方法，并验证其在多语种环境中的有效性。", "motivation": "以往的研究为每种语言单独训练一个连接器，忽略了语言间的亲属关系。本文提出了一种新的、有效的连接器共享策略，根据语言家族成员身份来减少参数数量并提高跨域泛化能力。", "method": "通过基于语言家族的连接器分享方法，利用两种多语种LLM和两个涵盖策划与众包语音的真实世界数据集进行验证。", "result": "结果显示，基于语言家族的连接器可以有效地降低参数计数，并提升在不同领域的泛化性能。", "conclusion": "本文提出的策略提供了一种实用且可扩展的方法来部署多语种ASR系统。"}}
{"id": "2601.18897", "pdf": "https://arxiv.org/pdf/2601.18897", "abs": "https://arxiv.org/abs/2601.18897", "authors": ["Qusai Khaled", "Bahjat Mallak", "Uzay Kaymak", "Laura Genga"], "title": "Explainable Uncertainty Quantification for Wastewater Treatment Energy Prediction via Interval Type-2 Neuro-Fuzzy System", "categories": ["cs.AI", "cs.LG"], "comment": "Submitted to 21st International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems (IPMU2026)", "summary": "Wastewater treatment plants consume 1-3% of global electricity, making accurate energy forecasting critical for operational optimization and sustainability. While machine learning models provide point predictions, they lack explainable uncertainty quantification essential for risk-aware decision-making in safety-critical infrastructure. This study develops an Interval Type-2 Adaptive Neuro-Fuzzy Inference System (IT2-ANFIS) that generates interpretable prediction intervals through fuzzy rule structures. Unlike black-box probabilistic methods, the proposed framework decomposes uncertainty across three levels: feature-level, footprint of uncertainty identify which variables introduce ambiguity, rule-level analysis reveals confidence in local models, and instance-level intervals quantify overall prediction uncertainty. Validated on Melbourne Water's Eastern Treatment Plant dataset, IT2-ANFIS achieves comparable predictive performance to first order ANFIS with substantially reduced variance across training runs, while providing explainable uncertainty estimates that link prediction confidence directly to operational conditions and input variables.", "AI": {"tldr": "本文开发了一种基于区间二型自适应神经模糊推理系统的模型，用于污水处理厂能耗预测，并提供可解释的不确定性量化。", "motivation": "传统的机器学习模型虽然可以进行点预测，但缺乏可解释的不确定性量化，这对于安全关键基础设施的风险意识决策至关重要。", "method": "本文提出了一种区间二型自适应神经模糊推理系统（IT2-ANFIS），该系统通过模糊规则结构生成可解释的预测区间。方法分解了三个层次的不确定性：特征级、规则级和实例级。", "result": "在墨尔本水务东部污水处理厂的数据集上验证，所提出的方法实现了与一阶自适应神经模糊推理系统的预测性能相当的效果，并且训练运行中的方差显著减小，同时提供了可解释的不确定性估计。", "conclusion": "该研究证明了IT2-ANFIS模型在提供准确能耗预测的同时，能够有效地量化并解释不确定性的来源和影响。"}}
{"id": "2601.18891", "pdf": "https://arxiv.org/pdf/2601.18891", "abs": "https://arxiv.org/abs/2601.18891", "authors": ["Ghazaleh Serati", "Samuel Foucher", "Jerome Theau"], "title": "Weakly supervised framework for wildlife detection and counting in challenging Arctic environments: a case study on caribou (Rangifer tarandus)", "categories": ["cs.CV"], "comment": "30 pages, 8 figures, submitted to Frontiers in Ecology and Evolution", "summary": "Caribou across the Arctic has declined in recent decades, motivating scalable and accurate monitoring approaches to guide evidence-based conservation actions and policy decisions. Manual interpretation from this imagery is labor-intensive and error-prone, underscoring the need for automatic and reliable detection across varying scenes. Yet, such automatic detection is challenging due to severe background heterogeneity, dominant empty terrain (class imbalance), small or occluded targets, and wide variation in density and scale. To make the detection model (HerdNet) more robust to these challenges, a weakly supervised patch-level pretraining based on a detection network's architecture is proposed. The detection dataset includes five caribou herds distributed across Alaska. By learning from empty vs. non-empty labels in this dataset, the approach produces early weakly supervised knowledge for enhanced detection compared to HerdNet, which is initialized from generic weights. Accordingly, the patch-based pretrain network attained high accuracy on multi-herd imagery (2017) and on an independent year's (2019) test sets (F1: 93.7%/92.6%, respectively), enabling reliable mapping of regions containing animals to facilitate manual counting on large aerial imagery. Transferred to detection, initialization from weakly supervised pretraining yielded consistent gains over ImageNet weights on both positive patches (F1: 92.6%/93.5% vs. 89.3%/88.6%), and full-image counting (F1: 95.5%/93.3% vs. 91.5%/90.4%). Remaining limitations are false positives from animal-like background clutter and false negatives related to low animal density occlusions. Overall, pretraining on coarse labels prior to detection makes it possible to rely on weakly-supervised pretrained weights even when labeled data are limited, achieving results comparable to generic-weight initialization.", "AI": {"tldr": "本文提出了一种弱监督框架，用于在具有挑战性的北极环境中自动检测和计数野生动物（以驯鹿为例）。", "motivation": "近几十年来，驯鹿数量下降，促使开发可扩展且准确的监测方法以支持基于证据的保护行动与政策决策。人工解释这些图像耗时且易出错，因此需要一种可靠的方法在各种场景下进行自动检测。", "method": "提出了一种弱监督的补丁级别预训练框架（HerdNet），通过使用检测网络架构从空和非空标签中学习来提高检测模型的鲁棒性。该方法利用了阿拉斯加五个驯鹿群的数据，实现了高精度的多群图像检测。", "result": "实验表明，在2017年和独立测试集（2019）上，预训练网络达到了F1值分别为93.7%和92.6%，且在完整图像计数中表现更好。尽管仍存在背景噪声引起的假阳性和低密度遮挡导致的假阴性问题。", "conclusion": "通过粗标签进行弱监督预训练，在有限标注数据的情况下，可以使模型从预训练权重中受益，达到与通用权重初始化相当的结果。"}}
{"id": "2601.18858", "pdf": "https://arxiv.org/pdf/2601.18858", "abs": "https://arxiv.org/abs/2601.18858", "authors": ["Zhiyu An", "Wan Du"], "title": "Representational Homomorphism Predicts and Improves Compositional Generalization In Transformer Language Model", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Compositional generalization-the ability to interpret novel combinations of familiar components-remains a persistent challenge for neural networks. Behavioral evaluations reveal when models fail but offer limited insight into why failures arise at the representational level. We introduce Homomorphism Error (HE), a structural metric that quantifies deviations from approximate homomorphisms between the expression algebra and a model's hidden-state space. We instantiate HE for two compositional operators in SCAN-style tasks: modifier HE for unary composition and sequence HE for binary composition, measured by learning representation-level operators that predict composed representations from their parts. Across controlled experiments with small decoder-only Transformers, HE predicts out-of-distribution (OOD) compositional generalization under noise injection, achieving R^2 = 0.73 correlation between modifier HE and OOD accuracy. Ablations show that model depth has minimal effect on either HE or OOD accuracy, training data coverage exhibits threshold effects (insufficient coverage sharply increases HE and degrades OOD performance), and randomly inserted noise tokens systematically increase HE. Finally, we test if HE-regularized training improves OOD accuracy. Experiment shows that explicitly enforcing low modifier HE during training significantly reduces modifier HE (p = 1.1x10-4) and sequence HE (p = 0.001) and yields a statistically significant improvement in OOD accuracy (p = 0.023). Together, these results indicate the potential of HE to be both a diagnostic and an actionable training signal for improving compositional generalization. Code to reproduce our experiments is open-sourced.", "AI": {"tldr": "该论文通过引入Homomorphism Error（HE）这一结构化指标来预测和改善Transformer语言模型的组合泛化能力。", "motivation": "神经网络在处理组成泛化的任务时表现不佳，且行为评估只能揭示失败的现象而无法解释背后的原因。因此，研究者希望通过引入一个新的度量标准来更好地理解这种现象并提高模型的表现。", "method": "论文提出了Homomorphism Error（HE），用于量化表达代数与模型隐藏状态空间之间的近似同态偏差。通过在SCAN风格的任务中使用两种组成操作符：修饰器HE和序列HE，衡量学习表示级别的运算符来预测组合表示的性能。此外，实验还研究了不同因素如模型深度、训练数据覆盖率以及随机插入噪声令牌对HE的影响。", "result": "实验证明，Homomorphism Error（HE）可以有效地预测并改善Transformer语言模型在出现噪音情况下的组合泛化能力。特别是通过减少修饰器HE和序列HE的值，在统计上显著提高了模型的OOD准确性。", "conclusion": "该研究展示了Homomorphism Error作为诊断工具以及训练信号，有助于提高Transformer语言模型的组合泛化能力，并且这些结论可以通过开源代码进行验证实验。"}}
{"id": "2601.18851", "pdf": "https://arxiv.org/pdf/2601.18851", "abs": "https://arxiv.org/abs/2601.18851", "authors": ["Wei Liang", "Hui Yu", "Derui Ding", "Rachael E. Jack", "Philippe G. Schyns"], "title": "SelfieAvatar: Real-time Head Avatar reenactment from a Selfie Video", "categories": ["cs.CV"], "comment": null, "summary": "Head avatar reenactment focuses on creating animatable personal avatars from monocular videos, serving as a foundational element for applications like social signal understanding, gaming, human-machine interaction, and computer vision. Recent advances in 3D Morphable Model (3DMM)-based facial reconstruction methods have achieved remarkable high-fidelity face estimation. However, on the one hand, they struggle to capture the entire head, including non-facial regions and background details in real time, which is an essential aspect for producing realistic, high-fidelity head avatars. On the other hand, recent approaches leveraging generative adversarial networks (GANs) for head avatar generation from videos can achieve high-quality reenactments but encounter limitations in reproducing fine-grained head details, such as wrinkles and hair textures. In addition, existing methods generally rely on a large amount of training data, and rarely focus on using only a simple selfie video to achieve avatar reenactment. To address these challenges, this study introduces a method for detailed head avatar reenactment using a selfie video. The approach combines 3DMMs with a StyleGAN-based generator. A detailed reconstruction model is proposed, incorporating mixed loss functions for foreground reconstruction and avatar image generation during adversarial training to recover high-frequency details. Qualitative and quantitative evaluations on self-reenactment and cross-reenactment tasks demonstrate that the proposed method achieves superior head avatar reconstruction with rich and intricate textures compared to existing approaches.", "AI": {"tldr": "本文提出了一种使用自拍视频进行详细头部头像再现的方法，结合了3DMM和StyleGAN生成器。", "motivation": "现有方法难以在实时捕获整个头部细节的同时保持高保真度，并且在生成精细的头部纹理时存在局限性。此外，大多数方法需要大量训练数据，而本文专注于仅使用自拍视频实现头像再现。", "method": "该方法结合了3DMM和StyleGAN生成器，并提出了一个详细的重建模型，利用混合损失函数进行前景重建和头像图像生成的对抗训练以恢复高频细节。", "result": "在自我再现和跨再现任务上进行了定性和定量评估，证明该方法实现了比现有方法更出色的头部头像重建效果，具有丰富而复杂的纹理。", "conclusion": "通过结合3DMM和StyleGAN技术，本文的方法能够从简单的自拍视频中生成高质量的、细节丰富的头部头像。"}}
{"id": "2601.18849", "pdf": "https://arxiv.org/pdf/2601.18849", "abs": "https://arxiv.org/abs/2601.18849", "authors": ["Yuhui Zhang", "Hui Yu", "Wei Liang", "Sunjie Zhang"], "title": "Audio-Driven Talking Face Generation with Blink Embedding and Hash Grid Landmarks Encoding", "categories": ["cs.CV"], "comment": null, "summary": "Dynamic Neural Radiance Fields (NeRF) have demonstrated considerable success in generating high-fidelity 3D models of talking portraits. Despite significant advancements in the rendering speed and generation quality, challenges persist in accurately and efficiently capturing mouth movements in talking portraits. To tackle this challenge, we propose an automatic method based on blink embedding and hash grid landmarks encoding in this study, which can substantially enhance the fidelity of talking faces. Specifically, we leverage facial features encoded as conditional features and integrate audio features as residual terms into our model through a Dynamic Landmark Transformer. Furthermore, we employ neural radiance fields to model the entire face, resulting in a lifelike face representation. Experimental evaluations have validated the superiority of our approach to existing methods.", "AI": {"tldr": "本文提出了一种基于眨眼嵌入和哈希网格特征编码的方法，用于生成逼真的说话人脸。", "motivation": "当前动态神经辐射场在生成高保真度的说话肖像方面存在挑战，特别是在准确捕获嘴部动作上。为此，文章提出了新的方法来提高说话面孔的真实性。", "method": "该方法利用面部特征作为条件特征，并通过动态地标变压器将音频特征集成到模型中；同时使用神经辐射场建模整个脸部。", "result": "实验结果验证了所提方法相较于现有技术具有显著优势，能够在保持高效的同时实现高质量的说话人脸生成。", "conclusion": "该研究证明了一种新的基于眨眼嵌入和哈希网格特征编码的方法在生成逼真的说话人脸方面是有效的。"}}
{"id": "2601.18847", "pdf": "https://arxiv.org/pdf/2601.18847", "abs": "https://arxiv.org/abs/2601.18847", "authors": ["Zihan Wu", "Jie Xu", "Yun Peng", "Chun Yong Chong", "Xiaohua Jia"], "title": "MulVul: Retrieval-augmented Multi-Agent Code Vulnerability Detection via Cross-Model Prompt Evolution", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) struggle to automate real-world vulnerability detection due to two key limitations: the heterogeneity of vulnerability patterns undermines the effectiveness of a single unified model, and manual prompt engineering for massive weakness categories is unscalable. To address these challenges, we propose \\textbf{MulVul}, a retrieval-augmented multi-agent framework designed for precise and broad-coverage vulnerability detection. MulVul adopts a coarse-to-fine strategy: a \\emph{Router} agent first predicts the top-$k$ coarse categories and then forwards the input to specialized \\emph{Detector} agents, which identify the exact vulnerability types. Both agents are equipped with retrieval tools to actively source evidence from vulnerability knowledge bases to mitigate hallucinations. Crucially, to automate the generation of specialized prompts, we design \\emph{Cross-Model Prompt Evolution}, a prompt optimization mechanism where a generator LLM iteratively refines candidate prompts while a distinct executor LLM validates their effectiveness. This decoupling mitigates the self-correction bias inherent in single-model optimization. Evaluated on 130 CWE types, MulVul achieves 34.79\\% Macro-F1, outperforming the best baseline by 41.5\\%. Ablation studies validate cross-model prompt evolution, which boosts performance by 51.6\\% over manual prompts by effectively handling diverse vulnerability patterns.", "AI": {"tldr": "本文提出了MulVul框架，用于自动化代码漏洞检测。", "motivation": "大型语言模型在现实世界中的漏洞检测中存在两个主要限制：单一统一模型的有效性受到漏洞模式异质性的挑战；手动提示工程对于大量弱点类别不具有可扩展性。为解决这些问题，设计了MulVul框架。", "method": "MulVul采用粗到细策略，使用路由代理预测前k个粗粒度类别，并将输入传递给专门的检测代理进行精确漏洞类型识别。引入跨模型提示进化机制来自动化生成专用提示，通过迭代优化和验证候选提示的有效性来缓解自校正偏差。", "result": "在130种CWE类型的评估中，MulVul达到了34.79％Macro-F1评分，超过最佳基线的41.5%，跨模型提示进化机制使性能比手动提示提升了51.6%。", "conclusion": "通过引入精细化策略和跨模型提示优化方法，MulVul在自动化代码漏洞检测方面表现出色。"}}
{"id": "2601.18846", "pdf": "https://arxiv.org/pdf/2601.18846", "abs": "https://arxiv.org/abs/2601.18846", "authors": ["Urban Skvorc", "Niki van Stein", "Moritz Seiler", "Britta Grimme", "Thomas Bäck", "Heike Trautmann"], "title": "LLM Driven Design of Continuous Optimization Problems with Controllable High-level Properties", "categories": ["cs.AI", "cs.NE"], "comment": "17 pages, accepted at EvoApplications 2026", "summary": "Benchmarking in continuous black-box optimisation is hindered by the limited structural diversity of existing test suites such as BBOB. We explore whether large language models embedded in an evolutionary loop can be used to design optimisation problems with clearly defined high-level landscape characteristics. Using the LLaMEA framework, we guide an LLM to generate problem code from natural-language descriptions of target properties, including multimodality, separability, basin-size homogeneity, search-space homogeneity and globallocal optima contrast. Inside the loop we score candidates through ELA-based property predictors. We introduce an ELA-space fitness-sharing mechanism that increases population diversity and steers the generator away from redundant landscapes. A complementary basin-of-attraction analysis, statistical testing and visual inspection, verifies that many of the generated functions indeed exhibit the intended structural traits. In addition, a t-SNE embedding shows that they expand the BBOB instance space rather than forming an unrelated cluster. The resulting library provides a broad, interpretable, and reproducible set of benchmark problems for landscape analysis and downstream tasks such as automated algorithm selection.", "AI": {"tldr": "该论文探讨了如何通过大型语言模型和进化循环设计具有明确高级景观特征的连续优化问题。", "motivation": "现有的基准测试在连续黑盒优化中受限于结构多样性不足的问题，作者希望通过嵌入进化循环的大规模语言模型生成具备特定高级属性的优化问题来解决这一难题。", "method": "利用LLaMEA框架指导大型语言模型从自然语言描述的目标属性生成问题代码，并通过基于ELA的属性预测器评估候选方案。引入了种群多样性增加和避免冗余景观机制，同时使用盆地吸引分析、统计测试以及视觉检验来验证结果。", "result": "许多生成的功能确实表现出预期的结构特征，并且扩展了BBOB实例空间而非形成无关簇。", "conclusion": "该方法为连续优化问题提供了广泛的、可解释的和可重复的基准，有利于景观分析及下游任务如自动化算法选择。"}}
{"id": "2601.18845", "pdf": "https://arxiv.org/pdf/2601.18845", "abs": "https://arxiv.org/abs/2601.18845", "authors": ["Zeineb Dridi", "Jihen Bennaceur", "Amine Ben Hassouna"], "title": "Dynamic Mask-Based Backdoor Attack Against Vision AI Models: A Case Study on Mushroom Detection", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning has revolutionized numerous tasks within the computer vision field, including image classification, image segmentation, and object detection. However, the increasing deployment of deep learning models has exposed them to various adversarial attacks, including backdoor attacks. This paper presents a novel dynamic mask-based backdoor attack method, specifically designed for object detection models. We exploit a dataset poisoning technique to embed a malicious trigger, rendering any models trained on this compromised dataset vulnerable to our backdoor attack. We particularly focus on a mushroom detection dataset to demonstrate the practical risks posed by such attacks on critical real-life domains. Our work also emphasizes the importance of creating a detailed backdoor attack scenario to illustrate the significant risks associated with the outsourcing practice. Our approach leverages SAM, a recent and powerful image segmentation AI model, to create masks for dynamic trigger placement, introducing a new and stealthy attack method. Through extensive experimentation, we show that our sophisticated attack scenario maintains high accuracy on clean data with the YOLOv7 object detection model while achieving high attack success rates on poisoned samples. Our approach surpasses traditional methods for backdoor injection, which are based on static and consistent patterns. Our findings underscore the urgent need for robust countermeasures to protect deep learning models from these evolving adversarial threats.", "AI": {"tldr": "本文提出了一种针对物体检测模型的动态掩码式后门攻击方法，通过利用数据集投毒技术嵌入恶意触发器，展示这种攻击对实际应用中的风险。", "motivation": "随着深度学习模型在计算机视觉领域的广泛应用，它们也面临着各种对抗性攻击的风险。本文旨在揭示一种新的动态掩码式后门攻击方法，以突显外包实践中存在的安全威胁，并强调需要开发有效的防御措施来保护这些模型。", "method": "通过使用SAM（一种强大的图像分割AI模型）生成的掩模进行动态触发器放置，作者提出了一种新颖且隐蔽的后门攻击方式。这种方法利用了数据集投毒技术将恶意模式嵌入到训练集中，使任何基于此中毒数据集训练的对象检测模型变得脆弱。", "result": "实验结果表明，该方法在使用YOLOv7物体检测模型时，在干净的数据上保持高准确率的同时对有毒样本实现了很高的攻击成功率。这证明了所提出的动态掩码后门攻击比传统的静态模式注入更有效且难以检测。", "conclusion": "本文的研究强调了开发针对深度学习模型的新型对抗威胁保护机制的重要性，这些威胁可能会随着技术的发展而演变。"}}
{"id": "2601.18844", "pdf": "https://arxiv.org/pdf/2601.18844", "abs": "https://arxiv.org/abs/2601.18844", "authors": ["Xueying Du", "Jiayi Feng", "Yi Zou", "Wei Xu", "Jie Ma", "Wei Zhang", "Sisi Liu", "Xin Peng", "Yiling Lou"], "title": "Reducing False Positives in Static Bug Detection with LLMs: An Empirical Study in Industry", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Static analysis tools (SATs) are widely adopted in both academia and industry for improving software quality, yet their practical use is often hindered by high false positive rates, especially in large-scale enterprise systems. These false alarms demand substantial manual inspection, creating severe inefficiencies in industrial code review. While recent work has demonstrated the potential of large language models (LLMs) for false alarm reduction on open-source benchmarks, their effectiveness in real-world enterprise settings remains unclear. To bridge this gap, we conduct the first comprehensive empirical study of diverse LLM-based false alarm reduction techniques in an industrial context at Tencent, one of the largest IT companies in China. Using data from Tencent's enterprise-customized SAT on its large-scale Advertising and Marketing Services software, we construct a dataset of 433 alarms (328 false positives, 105 true positives) covering three common bug types. Through interviewing developers and analyzing the data, our results highlight the prevalence of false positives, which wastes substantial manual effort (e.g., 10-20 minutes of manual inspection per alarm). Meanwhile, our results show the huge potential of LLMs for reducing false alarms in industrial settings (e.g., hybrid techniques of LLM and static analysis eliminate 94-98% of false positives with high recall). Furthermore, LLM-based techniques are cost-effective, with per-alarm costs as low as 2.1-109.5 seconds and $0.0011-$0.12, representing orders-of-magnitude savings compared to manual review. Finally, our case analysis further identifies key limitations of LLM-based false alarm reduction in industrial settings.", "AI": {"tldr": "本文研究了大型语言模型在工业环境中减少静态分析工具误报的有效性。", "motivation": "静态代码分析工具广泛应用于提高软件质量，但高误报率导致大量不必要的手工审查，严重影响生产效率。本文旨在通过实证研究探讨大型语言模型减少误报的潜力。", "method": "本研究在腾讯的大规模广告和市场营销服务软件中构建了一个包含433个报警的数据集，并使用混合技术（结合LLM与静态分析）评估了不同LLM方法的效果。", "result": "研究表明，LLM可以显著减少工业环境中的误报率（94%-98%），并且具有较低的成本效益。然而也存在一定的局限性需要进一步研究解决。", "conclusion": "大型语言模型在降低静态代码分析工具的误报警告中显示出巨大的潜力和成本节约效果，但仍需关注其实际应用中存在的挑战和限制。"}}
{"id": "2601.18842", "pdf": "https://arxiv.org/pdf/2601.18842", "abs": "https://arxiv.org/abs/2601.18842", "authors": ["Yanxi Wang", "Zhiling Zhang", "Wenbo Zhou", "Weiming Zhang", "Jie Zhang", "Qiannan Zhu", "Yu Shi", "Shuxin Zheng", "Jiyan He"], "title": "GUIGuard: Toward a General Framework for Privacy-Preserving GUI Agents", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": null, "summary": "GUI agents enable end-to-end automation through direct perception of and interaction with on-screen interfaces. However, these agents frequently access interfaces containing sensitive personal information, and screenshots are often transmitted to remote models, creating substantial privacy risks. These risks are particularly severe in GUI workflows: GUIs expose richer, more accessible private information, and privacy risks depend on interaction trajectories across sequential scenes. We propose GUIGuard, a three-stage framework for privacy-preserving GUI agents: (1) privacy recognition, (2) privacy protection, and (3) task execution under protection. We further construct GUIGuard-Bench, a cross-platform benchmark with 630 trajectories and 13,830 screenshots, annotated with region-level privacy grounding and fine-grained labels of risk level, privacy category, and task necessity. Evaluations reveal that existing agents exhibit limited privacy recognition, with state-of-the-art models achieving only 13.3% accuracy on Android and 1.4% on PC. Under privacy protection, task-planning semantics can still be maintained, with closed-source models showing stronger semantic consistency than open-source ones. Case studies on MobileWorld show that carefully designed protection strategies achieve higher task accuracy while preserving privacy. Our results highlight privacy recognition as a critical bottleneck for practical GUI agents. Project: https://futuresis.github.io/GUIGuard-page/", "AI": {"tldr": "GUIGuard是一个用于保护GUI代理隐私的三阶段框架，它包括隐私识别、隐私保护和受保护的任务执行。", "motivation": "在自动化过程中，GUI代理需要直接感知和与屏幕界面交互，这可能导致暴露个人敏感信息的风险。现有的隐私保护措施不足，尤其是在跨平台环境中。", "method": "GUIGuard框架由三个阶段组成：隐私识别、隐私保护以及任务执行时的隐私保护。研究者还构建了一个名为GUIGuard-Bench的基准测试，其中包括630条轨迹和13,830张截图，并且进行了详细标注以评估隐私风险。", "result": "现有的GUI代理在隐私识别方面表现不佳；即使是最佳模型也只达到了13.3%（Android）和1.4%（PC）的准确性。然而，当采取适当的保护策略时，在保持任务准确性的前提下可以有效保护隐私。", "conclusion": "本研究强调了提高GUI代理在隐私识别方面能力的重要性，并通过案例研究展示了精心设计的隐私保护策略可以在不损害任务性能的情况下确保用户隐私。"}}
{"id": "2601.18834", "pdf": "https://arxiv.org/pdf/2601.18834", "abs": "https://arxiv.org/abs/2601.18834", "authors": ["Deep Mehta"], "title": "CanaryBench: Stress Testing Privacy Leakage in Cluster-Level Conversation Summaries", "categories": ["cs.CR", "cs.AI"], "comment": "13 pages, 4 figures. Code repository: https://github.com/researchaudio/canarybench", "summary": "Aggregate analytics over conversational data are increasingly used for safety monitoring, governance, and product analysis in large language model systems. A common practice is to embed conversations, cluster them, and publish short textual summaries describing each cluster. While raw conversations may never be exposed, these derived summaries can still pose privacy risks if they contain personally identifying information (PII) or uniquely traceable strings copied from individual conversations. We introduce CanaryBench, a simple and reproducible stress test for privacy leakage in cluster-level conversation summaries. CanaryBench generates synthetic conversations with planted secret strings (\"canaries\") that simulate sensitive identifiers. Because canaries are known a priori, any appearance of these strings in published summaries constitutes a measurable leak. Using TF-IDF embeddings and k-means clustering on 3,000 synthetic conversations (24 topics) with a canary injection rate of 0.60, we evaluate an intentionally extractive example snippet summarizer that models quote-like reporting. In this configuration, we observe canary leakage in 50 of 52 canary-containing clusters (cluster-level leakage rate 0.961538), along with nonzero regex-based PII indicator counts. A minimal defense combining a minimum cluster-size publication threshold (k-min = 25) and regex-based redaction eliminates measured canary leakage and PII indicator hits in the reported run while maintaining a similar cluster-coherence proxy. We position this work as a societal impacts contribution centered on privacy risk measurement for published analytics artifacts rather than raw user data.", "AI": {"tldr": "CanaryBench是一个用于测试集群级对话摘要隐私泄露风险的简单可重复的压力测试。", "motivation": "随着大规模语言模型系统中对聚合分析的需求增加，生成并发布描述每个聚类的简短文本摘要已经成为一种常见做法。然而，这种衍生摘要可能会泄漏个人身份信息或独特字符串，从而导致隐私风险。", "method": "CanaryBench通过在合成对话中插入已知的敏感标识符（“canaries”），模拟潜在的隐私泄露场景，并使用TF-IDF嵌入和k-means聚类方法评估汇总工具对这些标记的处理能力。此外，提出了一种防御策略，结合最小集群大小阈值和正则表达式红行动以消除可测量的canary泄漏。", "result": "在3000个合成对话中（24个话题），CanaryBench检测到52个包含canary的聚类中有50个存在canary泄露，即集群级泄露率为96.15%。应用防御策略后，可以完全消除可测量的canary泄漏和正则表达式PII指标。", "conclusion": "CanaryBench有助于评估发布分析成果中的隐私风险，并提出了一种有效的防御机制来减少或防止此类风险。"}}
{"id": "2601.18833", "pdf": "https://arxiv.org/pdf/2601.18833", "abs": "https://arxiv.org/abs/2601.18833", "authors": ["Marlon Dumas", "Fredrik Milani", "David Chapela-Campa"], "title": "Agentic Business Process Management Systems", "categories": ["cs.AI", "cs.SE"], "comment": "Presented at the BPM'2025 conference on Artificial Intelligence for Business Process Management (AI4BPM)", "summary": "Since the early 90s, the evolution of the Business Process Management (BPM) discipline has been punctuated by successive waves of automation technologies. Some of these technologies enable the automation of individual tasks, while others focus on orchestrating the execution of end-to-end processes. The rise of Generative and Agentic Artificial Intelligence (AI) is opening the way for another such wave. However, this wave is poised to be different because it shifts the focus from automation to autonomy and from design-driven management of business processes to data-driven management, leveraging process mining techniques. This position paper, based on a keynote talk at the 2025 Workshop on AI for BPM, outlines how process mining has laid the foundations on top of which agents can sense process states, reason about improvement opportunities, and act to maintain and optimize performance. The paper proposes an architectural vision for Agentic Business Process Management Systems (A-BPMS): a new class of platforms that integrate autonomy, reasoning, and learning into process management and execution. The paper contends that such systems must support a continuum of processes, spanning from human-driven to fully autonomous, thus redefining the boundaries of process automation and governance.", "AI": {"tldr": "本文提出了代理商务流程管理系统的架构愿景，这些系统通过自主性和学习能力优化业务流程。", "motivation": "随着生成式和代理人工智能的发展，BPM领域迎来了新的自动化浪潮。这一波不同于以往的是，它强调从自动化转向自治，并推动了基于数据驱动的管理模式发展。", "method": "基于一个关于AI在BPM中的应用的关键演讲，本文概述了如何利用过程挖掘技术使系统能够感知流程状态、分析改进机会并采取行动来维护和优化性能。", "result": "提出了A-BPMS的概念，并建议该平台需要支持从人驱动到完全自主的过程连续体。", "conclusion": "这些集成自治性、推理能力和学习能力的BPMS将重新定义流程自动化和治理的界限。"}}
{"id": "2601.18832", "pdf": "https://arxiv.org/pdf/2601.18832", "abs": "https://arxiv.org/abs/2601.18832", "authors": ["Ren Zhuang", "Ben Wang", "Shuifa Sun"], "title": "The Geometric Reasoner: Manifold-Informed Latent Foresight Search for Long-Context Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 5 figures", "summary": "Scaling test-time compute enhances long chain-of-thought (CoT) reasoning, yet existing approaches face a fundamental trade-off between computational cost and coverage quality: either incurring high training expense or yielding redundant trajectories. We introduce The Geometric Reasoner (TGR), a training-free framework that performs manifold-informed latent foresight search under strict memory bounds. At each chunk boundary, TGR scores candidate latent anchors via a lightweight look-ahead estimate combined with soft geometric regularizers that encourage smooth trajectories and diverse exploration. Chunk-wise KV cache resets keep memory linear in chunk length. On challenging math and code benchmarks, TGR improves robust trajectory coverage, measured by the area under the Pass@$k$ curve (AUC), by up to 13 points on Qwen3-8B, with negligible overhead of about 1.1--1.3 times.", "AI": {"tldr": "介绍了一种名为The Geometric Reasoner (TGR)的训练自由框架，用于提高长链推理的质量。", "motivation": "现有的方法在计算成本和覆盖率质量之间存在根本性的权衡：要么产生高昂的训练费用，要么生成冗余轨迹。为了克服这一挑战，提出了新的解决方案以提升长链推理的能力。", "method": "TGR通过轻量级前瞻估计结合软几何正则化器，在每个块边界处为候选潜在锚点评分，鼓励平滑轨迹和多样化的探索，并保持线性内存约束。", "result": "在挑战性的数学和代码基准测试中，TGR提高了13个AUC的稳健轨迹覆盖率，同时只带来了大约1.1到1.3倍的额外开销。", "conclusion": "TGR框架展示了在不增加训练成本的情况下提升长链推理质量的强大潜力。"}}
{"id": "2601.18829", "pdf": "https://arxiv.org/pdf/2601.18829", "abs": "https://arxiv.org/abs/2601.18829", "authors": ["Yaohua Zha", "Chunlin Fan", "Peiyuan Liu", "Yong Jiang", "Tao Dai", "Hai Wu", "Shu-Tao Xia"], "title": "CP Loss: Channel-wise Perceptual Loss for Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICASSP 2026", "summary": "Multi-channel time-series data, prevalent across diverse applications, is characterized by significant heterogeneity in its different channels. However, existing forecasting models are typically guided by channel-agnostic loss functions like MSE, which apply a uniform metric across all channels. This often leads to fail to capture channel-specific dynamics such as sharp fluctuations or trend shifts. To address this, we propose a Channel-wise Perceptual Loss (CP Loss). Its core idea is to learn a unique perceptual space for each channel that is adapted to its characteristics, and to compute the loss within this space. Specifically, we first design a learnable channel-wise filter that decomposes the raw signal into disentangled multi-scale representations, which form the basis of our perceptual space. Crucially, the filter is optimized jointly with the main forecasting model, ensuring that the learned perceptual space is explicitly oriented towards the prediction task. Finally, losses are calculated within these perception spaces to optimize the model. Code is available at https://github.com/zyh16143998882/CP_Loss.", "AI": {"tldr": "提出一种针对多通道时间序列数据的通道感知损失函数CP Loss，以解决现有模型在处理不同通道特征时的不足。", "motivation": "现有的预测模型使用统一的损失函数（如MSE），忽略了各个通道的特性差异，导致无法捕捉到特定于某个通道的动力学特征，如尖锐波动或趋势变化。", "method": "设计了一种学习型通道过滤器以分解原始信号为解耦多尺度表示，并基于此构建感知空间。该滤波器与主预测模型联合优化，确保所学习的感知空间导向预测任务。在这些感知空间中计算损失函数。", "result": "未提供具体实验结果和数据支持。", "conclusion": "CP Loss通过通道特定的空间优化了多通道时间序列数据的预测准确性，改进了现有统一损失函数的局限性。"}}
{"id": "2601.18828", "pdf": "https://arxiv.org/pdf/2601.18828", "abs": "https://arxiv.org/abs/2601.18828", "authors": ["Mohammad Zare"], "title": "IPBC: An Interactive Projection-Based Framework for Human-in-the-Loop Semi-Supervised Clustering of High-Dimensional Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "High-dimensional datasets are increasingly common across scientific and industrial domains, yet they remain difficult to cluster effectively due to the diminishing usefulness of distance metrics and the tendency of clusters to collapse or overlap when projected into lower dimensions. Traditional dimensionality reduction techniques generate static 2D or 3D embeddings that provide limited interpretability and do not offer a mechanism to leverage the analyst's intuition during exploration. To address this gap, we propose Interactive Project-Based Clustering (IPBC), a framework that reframes clustering as an iterative human-guided visual analysis process. IPBC integrates a nonlinear projection module with a feedback loop that allows users to modify the embedding by adjusting viewing angles and supplying simple constraints such as must-link or cannot-link relationships. These constraints reshape the objective of the projection model, gradually pulling semantically related points closer together and pushing unrelated points further apart. As the projection becomes more structured and expressive through user interaction, a conventional clustering algorithm operating on the optimized 2D layout can more reliably identify distinct groups. An additional explainability component then maps each discovered cluster back to the original feature space, producing interpretable rules or feature rankings that highlight what distinguishes each cluster. Experiments on various benchmark datasets show that only a small number of interactive refinement steps can substantially improve cluster quality. Overall, IPBC turns clustering into a collaborative discovery process in which machine representation and human insight reinforce one another.", "AI": {"tldr": "提出了一种基于交互式投影框架的半监督聚类方法，用于高维数据集。", "motivation": "针对高维数据集中由于维度灾难导致的传统降维技术难以有效聚类的问题，设计了一个可以利用人类直觉进行探索和调整的互动系统来改善聚类质量。", "method": "IPBC整合了非线性投影模块与反馈循环机制，允许用户通过改变视角并提供约束关系（如必须连接或不能连接）来修改嵌入。这种交互式过程使机器表示和人类洞察力相互加强。", "result": "实验表明，在各种基准数据集上进行少量互动改进步骤即可显著提高聚类质量。", "conclusion": "IPBC将聚类转化为一种人机协作的发现流程，其中机器表示与人类直觉互相补充，提高了高维数据的有效分析能力。"}}
{"id": "2601.18827", "pdf": "https://arxiv.org/pdf/2601.18827", "abs": "https://arxiv.org/abs/2601.18827", "authors": ["Jens Kohl", "Otto Kruse", "Youssef Mostafa", "Andre Luckow", "Karsten Schroer", "Thomas Riedl", "Ryan French", "David Katz", "Manuel P. Luitz", "Tanrajbir Takher", "Ken E. Friedl", "Céline Laurent-Winter"], "title": "Automated structural testing of LLM-based agents: methods, framework, and case studies", "categories": ["cs.SE", "cs.AI"], "comment": "10 pages, 5 figures. Preprint of an accepted paper at IEEE BigData 2025 (main track). Source code for the introduced methods and framework available at https://github.com/awslabs/generative-ai-toolkit", "summary": "LLM-based agents are rapidly being adopted across diverse domains. Since they interact with users without supervision, they must be tested extensively. Current testing approaches focus on acceptance-level evaluation from the user's perspective. While intuitive, these tests require manual evaluation, are difficult to automate, do not facilitate root cause analysis, and incur expensive test environments. In this paper, we present methods to enable structural testing of LLM-based agents. Our approach utilizes traces (based on OpenTelemetry) to capture agent trajectories, employs mocking to enforce reproducible LLM behavior, and adds assertions to automate test verification. This enables testing agent components and interactions at a deeper technical level within automated workflows. We demonstrate how structural testing enables the adaptation of software engineering best practices to agents, including the test automation pyramid, regression testing, test-driven development, and multi-language testing. In representative case studies, we demonstrate automated execution and faster root-cause analysis. Collectively, these methods reduce testing costs and improve agent quality through higher coverage, reusability, and earlier defect detection. We provide an open source reference implementation on GitHub.", "AI": {"tldr": "论文提出了针对基于LLM的代理进行结构化测试的方法，包括轨迹捕获、模拟和断言验证。", "motivation": "当前的测试方法主要从用户角度出发，需要手动评估且难以自动化。为了改进这些问题并降低测试成本，提高质量，作者提出了一种新的测试框架。", "method": "论文采用基于OpenTelemetry的追踪技术来捕获代理行为轨迹，并使用模拟技术强制重复执行LLM的行为模式，通过添加断言以实现自动验证。", "result": "案例研究展示了结构化测试能够支持自动化运行和更快速的问题根源分析。这些方法有助于减少成本、提高覆盖率和可重用性，并且能更快地检测到缺陷。", "conclusion": "论文提供了一种新的基于LLM代理的结构化测试框架，该框架能够在软件开发中采用最佳实践如自动化测试金字塔、回归测试等，并且已经开源在GitHub上。"}}
{"id": "2601.18824", "pdf": "https://arxiv.org/pdf/2601.18824", "abs": "https://arxiv.org/abs/2601.18824", "authors": ["Zhiyu An", "Duaa Nakshbandi", "Wan Du"], "title": "Differential Voting: Loss Functions For Axiomatically Diverse Aggregation of Heterogeneous Preferences", "categories": ["cs.GT", "cs.AI"], "comment": null, "summary": "Reinforcement learning from human feedback (RLHF) implicitly aggregates heterogeneous human preferences into a single utility function, even though the underlying utilities of the participants are in practice diverse. Hence, RLHF can be viewed as a form of voting, where the aggregation mechanism is defined by the loss function. Although Arrow's Impossibility Theorem suggests that different mechanisms satisfy different sets of desirable axioms, most existing methods rely on a single aggregation principle, typically the Bradley-Terry-Luce (BTL) model, which corresponds to Borda count voting. This restricts the axiomatic properties of the learned reward and obscures the normative assumptions embedded in optimization. In this work, we introduce Differential Voting, a unifying framework that constructs instance-wise, differentiable loss functions whose population-level optima provably correspond to distinct classical voting rules. We develop differentiable surrogates for majority-based aggregation (BTL), Copeland, and Kemeny rules, and formally analyze their calibration properties, gradient fields, and limiting behavior as smoothing parameters vanish. For each loss, we establish consistency with the corresponding social choice rule and characterize the axioms it satisfies or violates. Our analysis shows how design choices in loss geometry-such as margin sensitivity and boundary concentration-directly translate into normative aggregation behavior. Differential Voting makes preference aggregation an explicit and controllable design choice in RLHF, enabling principled trade-offs between axiomatic guarantees and optimization stability. Code to reproduce our experiments is open-sourced.", "AI": {"tldr": "提出了Differential Voting框架，通过构建实例级别的可微损失函数来统一不同的偏好聚合方法。", "motivation": "现有的RLHF方法主要依赖单一的Bradley-Terry-Luce模型，这限制了学习奖励的功能特性并掩盖了优化过程中的规范性假设。作者旨在引入一种新的框架以使偏好聚合成为显式且可控的设计选择。", "method": "提出了Differential Voting框架，开发了多数投票、Copeland规则和Kemeny规则的可微近似，并分析了它们的校准特性、梯度场以及随着平滑参数消失时的行为。", "result": "证明了所提出的损失函数在人口层面上与相应的社会选择规则一致，并且能够明确满足或违反哪些公理。", "conclusion": "Differential Voting框架使偏好聚合成为RLHF中的显式和可控设计选项，可以进行规范保证与优化稳定性之间的原则性权衡。"}}
{"id": "2601.18821", "pdf": "https://arxiv.org/pdf/2601.18821", "abs": "https://arxiv.org/abs/2601.18821", "authors": ["Avinash Kadimisetty", "Oswald C", "Sivaselvan B", "Alekhya Kadimisetty"], "title": "Lossy Image Compression -- A Frequent Sequence Mining perspective employing efficient Clustering", "categories": ["eess.IV", "cs.AI", "cs.MM"], "comment": null, "summary": "This work explores the scope of Frequent Sequence Mining in the domain of Lossy Image Compression. The proposed work is based on the idea of clustering pixels and using the cluster identifiers in the compression. The DCT phase in JPEG is replaced with a combination of closed frequent sequence mining and k-means clustering to handle the redundant data effectively. This method focuses mainly on applying k-means clustering in parallel to all blocks of each component of the image to reduce the compression time. Conventional GSP algorithm is refined to optimize the cardinality of patterns through a novel pruning strategy, thus achieving a good reduction in the code table size. Simulations of the proposed algorithm indicate significant gains in compression ratio and quality in relation to the existing alternatives.", "AI": {"tldr": "本文探讨了在有损图像压缩领域中运用频繁序列挖掘的方法。通过结合封闭频序列挖掘和k-means聚类来处理冗余数据，并使用新的剪枝策略优化模式基数，从而减少代码表大小。", "motivation": "提出了一种基于像素簇标识符的新型图像压缩方法，旨在通过更有效的冗余数据处理技术提高压缩效率和质量。", "method": "将JPEG中的DCT阶段替换为封闭频繁序列挖掘与k-means聚类相结合的方式，并应用改进后的GSP算法优化模式基数。", "result": "实验表明所提出的方法在压缩比率和图像质量方面均优于现有方法。", "conclusion": "该研究展示了通过频繁序列挖掘结合高效聚类技术进行有损图像压缩的可行性和优越性。"}}
{"id": "2601.18818", "pdf": "https://arxiv.org/pdf/2601.18818", "abs": "https://arxiv.org/abs/2601.18818", "authors": ["Marc Grimson", "Joshua Fan", "Courtney L. Davis", "Dylan van Bramer", "Daniel Fink", "Carla P. Gomes"], "title": "LabelKAN -- Kolmogorov-Arnold Networks for Inter-Label Learning: Avian Community Learning", "categories": ["q-bio.QM", "cs.AI", "q-bio.PE"], "comment": null, "summary": "Global biodiversity loss is accelerating, prompting international efforts such as the Kunming-Montreal Global Biodiversity Framework (GBF) and the United Nations Sustainable Development Goals to direct resources toward halting species declines. A key challenge in achieving this goal is having access to robust methodologies to understand where species occur and how they relate to each other within broader ecological communities. Recent deep learning-based advances in joint species distribution modeling have shown improved predictive performance, but effectively incorporating community-level learning, taking into account species-species relationships in addition to species-environment relationships, remains an outstanding challenge. We introduce LabelKAN, a novel framework based on Kolmogorov-Arnold Networks (KANs) to learn inter-label connections from predictions of each label. When modeling avian species distributions, LabelKAN achieves substantial gains in predictive performance across the vast majority of species. In particular, our method demonstrates strong improvements for rare and difficult-to-predict species, which are often the most important when setting biodiversity targets under frameworks like GBF. These performance gains also translate to more confident predictions of the species spatial patterns as well as more confident predictions of community structure. We illustrate how the LabelKAN leads to qualitative and quantitative improvements with a focused application on the Great Blue Heron, an emblematic species in freshwater ecosystems that has experienced significant population declines across the United States in recent years. Using the LabelKAN framework, we are able to identify communities and species in New York that will be most sensitive to further declines in Great Blue Heron populations.", "AI": {"tldr": "基于Kolmogorov-Arnold网络（KAN）提出LabelKAN框架，用于学习物种间关系以改进鸟类分布模型。", "motivation": "全球生物多样性丧失加速，迫切需要有效方法理解物种在生态系统中的位置及其相互关系。现有深度学习技术在联合物种分布建模方面取得了进步，但尚缺乏充分考虑物种间关系的方法。", "method": "提出LabelKAN框架，基于Kolmogorov-Arnold网络（KAN）从每个标签的预测中学习跨标签连接，提高模型对稀有种和难以预测种群的表现。", "result": "在鸟类分布建模中，LabelKAN提高了大多数物种的预测性能，特别是对于稀有且难预测的物种。该方法不仅提高了预测准确性和置信度，还增强了生态社区结构的理解。", "conclusion": "通过LabelKAN框架，在美国纽约地区识别出对大蓝鹭种群进一步下降最敏感的社区和物种，证明了其在生物多样性保护中的潜在价值。"}}
{"id": "2601.18814", "pdf": "https://arxiv.org/pdf/2601.18814", "abs": "https://arxiv.org/abs/2601.18814", "authors": ["Jingsong Xia"], "title": "Lightweight Quantum-Enhanced ResNet for Coronary Angiography Classification: A Hybrid Quantum-Classical Feature Enhancement Framework", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": ":I.2.7; F.2.2", "summary": "Background: Coronary angiography (CAG) is the cornerstone imaging modality for evaluating coronary artery stenosis and guiding interventional decision-making. However, interpretation based on single-frame angiographic images remains highly operator-dependent, and conventional deep learning models still face challenges in modeling complex vascular morphology and fine-grained texture patterns.Methods: We propose a Lightweight Quantum-Enhanced ResNet (LQER) for binary classification of coronary angiography images. A pretrained ResNet18 is employed as a classical feature extractor, while a parameterized quantum circuit (PQC) is introduced at the high-level semantic feature space for quantum feature enhancement. The quantum module utilizes data re-uploading and entanglement structures, followed by residual fusion with classical features, enabling end-to-end hybrid optimization with a strictly controlled number of qubits.Results: On an independent test set, the proposed LQER outperformed the classical ResNet18 baseline in accuracy, AUC, and F1-score, achieving a test accuracy exceeding 90%. The results demonstrate that lightweight quantum feature enhancement improves discrimination of positive lesions, particularly under class-imbalanced conditions.Conclusion: This study validates a practical hybrid quantum--classical learning paradigm for coronary angiography analysis, providing a feasible pathway for deploying quantum machine learning in medical imaging applications.", "AI": {"tldr": "本文提出了一种轻量级的量子增强残差网络（LQER）用于冠状动脉造影图像的二分类任务。", "motivation": "传统深度学习模型在处理复杂的血管形态和细粒度纹理模式方面存在挑战，冠状动脉造影图像解释依赖于操作者。为解决这一问题，提出了利用量子增强方法改进经典特征提取器。", "method": "使用预训练的ResNet18作为经典的特征提取器，并引入参数化量子电路（PQC）在高层次语义特征空间进行量子特征增强。通过残差融合与经典特征相结合，实现了端到端混合优化，同时严格控制了量子比特的数量。", "result": "实验表明，在独立测试集上提出的LQER模型比传统ResNet18基线模型具有更高的准确率、AUC和F1分数，测试准确率达到90%以上。结果还显示轻量级量子特征增强在不平衡数据条件下对正病变的区分能力更强。", "conclusion": "研究验证了一种实用的混合量子-经典学习范式用于冠状动脉造影分析，并提供了将量子机器学习应用于医学影像应用领域的可行途径"}}
{"id": "2601.18802", "pdf": "https://arxiv.org/pdf/2601.18802", "abs": "https://arxiv.org/abs/2601.18802", "authors": ["Louis Rosenberg"], "title": "AI-Powered Augmented Reality as a Threat Vector for Human Manipulation", "categories": ["cs.CY", "cs.HC"], "comment": "Citation of this book chapter: Rosenberg, Louis (2025) AI-Powered Augmented Reality as a Threat Vector for Human Manipulation. In book Augmented Reality - Situated Spatial Synergy. http://dx.doi.org/10.5772/intechopen.1011751", "summary": "Augmented Reality (AR) is a powerful perceptual technology that can alter what users see, hear, feel, and experience throughout their daily lives. When combined with the speed and flexibility of context-aware generative AI, the power is greatly expanded, allowing individual users to be targeted with custom-generated AR experiences that are instantly tailored to who they are, where they are, and what they are doing. This can transform the physical world into a magical place, but only if the augmentation of a user's environment is enacted for their personal benefit and best interests. Instead, if AI-powered AR systems are controlled by unregulated third parties, such as large corporations or state actors, individually adaptive AR experiences could be deployed as a dangerous form of targeted influence. In fact, if the industry adopts an advertising business model for AI-powered AR devices, context-aware generative influence could become a widely used manipulative path for promotion of products and services in the physical world. Worse, similar techniques could be used for political influence, propaganda, and disinformation. This chapter reviews the power and flexibility of AI-generated augmented reality, explores the risks that emerge when used for persuasion, manipulation, or influence, and proposes policy directions to mitigate these risks.", "AI": {"tldr": "探讨人工智能驱动的增强现实技术对人类操纵的风险。", "motivation": "为了防止大型企业或国家行为者利用不受监管的人工智能生成的增强现实系统进行针对性影响，本文审视了这种技术的安全性问题。", "method": "通过回顾AI生成的AR技术的力量和灵活性，并探讨其在说服、操控或影响力方面带来的风险，提出政策建议来缓解这些问题。", "result": "识别并评估了人工智能驱动的AR技术可能带来的各种操纵风险，包括广告推广、政治影响以及宣传和虚假信息传播。", "conclusion": "强调需要制定相关政策来管理AI生成的增强现实技术的应用，以防止其被滥用。"}}
{"id": "2601.18800", "pdf": "https://arxiv.org/pdf/2601.18800", "abs": "https://arxiv.org/abs/2601.18800", "authors": ["Yoontae Hwang", "Dongwoo Lee", "Minseok Choi", "Yong Sup Ihn", "Daham Kim", "Deok-Young Lee"], "title": "NavFormer: IGRF Forecasting in Moving Coordinate Frames", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Triad magnetometer components change with sensor attitude even when the IGRF total intensity target stays invariant. NavFormer forecasts this invariant target with rotation invariant scalar features and a Canonical SPD module that stabilizes the spectrum of window level second moments of the triads without sign discontinuities. The module builds a canonical frame from a Gram matrix per window and applies state dependent spectral scaling in the original coordinates. Experiments across five flights show lower error than strong baselines in standard training, few shot training, and zero shot transfer. The code is available at: https://anonymous.4open.science/r/NavFormer-Robust-IGRF-Forecasting-for-Autonomous-Navigators-0765", "AI": {"tldr": "本文提出了NavFormer，一种在移动坐标系中进行IGRF预测的方法。", "motivation": "磁力计组件随传感器姿态变化而改变，即使当IGRF总强度目标保持不变时。为了准确预测这种不变的目标值，需要开发一种新的方法来处理旋转不变性的问题。", "method": "NavFormer利用旋转不变的标量特征和一个标准正定矩阵（Canonical SPD）模块来稳定窗口级二阶矩谱并避免符号不连续性。通过构建每个窗口的Gram矩阵并应用状态依赖的频谱缩放，该方法能够在原始坐标中实现稳定的预测。", "result": "实验结果显示，在五个飞行测试中的标准训练、少量样本训练以及零样本迁移情况下，NavFormer均表现出比强大基线更低的误差率。", "conclusion": "本文提出的NavFormer在移动坐标系下成功实现了IGRF的准确预测，并且展示了良好的鲁棒性和泛化能力。"}}
{"id": "2601.18799", "pdf": "https://arxiv.org/pdf/2601.18799", "abs": "https://arxiv.org/abs/2601.18799", "authors": ["Christopher Burr", "Mark Enzer", "Jason Shepherd", "David Wagg"], "title": "Agentic Digital Twins: A Taxonomy of Capabilities for Understanding Possible Futures", "categories": ["cs.CY", "cs.AI", "cs.ET"], "comment": "32 pages, 6 figures", "summary": "As digital twins (DTs) evolve to become more agentic through the integration of artificial intelligence (AI), they acquire capabilities that extend beyond dynamic representation of their target systems. This paper presents a taxonomy of agentic DTs organised around three fundamental dimensions: the locus of agency (external, internal, distributed), the tightness of coupling (loose, tight, constitutive), and model evolution (static, adaptive, reconstructive). From the resulting 27-configuration space, we identify nine illustrative configurations grouped into three clusters: \"The Present\" (existing tools and emerging steering systems), \"The Threshold\" (where emergent properties appear and coupling becomes constitutive), and \"The Frontier\" (where systems gain reconstructive capabilities). Our analysis explores how agentic DTs exercise performative power--not merely representing physical systems but actively participating in constituting them. Using traffic navigation systems as examples, we show how even passive tools can exhibit emergent performativity, while advanced configurations risk performative lock-in. Drawing on performative prediction theory, we trace a progression from passive tools through active steering to ontological reconstruction, examining how constitutive coupling enables systems to create self-validating realities. Understanding these configurations is essential for navigating the transformation from DTs as mirror worlds to DTs as architects of new ontologies.", "AI": {"tldr": "本文提出了一种关于具有代理能力的数字孪生（DTs）的能力分类法，探讨了它们在不同配置下的表现和影响。", "motivation": "随着人工智能的发展，数字孪生开始具备更高级别的代理能力和潜在的影响。作者希望通过构建一种系统化的分类方法来理解和预测这种新的数字孪生形态可能带来的未来变化。", "method": "文章提出了一个基于三个维度（代理位置、耦合紧密度、模型演化）的27种配置空间，并将其分为三大类：现状、临界点和前沿，以此分析不同配置下的表现。", "result": "通过这一分类法，研究者展示了从被动工具到主动参与构成现实的不同阶段的过渡路径，以及各种代理性数字孪生在交通导航系统等实例中的应用。", "conclusion": "理解这些不同的配置对于应对由简单的镜像世界向构建新现实的转变至关重要。"}}
{"id": "2601.18798", "pdf": "https://arxiv.org/pdf/2601.18798", "abs": "https://arxiv.org/abs/2601.18798", "authors": ["William Han", "Tony Chen", "Chaojing Duan", "Xiaoyu Song", "Yihang Yao", "Yuzhe Yang", "Michael A. Rosenberg", "Emerson Liu", "Ding Zhao"], "title": "Encoder-Free ECG-Language Models", "categories": ["cs.MM", "cs.AI"], "comment": "16 pages, 4 figures", "summary": "ECG-Language Models (ELMs) extend recent progress in Multimodal Large Language Models (MLLMs) to automated ECG interpretation. However, most ELMs follow Vision-Language Model (VLM) designs and depend on pretrained ECG encoders, adding architectural and training complexity. Inspired by encoder-free VLMs, we introduce ELF, an encoder-free ELM that replaces the ECG encoder with a single projection layer trained jointly with the LLM. Across five datasets, ELF matches or exceeds state-of-the-art ELMs that use far more complex encoders and training pipelines. We also test whether adding architectural biases to ELF improves performance and find that the single linear projection remains competitive. Finally, we show that ELF, and potentially other ELMs, often rely more on benchmark artifacts and language priors than ECG-derived information, highlighting limitations in current evaluation practices and ELM design. All data and code is available at https://github.com/willxxy/ECG-Bench.", "AI": {"tldr": "本文介绍了一种无编码器的ECG语言模型ELF，通过将单个投影层与LLM联合训练来简化现有模型的设计。", "motivation": "大多数ECG语言模型依赖于预训练的ECG编码器，这增加了架构和训练复杂性。为了减少这种复杂性并提高性能，本文提出了无编码器的方法。", "method": "ELF通过使用单个线性投影层替换传统的ECG编码器，并与LLM联合训练来工作。该模型在五个数据集上进行了评估。", "result": "实验结果表明，ELF在多个数据集中达到了或超过了现有的最先进的ECG语言模型性能，这些模型采用了更加复杂的架构和训练方法。", "conclusion": "研究发现单个线性投影层可以保持竞争力，并指出当前的评估实践可能更多依赖于基准测试中的偏见而非真实的ECG信息。"}}
{"id": "2601.18796", "pdf": "https://arxiv.org/pdf/2601.18796", "abs": "https://arxiv.org/abs/2601.18796", "authors": ["Brian Ondov", "Chia-Hsuan Chang", "Yujia Zhou", "Mauro Giuffrè", "Hua Xu"], "title": "ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond.", "AI": {"tldr": "该论文提出了一种名为ctELM的方法，用于解码和操纵临床试验的嵌入空间。", "motivation": "当前解释、探索和逆向工程嵌入空间的方法有限，这减少了透明度并阻止了潜在有价值的应用场景。因此，开发一种可以理解和生成临床试验的新方法是必要的。", "method": "论文采用最近报道的Embedding语言模型（ELM）方法，将大规模语言模型与临床试验的文本嵌入对齐。通过设计特定任务和训练框架，构建了一个开源且领域无关的ELM架构，并使用专家验证过的合成数据集进行训练。", "result": "最终模型ctELM能够仅从嵌入中准确描述并比较未见过的临床试验，并能根据新向量生成可信的临床试验。此外，通过沿年龄和性别概念向量移动嵌入，可以响应地调整生成的摘要内容。", "conclusion": "该论文的结果表明，公共ELM实现和支持的大规模语言模型与嵌入空间对齐，有助于在生物医学领域和其他领域中应用。"}}
{"id": "2601.18795", "pdf": "https://arxiv.org/pdf/2601.18795", "abs": "https://arxiv.org/abs/2601.18795", "authors": ["Amrith Setlur", "Zijian Wang", "Andrew Cohen", "Paria Rashidinejad", "Sang Michael Xie"], "title": "Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.", "AI": {"tldr": "本文提出了一种名为PrefixRL的强化学习方法，用于在困难问题上更高效地进行训练。", "motivation": "传统强化学习方法在处理复杂任务时存在效率低下和学习停滞的问题。为了解决这些问题，提出了通过复用先前采样的计算资源来提升学习效率的新思路。", "method": "PrefixRL通过将成功离策略轨迹的前缀作为条件，并执行在线策略强化学习以完成这些轨迹，从而绕过了离策略方法中的不稳定问题。", "result": "实验表明，PrefixRL能够在较短的时间内达到与最强基线相同的训练奖励，并且最终奖励提升了3倍。此外，该方法还展示了在未见过的问题上的泛化能力。", "conclusion": "PrefixRL提供了一种灵活有效的方法来解决复杂问题的强化学习挑战，即使离策略轨迹源自不同的模型家族也能够取得良好的效果。"}}
{"id": "2601.18792", "pdf": "https://arxiv.org/pdf/2601.18792", "abs": "https://arxiv.org/abs/2601.18792", "authors": ["Brian Liu", "Oiwi Parker Jones"], "title": "MEGnifying Emotion: Sentiment Analysis from Annotated Brain Data", "categories": ["cs.HC", "cs.CL", "cs.LG"], "comment": null, "summary": "Decoding emotion from brain activity could unlock a deeper understanding of the human experience. While a number of existing datasets align brain data with speech and with speech transcripts, no datasets have annotated brain data with sentiment. To bridge this gap, we explore the use of pre-trained Text-to-Sentiment models to annotate non invasive brain recordings, acquired using magnetoencephalography (MEG), while participants listened to audiobooks. Having annotated the text, we employ force-alignment of the text and audio to align our sentiment labels with the brain recordings. It is straightforward then to train Brainto-Sentiment models on these data. Experimental results show an improvement in balanced accuracy for Brain-to-Sentiment compared to baseline, supporting the proposed approach as a proof-of-concept for leveraging existing MEG datasets and learning to decode sentiment directly from the brain.", "AI": {"tldr": "从脑电活动解码情绪，利用MEG数据和预训练的文本情感模型进行研究", "motivation": "现有数据集未将大脑数据与情感标注结合，此研究填补这一空白，以实现对人类情感体验更深层次的理解", "method": "使用预训练的Text-to-Sentiment模型为非侵入性脑电记录（MEG）提供情感标签，并通过文本和音频的时间对齐来获得准确的情感标记。然后训练Brain-to-Sentiment模型进行实验验证", "result": "对比基准，该方法在平衡精度上显示出改进，证实了利用现有MEG数据集并直接从大脑解码情绪的可行性", "conclusion": "研究证明了使用MEG数据和预训练情感模型进行情感识别的有效性"}}
{"id": "2601.18791", "pdf": "https://arxiv.org/pdf/2601.18791", "abs": "https://arxiv.org/abs/2601.18791", "authors": ["Iaroslav Chelombitko", "Mika Hämäläinen", "Aleksey Komissarov"], "title": "Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "15 pages, 4 figues, 4 tables", "summary": "We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing 'glottosets' from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations demonstrate that BPE segmentation aligns with morpheme boundaries 95% better than random baseline across 15 languages (F1 = 0.34 vs 0.15). BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001), with Romance languages forming the tightest cluster (mean distance 0.51) and cross-family pairs showing clear separation (0.82). Analysis of 26,939 cross-linguistic homographs reveals that 48.7% receive different segmentations across related languages, with variation correlating to phylogenetic distance. Our results provide quantitative macro-linguistic insights into lexical patterns across typologically diverse languages within a unified analytical framework.", "AI": {"tldr": "通过维基百科词汇构建的“glottosets”，使用Byte-Pair Encoding（BPE）方法对242种拉丁文和西里尔文字语言进行大规模跨语言比较研究。", "motivation": "利用字节级子词编码技术，探索不同语言之间的词汇重叠、词汇差异及语言相似性，并验证其在基因语言关系中的相关性和定量宏观语义学分析的有效性。", "method": "构建维基百科词汇‘glottosets’；使用Byte-Pair Encoding（BPE）进行词汇分割；基于排名的子词向量分析词汇重叠、词汇差异和语言相似性；计算遗传语言关系的相关度，并通过26,939个跨语言同形异义词分析变异情况。", "result": "结果显示，BPE分段在15种语言中比随机基线更准确地与形态边界对齐（F1 = 0.34 vs 0.15）。BPE词汇相似性与遗传语言关系显著相关（Mantel r = 0.329, p < 0.001），罗曼语族形成最紧密的簇，而跨家族配对显示出明显的分离。在相关语言中，48.7%的同形异义词接收不同的分段。", "conclusion": "该研究提供了一种统一分析框架下的定量宏观语言学见解，揭示了不同类型语言间的词汇模式，并验证了BPE方法的有效性。"}}
{"id": "2601.18785", "pdf": "https://arxiv.org/pdf/2601.18785", "abs": "https://arxiv.org/abs/2601.18785", "authors": ["Tiffany Wang", "Yuqian Sun", "Yi Wang", "Melissa Roemmele", "John Joon Young Chung", "Max Kreminski"], "title": "Design Techniques for LLM-Powered Interactive Storytelling: A Case Study of the Dramamancer System", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": "Extended abstract presented at the 2025 Wordplay Workshop at EMNLP", "summary": "The rise of Large Language Models (LLMs) has enabled a new paradigm for bridging authorial intent and player agency in interactive narrative. We consider this paradigm through the example of Dramamancer, a system that uses an LLM to transform author-created story schemas into player-driven playthroughs. This extended abstract outlines some design techniques and evaluation considerations associated with this system.", "AI": {"tldr": "本文通过Dramamancer系统探讨了利用大型语言模型（LLM）将作者创作的故事结构转化为玩家驱动的游戏体验的设计技术和评估考虑。", "motivation": "随着大型语言模型的崛起，一个新的范式出现在作者意图和玩家自主性之间的桥梁搭建上。本文旨在展示如何使用这种新工具来实现更灵活、更有创意的互动叙事。", "method": "Dramamancer系统利用LLM将作者设计的故事框架转换为可以根据玩家选择生成动态故事的游戏体验。", "result": "该研究提出了几种设计技术和评估方法，以确保基于LLM的交互式叙事系统的有效性和趣味性。", "conclusion": "通过案例展示和讨论，本文强调了大型语言模型在互动叙事中的潜力，并指出了未来研究的方向。"}}
{"id": "2601.18783", "pdf": "https://arxiv.org/pdf/2601.18783", "abs": "https://arxiv.org/abs/2601.18783", "authors": ["Deepthi Pathare", "Leo Laine", "Morteza Haghir Chehreghani"], "title": "Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic", "categories": ["cs.LG", "cs.AI", "eess.SY"], "comment": null, "summary": "Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications.", "AI": {"tldr": "该论文提出了一个多目标强化学习框架，用于解决重型车辆在高速公路上的安全、效率和运营成本之间的权衡问题。", "motivation": "传统的单目标奖励函数难以捕捉安全、能耗和时间效率之间的复杂权衡关系。因此需要一个能够同时优化多个竞争性目标的解决方案。", "method": "采用基于近端策略优化（PPO）的多目标强化学习框架，在可扩展的模拟平台上为卡车战术决策学习一组连续的帕累托最优政策，以实现对这些矛盾目标之间的权衡。", "result": "生成的帕累托前沿平滑且易于理解，可以灵活选择不同冲突目标下的驾驶行为。并且允许在不同的驾驶策略之间无缝转换而无需重新训练。", "conclusion": "提出的框架提供了一种鲁棒性和适应性强的决策制定策略，适用于自动驾驶卡车应用。"}}
{"id": "2601.18779", "pdf": "https://arxiv.org/pdf/2601.18779", "abs": "https://arxiv.org/abs/2601.18779", "authors": ["Yuxiao Qu", "Amrith Setlur", "Virginia Smith", "Ruslan Salakhutdinov", "Aviral Kumar"], "title": "POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks.", "AI": {"tldr": "本文提出了一种通过特权在线探索（POPE）来提高大型语言模型在难题上推理能力的方法。", "motivation": "目前强化学习方法在解决难题时面临探索不足的问题，导致难以获得有效的训练信号。传统解决方案如熵奖励、重要性比率剪裁等并未有效改善这一问题，并且可能引入优化不稳定性的风险。", "method": "本文提出了特权在线探索（POPE）策略，利用人类或其他来源的解作为引导信息来指导难题上的探索过程。该方法通过向难题添加来自权威解决方案的前缀，使得强化学习在受导角色中能够获得非零奖励。", "result": "实验表明，与现有方法相比，本文提出的POPE能够显著扩展可解决的问题范围，并大幅提高处理困难推理任务时的表现。", "conclusion": "通过利用特权信息来引导探索过程，POPE提供了一种有效的方法以增强大型语言模型在难题上的学习能力。"}}
{"id": "2601.18777", "pdf": "https://arxiv.org/pdf/2601.18777", "abs": "https://arxiv.org/abs/2601.18777", "authors": ["Abhishek Divekar", "Anirban Majumder"], "title": "PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted at AAAI 2026 - Innovative Applications of AI (IAAI-26)", "summary": "Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.", "AI": {"tldr": "本文提出了一种结合大型语言模型和少量人工标注以减少评估偏差的统计框架。", "motivation": "传统评价搜索、排名系统需要大量的人工相关性标注，而使用大型语言模型作为自动评判工具存在固有偏见。为了克服这一问题并显著降低注释需求，本文提出了PRECISE框架。", "method": "通过扩展预测驱动推断（PPI），结合少量人工标注和大型语言模型判断来生成可靠的估计值，并且将评估空间重新定义为查询-文档级别以减少计算复杂度。", "result": "实验结果表明，在低资源设置下，该方法能够有效降低关键指标Precision@K的估计方差并纠正偏见。", "conclusion": "PRECISE框架通过结合少量人工标注和大型语言模型判断显著减少了评估偏差，并展示了在查询重述应用中的潜在价值。"}}
{"id": "2601.18772", "pdf": "https://arxiv.org/pdf/2601.18772", "abs": "https://arxiv.org/abs/2601.18772", "authors": ["Yongle Zhang", "Ge Gao"], "title": "Are Conversational AI Agents the Way Out? Co-Designing Reader-Oriented News Experiences with Immigrants and Journalists", "categories": ["cs.HC"], "comment": "ef:In Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems", "summary": "Recent discussions at the intersection of journalism, HCI, and human-centered computing ask how technologies can help create reader-oriented news experiences. The current paper takes up this initiative by focusing on immigrant readers, a group who reports significant difficulties engaging with mainstream news yet has received limited attention in prior research. We report findings from our co-design research with eleven immigrant readers living in the United States and seven journalists working in the same region, aiming to enhance the news experience of the former. Data collected from all participants revealed an \"unaddressed-or-unaccountable\" paradox that challenges value alignment across immigrant readers and journalists. This paradox points to four metaphors regarding how conversational AI agents can be designed to assist news reading. Each metaphor requires conversational AI, journalists, and immigrant readers to coordinate their shared responsibilities in a distinct manner. These findings provide insights into reader-oriented news experiences with AI in the loop.", "AI": {"tldr": "本文通过与移民读者和记者的共同设计研究，探讨了如何使用对话式AI技术来改善移民群体的新闻阅读体验。", "motivation": "当前的研究关注于如何利用技术创造以读者为中心的新闻体验，并特别聚焦在面临显著困难参与主流新闻报道的移民读者群体上。", "method": "作者与美国的11名移民读者和7名记者进行了共同设计研究，收集了所有参与者的数据。", "result": "发现了一个价值对齐矛盾，提出了四种对话式AI助手的设计隐喻，这要求对话式AI、记者和移民读者以不同的方式协调其共享职责。", "conclusion": "这些发现在利用AI技术改善新闻阅读体验方面提供了新的见解。"}}
{"id": "2601.18771", "pdf": "https://arxiv.org/pdf/2601.18771", "abs": "https://arxiv.org/abs/2601.18771", "authors": ["Yanming Liu", "Xinyue Peng", "Zixuan Yan", "Yanxin Shen", "Wenjie Xu", "Yuefeng Huang", "Xinyi Wang", "Jiannan Cao", "Jianwei Yin", "Xuhong Zhang"], "title": "Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Dep-Search 1st version", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.", "AI": {"tldr": "本文提出了一种依赖感知的搜索框架Dep-Search，通过结构化推理、检索和持久内存来增强大规模语言模型处理复杂多步推理任务的能力。", "motivation": "现有的基于搜索的知识增强框架在管理子问题间的依赖关系、有效重用先前检索到的信息以及学习最佳搜索策略方面存在局限性。本文旨在解决这些挑战，提升LLM的逻辑推理能力。", "method": "Dep-Search通过GRPO机制将结构化推理与检索和持久内存相结合，引入显式的控制机制来分解具有依赖关系的问题、按需检索信息并从记忆中获取先前存储的知识，并总结长推理上下文以生成可重用的记忆条目。", "result": "在七个不同问答数据集上进行的大量实验表明，Dep-Search显著提高了LLM处理复杂多步推理任务的能力，在各种模型规模下均实现了对强大基线方法的重大改进。", "conclusion": "通过引入依赖感知搜索框架和持久内存机制，Dep-Search成功解决了传统检索增强生成框架中的关键问题，并展示了在处理复杂推理任务方面的优越性能。"}}
{"id": "2601.18766", "pdf": "https://arxiv.org/pdf/2601.18766", "abs": "https://arxiv.org/abs/2601.18766", "authors": ["Parampreet Singh", "Somya Kumar", "Chaitanya Shailendra Nitawe", "Vipul Arora"], "title": "Learning to Discover: A Generalized Framework for Raga Identification without Forgetting", "categories": ["eess.AS", "cs.LG"], "comment": "Accepted at NCC 2026 conference", "summary": "Raga identification in Indian Art Music (IAM) remains challenging due to the presence of numerous rarely performed Ragas that are not represented in available training datasets. Traditional classification models struggle in this setting, as they assume a closed set of known categories and therefore fail to recognise or meaningfully group previously unseen Ragas. Recent works have tried categorizing unseen Ragas, but they run into a problem of catastrophic forgetting, where the knowledge of previously seen Ragas is diminished. To address this problem, we adopt a unified learning framework that leverages both labeled and unlabeled audio, enabling the model to discover coherent categories corresponding to the unseen Ragas, while retaining the knowledge of previously known ones. We test our model on benchmark Raga Identification datasets and demonstrate its performance in categorizing previously seen, unseen, and all Raga classes. The proposed approach surpasses the previous NCD-based pipeline even in discovering the unseen Raga categories, offering new insights into representation learning for IAM tasks.", "AI": {"tldr": "本文提出了一种在印度艺术音乐中识别拉加而不忘记已知拉加知识的统一学习框架。", "motivation": "传统分类模型难以处理从未见过的拉加，因为它们假设类别是封闭和已知的。此外，最近的工作遇到了灾难性遗忘问题，即先前已知拉加的知识被削弱了。", "method": "本文采用了一种利用标记和未标记音频数据的统一学习框架，使模型能够发现新的拉加类，并保持对之前见过的拉加的记忆。", "result": "该方法在基准拉加识别数据集上超过了以前基于NCD的方法，在分类已知、未知以及所有类别方面的表现更优。", "conclusion": "提出的方案为印度艺术音乐任务中的表示学习提供了新的见解，表明了统一框架的有效性。"}}
{"id": "2601.18765", "pdf": "https://arxiv.org/pdf/2601.18765", "abs": "https://arxiv.org/abs/2601.18765", "authors": ["Shutong Chen", "Adnan Aijaz", "Yansha Deng"], "title": "Goal-oriented Communication for Fast and Robust Robotic Fault Detection and Recovery", "categories": ["cs.RO"], "comment": "Submit to IEEE for potential publication", "summary": "Autonomous robotic systems are widely deployed in smart factories and operate in dynamic, uncertain, and human-involved environments that require low-latency and robust fault detection and recovery (FDR). However, existing FDR frameworks exhibit various limitations, such as significant delays in communication and computation, and unreliability in robot motion/trajectory generation, mainly because the communication-computation-control (3C) loop is designed without considering the downstream FDR goal. To address this, we propose a novel Goal-oriented Communication (GoC) framework that jointly designs the 3C loop tailored for fast and robust robotic FDR, with the goal of minimising the FDR time while maximising the robotic task (e.g., workpiece sorting) success rate. For fault detection, our GoC framework innovatively defines and extracts the 3D scene graph (3D-SG) as the semantic representation via our designed representation extractor, and detects faults by monitoring spatial relationship changes in the 3D-SG. For fault recovery, we fine-tune a small language model (SLM) via Low-Rank Adaptation (LoRA) and enhance its reasoning and generalization capabilities via knowledge distillation to generate recovery motions for robots. We also design a lightweight goal-oriented digital twin reconstruction module to refine the recovery motions generated by the SLM when fine-grained robotic control is required, using only task-relevant object contours for digital twin reconstruction. Extensive simulations demonstrate that our GoC framework reduces the FDR time by up to 82.6% and improves the task success rate by up to 76%, compared to the state-of-the-art frameworks that rely on vision language models for fault detection and large language models for fault recovery.", "AI": {"tldr": "提出了一种目标导向通信框架，用于快速和可靠的机器人故障检测与恢复。", "motivation": "现有故障检测与恢复框架存在延迟大、计算复杂度高以及对下游任务支持不足等问题。因此需要一种新的方法来减少故障时间并提高成功率。", "method": "设计了一个目标导向的通信框架，通过定义三维场景图作为语义表示进行故障检测，并使用小语言模型和知识蒸馏生成恢复运动。同时引入了一种轻量级的目标导向数字孪生重建模块以优化机器人控制。", "result": "实验表明该方法能将故障检测与恢复时间减少最多82.6%，成功率提高最多76%。", "conclusion": "通过目标导向通信框架，显著减少了故障检测与恢复的时间，并提高了任务的成功率。"}}
{"id": "2601.18761", "pdf": "https://arxiv.org/pdf/2601.18761", "abs": "https://arxiv.org/abs/2601.18761", "authors": ["Wout Slabbinck", "Wouter Termont", "Ruben Dedecker", "Beatriz Esteves"], "title": "From Access Control to Usage Control with User-Managed Access", "categories": ["cs.ET"], "comment": null, "summary": "Recent data protection and data governance regulations have intensified the demand for interoperable, decentralized data ecosystems that can support not only access control but also legally-aligned governance over data use. Existing Web-based data storage platforms increasingly struggle to meet these regulatory and practical requirements, as their authorization mechanisms rely on tightly coupled, document-centric access control models that lack expressiveness for legal constraints and fail to separate data management from authorization concerns. In parallel, widely adopted authorization standards remain poorly aligned with decentralized, semantically rich usage-control scenarios. To bridge this gap, this work introduces an architecture that replaces Solid's native access control mechanisms with a UMA authorization flow, enabling the enforcement of usage control policies expressed with the W3C ODRL standard. This article details the conceptual background motivating this approach, presents the proposed UMA-based architecture, and describes a prototype implementation that integrates an ODRL-enabled Authorization Server with a Solid-compatible Resource Server. The prototype demonstrates that decoupling authorization from storage enables more flexible, interoperable, and legally expressive control over data use, while remaining compatible with existing Solid infrastructure. It also highlights practical design choices required to evaluate ODRL policies in the absence of a fully standardized evaluation semantics. Moreover, this work shows how usage control can be operationalized using existing Web standards, offering a concrete path beyond permission-based access control toward policy-aware, legally informed data governance. Future research will focus on policy management interfaces, richer claim verification mechanisms, and techniques for communicating and enforcing obligations over time.", "AI": {"tldr": "本文提出了一个架构，通过将Solid原生访问控制机制替换为UMA授权流程，实现了基于W3C ODRL标准的使用控制策略的执行。", "motivation": "现有的Web数据存储平台依赖于紧密耦合、文档为中心的访问控制模型，在表达法律约束方面存在不足，并未能分离数据管理和授权问题。随着数据保护和治理法规的加强，需要一个能够支持不仅包括访问控制还包括法律对齐的数据使用监管的可互操作的去中心化数据生态系统。", "method": "本文介绍了一种架构，该架构用UMA授权流程替换了Solid原生的访问控制机制，并提出了一种将ODRL增强型授权服务器与Solid兼容资源服务器整合的原型实现方案。", "result": "通过解耦存储和授权，这种方法实现了更灵活、可互操作且法律表达性更强的数据使用控制。此外，该工作展示了如何使用现有的Web标准来实施使用控制，并提出了未来的研究方向。", "conclusion": "本文提出的方法为超越基于权限的访问控制向政策感知型数据治理迈进提供了一条切实可行的道路，并强调了在缺乏完全标准化评估语义的情况下进行ODRL策略评估所需的实际设计选择。"}}
{"id": "2601.18759", "pdf": "https://arxiv.org/pdf/2601.18759", "abs": "https://arxiv.org/abs/2601.18759", "authors": ["Junling Wang", "Hongyi Lan", "Xiaotian Su", "Mustafa Doga Dogan", "April Yi Wang"], "title": "UI Remix: Supporting UI Design Through Interactive Example Retrieval and Remixing", "categories": ["cs.HC"], "comment": "Accepted at the 31st International Conference on Intelligent User Interfaces (IUI 2026)", "summary": "Designing user interfaces (UIs) is a critical step when launching products, building portfolios, or personalizing projects, yet end users without design expertise often struggle to articulate their intent and to trust design choices. Existing example-based tools either promote broad exploration, which can cause overwhelm and design drift, or require adapting a single example, risking design fixation. We present UI Remix, an interactive system that supports mobile UI design through an example-driven design workflow. Powered by a multimodal retrieval-augmented generation (MMRAG) model, UI Remix enables iterative search, selection, and adaptation of examples at both the global (whole interface) and local (component) level. To foster trust, it presents source transparency cues such as ratings, download counts, and developer information. In an empirical study with 24 end users, UI Remix significantly improved participants' ability to achieve their design goals, facilitated effective iteration, and encouraged exploration of alternative designs. Participants also reported that source transparency cues enhanced their confidence in adapting examples. Our findings suggest new directions for AI-assisted, example-driven systems that empower end users to design with greater control, trust, and openness to exploration.", "AI": {"tldr": "UI Remix 是一种支持用户界面设计的交互式系统，通过迭代搜索、选择和调整示例来增强用户体验。", "motivation": "缺乏设计经验的终端用户在进行用户界面设计时面临挑战，现有的基于示例的工具可能造成设计漂移或固定。因此开发 UI Remix 系统以解决这些问题，提高用户的信心并鼓励探索不同设计。", "method": "UI Remix 使用多模态检索增强生成模型来支持用户通过全局和局部水平迭代搜索、选择和调整示例，并提供源透明度提示如评分、下载次数和开发者信息以增加信任感。", "result": "实验研究显示，使用 UI Remix 参与者的界面设计目标实现能力显著提高，促进了有效迭代并鼓励探索不同设计方案。参与者还报告称，来源透明度提示增强了他们对调整示例的信心。", "conclusion": "UI Remix 系统通过增强用户控制、信任和开放探索意愿的方式支持用户进行更有成效的设计工作。"}}
{"id": "2601.18754", "pdf": "https://arxiv.org/pdf/2601.18754", "abs": "https://arxiv.org/abs/2601.18754", "authors": ["Mohamed Amine Ferrag", "Abderrahmane Lakas", "Merouane Debbah"], "title": "$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Autonomous unmanned aerial vehicle (UAV) systems are increasingly deployed in safety-critical, networked environments where they must operate reliably in the presence of malicious adversaries. While recent benchmarks have evaluated large language model (LLM)-based UAV agents in reasoning, navigation, and efficiency, systematic assessment of security, resilience, and trust under adversarial conditions remains largely unexplored, particularly in emerging 6G-enabled settings. We introduce $α^{3}$-SecBench, the first large-scale evaluation suite for assessing the security-aware autonomy of LLM-based UAV agents under realistic adversarial interference. Building on multi-turn conversational UAV missions from $α^{3}$-Bench, the framework augments benign episodes with 20,000 validated security overlay attack scenarios targeting seven autonomy layers, including sensing, perception, planning, control, communication, edge/cloud infrastructure, and LLM reasoning. $α^{3}$-SecBench evaluates agents across three orthogonal dimensions: security (attack detection and vulnerability attribution), resilience (safe degradation behavior), and trust (policy-compliant tool usage). We evaluate 23 state-of-the-art LLMs from major industrial providers and leading AI labs using thousands of adversarially augmented UAV episodes sampled from a corpus of 113,475 missions spanning 175 threat types. While many models reliably detect anomalous behavior, effective mitigation, vulnerability attribution, and trustworthy control actions remain inconsistent. Normalized overall scores range from 12.9% to 57.1%, highlighting a significant gap between anomaly detection and security-aware autonomous decision-making. We release $α^{3}$-SecBench on GitHub: https://github.com/maferrag/AlphaSecBench", "AI": {"tldr": "该论文介绍了$α^{3}$-SecBench，这是一个评估基于大语言模型（LLM）的无人飞行器（UAV）代理在6G网络环境下的安全、弹性和信任的大规模评测套件。", "motivation": "现有的基准测试主要关注LLM-UAV代理的认知、导航和效率，而关于这些系统在对抗条件下的安全性和信任性评估还存在很大的空白。作者提出$α^{3}$-SecBench来填补这一空白，并提供全面的测评框架以应对现实环境中的威胁。", "method": "$α^{3}$-SecBench通过引入20,000个经过验证的安全攻击场景，覆盖七层自主性（感知、规划、控制等），对来自不同厂商和实验室的23种最先进的LLM进行评估。这些模型使用了包含175种威胁类型的113,475次任务。", "result": "在测试中，很多模型能够检测到异常行为，但是它们在有效缓解攻击、归因漏洞以及做出值得信赖的控制决策方面表现不一。整体评分范围为12.9%至57.1%，表明从识别威胁到采取安全自主行动之间存在显著差距。", "conclusion": "$α^{3}$-SecBench揭示了LLM-UAV代理在面对复杂攻击时的安全性和信任性的不足，强调了在未来研究和系统开发中加强这些方面的重要性。"}}
{"id": "2601.18753", "pdf": "https://arxiv.org/pdf/2601.18753", "abs": "https://arxiv.org/abs/2601.18753", "authors": ["Xinyue Zeng", "Junhong Lin", "Yujun Yan", "Feng Guo", "Liang Shi", "Jun Wu", "Dawei Zhou"], "title": "HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs", "categories": ["cs.LG", "cs.AI"], "comment": "Have been accepted by ICLR'26", "summary": "The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.", "AI": {"tldr": "该论文提出了一种新的框架HalluGuard，用于检测大型语言模型中的数据驱动和推理驱动的幻觉。", "motivation": "现有方法通常只解决一种类型的幻觉问题，并依赖任务特定启发式算法，这限制了它们在复杂场景下的泛化能力。作者希望通过理论框架和基于NTK的得分方法来统一处理这两种类型的问题。", "method": "提出了Hallucination Risk Bound这一理论框架，将幻觉风险分解为数据驱动部分和推理驱动部分，并引入基于NTK的评分方法HalluGuard以检测这两类幻觉。", "result": "在10个不同的基准测试集上评估了HalluGuard与11种竞争基线模型相比，在9种流行的LLM架构上保持了识别多种形式幻觉的最佳表现。", "conclusion": "该框架提供了一种统一的方法来解决大型语言模型中的数据驱动和推理驱动的幻觉问题，展示了优越的效果并为未来的研究奠定了基础。"}}
{"id": "2601.18751", "pdf": "https://arxiv.org/pdf/2601.18751", "abs": "https://arxiv.org/abs/2601.18751", "authors": ["Seyed Amir Hosseini", "Maryam Abdolali", "Amirhosein Tavakkoli", "Fardin Ayar", "Ehsan Javanmardi", "Manabu Tsukada", "Mahdi Javanmardi"], "title": "Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback", "categories": ["cs.LG", "cs.AI"], "comment": "Equal contribution: Seyed Amir Hosseini and Maryam Abdolali. Corresponding author: Maryam Abdolali (maryam.abdolali@kntu.ac.ir)", "summary": "Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines.", "AI": {"tldr": "介绍了一种名为TriTrust-PBRL（TTP）的框架，该框架通过从多专家偏好反馈中学习共享奖励模型和特定于专家的信任参数来实现稳健的基于偏好的强化学习。", "motivation": "现有的基于偏好的强化学习方法在面对系统性错误提供偏好的对抗性注释者时表现不佳。提出了一种新的方法，可以在有可靠、噪声或对抗性的注释者的混合环境中有效工作。", "method": "TTP框架通过从多专家偏好反馈中联合学习共享奖励模型和特定于专家的信任参数来实现稳健的基于偏好的强化学习。信任参数在梯度优化过程中自然演化为正值（信任）、接近零值（忽略）或负值（翻转），从而自动反转对抗性偏好。", "result": "实验结果显示，在各种腐败场景下，TTP框架均表现出优异的鲁棒性和性能，即使面对对抗性的注释者也能保持接近最优的表现。这证明了该方法在学习混合专家群体中的优势。", "conclusion": "提出了TriTrust-PBRL（TTP）作为应对多源偏好数据中潜在对抗性反馈的有效策略，并展示了其在解决基于偏好的强化学习问题上的优越性能和鲁棒性。"}}
{"id": "2601.18750", "pdf": "https://arxiv.org/pdf/2601.18750", "abs": "https://arxiv.org/abs/2601.18750", "authors": ["Francesco Chiossi", "Elnur Imamaliyev", "Martin Bleichner", "Sven Mayer"], "title": "Anticipation Before Action: EEG-Based Implicit Intent Detection for Adaptive Gaze Interaction in Mixed Reality", "categories": ["cs.HC"], "comment": null, "summary": "Mixed Reality (MR) interfaces increasingly rely on gaze for interaction , yet distinguishing visual attention from intentional action remains difficult, leading to the Midas Touch problem. Existing solutions require explicit confirmations, while brain-computer interfaces may provide an implicit marker of intention using Stimulus-Preceding Negativity (SPN). We investigated how Intention (Select vs. Observe) and Feedback (With vs. Without) modulate SPN during gaze-based MR interactions. During realistic selection tasks, we acquired EEG and eye-tracking data from 28 participants. SPN was robustly elicited and sensitive to both factors: observation without feedback produced the strongest amplitudes, while intention to select and expectation of feedback reduced activity, suggesting SPN reflects anticipatory uncertainty rather than motor preparation. Complementary decoding with deep learning models achieved reliable person-dependent classification of user intention, with accuracies ranging from 75% to 97% across participants. These findings identify SPN as an implicit marker for building intention-aware MR interfaces that mitigate the Midas Touch.", "AI": {"tldr": "本文探讨了在混合现实交互中使用脑电图（EEG）来识别用户的隐含意图，以解决视觉注意力和有意动作难以区分的问题。", "motivation": "现有的解决方案需要显式的确认来区分视线关注与有意操作，而通过刺激前负波（SPN）可以提供一个用户意图的隐式标记。", "method": "在真实选择任务中获取了28名参与者的眼动和脑电图数据。研究了意图（选择vs观察）和反馈（有无）对SPN的影响，并利用深度学习模型进行了可靠的个人依赖分类。", "result": "SPN能够被可靠地提取并且对于两个因素都非常敏感，即观察且没有反馈产生最强的振幅；而有意去选择与期待反馈则减少了活动。使用深度学习进行互补解码实现了用户意图的人体相关分类，准确率在75%-97%之间。", "conclusion": "研究结果表明SPN是构建有意识混合现实界面的一种隐式标记，可以解决视线触碰问题，并提供更自然的交互体验"}}
{"id": "2601.18748", "pdf": "https://arxiv.org/pdf/2601.18748", "abs": "https://arxiv.org/abs/2601.18748", "authors": ["Aiya Kuchukova", "Santosh Vempala", "Daniel J. Zhang"], "title": "Sampling Sphere Packings with Continuum Glauber Dynamics", "categories": ["cs.DS", "math.PR"], "comment": "77 pages, 1 figure", "summary": "We establish a spectral gap for Continuum Glauber dynamics on the hard sphere model assuming strong spatial mixing, thereby extending the range of parameters in which Continuum Glauber is provably rapidly mixing. To do this, we introduce continuous extensions of spectral independence and negative fields localization. Our techniques apply to general Gibbs point processes with finite-range repulsive pair potentials. As a corollary, we improve the threshold up to which packings of a fixed number of spheres can be sampled from a bounded domain.", "AI": {"tldr": "该论文建立了连续格拉乌伯动力学在球模型上的谱隙，扩展了可以证明快速混合的参数范围。", "motivation": "通过引入谱独立性和负场定位的连续延拓来改进球堆叠采样的阈值。", "method": "利用连续Glauber动态系统和谱独立性理论对有限距离排斥偶相互作用的吉布斯点过程进行分析。", "result": "证明了在强空间混合假设下，对于固定数量的球体从有界域中采样可以达到更高的阈值。", "conclusion": "研究成功地扩展了连续Glauber动态系统快速混合参数范围，并改进了特定条件下的球堆叠采样效率。"}}
{"id": "2601.18747", "pdf": "https://arxiv.org/pdf/2601.18747", "abs": "https://arxiv.org/abs/2601.18747", "authors": ["Amir Aavani"], "title": "Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval", "categories": ["cs.IR", "cs.AI", "cs.CC", "cs.CL", "cs.DB"], "comment": null, "summary": "Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions. In this paper, we propose that a retrieval engine must be capable of ``Capturing $\\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\\mathbf{P}$. We introduce \\texttt{ComputePN}, a novel evaluation algorithm that makes $\\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \\texttt{ComputePN} ensures the efficient evaluation of any query in $\\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.18744", "pdf": "https://arxiv.org/pdf/2601.18744", "abs": "https://arxiv.org/abs/2601.18744", "authors": ["Fangxu Yu", "Xingang Guo", "Lingzhi Yuan", "Haoqiang Kang", "Hongyu Zhao", "Lianhui Qin", "Furong Huang", "Bin Hu", "Tianyi Zhou"], "title": "TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.", "AI": {"tldr": "TSRBench 是一个多任务多模态时间序列推理基准，旨在全面评估一般模型在时间序列推理方面的能力。", "motivation": "现有的通用模型基准缺乏对时间序列推理能力的测试。为了弥补这一不足，提出了 TSRBench，以检测和改进这些模型的时间序列推理性能。", "method": "TSRBench 包含来自14个领域的4125个问题，分为感知、推理、预测和决策四大维度，并通过实验评估了超过30种领先的语言模型、视觉语言模型和时间序列语言模型。", "result": "结果显示，在感知和推理方面存在规模定律，但在预测方面则不存在；强大的推理能力并不能保证准确的上下文感知预测；当前多模态模型在融合文本和视觉表示以实现性能增益方面效果不佳。", "conclusion": "TSRBench 为时间序列推理提供了一个标准化评估平台，不仅突出了现有挑战，还提供了宝贵的见解来推进通用模型的发展。"}}
{"id": "2601.18739", "pdf": "https://arxiv.org/pdf/2601.18739", "abs": "https://arxiv.org/abs/2601.18739", "authors": ["Ignacio Antequera-Sánchez", "Juan Luis Suárez-Díaz", "Rosana Montes", "Francisco Herrera"], "title": "SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification", "categories": ["cs.CV", "cs.AI"], "comment": "28 pages", "summary": "Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance.", "AI": {"tldr": "本文提出了一种新的方法SeNeDiF-OOD，用于检测开放世界环境下的人工智能应用中的异常数据（OOD）。", "motivation": "解决开放环境中不同类型异常数据的挑战，包括低级扰动和语义变化，传统的单阶段探测器难以应对这些问题。", "method": "本文提出了一种基于语义嵌套分层融合的方法SeNeDiF-OOD。该方法将检测任务分解成层次化的二元融合节点结构，每个层级旨在整合特定语义抽象级别的决策边界。", "result": "实验结果表明，在MonuMAI的开放环境中应用SeNeDiF-OOD框架能够有效过滤多种异常数据类别，并保持分布内性能。", "conclusion": "本文提出的基于层次化融合的方法在OOD检测上表现优异，展示了其在解决复杂语义变化和低级扰动问题上的有效性。"}}
{"id": "2601.18735", "pdf": "https://arxiv.org/pdf/2601.18735", "abs": "https://arxiv.org/abs/2601.18735", "authors": ["Jusheng Zhang", "Yijia Fan", "Kaitong Cai", "Jing Yang", "Jiawei Yao", "Jian Wang", "Guanlong Qu", "Ziliang Chen", "Keze Wang"], "title": "Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted to ICLR 2026", "summary": "Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We introduce Agora, a framework that reframes coordination as a decentralized market for uncertainty. Agora formalizes epistemic uncertainty into a structured, tradable asset (perceptual, semantic, inferential), and enforces profitability-driven trading among agents based on rational economic rules. A market-aware broker, extending Thompson Sampling, initiates collaboration and guides the system toward cost-efficient equilibria. Experiments on five multimodal benchmarks (MMMU, MMBench, MathVision, InfoVQA, CC-OCR) show that Agora outperforms strong VLMs and heuristic multi-agent strategies, e.g., achieving +8.5% accuracy over the best baseline on MMMU while reducing cost by over 3x. These results establish market-based coordination as a principled and scalable paradigm for building economically viable multi-agent visual intelligence systems.", "AI": {"tldr": "本文提出了一种框架Agora，通过将协调问题转化为一个分散的不确定性市场来解决多智能体系统中的经济不可持续性问题。", "motivation": "现有的视觉语言模型在异构代理之间的协调中存在信息不对称和成本不经济的问题。传统的策略依赖于忽略成本的启发式方法，并且无法有效处理不确定性的结构。", "method": "Agora框架将知识不确定性转化为可交易资产，通过理性经济规则引导智能体之间基于盈利能力进行交易。使用扩展了汤普森采样的市场意识经纪人来启动合作和指导系统走向成本效益平衡。", "result": "实验结果表明，Agora在五个多元基准测试上优于现有的视觉语言模型和其他策略，例如，在MMMU上实现了比最强基线高8.5%的准确率，并将成本减少了3倍以上。", "conclusion": "市场基础协调被证明是一种构建经济可行多智能体视觉智能系统的有效且可扩展的方法。"}}
{"id": "2601.18733", "pdf": "https://arxiv.org/pdf/2601.18733", "abs": "https://arxiv.org/abs/2601.18733", "authors": ["Li Kang", "Heng Zhou", "Xiufeng Song", "Rui Li", "Bruno N. Y. Chen", "Ziye Wang", "Ximeng Meng", "Stone Tao", "Yiran Qin", "Xiaohong Liu", "Ruimao Zhang", "Lei Bai", "Yilun Du", "Hao Su", "Philip Torr", "Zhenfei Yin", "Ruihao Gong", "Yejun Zeng", "Fengjun Zhong", "Shenghao Jin", "Jinyang Guo", "Xianglong Liu", "Xiaojun Jia", "Tianqi Shan", "Wenqi Ren", "et al. (19 additional authors not shown)"], "title": "Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "MARS Challenge @ NeurIPS 2025 Workshop on Space in Vision, Language, and Embodied AI. Challenge page: https://mars-eai.github.io/MARS-Challenge-Webpage/", "summary": "Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enhancing system efficiency through task delegation, and enabling advanced human-agent interactions. To address the challenges posed by multi-agent collaboration, we propose the Multi-Agent Robotic System (MARS) Challenge, held at the NeurIPS 2025 Workshop on SpaVLE. The competition focuses on two critical areas: planning and control, where participants explore multi-agent embodied planning using vision-language models (VLMs) to coordinate tasks and policy execution to perform robotic manipulation in dynamic environments. By evaluating solutions submitted by participants, the challenge provides valuable insights into the design and coordination of embodied multi-agent systems, contributing to the future development of advanced collaborative AI systems.", "AI": {"tldr": "提出了MARS挑战赛，旨在评估多智能体系统的规划与控制能力。", "motivation": "随着代理能力和系统效率的提升以及人机交互的复杂化，需要更有效的框架来处理多代理协作中的问题。", "method": "通过在NeurIPS 2025工作坊上举办的MARS挑战赛评估基于视觉语言模型的规划和执行策略。", "result": "为未来的先进协同AI系统的设计提供了有价值的见解。", "conclusion": "竞赛促进了对多代理系统的理解和改进，推动了相关领域的技术进步。"}}
{"id": "2601.18732", "pdf": "https://arxiv.org/pdf/2601.18732", "abs": "https://arxiv.org/abs/2601.18732", "authors": ["Joshua S. Gans"], "title": "Optimal Use of Preferences in Artificial Intelligence Algorithms", "categories": ["econ.TH", "cs.AI"], "comment": "54 pages, 2 figures", "summary": "Machine learning systems embed preferences either in training losses or through post-processing of calibrated predictions. Applying information design methods from Strack and Yang (2024), this paper provides decision problem agnostic conditions under which separation training preference free and applying preferences ex post is optimal. Unlike prior work that requires specifying downstream objectives, the welfare results here apply uniformly across decision problems. The key primitive is a diminishing-value-of-information condition: relative to a fixed (normalised) preference-free loss, preference embedding makes informativeness less valuable at the margin, inducing a mean-preserving contraction of learned posteriors. Because the value of information is convex in beliefs, preference-free training weakly dominates for any expected utility decision problem. This provides theoretical foundations for modular AI pipelines that learn calibrated probabilities and implement asymmetric costs through downstream decision rules. However, separation requires users to implement optimal decision rules. When cognitive constraints bind, as documented in human AI decision-making, preference embedding can dominate by automating threshold computation. These results provide design guidance: preserve optionality through post-processing when objectives may shift; embed preferences when decision-stage frictions dominate.", "AI": {"tldr": "本文研究了在人工智能算法中嵌入偏好的最优方法，探讨了如何在训练过程中保持无偏好性并在后期应用偏好。", "motivation": "该文旨在提供一种不依赖于具体决策问题的框架，用于确定何时应该分离偏好自由的训练和后处理阶段的应用偏好。目标是在不同下游任务之间保持灵活性，并在认知限制条件下自动化阈值计算。", "method": "采用信息设计方法从Strack and Yang (2024)获得，文中提出了一个边际价值递减的信息条件，说明相对固定（标准化）无偏好的损失而言，偏好嵌入使得信息的额外价值降低。这种方法适用于任何期望效用决策问题，并为模块化AI管道的设计提供了理论基础。", "result": "该研究发现，在不考虑具体下游目标的情况下，偏好自由训练在所有预期效用决策问题中均占优势；然而当认知约束存在时，直接嵌入偏好可以在自动化阈值计算方面优于分离方法。", "conclusion": "结论建议：如果目标可能变化，则通过后期处理保持选项灵活性；若决策阶段摩擦占据主导地位，则直接嵌入偏好以优化AI系统设计。"}}
{"id": "2601.18731", "pdf": "https://arxiv.org/pdf/2601.18731", "abs": "https://arxiv.org/abs/2601.18731", "authors": ["Hongru Cai", "Yongqi Li", "Tiezheng Yu", "Fengbin Zhu", "Wenjie Wang", "Fuli Feng", "Wenjie Li"], "title": "One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines.", "AI": {"tldr": "提出一种元奖励建模（MRM）方法，通过学习偏好适应过程解决个性化大型语言模型对齐问题。", "motivation": "为了解决个性化奖励模型面临的数据反馈稀缺和快速适应新用户的挑战，需要从数据拟合转向学习偏好数量化的过程。", "method": "元奖励建模（MRM）将个性化奖励模型作为元学习问题来解决。通过使用权重组合基础奖励函数的方式表示每个用户奖励模型，并采用Model-Agnostic Meta-Learning（MAML）框架优化这些权重的初始化，以实现在有限反馈下的快速适应。", "result": "实验表明，MRM能够增强小样本个性化能力并提高对难以学习用户的鲁棒性，在个人偏好数据集上超越了基线方法。", "conclusion": "元奖励建模（MRM）为解决大型语言模型的个性化对齐问题提供了有效的方法。"}}
{"id": "2601.18724", "pdf": "https://arxiv.org/pdf/2601.18724", "abs": "https://arxiv.org/abs/2601.18724", "authors": ["Yusuke Sakai", "Hidetaka Kamigaito", "Taro Watanabe"], "title": "HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences", "categories": ["cs.CL", "cs.AI", "cs.DL"], "comment": "Work In Progress", "summary": "Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as \"HalluCitation\" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.", "AI": {"tldr": "系统性地分析了在ACL、NAACL和EMNLP会议中出现的虚假引用（HalluCitation）的影响。", "motivation": "研究虚假引用对科学可靠性及会议信誉的影响，以提高学术诚信。", "method": "分析2024年与2025年间这些会议上所有已发表论文中的虚假引用情况。", "result": "发现近300篇论文至少包含一个虚假引用，其中一半出现在最近的EMNLP 2025会议中，并且超过100篇被接受为主会或Findings论文。", "conclusion": "表明在学术会议上出现的虚假引用问题日益严重，影响了会议和整体学界的信誉。"}}
{"id": "2601.18723", "pdf": "https://arxiv.org/pdf/2601.18723", "abs": "https://arxiv.org/abs/2601.18723", "authors": ["Mengyuan Liu", "Juyi Sheng", "Peiming Li", "Ziyi Wang", "Tianming Xu", "Tiantian Xu", "Hong Liu"], "title": "Trustworthy Evaluation of Robotic Manipulation: A New Benchmark and AutoEval Methods", "categories": ["cs.RO"], "comment": null, "summary": "Driven by the rapid evolution of Vision-Action and Vision-Language-Action models, imitation learning has significantly advanced robotic manipulation capabilities. However, evaluation methodologies have lagged behind, hindering the establishment of Trustworthy Evaluation for these behaviors. Current paradigms rely on binary success rates, failing to address the critical dimensions of trust: Source Authenticity (i.e., distinguishing genuine policy behaviors from human teleoperation) and Execution Quality (e.g., smoothness and safety). To bridge these gaps, we propose a solution that combines the Eval-Actions benchmark and the AutoEval architecture. First, we construct the Eval-Actions benchmark to support trustworthiness analysis. Distinct from existing datasets restricted to successful human demonstrations, Eval-Actions integrates VA and VLA policy execution trajectories alongside human teleoperation data, explicitly including failure scenarios. This dataset is structured around three core supervision signals: Expert Grading (EG), Rank-Guided preferences (RG), and Chain-of-Thought (CoT). Building on this, we propose the AutoEval architecture: AutoEval leverages Spatio-Temporal Aggregation for semantic assessment, augmented by an auxiliary Kinematic Calibration Signal to refine motion smoothness; AutoEval Plus (AutoEval-P) incorporates the Group Relative Policy Optimization (GRPO) paradigm to enhance logical reasoning capabilities. Experiments show AutoEval achieves Spearman's Rank Correlation Coefficients (SRCC) of 0.81 and 0.84 under the EG and RG protocols, respectively. Crucially, the framework possesses robust source discrimination capabilities, distinguishing between policy-generated and teleoperated videos with 99.6% accuracy, thereby establishing a rigorous standard for trustworthy robotic evaluation. Our project and code are available at https://term-bench.github.io/.", "AI": {"tldr": "本文提出了一种新的基准测试和自动评估方法，以解决当前机器人抓取评价体系中的不足。", "motivation": "当前的评价方法主要依赖于二元成功率指标，无法全面反映操作的真实性和质量。为提高信任度，需要引入更详细的评估维度和框架。", "method": "提出了一种新的基准测试Eval-Actions以及AutoEval架构，后者结合时空聚合进行语义评估，并通过辅助信号优化运动平滑度和逻辑推理能力。", "result": "实验结果表明，提出的自动评估方法在专家评分和等级导向偏好协议下分别达到了0.81和0.84的斯皮尔曼秩相关系数，并能以99.6%的准确率区分策略生成视频与远程操作视频。", "conclusion": "本文通过建立新基准测试和自动评估架构，为机器人抓取行为提供了更可信、全面的评价标准。"}}
{"id": "2601.18716", "pdf": "https://arxiv.org/pdf/2601.18716", "abs": "https://arxiv.org/abs/2601.18716", "authors": ["Naeyma N. Islam", "Thomas R. Caulfield"], "title": "Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules", "categories": ["cs.AI", "q-bio.BM"], "comment": "30 pages, 8 figures", "summary": "Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases.", "AI": {"tldr": "本文提出了一种新型的人工智能辅助药物设计方法，通过泛素-蛋白酶体系统（UPS）促进针对阿尔茨海默病患者β-淀粉样蛋白42的靶向降解。", "motivation": "阿尔茨海默病的一个标志是β-淀粉样蛋白42的异常积累。这种蛋白质不仅形成细胞外斑块，还可能在细胞内引起毒性反应并加速神经退行性变。因此，本文旨在开发一种针对UPS系统的新型药物设计方法，以期实现对β-42的高效降解。", "method": "通过结构基元建模、ADMET筛选及对接实验评估了β-42与三种E3连接酶（CRBN, VHL和MDM2）形成的三元复合体的可能性。随后开发了一种Ligase条件化的 Junction Tree变分自动编码器(LC-JT-VAE)来生成特定于靶点的小分子，同时引入蛋白质序列嵌入以及考虑扭转角的分子图。", "result": "实验结果显示该模型能够产生化学上有效且具有新颖性的特异性分子胶，这些分子有望促进β-42蛋白的有效降解。", "conclusion": "这一综合方法为设计针对神经退行性疾病的泛素-蛋白酶体系统靶向疗法提供了有前景的框架。"}}
{"id": "2601.18714", "pdf": "https://arxiv.org/pdf/2601.18714", "abs": "https://arxiv.org/abs/2601.18714", "authors": ["Judith Vilella-Cantos", "Mauro Martini", "Marcello Chiaberge", "Mónica Ballesta", "David Valiente"], "title": "Low Cost, High Efficiency: LiDAR Place Recognition in Vineyards with Matryoshka Representation Learning", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Localization in agricultural environments is challenging due to their unstructured nature and lack of distinctive landmarks. Although agricultural settings have been studied in the context of object classification and segmentation, the place recognition task for mobile robots is not trivial in the current state of the art. In this study, we propose MinkUNeXt-VINE, a lightweight, deep-learning-based method that surpasses state-of-the-art methods in vineyard environments thanks to its pre-processing and Matryoshka Representation Learning multi-loss approach. Our method prioritizes enhanced performance with low-cost, sparse LiDAR inputs and lower-dimensionality outputs to ensure high efficiency in real-time scenarios. Additionally, we present a comprehensive ablation study of the results on various evaluation cases and two extensive long-term vineyard datasets employing different LiDAR sensors. The results demonstrate the efficiency of the trade-off output produced by this approach, as well as its robust performance on low-cost and low-resolution input data. The code is publicly available for reproduction.", "AI": {"tldr": "提出了一种轻量级的基于深度学习的方法MinkUNeXt-VINE，用于葡萄园环境中的LiDAR位置识别。", "motivation": "农业环境中定位由于其无结构特性及缺乏显著地标而具有挑战性。当前最先进的方法未能有效应对移动机器人在这些场景下的地点识别任务。", "method": "提出了一种轻量级深度学习方法MinkUNeXt-VINE，通过预处理和Matryoshka表示学习多损失函数的方法，使用低成本、稀疏的LiDAR输入及低维度输出以确保实时效率。进行了广泛的消融研究并验证了在两个大型长时间葡萄园数据集上的表现。", "result": "该方法展示了高效性，并且能够对低成本和低分辨率输入数据保持稳健性能。提供了公开代码用于复制实验结果。", "conclusion": "MinkUNeXt-VINE通过其特有的预处理及多损失函数设计，成功在葡萄园环境中实现了高性能的LiDAR位置识别，同时确保了低计算成本。"}}
{"id": "2601.18713", "pdf": "https://arxiv.org/pdf/2601.18713", "abs": "https://arxiv.org/abs/2601.18713", "authors": ["Muyuan Chen", "Muchen Li", "Renjie Liao"], "title": "Point transformer for protein structural heterogeneity analysis using CryoEM", "categories": ["q-bio.QM", "cs.AI"], "comment": null, "summary": "Structural dynamics of macromolecules is critical to their structural-function relationship. Cryogenic electron microscopy (CryoEM) provides snapshots of vitrified protein at different compositional and conformational states, and the structural heterogeneity of proteins can be characterized through computational analysis of the images. For protein systems with multiple degrees of freedom, it is still challenging to disentangle and interpret the different modes of dynamics. Here, by implementing Point Transformer, a self-attention network designed for point cloud analysis, we are able to improve the performance of heterogeneity analysis on CryoEM data, and characterize the dynamics of highly complex protein systems in a more human-interpretable way.", "AI": {"tldr": "本论文通过实现点变换器，提高了CryoEM数据的异质性分析性能，并以更易于人类理解的方式描述了复杂蛋白质系统的动态。", "motivation": "蛋白质的结构动力学对其功能至关重要。然而，在蛋白质系统中解缠和解释不同动态模式仍然具有挑战性。", "method": "通过实施为点云分析设计的自注意网络-点变换器，来改善CryoEM数据中的异质性分析性能。", "result": "本研究提高了对复杂蛋白系统的异质性和动力学特征的理解，并以一种更易解读的方式进行描述。", "conclusion": "利用点变换器可以更好地解析和理解蛋白质系统中复杂的动态模式。"}}
{"id": "2601.18710", "pdf": "https://arxiv.org/pdf/2601.18710", "abs": "https://arxiv.org/abs/2601.18710", "authors": ["A. Bano", "L. Liebovitch"], "title": "Analyzing Images of Blood Cells with Quantum Machine Learning Methods: Equilibrium Propagation and Variational Quantum Circuits to Detect Acute Myeloid Leukemia", "categories": ["cs.ET", "cs.LG", "quant-ph"], "comment": "5 pages, 1 figure, 2 tables", "summary": "This paper presents a feasibility study demonstrating that quantum machine learning (QML) algorithms achieve competitive performance on real-world medical imaging despite operating under severe constraints. We evaluate Equilibrium Propagation (EP), an energy-based learning method that does not use backpropagation (incompatible with quantum systems due to state-collapsing measurements) and Variational Quantum Circuits (VQCs) for automated detection of Acute Myeloid Leukemia (AML) from blood cell microscopy images using binary classification (2 classes: AML vs. Healthy). Key Result: Using limited subsets (50-250 samples per class) of the AML-Cytomorphology dataset (18,365 expert-annotated images), quantum methods achieve performance only 12-15% below classical CNNs despite reduced image resolution (64x64 pixels), engineered features (20D), and classical simulation via Qiskit. EP reaches 86.4% accuracy (only 12% below CNN) without backpropagation, while the 4-qubit VQC attains 83.0% accuracy with consistent data efficiency: VQC maintains stable 83% performance with only 50 samples per class, whereas CNN requires 250 samples (5x more data) to reach 98%. These results establish reproducible baselines for QML in healthcare, validating NISQ-era feasibility.", "AI": {"tldr": "本文研究了量子机器学习算法在实际医疗成像中的可行性，特别是用于急性髓系白血病（AML）的自动检测。", "motivation": "探索量子机器学习方法在受限条件下的性能潜力，并与传统方法进行对比，以验证其在真实世界医学图像分析中的应用价值。", "method": "使用平衡传播算法和变分量子电路对血液细胞显微镜图像进行二分类（AML vs. 健康），评估两种量子机器学习方法的检测能力。", "result": "尽管样本数量有限、图像分辨率较低且没有反向传播，所提出的量子方法仍能达到83%至86.4%的准确率，并表现出良好的数据效率和稳定性。", "conclusion": "研究结果表明，在当前嘈杂中等规模量子（NISQ）时代下，量子机器学习在医疗影像分析中的可行性得到了验证，提供了可靠的基准线。"}}
{"id": "2601.18707", "pdf": "https://arxiv.org/pdf/2601.18707", "abs": "https://arxiv.org/abs/2601.18707", "authors": ["Jan Hagnberger", "Mathias Niepert"], "title": "SMART: Scalable Mesh-free Aerodynamic Simulations from Raw Geometries using a Transformer-based Surrogate Model", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.NE"], "comment": null, "summary": "Machine learning-based surrogate models have emerged as more efficient alternatives to numerical solvers for physical simulations over complex geometries, such as car bodies. Many existing models incorporate the simulation mesh as an additional input, thereby reducing prediction errors. However, generating a simulation mesh for new geometries is computationally costly. In contrast, mesh-free methods, which do not rely on the simulation mesh, typically incur higher errors. Motivated by these considerations, we introduce SMART, a neural surrogate model that predicts physical quantities at arbitrary query locations using only a point-cloud representation of the geometry, without requiring access to the simulation mesh. The geometry and simulation parameters are encoded into a shared latent space that captures both structural and parametric characteristics of the physical field. A physics decoder then attends to the encoder's intermediate latent representations to map spatial queries to physical quantities. Through this cross-layer interaction, the model jointly updates latent geometric features and the evolving physical field. Extensive experiments show that SMART is competitive with and often outperforms existing methods that rely on the simulation mesh as input, demonstrating its capabilities for industry-level simulations.", "AI": {"tldr": "本文提出了一种基于Transformer的神经网络模型SMART，用于从原始几何形状点云预测物理量，无需模拟网格输入。", "motivation": "现有的基于机器学习的替代模型通常需要将仿真网格作为额外输入以减少预测误差。然而生成新的几何形状的模拟网格是计算密集型任务。为了克服这一问题，论文提出了SMART。", "method": "SMART通过一个编码器将几何和仿真参数转换为共享潜在空间，并利用物理解码器在跨层交互中更新几何特征和物理场。", "result": "实验结果表明，SMART与现有依赖于模拟网格输入的方法相比具有竞争力并往往表现更优。", "conclusion": "该模型展示了其在行业级仿真中的能力。"}}
{"id": "2601.18706", "pdf": "https://arxiv.org/pdf/2601.18706", "abs": "https://arxiv.org/abs/2601.18706", "authors": ["Zhichao Yang", "Sepehr Janghorbani", "Dongxu Zhang", "Jun Han", "Qian Qian", "Andrew Ressler II", "Gregory D. Lyng", "Sanjit Singh Batra", "Robert E. Tillman"], "title": "Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable.", "AI": {"tldr": "介绍了一种可扩展的评估和训练框架Health-SCORE，用于改善医疗领域的大型语言模型。", "motivation": "在安全关键领域如医疗保健中创建高质量且特定域的评分标准需要大量的人力专业知识及开发成本，这使得基于评分标准的评估与培训难以规模化。", "method": "提出了一种通用且可扩展的评分框架Health-SCORE，以显著降低评分开发的成本而不牺牲性能。该框架不仅可以作为结构化的奖励信号引导带安全意识监督的强化学习，还可以直接融入提示中通过上下文学习改进响应质量。", "result": "在各种开放式的医疗任务上，Health-SCORE实现了与人类创建评分标准相当的评估质量的同时大幅降低了开发的努力。", "conclusion": "使得基于评分标准的评估和培训更加可扩展。"}}
{"id": "2601.18702", "pdf": "https://arxiv.org/pdf/2601.18702", "abs": "https://arxiv.org/abs/2601.18702", "authors": ["Hansheng Ren"], "title": "From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": "8 pages, 6 figures. Submitted to UAI 2026", "summary": "Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the \"hallucinations\" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.", "AI": {"tldr": "本文提出了Halo架构，旨在通过有理数算术减少大型语言模型中的逻辑不确定性。", "motivation": "当前深度学习方法依赖于低精度的浮点运算，这会导致累积误差和逻辑不一致性。作者提出精确性假设，即高级智能需要任意精度算术作为计算基础。", "method": "引入Halo架构和支持它的准确推理单元（EIU），该架构基于有理数算术，并通过实验证明在复杂系统中可以保持零数值偏差。", "result": "实验表明，在600B参数规模下，基准模型使用BF16格式时会崩溃于混乱状态，而Halo架构能够无限期地维持无数值偏离。", "conclusion": "本文确立了精确算术作为减少系统2AGI逻辑不确定性前提的重要性。"}}
{"id": "2601.18700", "pdf": "https://arxiv.org/pdf/2601.18700", "abs": "https://arxiv.org/abs/2601.18700", "authors": ["Xingyu Sui", "Yanyan Zhao", "Yulin Hu", "Jiahe Guo", "Weixiang Zhao", "Bing Qin"], "title": "TEA-Bench: A Systematic Benchmarking of Tool-enhanced Emotional Support Dialogue Agent", "categories": ["cs.AI"], "comment": null, "summary": "Emotional Support Conversation requires not only affective expression but also grounded instrumental support to provide trustworthy guidance. However, existing ESC systems and benchmarks largely focus on affective support in text-only settings, overlooking how external tools can enable factual grounding and reduce hallucination in multi-turn emotional support. We introduce TEA-Bench, the first interactive benchmark for evaluating tool-augmented agents in ESC, featuring realistic emotional scenarios, an MCP-style tool environment, and process-level metrics that jointly assess the quality and factual grounding of emotional support. Experiments on nine LLMs show that tool augmentation generally improves emotional support quality and reduces hallucination, but the gains are strongly capacity-dependent: stronger models use tools more selectively and effectively, while weaker models benefit only marginally. We further release TEA-Dialog, a dataset of tool-enhanced ESC dialogues, and find that supervised fine-tuning improves in-distribution support but generalizes poorly. Our results underscore the importance of tool use in building reliable emotional support agents.", "AI": {"tldr": "该论文介绍了TEA-Bench，一个用于评估工具增强型代理在情感支持对话中的表现的系统性基准。", "motivation": "当前的情感支持对话系统和基准主要集中在文本情感支持上，忽略了外部工具如何提高事实基础并减少多轮对话中的幻觉问题。因此，该论文旨在填补这一空白。", "method": "TEA-Bench包括真实的感情场景、MCP风格的工具环境以及衡量质量和事实依据的过程级指标。实验在九个大模型上进行，并发布了TEA-Dialog数据集来评估监督微调的效果。", "result": "实验证明，使用外部工具可以提高情感支持的质量并减少幻觉问题。然而，这种改进取决于模型的能力：更强的模型更有效地选择和使用工具，而较弱的模型仅能稍微获益。", "conclusion": "结果表明，在构建可靠的情感支持代理时，有效利用工具至关重要。"}}
{"id": "2601.18698", "pdf": "https://arxiv.org/pdf/2601.18698", "abs": "https://arxiv.org/abs/2601.18698", "authors": ["Xiao Liu", "Jiawei Zhang"], "title": "Are Video Generation Models Geographically Fair? An Attraction-Centric Evaluation of Global Visual Knowledge", "categories": ["cs.CV"], "comment": "Work in progress", "summary": "Recent advances in text-to-video generation have produced visually compelling results, yet it remains unclear whether these models encode geographically equitable visual knowledge. In this work, we investigate the geo-equity and geographically grounded visual knowledge of text-to-video models through an attraction-centric evaluation. We introduce Geo-Attraction Landmark Probing (GAP), a systematic framework for assessing how faithfully models synthesize tourist attractions from diverse regions, and construct GEOATTRACTION-500, a benchmark of 500 globally distributed attractions spanning varied regions and popularity levels. GAP integrates complementary metrics that disentangle overall video quality from attraction-specific knowledge, including global structural alignment, fine-grained keypoint-based alignment, and vision-language model judgments, all validated against human evaluation. Applying GAP to the state-of-the-art text-to-video model Sora 2, we find that, contrary to common assumptions of strong geographic bias, the model exhibits a relatively uniform level of geographically grounded visual knowledge across regions, development levels, and cultural groupings, with only weak dependence on attraction popularity. These results suggest that current text-to-video models express global visual knowledge more evenly than expected, highlighting both their promise for globally deployed applications and the need for continued evaluation as such systems evolve.", "AI": {"tldr": "研究通过引入Geo-Attraction Landmark Probing（GAP）框架评估文本到视频生成模型在不同地区旅游景点的视觉知识准确性。", "motivation": "探讨当前先进文本至视频生成模型是否具备地理公平性，即其编码的视觉知识在全球范围内分布是否均衡。", "method": "构建一个名为Geo-Attraction Landmark Probing（GAP）的新框架来评估不同地区的旅游景点在生成视频中的表现，并通过多个指标评价包括全球结构对齐、关键点基线对齐和视觉语言模型评判等。", "result": "发现最先进的文本到视频生成系统Sora2在处理来自不同地区、发展水平及文化背景的旅游景点时，展现了一种相对均衡的地理相关知识，且这种知识与吸引力的流行程度关系不大。", "conclusion": "当前的文本至视频模型在全球范围内表现出了比预期更均匀的知识分布，这表明它们对于全球应用具有巨大潜力，同时也强调了继续对其发展进行评估的重要性。"}}
{"id": "2601.18697", "pdf": "https://arxiv.org/pdf/2601.18697", "abs": "https://arxiv.org/abs/2601.18697", "authors": ["Junling Wang", "Lahari Goswami", "Gustavo Kreia Umbelino", "Kiara Garcia Chau", "Mrinmaya Sachan", "April Yi Wang"], "title": "Bridging Instead of Replacing Online Coding Communities with AI through Community-Enriched Chatbot Designs", "categories": ["cs.HC"], "comment": "Accepted at the ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW 2026). To appear in PACMHCI", "summary": "LLM-based chatbots like ChatGPT have become popular tools for assisting with coding tasks. However, they often produce isolated responses and lack mechanisms for social learning or contextual grounding. In contrast, online coding communities like Kaggle offer socially mediated learning environments that foster critical thinking, engagement, and a sense of belonging. Yet, growing reliance on LLMs risks diminishing participation in these communities and weakening their collaborative value. To address this, we propose Community-Enriched AI, a design paradigm that embeds social learning dynamics into LLM-based chatbots by surfacing user-generated content and social design feature from online coding communities. Using this paradigm, we implemented a RAG-based AI chatbot leveraging resources from Kaggle to validate our design. Across two empirical studies involving 28 and 12 data science learners, respectively, we found that Community-Enriched AI significantly enhances user trust, encourages engagement with community, and effectively supports learners in solving data science tasks. We conclude by discussing design implications for AI assistance systems that bridge -- rather than replace -- online coding communities.", "AI": {"tldr": "提出社区增强型AI设计范式，使LLM聊天机器人嵌入社交学习机制，通过融入用户生成内容和在线编程社区的设计特点来增强用户体验。", "motivation": "当前基于LLM的聊天机器人在处理编码任务时通常提供孤立的答案，并缺乏社会学习或情境定位的机制。同时，过度依赖这些工具可能会削弱在线编程社区的价值和参与度。因此需要一种设计方法将社交元素融入AI系统中。", "method": "提出了一种名为“社区增强型AI”的新设计范式，通过整合用户生成的内容和来自Kaggle等平台的设计特点来改进LLM聊天机器人。在两个实证研究中验证该模型的有效性。", "result": "实验结果表明，与传统方法相比，社区增强型AI显著提高了用户的信任度并鼓励了对社区的参与和支持学习者解决数据科学任务的能力。", "conclusion": "讨论了设计面向社区的AI辅助系统的潜在影响和未来研究方向，强调应开发能够促进而非取代在线编程社区互动的设计。"}}
{"id": "2601.18694", "pdf": "https://arxiv.org/pdf/2601.18694", "abs": "https://arxiv.org/abs/2601.18694", "authors": ["Aayush M. Shrestha", "Aditya Bajracharya", "Projan Shakya", "Dinesh B. Kshatri"], "title": "Neural Multi-Speaker Voice Cloning for Nepali in Low-Resource Settings", "categories": ["cs.SD", "cs.AI"], "comment": "16 pages with appendix included", "summary": "This research presents a few-shot voice cloning system for Nepali speakers, designed to synthesize speech in a specific speaker's voice from Devanagari text using minimal data. Voice cloning in Nepali remains largely unexplored due to its low-resource nature. To address this, we constructed separate datasets: untranscribed audio for training a speaker encoder and paired text-audio data for training a Tacotron2-based synthesizer. The speaker encoder, optimized with Generative End2End loss, generates embeddings that capture the speaker's vocal identity, validated through Uniform Manifold Approximation and Projection (UMAP) for dimension reduction visualizations. These embeddings are fused with Tacotron2's text embeddings to produce mel-spectrograms, which are then converted into audio using a WaveRNN vocoder. Audio data were collected from various sources, including self-recordings, and underwent thorough preprocessing for quality and alignment. Training was performed using mel and gate loss functions under multiple hyperparameter settings. The system effectively clones speaker characteristics even for unseen voices, demonstrating the feasibility of few-shot voice cloning for the Nepali language and establishing a foundation for personalized speech synthesis in low-resource scenarios.", "AI": {"tldr": "该论文提出了一个针对尼泊尔语的少样本声音克隆系统，使用最少的数据从德瓦那格里文本合成特定说话者的语音。", "motivation": "由于尼泊尔语资源匮乏，其声音克隆技术尚未得到充分研究。为了填补这一空白，作者开发了一种有效的声音克隆方法以适应低资源环境下的个性化语音合成功能。", "method": "通过构建单独的未标注音频训练说话者编码器和文本-音频配对数据训练Tacotron2合成器的数据集，优化后的说话者编码器利用生成式端到端损失函数产生捕捉说话人声音特征的身份嵌入。这些嵌入与Tacotron2的文字嵌合以生成梅尔频谱图，并通过WaveRNN声码器转换成音频。", "result": "该系统能够有效克隆未见过的说话者的声音特性，证明了在低资源条件下实现尼泊尔语少样本声音克隆的可行性。", "conclusion": "这项研究展示了在有限数据下进行个性化语音合成功能的有效性，并为今后开发更多样化的语言应用奠定了基础。"}}
{"id": "2601.18692", "pdf": "https://arxiv.org/pdf/2601.18692", "abs": "https://arxiv.org/abs/2601.18692", "authors": ["Wei Wu", "Fan Lu", "Yunnan Wang", "Shuai Yang", "Shi Liu", "Fangjing Wang", "Qian Zhu", "He Sun", "Yong Wang", "Shuailei Ma", "Yiyu Ren", "Kejia Zhang", "Hui Yu", "Jingmei Zhao", "Shuai Zhou", "Zhenqi Qiu", "Houlong Xiong", "Ziyu Wang", "Zechen Wang", "Ran Cheng", "Yong-Lu Li", "Yongtao Huang", "Xing Zhu", "Yujun Shen", "Kecheng Zheng"], "title": "A Pragmatic VLA Foundation Model", "categories": ["cs.RO", "cs.CV"], "comment": "Project Webpage: https://technology.robbyant.com/lingbot-vla/, Code: https://github.com/Robbyant/lingbot-vla/", "summary": "Offering great potential in robotic manipulation, a capable Vision-Language-Action (VLA) foundation model is expected to faithfully generalize across tasks and platforms while ensuring cost efficiency (e.g., data and GPU hours required for adaptation). To this end, we develop LingBot-VLA with around 20,000 hours of real-world data from 9 popular dual-arm robot configurations. Through a systematic assessment on 3 robotic platforms, each completing 100 tasks with 130 post-training episodes per task, our model achieves clear superiority over competitors, showcasing its strong performance and broad generalizability. We have also built an efficient codebase, which delivers a throughput of 261 samples per second per GPU with an 8-GPU training setup, representing a 1.5~2.8$\\times$ (depending on the relied VLM base model) speedup over existing VLA-oriented codebases. The above features ensure that our model is well-suited for real-world deployment. To advance the field of robot learning, we provide open access to the code, base model, and benchmark data, with a focus on enabling more challenging tasks and promoting sound evaluation standards.", "AI": {"tldr": "开发了具有强大泛化能力的VLA基础模型LingBot-VLA，通过大量实测数据和多平台评估验证其性能。", "motivation": "期望建立一个能够在任务和平台上广泛通用且成本效益高的VLA基础模型。", "method": "使用约20,000小时的真实世界数据训练模型，并在三个机器人平台上进行了系统性评估，以展示其泛化能力与效率。", "result": "该模型相较于竞争对手显示出明显的优越性，在130个后训练场景中实现了显著的性能提升。", "conclusion": "LingBot-VLA具备高性能和广泛的适用性，适合实际部署，并通过开放资源支持更复杂的任务评估。"}}
{"id": "2601.18681", "pdf": "https://arxiv.org/pdf/2601.18681", "abs": "https://arxiv.org/abs/2601.18681", "authors": ["Yilie Huang", "Wenpin Tang", "Xunyu Zhou"], "title": "ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule", "categories": ["cs.LG", "cs.AI", "eess.SY", "math.OC"], "comment": "17 pages, 7 figures", "summary": "We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Fréchet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining.", "AI": {"tldr": "本文提出了一种自适应重参数化时间(ART)方法，通过强化学习来优化扩散模型的时间步长调度以提高生成样本的质量。", "motivation": "传统的时间离散化方式如均匀和手工设计的网格可能不是最优的选择，尤其是在给定时间步预算的情况下。为了最小化由离散欧拉方案引起的累积误差，研究提出了一种新的方法。", "method": "该方法包括自适应重参数化时间和其随机控制伙伴ART-RL，将时间变化问题视为连续时间强化学习问题，并使用高斯策略来解决这一问题。通过证明求解ART-RL可以恢复最优的ART调度，实现了基于数据驱动的方式来更新演员和评论者。", "result": "在官方EDM流水线上进行实验后，发现基于CIFAR-10的数据集上，ART-RL改进了Fréchet Inception距离，并且该方法能够迁移到AFHQv2、FFHQ和ImageNet等其他图像数据集中而不需要重新训练。", "conclusion": "通过采用自适应重参数化时间(ART)和强化学习相结合的方法，可以在不增加计算成本的情况下提高生成模型的样本质量。"}}
{"id": "2601.18678", "pdf": "https://arxiv.org/pdf/2601.18678", "abs": "https://arxiv.org/abs/2601.18678", "authors": ["Eslam Zaher", "Maciej Trzaskowski", "Quan Nguyen", "Fred Roosta"], "title": "Counterfactual Explanations on Robust Perceptual Geodesics", "categories": ["cs.LG", "cs.CV", "cs.HC", "math.DG"], "comment": "Accepted at ICLR 2026", "summary": "Latent-space optimization methods for counterfactual explanations - framed as minimal semantic perturbations that change model predictions - inherit the ambiguity of Wachter et al.'s objective: the choice of distance metric dictates whether perturbations are meaningful or adversarial. Existing approaches adopt flat or misaligned geometries, leading to off-manifold artifacts, semantic drift, or adversarial collapse. We introduce Perceptual Counterfactual Geodesics (PCG), a method that constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. This geometry aligns with human perception and penalizes brittle directions, enabling smooth, on-manifold, semantically valid transitions. Experiments on three vision datasets show that PCG outperforms baselines and reveals failure modes hidden under standard metrics.", "AI": {"tldr": "本文提出了感知反事实测地线(PCG)方法，通过在稳健视觉特征诱导的感知黎曼度量下追踪测地线来构造反事实样本。", "motivation": "现有反事实解释方法由于采用了扁平或不对齐的几何结构，导致生成的扰动不具有真实意义或是对抗性的。本文旨在提供一种与人类感知一致且能避免脆弱方向的方法。", "method": "PCG通过在稳健视觉特征诱导的感知黎曼度量下追踪测地线来构造反事实样本，这种方法使得生成的过渡平滑、位于数据流形上并具有语义有效性。", "result": "实验结果表明，在三个视觉数据集上的性能评估中，PCG优于基线方法，并揭示了在标准度量下隐藏的失败模式。", "conclusion": "本文提出的方法能够在保持反事实样本语义一致性和避免对抗性扰动的同时，提供更有效的解释能力。"}}
{"id": "2601.18675", "pdf": "https://arxiv.org/pdf/2601.18675", "abs": "https://arxiv.org/abs/2601.18675", "authors": ["Aditya Kumar", "Mario A. Cypko", "Oliver Amft"], "title": "Learning temporal embeddings from electronic health records of chronic kidney disease patients", "categories": ["cs.LG", "cs.AI"], "comment": "7 pages, 3 figures, 3 tables. The paper has been submitted to IEEE EMBC 2026 and copyright might be transferred without notice", "summary": "We investigate whether temporal embedding models trained on longitudinal electronic health records can learn clinically meaningful representations without compromising predictive performance, and how architectural choices affect embedding quality. Model-guided medicine requires representations that capture disease dynamics while remaining transparent and task agnostic, whereas most clinical prediction models are optimised for a single task. Representation learning facilitates learning embeddings that generalise across downstream tasks, and recurrent architectures are well-suited for modelling temporal structure in observational clinical data. Using the MIMIC-IV dataset, we study patients with chronic kidney disease (CKD) and compare three recurrent architectures: a vanilla LSTM, an attention-augmented LSTM, and a time-aware LSTM (T-LSTM). All models are trained both as embedding models and as direct end-to-end predictors. Embedding quality is evaluated via CKD stage clustering and in-ICU mortality prediction. The T-LSTM produces more structured embeddings, achieving a lower Davies-Bouldin Index (DBI = 9.91) and higher CKD stage classification accuracy (0.74) than the vanilla LSTM (DBI = 15.85, accuracy = 0.63) and attention-augmented LSTM (DBI = 20.72, accuracy = 0.67). For in-ICU mortality prediction, embedding models consistently outperform end-to-end predictors, improving accuracy from 0.72-0.75 to 0.82-0.83, which indicates that learning embeddings as an intermediate step is more effective than direct end-to-end learning.", "AI": {"tldr": "通过纵向电子健康记录训练的时序嵌入模型学习临床有意义的表示，并研究架构选择对嵌入质量的影响。", "motivation": "探讨是否可以从慢性肾病患者的电子健康记录中学习出既具有临床意义又不牺牲预测性能的时序表示，以及不同的架构如何影响嵌入的质量。", "method": "使用MIMIC-IV数据集对比研究三种递归结构：普通LSTM、注意力增强的LSTM和时间感知LSTM（T-LSTM），并评估CKD阶段聚类和重症监护室死亡预测任务中的表现。", "result": "T-LSTM在嵌入质量方面优于其他两种模型，其DBI更低且分类准确率更高；此外，在ICU死亡预测中，通过学习嵌入作为中间步骤比直接端到端学习更有效。", "conclusion": "时序嵌入方法不仅能够在保持临床意义的同时提高预测性能，而且在某些任务上超越了传统的端到端模型。"}}
{"id": "2601.18670", "pdf": "https://arxiv.org/pdf/2601.18670", "abs": "https://arxiv.org/abs/2601.18670", "authors": ["Yulong Zhang", "Ying Cui", "Zili Meng", "Abhishek Kumar", "Dirk Kutscher"], "title": "COMETS: Coordinated Multi-Destination Video Transmission with In-Network Rate Adaptation", "categories": ["cs.NI", "cs.MM", "eess.IV"], "comment": "Accepted to appear in IEEE Transactions on Multimedia (2026)", "summary": "Large-scale video streaming events attract millions of simultaneous viewers, stressing existing delivery infrastructures. Client-driven adaptation reacts slowly to shared congestion, while server-based coordination introduces scalability bottlenecks and single points of failure. We present COMETS, a coordinated multi-destination video transmission framework that leverages information-centric networking principles such as request aggregation and in-network state awareness to enable scalable, fair, and adaptive rate control. COMETS introduces a novel range-interest protocol and distributed in-network decision process that aligns video quality across receiver groups while minimizing redundant transmissions. To achieve this, we develop a lightweight distributed optimization framework that guides per-hop quality adaptation without centralized control. Extensive emulation shows that COMETS consistently improves bandwidth utilization, fairness, and user-perceived quality of experience over DASH, MoQ, and ICN baselines, particularly under high concurrency. The results highlight COMETS as a practical, deployable approach for next-generation scalable video delivery.", "AI": {"tldr": "提出了COMETS框架，用于大规模视频流传输事件的高效协调多目标视频传输。", "motivation": "现有的交付基础设施在处理数百万同时观看者时压力很大。客户端驱动的适应反应缓慢，服务器端协调则引入了可扩展瓶颈和单点故障。", "method": "开发了一种基于信息中心网络原理的框架COMETS，该框架利用请求聚合和网内状态感知来实现可伸缩、公平且自适应的速率控制。", "result": "仿真结果显示，在高并发情况下，与DASH、MoQ和ICN基线相比，COMETS在带宽利用率、公平性和用户体验方面表现更优。", "conclusion": "COMETS是一个实用且可部署的方法，适用于下一代大规模视频分发。"}}
{"id": "2601.18650", "pdf": "https://arxiv.org/pdf/2601.18650", "abs": "https://arxiv.org/abs/2601.18650", "authors": ["Liheng Yu", "Zhe Zhao", "Yuxuan Wang", "Pengkun Wang", "Binwu Wang", "Yang Wang"], "title": "FaLW: A Forgetting-aware Loss Reweighting for Long-tailed Unlearning", "categories": ["cs.LG", "cs.AI"], "comment": "camera-ready for iclr2026", "summary": "Machine unlearning, which aims to efficiently remove the influence of specific data from trained models, is crucial for upholding data privacy regulations like the ``right to be forgotten\". However, existing research predominantly evaluates unlearning methods on relatively balanced forget sets. This overlooks a common real-world scenario where data to be forgotten, such as a user's activity records, follows a long-tailed distribution. Our work is the first to investigate this critical research gap. We find that in such long-tailed settings, existing methods suffer from two key issues: \\textit{Heterogeneous Unlearning Deviation} and \\textit{Skewed Unlearning Deviation}. To address these challenges, we propose FaLW, a plug-and-play, instance-wise dynamic loss reweighting method. FaLW innovatively assesses the unlearning state of each sample by comparing its predictive probability to the distribution of unseen data from the same class. Based on this, it uses a forgetting-aware reweighting scheme, modulated by a balancing factor, to adaptively adjust the unlearning intensity for each sample. Extensive experiments demonstrate that FaLW achieves superior performance. Code is available at \\textbf{Supplementary Material}.", "AI": {"tldr": "研究提出了一种名为FaLW的遗忘感知损失重新加权方法，以解决长尾分布数据集下的机器卸载问题。", "motivation": "现有研究主要评估的是平衡的数据集上的卸载方法，忽略了现实世界中需要忘记的数据（如用户活动记录）通常遵循长尾分布的情况。在这样的场景下，现有的卸载方法存在偏差问题。", "method": "提出了一种基于实例的动态损失重新加权方法FaLW，通过比较每个样本的概率与未见数据从同一类别的概率分布来评估其卸载状态，并利用遗忘感知再平衡方案调整每个样本的卸载强度。", "result": "实验结果表明，提出的FaLW方法在长尾场景中具有更优越的表现。", "conclusion": "提出了针对长尾数据集下的机器卸载问题的有效解决方案，并展示了其在实际应用场景中的优势。"}}
{"id": "2601.18642", "pdf": "https://arxiv.org/pdf/2601.18642", "abs": "https://arxiv.org/abs/2601.18642", "authors": ["Lei Wei", "Xu Dong", "Xiao Peng", "Niantao Xie", "Bin Wang"], "title": "FadeMem: Biologically-Inspired Forgetting for Efficient Agent Memory", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large language models deployed as autonomous agents face critical memory limitations, lacking selective forgetting mechanisms that lead to either catastrophic forgetting at context boundaries or information overload within them. While human memory naturally balances retention and forgetting through adaptive decay processes, current AI systems employ binary retention strategies that preserve everything or lose it entirely. We propose FadeMem, a biologically-inspired agent memory architecture that incorporates active forgetting mechanisms mirroring human cognitive efficiency. FadeMem implements differential decay rates across a dual-layer memory hierarchy, where retention is governed by adaptive exponential decay functions modulated by semantic relevance, access frequency, and temporal patterns. Through LLM-guided conflict resolution and intelligent memory fusion, our system consolidates related information while allowing irrelevant details to fade. Experiments on Multi-Session Chat, LoCoMo, and LTI-Bench demonstrate superior multi-hop reasoning and retrieval with 45\\% storage reduction, validating the effectiveness of biologically-inspired forgetting in agent memory systems.", "AI": {"tldr": "FadeMem是一种生物启发的记忆架构，旨在通过主动遗忘机制解决自主代理的内存限制问题。", "motivation": "现有的AI系统缺乏选择性遗忘机制，在上下文边界处容易出现灾难性的记忆丢失或信息过载。人类记忆能够自然地在保留和忘记之间找到平衡，而当前的人工智能系统则采用二进制保持策略，要么保存一切要么全部失去。", "method": "FadeMem通过实现双层存储体系结构中的差异性衰减率，并利用语义相关性、访问频率和时间模式的适应性指数衰减函数来控制保留。此外，该架构还使用LLM引导的竞争解决与智能记忆融合，以整合相关信息并让无关细节逐渐消失。", "result": "实验结果表明，FadeMem在多轮对话、LoCoMo和LTI-Bench上的表现优于现有系统，减少了45％的存储需求，并且提高了跨步推理和检索的能力。", "conclusion": "生物启发式遗忘机制能够有效提高代理系统的内存效率，同时保持或改善其性能。"}}
{"id": "2601.18641", "pdf": "https://arxiv.org/pdf/2601.18641", "abs": "https://arxiv.org/abs/2601.18641", "authors": ["Onyedikachi Hope Amaechi-Okorie", "Branislav Radeljic"], "title": "Unheard in the Digital Age: Rethinking AI Bias and Speech Diversity", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "Speech remains one of the most visible yet overlooked vectors of inclusion and exclusion in contemporary society. While fluency is often equated with credibility and competence, individuals with atypical speech patterns are routinely marginalized. Given the current state of the debate, this article focuses on the structural biases that shape perceptions of atypical speech and are now being encoded into artificial intelligence. Automated speech recognition (ASR) systems and voice interfaces, trained predominantly on standardized speech, routinely fail to recognize or respond to diverse voices, compounding digital exclusion. As AI technologies increasingly mediate access to opportunity, the study calls for inclusive technological design, anti-bias training to minimize the impact of discriminatory algorithmic decisions, and enforceable policy reform that explicitly recognize speech diversity as a matter of equity, not merely accessibility. Drawing on interdisciplinary research, the article advocates for a cultural and institutional shift in how we value voice, urging co-created solutions that elevate the rights, representation, and realities of atypical speakers in the digital age. Ultimately, the article reframes speech inclusion as a matter of equity (not accommodation) and advocates for co-created AI systems that reflect the full spectrum of human voices.", "AI": {"tldr": "探讨在数字时代中人工智能偏见和语音多样性的问题，提出包容性设计、反偏训练及政策改革的重要性。", "motivation": "当前自动化语音识别系统主要基于标准化语音训练，导致对非标准声音的忽视与歧视加剧。", "method": "通过跨学科研究分析结构性偏见如何影响AI技术中的语音处理，并倡导文化及制度上的转变。", "result": "主张在人工智能设计中重视语音多样性，促进公平而非仅仅是可访问性。", "conclusion": "呼吁共创能够反映全人类声音的AI系统，将语音包容视为一项基本权利。"}}
{"id": "2601.18639", "pdf": "https://arxiv.org/pdf/2601.18639", "abs": "https://arxiv.org/abs/2601.18639", "authors": ["Ojasva Mishra", "Xiaolong Wu", "Min Xu"], "title": "Constraint-Aware Discrete-Time PID Gain Optimization for Robotic Joint Control Under Actuator Saturation", "categories": ["cs.RO"], "comment": "Pending IEEE Transactions on Robotics Publication", "summary": "The precise regulation of rotary actuation is fundamental in autonomous robotics, yet practical PID loops deviate from continuous-time theory due to discrete-time execution, actuator saturation, and small delays and measurement imperfections. We present an implementation-aware analysis and tuning workflow for saturated discrete-time joint control. We (i) derive PI stability regions under Euler and exact zero-order-hold (ZOH) discretizations using the Jury criterion, (ii) evaluate a discrete back-calculation anti-windup realization under saturation-dominant regimes, and (iii) propose a hybrid-certified Bayesian optimization workflow that screens analytically unstable candidates and behaviorally unsafe transients while optimizing a robust IAE objective with soft penalties on overshoot and saturation duty. Baseline sweeps ($τ=1.0$~s, $Δt=0.01$~s, $u\\in[-10,10]$) quantify rise/settle trends for P/PI/PID. Under a randomized model family emulating uncertainty, delay, noise, quantization, and tighter saturation, robustness-oriented tuning improves median IAE from $0.843$ to $0.430$ while keeping median overshoot below $2\\%$. In simulation-only tuning, the certification screen rejects $11.6\\%$ of randomly sampled gains within bounds before full robust evaluation, improving sample efficiency without hardware experiments.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.18633", "pdf": "https://arxiv.org/pdf/2601.18633", "abs": "https://arxiv.org/abs/2601.18633", "authors": ["Tong Shi", "Melonie de Almeida", "Daniela Ivanova", "Nicolas Pugeault", "Paul Henderson"], "title": "Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "Talking Head Generation aims at synthesizing natural-looking talking videos from speech and a single portrait image. Previous 3D talking head generation methods have relied on domain-specific heuristics such as warping-based facial motion representation priors to animate talking motions, yet still produce inaccurate 3D avatar reconstructions, thus undermining the realism of generated animations. We introduce Splat-Portrait, a Gaussian-splatting-based method that addresses the challenges of 3D head reconstruction and lip motion synthesis. Our approach automatically learns to disentangle a single portrait image into a static 3D reconstruction represented as static Gaussian Splatting, and a predicted whole-image 2D background. It then generates natural lip motion conditioned on input audio, without any motion driven priors. Training is driven purely by 2D reconstruction and score-distillation losses, without 3D supervision nor landmarks. Experimental results demonstrate that Splat-Portrait exhibits superior performance on talking head generation and novel view synthesis, achieving better visual quality compared to previous works. Our project code and supplementary documents are public available at https://github.com/stonewalking/Splat-portrait.", "AI": {"tldr": "本文提出了一种基于高斯点散布的方法Splat-Portrait，用于生成逼真的说话头像视频。", "motivation": "现有的三维说话头部生成方法依赖特定领域的启发式方法，如基于变形的脸部运动表示先验条件来驱动动作动画。这些方法难以准确地重建三维头部模型并合成唇部动作，从而影响生成动画的现实感。", "method": "本文提出了一种新的基于高斯点散布的方法Splat-Portrait，该方法通过自动将单幅肖像图像分解成静态的三维重构和预测的整体背景图来解决二维和三维头部分析问题，并且根据输入音频生成自然唇部动作。", "result": "实验结果表明，Splat-Portrait在说话头部生成及新颖视角合成方面表现出色，其视觉效果优于之前的工作。", "conclusion": "通过引入新的基于高斯点散布的方法，本文显著提高了三维头部分析的准确性和现实感，并展示了比现有方法更好的性能。"}}
{"id": "2601.18631", "pdf": "https://arxiv.org/pdf/2601.18631", "abs": "https://arxiv.org/abs/2601.18631", "authors": ["Mingyang Song", "Haoyu Sun", "Jiawei Gu", "Linjie Li", "Luxin Xu", "Ranjay Krishna", "Yu Cheng"], "title": "AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.MA"], "comment": "28 pages, 10 figures and 13 tables", "summary": "When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \\textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.", "AI": {"tldr": "介绍了AdaReasoner，一种用于迭代视觉推理的动态工具编排系统。", "motivation": "在处理超出直接能力的问题时，人类依赖于工具。因此，在多模态大型语言模型中改进视觉推理需要了解何时何地使用何种工具以及如何组合这些工具以完成任务。", "method": "通过构建可扩展的数据管理管道暴露模型的长期、多步工具交互；利用Tool-GRPO算法优化基于最终任务成功的工具选择和排序；并采用自适应学习机制动态调节工具使用。", "result": "AdaReasoner表现出强大的工具适应性和泛化能力，提高了7B基础模型在多个挑战性基准测试中的性能，并超越了GPT-5等强大系统。", "conclusion": "通过上述方法，实现了模型从任务上下文和中间结果中推断出工具的效用，从而协调多种工具并推广到未知工具。"}}
{"id": "2601.18630", "pdf": "https://arxiv.org/pdf/2601.18630", "abs": "https://arxiv.org/abs/2601.18630", "authors": ["Abeer Badawi", "Md Tahmid Rahman Laskar", "Elahe Rahimi", "Sheri Grach", "Lindsay Bertrand", "Lames Danok", "Frank Rudzicz", "Jimmy Huang", "Elham Dolatabadi"], "title": "Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI.", "AI": {"tldr": "评估大型语言模型在心理健康支持对话中的响应质量。", "motivation": "由于全球心理健康危机和治疗缺口，以及合格心理医生短缺的问题，探讨了大型语言模型作为可扩展的心理健康支持的潜力。然而，这些模型在可靠性、相关性和与人类标准一致性的方面仍然存在挑战。", "method": "通过一个由两个精神病训练专家进行的人类评估方法来评价九种不同大型语言模型产生的心理健康对话响应质量，并采用六项属性评分系统进行打分。", "result": "分析显示，尽管闭源模型（如GPT-4o）提供了平衡的治疗回应，开源模型显示出更多的情感平淡和变异性。此外，还存在认知与情感之间的差距，这表明需要以人类为中心、注重关系敏感度的信息准确性评估框架。", "conclusion": "倡导以人为中心、注重治疗敏感性的综合评价协议，以及在心理健康定向对话AI的设计和临床监督中提供负责任的指导框架。"}}
{"id": "2601.18629", "pdf": "https://arxiv.org/pdf/2601.18629", "abs": "https://arxiv.org/abs/2601.18629", "authors": ["Yiming Wang", "Ruogu Zhang", "Minyang Li", "Hao Shi", "Junbo Wang", "Deyi Li", "Jieji Ren", "Wenhai Liu", "Weiming Wang", "Hao-Shu Fang"], "title": "ExoGS: A 4D Real-to-Sim-to-Real Framework for Scalable Manipulation Data Collection", "categories": ["cs.RO"], "comment": null, "summary": "Real-to-Sim-to-Real technique is gaining increasing interest for robotic manipulation, as it can generate scalable data in simulation while having narrower sim-to-real gap. However, previous methods mainly focused on environment-level visual real-to-sim transfer, ignoring the transfer of interactions, which could be challenging and inefficient to obtain purely in simulation especially for contact-rich tasks. We propose ExoGS, a robot-free 4D Real-to-Sim-to-Real framework that captures both static environments and dynamic interactions in the real world and transfers them seamlessly to a simulated environment. It provides a new solution for scalable manipulation data collection and policy learning. ExoGS employs a self-designed robot-isomorphic passive exoskeleton AirExo-3 to capture kinematically consistent trajectories with millimeter-level accuracy and synchronized RGB observations during direct human demonstrations. The robot, objects, and environment are reconstructed as editable 3D Gaussian Splatting assets, enabling geometry-consistent replay and large-scale data augmentation. Additionally, a lightweight Mask Adapter injects instance-level semantics into the policy to enhance robustness under visual domain shifts. Real-world experiments demonstrate that ExoGS significantly improves data efficiency and policy generalization compared to teleoperation-based baselines. Code and hardware files have been released on https://github.com/zaixiabalala/ExoGS.", "AI": {"tldr": "ExoGS是一个用于机器人抓取的4D从真实到仿真再到真实的框架，它可以在现实世界中捕捉静态环境和动态交互，并无缝地转移到模拟环境中。", "motivation": "当前方法主要关注于视觉的真实到仿真的转换，而忽略了互动的转移。这在接触密集型任务中尤其具有挑战性和低效性。", "method": "ExoGS使用一个自设计的被动外骨骼AirExo-3来捕捉一致性的轨迹和同步RGB观察，并重建为可编辑的3D高斯点集资产，以实现几何一致性重播和大规模数据增强。此外，轻量级Mask Adapter注入实例级别语义，提高政策鲁棒性。", "result": "实验表明，ExoGS相比基于遥操作的基线显著提高了数据效率和策略泛化能力。", "conclusion": "ExoGS提供了一种新的解决方案，用于大规模抓取数据收集和策略学习。"}}
{"id": "2601.18626", "pdf": "https://arxiv.org/pdf/2601.18626", "abs": "https://arxiv.org/abs/2601.18626", "authors": ["Yingxiao Huo", "Satya Prakash Dash", "Radu Stoican", "Samuel Kaski", "Mingfei Sun"], "title": "Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines.", "AI": {"tldr": "提出了一种利用秩一近似逆费雪信息矩阵的高效自然策略优化技术，以加速深度强化学习中的收敛。", "motivation": "由于计算自然梯度需要在每次迭代中求解费雪信息矩阵的逆，这在实际应用中是计算密集型的。因此，研究者提出一种更有效的近似方法来解决这个问题。", "method": "利用秩一近似代替完整的逆费雪信息矩阵来加速自然策略优化过程，并理论证明了该方法在特定条件下收敛速度更快。", "result": "实验结果表明，在多种环境中，所提出的方法比传统的演员批评和信赖域基准表现出更好的性能。", "conclusion": "通过采用秩一近似技术，可以显著提高深度强化学习中自然策略优化的效率。"}}
{"id": "2601.18625", "pdf": "https://arxiv.org/pdf/2601.18625", "abs": "https://arxiv.org/abs/2601.18625", "authors": ["Zequn Xie"], "title": "CONQUER: Context-Aware Representation with Query Enhancement for Text-Based Person Search", "categories": ["cs.CV"], "comment": "Accepted by ICASSP 2026", "summary": "Text-Based Person Search (TBPS) aims to retrieve pedestrian images from large galleries using natural language descriptions. This task, essential for public safety applications, is hindered by cross-modal discrepancies and ambiguous user queries. We introduce CONQUER, a two-stage framework designed to address these challenges by enhancing cross-modal alignment during training and adaptively refining queries at inference. During training, CONQUER employs multi-granularity encoding, complementary pair mining, and context-guided optimal matching based on Optimal Transport to learn robust embeddings. At inference, a plug-and-play query enhancement module refines vague or incomplete queries via anchor selection and attribute-driven enrichment, without requiring retraining of the backbone. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that CONQUER consistently outperforms strong baselines in both Rank-1 accuracy and mAP, yielding notable improvements in cross-domain and incomplete-query scenarios. These results highlight CONQUER as a practical and effective solution for real-world TBPS deployment. Source code is available at https://github.com/zqxie77/CONQUER.", "AI": {"tldr": "本文提出了一种名为CONQUER的两阶段框架，用于解决基于文本的人体搜索中的跨模态差异和模糊查询问题。", "motivation": "鉴于基于文本的人体搜索任务在公共安全应用中的重要性以及跨模态差异和模糊用户查询带来的挑战，作者提出了CONQUER框架来提高检索精度。", "method": "CONQUER通过多粒度编码、互补对挖掘及上下文引导的最优传输匹配进行训练。推理时采用插件式查询增强模块以选择锚点并通过属性驱动的方式丰富不明确或不完整查询。", "result": "在CUHK-PEDES, ICFG-PEDES和RSTPReid数据集上的实验表明，CONQUER在Rank-1准确率和mAP方面显著优于基线方法，并且在跨域及不完整查询场景中表现出色。", "conclusion": "CONQUER框架是一个实用而有效的方法，适用于基于文本的人体搜索任务的现实世界部署。"}}
{"id": "2601.18623", "pdf": "https://arxiv.org/pdf/2601.18623", "abs": "https://arxiv.org/abs/2601.18623", "authors": ["Zihao Wang", "Yuzhou Chen", "Shaogang Ren"], "title": "Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation", "categories": ["cs.CV"], "comment": "Paper accepted as a conference paper at ICLR 2026", "summary": "Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model's role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps.", "AI": {"tldr": "本文提出了一种新的扩散模型，用于改进跨模态图像转换。", "motivation": "标准的扩散方法依赖单一全局线性转移导致了高成本和语义漂移问题。", "method": "通过在生成过程中嵌入域迁移动态，预测每个反向步骤的空间变化混合场，并注入显式目标一致恢复项以保持大型更新在流形上进行。", "result": "实验显示，在医学成像、遥感等领域，该框架提高了结构保真度和语义一致性。", "conclusion": "本文的方法解决了跨模态图像转换中的固定时间表域迁移问题，并且在多个任务中表现出了优越性。"}}
{"id": "2601.18619", "pdf": "https://arxiv.org/pdf/2601.18619", "abs": "https://arxiv.org/abs/2601.18619", "authors": ["Jorge Quesada", "Ghassan AlRegib"], "title": "Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures", "categories": ["cs.CV"], "comment": null, "summary": "Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains.", "AI": {"tldr": "提出了一种针对小且稀疏结构的分割任务自监督学习方法，通过在预训练过程中引入小窗口裁剪来适应尺度变化。", "motivation": "现有的自监督学习管道通常为大型、均匀区域设计，但在处理小型、稀疏或局部不规则的对象时性能下降。作者旨在改进这一限制，以提高在特定任务上的表现。", "method": "通过在预训练过程中引入小窗口裁剪的方法来适应尺度变化，这种方法特别针对地震成像和神经影像中的小目标进行优化。", "result": "该方法在标记受限的情况下，在地震断层分割中提高了13%的准确性，在细胞结构界定任务中提高了5%，展示了其对小型、稀疏结构的有效性。", "conclusion": "研究表明，自监督学习设计需要与对象大小和稀疏度相匹配，以构建更有效的表示学习管道。"}}
{"id": "2601.18617", "pdf": "https://arxiv.org/pdf/2601.18617", "abs": "https://arxiv.org/abs/2601.18617", "authors": ["Pierre Orhan", "Pablo Diego-Simón", "Emmnanuel Chemla", "Yair Lakretz", "Yves Boubenec", "Jean-Rémi King"], "title": "Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial Neural Networks", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "During language acquisition, children successively learn to categorize phonemes, identify words, and combine them with syntax to form new meaning. While the development of this behavior is well characterized, we still lack a unifying computational framework to explain its underlying neural representations. Here, we investigate whether and when phonemic, lexical, and syntactic representations emerge in the activations of artificial neural networks during their training. Our results show that both speech- and text-based models follow a sequence of learning stages: during training, their neural activations successively build subspaces, where the geometry of the neural activations represents phonemic, lexical, and syntactic structure. While this developmental trajectory qualitatively relates to children's, it is quantitatively different: These algorithms indeed require two to four orders of magnitude more data for these neural representations to emerge. Together, these results show conditions under which major stages of language acquisition spontaneously emerge, and hence delineate a promising path to understand the computations underpinning language acquisition.", "AI": {"tldr": "研究人工神经网络在训练过程中语音、词汇和句法表示的出现条件。", "motivation": "缺乏统一计算框架解释语言学习中神经表征的发展，探究语言习得阶段如何自发涌现。", "method": "通过训练基于语音和文本的人工神经网络模型，观察其激活模式的变化。", "result": "发现模型在训练过程中依次构建了表示语音、词汇和句法结构的子空间。", "conclusion": "这些结果揭示了语言习得阶段自发涌现的条件，并为理解语言学习背后的计算提供了新途径。"}}
{"id": "2601.18612", "pdf": "https://arxiv.org/pdf/2601.18612", "abs": "https://arxiv.org/abs/2601.18612", "authors": ["Susim Roy", "Nalini Ratha"], "title": "Multimodal Privacy-Preserving Entity Resolution with Fully Homomorphic Encryption", "categories": ["cs.CR", "cs.CV"], "comment": "5 pages, 3 figures, IEEE ICASSP'26", "summary": "The canonical challenge of entity resolution within high-compliance sectors, where secure identity reconciliation is frequently confounded by significant data heterogeneity, including syntactic variations in personal identifiers, is a longstanding and complex problem. To this end, we introduce a novel multimodal framework operating with the voluminous data sets typical of government and financial institutions. Specifically, our methodology is designed to address the tripartite challenge of data volume, matching fidelity, and privacy. Consequently, the underlying plaintext of personally identifiable information remains computationally inaccessible throughout the matching lifecycle, empowering institutions to rigorously satisfy stringent regulatory mandates with cryptographic assurances of client confidentiality while achieving a demonstrably low equal error rate and maintaining computational tractability at scale.", "AI": {"tldr": "提出了一种新的多模态框架，利用全同态加密处理大量数据集，实现实体解析同时保护隐私。", "motivation": "解决高合规性领域中由于个人身份标识符的语法差异导致的身份匹配难题，特别是在政府和金融机构中存在的海量异构数据问题。", "method": "采用全同态加密技术，在不泄露个人信息的前提下实现实体解析，并保证在大规模数据处理中的计算可行性。", "result": "实现了低错误率的同时保持了隐私保护和高效率的实体解析过程。", "conclusion": "通过使用全同态加密技术，能够在满足严苛监管要求的同时确保客户信息的安全性，有效解决了大数据量、匹配准确性和隐私保护之间的冲突。"}}
{"id": "2601.18608", "pdf": "https://arxiv.org/pdf/2601.18608", "abs": "https://arxiv.org/abs/2601.18608", "authors": ["Fabian Fumagalli", "R. Teal Witter", "Christopher Musco"], "title": "PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets. In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent. Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic.", "AI": {"tldr": "本文提出了一种名为PolySHAP的方法，该方法通过使用更高阶的多项式来逼近游戏，从而提高了对特征间非线性交互作用的理解。", "motivation": "计算Shapley值需要评估$2^d$次模型，这在实际应用中是不切实际的。KernelSHAP算法作为一种近似的方法被提出，然而它只能处理线性关系，并不能很好地捕捉到特征间的复杂非线性交互作用。因此，作者希望通过引入更高阶多项式来改进这种方法。", "method": "PolySHAP方法通过使用多项式回归模型代替原来的线性模型，能够更好地拟合非线性的特征间交互作用，从而提供更准确的Shapley值估计。", "result": "实验结果表明，在各种基准数据集上，PolySHAP方法相比其他方法能产生更好的Shapley值估计。此外，作者还证明了配对采样（反向抽样）与PolySHAP中的二次多项式模型输出相同的Shapley值近似。", "conclusion": "该论文提出了一个基于多项式的改进方法来更准确地估算Shapley值，并且发现配对采样的有效性可以通过这一理论得到解释。"}}
{"id": "2601.18597", "pdf": "https://arxiv.org/pdf/2601.18597", "abs": "https://arxiv.org/abs/2601.18597", "authors": ["Yu Xia", "Chang Liu", "Tianqi Xiang", "Zhigang Tu"], "title": "EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery", "categories": ["cs.CV"], "comment": null, "summary": "Real-time small object detection in Unmanned Aerial Vehicle (UAV) imagery remains challenging due to limited feature representation and ineffective multi-scale fusion. Existing methods underutilize frequency information and rely on static convolutional operations, which constrain the capacity to obtain rich feature representations and hinder the effective exploitation of deep semantic features. To address these issues, we propose EFSI-DETR, a novel detection framework that integrates efficient semantic feature enhancement with dynamic frequency-spatial guidance. EFSI-DETR comprises two main components: (1) a Dynamic Frequency-Spatial Unified Synergy Network (DyFusNet) that jointly exploits frequency and spatial cues for robust multi-scale feature fusion, (2) an Efficient Semantic Feature Concentrator (ESFC) that enables deep semantic extraction with minimal computational cost. Furthermore, a Fine-grained Feature Retention (FFR) strategy is adopted to incorporate spatially rich shallow features during fusion to preserve fine-grained details, crucial for small object detection in UAV imagery. Extensive experiments on VisDrone and CODrone benchmarks demonstrate that our EFSI-DETR achieves the state-of-the-art performance with real-time efficiency, yielding improvement of \\textbf{1.6}\\% and \\textbf{5.8}\\% in AP and AP$_{s}$ on VisDrone, while obtaining \\textbf{188} FPS inference speed on a single RTX 4090 GPU.", "AI": {"tldr": "提出了一种用于无人机影像中小目标实时检测的高效频率语义集成框架EFSI-DETR。", "motivation": "现有的小目标检测方法在利用频域信息和多尺度融合方面存在不足，限制了特征表示能力并阻碍了深度语义特征的有效使用。为了改进这些问题，本文提出了EFSI-DETR来提升无人机影像中小目标的实时检测性能。", "method": "该框架包含两个主要组件：动态频率空间统一协同网络DyFusNet用于频域和空域信息融合；高效语义特性集中器ESFC实现深度语义特征提取。此外，还采用细粒度特征保留策略以保持小目标的细节。", "result": "EFSI-DETR在VisDrone和CODrone数据集上优于现有方法，在AP和AP$_{s}$指标上分别提升了1.6%和5.8%，并在RTX 4090 GPU上实现了每秒188帧的推断速度。", "conclusion": "EFSI-DETR在无人机影像中小目标检测任务中表现出色，展示了良好的性能与实时性。"}}
{"id": "2601.18595", "pdf": "https://arxiv.org/pdf/2601.18595", "abs": "https://arxiv.org/abs/2601.18595", "authors": ["Joseph Cotnareanu", "Didier Chetelat", "Yingxue Zhang", "Mark Coates"], "title": "A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts.", "AI": {"tldr": "本文提出了一种新的方法，通过逻辑求解器的反馈来增强LLM提供常识关系的能力。", "motivation": "尽管大型语言模型在形式推理方面表现出色，但在处理需要复杂证明计划的问题时仍然会失败。现有的逻辑求解器虽然能更高效地进行逻辑推理，但无法解决缺少常识信息的问题。", "method": "该方法利用逻辑求解器的反馈迭代增强逻辑问题中的常识关系，并通过搜索过程找到有用的常识假设以最大化发现有用事实的机会。", "result": "在一系列从某些常识信息中移除纯逻辑推理数据集上，该方法比现有技术表现更好，证明了平衡神经元和符号元素的重要性。", "conclusion": "本文提出的方法能够有效提高LLM处理复杂逻辑问题的能力，并且通过结合神经网络与形式逻辑的优点，在人类上下文中表现出色。"}}
{"id": "2601.18592", "pdf": "https://arxiv.org/pdf/2601.18592", "abs": "https://arxiv.org/abs/2601.18592", "authors": ["Konstantin Sozykin", "Nikita Rybin", "Andrei Chertkov", "Anh-Huy Phan", "Ivan Oseledets", "Alexander Shapeev", "Ivan Novikov", "Gleb Ryzhakov"], "title": "Global Optimization of Atomic Clusters via Physically-Constrained Tensor Train Decomposition", "categories": ["math.OC", "cond-mat.mtrl-sci", "cs.NE"], "comment": "18 pages, 6 figures", "summary": "The global optimization of atomic clusters represents a fundamental challenge in computational chemistry and materials science due to the exponential growth of local minima with system size (i.e., the curse of dimensionality). We introduce a novel framework that overcomes this limitation by exploiting the low-rank structure of potential energy surfaces through Tensor Train (TT) decomposition. Our approach combines two complementary TT-based strategies: the algebraic TTOpt method, which utilizes maximum volume sampling, and the probabilistic PROTES method, which employs generative sampling. A key innovation is the development of physically-constrained encoding schemes that incorporate molecular constraints directly into the discretization process. We demonstrate the efficacy of our method by identifying global minima of Lennard-Jones clusters containing up to 45 atoms. Furthermore, we establish its practical applicability to real-world systems by optimizing 20-atom carbon clusters using a machine-learned Moment Tensor Potential, achieving geometries consistent with quantum-accurate simulations. This work establishes TT-decomposition as a powerful tool for molecular structure prediction and provides a general framework adaptable to a wide range of high-dimensional optimization problems in computational material science.", "AI": {"tldr": "本文通过张量列分解提出了一种新的原子簇全局优化框架，克服了维度诅咒问题。", "motivation": "原子簇的全局优化在计算化学和材料科学中是一个基本挑战，因为随着系统规模的增长，局部最小值的数量呈指数级增长。", "method": "本文结合代数TTOpt方法和概率PROTES方法，并开发了物理约束编码方案，直接将分子约束纳入离散化过程。", "result": "该方法成功识别了包含最多45个原子的Lennard-Jones簇的全局最小值。此外，在优化20个碳原子簇时达到了与量子准确模拟一致的几何形状。", "conclusion": "本文证明了张量列分解在分子结构预测中的强大功能，并提供了一种适用于计算材料科学中广泛高维优化问题的一般框架。"}}
{"id": "2601.18589", "pdf": "https://arxiv.org/pdf/2601.18589", "abs": "https://arxiv.org/abs/2601.18589", "authors": ["KV Karthikeya", "Ashok Kumar Das", "Shantanu Pal", "Vivekananda Bhat K", "Arun Sekar Rajasekaran"], "title": "AGSP-DSA: An Adaptive Graph Signal Processing Framework for Robust Multimodal Fusion with Dynamic Semantic Alignment", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "In this paper, we introduce an Adaptive Graph Signal Processing with Dynamic Semantic Alignment (AGSP DSA) framework to perform robust multimodal data fusion over heterogeneous sources, including text, audio, and images. The requested approach uses a dual-graph construction to learn both intra-modal and inter-modal relations, spectral graph filtering to boost the informative signals, and effective node embedding with Multi-scale Graph Convolutional Networks (GCNs). Semantic aware attention mechanism: each modality may dynamically contribute to the context with respect to contextual relevance. The experimental outcomes on three benchmark datasets, including CMU-MOSEI, AVE, and MM-IMDB, show that AGSP-DSA performs as the state of the art. More precisely, it achieves 95.3% accuracy, 0.936 F1-score, and 0.924 mAP on CMU-MOSEI, improving MM-GNN by 2.6 percent in accuracy. It gets 93.4% accuracy and 0.911 F1-score on AVE and 91.8% accuracy and 0.886 F1-score on MM-IMDB, which demonstrate good generalization and robustness in the missing modality setting. These findings verify the efficiency of AGSP-DSA in promoting multimodal learning in sentiment analysis, event recognition and multimedia classification.", "AI": {"tldr": "提出一种自适应图信号处理框架AGSP DSA，用于异构多模态数据融合", "motivation": "提高多模态数据融合的鲁棒性和准确性，特别是在情感分析、事件识别和多媒体分类任务中", "method": "使用双重图构造学习跨模态和内模态关系，通过谱图滤波增强信息信号，并采用多尺度GCN进行节点嵌入。引入语义感知注意机制，使各模态根据上下文相关性动态贡献到上下文中", "result": "在CMU-MOSEI、AVE和MM-IMDB数据集上表现优于现有方法，验证了AGSP DSA的有效性和鲁棒性", "conclusion": "AGSP DSA框架通过自适应地融合多模态信息并增强语义关联，在多个基准测试中展现了优越性能"}}
{"id": "2601.18588", "pdf": "https://arxiv.org/pdf/2601.18588", "abs": "https://arxiv.org/abs/2601.18588", "authors": ["Xianzhe Meng", "Qiangsheng Zeng", "Ling Luo", "Qinghan Yang", "Jiarui Hao", "Wenbo Wu", "Qinyu Wang", "Rui Yin", "Lin Qi", "Renzhi Lu"], "title": "Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.", "AI": {"tldr": "研究大型语言模型在稳定训练过程中的生成分布变化，揭示稳定性与生成质量之间的矛盾。", "motivation": "探讨优化稳定性和生成表达力之间的关系及其对模型性能的影响。", "method": "通过最大似然训练分析参数轨迹的稳定性对生成分布的影响，并采用反馈控制框架验证这一影响。", "result": "观察到在各种架构和随机种子下，稳定训练会导致低熵输出和重复行为，表明单纯依赖优化稳定性不足以保证生成质量。", "conclusion": "优化稳定性和生成表达力之间存在矛盾，需要寻找新的评估标准来衡量模型的生成能力。"}}
{"id": "2601.18586", "pdf": "https://arxiv.org/pdf/2601.18586", "abs": "https://arxiv.org/abs/2601.18586", "authors": ["Miguel Costa", "Arthur Vandervoort", "Carolin Schmidt", "Morten W. Petersen", "Martin Drews", "Karyn Morrissey", "Francisco C. Pereira"], "title": "Learning long term climate-resilient transport adaptation pathways under direct and indirect flood impacts using reinforcement learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Climate change is expected to intensify rainfall and other hazards, increasing disruptions in urban transportation systems. Designing effective adaptation strategies is challenging due to the long-term, sequential nature of infrastructure investments, deep uncertainty, and complex cross-sector interactions. We propose a generic decision-support framework that couples an integrated assessment model (IAM) with reinforcement learning (RL) to learn adaptive, multi-decade investment pathways under uncertainty. The framework combines long-term climate projections (e.g., IPCC scenario pathways) with models that map projected extreme-weather drivers (e.g. rain) into hazard likelihoods (e.g. flooding), propagate hazards into urban infrastructure impacts (e.g. transport disruption), and value direct and indirect consequences for service performance and societal costs. Embedded in a reinforcement-learning loop, it learns adaptive climate adaptation policies that trade off investment and maintenance expenditures against avoided impacts. In collaboration with Copenhagen Municipality, we demonstrate the approach on pluvial flooding in the inner city for the horizon of 2024 to 2100. The learned strategies yield coordinated spatial-temporal pathways and improved robustness relative to conventional optimization baselines, namely inaction and random action, illustrating the framework's transferability to other hazards and cities.", "AI": {"tldr": "提出了一种结合集成评估模型和强化学习的决策支持框架，用于在不确定性下学习长期适应性投资路径，以应对气候风险对城市交通系统的影响。", "motivation": "气候变化加剧了降雨和其他灾害，导致城市交通系统的中断。设计有效的适应策略具有挑战性，因为基础设施投资有长期、顺序性的特点，并存在深刻的不确定性和跨部门的复杂互动。", "method": "将集成评估模型与强化学习结合，通过考虑长期气候预测和极端天气驱动因素，映射出洪水发生的可能性及其对城市基础设施的影响，并计算直接和间接后果。该框架在强化学习循环中运行，以找到最佳适应策略，在投资维护支出和避免影响之间进行权衡。", "result": "所学的战略产生协调的时空路径并改进了相对于其他基准方法（不采取行动和随机行动）的鲁棒性。", "conclusion": "展示的方法可以在不同灾害类型和城市间转移应用。"}}
{"id": "2601.18585", "pdf": "https://arxiv.org/pdf/2601.18585", "abs": "https://arxiv.org/abs/2601.18585", "authors": ["Chenxi Liu", "Selena Ling", "Alec Jacobson"], "title": "GimmBO: Interactive Generative Image Model Merging via Bayesian Optimization", "categories": ["cs.CV", "cs.GR"], "comment": ":I.3.6; I.4.9", "summary": "Fine-tuning-based adaptation is widely used to customize diffusion-based image generation, leading to large collections of community-created adapters that capture diverse subjects and styles. Adapters derived from the same base model can be merged with weights, enabling the synthesis of new visual results within a vast and continuous design space. To explore this space, current workflows rely on manual slider-based tuning, an approach that scales poorly and makes weight selection difficult, even when the candidate set is limited to 20-30 adapters. We propose GimmBO to support interactive exploration of adapter merging for image generation through Preferential Bayesian Optimization (PBO). Motivated by observations from real-world usage, including sparsity and constrained weight ranges, we introduce a two-stage BO backend that improves sampling efficiency and convergence in high-dimensional spaces. We evaluate our approach with simulated users and a user study, demonstrating improved convergence, high success rates, and consistent gains over BO and line-search baselines, and further show the flexibility of the framework through several extensions.", "AI": {"tldr": "本文提出了一种基于偏爱贝叶斯优化的交互式生成图像模型融合方法GimmBO，用于支持图像生成中适配器合并的空间探索。", "motivation": "当前的工作流程依赖手动调整权重，这在高维度空间中的效率低下且难以操作。因此，作者提出了GimmBO来提高用户体验和搜索效率。", "method": "通过偏爱贝叶斯优化（PBO），引入两阶段的BO后端以改进采样效率和收敛性，适应实际使用的稀疏性和权重范围限制。", "result": "评估显示该方法在模拟用户和真实用户实验中表现优异，比基线BO和直线搜索算法有显著的优势。", "conclusion": "GimmBO提供了一种灵活且有效的框架用于探索生成图像模型的合并空间。"}}
{"id": "2601.18579", "pdf": "https://arxiv.org/pdf/2601.18579", "abs": "https://arxiv.org/abs/2601.18579", "authors": ["Seonho An", "Chaejeong Hyun", "Min-Soo Kim"], "title": "FastInsight: Fast and Insightful Retrieval via Fusion Operators for Graph RAG", "categories": ["cs.IR", "cs.AI"], "comment": "under review", "summary": "Existing Graph RAG methods aiming for insightful retrieval on corpus graphs typically rely on time-intensive processes that interleave Large Language Model (LLM) reasoning. To enable time-efficient insightful retrieval, we propose FastInsight. We first introduce a graph retrieval taxonomy that categorizes existing methods into three fundamental operations: vector search, graph search, and model-based search. Through this taxonomy, we identify two critical limitations in current approaches: the topology-blindness of model-based search and the semantics-blindness of graph search. FastInsight overcomes these limitations by interleaving two novel fusion operators: the Graph-based Reranker (GRanker), which functions as a graph model-based search, and Semantic-Topological eXpansion (STeX), which operates as a vector-graph search. Extensive experiments on broad retrieval and generation datasets demonstrate that FastInsight significantly improves both retrieval accuracy and generation quality compared to state-of-the-art baselines, achieving a substantial Pareto improvement in the trade-off between effectiveness and efficiency.", "AI": {"tldr": "FastInsight是一种通过融合操作符实现快速且富有洞察力的图检索的方法。", "motivation": "现有的图RAG方法通常依赖于耗时的LLM推理过程。为了解决这一问题，该论文提出了一种新的方法以实现在不牺牲准确性的情况下提高效率的目标。", "method": "FastInsight通过引入一个图检索分类法来识别现有方法中的两个关键限制，并设计了两种新的融合操作符：基于模型的重排序器GRanker和语义-拓扑扩展STeX。", "result": "实验结果表明，与现有的最佳基线相比，FastInsight在检索准确性和生成质量上都有显著提高，在效率和效果之间实现了帕累托改进。", "conclusion": "通过提出新的融合操作符GRanker和STeX，FastInsight有效地解决了现有方法中的关键限制，并提高了图检索的有效性与效率。"}}
{"id": "2601.18577", "pdf": "https://arxiv.org/pdf/2601.18577", "abs": "https://arxiv.org/abs/2601.18577", "authors": ["Sangwon Jang", "Taekyung Ki", "Jaehyeong Jo", "Saining Xie", "Jaehong Yoon", "Sung Ju Hwang"], "title": "Self-Refining Video Sampling", "categories": ["cs.CV", "cs.LG"], "comment": "Project page: https://agwmon.github.io/self-refine-video/", "summary": "Modern video generators still struggle with complex physical dynamics, often falling short of physical realism. Existing approaches address this using external verifiers or additional training on augmented data, which is computationally expensive and still limited in capturing fine-grained motion. In this work, we present self-refining video sampling, a simple method that uses a pre-trained video generator trained on large-scale datasets as its own self-refiner. By interpreting the generator as a denoising autoencoder, we enable iterative inner-loop refinement at inference time without any external verifier or additional training. We further introduce an uncertainty-aware refinement strategy that selectively refines regions based on self-consistency, which prevents artifacts caused by over-refinement. Experiments on state-of-the-art video generators demonstrate significant improvements in motion coherence and physics alignment, achieving over 70\\% human preference compared to the default sampler and guidance-based sampler.", "AI": {"tldr": "该论文提出了一种自我优化视频采样方法，用于改善现有视频生成器在复杂物理动态下的表现。", "motivation": "当前的视频生成器难以精确再现复杂的物理运动和细节，现有的解决方案依赖于外部验证或额外的数据训练，这不仅计算成本高且效果有限。因此，该论文旨在提出一种新的自我优化方法来提高视频的真实感。", "method": "通过将预训练的大型数据集上的视频生成器视为去噪自动编码器，实现无需额外验证器和训练步骤的迭代内循环细化。引入了基于自一致性的不确定性感知细化策略，以避免过度细化导致的伪影问题。", "result": "实验表明该方法在运动一致性及物理规律遵循方面优于标准采样器和指导基线采样器，超过70％的人类偏好选择其生成的结果。", "conclusion": "自我优化视频采样法显著提升了现有视频生成器的质量，特别是在处理复杂物理动态时。这种方法能够有效且经济地提高视频的真实感。"}}
{"id": "2601.18573", "pdf": "https://arxiv.org/pdf/2601.18573", "abs": "https://arxiv.org/abs/2601.18573", "authors": ["Frederik Glitzner", "David Manlove"], "title": "Stable Matching with Deviators and Conformists", "categories": ["cs.GT", "cs.DS"], "comment": "Preliminary version to appear at AAMAS 2026", "summary": "In the fundamental Stable Marriage and Stable Roommates problems, there are inherent trade-offs between the size and stability of solutions. While in the former problem, a stable matching always exists and can be found efficiently using the celebrated Gale-Shapley algorithm, the existence of a stable matching is not guaranteed in the latter problem, but can be determined efficiently using Irving's algorithm. However, the computation of matchings that minimise the instability, either due to the presence of additional constraints on the size of the matching or due to restrictive preference cycles, gives rise to a collection of infamously intractable almost-stable matching problems. In practice, however, not every agent is able or likely to initiate deviations caused by blocking pairs. Suppose we knew, for example, due to a set of requirements or estimates based on historical data, which agents are likely to initiate deviations - the deviators - and which are likely to comply with whatever matching they are presented with - the conformists. Can we decide efficiently whether a matching exists in which no deviator is blocking, i.e., in which no deviator has an incentive to initiate a deviation? Furthermore, can we find matchings in which only a few deviators are blocking? We characterise the computational complexity of this question in bipartite and non-bipartite preference settings. Surprisingly, these problems prove computationally intractable in strong ways: for example, unlike in the classical setting, where every agent is considered a deviator, in this extension, we prove that it is NP-complete to decide whether a matching exists where no deviator is blocking. On the positive side, we identify polynomial-time and fixed-parameter tractable cases, providing novel algorithmics for multi-agent systems where stability cannot be fully guaranteed.", "AI": {"tldr": "研究了在匹配中考虑不同类型的参与者的偏离行为，以减少不稳定性。", "motivation": "传统稳定婚姻和室友问题存在固有的取舍。引入不同类型参与者（偏离者与服从者）以探讨更现实的场景，并优化匹配方案。", "method": "通过分析包含特定类型参与者的偏差性匹配问题，在双部图和平行图偏好的情况下确定这些问题的时间复杂度。", "result": "证明了在某些条件下，此类问题为NP完全。同时，识别出多项式时间和固定参数可追踪的情况。", "conclusion": "研究揭示了考虑不同参与者行为的偏离稳定性匹配问题的复杂性，并提供了新的算法技术以适应多代理系统中的不稳定情况。"}}
{"id": "2601.18569", "pdf": "https://arxiv.org/pdf/2601.18569", "abs": "https://arxiv.org/abs/2601.18569", "authors": ["Seokju Lee", "Kyung-Soo Kim"], "title": "Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "8 pages, 6 figures, Accepted to IEEE Robotics and Automation Letters (RA-L)", "summary": "In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state estimation in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic measurements violate the no-slip assumption and inject bias during the update step. Our objective is to estimate this slip-induced error and compensate for it. To this end, we augment an Invariant Extended Kalman Filter (InEKF) with a neural compensator that uses an attention mechanism to infer error conditioned on foot-slip severity and then applies this estimate as a post-update compensation to the InEKF state (i.e., after the filter update). The compensator is trained in a latent space, which aims to reduce sensitivity to raw input scales and encourages structured slip-conditioned compensations, while preserving the InEKF recursion. Experiments demonstrate improved performance compared to existing legged-robot state estimators, particularly under slip-prone conditions.", "AI": {"tldr": "提出了一种基于注意力机制的神经增强卡尔曼滤波器（AttenNKF），用于四足机器人状态估计，特别是在滑动情况下提高准确性。", "motivation": "为了减少由脚部滑移引起的估计误差，尤其是在更新步中引入偏差的情况下，需要一种方法来检测和补偿这种错误。", "method": "通过将不变扩展卡尔曼滤波器（InEKF）与一个使用注意力机制的神经补偿器相结合，在训练时利用潜在空间来降低对原始输入尺度敏感性的同时保持滤波器递归过程，从而提高四足机器人状态估计的准确性。", "result": "实验显示，该方法相较于现有的四足机器人状态估计算法在滑动情况下性能更优。", "conclusion": "提出的基于注意力机制的神经增强卡尔曼滤波器能够有效补偿由脚部滑移引起的误差，并显著提高四足机器人的状态估计精度。"}}
{"id": "2601.18564", "pdf": "https://arxiv.org/pdf/2601.18564", "abs": "https://arxiv.org/abs/2601.18564", "authors": ["Chong Hyun Lee", "Kibae Lee", "Hyun Hee Yim"], "title": "An Unsupervised Tensor-Based Domain Alignment", "categories": ["cs.LG", "cs.CV", "eess.SP"], "comment": "5 pages, 5 figures", "summary": "We propose a tensor-based domain alignment (DA) algorithm designed to align source and target tensors within an invariant subspace through the use of alignment matrices. These matrices along with the subspace undergo iterative optimization of which constraint is on oblique manifold, which offers greater flexibility and adaptability compared to the traditional Stiefel manifold. Moreover, regularization terms defined to preserve the variance of both source and target tensors, ensures robust performance. Our framework is versatile, effectively generalizing existing tensor-based DA methods as special cases. Through extensive experiments, we demonstrate that our approach not only enhances DA conversion speed but also significantly boosts classification accuracy. This positions our method as superior to current state-of-the-art techniques, making it a preferable choice for complex domain adaptation tasks.", "AI": {"tldr": "本文提出了一个基于张量的领域对齐算法，通过在斜流形上迭代优化对齐矩阵和不变子空间来实现源域和目标域数据之间的对齐。", "motivation": "为了提高领域的适应性以及保持源域和目标域之间的一致性，同时确保更好的分类性能和更快的转换速度。", "method": "利用张量作为输入并采用斜流形上的迭代优化方法来寻找最优的领域对齐矩阵和不变子空间。在优化过程中加入了正则化项以保留原始数据方差。", "result": "实验结果显示该方法不仅提高了分类精度，还加速了领域的转换过程，并且优于现有的最先进的领域适应技术。", "conclusion": "所提出的方法通过利用张量并引入斜流形上的迭代优化策略，在复杂领域的适应任务中表现出色。"}}
{"id": "2601.18560", "pdf": "https://arxiv.org/pdf/2601.18560", "abs": "https://arxiv.org/abs/2601.18560", "authors": ["Li Fang", "Tianyu Li", "Yanghong Lin", "Shudong Zhou", "Wei Yao"], "title": "AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging", "categories": ["cs.CV"], "comment": null, "summary": "As the important component of the Earth observation system, hyperspectral imaging satellites provide high-fidelity and enriched information for the formulation of related policies due to the powerful spectral measurement capabilities. However, the transmission speed of the satellite downlink has become a major bottleneck in certain applications, such as disaster monitoring and emergency mapping, which demand a fast response ability. We propose an efficient AI-enabled Satellite Edge Computing paradigm for hyperspectral image classification, facilitating the satellites to attain autonomous decision-making. To accommodate the resource constraints of satellite platforms, the proposed method adopts a lightweight, non-deep learning framework integrated with a few-shot learning strategy. Moreover, onboard processing on satellites could be faced with sensor failure and scan pattern errors, which result in degraded image quality with bad/misaligned pixels and mixed noise. To address these challenges, we develop a novel two-stage pixel-wise label propagation scheme that utilizes only intrinsic spectral features at the single pixel level without the necessity to consider spatial structural information as requested by deep neural networks. In the first stage, initial pixel labels are obtained by propagating selected anchor labels through the constructed anchor-pixel affinity matrix. Subsequently, a top-k pruned sparse graph is generated by directly computing pixel-level similarities. In the second stage, a closed-form solution derived from the sparse graph is employed to replace iterative computations. Furthermore, we developed a rank constraint-based graph clustering algorithm to determine the anchor labels.", "AI": {"tldr": "提出了一种基于单像素特征的浅层分类模型，用于遥感卫星上的高光谱图像处理", "motivation": "解决高光谱成像卫星数据传输速度瓶颈问题，实现快速响应能力", "method": "采用轻量级非深度学习框架结合少量样本学习策略，开发了两阶段像素标签传播方案", "result": "实现了高效的边缘计算和准确的分类结果", "conclusion": "所提方法能够有效应对资源限制和图像质量下降的问题"}}
{"id": "2601.18556", "pdf": "https://arxiv.org/pdf/2601.18556", "abs": "https://arxiv.org/abs/2601.18556", "authors": ["Jingsong Xia", "Siqi Wang"], "title": "Generative Diffusion Augmentation with Quantum-Enhanced Discrimination for Medical Image Diagnosis", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In biomedical engineering, artificial intelligence has become a pivotal tool for enhancing medical diagnostics, particularly in medical image classification tasks such as detecting pneumonia from chest X-rays and breast cancer screening. However, real-world medical datasets frequently exhibit severe class imbalance, where positive samples substantially outnumber negative samples, leading to biased models with low recall rates for minority classes. This imbalance not only compromises diagnostic accuracy but also poses clinical misdiagnosis risks. To address this challenge, we propose SDA-QEC (Simplified Diffusion Augmentation with Quantum-Enhanced Classification), an innovative framework that integrates simplified diffusion-based data augmentation with quantum-enhanced feature discrimination. Our approach employs a lightweight diffusion augmentor to generate high-quality synthetic samples for minority classes, rebalancing the training distribution. Subsequently, a quantum feature layer embedded within MobileNetV2 architecture enhances the model's discriminative capability through high-dimensional feature mapping in Hilbert space. Comprehensive experiments on coronary angiography image classification demonstrate that SDA-QEC achieves 98.33% accuracy, 98.78% AUC, and 98.33% F1-score, significantly outperforming classical baselines including ResNet18, MobileNetV2, DenseNet121, and VGG16. Notably, our framework simultaneously attains 98.33% sensitivity and 98.33% specificity, achieving a balanced performance critical for clinical deployment. The proposed method validates the feasibility of integrating generative augmentation with quantum-enhanced modeling in real-world medical imaging tasks, offering a novel research pathway for developing highly reliable medical AI systems in small-sample, highly imbalanced, and high-risk diagnostic scenarios.", "AI": {"tldr": "提出了一种结合简化扩散数据增强与量子增强分类的框架SDA-QEC，用于改善医疗图像诊断中的类不平衡问题。", "motivation": "为了应对医学影像中由于正样本显著多于负样本导致的模型偏差和低召回率，开发了新的方法来提高诊断准确性并降低临床误诊风险。", "method": "采用轻量级扩散增强器生成高质量合成少数类别样本以平衡训练分布；在MobileNetV2架构中嵌入量子特征层通过希尔伯特空间中的高维映射提升模型的辨别能力。", "result": "实验证明，SDA-QEC框架在冠状动脉造影图像分类任务上达到了98.33%准确率、98.78%AUC和98.33%F1分数，并同时实现了98.33%敏感性和98.33%特异性。", "conclusion": "该方法验证了在实际医学成像任务中整合生成增强与量子增强建模的可行性，为开发小样本、高度不平衡且高风险诊断场景下的可靠医疗AI系统提供了一条新的研究路径。"}}
{"id": "2601.18555", "pdf": "https://arxiv.org/pdf/2601.18555", "abs": "https://arxiv.org/abs/2601.18555", "authors": ["Roberto Di Via", "Vito Paolo Pastore", "Francesca Odone", "Siôn Glyn-Jones", "Irina Voiculescu"], "title": "Automated Landmark Detection for assessing hip conditions: A Cross-Modality Validation of MRI versus X-ray", "categories": ["cs.CV"], "comment": "Accepted at International Symposium on Biomedical Imaging (ISBI 2026)", "summary": "Many clinical screening decisions are based on angle measurements. In particular, FemoroAcetabular Impingement (FAI) screening relies on angles traditionally measured on X-rays. However, assessing the height and span of the impingement area requires also a 3D view through an MRI scan. The two modalities inform the surgeon on different aspects of the condition. In this work, we conduct a matched-cohort validation study (89 patients, paired MRI/X-ray) using standard heatmap regression architectures to assess cross-modality clinical equivalence. Seen that landmark detection has been proven effective on X-rays, we show that MRI also achieves equivalent localisation and diagnostic accuracy for cam-type impingement. Our method demonstrates clinical feasibility for FAI assessment in coronal views of 3D MRI volumes, opening the possibility for volumetric analysis through placing further landmarks. These results support integrating automated FAI assessment into routine MRI workflows. Code is released at https://github.com/Malga-Vision/Landmarks-Hip-Conditions", "AI": {"tldr": "该论文通过使用标准的热图回归架构，在MRI和X射线之间进行配对患者验证，以评估跨模态临床等效性。", "motivation": "传统的FAI筛查依赖于从X射线中测量的角度。然而，为了全面了解病变区域的高度和跨度，还需要3D视图通过MRI扫描。该研究旨在确定MRI是否可以提供与X射线相媲美的定位准确性。", "method": "使用标准的热图回归架构，在89名患者的配对MRI和X光片之间进行验证研究，以评估跨模态临床等效性。", "result": "结果显示MRI在冠状视图中也实现了与X射线相当的定位准确性和诊断准确性。该方法为FAI的自动评估提供了临床可行性。", "conclusion": "这些结果支持将自动化的FAI评估集成到常规MRI工作流程中的可能性，为进一步的体积分析提供基础。"}}
{"id": "2601.18554", "pdf": "https://arxiv.org/pdf/2601.18554", "abs": "https://arxiv.org/abs/2601.18554", "authors": ["Alberto Purpura", "Li Wang", "Sahil Badyal", "Eugenio Beaufrand", "Adam Faulkner"], "title": "Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities", "categories": ["cs.AI"], "comment": "Paper accepted to EACL 2026", "summary": "Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions.", "AI": {"tldr": "介绍MOSAIC框架，用于评估大型语言模型遵循复杂指令的能力。", "motivation": "现有的基准测试无法真实反映现实世界中的应用或分离出遵守指令的能力与任务成功的关系。因此需要一个更精细的评估方法来衡量模型遵从性。", "method": "提出了一个模块化合成评估框架MOSAIC，使用动态生成的数据集进行评测，数据集中包含20个应用导向的生成约束。", "result": "通过对五种不同类型的大型语言模型进行测试，发现模型在面对不同的指令类型、数量和位置时遵从性表现不一。这些结果揭示了模型特定弱点及相互影响，并识别出明显的优先效应和最近效应等偏见。", "conclusion": "通过细致的分析，有助于诊断模型错误并开发更可靠的大型语言模型以应对严格遵循复杂指令的需求。"}}
{"id": "2601.18548", "pdf": "https://arxiv.org/pdf/2601.18548", "abs": "https://arxiv.org/abs/2601.18548", "authors": ["Yulin Li", "Zhiyuan Song", "Yiming Li", "Zhicheng Song", "Kai Chen", "Chunxin Zheng", "Zhihai Bi", "Jiahang Cao", "Sylvain Calinon", "Fan Shi", "Jun Ma"], "title": "Fast and Safe Trajectory Optimization for Mobile Manipulators With Neural Configuration Space Distance Field", "categories": ["cs.RO"], "comment": null, "summary": "Mobile manipulators promise agile, long-horizon behavior by coordinating base and arm motion, yet whole-body trajectory optimization in cluttered, confined spaces remains difficult due to high-dimensional nonconvexity and the need for fast, accurate collision reasoning. Configuration Space Distance Fields (CDF) enable fixed-base manipulators to model collisions directly in configuration space via smooth, implicit distances. This representation holds strong potential to bypass the nonlinear configuration-to-workspace mapping while preserving accurate whole-body geometry and providing optimization-friendly collision costs. Yet, extending this capability to mobile manipulators is hindered by unbounded workspaces and tighter base-arm coupling. We lift this promise to mobile manipulation with Generalized Configuration Space Distance Fields (GCDF), extending CDF to robots with both translational and rotational joints in unbounded workspaces with tighter base-arm coupling. We prove that GCDF preserves Euclidean-like local distance structure and accurately encodes whole-body geometry in configuration space, and develop a data generation and training pipeline that yields continuous neural GCDFs with accurate values and gradients, supporting efficient GPU-batched queries. Building on this representation, we develop a high-performance sequential convex optimization framework centered on GCDF-based collision reasoning. The solver scales to large numbers of implicit constraints through (i) online specification of neural constraints, (ii) sparsity-aware active-set detection with parallel batched evaluation across thousands of constraints, and (iii) incremental constraint management for rapid replanning under scene changes.", "AI": {"tldr": "提出了广义配置空间距离场（GCDF），用于移动机器人的快速安全轨迹优化", "motivation": "解决了固定基础操作器的碰撞检测问题，但对于带有移动平台和更紧密臂基耦合的机器人来说仍然存在挑战", "method": "开发了数据生成和训练管道以构建连续神经GCDF，并基于此提出了高效的序列凸优化框架进行碰撞推理", "result": "提出的解算器能够处理大量的隐式约束，并在场景变化下快速重新规划", "conclusion": "该方法使得移动机器人的长时轨迹优化成为可能，提高了操作的敏捷性和效率"}}
{"id": "2601.18547", "pdf": "https://arxiv.org/pdf/2601.18547", "abs": "https://arxiv.org/abs/2601.18547", "authors": ["Qing Ding", "Mai Xu", "Shengxi Li", "Xin Deng", "Xin Zou"], "title": "REMAC: Reference-Based Martian Asymmetrical Image Compression", "categories": ["cs.CV", "cs.MM"], "comment": "Accepted for publication in IEEE Transactions on Geoscience and Remote Sensing (TGRS). 2025 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. 18 pages, 20 figures", "summary": "To expedite space exploration on Mars, it is indispensable to develop an efficient Martian image compression method for transmitting images through the constrained Mars-to-Earth communication channel. Although the existing learned compression methods have achieved promising results for natural images from earth, there remain two critical issues that hinder their effectiveness for Martian image compression: 1) They overlook the highly-limited computational resources on Mars; 2) They do not utilize the strong \\textit{inter-image} similarities across Martian images to advance image compression performance. Motivated by our empirical analysis of the strong \\textit{intra-} and \\textit{inter-image} similarities from the perspective of texture, color, and semantics, we propose a reference-based Martian asymmetrical image compression (REMAC) approach, which shifts computational complexity from the encoder to the resource-rich decoder and simultaneously improves compression performance. To leverage \\textit{inter-image} similarities, we propose a reference-guided entropy module and a ref-decoder that utilize useful information from reference images, reducing redundant operations at the encoder and achieving superior compression performance. To exploit \\textit{intra-image} similarities, the ref-decoder adopts a deep, multi-scale architecture with enlarged receptive field size to model long-range spatial dependencies. Additionally, we develop a latent feature recycling mechanism to further alleviate the extreme computational constraints on Mars. Experimental results show that REMAC reduces encoder complexity by 43.51\\% compared to the state-of-the-art method, while achieving a BD-PSNR gain of 0.2664 dB.", "AI": {"tldr": "提出了一种基于参考的火星不对称图像压缩方法(REMAC)，利用图像间相似性减轻计算资源限制，提高压缩性能。", "motivation": "现有学习压缩方法忽视了火星有限的计算资源，并未充分利用图像间的相似性以提升压缩效果。通过实证分析火星图像在纹理、颜色和语义上的强内、外相似性，本文提出了REMAC方法。", "method": "采用参考引导熵模块及ref-decoder利用参照图的信息减少编码冗余操作并改善压缩性能；采用深层多尺度架构来建模长程空间依赖关系；开发了隐特征循环机制以进一步缓解极端计算限制。", "result": "实验表明REMAC相比最先进的方法减少了43.51%的编码复杂度，同时获得了0.2664dB的BD-PSNR增益。", "conclusion": "REMAC通过将复杂性转移到资源丰富的解码器上并利用图像间相似性显著提高了火星图像压缩性能。"}}
{"id": "2601.18543", "pdf": "https://arxiv.org/pdf/2601.18543", "abs": "https://arxiv.org/abs/2601.18543", "authors": ["Kaixun Jiang", "Yuzheng Wang", "Junjie Zhou", "Pandeng Li", "Zhihang Liu", "Chen-Wei Xie", "Zhaoyu Chen", "Yun Zheng", "Wenqiang Zhang"], "title": "GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\\%) and WISE (+14\\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \\href{https://github.com/deep-kaixun/GenAgent}{this url}.", "AI": {"tldr": "GenAgent通过代理多模态模型统一了视觉理解和图像生成，并通过两阶段训练策略提高了基础生成器的性能。", "motivation": "现有的统一模型面临昂贵的训练成本和理解与生成之间的权衡，而模块化系统则受限于静态流水线。GenAgent旨在解决这些问题，通过自主多轮交互提高文本到图像生成的质量。", "method": "首先进行监督微调以引导代理行为，然后结合点奖励和对偶奖励的端到端代理强化学习，增强多轮探索，并实现跨工具泛化、测试时间扩展以及任务自适应推理。", "result": "GenAgent显著提高了基础生成器在GenEval++和WISE上的性能，展示了跨工具泛化的潜力，测试时随交互次数增加而持续改进的能力，以及根据不同任务自动调整的能力。", "conclusion": "该研究提出了一种新的代理多模态框架，通过自主多轮交互实现文本到图像的生成，并且提高了现有基础生成器的表现。"}}
{"id": "2601.18537", "pdf": "https://arxiv.org/pdf/2601.18537", "abs": "https://arxiv.org/abs/2601.18537", "authors": ["Linyong Gan", "Zimo Li", "Wenxin Xu", "Xingjian Li", "Jianhua Z. Huang", "Enmei Tu", "Shuhang Chen"], "title": "SKETCH: Semantic Key-Point Conditioning for Long-Horizon Vessel Trajectory Prediction", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Accurate long-horizon vessel trajectory prediction remains challenging due to compounded uncertainty from complex navigation behaviors and environmental factors. Existing methods often struggle to maintain global directional consistency, leading to drifting or implausible trajectories when extrapolated over long time horizons. To address this issue, we propose a semantic-key-point-conditioned trajectory modeling framework, in which future trajectories are predicted by conditioning on a high-level Next Key Point (NKP) that captures navigational intent. This formulation decomposes long-horizon prediction into global semantic decision-making and local motion modeling, effectively restricting the support of future trajectories to semantically feasible subsets. To efficiently estimate the NKP prior from historical observations, we adopt a pretrain-finetune strategy. Extensive experiments on real-world AIS data demonstrate that the proposed method consistently outperforms state-of-the-art approaches, particularly for long travel durations, directional accuracy, and fine-grained trajectory prediction.", "AI": {"tldr": "提出了一种基于语义关键点的长时序船舶轨迹预测框架，以提高预测准确性。", "motivation": "现有方法在长时序预测中难以保持全局方向一致性，导致漂移或不合理轨迹。", "method": "通过引入高阶下一步关键点（NKP）来捕捉导航意图，并采用预训练微调策略估计NKP先验。", "result": "实验结果表明该方法显著优于现有技术，在长航时、方向准确性和细粒度轨迹预测方面表现尤为出色。", "conclusion": "所提出的方法有效解决了船舶长期轨迹预测中的关键问题，提高了预测的可行性和准确性。"}}
{"id": "2601.18535", "pdf": "https://arxiv.org/pdf/2601.18535", "abs": "https://arxiv.org/abs/2601.18535", "authors": ["Peter Balušík", "Pavel Rajmic"], "title": "Audio Inpainting in Time-Frequency Domain with Phase-Aware Prior", "categories": ["eess.AS", "cs.SD"], "comment": "submitted to IEEE Transactions on Audio, Speech and Language Processing", "summary": "The so-called audio inpainting problem in the time domain refers to estimating missing segments of samples within a signal. Over the years, several methods have been developed for such type of audio inpainting. In contrast to this case, a time-frequency variant of inpainting appeared in the literature, where the challenge is to reconstruct missing spectrogram columns with reliable information. We propose a method to address this time-frequency audio inpainting problem. Our approach is based on the recently introduced phase-aware signal prior that exploits an estimate of the instantaneous frequency. An optimization problem is formulated and solved using the generalized Chambolle-Pock algorithm. The proposed method is evaluated both objectively and subjectively against other time-frequency inpainting methods, specifically a deep-prior neural network and the autoregression-based approach known as Janssen-TF. Our proposed approach surpassed these methods in the objective evaluation as well as in the conducted listening test. Moreover, this outcome is achieved with a substantially reduced computational requirement compared to alternative methods.", "AI": {"tldr": "本文提出了一种基于相位感知信号先验的时间频率域音频插值方法，通过解决缺失频谱列的重建问题来提高音频质量。", "motivation": "现有的时间域音频插值技术已经较为成熟，但针对时间频率域内的音频插值仍然存在挑战。为了更精确地恢复丢失的部分并减少计算需求，本文提出了一种新的相位感知方法。", "method": "使用了估计瞬时频率的相位感知信号先验，并通过广义Chambolle-Pock算法解决优化问题来实现时间频率域内的音频插值。", "result": "该方法在客观评估和主观听觉测试中均优于其他时间频率域内音频插值技术，且计算需求较低。", "conclusion": "相位感知信号先验的方法可以有效地进行时间频率域内的音频插值，并具备良好的性能表现与低计算复杂度。"}}
{"id": "2601.18532", "pdf": "https://arxiv.org/pdf/2601.18532", "abs": "https://arxiv.org/abs/2601.18532", "authors": ["Devon Levy", "Bar Assayag", "Laura Gaspar", "Ilan Shimshoni", "Bella Specktor-Fadida"], "title": "From Cold Start to Active Learning: Embedding-Based Scan Selection for Medical Image Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "19 pages without references", "summary": "Accurate segmentation annotations are critical for disease monitoring, yet manual labeling remains a major bottleneck due to the time and expertise required. Active learning (AL) alleviates this burden by prioritizing informative samples for annotation, typically through a diversity-based cold-start phase followed by uncertainty-driven selection. We propose a novel cold-start sampling strategy that combines foundation-model embeddings with clustering, including automatic selection of the number of clusters and proportional sampling across clusters, to construct a diverse and representative initial training. This is followed by an uncertainty-based AL framework that integrates spatial diversity to guide sample selection. The proposed method is intuitive and interpretable, enabling visualization of the feature-space distribution of candidate samples. We evaluate our approach on three datasets spanning X-ray and MRI modalities. On the CheXmask dataset, the cold-start strategy outperforms random selection, improving Dice from 0.918 to 0.929 and reducing the Hausdorff distance from 32.41 to 27.66 mm. In the AL setting, combined entropy and diversity selection improves Dice from 0.919 to 0.939 and reduces the Hausdorff distance from 30.10 to 19.16 mm. On the Montgomery dataset, cold-start gains are substantial, with Dice improving from 0.928 to 0.950 and Hausdorff distance decreasing from 14.22 to 9.38 mm. On the SynthStrip dataset, cold-start selection slightly affects Dice but reduces the Hausdorff distance from 9.43 to 8.69 mm, while active learning improves Dice from 0.816 to 0.826 and reduces the Hausdorff distance from 7.76 to 6.38 mm. Overall, the proposed framework consistently outperforms baseline methods in low-data regimes, improving segmentation accuracy.", "AI": {"tldr": "提出了一种结合基础模型嵌入和聚类的新型冷启动采样策略，用于医学图像分割中的主动学习。", "motivation": "为了减轻手动标记耗时且需要专业知识的问题，通过优先选择信息丰富的样本进行标注来减少负担。本文动机在于通过新颖的冷启动策略提高数据利用率，进而改善医学图像分割任务。", "method": "首先使用基础模型嵌入和聚类自动选择集群数量及比例采样以构造多样性的初始训练集；然后采用不确定性驱动的选择框架结合空间多样性进行样本选取，并能够可视化候选样本在特征空间的分布情况。", "result": "实验结果表明，冷启动策略相比随机选择提高了Dice系数并减少了Hausdorff距离，在不同数据集上的性能均有显著提升。主动学习设置下，集成熵和多样性的选择进一步增强了分割准确性。", "conclusion": "所提出的框架在低数据条件下表现出了优于基线方法的性能，有效提升了医学图像分割的准确度"}}
{"id": "2601.18525", "pdf": "https://arxiv.org/pdf/2601.18525", "abs": "https://arxiv.org/abs/2601.18525", "authors": ["Eleonora Grassucci", "Giordano Cicchetti", "Emanuele Frasca", "Aurelio Uncini", "Danilo Comminiello"], "title": "Closing the Modality Gap Aligns Group-Wise Semantics", "categories": ["cs.LG", "cs.CV"], "comment": "ICLR 2026", "summary": "In multimodal learning, CLIP has been recognized as the \\textit{de facto} method for learning a shared latent space across multiple modalities, placing similar representations close to each other and moving them away from dissimilar ones. Although CLIP-based losses effectively align modalities at the semantic level, the resulting latent spaces often remain only partially shared, revealing a structural mismatch known as the modality gap. While the necessity of addressing this phenomenon remains debated, particularly given its limited impact on instance-wise tasks (e.g., retrieval), we prove that its influence is instead strongly pronounced in group-level tasks (e.g., clustering). To support this claim, we introduce a novel method designed to consistently reduce this discrepancy in two-modal settings, with a straightforward extension to the general $n$-modal case. Through our extensive evaluation, we demonstrate our novel insight: while reducing the gap provides only marginal or inconsistent improvements in traditional instance-wise tasks, it significantly enhances group-wise tasks. These findings may reshape our understanding of the modality gap, highlighting its key role in improving performance on tasks requiring semantic grouping.", "AI": {"tldr": "该论文提出了一种减少多模态学习中模态间隙的方法，以改善语义分组任务的表现。", "motivation": "虽然CLIP在实例级别任务中的影响有限，但该研究证明了模态差距对群体级别任务有着显著的影响。为此，作者旨在解决这一问题，提高语义分组相关任务的性能。", "method": "通过引入一种新的方法，在两模态设置下系统地减少这种差异，并且可以简单地扩展到一般n模态情况。", "result": "实验结果显示，虽然减少模态差距在传统的实例级别任务中仅提供边际或不一致的改进，但对群体水平的任务有显著提升效果。", "conclusion": "这些发现可能重新定义我们对模态差距的理解，并强调其对于需要语义分组的任务的重要性。"}}
{"id": "2601.18521", "pdf": "https://arxiv.org/pdf/2601.18521", "abs": "https://arxiv.org/abs/2601.18521", "authors": ["Emna Boudabbous", "Mohamed Karaa", "Lokman Sboui", "Julio Montecinos", "Omar Alam"], "title": "Scalable Transit Delay Prediction at City Scale: A Systematic Approach with Multi-Resolution Feature Engineering and Deep Learning", "categories": ["cs.LG", "cs.AI"], "comment": "This manuscript is a preprint of an earlier version. A revised system-oriented version is currently under review", "summary": "Urban bus transit agencies need reliable, network-wide delay predictions to provide accurate arrival information to passengers and support real-time operational control. Accurate predictions help passengers plan their trips, reduce waiting time, and allow operations staff to adjust headways, dispatch extra vehicles, and manage disruptions. Although real-time feeds such as GTFS-Realtime (GTFS-RT) are now widely available, most existing delay prediction systems handle only a few routes, depend on hand-crafted features, and offer little guidance on how to design a scalable, reusable architecture. We present a city-scale prediction pipeline that combines multi-resolution feature engineering, dimensionality reduction, and deep learning. The framework generates 1,683 spatiotemporal features by exploring 23 aggregation combinations over H3 cells, routes, segments, and temporal patterns, and compresses them into 83 components using Adaptive PCA while preserving 95% of the variance. To avoid the \"giant cluster\" problem that occurs when dense urban areas fall into a single H3 region, we introduce a hybrid H3+topology clustering method that yields 12 balanced route clusters (coefficient of variation 0.608) and enables efficient distributed training. We compare five model architectures on six months of bus operations from the Société de transport de Montréal (STM) network in Montréal. A global LSTM with cluster-aware features achieves the best trade-off between accuracy and efficiency, outperforming transformer models by 18 to 52% while using 275 times fewer parameters. We also report multi-level evaluation at the elementary segment, segment, and trip level with walk-forward validation and latency analysis, showing that the proposed pipeline is suitable for real-time, city-scale deployment and can be reused for other networks with limited adaptation.", "AI": {"tldr": "提出了一种基于多分辨率特征工程和深度学习的城市公交延迟预测系统。", "motivation": "城市公交机构需要准确的网络范围内的延误预测来提供乘客准确到达信息和支持实时运营控制。现有的延时预测系统处理线路有限，依赖手工设计特征，并缺乏可扩展、重用架构的设计指导。", "method": "结合多分辨率特征工程、降维和深度学习技术构建了一个城市规模的预测管道，使用自适应PCA压缩1683个时空特征为83个组件并保持95%方差。采用混合H3+拓扑聚类方法解决密集城区单一区域问题，并进行高效的分布式训练。", "result": "在全球LSTM模型中加入簇感知特性，在蒙特利尔公共交通网络上比变压器模型准确率高18到52%，参数少275倍。通过多级评估和延迟分析表明该管道适合实时城市规模部署并可应用于其他公交网络。", "conclusion": "提出的系统能够有效解决大规模城市公交延误预测问题，具有良好的准确性、效率和通用性。"}}
{"id": "2601.18510", "pdf": "https://arxiv.org/pdf/2601.18510", "abs": "https://arxiv.org/abs/2601.18510", "authors": ["Yibo Li", "Zijie Lin", "Ailin Deng", "Xuan Zhang", "Yufei He", "Shuo Ji", "Tri Cao", "Bryan Hooi"], "title": "Just-In-Time Reinforcement Learning: Continual Learning in LLM Agents Without Gradient Updates", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While Large Language Model (LLM) agents excel at general tasks, they inherently struggle with continual adaptation due to the frozen weights after deployment. Conventional reinforcement learning (RL) offers a solution but incurs prohibitive computational costs and the risk of catastrophic forgetting. We introduce Just-In-Time Reinforcement Learning (JitRL), a training-free framework that enables test-time policy optimization without any gradient updates. JitRL maintains a dynamic, non-parametric memory of experiences and retrieves relevant trajectories to estimate action advantages on-the-fly. These estimates are then used to directly modulate the LLM's output logits. We theoretically prove that this additive update rule is the exact closed-form solution to the KL-constrained policy optimization objective. Extensive experiments on WebArena and Jericho demonstrate that JitRL establishes a new state-of-the-art among training-free methods. Crucially, JitRL outperforms the performance of computationally expensive fine-tuning methods (e.g., WebRL) while reducing monetary costs by over 30 times, offering a scalable path for continual learning agents. The code is available at https://github.com/liushiliushi/JitRL.", "AI": {"tldr": "本文介绍了Just-In-Time Reinforcement Learning（JitRL），一种无需梯度更新的即时策略优化框架，用于大型语言模型代理在部署后的持续学习。", "motivation": "现有的大型语言模型代理由于冻结权重而难以进行连续适应。传统的强化学习方法虽然提供了解决方案但计算成本高且容易导致灾难性遗忘，因此提出了JitRL以解决这些问题。", "method": "JitRL通过维护一个动态的经验记忆库并从该库中检索相关的轨迹来估计动作优势，并使用这些估计值直接调整LLM的输出logits，从而实现即时策略优化。这种方法在理论上被证明是KL约束下的政策优化目标的确切闭形式解。", "result": "实验结果表明，JitRL不仅建立了训练免费方法的新标准，还超越了计算成本高昂的微调方法（如WebRL），同时将成本降低了30倍以上。", "conclusion": "JitRL提供了一种无需训练且可扩展的方法来实现大型语言模型代理的持续学习。"}}
{"id": "2601.18497", "pdf": "https://arxiv.org/pdf/2601.18497", "abs": "https://arxiv.org/abs/2601.18497", "authors": ["Sizhe Cheng", "Songheng Zhang", "Dong Ma", "Yong Wang"], "title": "BAIT: Visual-illusion-inspired Privacy Preservation for Mobile Data Visualization", "categories": ["cs.HC"], "comment": "Accepted by CHI'26", "summary": "With the prevalence of mobile data visualizations, there have been growing concerns about their privacy risks, especially shoulder surfing attacks. Inspired by prior research on visual illusion, we propose BAIT, a novel approach to automatically generate privacy-preserving visualizations by stacking a decoy visualization over a given visualization. It allows visualization owners at proximity to clearly discern the original visualization and makes shoulder surfers at a distance be misled by the decoy visualization, by adjusting different visual channels of a decoy visualization (e.g., shape, position, tilt, size, color and spatial frequency). We explicitly model human perception effect at different viewing distances to optimize the decoy visualization design. Privacy-preserving examples and two in-depth user studies demonstrate the effectiveness of BAIT in both controlled lab study and real-world scenarios.", "AI": {"tldr": "提出一种基于视觉错觉的隐私保护方法BAIT，用于移动数据可视化中防止肩窥攻击。", "motivation": "随着移动数据可视化的普及，隐私风险增加，特别是肩窥攻击。通过借鉴视觉错觉的研究成果来减少这种风险。", "method": "通过叠加一个伪装视图在给定视图之上生成隐私保护的可视化效果，调整伪装视图的不同视觉通道（如形状、位置、倾斜度、大小、颜色和空间频率）以实现对近距离的用户清晰展示原始数据，而使远距离的肩窥者被误导。", "result": "通过具体的隐私保护示例及深入的用户体验研究，在控制实验室环境与真实世界场景中展示了BAIT的有效性。", "conclusion": "BAIT能够在不影响近距离用户的前提下有效防止肩窥攻击，并且这种方法在不同应用场景中有很好的适应性和实用性。"}}
{"id": "2601.18496", "pdf": "https://arxiv.org/pdf/2601.18496", "abs": "https://arxiv.org/abs/2601.18496", "authors": ["Zihan wang", "Hao Wang", "Shi Feng", "Xiaocui Yang", "Daling Wang", "Yiqun Zhang", "Jinghao Lin", "Haihua Yang", "Xiaozhong Ji"], "title": "DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference", "categories": ["cs.AI"], "comment": null, "summary": "Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus \"find it but fail to use it,\" leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\\% on average and outperforms larger medical reasoning and DR models.", "AI": {"tldr": "构建了一个名为DEEPMED的医疗深度研究代理，通过多跳医学搜索数据和分步控制代理训练及推理方法，提高了在七个医疗基准测试上的表现。", "motivation": "现有模型受限于参数知识，在医疗领域容易产生遗忘和错误；而通用的DeepResearch模型虽然可以检索信息但缺乏临床背景下的推理能力。此外，盲目扩大工具调用可能导致噪音增加影响敏感的医学推理。因此提出DEEPMED以解决这些问题。", "method": "采用多跳医学搜索QA合成方法使模型在医疗场景中应用DR范式；训练过程中引入难度感知轮次惩罚抑制过度使用工具；推理时添加验证器控制假设检验步骤数避免背景信息丢失。", "result": "相比基准模型，DEEPMED平均提升了9.79%；优于其他医学推理和DR模型。", "conclusion": "通过特定方法改进了现有医疗领域中的深度研究代理性能，展示了在复杂多变的临床环境中提高准确性和效率的可能性。"}}
{"id": "2601.18493", "pdf": "https://arxiv.org/pdf/2601.18493", "abs": "https://arxiv.org/abs/2601.18493", "authors": ["Sara Tehrani", "Yonghao Xu", "Leif Haglund", "Amanda Berg", "Michael Felsberg"], "title": "DisasterInsight: A Multimodal Benchmark for Function-Aware and Grounded Disaster Assessment", "categories": ["cs.CV"], "comment": "Under review at ICPR 2026", "summary": "Timely interpretation of satellite imagery is critical for disaster response, yet existing vision-language benchmarks for remote sensing largely focus on coarse labels and image-level recognition, overlooking the functional understanding and instruction robustness required in real humanitarian workflows. We introduce DisasterInsight, a multimodal benchmark designed to evaluate vision-language models (VLMs) on realistic disaster analysis tasks. DisasterInsight restructures the xBD dataset into approximately 112K building-centered instances and supports instruction-diverse evaluation across multiple tasks, including building-function classification, damage-level and disaster-type classification, counting, and structured report generation aligned with humanitarian assessment guidelines. To establish domain-adapted baselines, we propose DI-Chat, obtained by fine-tuning existing VLM backbones on disaster-specific instruction data using parameter-efficient Low-Rank Adaptation (LoRA). Extensive experiments on state-of-the-art generic and remote-sensing VLMs reveal substantial performance gaps across tasks, particularly in damage understanding and structured report generation. DI-Chat achieves significant improvements on damage-level and disaster-type classification as well as report generation quality, while building-function classification remains challenging for all evaluated models. DisasterInsight provides a unified benchmark for studying grounded multimodal reasoning in disaster imagery.", "AI": {"tldr": "本论文介绍了一个名为DisasterInsight的多模态基准，用于评估视觉语言模型在灾害分析任务中的表现。", "motivation": "现有的视觉-语言基准主要关注粗糙标签和图像级别的识别，忽视了灾难响应中所需的结构化理解和指令鲁棒性。因此，提出了新的基准以满足人道主义工作流程的实际需求。", "method": "通过重构xBD数据集为112K个建筑为中心的实例，并支持多任务评估如建筑物功能分类、损害程度和灾害类型识别等，引入了DisasterInsight。此外，提出DI-Chat模型，使用参数高效的低秩适应（LoRA）方法对灾难特定指令数据进行微调。", "result": "实验表明，在损伤理解和结构化报告生成方面存在显著性能差距，尤其是建筑功能分类仍然具有挑战性。然而，DI-Chat在损害程度和灾害类型识别以及报告质量上取得了显著改进。", "conclusion": "DisasterInsight为研究灾难图像中的基于多模态推理提供了统一的基准。"}}
{"id": "2601.18492", "pdf": "https://arxiv.org/pdf/2601.18492", "abs": "https://arxiv.org/abs/2601.18492", "authors": ["Zijun Li", "Shijie Li", "Zhenxi Zhang", "Bin Li", "Shoujun Zhou"], "title": "DV-VLN: Dual Verification for Reliable LLM-Based Vision-and-Language Navigation", "categories": ["cs.RO"], "comment": null, "summary": "Vision-and-Language Navigation (VLN) requires an embodied agent to navigate in a complex 3D environment according to natural language instructions. Recent progress in large language models (LLMs) has enabled language-driven navigation with improved interpretability. However, most LLM-based agents still rely on single-shot action decisions, where the model must choose one option from noisy, textualized multi-perspective observations. Due to local mismatches and imperfect intermediate reasoning, such decisions can easily deviate from the correct path, leading to error accumulation and reduced reliability in unseen environments. In this paper, we propose DV-VLN, a new VLN framework that follows a generate-then-verify paradigm. DV-VLN first performs parameter-efficient in-domain adaptation of an open-source LLaMA-2 backbone to produce a structured navigational chain-of-thought, and then verifies candidate actions with two complementary channels: True-False Verification (TFV) and Masked-Entity Verification (MEV). DV-VLN selects actions by aggregating verification successes across multiple samples, yielding interpretable scores for reranking. Experiments on R2R, RxR (English subset), and REVERIE show that DV-VLN consistently improves over direct prediction and sampling-only baselines, achieving competitive performance among language-only VLN agents and promising results compared with several cross-modal systems.Code is available at https://github.com/PlumJun/DV-VLN.", "AI": {"tldr": "本文提出了一种新的基于大语言模型的视觉和语言导航框架DV-VLN，采用生成-验证范式提高决策可靠性。", "motivation": "传统的基于语言的大规模模型在复杂环境中执行单一决策时容易因局部不匹配和中间推理不足而偏离正确路径。这导致误差积累并降低在未见过环境中的性能。", "method": "DV-VLN首先通过领域适应技术生成导航策略，然后使用真伪验证（TFV）和掩码实体验证（MEV）双通道对候选操作进行验证，并根据多次采样的验证成功次数重新排序选择动作。", "result": "实验结果显示，在R2R、RxR（英语子集）、REVERIE数据集中，DV-VLN优于直接预测和仅采用采样方法的基线模型，具有与跨模态系统相竞争的表现。", "conclusion": "DV-VLN通过生成-验证的方法提高了基于语言的大规模模型在视觉和语言导航任务中的可靠性，取得了显著的结果。"}}
{"id": "2601.18491", "pdf": "https://arxiv.org/pdf/2601.18491", "abs": "https://arxiv.org/abs/2601.18491", "authors": ["Dongrui Liu", "Qihan Ren", "Chen Qian", "Shuai Shao", "Yuejin Xie", "Yu Li", "Zhonghao Yang", "Haoyu Luo", "Peng Wang", "Qingyu Liu", "Binxin Hu", "Ling Tang", "Jilin Mei", "Dadi Guo", "Leitao Yuan", "Junyao Yang", "Guanxu Chen", "Qihao Lin", "Yi Yu", "Bo Zhang", "Jiaxuan Guo", "Jie Zhang", "Wenqi Shao", "Huiqi Deng", "Zhiheng Xi", "et al. (18 additional authors not shown)"], "title": "AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security", "categories": ["cs.AI", "cs.CC", "cs.CL", "cs.CV", "cs.LG"], "comment": "40 pages, 26 figures", "summary": "The rise of AI agents introduces complex safety and security challenges arising from autonomous tool use and environmental interactions. Current guardrail models lack agentic risk awareness and transparency in risk diagnosis. To introduce an agentic guardrail that covers complex and numerous risky behaviors, we first propose a unified three-dimensional taxonomy that orthogonally categorizes agentic risks by their source (where), failure mode (how), and consequence (what). Guided by this structured and hierarchical taxonomy, we introduce a new fine-grained agentic safety benchmark (ATBench) and a Diagnostic Guardrail framework for agent safety and security (AgentDoG). AgentDoG provides fine-grained and contextual monitoring across agent trajectories. More Crucially, AgentDoG can diagnose the root causes of unsafe actions and seemingly safe but unreasonable actions, offering provenance and transparency beyond binary labels to facilitate effective agent alignment. AgentDoG variants are available in three sizes (4B, 7B, and 8B parameters) across Qwen and Llama model families. Extensive experimental results demonstrate that AgentDoG achieves state-of-the-art performance in agentic safety moderation in diverse and complex interactive scenarios. All models and datasets are openly released.", "AI": {"tldr": "本文提出了AgentDoG框架，用于AI代理的安全性和透明度监控，并通过三个维度的分类系统来诊断和预防风险行为。", "motivation": "当前的AI代理安全防护措施缺乏针对复杂且多样的风险行为进行全面评估的能力。为了填补这一空白，论文旨在创建一个可以覆盖更多风险场景并提供诊断能力的新框架。", "method": "首先构建了三个维度的风险分类系统来识别和归类不同类型的潜在风险；基于此分类系统开发了一种新的基准测试ATBench以及AgentDoG框架，并提供了模型变体以适应不同的需求。", "result": "实验结果显示，AgentDoG在多种复杂互动场景下的代理安全监管中表现出色，达到了当前的最高性能水平。", "conclusion": "论文通过引入AgentDoG框架和风险分类系统提高了AI代理的安全性、透明度以及诊断能力，有助于更好地对齐人类意图。所有模型及数据集都已公开发布供研究使用。"}}
{"id": "2601.18483", "pdf": "https://arxiv.org/pdf/2601.18483", "abs": "https://arxiv.org/abs/2601.18483", "authors": ["Arya Labroo", "Ivaxi Sheth", "Vyas Raina", "Amaani Ahmed", "Mario Fritz"], "title": "Funny or Persuasive, but Not Both: Evaluating Fine-Grained Multi-Concept Control in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted for publication at EACL main conference", "summary": "Large Language Models (LLMs) offer strong generative capabilities, but many applications require explicit and \\textit{fine-grained} control over specific textual concepts, such as humor, persuasiveness, or formality. Prior approaches in prompting and representation engineering can provide coarse or single-attribute control, but systematic evaluation of multi-attribute settings remains limited. We introduce an evaluation framework for fine-grained controllability for both single- and dual-concept scenarios, focusing on linguistically distinct concept pairs (e.g., persuasiveness vs.~humor). Surprisingly, across multiple LLMs and generative tasks, we find that performance often drops in the dual-concept setting, even though the chosen concepts should in principle be separable. This reveals a fundamental limitation of naive prompting-based control: models struggle with compositionality even when concepts are intuitively independent. Our framework provides systematic evidence of this gap and offers a principled approach for measuring the ability of future methods for multi-concept control.", "AI": {"tldr": "该论文提出了一种评估大型语言模型（LLM）在单一和双重概念控制下的框架，发现即使独立的概念，LLM也难以同时管理。", "motivation": "当前的LLM虽然具备强大的生成能力，但在需要对特定文本概念如幽默、说服力或正式性进行显式且精细控制的应用中面临挑战。现有方法通常只能提供粗略或单一属性的控制，缺乏系统评估多属性设置的能力。", "method": "提出了一种新的评价框架来检验LLM在单个和双重概念场景中的细粒度可控性，并通过多种任务测试了多个LLM的表现。", "result": "研究表明，在双概念环境下，性能通常会下降，即使所选的概念从理论上应该是可分离的。这揭示了一个基本限制：基于提示的方法难以实现组成性控制。", "conclusion": "该框架为未来改进多概念控制提供了一种系统的测量方法，并强调了当前LLM在处理复杂文本属性时存在的问题。"}}
{"id": "2601.18475", "pdf": "https://arxiv.org/pdf/2601.18475", "abs": "https://arxiv.org/abs/2601.18475", "authors": ["Xinhui Liu", "Can Wang", "Lei Liu", "Zhenghao Chen", "Wei Jiang", "Wei Wang", "Dong Xu"], "title": "LoD-Structured 3D Gaussian Splatting for Streaming Video Reconstruction", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Free-Viewpoint Video (FVV) reconstruction enables photorealistic and interactive 3D scene visualization; however, real-time streaming is often bottlenecked by sparse-view inputs, prohibitive training costs, and bandwidth constraints. While recent 3D Gaussian Splatting (3DGS) has advanced FVV due to its superior rendering speed, Streaming Free-Viewpoint Video (SFVV) introduces additional demands for rapid optimization, high-fidelity reconstruction under sparse constraints, and minimal storage footprints. To bridge this gap, we propose StreamLoD-GS, an LoD-based Gaussian Splatting framework designed specifically for SFVV. Our approach integrates three core innovations: 1) an Anchor- and Octree-based LoD-structured 3DGS with a hierarchical Gaussian dropout technique to ensure efficient and stable optimization while maintaining high-quality rendering; 2) a GMM-based motion partitioning mechanism that separates dynamic and static content, refining dynamic regions while preserving background stability; and 3) a quantized residual refinement framework that significantly reduces storage requirements without compromising visual fidelity. Extensive experiments demonstrate that StreamLoD-GS achieves competitive or state-of-the-art performance in terms of quality, efficiency, and storage.", "AI": {"tldr": "提出了一种层次结构的3D高斯点状图框架，用于流式自由视角视频重建。", "motivation": "解决稀疏视图输入、高昂训练成本和带宽限制等问题，以实现实时流传输。", "method": "1) 基于锚点和八叉树的LoD-结构化3DGS结合层次高斯丢弃技术；2) 利用GMM进行运动分割机制分离动态静态内容；3) 量化残差细化框架减少存储需求。", "result": "在质量、效率和存储方面表现出色，达到或超过现有方法。", "conclusion": "StreamLoD-GS成功解决了流式自由视角视频重建中的关键挑战，提高了质量和效率，并减少了存储要求。"}}
{"id": "2601.18467", "pdf": "https://arxiv.org/pdf/2601.18467", "abs": "https://arxiv.org/abs/2601.18467", "authors": ["Yuhang Zhou", "Kai Zheng", "Qiguang Chen", "Mengkang Hu", "Qingfeng Sun", "Can Xu", "Jingjing Chen"], "title": "OffSeeker: Online Reinforcement Learning Is Not All You Need for Deep Research Agents", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Deep research agents have shown remarkable potential in handling long-horizon tasks. However, state-of-the-art performance typically relies on online reinforcement learning (RL), which is financially expensive due to extensive API calls. While offline training offers a more efficient alternative, its progress is hindered by the scarcity of high-quality research trajectories. In this paper, we demonstrate that expensive online reinforcement learning is not all you need to build powerful research agents. To bridge this gap, we introduce a fully open-source suite designed for effective offline training. Our core contributions include DeepForge, a ready-to-use task synthesis framework that generates large-scale research queries without heavy preprocessing; and a curated collection of 66k QA pairs, 33k SFT trajectories, and 21k DPO pairs. Leveraging these resources, we train OffSeeker (8B), a model developed entirely offline. Extensive evaluations across six benchmarks show that OffSeeker not only leads among similar-sized agents but also remains competitive with 30B-parameter systems trained via heavy online RL.", "AI": {"tldr": "该论文展示了通过离线训练可以创建强大的研究代理，而无需昂贵的在线强化学习。", "motivation": "现有的深度研究代理依赖于耗资巨大的在线强化学习。为了提高效率和降低成本，作者提出了一种替代方法：利用高质量的研究轨迹进行离线训练。", "method": "引入了一个开源套件，包括DeepForge任务合成框架，生成大量研究查询的工具；并提供了一系列预处理过的数据集（66k QA对、33k SFT轨迹和21k DPO对）。使用这些资源，作者完全通过离线方式训练了OffSeeker模型。", "result": "评估显示，OffSeeker在六项基准测试中表现出色，并且与需要大量在线RL的较大参数系统相比具有竞争力。", "conclusion": "证明了昂贵的在线强化学习并非创建强大研究代理所必需，离线方法同样能够取得卓越成果。"}}
{"id": "2601.18464", "pdf": "https://arxiv.org/pdf/2601.18464", "abs": "https://arxiv.org/abs/2601.18464", "authors": ["Wenbin Wei", "Suyuan Yao", "Cheng Huang", "Xiangyu Gao"], "title": "Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain AI System", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Glaucoma is a top cause of irreversible blindness globally, making early detection and longitudinal follow-up pivotal to preventing permanent vision loss. Current screening and progression assessment, however, rely on single tests or loosely linked examinations, introducing subjectivity and fragmented care. Limited access to high-quality imaging tools and specialist expertise further compromises consistency and equity in real-world use. To address these gaps, we developed Fair-Eye Net, a fair, reliable multimodal AI system closing the clinical loop from glaucoma screening to follow-up and risk alerting. It integrates fundus photos, OCT structural metrics, VF functional indices, and demographic factors via a dual-stream heterogeneous fusion architecture, with an uncertainty-aware hierarchical gating strategy for selective prediction and safe referral. A fairness constraint reduces missed diagnoses in disadvantaged subgroups. Experimental results show it achieved an AUC of 0.912 (96.7% specificity), cut racial false-negativity disparity by 73.4% (12.31% to 3.28%), maintained stable cross-domain performance, and enabled 3-12 months of early risk alerts (92% sensitivity, 88% specificity). Unlike post hoc fairness adjustments, Fair-Eye Net optimizes fairness as a primary goal with clinical reliability via multitask learning, offering a reproducible path for clinical translation and large-scale deployment to advance global eye health equity.", "AI": {"tldr": "开发了一种公平、可靠且全面的AI系统，用于青光眼筛查和随访管理。", "motivation": "为了提高青光眼早期检测准确性并减少种族诊断差异，解决现有单一测试或松散关联检查带来的主观性和碎片化问题，同时增加对高风险群体的有效识别与跟踪。", "method": "利用双流异构融合架构整合了视网膜照片、OCT结构指标和视野功能指数等多模态数据，并通过不确定性感知的分层门控策略实现选择性预测与安全转诊。引入公平约束减少弱势群体中的误诊率，优化模型性能。", "result": "实验结果显示该系统在诊断青光眼方面达到了0.912的AUC值（特异性为96.7%），降低了73.4%的种族假阴性差异，并能提供长达一年的风险预警。", "conclusion": "Fair-Eye Net通过多任务学习优化了公平性和临床可靠性，为青光眼筛查和管理提供了可复制路径，有助于全球眼健康平等。"}}
{"id": "2601.18456", "pdf": "https://arxiv.org/pdf/2601.18456", "abs": "https://arxiv.org/abs/2601.18456", "authors": ["Kohei Asai", "Wataru Nakata", "Yuki Saito", "Hiroshi Saruwatari"], "title": "Geneses: Unified Generative Speech Enhancement and Separation", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted to ICASSP 2025 workshop", "summary": "Real-world audio recordings often contain multiple speakers and various degradations, which limit both the quantity and quality of speech data available for building state-of-the-art speech processing models. Although end-to-end approaches that concatenate speech enhancement (SE) and speech separation (SS) to obtain a clean speech signal for each speaker are promising, conventional SE-SS methods suffer from complex degradations beyond additive noise. To this end, we propose \\textbf{Geneses}, a generative framework to achieve unified, high-quality SE--SS. Our Geneses leverages latent flow matching to estimate each speaker's clean speech features using multi-modal diffusion Transformer conditioned on self-supervised learning representation from noisy mixture. We conduct experimental evaluation using two-speaker mixtures from LibriTTS-R under two conditions: additive-noise-only and complex degradations. The results demonstrate that Geneses significantly outperforms a conventional mask-based SE--SS method across various objective metrics with high robustness against complex degradations. Audio samples are available in our demo page.", "AI": {"tldr": "本论文提出了一种统一的生成式语音增强和分离框架Geneses，旨在提高含复杂退化的真实世界音频数据的质量。", "motivation": "现实世界的录音通常包含多说话人及各种降质因素，限制了高质量语音数据的数量与质量。传统SE-SS方法在处理超出加性噪声的复杂退化时效果不佳。", "method": "Geneses利用潜在流匹配从嘈杂混合物中估计每个发言者的清晰语音特征，并通过自监督学习表示条件下的多模态扩散Transformer。", "result": "实验表明，与传统掩码基SE-SS方法相比，Geneses在多种客观指标上表现出色，尤其对复杂退化具有高鲁棒性。", "conclusion": "研究表明，Geneses能够有效提升含复杂降质的真实世界音频的质量，在语音处理领域展现出广阔的应用前景。"}}
{"id": "2601.18451", "pdf": "https://arxiv.org/pdf/2601.18451", "abs": "https://arxiv.org/abs/2601.18451", "authors": ["Xuanmeng Sha", "Liyun Zhang", "Tomohiro Mashita", "Naoya Chiba", "Yuki Uranishi"], "title": "3DGesPolicy: Phoneme-Aware Holistic Co-Speech Gesture Generation Based on Action Control", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.SD"], "comment": "13 pages, 5 figures", "summary": "Generating holistic co-speech gestures that integrate full-body motion with facial expressions suffers from semantically incoherent coordination on body motion and spatially unstable meaningless movements due to existing part-decomposed or frame-level regression methods, We introduce 3DGesPolicy, a novel action-based framework that reformulates holistic gesture generation as a continuous trajectory control problem through diffusion policy from robotics. By modeling frame-to-frame variations as unified holistic actions, our method effectively learns inter-frame holistic gesture motion patterns and ensures both spatially and semantically coherent movement trajectories that adhere to realistic motion manifolds. To further bridge the gap in expressive alignment, we propose a Gesture-Audio-Phoneme (GAP) fusion module that can deeply integrate and refine multi-modal signals, ensuring structured and fine-grained alignment between speech semantics, body motion, and facial expressions. Extensive quantitative and qualitative experiments on the BEAT2 dataset demonstrate the effectiveness of our 3DGesPolicy across other state-of-the-art methods in generating natural, expressive, and highly speech-aligned holistic gestures.", "AI": {"tldr": "本文提出了一个名为3DGesPolicy的新框架，用于生成与说话内容协调的全身动作和面部表情。", "motivation": "现有的手势生成方法存在语义不一致和空间不稳定的问题，因此需要一种新的方法来改善这些问题。", "method": "通过将整体手势生成作为连续轨迹控制问题重新建模，并引入Gesture-Audio-Phoneme融合模块以深化多模式信号的整合与优化。", "result": "实验结果表明该框架在BEAT2数据集上的表现优于其他最先进的方法，能够生成更加自然、富有表情且与语音高度同步的整体手势。", "conclusion": "3DGesPolicy通过引入新的方法和模型解决了现有手势生成技术中的局限性，并成功提高了整体手势生成的效果。"}}
{"id": "2601.18448", "pdf": "https://arxiv.org/pdf/2601.18448", "abs": "https://arxiv.org/abs/2601.18448", "authors": ["Lloyd Austin Courtenay"], "title": "On Procrustes Contamination in Machine Learning Applications of Geometric Morphometrics", "categories": ["cs.CV", "cs.LG"], "comment": "17 pages, 5 figures, Preprint pending review", "summary": "Geometric morphometrics (GMM) is widely used to quantify shape variation, more recently serving as input for machine learning (ML) analyses. Standard practice aligns all specimens via Generalized Procrustes Analysis (GPA) prior to splitting data into training and test sets, potentially introducing statistical dependence and contaminating downstream predictive models. Here, the effects of GPA-induced contamination are formally characterised using controlled 2D and 3D simulations across varying sample sizes, landmark densities, and allometric patterns. A novel realignment procedure is proposed, whereby test specimens are aligned to the training set prior to model fitting, eliminating cross-sample dependency. Simulations reveal a robust \"diagonal\" in sample-size vs. landmark-space, reflecting the scaling of RMSE under isotropic variation, with slopes analytically derived from the degrees of freedom in Procrustes tangent space. The importance of spatial autocorrelation among landmarks is further demonstrated using linear and convolutional regression models, highlighting performance degradation when landmark relationships are ignored. This work establishes the need for careful preprocessing in ML applications of GMM, provides practical guidelines for realignment, and clarifies fundamental statistical constraints inherent to Procrustes shape space.", "AI": {"tldr": "本文探讨了广义普罗克斯特斯分析（GPA）在机器学习应用中的潜在问题，并提出了一种新的对齐方法以消除跨样本依赖性。", "motivation": "标准实践是在进行训练集和测试集划分之前，通过广义普罗克斯特斯分析（GPA）对所有标本进行对齐。然而，这种做法可能导致统计上的依赖关系并污染下游预测模型。本文旨在正式描述GPA引起的污染效应，并提出解决方案。", "method": "使用受控的2D和3D模拟在不同的样本量、地标密度和全息模式下研究了广义普罗克斯特斯分析（GPA）的影响，提出了新的对齐方法：即将测试标本与训练集对齐后再进行模型拟合。此外，还通过线性和卷积回归模型展示了地标间空间自相关的显著性。", "result": "模拟揭示了一种样本量和地标空间之间的“对角线”，反映了在各向同性变化下RMSE的缩放情况，并且这些斜率可以从普罗克斯特斯切空间中的自由度中得出。证明了忽略地标间关系时，模型性能会下降。", "conclusion": "这项工作强调了GMM应用于机器学习时需要仔细预处理的重要性，提供了重新对齐的实际指南，并澄清了普罗克斯特斯形状空间的基本统计约束。"}}
{"id": "2601.18447", "pdf": "https://arxiv.org/pdf/2601.18447", "abs": "https://arxiv.org/abs/2601.18447", "authors": ["Jinlong Hu", "Jiacheng Liu"], "title": "GCFX: Generative Counterfactual Explanations for Deep Graph Models at the Model Level", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep graph learning models have demonstrated remarkable capabilities in processing graph-structured data and have been widely applied across various fields. However, their complex internal architectures and lack of transparency make it difficult to explain their decisions, resulting in opaque models that users find hard to understand and trust. In this paper, we explore model-level explanation techniques for deep graph learning models, aiming to provide users with a comprehensive understanding of the models' overall decision-making processes and underlying mechanisms. Specifically, we address the problem of counterfactual explanations for deep graph learning models by introducing a generative model-level counterfactual explanation approach called GCFX, which is based on deep graph generation. This approach generates a set of high-quality counterfactual explanations that reflect the model's global predictive behavior by leveraging an enhanced deep graph generation framework and a global summarization algorithm. GCFX features an architecture that combines dual encoders, structure-aware taggers, and Message Passing Neural Network decoders, enabling it to accurately learn the true latent distribution of input data and generate high-quality, closely related counterfactual examples. Subsequently, a global counterfactual summarization algorithm selects the most representative and comprehensive explanations from numerous candidate counterfactuals, providing broad insights into the model's global predictive patterns. Experiments on a synthetic dataset and several real-world datasets demonstrate that GCFX outperforms existing methods in terms of counterfactual validity and coverage while maintaining low explanation costs, thereby offering crucial support for enhancing the practicality and trustworthiness of global counterfactual explanations.", "AI": {"tldr": "提出了一种名为GCFX的生成模型级反事实解释方法，用于深度图学习模型。", "motivation": "为了提高用户对复杂且不透明的深度图学习模型的理解和信任，开发一种能够提供全面理解模型决策过程的方法。", "method": "通过使用增强的深度图生成框架和全局总结算法来生成高质量的反事实解释。该方法结合双编码器、结构感知标记器以及消息传递神经网络解码器构建架构。", "result": "实验表明GCFX在反事实有效性和覆盖率上优于现有方法，同时保持低解释成本。", "conclusion": "GCFX为提高全局反事实解释的实际应用价值和可信度提供了重要支持。"}}
{"id": "2601.18446", "pdf": "https://arxiv.org/pdf/2601.18446", "abs": "https://arxiv.org/abs/2601.18446", "authors": ["Xinmeng Yu", "Tao Jiang", "Ran Cheng", "Yaochu Jin", "Kay Chen Tan"], "title": "Scaling Behaviors of Evolutionary Algorithms on GPUs: When Does Parallelism Pay Off?", "categories": ["cs.NE"], "comment": null, "summary": "Evolutionary algorithms (EAs) are increasingly implemented on graphics processing units (GPUs) to leverage parallel processing capabilities for enhanced efficiency. However, existing studies largely emphasize the raw speedup obtained by porting individual algorithms from CPUs to GPUs. Consequently, these studies offer limited insight into when and why GPU parallelism fundamentally benefits EAs. To address this gap, we investigate how GPU parallelism alters the behavior of EAs beyond simple acceleration metrics. We conduct a systematic empirical study of 16 representative EAs on 30 benchmark problems. Specifically, we compare CPU and GPU executions across a wide range of problem dimensionalities and population sizes. Our results reveal that the impact of GPU acceleration is highly heterogeneous and depends strongly on algorithmic structure. We further demonstrate that conventional fixed-budget evaluation based on the number of function evaluations (FEs) is inadequate for GPU execution. In contrast, fixed-time evaluation uncovers performance characteristics that are unobservable under small or practically constrained FE budgets, particularly for adaptive and exploration-oriented algorithms. Moreover, we identify distinct scaling regimes in which GPU parallelism is beneficial, saturates, or degrades as problem dimensionality and population size increase. Crucially, we show that large populations enabled by GPUs not only improve hardware utilization but also reveal algorithm-specific convergence and diversity dynamics that are difficult to observe under CPU-constrained settings. Consequently, our findings indicate that GPU parallelism is not strictly an implementation detail, but a pivotal factor that influences how EAs should be evaluated, compared, and designed for modern computing platforms.", "AI": {"tldr": "研究进化算法在GPU上的扩展行为，探讨何时并行计算有益", "motivation": "现有研究表明将进化算法从CPU移植到GPU可获得加速，但缺乏对其根本益处的深入理解。本研究旨在填补这一空白。", "method": "系统性地比较了16种代表性的进化算法在30个基准问题上的CPU和GPU执行情况，并探讨了不同问题规模与群体大小下的性能表现", "result": "发现GPU加速效果因算法结构而异，固定时间评估揭示了固定FE预算下难以观察到的性能特征。此外，在大维度和群体大小情况下识别出不同的扩展阶段。", "conclusion": "结论指出GPU并行性不仅提升硬件利用率，还揭示出在CPU受限条件下难以观测的收敛性和多样性动态"}}
{"id": "2601.18442", "pdf": "https://arxiv.org/pdf/2601.18442", "abs": "https://arxiv.org/abs/2601.18442", "authors": ["Hongyi Zhao", "Shuo Wang", "Qijie He", "Ziyuan Pu"], "title": "SG-CADVLM: A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous vehicle safety validation requires testing on safety-critical scenarios, but these events are rare in real-world driving and costly to test due to collision risks. Crash reports provide authentic specifications of safety-critical events, offering a vital alternative to scarce real-world collision trajectory data. This makes them valuable sources for generating realistic high-risk scenarios through simulation. Existing approaches face significant limitations because data-driven methods lack diversity due to their reliance on existing latent distributions, whereas adversarial methods often produce unrealistic scenarios lacking physical fidelity. Large Language Model (LLM) and Vision Language Model (VLM)-based methods show significant promise. However, they suffer from context suppression issues where internal parametric knowledge overrides crash specifications, producing scenarios that deviate from actual accident characteristics. This paper presents SG-CADVLM (A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation), a framework that integrates Context-Aware Decoding with multi-modal input processing to generate safety-critical scenarios from crash reports and road network diagrams. The framework mitigates VLM hallucination issues while enabling the simultaneous generation of road geometry and vehicle trajectories. The experimental results demonstrate that SG-CADVLM generates critical risk scenarios at a rate of 84.4% compared to 12.5% for the baseline methods, representing an improvement of 469%, while producing executable simulations for autonomous vehicle testing.", "AI": {"tldr": "提出了一种用于生成安全关键场景的框架SG-CADVLM，该框架结合了上下文感知解码和多模态输入处理。", "motivation": "为了验证自动驾驶的安全性，需要测试在真实驾驶中罕见且危险的成本高昂的情景。现有的方法存在数据多样性不足及物理真实性差的问题。", "method": "提出了一个集成上下文感知解码与多模态输入处理的框架SG-CADVLM，利用碰撞报告和道路网络图生成安全关键场景。", "result": "实验结果表明，SG-CADVLM生成的安全关键场景的有效率为84.4%，比基线方法提高469%。", "conclusion": "该框架通过上下文感知解码技术提高了自动驾驶车辆测试中安全关键场景的生成效率和准确性。"}}
{"id": "2601.18438", "pdf": "https://arxiv.org/pdf/2601.18438", "abs": "https://arxiv.org/abs/2601.18438", "authors": ["Wei Wang", "Wangyou Zhang", "Chenda Li", "Jiahe Wang", "Samuele Cornell", "Marvin Sach", "Kohei Saijo", "Yihui Fu", "Zhaoheng Ni", "Bing Han", "Xun Gong", "Mengxiao Bi", "Tim Fingscheidt", "Shinji Watanabe", "Yanmin Qian"], "title": "UrgentMOS: Unified Multi-Metric and Preference Learning for Robust Speech Quality Assessment", "categories": ["cs.SD"], "comment": null, "summary": "Automatic speech quality assessment has become increasingly important as modern speech generation systems continue to advance, while human listening tests remain costly, time-consuming, and difficult to scale. Most existing learning-based assessment models rely primarily on scarce human-annotated mean opinion score (MOS) data, which limits robustness and generalization, especially when training across heterogeneous datasets. In this work, we propose UrgentMOS, a unified speech quality assessment framework that jointly learns from diverse objective and perceptual quality metrics, while explicitly tolerating the absence of arbitrary subsets of metrics during training. By leveraging complementary quality facets under heterogeneous supervision, UrgentMOS enables effective utilization of partially annotated data and improves robustness when trained on large-scale, multi-source datasets. Beyond absolute score prediction, UrgentMOS explicitly models pairwise quality preferences by directly predicting comparative MOS (CMOS), making it well suited for preference-based evaluation scenarios commonly adopted in system benchmarking. Extensive experiments across a wide range of speech quality datasets, including simulated distortions, speech enhancement, and speech synthesis, demonstrate that UrgentMOS consistently achieves state-of-the-art performance in both absolute and comparative evaluation settings.", "AI": {"tldr": "提出了一种统一的语音质量评估框架UrgentMOS，能够从多种客观和感知的质量指标中学习，并且在训练过程中可以容忍任意子集缺失的数据。", "motivation": "随着现代语音生成系统的进步，自动化的语音质量评估变得越来越重要。然而，人类听觉测试既耗时又昂贵，难以扩展。现有的基于学习的评估模型主要依赖稀少的人类注释MOS数据，这限制了其鲁棒性和泛化能力。", "method": "UrgentMOS框架联合学习多种客观和感知质量指标，并在训练过程中容忍任意子集缺失的数据。该方法不仅预测绝对分值，还通过直接预测比较性意见评分（CMOS）来建模语音质量偏好。", "result": "实验结果表明，UrgentMOS在各种语音质量数据集中均表现出了最先进的性能，在绝对和相对评估设置中都表现出色。", "conclusion": "UrgentMOS框架通过综合利用多种指标并容忍任意子集缺失的数据，提高了鲁棒性和泛化能力。该方法适用于偏好基础的评估场景，并在广泛的实验数据集中展示了优越的表现。"}}
{"id": "2601.18435", "pdf": "https://arxiv.org/pdf/2601.18435", "abs": "https://arxiv.org/abs/2601.18435", "authors": ["Biraja Ghoshal"], "title": "The Quantum Cliff: A Critical Proton Tunneling Threshold Determines Clinical Severity in RPE65-Mediated Retinal Disease", "categories": ["cs.ET", "q-bio.BM"], "comment": null, "summary": "Predicting clinical severity from genotype remains a fundamental challenge in molecular medicine, particularly for enzymes whose function depends on sub-atomic-scale geometry. Mutations in the \\textit{RPE65} isomerohydrolase cause Leber Congenital Amaurosis (LCA) and related retinal diseases; however, the kinetic mechanisms connecting sub-atomic-scale perturbations to blindness remain unclear. In this study, we demonstrate that mutations in the human visual isomerase RPE65 are governed by a quantum-mechanical threshold effect arising from proton tunneling in the active site. We established a hybrid quantum-classical structure-to-phenotype pipeline combining AlphaFold structure prediction with \\textit{ab initio} quantum simulation using the Variational Quantum Eigensolver (VQE) to analyze minimal proton-coupled electron transfer in the visual cycle. Our analysis reveals that many pathogenic mutations do not merely occlude the active site, but rather strongly reduce the quantum probability of proton tunneling. We observed a sharp non-linear effect, termed the \"Quantum Cliff,\" where minute structural changes (below 0.1 Å) reduce the reaction rate by multiple orders of magnitude. Based on these findings, we introduce a dimensionless Relative Quantum Activity Score (RQAS) that isolates the geometry-controlled exponential sensitivity of the reaction rate and successfully distinguishes between mild and severe patient phenotypes. These results suggest that RPE65 operates near a quantum-critical point, where sub-Angstrom structural perturbations induce a catastrophic loss of function. Furthermore, our findings establish quantum tunneling as a predictive mechanistic link between atomic structure and clinical phenotype, proposing a general framework for quantum-structural disease modeling.", "AI": {"tldr": "论文通过量子力学阈值效应来解释RPE65突变导致的临床严重程度，提出了预测机制和评分系统。", "motivation": "探索酶功能依赖于次原子尺度几何结构的情况下如何从基因型预测临床严重性，特别是对于LCA和相关视网膜疾病中的RPE65突变。", "method": "使用AlphaFold进行蛋白质结构预测，结合VQE量子模拟分析视觉循环中最小质子耦合电子转移的量子力学阈值效应。", "result": "发现许多病理性突变不仅阻塞活性位点，还强烈降低质子隧穿的概率，提出了一个区分轻度和重度临床表型的相对量子活动评分系统（RQAS）。", "conclusion": "研究表明RPE65在接近量子临界点时运行，其中次原子结构扰动会引起功能灾难性损失，并提出了一种通过量子结构性质进行疾病建模的一般框架。"}}
{"id": "2601.18428", "pdf": "https://arxiv.org/pdf/2601.18428", "abs": "https://arxiv.org/abs/2601.18428", "authors": ["Jiayi Zhou", "Liwenhan Xie", "Jiaju Ma", "Zheng Wei", "Huamin Qu", "Anyi Rao"], "title": "Collaposer: Transforming Photo Collections into Visual Assets for Storytelling with Collages", "categories": ["cs.HC"], "comment": "To be published at ACM CHI 2026 Conference on Human Factors in Computing Systems", "summary": "Digital collage is an artistic practice that combines image cutouts to tell stories. However, preparing cutouts from a set of photos remains a tedious and time-consuming task. A formative study identified three main challenges: 1) inefficient search for relevant photos, 2) manual image cutout, and 3) difficulty in organizing large sets of cutouts. To meet these challenges and facilitate asset preparation for collage, we propose Collaposer, a tool that transforms a collection of photos into organized, ready-to-use visual cutouts based on user-provided story descriptions. Collaposer tags, detects, and segments photos, and then uses an LLM to select central and related labels based on the user-provided story description. Collaposer presents the resulting visuals in varying sizes, clustered according to semantic hierarchy. Our evaluation shows that Collaposer effectively automates the preparation process to produce diverse sets of visual cutouts adhering to the storyline, allowing users to focus on collaging these assets for storytelling. Project website: https://jiayzhou.github.io/collaposer-website/", "AI": {"tldr": "本文提出了一种名为Collaposer的工具，通过用户提供的故事描述来自动准备数字拼贴画所需的视觉资产。", "motivation": "传统的数字拼贴画制作过程包括搜索相关照片、手动裁剪图像和组织大量的切图，这些步骤既耗时又繁琐。为了简化这个过程，提高用户体验，作者提出了Collaposer工具。", "method": "Collaposer通过标记、检测和分割输入的照片，并使用大语言模型根据用户提供的故事描述选择相关的标签来生成视觉资产。最终结果按照语义层次进行分类展示。", "result": "实验表明，Collaposer能够有效地准备多样化的视觉切图集，这些切图符合给定的故事线，使得用户可以专注于拼贴画的创作过程。", "conclusion": "Collaposer通过自动化准备工作流中的繁琐任务，显著提高了数字故事叙述的过程效率和用户体验。"}}
{"id": "2601.18424", "pdf": "https://arxiv.org/pdf/2601.18424", "abs": "https://arxiv.org/abs/2601.18424", "authors": ["Tianyi Gong", "Can Han", "Junxi Wu", "Dahong Qian"], "title": "Fusion of Spatio-Temporal and Multi-Scale Frequency Features for Dry Electrodes MI-EEG Decoding", "categories": ["cs.HC", "cs.LG"], "comment": null, "summary": "Dry-electrode Motor Imagery Electroencephalography (MI-EEG) enables fast, comfortable, real-world Brain Computer Interface by eliminating gels and shortening setup for at-home and wearable use.However, dry recordings pose three main issues: lower Signal-to-Noise Ratio with more baseline drift and sudden transients; weaker and noisier data with poor phase alignment across trials; and bigger variances between sessions. These drawbacks lead to larger data distribution shift, making features less stable for MI-EEG tasks.To address these problems, we introduce STGMFM, a tri-branch framework tailored for dry-electrode MI-EEG, which models complementary spatio-temporal dependencies via dual graph orders, and captures robust envelope dynamics with a multi-scale frequency mixing branch, motivated by the observation that amplitude envelopes are less sensitive to contact variability than instantaneous waveforms. Physiologically meaningful connectivity priors guide learning, and decision-level fusion consolidates a noise-tolerant consensus. On our collected dry-electrode MI-EEG, STGMFM consistently surpasses competitive CNN/Transformer/graph baselines. Codes are available at https://github.com/Tianyi-325/STGMFM.", "AI": {"tldr": "该论文提出了一种针对干电极运动想象脑电图的三分支框架STGMFM，通过建模互补的空间-时间依赖关系和捕获鲁棒的包络动态来解决干记录带来的问题。", "motivation": "干电极运动想象EEG在无凝胶、快速设置的情况下适用于家庭和可穿戴使用场景。然而，干记录带来了信噪比低、基线漂移、突发瞬变、数据弱且噪声大以及跨会话方差大的问题，导致特征稳定性下降。", "method": "该论文提出了STGMFM框架，包括三个分支：建模空间-时间依赖关系的双图模型和捕获鲁棒包络动态的多尺度频率混合分支。通过生理学意义的连接先验引导学习，并在决策层融合以形成噪声容忍共识。", "result": "实验结果显示，所提出的STGMFM框架在干电极运动想象EEG上优于竞争性的CNN、Transformer和图基线方法。", "conclusion": "该工作解决了干电极记录中的稳定性问题并提升了特征的鲁棒性。"}}
{"id": "2601.18420", "pdf": "https://arxiv.org/pdf/2601.18420", "abs": "https://arxiv.org/abs/2601.18420", "authors": ["Satya Prakash Dash", "Hossein Abdi", "Wei Pan", "Samuel Kaski", "Mingfei Sun"], "title": "Gradient Regularized Natural Gradients", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Gradient regularization (GR) has been shown to improve the generalizability of trained models. While Natural Gradient Descent has been shown to accelerate optimization in the initial phase of training, little attention has been paid to how the training dynamics of second-order optimizers can benefit from GR. In this work, we propose Gradient-Regularized Natural Gradients (GRNG), a family of scalable second-order optimizers that integrate explicit gradient regularization with natural gradient updates. Our framework provides two complementary algorithms: a frequentist variant that avoids explicit inversion of the Fisher Information Matrix (FIM) via structured approximations, and a Bayesian variant based on a Regularized-Kalman formulation that eliminates the need for FIM inversion entirely. We establish convergence guarantees for GRNG, showing that gradient regularization improves stability and enables convergence to global minima. Empirically, we demonstrate that GRNG consistently enhances both optimization speed and generalization compared to first-order methods (SGD, AdamW) and second-order baselines (K-FAC, Sophia), with strong results on vision and language benchmarks. Our findings highlight gradient regularization as a principled and practical tool to unlock the robustness of natural gradient methods for large-scale deep learning.", "AI": {"tldr": "提出了Gradient-Regularized Natural Gradients (GRNG)算法，该算法将梯度正则化与自然梯度更新相结合，用于改善大规模深度学习模型的优化速度和泛化能力。", "motivation": "为了提高第二阶优化器在训练过程中的动态性能，并利用梯度正则化的优点来增强自然梯度方法的鲁棒性。", "method": "提出了GRNG算法族，包括一种频繁主义变体和贝叶斯变体。频繁主义变种通过结构化近似避免了FIM的显式逆运算，而贝叶斯变种基于正则化的卡尔曼公式完全消除了对FIM逆运算的需求。", "result": "GRNG在优化速度和泛化能力方面优于一阶方法（如SGD、AdamW）以及二阶基线（如K-FAC、Sophia），并在视觉和语言基准测试中取得了显著成果。证明了梯度正则化可以提高稳定性并促进收敛至全局最小值。", "conclusion": "该研究展示了GRNG算法在优化速度和泛化性能上的优越性，并强调了梯度正则化作为解锁自然梯度方法鲁棒性的原则性和实用工具的重要性，特别是在大规模深度学习中。"}}
{"id": "2601.18419", "pdf": "https://arxiv.org/pdf/2601.18419", "abs": "https://arxiv.org/abs/2601.18419", "authors": ["Michael Kölle", "Christian Reff", "Leo Sünkel", "Julian Hager", "Gerhard Stenzel", "Claudia Linnhoff-Popien"], "title": "Emergent Cooperation in Quantum Multi-Agent Reinforcement Learning Using Communication", "categories": ["quant-ph", "cs.AI", "cs.LG", "cs.MA"], "comment": "Accepted at IEEE ICC 2026", "summary": "Emergent cooperation in classical Multi-Agent Reinforcement Learning has gained significant attention, particularly in the context of Sequential Social Dilemmas (SSDs). While classical reinforcement learning approaches have demonstrated capability for emergent cooperation, research on extending these methods to Quantum Multi-Agent Reinforcement Learning remains limited, particularly through communication. In this paper, we apply communication approaches to quantum Q-Learning agents: the Mutual Acknowledgment Token Exchange (MATE) protocol, its extension Mutually Endorsed Distributed Incentive Acknowledgment Token Exchange (MEDIATE), the peer rewarding mechanism Gifting, and Reinforced Inter-Agent Learning (RIAL). We evaluate these approaches in three SSDs: the Iterated Prisoner's Dilemma, Iterated Stag Hunt, and Iterated Game of Chicken. Our experimental results show that approaches using MATE with temporal-difference measure (MATE\\textsubscript{TD}), AutoMATE, MEDIATE-I, and MEDIATE-S achieved high cooperation levels across all dilemmas, demonstrating that communication is a viable mechanism for fostering emergent cooperation in Quantum Multi-Agent Reinforcement Learning.", "AI": {"tldr": "量子多智能体强化学习中通过通信实现合作的探索", "motivation": "经典多智能体强化学习在解决社会困境方面取得了显著成果，但将这些方法应用于量子多智能体环境中尚处于初级阶段。因此，研究如何利用通信机制促进量子环境下的合作显得尤为重要。", "method": "本文采用四种不同的通信协议：相互确认令牌交换（MATE）协议、其扩展版互认分布式激励承认令牌交换（MEDIATE）、同伴奖励机制赠予（Gifting）以及增强智能体间学习（RIAL）。在反复囚徒困境、反复鹿猎和反复斗鸡游戏中评估这些方法的效果。", "result": "实验结果显示，采用带有时间差度量的MATE协议、自动MATE协议、MEDIATE-I与MEDIATE-S的方法均表现出高水平的合作率。这表明通信是促进量子多智能体强化学习中合作的有效机制。", "conclusion": "研究表明在量子环境中通过特定设计的通信方法能够显著提升多智能体间的合作水平，为未来的研究提供了新的方向和可能性。"}}
{"id": "2601.18418", "pdf": "https://arxiv.org/pdf/2601.18418", "abs": "https://arxiv.org/abs/2601.18418", "authors": ["Ji Zeng", "Dayuan Fu", "Tiantian Mi", "Yumin Zhuang", "Yaxing Huang", "Xuefeng Li", "Lyumanshan Ye", "Muhang Xie", "Qishuo Hua", "Zhen Huang", "Mohan Jiang", "Hanning Wang", "Jifan Lin", "Yang Xiao", "Jie Sun", "Yunze Wu", "Pengfei Liu"], "title": "daVinci-Dev: Agent-native Mid-training for Software Engineering", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Recently, the frontier of Large Language Model (LLM) capabilities has shifted from single-turn code generation to agentic software engineering-a paradigm where models autonomously navigate, edit, and test complex repositories. While post-training methods have become the de facto approach for code agents, **agentic mid-training**-mid-training (MT) on large-scale data that mirrors authentic agentic workflows-remains critically underexplored due to substantial resource requirements, despite offering a more scalable path to instilling foundational agentic behaviors than relying solely on expensive reinforcement learning. A central challenge in realizing effective agentic mid-training is the distribution mismatch between static training data and the dynamic, feedback-rich environment of real development. To address this, we present a systematic study of agentic mid-training, establishing both the data synthesis principles and training methodology for effective agent development at scale. Central to our approach is **agent-native data**-supervision comprising two complementary types of trajectories: **contextually-native trajectories** that preserve the complete information flow an agent experiences, offering broad coverage and diversity; and **environmentally-native trajectories** collected from executable repositories where observations stem from actual tool invocations and test executions, providing depth and interaction authenticity. We verify the model's agentic capabilities on `SWE-Bench Verified`. We demonstrate our superiority over the previous open software engineering mid-training recipe `Kimi-Dev` under two post-training settings with an aligned base model and agentic scaffold, while using less than half mid-training tokens (73.1B). Besides relative advantage, our best performing 32B and 72B models achieve **56.1%** and **58.5%** resolution rates, respectively, which are ...", "AI": {"tldr": "本文提出了一个系统性的研究，通过在大规模数据上进行agentic mid-training来提升代码代理的自主开发能力。", "motivation": "现有方法主要依赖于昂贵的强化学习训练模型以实现自主软件工程能力，但这种方法不够经济高效。本文旨在探索一种更有效的路径：利用大规模真实场景中的动态、反馈丰富的环境来进行mid-training。", "method": "提出了一种名为agent-native的数据合成和培训方案，其中包括两类轨迹——上下文原生轨迹和环境原生轨迹，通过这种方案来解决静态训练数据与实际开发环境中存在的分布不匹配问题。", "result": "实验结果表明，使用本文的方法可以在SWE-Bench Verified上验证模型的自主能力，并且在相同基线模型下超过前人工作Kimi-Dev的表现。同时，32B和72B模型分别达到了56.1%和58.5%的问题解决率。", "conclusion": "通过创新的数据合成原则和训练方法，本文成功地解决了agentic mid-training中的分布不匹配问题，并且在实际应用中展现了超越现有方法的表现。"}}
{"id": "2601.18415", "pdf": "https://arxiv.org/pdf/2601.18415", "abs": "https://arxiv.org/abs/2601.18415", "authors": ["Ivan Bondarenko", "Daniil Grebenkin", "Oleg Sedukhin", "Mikhail Klementev", "Roman Derunets", "Lyudmila Budneva"], "title": "Pisets: A Robust Speech Recognition System for Lectures and Interviews", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "ef:Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 3: Industry Track), pp. 988-997", "summary": "This work presents a speech-to-text system \"Pisets\" for scientists and journalists which is based on a three-component architecture aimed at improving speech recognition accuracy while minimizing errors and hallucinations associated with the Whisper model. The architecture comprises primary recognition using Wav2Vec2, false positive filtering via the Audio Spectrogram Transformer (AST), and final speech recognition through Whisper. The implementation of curriculum learning methods and the utilization of diverse Russian-language speech corpora significantly enhanced the system's effectiveness. Additionally, advanced uncertainty modeling techniques were introduced, contributing to further improvements in transcription quality. The proposed approaches ensure robust transcribing of long audio data across various acoustic conditions compared to WhisperX and the usual Whisper model. The source code of \"Pisets\" system is publicly available at GitHub: https://github.com/bond005/pisets.", "AI": {"tldr": "本文介绍了针对科学家和记者的语音转文本系统Pisets，该系统通过三种组件架构改进了语音识别的准确性。", "motivation": "旨在提高Whisper模型在语音识别中的精度，并减少错误及幻觉现象，特别是在处理长音频数据时的表现。同时利用多样化的俄语语音语料库和先进的不确定性建模技术进一步提升转录质量。", "method": "采用了包括Wav2Vec2的主要识别、AST的误报过滤以及Whisper的最终语音识别在内的三组件架构，并实施了课程学习方法。", "result": "Pisets系统在不同的声学条件下，相较于WhisperX和标准的Whisper模型，在长音频数据转录方面表现更为稳健。", "conclusion": "通过改进的方法，Pisets系统显著提高了语音识别的质量。源代码已公开于GitHub供进一步研究使用。"}}
{"id": "2601.18414", "pdf": "https://arxiv.org/pdf/2601.18414", "abs": "https://arxiv.org/abs/2601.18414", "authors": ["Aura Loredana Dan"], "title": "Comparative Evaluation of Machine Learning Algorithms for Affective State Recognition from Children's Drawings", "categories": ["cs.CV"], "comment": "9 pages, 8 figures", "summary": "Autism spectrum disorder (ASD) represents a neurodevelopmental condition characterized by difficulties in expressing emotions and communication, particularly during early childhood. Understanding the affective state of children at an early age remains challenging, as conventional assessment methods are often intrusive, subjective, or difficult to apply consistently. This paper builds upon previous work on affective state recognition from children's drawings by presenting a comparative evaluation of machine learning models for emotion classification. Three deep learning architectures -- MobileNet, EfficientNet, and VGG16 -- are evaluated within a unified experimental framework to analyze classification performance, robustness, and computational efficiency. The models are trained using transfer learning on a dataset of children's drawings annotated with emotional labels provided by psychological experts. The results highlight important trade-offs between lightweight and deeper architectures when applied to drawing-based affective computing tasks, particularly in mobile and real-time application contexts.", "AI": {"tldr": "比较评估了用于从儿童绘画中识别情感状态的机器学习算法", "motivation": "理解早期儿童的情绪状态是一个挑战，常规评估方法往往具有侵入性或主观性。研究旨在通过深度学习模型来提高情绪分类的效果和效率", "method": "使用MobileNet, EfficientNet和VGG16三种深度学习架构进行转移学习，在经过心理专家标注情感标签的儿童绘画数据集上训练模型并比较其性能、鲁棒性和计算效率", "result": "结果突显了轻量级与深层架构之间的权衡，特别是在移动和实时应用上下文中", "conclusion": "研究证明了从儿童绘画中识别情绪状态的有效性，并指出了不同深度学习架构在实际应用中的优缺点"}}
{"id": "2601.18407", "pdf": "https://arxiv.org/pdf/2601.18407", "abs": "https://arxiv.org/abs/2601.18407", "authors": ["Jon Sporring", "David Stansby"], "title": "Larger than memory image processing", "categories": ["cs.CV"], "comment": "10 pages", "summary": "This report addresses larger-than-memory image analysis for petascale datasets such as 1.4 PB electron-microscopy volumes and 150 TB human-organ atlases. We argue that performance is fundamentally I/O-bound. We show that structuring analysis as streaming passes over data is crucial. For 3D volumes, two representations are popular: stacks of 2D slices (e.g., directories or multi-page TIFF) and 3D chunked layouts (e.g., Zarr/HDF5). While for a few algorithms, chunked layout on disk is crucial to keep disk I/O at a minimum, we show how the slice-based streaming architecture can be built on top of either image representation in a manner that minimizes disk I/O. This is in particular advantageous for algorithms relying on neighbouring values, since the slicing streaming architecture is 1D, which implies that there are only 2 possible sweeping orders, both of which are aligned with the order in which images are read from the disk. This is in contrast to 3D chunks, in which any sweep cannot be done without accessing each chunk at least 9 times. We formalize this with sweep-based execution (natural 2D/3D orders), windowed operations, and overlap-aware tiling to minimize redundant access. Building on these principles, we introduce a domain-specific language (DSL) that encodes algorithms with intrinsic knowledge of their optimal streaming and memory use; the DSL performs compile-time and run-time pipeline analyses to automatically select window sizes, fuse stages, tee and zip streams, and schedule passes for limited-RAM machines, yielding near-linear I/O scans and predictable memory footprints. The approach integrates with existing tooling for segmentation and morphology but reframes pre/post-processing as pipelines that privilege sequential read/write patterns, delivering substantial throughput gains for extremely large images without requiring full-volume residency in memory.", "AI": {"tldr": "本文提出了一种用于处理大型图像数据集的流式处理架构，通过最小化磁盘I/O来提高性能。", "motivation": "面对PB级别的电子显微镜体积和TB级的人体器官图谱等超大规模图像数据集，传统的内存存储方式难以胜任。为了提升这类大数据集的分析效率，作者认为关键在于优化输入/输出操作。", "method": "采用分层切片流式架构处理3D卷积数据，并提出了一种领域特定语言（DSL），该语言能够在编译时和运行时进行流水线分析，自动选择窗口大小、融合阶段、分支合并及调度有限内存机器上的通路，以实现近似线性的I/O扫描。", "result": "通过这种方法，在处理大规模图像数据集时，能够显著提高吞吐量而无需整个体积都存储在内存中。", "conclusion": "该方法不仅适用于现有的分割和形态学工具，还能重新定义预/后处理为优先考虑顺序读写模式的流水线，对于极大型图像提供了有效的解决方案。"}}
{"id": "2601.18405", "pdf": "https://arxiv.org/pdf/2601.18405", "abs": "https://arxiv.org/abs/2601.18405", "authors": ["Sara Solarova", "Matúš Mesarčík", "Branislav Pecher", "Ivan Srba"], "title": "Beyond the Checkbox: Strengthening DSA Compliance Through Social Media Algorithmic Auditing", "categories": ["cs.CY", "cs.HC", "cs.IR", "cs.SI"], "comment": "2026 CHI Conference on Human Factors in Computing Systems", "summary": "Algorithms of online platforms are required under the Digital Services Act (DSA) to comply with specific obligations concerning algorithmic transparency, user protection and privacy. To verify compliance with these requirements, DSA mandates platforms to undergo independent audits. Little is known about current auditing practices and their effectiveness in ensuring such compliance. To this end, we bridge regulatory and technical perspectives by critically examining selected audit reports across three critical algorithmic-related provisions: restrictions on profiling minors, transparency in recommender systems, and limitations on targeted advertising using sensitive data. Our analysis shows significant inconsistencies in methodologies and lack of technical depth when evaluating AI-powered systems. To enhance the depth, scale, and independence of compliance assessments, we propose to employ algorithmic auditing -- a process of behavioural assessment of AI algorithms by means of simulating user behaviour, observing algorithm responses and analysing them for audited phenomena.", "AI": {"tldr": "探讨如何通过算法审计来加强数字服务法案（DSA）合规性", "motivation": "现行的审计实践对于确保遵守特定义务的有效性知之甚少，提出一种更深入、更具独立性的评估方法以提高平台合规性", "method": "通过对选定审计报告进行审查，模拟用户行为并观察AI系统响应来执行算法审计", "result": "发现了现有审计在方法论和深度上的不足，并提出了改进策略", "conclusion": "通过实施更加细致和技术驱动的算法审计可以更有效地确保DSA合规"}}
{"id": "2601.18396", "pdf": "https://arxiv.org/pdf/2601.18396", "abs": "https://arxiv.org/abs/2601.18396", "authors": ["Zhengyang Li", "Thomas Graave", "Björn Möller", "Zehang Wu", "Matthias Franz", "Tim Fingscheidt"], "title": "Noise-Robust AV-ASR Using Visual Features Both in the Whisper Encoder and Decoder", "categories": ["eess.AS", "cs.CL", "cs.CV", "cs.SD"], "comment": "accepted at ICASSP2026", "summary": "In audiovisual automatic speech recognition (AV-ASR) systems, information fusion of visual features in a pre-trained ASR has been proven as a promising method to improve noise robustness. In this work, based on the prominent Whisper ASR, first, we propose a simple and effective visual fusion method -- use of visual features both in encoder and decoder (dual-use) -- to learn the audiovisual interactions in the encoder and to weigh modalities in the decoder. Second, we compare visual fusion methods in Whisper models of various sizes. Our proposed dual-use method shows consistent noise robustness improvement, e.g., a 35% relative improvement (WER: 4.41% vs. 6.83%) based on Whisper small, and a 57% relative improvement (WER: 4.07% vs. 9.53%) based on Whisper medium, compared to typical reference middle fusion in babble noise with a signal-to-noise ratio (SNR) of 0dB. Third, we conduct ablation studies examining the impact of various module designs and fusion options. Fine-tuned on 1929 hours of audiovisual data, our dual-use method using Whisper medium achieves 4.08% (MUSAN babble noise) and 4.43% (NoiseX babble noise) average WER across various SNRs, thereby establishing a new state-of-the-art in noisy conditions on the LRS3 AV-ASR benchmark. Our code is at https://github.com/ifnspaml/Dual-Use-AVASR", "AI": {"tldr": "本文提出了一种在编码器和解码器中同时使用视觉特征的方法，以提高音频识别系统中的噪声鲁棒性。", "motivation": "通过融合预训练的ASR模型中的视觉特征来增强AV-ASR系统的抗噪能力。", "method": "基于Whisper ASR模型，在编码器和解码器中同时引入视觉特征，进行模态间的交互学习和加权。并比较了不同大小的Whisper模型下的各种融合方法。", "result": "在0dB信噪比下，与传统的中间融合相比，基于Whisper small的方法提高了35%（WER从6.83％降至4.41％），而基于Whisper medium的方法提高了57%（WER从9.53％降至4.07％）。使用双用途方法的模型在MUSAN和NoiseX噪声下分别取得了4.08％和4.43％的平均词错误率。", "conclusion": "提出了一种新的音频视觉融合策略，显著提高了AV-ASR系统的抗噪性能，在LRS3基准测试中建立了新纪录。"}}
{"id": "2601.18393", "pdf": "https://arxiv.org/pdf/2601.18393", "abs": "https://arxiv.org/abs/2601.18393", "authors": ["Junli Chen", "Changli Tang", "Yixuan Li", "Guangzhi Sun", "Chao Zhang"], "title": "OCR-Enhanced Multimodal ASR Can Read While Listening", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "4 pages, 2 figures. Submitted to ICASSP 2026", "summary": "Visual information, such as subtitles in a movie, often helps automatic speech recognition. In this paper, we propose Donut-Whisper, an audio-visual ASR model with dual encoder to leverage visual information to improve speech recognition performance in both English and Chinese. Donut-Whisper combines the advantage of the linear and the Q-Former-based modality alignment structures via a cross-attention module, generating more powerful audio-visual features. Meanwhile, we propose a lightweight knowledge distillation scheme showcasing the potential of using audio-visual models to teach audio-only models to achieve better performance. Moreover, we propose a new multilingual audio-visual speech recognition dataset based on movie clips containing both Chinese and English partitions. As a result, Donut-Whisper achieved significantly better performance on both English and Chinese partition of the dataset compared to both Donut and Whisper large V3 baselines. In particular, an absolute 5.75% WER reduction and a 16.5% absolute CER reduction were achieved on the English and Chinese sets respectively compared to the Whisper ASR baseline.", "AI": {"tldr": "提出了一种结合视觉信息以提高英语和中文语音识别性能的音频-视觉ASR模型Donut-Whisper。", "motivation": "利用视听信息提升自动语音识别性能，特别是在存在字幕等视觉辅助的情况下。", "method": "提出了一个包含双编码器的音频-视觉ASR模型Donut-Whisper，并通过交叉注意模块结合线性和Q-Former基模态对齐结构的优势。还提出了一种轻量级知识蒸馏方案和一个多语言视听语音识别数据集，基于电影片段。", "result": "Donut-Whisper在多语言音频视觉言语识别数据集中实现了显著的性能提升，在英语和中文部分分别降低了5.75％ WER和16.5％绝对CER与基准线相比。", "conclusion": "通过结合视听信息，Donut-Whisper能够提高语音识别准确率，并展示了使用多模态模型训练单一模态模型以获得更好性能的潜力。"}}
{"id": "2601.18392", "pdf": "https://arxiv.org/pdf/2601.18392", "abs": "https://arxiv.org/abs/2601.18392", "authors": ["Moritz Rempe", "Lukas T. Rotkopf", "Marco Schlimbach", "Helmut Becker", "Fabian Hörst", "Johannes Haubold", "Philipp Dammann", "Kevin Kröninger", "Jens Kleesiek"], "title": "Efficient Complex-Valued Vision Transformers for MRI Classification Directly from k-Space", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning applications in Magnetic Resonance Imaging (MRI) predominantly operate on reconstructed magnitude images, a process that discards phase information and requires computationally expensive transforms. Standard neural network architectures rely on local operations (convolutions or grid-patches) that are ill-suited for the global, non-local nature of raw frequency-domain (k-Space) data. In this work, we propose a novel complex-valued Vision Transformer (kViT) designed to perform classification directly on k-Space data. To bridge the geometric disconnect between current architectures and MRI physics, we introduce a radial k-Space patching strategy that respects the spectral energy distribution of the frequency-domain. Extensive experiments on the fastMRI and in-house datasets demonstrate that our approach achieves classification performance competitive with state-of-the-art image-domain baselines (ResNet, EfficientNet, ViT). Crucially, kViT exhibits superior robustness to high acceleration factors and offers a paradigm shift in computational efficiency, reducing VRAM consumption during training by up to 68$\\times$ compared to standard methods. This establishes a pathway for resource-efficient, direct-from-scanner AI analysis.", "AI": {"tldr": "提出了一种新的复数Vision Transformer（kViT），用于直接在k-Space数据上进行MRI分类。", "motivation": "传统的神经网络架构依赖于局部操作，不适用于全局、非本地性质的原始频率域数据。该研究旨在通过处理包含相位信息的k-Space数据来提高计算效率和鲁棒性。", "method": "引入了复数Vision Transformer（kViT），并采用径向k-Space打补丁策略以尊重频谱能量分布，从而直接在原始频率域上进行MRI分类任务。", "result": "实验结果表明，所提方法的性能与基于图像领域的基线模型相当，并且对高加速因子表现出更强的鲁棒性。相较于标准方法，在训练过程中降低了68倍的VRAM消耗。", "conclusion": "该研究展示了一种直接从扫描器获取并分析数据的新途径，实现了资源高效的AI分析方法。"}}
{"id": "2601.18386", "pdf": "https://arxiv.org/pdf/2601.18386", "abs": "https://arxiv.org/abs/2601.18386", "authors": ["Gabriel Lee Jun Rong", "Christos Korgialas", "Dion Jia Xu Ho", "Pai Chet Ng", "Xiaoxiao Miao", "Konstantinos N. Plataniotis"], "title": "ARMOR: Agentic Reasoning for Methods Orchestration and Reparameterization for Robust Adversarial Attacks", "categories": ["cs.CV"], "comment": null, "summary": "Existing automated attack suites operate as static ensembles with fixed sequences, lacking strategic adaptation and semantic awareness. This paper introduces the Agentic Reasoning for Methods Orchestration and Reparameterization (ARMOR) framework to address these limitations. ARMOR orchestrates three canonical adversarial primitives, Carlini-Wagner (CW), Jacobian-based Saliency Map Attack (JSMA), and Spatially Transformed Attacks (STA) via Vision Language Models (VLM)-guided agents that collaboratively generate and synthesize perturbations through a shared ``Mixing Desk\". Large Language Models (LLMs) adaptively tune and reparameterize parallel attack agents in a real-time, closed-loop system that exploits image-specific semantic vulnerabilities. On standard benchmarks, ARMOR achieves improved cross-architecture transfer and reliably fools both settings, delivering a blended output for blind targets and selecting the best attack or blended attacks for white-box targets using a confidence-and-SSIM score.", "AI": {"tldr": "本文提出了ARMOR框架，该框架通过视觉语言模型指导的代理协同生成和合成扰动来优化对抗性攻击。", "motivation": "现有的自动化攻击套件序列固定，缺乏战略适应性和语义感知。为此，作者提出了一种具有适应性调整能力的新框架以解决这些问题。", "method": "ARMOR框架利用视觉语言模型(VLM)引导的代理协同生成和合成扰动，并通过一个共享‘Mixing Desk’进行优化。大型语言模型(LLL)在实时闭环系统中动态调优并重新配置平行攻击代理，以针对图像特定的语义漏洞。", "result": "ARMOR在标准基准测试上实现了改进的跨架构转移效果，并能够可靠地愚弄盲目标和白盒目标。", "conclusion": "本文展示了ARMOR框架的有效性，它不仅提高了对抗性攻击的成功率，还增强了对不同模型架构的适应能力。"}}
{"id": "2601.18385", "pdf": "https://arxiv.org/pdf/2601.18385", "abs": "https://arxiv.org/abs/2601.18385", "authors": ["Rinka Kawano", "Masaki Kawamura"], "title": "Estimation of geometric transformation matrices using grid-shaped pilot signals", "categories": ["cs.CV"], "comment": "ef:APSIPA Transactions on Signal and Information Processing (2025) 14 (1)", "summary": "Digital watermarking techniques are essential to prevent unauthorized use of images. Since pirated images are often geometrically distorted by operations such as scaling and cropping, accurate synchronization - detecting the embedding position of the watermark - is critical for proper extraction. In particular, cropping changes the origin of the image, making synchronization difficult. However, few existing methods are robust against cropping. To address this issue, we propose a watermarking method that estimates geometric transformations applied to a stego image using a pilot signal, allowing synchronization even after cropping. A grid-shaped pilot signal with distinct horizontal and vertical values is embedded in the image. When the image is transformed, the grid is also distorted. By analyzing this distortion, the transformation matrix can be estimated. Applying the Radon transform to the distorted image allows estimation of the grid angles and intervals. In addition, since the horizontal and vertical grid lines are encoded differently, the grid orientation can be determined, which reduces ambiguity. To validate our method, we performed simulations with anisotropic scaling, rotation, shearing, and cropping. The results show that the proposed method accurately estimates transformation matrices with low error under both single and composite attacks.", "AI": {"tldr": "本文提出了一种使用网格状引导信号估计几何变换矩阵的数字水印技术，以解决图像裁剪后的同步问题。", "motivation": "现有的数字水印方法在面对图像裁剪时难以实现准确同步。为了解决这一问题，文章提出了利用引导信号来估算几何变换，从而提高水印提取的准确性。", "method": "通过嵌入网格状的引导信号，并分析这些信号因几何变换而产生的扭曲变化，可以估计出原始图像所经历的变换矩阵。具体来说，应用Radon变换以获得变形后的网格角度和间隔信息；由于水平和垂直线被不同地编码，因此可以通过这种方式确定网格的方向，从而减少不确定性。", "result": "实验表明，在单一攻击（如非等比例缩放、旋转、剪切）或复合攻击下，该方法能够准确估计出变换矩阵且误差较低。", "conclusion": "研究提出的方法通过使用特定的引导信号能有效地应对图像裁剪带来的同步难题，并且在各种几何变换中均表现良好。"}}
{"id": "2601.18383", "pdf": "https://arxiv.org/pdf/2601.18383", "abs": "https://arxiv.org/abs/2601.18383", "authors": ["Zhenyuan Guo", "Tong Chen", "Wenlong Meng", "Chen Gong", "Xin Yu", "Chengkun Wei", "Wenzhi Chen"], "title": "Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.", "AI": {"tldr": "提出动态思考令牌选择方法以提高大规模推理模型的效率", "motivation": "解决大型推理模型在生成复杂问题解决方案时因扩展生成而导致的记忆占用和计算开销瓶颈", "method": "使用注意力图分析推理轨迹的影响，识别决策关键令牌，并仅保留其关联的关键值缓存状态，在推理过程中剔除冗余项以优化效率", "result": "通过这种方法，可以有效减少内存占用和计算资源消耗，提高模型的运行效率", "conclusion": "动态思考令牌选择方法在不牺牲准确性的情况下显著提高了大型推理模型的效率"}}
{"id": "2601.18381", "pdf": "https://arxiv.org/pdf/2601.18381", "abs": "https://arxiv.org/abs/2601.18381", "authors": ["Yinghan Hou", "Zongyou Yang"], "title": "AI Agent for Reverse-Engineering Legacy Finite-Difference Code and Translating to Devito", "categories": ["cs.AI", "cs.SE"], "comment": "14 pages, 7 figures", "summary": "To facilitate the transformation of legacy finite difference implementations into the Devito environment, this study develops an integrated AI agent framework. Retrieval-Augmented Generation (RAG) and open-source Large Language Models are combined through multi-stage iterative workflows in the system's hybrid LangGraph architecture. The agent constructs an extensive Devito knowledge graph through document parsing, structure-aware segmentation, extraction of entity relationships, and Leiden-based community detection. GraphRAG optimisation enhances query performance across semantic communities that include seismic wave simulation, computational fluid dynamics, and performance tuning libraries. A reverse engineering component derives three-level query strategies for RAG retrieval through static analysis of Fortran source code. To deliver precise contextual information for language model guidance, the multi-stage retrieval pipeline performs parallel searching, concept expansion, community-scale retrieval, and semantic similarity analysis. Code synthesis is governed by Pydantic-based constraints to guarantee structured outputs and reliability. A comprehensive validation framework integrates conventional static analysis with the G-Eval approach, covering execution correctness, structural soundness, mathematical consistency, and API compliance. The overall agent workflow is implemented on the LangGraph framework and adopts concurrent processing to support quality-based iterative refinement and state-aware dynamic routing. The principal contribution lies in the incorporation of feedback mechanisms motivated by reinforcement learning, enabling a transition from static code translation toward dynamic and adaptive analytical behavior.", "AI": {"tldr": "开发一个集成AI代理框架，用于将旧的有限差分实现转换到Devito环境中", "motivation": "为了使老旧的有限差分实现能够迁移到先进的计算平台如Devito上，并提高其性能和可维护性", "method": "结合RAG技术和开源大语言模型，通过多层次迭代工作流构建知识图谱并进行代码逆向工程与合成。使用Leiden社区检测技术优化查询效率，通过静态分析Fortran源码生成多级查询策略以增强检索准确性，采用Pydantic约束确保输出结构化且可靠", "result": "该框架集成了传统静态分析和G-Eval方法进行全面验证，包括执行正确性、结构性健全性、数学一致性及API遵从性。实现并行处理支持基于质量的迭代精炼和状态感知动态路由", "conclusion": "本文的主要贡献在于引入了强化学习驱动的反馈机制，使代码翻译工作能够从静态翻译转向具有自适应分析行为"}}
{"id": "2601.18372", "pdf": "https://arxiv.org/pdf/2601.18372", "abs": "https://arxiv.org/abs/2601.18372", "authors": ["Christos Petrou", "Harris Partaourides", "Athanasios Balomenos", "Yannis Kopsinis", "Sotirios Chatzis"], "title": "Gaze Prediction in Virtual Reality Without Eye Tracking Using Visual and Head Motion Cues", "categories": ["cs.CV"], "comment": null, "summary": "Gaze prediction plays a critical role in Virtual Reality (VR) applications by reducing sensor-induced latency and enabling computationally demanding techniques such as foveated rendering, which rely on anticipating user attention. However, direct eye tracking is often unavailable due to hardware limitations or privacy concerns. To address this, we present a novel gaze prediction framework that combines Head-Mounted Display (HMD) motion signals with visual saliency cues derived from video frames. Our method employs UniSal, a lightweight saliency encoder, to extract visual features, which are then fused with HMD motion data and processed through a time-series prediction module. We evaluate two lightweight architectures, TSMixer and LSTM, for forecasting future gaze directions. Experiments on the EHTask dataset, along with deployment on commercial VR hardware, show that our approach consistently outperforms baselines such as Center-of-HMD and Mean Gaze. These results demonstrate the effectiveness of predictive gaze modeling in reducing perceptual lag and enhancing natural interaction in VR environments where direct eye tracking is constrained.", "AI": {"tldr": "该论文提出了一个无需直接眼动追踪的虚拟现实场景中的凝视预测框架，结合头部运动信号和视觉显著性线索来预测用户的注意力。", "motivation": "在虚拟现实中，直接的眼动跟踪由于硬件限制或隐私问题可能不可用。通过减少传感器引起的延迟并提高计算密集型技术（如注视点渲染）的效率，该论文旨在解决这些问题。", "method": "提出的方法采用UniSal模型从视频帧中提取视觉显著性特征，并结合头部运动数据输入时间序列预测模块进行未来凝视方向的预测。测试了两种轻量级架构TSMixer和LSTM来实现这一目标。", "result": "实验表明，所提方法在EHTask数据集上的表现优于基线方法如中心头盔法和平均凝视法，并且在商业VR硬件上部署时效果显著。", "conclusion": "该论文证明了预测性凝视模型的有效性，在没有直接眼动追踪的情况下可以减少感知延迟并增强虚拟现实中的自然交互体验。"}}
{"id": "2601.18368", "pdf": "https://arxiv.org/pdf/2601.18368", "abs": "https://arxiv.org/abs/2601.18368", "authors": ["Caterina Fuster-Barceló", "Claudia Castrillón", "Laura Rodrigo-Muñoz", "Victor Manuel Vega-Suárez", "Nicolás Pérez-Fernández", "Gorka Bastarrika", "Arrate Muñoz-Barrutia"], "title": "OREHAS: A fully automated deep-learning pipeline for volumetric endolymphatic hydrops quantification in MRI", "categories": ["cs.CV"], "comment": null, "summary": "We present OREHAS (Optimized Recognition & Evaluation of volumetric Hydrops in the Auditory System), the first fully automatic pipeline for volumetric quantification of endolymphatic hydrops (EH) from routine 3D-SPACE-MRC and 3D-REAL-IR MRI. The system integrates three components -- slice classification, inner ear localization, and sequence-specific segmentation -- into a single workflow that computes per-ear endolymphatic-to-vestibular volume ratios (ELR) directly from whole MRI volumes, eliminating the need for manual intervention. Trained with only 3 to 6 annotated slices per patient, OREHAS generalized effectively to full 3D volumes, achieving Dice scores of 0.90 for SPACE-MRC and 0.75 for REAL-IR. In an external validation cohort with complete manual annotations, OREHAS closely matched expert ground truth (VSI = 74.3%) and substantially outperformed the clinical syngo.via software (VSI = 42.5%), which tended to overestimate endolymphatic volumes. Across 19 test patients, vestibular measurements from OREHAS were consistent with syngo.via, while endolymphatic volumes were systematically smaller and more physiologically realistic. These results show that reliable and reproducible EH quantification can be achieved from standard MRI using limited supervision. By combining efficient deep-learning-based segmentation with a clinically aligned volumetric workflow, OREHAS reduces operator dependence, ensures methodological consistency. Besides, the results are compatible with established imaging protocols. The approach provides a robust foundation for large-scale studies and for recalibrating clinical diagnostic thresholds based on accurate volumetric measurements of the inner ear.", "AI": {"tldr": "提出OREHAS系统，实现内耳积水的自动量化。", "motivation": "通过自动化流程提高MRI图像中内耳积水量化的准确性与可重复性。", "method": "集成切片分类、内耳定位和序列特定分割三个模块，形成完整工作流。", "result": "在外部验证队列中，OREHAS表现优于临床软件，在Dice评分和一致性方面均表现出色。", "conclusion": "通过深度学习与临床成像协议结合，OREHAS为大规模研究提供了可靠基础。"}}
{"id": "2601.18353", "pdf": "https://arxiv.org/pdf/2601.18353", "abs": "https://arxiv.org/abs/2601.18353", "authors": ["Tuhin Chakrabarty", "Paramveer S. Dhillon"], "title": "Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books", "categories": ["cs.AI", "cs.CL", "cs.HC"], "comment": "Proceedings of CHI 2026 Conference (To Appear)", "summary": "Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes \"good writing.\" These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor.", "AI": {"tldr": "研究探讨了通过在高质量书籍上微调生成式AI模型后，专家级作家与AI在模仿知名作者风格上的表现对比。", "motivation": "挑战长期以来认为创造性写作是人类独有的观念，并探索是否机器可以通过微调来复制作者的写作风格和创造力。", "method": "28位MFA作家（专家）与三个LLM进行比赛，模仿50位获得好评的作者。通过盲审方式由28名专家评委和131名普通评委进行评分比较。", "result": "在上下文提示条件下，专家偏好人类写作的比例为82.7%，而在微调后AI作品时这一比例降至62%；相比之下，普通评委始终更青睐于AI的创作。", "conclusion": "研究结果挑战了关于AI创造力局限性的讨论，并提出了有关未来创意劳动本质的基本问题。"}}
{"id": "2601.18352", "pdf": "https://arxiv.org/pdf/2601.18352", "abs": "https://arxiv.org/abs/2601.18352", "authors": ["Manjie Xu", "Isabella Yin", "Xinyi Tu", "Chi Zhang", "Yixin Zhu"], "title": "Code over Words: Overcoming Semantic Inertia via Code-Grounded Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "LLMs struggle with Semantic Inertia: the inability to inhibit pre-trained priors (e.g., \"Lava is Dangerous\") when dynamic, in-context rules contradict them. We probe this phenomenon using Baba Is You, where physical laws are mutable text rules, enabling precise evaluation of models' ability to override learned priors when rules change. We quantatively observe that larger models can exhibit inverse scaling: they perform worse than smaller models when natural language reasoning requires suppressing pre-trained associations (e.g., accepting \"Lava is Safe\"). Our analysis attributes this to natural language encoding, which entangles descriptive semantics and logical rules, leading to persistent hallucinations of familiar physics despite explicit contradictory rules. Here we show that representing dynamics as executable code, rather than descriptive text, reverses this trend and enables effective prior inhibition. We introduce Code-Grounded Vistas (LCV), which fine-tunes models on counterfactual pairs and identifies states with contradictory rules, thereby forcing attention to logical constraints rather than visual semantics. This training-time approach outperforms expensive inference-time search methods in both efficiency and accuracy. Our results demonstrate that representation fundamentally determines whether scaling improves or impairs contextual reasoning. This challenges the assumption that larger models are universally better, with implications for domains that require dynamic overriding of learned priors.", "AI": {"tldr": "研究提出Code-Grounded Vistas (LCV) 方法，通过将动态规则表示为可执行代码而非描述性文本，克服了大模型在抑制预训练先验方面的挑战。", "motivation": "LLMs存在语义惯性问题，即难以在动态上下文规则与已学习的先验知识相冲突时进行有效推理。更大模型反而表现出更差的表现，原因是自然语言编码纠缠描述性语义和逻辑规则。", "method": "提出Code-Grounded Vistas (LCV) 方法，该方法通过反事实对训练模型，并识别具有矛盾规则的状态来迫使注意力集中在逻辑约束而非视觉语义上。", "result": "实验证明了这种方法在效率和准确性方面优于复杂的推理时间搜索方法，同时展示了表示形式决定了上下文推理能力的提升或降低。", "conclusion": "研究表明，通过将动态规则表示为可执行代码而不是描述性文本，可以有效抑制预训练先验。这挑战了更大模型总是更好的假设，并对需要动态覆盖学习先验的知识领域具有重要意义。"}}
{"id": "2601.18350", "pdf": "https://arxiv.org/pdf/2601.18350", "abs": "https://arxiv.org/abs/2601.18350", "authors": ["Junyi Zou"], "title": "When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) show strong general capability but often struggle with medical terminology precision and safety-critical instruction following. We present a case study for adapter interference in safety-critical domains using a 14B-parameter base model through a two-stage LoRA pipeline: (1) domain-adaptive pre-training (PT) to inject broad medical knowledge via continued pre-training (DAPT), and (2) supervised fine-tuning (SFT) to align the model with medical question-answering behaviors through instruction-style data. To balance instruction-following ability and domain knowledge retention, we propose Weighted Adapter Merging, linearly combining SFT and PT adapters before exporting a merged base-model checkpoint. On a held-out medical validation set (F5/F6), the merged model achieves BLEU-4 = 16.38, ROUGE-1 = 20.42, ROUGE-2 = 4.60, and ROUGE-L = 11.54 under a practical decoding configuration. We further analyze decoding sensitivity and training stability with loss curves and controlled decoding comparisons.", "AI": {"tldr": "研究在大型语言模型中通过适配器合并技术解决领域预训练与指令对齐冲突的问题，以提高医学领域的精准性和安全性。", "motivation": "大型语言模型虽然表现出强大的通用能力，但在处理医学术语和安全关键性指令时存在不足。因此需要改进方法来增强模型在特定领域的精确度和安全性。", "method": "提出一个两阶段的LoRA流程：首先通过领域适应预训练(DAPT)注入广泛的知识；然后进行监督微调(SFT)，使模型与医学问题回答行为对齐。最后引入加权适配器合并技术，线性组合SFT和PT适配器，生成一个合并后的基准模型检查点。", "result": "在独立的医学验证集上评估，合并后模型达到BLEU-4=16.38, ROUGE-1=20.42, ROUGE-2=4.60以及ROUGE-L=11.54。进一步分析解码敏感性和训练稳定性。", "conclusion": "通过适配器合并技术能够有效提高大型语言模型在医学领域中的表现，并且对于解码策略和损失曲线的分析表明该方法具备一定的稳定性和实用性。"}}
{"id": "2601.18346", "pdf": "https://arxiv.org/pdf/2601.18346", "abs": "https://arxiv.org/abs/2601.18346", "authors": ["Sijing Wu", "Yunhao Li", "Zicheng Zhang", "Qi Jia", "Xinyue Li", "Huiyu Duan", "Xiongkuo Min", "Guangtao Zhai"], "title": "Q-Bench-Portrait: Benchmarking Multimodal Large Language Models on Portrait Image Quality Perception", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in multimodal large language models (MLLMs) have demonstrated impressive performance on existing low-level vision benchmarks, which primarily focus on generic images. However, their capabilities to perceive and assess portrait images, a domain characterized by distinct structural and perceptual properties, remain largely underexplored. To this end, we introduce Q-Bench-Portrait, the first holistic benchmark specifically designed for portrait image quality perception, comprising 2,765 image-question-answer triplets and featuring (1) diverse portrait image sources, including natural, synthetic distortion, AI-generated, artistic, and computer graphics images; (2) comprehensive quality dimensions, covering technical distortions, AIGC-specific distortions, and aesthetics; and (3) a range of question formats, including single-choice, multiple-choice, true/false, and open-ended questions, at both global and local levels. Based on Q-Bench-Portrait, we evaluate 20 open-source and 5 closed-source MLLMs, revealing that although current models demonstrate some competence in portrait image perception, their performance remains limited and imprecise, with a clear gap relative to human judgments. We hope that the proposed benchmark will foster further research into enhancing the portrait image perception capabilities of both general-purpose and domain-specific MLLMs.", "AI": {"tldr": "提出了Q-Bench-Portrait基准，用于评估多模态大语言模型在肖像图像质量感知方面的能力。", "motivation": "现有低级视觉基准主要针对普通图像，对于具有独特结构和感知属性的肖像图像领域，多模态大型语言模型（MLLM）的表现力未被充分探索。", "method": "创建了包含2765张图片-问题-答案三元组的数据集Q-Bench-Portrait，涵盖不同类型的肖像图像、全面的质量维度以及各种类型的问题。基于此基准评估了20个开源和5个闭源MLLM。", "result": "结果显示当前模型在某些方面表现出对肖像图像感知能力的一定水准，但整体表现仍然有限且不精确，与人类判断之间存在明显差距。", "conclusion": "希望通过提出的Q-Bench-Portrait基准促进研究进一步提升通用和特定领域的MLLM对于肖像图像感知的能力。"}}
{"id": "2601.18340", "pdf": "https://arxiv.org/pdf/2601.18340", "abs": "https://arxiv.org/abs/2601.18340", "authors": ["Bingzheng Qu", "Kehai Chen", "Xuefeng Bai", "Jun Yu", "Min Zhang"], "title": "Beyond Rigid: Benchmarking Non-Rigid Video Editing", "categories": ["cs.CV"], "comment": null, "summary": "Despite the remarkable progress in text-driven video editing, generating coherent non-rigid deformations remains a critical challenge, often plagued by physical distortion and temporal flicker. To bridge this gap, we propose NRVBench, the first dedicated and comprehensive benchmark designed to evaluate non-rigid video editing. First, we curate a high-quality dataset consisting of 180 non-rigid motion videos from six physics-based categories, equipped with 2,340 fine-grained task instructions and 360 multiple-choice questions. Second, we propose NRVE-Acc, a novel evaluation metric based on Vision-Language Models that can rigorously assess physical compliance, temporal consistency, and instruction alignment, overcoming the limitations of general metrics in capturing complex dynamics. Third, we introduce a training-free baseline, VM-Edit, which utilizes a dual-region denoising mechanism to achieve structure-aware control, balancing structural preservation and dynamic deformation. Extensive experiments demonstrate that while current methods have shortcomings in maintaining physical plausibility, our method achieves excellent performance across both standard and proposed metrics. We believe the benchmark could serve as a standard testing platform for advancing physics-aware video editing.", "AI": {"tldr": "提出了一种评估非刚性视频编辑的新基准和方法，包括数据集、评价指标和训练免费的基线。", "motivation": "解决现有文本驱动视频编辑中生成非刚性变形时出现的物理扭曲和时间闪烁问题。", "method": "构建高质量的数据集；提出基于视觉语言模型的评估标准NRVE-Acc；介绍无需训练的VM-Edit基线方法，利用双区域降噪机制实现结构感知控制。", "result": "实验表明当前方法在保持物理合理性方面存在不足，而该研究的方法在标准和新提出的指标上表现出色。", "conclusion": "新基准为推进具有物理学意识的视频编辑提供了一个标准化测试平台。"}}
{"id": "2601.18339", "pdf": "https://arxiv.org/pdf/2601.18339", "abs": "https://arxiv.org/abs/2601.18339", "authors": ["Reemt Hinrichs", "Sonja Stephan", "Alexander Lange", "Jörn Ostermann"], "title": "A Dataset for Automatic Vocal Mode Classification", "categories": ["cs.SD", "cs.LG"], "comment": "Part of the proceedings of the EvoMUSART 2026: 15th International Conference on Artificial Intelligence in Music, Sound, Art and Design", "summary": "The Complete Vocal Technique (CVT) is a school of singing developed in the past decades by Cathrin Sadolin et al.. CVT groups the use of the voice into so called vocal modes, namely Neutral, Curbing, Overdrive and Edge. Knowledge of the desired vocal mode can be helpful for singing students. Automatic classification of vocal modes can thus be important for technology-assisted singing teaching. Previously, automatic classification of vocal modes has been attempted without major success, potentially due to a lack of data. Therefore, we recorded a novel vocal mode dataset consisting of sustained vowels recorded from four singers, three of which professional singers with more than five years of CVT-experience. The dataset covers the entire vocal range of the subjects, totaling 3,752 unique samples. By using four microphones, thereby offering a natural data augmentation, the dataset consists of more than 13,000 samples combined. An annotation was created using three CVT-experienced annotators, each providing an individual annotation. The merged annotation as well as the three individual annotations come with the published dataset. Additionally, we provide some baseline classification results. The best balanced accuracy across a 5-fold cross validation of 81.3\\,\\% was achieved with a ResNet18. The dataset can be downloaded under https://zenodo.org/records/14276415.", "AI": {"tldr": "构建了一套用于自动分类CVT声乐模式的数据集，并提供了初步的分类结果。", "motivation": "为了解决过去在自动分类CVT声乐模式方面的不成功问题，尤其是由于缺乏数据的问题，创建了一个新的高质量数据集来支持技术辅助的教学。", "method": "通过四个专业歌手录制了涵盖整个音域的声音样本，并使用四种不同的麦克风进行录音以提供自然的数据增强。利用三个有经验的注解员对声音样本进行了标注，并提供了基线分类结果。", "result": "在5折交叉验证中，ResNet18模型实现了最佳平衡精度为81.3%。", "conclusion": "数据集对于自动声乐模式分类任务非常有用，可以进一步改进并用于改善技术辅助的教学。"}}
{"id": "2601.18336", "pdf": "https://arxiv.org/pdf/2601.18336", "abs": "https://arxiv.org/abs/2601.18336", "authors": ["Isaac Deutsch", "Nicolas Moënne-Loccoz", "Gavriel State", "Zan Gojcic"], "title": "PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction", "categories": ["cs.CV", "cs.GR"], "comment": "For more details and updates, please visit our project website: https://research.nvidia.com/labs/sil/projects/ppisp/", "summary": "Multi-view 3D reconstruction methods remain highly sensitive to photometric inconsistencies arising from camera optical characteristics and variations in image signal processing (ISP). Existing mitigation strategies such as per-frame latent variables or affine color corrections lack physical grounding and generalize poorly to novel views. We propose the Physically-Plausible ISP (PPISP) correction module, which disentangles camera-intrinsic and capture-dependent effects through physically based and interpretable transformations. A dedicated PPISP controller, trained on the input views, predicts ISP parameters for novel viewpoints, analogous to auto exposure and auto white balance in real cameras. This design enables realistic and fair evaluation on novel views without access to ground-truth images. PPISP achieves SoTA performance on standard benchmarks, while providing intuitive control and supporting the integration of metadata when available. The source code is available at: https://github.com/nv-tlabs/ppisp", "AI": {"tldr": "提出了PPISP模块，用于通过物理基础的转换来分离相机固有的和捕捉相关的光度变化，并训练一个控制器预测新的视点下的ISP参数。", "motivation": "多视角3D重建方法对光度不一致性敏感。现有策略如每帧潜变量或仿射颜色校正缺乏物理依据，难以泛化到新视图。", "method": "通过基于物理的解耦转换分离相机特性和捕捉影响，并训练PPISP控制器预测新的视点下的ISP参数。", "result": "PPISP在标准基准测试中达到最先进水平，提供直观控制并支持元数据集成。", "conclusion": "提出的PPISP模块提高了多视角3D重建的光度一致性，实现了更准确和可泛化的结果。"}}
{"id": "2601.18335", "pdf": "https://arxiv.org/pdf/2601.18335", "abs": "https://arxiv.org/abs/2601.18335", "authors": ["Zexia Fan", "Yu Chen", "Qiquan Zhang", "Kainan Chen", "Xinyuan Qian"], "title": "Analytic Incremental Learning For Sound Source Localization With Imbalance Rectification", "categories": ["cs.SD", "cs.AI"], "comment": "Accepted by ICASSP26", "summary": "Sound source localization (SSL) demonstrates remarkable results in controlled settings but struggles in real-world deployment due to dual imbalance challenges: intra-task imbalance arising from long-tailed direction-of-arrival (DoA) distributions, and inter-task imbalance induced by cross-task skews and overlaps. These often lead to catastrophic forgetting, significantly degrading the localization accuracy. To mitigate these issues, we propose a unified framework with two key innovations. Specifically, we design a GCC-PHAT-based data augmentation (GDA) method that leverages peak characteristics to alleviate intra-task distribution skews. We also propose an Analytic dynamic imbalance rectifier (ADIR) with task-adaption regularization, which enables analytic updates that adapt to inter-task dynamics. On the SSLR benchmark, our proposal achieves state-of-the-art (SoTA) results of 89.0% accuracy, 5.3° mean absolute error, and 1.6 backward transfer, demonstrating robustness to evolving imbalances without exemplar storage.", "AI": {"tldr": "该论文提出了一种解决声音源定位中双重不平衡挑战的统一框架。", "motivation": "声音源定位在实际部署时因长尾分布和任务间偏斜导致表现不佳，需要新的方法来克服这些问题。", "method": "设计了基于GCC-PHAT的数据增强方法以缓解内部分布失衡，并提出了一种具有任务适应正则化的分析不平衡校正器，实现了自适应更新。", "result": "在SSLR基准测试上，该方法达到89.0％的准确率、5.3°的平均绝对误差和1.6的反向迁移能力。", "conclusion": "所提出的方法表现出强大的鲁棒性，能够应对不断变化的不平衡情况。"}}
{"id": "2601.18330", "pdf": "https://arxiv.org/pdf/2601.18330", "abs": "https://arxiv.org/abs/2601.18330", "authors": ["Muhammad Ali Shah", "Muhammad Mansoor Alam", "Saddam Hussain Khan"], "title": "A Tumor Aware DenseNet Swin Hybrid Learning with Boosted and Hierarchical Feature Spaces for Large-Scale Brain MRI Classification", "categories": ["cs.CV", "cs.LG"], "comment": "33 Pages, 8 Tables, Figures 16", "summary": "This study proposes an efficient Densely Swin Hybrid (EDSH) framework for brain tumor MRI analysis, designed to jointly capture fine grained texture patterns and long range contextual dependencies. Two tumor aware experimental setups are introduced to address class-specific diagnostic challenges. The first setup employs a Boosted Feature Space (BFS), where independently customized DenseNet and Swint branches learn complementary local and global representations that are dimension aligned, fused, and boosted, enabling highly sensitive detection of diffuse glioma patterns by successfully learning the features of irregular shape, poorly defined mass, and heterogeneous texture. The second setup adopts a hierarchical DenseNet Swint architecture with Deep Feature Extraction have Dual Residual connections (DFE and DR), in which DenseNet serves as a stem CNN for structured local feature learning, while Swin_t models global tumor morphology, effectively suppressing false negatives in meningioma and pituitary tumor classification by learning the features of well defined mass, location (outside brain) and enlargments in tumors (dural tail or upward extension). DenseNet is customized at the input level to match MRI spatial characteristics, leveraging dense residual connectivity to preserve texture information and mitigate vanishing-gradient effects. In parallel, Swint is tailored through task aligned patch embedding and shifted-window self attention to efficiently capture hierarchical global dependencies. Extensive evaluation on a large-scale MRI dataset (stringent 40,260 images across four tumor classes) demonstrates consistent superiority over standalone CNNs, Vision Transformers, and hybrids, achieving 98.50 accuracy and recall on the test unseen dataset.", "AI": {"tldr": "提出了一种高效的Densely Swin Hybrid框架，用于脑肿瘤MRI分析。", "motivation": "旨在解决特定类型的诊断挑战，通过引入两个基于肿瘤的实验设置来分别处理弥漫性胶质瘤和良性肿瘤的特征学习问题。", "method": "采用了Boosted Feature Space（BFS）和分层DenseNet Swint架构。BFS通过定制化的分支捕捉互补的局部和全局表示；分层架构则使用了改进后的DenseNet进行局部特性提取，Swin_t模型用于全球肿瘤形态学分析。", "result": "实验结果表明，在大规模MRI数据集上（包含40,260张图像）达到了98.5%的准确率和召回率。", "conclusion": "所提出的框架在脑肿瘤分类任务中展现了优越性能，超过了单独使用CNNs、Vision Transformers和其他混合模型。"}}
{"id": "2601.18328", "pdf": "https://arxiv.org/pdf/2601.18328", "abs": "https://arxiv.org/abs/2601.18328", "authors": ["Shaozhang Dai", "Kadek Ananta Satriadi", "Jim Smiley", "Barrett Ens", "Lonni Besançon", "Tim Dwyer"], "title": "MarioChart: Autonomous Tangibles as Active Proxy Interfaces for Embodied Casual Data Exploration", "categories": ["cs.HC"], "comment": null, "summary": "We introduce the notion of an Active Proxy interface, i.e. tangible models as proxies for physical data referents, supporting interactive exploration of data through active manipulation. We realise an active proxy data visualisation system, \"MarioChart\", using robot carts relocating themselves on a tabletop, e.g., to align with their data referents in a map or other visual layout. We consider a casual-data exploration scenario involving a multivariate campus sustainability dataset, using scale models as proxies for their physical building data referents. Our empirical study (n=12) compares active proxy use with conventional tablet interaction, finding that our active proxy system enhances short-term spatial memory of data and enables faster completion of certain data analytic tasks. It shows no significant differences compared to traditional touch-screens in long-term memory, physical fatigue, mental workload, or user engagement. Our study offers an initial baseline for active proxy techniques and advances understanding of tangible interfaces in situated data visualisation.", "AI": {"tldr": "介绍了一种使用机器人小车作为物理数据代理的主动实体界面系统，用于校园可持续性数据集的互动探索。", "motivation": "通过将实体模型作为物理数据参考物的代理来支持交互式的数据探索，并通过实验研究探讨这种新的交互方式的优点和局限性。", "method": "设计并实现了一个名为MarioChart的主动实体界面系统，该系统使用机器人小车在桌面上移动以对齐它们的数据参照对象。进行了对比测试，将该方法与传统触屏互动进行比较。", "result": "实验表明，主动代理系统可以增强短期空间数据记忆，并且能够更快地完成某些数据分析任务，但在长期记忆、身体疲劳和心理工作量方面没有显著差异。", "conclusion": "这项研究为了解主动实体界面技术提供了一个基线，并扩展了我们对实体接口在情境化数据可视化中的理解。"}}
{"id": "2601.18323", "pdf": "https://arxiv.org/pdf/2601.18323", "abs": "https://arxiv.org/abs/2601.18323", "authors": ["Weishi Mi", "Yong Bao", "Xiaowei Chi", "Xiaozhu Ju", "Zhiyuan Qin", "Kuangzhi Ge", "Kai Tang", "Peidong Jia", "Shanghang Zhang", "Jian Tang"], "title": "TC-IDM: Grounding Video Generation for Executable Zero-shot Robot Motion", "categories": ["cs.RO"], "comment": null, "summary": "The vision-language-action (VLA) paradigm has enabled powerful robotic control by leveraging vision-language models, but its reliance on large-scale, high-quality robot data limits its generalization. Generative world models offer a promising alternative for general-purpose embodied AI, yet a critical gap remains between their pixel-level plans and physically executable actions. To this end, we propose the Tool-Centric Inverse Dynamics Model (TC-IDM). By focusing on the tool's imagined trajectory as synthesized by the world model, TC-IDM establishes a robust intermediate representation that bridges the gap between visual planning and physical control. TC-IDM extracts the tool's point cloud trajectories via segmentation and 3D motion estimation from generated videos. Considering diverse tool attributes, our architecture employs decoupled action heads to project these planned trajectories into 6-DoF end-effector motions and corresponding control signals. This plan-and-translate paradigm not only supports a wide range of end-effectors but also significantly improves viewpoint invariance. Furthermore, it exhibits strong generalization capabilities across long-horizon and out-of-distribution tasks, including interacting with deformable objects. In real-world evaluations, the world model with TC-IDM achieves an average success rate of 61.11 percent, with 77.7 percent on simple tasks and 38.46 percent on zero-shot deformable object tasks. It substantially outperforms end-to-end VLA-style baselines and other inverse dynamics models.", "AI": {"tldr": "TC-IDM模型通过生成视频中的工具轨迹，转化为机器人物理控制的动作信号。", "motivation": "现有视觉-语言-动作范式依赖大规模高质量数据限制了泛化能力。为此引入中间表示将视觉规划与物理控制联系起来。", "method": "提出Tool-Centric Inverse Dynamics Model（TC-IDM），通过分割和3D运动估计生成视频中的工具点云轨迹，并转化为6自由度末端执行器动作及控制信号。", "result": "实验显示模型在简单任务成功率77.7%，零样本可变形物体交互任务中为38.46%。", "conclusion": "TC-IDM显著提高了机器人动作规划与物理执行之间的转换能力，展示了强大的泛化性能。"}}
{"id": "2601.18322", "pdf": "https://arxiv.org/pdf/2601.18322", "abs": "https://arxiv.org/abs/2601.18322", "authors": ["Thomas Deppisch", "Yang Gao", "Manan Mittal", "Benjamin Stahl", "Christoph Hold", "David Alon", "Zamir Ben-Hur"], "title": "Residual Learning for Neural Ambisonics Encoders", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "Emerging wearable devices such as smartglasses and extended reality headsets demand high-quality spatial audio capture from compact, head-worn microphone arrays. Ambisonics provides a device-agnostic spatial audio representation by mapping array signals to spherical harmonic (SH) coefficients. In practice, however, accurate encoding remains challenging. While traditional linear encoders are signal-independent and robust, they amplify low-frequency noise and suffer from high-frequency spatial aliasing. On the other hand, neural network approaches can outperform linear encoders but they often assume idealized microphones and may perform inconsistently in real-world scenarios. To leverage their complementary strengths, we introduce a residual-learning framework that refines a linear encoder with corrections from a neural network. Using measured array transfer functions from smartglasses, we compare a UNet-based encoder from the literature with a new recurrent attention model. Our analysis reveals that both neural encoders only consistently outperform the linear baseline when integrated within the residual learning framework. In the residual configuration, both neural models achieve consistent and significant improvements across all tested metrics for in-domain data and moderate gains for out-of-domain data. Yet, coherence analysis indicates that all neural encoder configurations continue to struggle with directionally accurate high-frequency encoding.", "AI": {"tldr": "本文提出了一个残差学习框架，以改进线性编码器，并引入了新的递归注意力模型来提高空间音频捕获的质量。", "motivation": "现有的线性编码器在处理低频噪声和高频空间混叠方面存在不足；而基于神经网络的方法虽然性能优越但假设理想化的麦克风且难以稳定表现。因此，本文旨在结合二者的优点。", "method": "该框架将线性编码器与神经网络的修正相结合。通过使用从智能眼镜测量到的阵列传输函数，比较了UNet基编码器和新递归注意力模型的表现。", "result": "在残差学习框架中，两种神经编码器均表现出显著改善，并且在域内数据上取得了一致性提升；但在高频方向准确性方面仍然存在问题。", "conclusion": "结合线性和神经网络方法可以有效提高空间音频捕获质量，但仍需进一步改进以解决高频方向准确性的挑战。"}}
{"id": "2601.18321", "pdf": "https://arxiv.org/pdf/2601.18321", "abs": "https://arxiv.org/abs/2601.18321", "authors": ["Zhixian Zhao", "Wenjie Tian", "Xiaohai Tian", "Jun Zhang", "Lei Xie"], "title": "Integrating Fine-Grained Audio-Visual Evidence for Robust Multimodal Emotion Reasoning", "categories": ["cs.MM", "cs.CL", "cs.CV"], "comment": null, "summary": "Multimodal emotion analysis is shifting from static classification to generative reasoning. Beyond simple label prediction, robust affective reasoning must synthesize fine-grained signals such as facial micro-expressions and prosodic which shifts to decode the latent causality within complex social contexts. However, current Multimodal Large Language Models (MLLMs) face significant limitations in fine-grained perception, primarily due to data scarcity and insufficient cross-modal fusion. As a result, these models often exhibit unimodal dominance which leads to hallucinations in complex multimodal interactions, particularly when visual and acoustic cues are subtle, ambiguous, or even contradictory (e.g., in sarcastic scenery). To address this, we introduce SABER-LLM, a framework designed for robust multimodal reasoning. First, we construct SABER, a large-scale emotion reasoning dataset comprising 600K video clips, annotated with a novel six-dimensional schema that jointly captures audiovisual cues and causal logic. Second, we propose the structured evidence decomposition paradigm, which enforces a \"perceive-then-reason\" separation between evidence extraction and reasoning to alleviate unimodal dominance. The ability to perceive complex scenes is further reinforced by consistency-aware direct preference optimization, which explicitly encourages alignment among modalities under ambiguous or conflicting perceptual conditions. Experiments on EMER, EmoBench-M, and SABER-Test demonstrate that SABER-LLM significantly outperforms open-source baselines and achieves robustness competitive with closed-source models in decoding complex emotional dynamics. The dataset and model are available at https://github.com/zxzhao0/SABER-LLM.", "AI": {"tldr": "本文提出了SABER-LLM框架，用于鲁棒的多模态情绪推理。", "motivation": "现有的多模态大语言模型在细粒度感知和跨模式融合方面存在局限性，导致在复杂多模态交互中的幻觉现象。为解决此问题，本文引入了SABER数据集与结构化证据分解范式以提高鲁棒性和准确性。", "method": "构建了一个包含60万视频片段的大型情绪推理数据集，并提出了\"感知然后推理\"分离框架及一致性意识直接偏好优化方法来提升模型性能。", "result": "实验结果显示，SABER-LLM在解码复杂的情绪动态方面表现出色，优于开源基线并可与闭源模型竞争。", "conclusion": "本文通过创新的数据集和方法论改进了多模态情绪分析的准确性和鲁棒性，对相关领域的发展具有积极意义。"}}
{"id": "2601.18320", "pdf": "https://arxiv.org/pdf/2601.18320", "abs": "https://arxiv.org/abs/2601.18320", "authors": ["Jinwei Lu", "Yuanfeng Song", "Chen Zhang", "Raymond Chi-Wing Wong"], "title": "MultiVis-Agent: A Multi-Agent Framework with Logic Rules for Reliable and Comprehensive Cross-Modal Data Visualization", "categories": ["cs.CL", "cs.AI", "cs.DB"], "comment": "Accepted to SIGMOD 2026", "summary": "Real-world visualization tasks involve complex, multi-modal requirements that extend beyond simple text-to-chart generation, requiring reference images, code examples, and iterative refinement. Current systems exhibit fundamental limitations: single-modality input, one-shot generation, and rigid workflows. While LLM-based approaches show potential for these complex requirements, they introduce reliability challenges including catastrophic failures and infinite loop susceptibility. To address this gap, we propose MultiVis-Agent, a logic rule-enhanced multi-agent framework for reliable multi-modal and multi-scenario visualization generation. Our approach introduces a four-layer logic rule framework that provides mathematical guarantees for system reliability while maintaining flexibility. Unlike traditional rule-based systems, our logic rules are mathematical constraints that guide LLM reasoning rather than replacing it. We formalize the MultiVis task spanning four scenarios from basic generation to iterative refinement, and develop MultiVis-Bench, a benchmark with over 1,000 cases for multi-modal visualization evaluation. Extensive experiments demonstrate that our approach achieves 75.63% visualization score on challenging tasks, significantly outperforming baselines (57.54-62.79%), with task completion rates of 99.58% and code execution success rates of 94.56% (vs. 74.48% and 65.10% without logic rules), successfully addressing both complexity and reliability challenges in automated visualization generation.", "AI": {"tldr": "提出了一种基于逻辑规则的多代理框架MultiVis-Agent，用于可靠和全面的跨模态数据可视化。", "motivation": "现有的系统在单一模式输入、一次性生成及刚性工作流程上存在局限。LLM方法虽然有潜力应对复杂需求但存在可靠性挑战，如灾难性失败和无限循环问题。因此提出了一种新的框架解决这些问题。", "method": "引入了一个四层逻辑规则框架提供数学保证以确保系统可靠性并保持灵活性；使用了基于数学约束的指导而非替换LLM推理的传统规则；设计了MultiVis任务涵盖从基本生成到迭代改进的不同场景，并建立了包含超过1000个案例的基准测试。", "result": "在具有挑战性的任务上，获得75.63%的可视化得分，明显优于基线（57.54-62.79%）；任务完成率达到99.58%，代码执行成功率为94.56%，显著高于未使用逻辑规则的情况。", "conclusion": "MultiVis-Agent框架能够有效地解决自动化数据可视化的复杂性和可靠性挑战。"}}
{"id": "2601.18308", "pdf": "https://arxiv.org/pdf/2601.18308", "abs": "https://arxiv.org/abs/2601.18308", "authors": ["Geunsik Lim"], "title": "A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience", "categories": ["cs.AI", "cs.SI", "eess.SY"], "comment": "19 pages", "summary": "As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures.", "AI": {"tldr": "本文介绍了一个基于生成式AI的可靠性层Climate RADAR，旨在通过个性化推荐提升灾害响应效率。", "motivation": "传统的早期预警系统虽然能够快速传播警报信息，但往往无法有效触发保护行动，导致可预防损失和不平等现象。为解决这一问题，文章提出了一种新的系统来增强灾难应对的及时性和有效性。", "method": "Climate RADAR集成气象、水文、脆弱性和社会数据形成综合风险指数，并使用嵌入了护栏机制的大规模语言模型(LLMs)生成个性化建议。", "result": "通过模拟测试和用户研究，发现该系统的应用提高了防护行动执行率，减少了响应延迟，并增强了用户体验和信任度。", "conclusion": "Climate RADAR结合预测分析、行为科学和负责任的人工智能技术，为灾害预警系统提供了以人为本的解决方案，促进了合规就绪的灾难韧性基础设施的发展。"}}
{"id": "2601.18306", "pdf": "https://arxiv.org/pdf/2601.18306", "abs": "https://arxiv.org/abs/2601.18306", "authors": ["Everlyn Asiko Chimoto", "Mostafa Elhoushi", "Bruce A. Bassett"], "title": "Calibrating Beyond English: Language Diversity for Better Quantized Multilingual LLM", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to EACL 2026 Main Conference", "summary": "Quantization is an effective technique for reducing the storage footprint and computational costs of Large Language Models (LLMs), but it often results in performance degradation. Existing post-training quantization methods typically use small, English-only calibration sets; however, their impact on multilingual models remains underexplored. We systematically evaluate eight calibration settings (five single-language and three multilingual mixes) on two quantizers (GPTQ, AWQ) on data from 10 languages. Our findings reveal a consistent trend: non-English and multilingual calibration sets significantly improve perplexity compared to English-only baselines. Specifically, we observe notable average perplexity gains across both quantizers on Llama3.1 8B and Qwen2.5 7B, with multilingual mixes achieving the largest overall reductions of up to 3.52 points in perplexity. Furthermore, our analysis indicates that tailoring calibration sets to the evaluation language yields the largest improvements for individual languages, underscoring the importance of linguistic alignment. We also identify specific failure cases where certain language-quantizer combinations degrade performance, which we trace to differences in activation range distributions across languages. These results highlight that static one-size-fits-all calibration is suboptimal and that tailoring calibration data, both in language and diversity, plays a crucial role in robustly quantizing multilingual LLMs.", "AI": {"tldr": "研究如何通过不同语言校准集优化量化多语种大型语言模型的性能。", "motivation": "现有后训练量化方法依赖于小规模、仅英语的数据集进行校准，对于多语种模型的效果尚未深入探讨。本论文旨在探究使用非英语和多语种数据集能否提升量化效果，并找出最佳校准策略。", "method": "系统性地评估了八种不同的校准设置（五种单语言和三种多语言混合）在两个量化器（GPTQ、AWQ）上的表现，涵盖十种不同语言的数据。通过对比实验，分析并总结不同语言和量化器组合的效果差异。", "result": "非英语及多语种校准集相比仅用英语的基准线显著提升了困惑度，特别是在Llama3.1 8B与Qwen2.5 7B模型上观察到了最大可达3.52点的困惑度降低。语言特定校准对提升单个语言性能尤为有效。", "conclusion": "静态单一标准校准在多语种量化中表现不佳，定制化的语言和多样性数据校准是优化量化效果的关键因素。"}}
{"id": "2601.18305", "pdf": "https://arxiv.org/pdf/2601.18305", "abs": "https://arxiv.org/abs/2601.18305", "authors": ["Xuan Wang", "Siyuan Su", "Quantong Fu", "Yongxiang Hu", "Yangfan Zhou"], "title": "SwipeGen: Bridging the Execution Gap in GUI Agents via Human-like Swipe Synthesis", "categories": ["cs.CV"], "comment": "15 pages, 3 figures. Under review. Code and dataset will be released upon acceptance", "summary": "With the widespread adoption of Graphical User Interface (GUI) agents for automating GUI interaction tasks, substantial research focused on improving GUI perception to ground task instructions into concrete action steps. However, the step execution capability of these agents has gradually emerged as a new bottleneck for task completion. In particular, existing GUI agents often adopt overly simplified strategies for handling swipe interactions, preventing them from accurately replicating human-like behavior. To address this limitation, we decompose human swipe gestures into multiple quantifiable dimensions and propose an automated pipeline SwipeGen to synthesize human-like swipe interactions through GUI exploration. Based on this pipeline, we construct and release the first benchmark for evaluating the swipe execution capability of GUI agents. Furthermore, leveraging the synthesized data, we propose GUISwiper, a GUI agent with enhanced interaction execution capabilities. Experimental results demonstrate that GUISwiper achieves a swipe execution accuracy of 69.07%, representing a 214% improvement over existing VLM baselines.", "AI": {"tldr": "本文提出了SwipeGen，一种用于生成类人滑动手势的自动化管道和评估GUI代理执行能力的新基准，并基于此开发了交互执行能力增强的GUI代理GUISwiper。", "motivation": "现有的GUI代理在处理滑动交互时采用过于简化的策略，导致无法准确复制人类行为。为了改善这一点，本文旨在提高GUI代理执行滑动手势的能力。", "method": "将人类滑动手势分解成多个可量化维度，并提出了一种自动化管道SwipeGen以生成类人滑动手势。基于此，构建了一个新的评估基准，同时开发了交互执行能力增强的GUI代理GUISwiper。", "result": "实验结果表明，GUISwiper实现了69.07%的滑动执行准确率，相较于现有VLM基线提高了214％。", "conclusion": "通过改进滑动手势的处理方法，可以显著提高GUI代理完成任务的能力。"}}
{"id": "2601.18301", "pdf": "https://arxiv.org/pdf/2601.18301", "abs": "https://arxiv.org/abs/2601.18301", "authors": ["Seyedali Mousavi", "Seyedhamidreza Mousavi", "Masoud Daneshtalab"], "title": "Contextual Range-View Projection for 3D LiDAR Point Clouds", "categories": ["cs.CV"], "comment": null, "summary": "Range-view projection provides an efficient method for transforming 3D LiDAR point clouds into 2D range image representations, enabling effective processing with 2D deep learning models. However, a major challenge in this projection is the many-to-one conflict, where multiple 3D points are mapped onto the same pixel in the range image, requiring a selection strategy. Existing approaches typically retain the point with the smallest depth (closest to the LiDAR), disregarding semantic relevance and object structure, which leads to the loss of important contextual information. In this paper, we extend the depth-based selection rule by incorporating contextual information from both instance centers and class labels, introducing two mechanisms: \\textit{Centerness-Aware Projection (CAP)} and \\textit{Class-Weighted-Aware Projection (CWAP)}. In CAP, point depths are adjusted according to their distance from the instance center, thereby prioritizing central instance points over noisy boundary and background points. In CWAP, object classes are prioritized through user-defined weights, offering flexibility in the projection strategy. Our evaluations on the SemanticKITTI dataset show that CAP preserves more instance points during projection, achieving up to a 3.1\\% mIoU improvement compared to the baseline. Furthermore, CWAP enhances the performance of targeted classes while having a negligible impact on the performance of other classes", "AI": {"tldr": "提出了一种基于上下文信息的3D LiDAR点云投影方法，改进了现有深度选择策略，提高了范围视图投影的效果", "motivation": "现有的范围视图投影在处理多对一冲突时，仅保留最近点而忽视语义相关性和物体结构，导致重要上下文信息丢失。为了提高投影质量，本文引入了基于中心感知和类别加权的改进策略", "method": "本文提出了两种机制：Centerness-Aware Projection (CAP) 和 Class-Weighted-Aware Projection (CWAP)，前者根据点与实例中心的距离调整深度，后者通过用户定义权重优先考虑特定类别的对象。这些方法结合使用以更好地保留重要信息", "result": "在SemanticKITTI数据集上的实验表明，CAP 方法可以提高最多3.1％的mIoU指标； CWAP则进一步增强了目标类别性能，对其他类别影响较小", "conclusion": "本文通过引入上下文感知策略改进了范围视图投影方法，显著提升了点云处理效果"}}
{"id": "2601.18296", "pdf": "https://arxiv.org/pdf/2601.18296", "abs": "https://arxiv.org/abs/2601.18296", "authors": ["Zhaoyan Gong", "Zhiqiang Liu", "Songze Li", "Xiaoke Guo", "Yuanxiang Liu", "Xinle Deng", "Zhizhen Liu", "Lei Liang", "Huajun Chen", "Wen Zhang"], "title": "Temp-R1: A Unified Autonomous Agent for Complex Temporal KGQA via Reverse Curriculum Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Work in progress", "summary": "Temporal Knowledge Graph Question Answering (TKGQA) is inherently challenging, as it requires sophisticated reasoning over dynamic facts with multi-hop dependencies and complex temporal constraints. Existing methods rely on fixed workflows and expensive closed-source APIs, limiting flexibility and scalability. We propose Temp-R1, the first autonomous end-to-end agent for TKGQA trained through reinforcement learning. To address cognitive overload in single-action reasoning, we expand the action space with specialized internal actions alongside external action. To prevent shortcut learning on simple questions, we introduce reverse curriculum learning that trains on difficult questions first, forcing the development of sophisticated reasoning before transferring to easier cases. Our 8B-parameter Temp-R1 achieves state-of-the-art performance on MultiTQ and TimelineKGQA, improving 19.8% over strong baselines on complex questions. Our work establishes a new paradigm for autonomous temporal reasoning agents. Our code will be publicly available soon at https://github.com/zjukg/Temp-R1.", "AI": {"tldr": "本文提出了Temp-R1，一种通过强化学习训练的用于复杂时间知识图谱问答（TKGQA）的自主端到端代理。", "motivation": "现有的方法依赖于固定的流程和昂贵的闭源API，限制了灵活性和可扩展性。为了应对单一行动推理的认知过载问题，并防止在简单问题上进行捷径学习，本文提出了一种新的自主时间推理代理的方法。", "method": "Temp-R1通过引入特殊的内部动作扩展了行为空间并采用逆向课程强化学习先从困难的问题开始训练以避免简单的捷径学习策略。该模型具有80亿参数，并在MultiTQ和TimelineKGQA上达到了最先进的性能。", "result": "在复杂问题上的表现，Temp-R1比强基线提高了19.8%。", "conclusion": "这项工作为自主时间推理代理建立了一个新的范式。"}}
{"id": "2601.18295", "pdf": "https://arxiv.org/pdf/2601.18295", "abs": "https://arxiv.org/abs/2601.18295", "authors": ["Milan Marocchi", "Matthew Fynn", "Yue Rong"], "title": "Noise-Robust Contrastive Learning with an MFCC-Conformer For Coronary Artery Disease Detection", "categories": ["eess.AS", "cs.SD"], "comment": "This paper has been accepted for presentation at ICASSP 2026. \\c{opyright} 2026 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses. 5 pages, 1 figure", "summary": "Cardiovascular diseases (CVD) are the leading cause of death worldwide, with coronary artery disease (CAD) comprising the largest subcategory of CVDs. Recently, there has been increased focus on detecting CAD using phonocardiogram (PCG) signals, with high success in clinical environments with low noise and optimal sensor placement. Multichannel techniques have been found to be more robust to noise; however, achieving robust performance on real-world data remains a challenge. This work utilises a novel multichannel energy-based noisy-segment rejection algorithm, using heart and noise-reference microphones, to discard audio segments with large amounts of nonstationary noise before training a deep learning classifier. This conformer-based classifier takes mel-frequency cepstral coefficients (MFCCs) from multiple channels, further helping improve the model's noise robustness. The proposed method achieved 78.4% accuracy and 78.2% balanced accuracy on 297 subjects, representing improvements of 4.1% and 4.3%, respectively, compared to training without noisy-segment rejection.", "AI": {"tldr": "本文提出了一种利用多通道能量基于噪声段拒绝的算法，结合MFCC-Conformer模型进行冠状动脉疾病的检测。", "motivation": "心血管疾病是全球死亡的主要原因，其中冠状动脉疾病是最常见的类型。使用心音图信号（PCG）来检测CAD在临床环境中取得了一定的成功，但在现实世界的数据中仍面临噪音问题的挑战。", "method": "本文提出一种基于多通道能量的新噪声段拒绝算法，该算法利用心脏和噪声参考麦克风去除含大量非稳态噪声的音频片段，并训练一个深度学习分类器。此分类器采用来自多个通道的梅尔频率倒谱系数（MFCC），进一步提高了模型对噪音的鲁棒性。", "result": "提出的这种方法在297名受试者的数据集上达到了78.4％的准确率和78.2％的平衡准确度，与不使用噪声段拒绝训练相比分别提高了4.1%和4.3%。", "conclusion": "所提出的方法通过结合多通道能量基于噪声段拒绝算法以及MFCC-Conformer模型，在冠状动脉疾病的检测中取得了显著的进步，并展示了在实际数据集上的优越性能。"}}
{"id": "2601.18292", "pdf": "https://arxiv.org/pdf/2601.18292", "abs": "https://arxiv.org/abs/2601.18292", "authors": ["Zhewen Tan", "Wenhan Yu", "Jianfeng Si", "Tongxin Liu", "Kaiqi Guan", "Huiyan Jin", "Jiawen Tao", "Xiaokun Yuan", "Duohe Ma", "Xiangzheng Zhang", "Tong Yang", "Lin Sun"], "title": "TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In recent years, safety risks associated with large language models have become increasingly prominent, highlighting the urgent need to mitigate the generation of toxic and harmful content. The mainstream paradigm for LLM safety alignment typically adopts a collaborative framework involving three roles: an attacker for adversarial prompt generation, a defender for safety defense, and an evaluator for response assessment. In this paper, we propose a closed-loop reinforcement learning framework called TriPlay-RL that enables iterative and co-improving collaboration among three roles with near-zero manual annotation. Experimental results show that the attacker preserves high output diversity while achieving a 20%-50% improvement in adversarial effectiveness; the defender attains 10%-30% gains in safety performance without degrading general reasoning capability; and the evaluator continuously refines its fine-grained judgment ability through iterations, accurately distinguishing unsafe responses, simple refusals, and useful guidance. Overall, our framework establishes an efficient and scalable paradigm for LLM safety alignment, enabling continuous co-evolution within a unified learning loop.", "AI": {"tldr": "提出了一种闭合循环的强化学习框架TriPlay-RL，用于大语言模型的安全对齐。", "motivation": "近年来，大型语言模型的安全风险日益突出，迫切需要减轻有害内容生成的问题。传统的主流方法采用包含攻击者、防御者和评估者的协作框架来解决这个问题。", "method": "通过一种迭代协同增强的三角色自博弈强化学习TriPlay-RL框架，在几乎不需要人工标注的情况下实现安全对齐。该框架包括了三个相互竞争的角色：攻击者生成对抗性提示，防御者进行安全性防护，评估者评估响应质量，并且在循环中不断改进。", "result": "实验结果显示，攻击者的输出多样性得到了保持并且其有效性提高了20%到50%，而防守者则通过迭代达到了10%-30%的安全性能提升。同时，评价器的判断能力也得到了显著增强。", "conclusion": "TriPlay-RL框架提供了一个高效且可扩展的方法来实现大语言模型的安全对齐，并能够在统一的学习循环中实现持续共进化。"}}
{"id": "2601.18289", "pdf": "https://arxiv.org/pdf/2601.18289", "abs": "https://arxiv.org/abs/2601.18289", "authors": ["Jialong Li", "Zhenguo Wang", "Tianci Wang", "Maj Stenmark", "Volker Krueger"], "title": "Quest2ROS2: A ROS 2 Framework for Bi-manual VR Teleoperation", "categories": ["cs.RO"], "comment": "HRI 2026", "summary": "Quest2ROS2 is an open-source ROS2 framework for bi-manual teleoperation designed to scale robot data collection. Extending Quest2ROS, it overcomes workspace limitations via relative motion-based control, calculating robot movement from VR controller pose changes to enable intuitive, pose-independent operation. The framework integrates essential usability and safety features, including real-time RViz visualization, streamlined gripper control, and a pause-and-reset function for smooth transitions. We detail a modular architecture that supports \"Side-by-Side\" and \"Mirror\" control modes to optimize operator experience across diverse platforms. Code is available at: https://github.com/Taokt/Quest2ROS2.", "AI": {"tldr": "Quest2ROS2是一个用于双臂虚拟现实遥操作的开源ROS2框架，旨在通过相对运动控制克服工作空间限制，并提供实时可视化、简化夹爪控制和暂停重置功能。", "motivation": "该论文旨在开发一个能够解决传统遥操作系统在数据收集过程中遇到的工作空间限制问题的新框架。通过使用相对运动来计算机器人动作，使得操作更加直观且不受姿势影响。", "method": "构建了一个模块化架构的ROS2框架，并支持\"Side-by-Side\"和\"Mirror\"控制模式。该框架集成了实时RViz可视化、简化夹爪控制及暂停重置功能以优化用户体验。", "result": "提供了一种能够克服工作空间限制并实现直观操作的新方法，同时增强了安全性和易用性。", "conclusion": "Quest2ROS2为双臂虚拟现实遥操作系统提供了新的解决方案，并且可以支持不同的平台和控制模式。代码已经开源以供参考使用。"}}
{"id": "2601.18282", "pdf": "https://arxiv.org/pdf/2601.18282", "abs": "https://arxiv.org/abs/2601.18282", "authors": ["Lei Wei", "Jinpeng Ou", "Xiao Peng", "Bin Wang"], "title": "Think-Augmented Function Calling: Improving LLM Parameter Accuracy Through Embedded Reasoning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in function calling for autonomous agents, yet current mechanisms lack explicit reasoning transparency during parameter generation, particularly for complex functions with interdependent parameters. While existing approaches like chain-of-thought prompting operate at the agent level, they fail to provide fine-grained reasoning guidance for individual function parameters. To address these limitations, we propose Think-Augmented Function Calling (TAFC), a novel framework that enhances function calling accuracy through explicit reasoning at both function and parameter levels. Our method introduces a universal \"think\" parameter augmentation that enables models to articulate their decision-making process, with dynamic optimization for parameter descriptions to improve reasoning quality. For complex parameters, TAFC automatically triggers granular reasoning based on complexity scoring, ensuring appropriate justification for critical decisions. Additionally, we propose reasoning-guided optimization to align generated reasoning with human expectations. TAFC requires no architectural modifications to existing LLMs while maintaining full API compatibility. Evaluation on ToolBench across proprietary and open-source models demonstrates significant improvements in parameter generation accuracy and reasoning coherence for multi-parameter functions, while providing enhanced interpretability for debugging AI agent behaviors.", "AI": {"tldr": "该论文提出了一种增强大型语言模型（LLM）函数调用准确性的方法，通过显式推理提高参数生成的透明度和准确性。", "motivation": "现有的函数调用机制在复杂功能的相互依赖参数生成中缺乏明确的推理透明性。尽管链式思考提示等现有方法可以在代理级别提供指导，但对于单一参数的精细级推理支持不足。为解决这些问题，作者提出了一种新的框架——Think-Augmented Function Calling（TAFC）。", "method": "TAFC通过引入一个普遍适用的“think”参数增强模型，使它们能够表达决策过程，并针对复杂性评分自动触发细化推理以确保关键决策得到适当解释。此外，该方法还包括引导优化，以确保生成的推理与人类期望一致。", "result": "在ToolBench上对多种LLM进行评估显示，TAFC显著提高了多参数函数中的参数生成准确性及推理连贯性，并增强了AI代理行为的可调试性。", "conclusion": "TAFC通过提供显式的决策过程表达和细化推理来提高LLM在复杂功能调用中的准确性和透明度。此方法无需对现有模型架构进行修改，保持了API兼容性。"}}
{"id": "2601.18281", "pdf": "https://arxiv.org/pdf/2601.18281", "abs": "https://arxiv.org/abs/2601.18281", "authors": ["Yuhang Jia", "Pei Liu", "Haoqin Sun", "Jiaming Zhou", "Xuxin Cheng", "Cao Liu", "Ke Zeng", "Xunliang Cai", "Yong Qin"], "title": "Reflecting Twice before Speaking with Empathy: Self-Reflective Alternating Inference for Empathy-Aware End-to-End Spoken Dialogue", "categories": ["cs.CL", "cs.SD"], "comment": null, "summary": "End-to-end Spoken Language Models (SLMs) hold great potential for paralinguistic perception, and numerous studies have aimed to enhance their capabilities, particularly for empathetic dialogue. However, current approaches largely depend on rigid supervised signals, such as ground-truth response in supervised fine-tuning or preference scores in reinforcement learning. Such reliance is fundamentally limited for modeling complex empathy, as there is no single \"correct\" response and a simple numerical score cannot fully capture the nuances of emotional expression or the appropriateness of empathetic behavior. To address these limitations, we sequentially introduce EmpathyEval, a descriptive natural-language-based evaluation model for assessing empathetic quality in spoken dialogues. Building upon EmpathyEval, we propose ReEmpathy, an end-to-end SLM that enhances empathetic dialogue through a novel Empathetic Self-Reflective Alternating Inference mechanism, which interleaves spoken response generation with free-form, empathy-related reflective reasoning. Extensive experiments demonstrate that ReEmpathy substantially improves empathy-sensitive spoken dialogue by enabling reflective reasoning, offering a promising approach toward more emotionally intelligent and empathy-aware human-computer interactions.", "AI": {"tldr": "该论文提出了一种新的方法，通过反思性推理来提高对话系统的情感智能。", "motivation": "现有基于监督信号的方法对于模拟复杂的情感难以实现全面捕捉，因此需要一种能够更好地理解和回应情感的语言模型。", "method": "作者提出了EmpathyEval评估模型和ReEmpathy语言模型，后者使用了自反交替推断机制，在生成回复时进行自由形式的反思性推理来提高对话中的同理心。", "result": "实验表明，ReEmpathy在情感敏感的对话中表现出显著改进。", "conclusion": "该方法为更智能、更具同情心的人机交互提供了一种有前途的方法。"}}
{"id": "2601.18278", "pdf": "https://arxiv.org/pdf/2601.18278", "abs": "https://arxiv.org/abs/2601.18278", "authors": ["Indrė Žliobaitė"], "title": "What Do Learned Models Measure?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In many scientific and data-driven applications, machine learning models are increasingly used as measurement instruments, rather than merely as predictors of predefined labels. When the measurement function is learned from data, the mapping from observations to quantities is determined implicitly by the training distribution and inductive biases, allowing multiple inequivalent mappings to satisfy standard predictive evaluation criteria. We formalize learned measurement functions as a distinct focus of evaluation and introduce measurement stability, a property capturing invariance of the measured quantity across admissible realizations of the learning process and across contexts. We show that standard evaluation criteria in machine learning, including generalization error, calibration, and robustness, do not guarantee measurement stability. Through a real-world case study, we show that models with comparable predictive performance can implement systematically inequivalent measurement functions, with distribution shift providing a concrete illustration of this failure. Taken together, our results highlight a limitation of existing evaluation frameworks in settings where learned model outputs are identified as measurements, motivating the need for an additional evaluative dimension.", "AI": {"tldr": "该论文探讨了机器学习模型作为测量工具时的局限性，尤其是在不同训练分布和归纳偏置下可能导致不同的测量函数。", "motivation": "在许多科学和数据驱动的应用中，机器学习模型被用作测量工具而非仅仅是预定义标签的预测器。标准评估准则如泛化误差、校准和鲁棒性并不能保证测量稳定性，即测量结果的一致性和不变性。因此，需要一种额外的评价维度来解决这一问题。", "method": "论文提出了“测量稳定性”的概念，并通过一个现实世界的案例研究展示了具有类似预测性能的模型可以实现不同的测量函数。同时探讨了分布变化如何具体说明这种失败情况。", "result": "结果表明，在机器学习中常用的评估标准不足以保证测量稳定性，即使是在相同预测性能下也存在显著差异。", "conclusion": "论文强调在将学习模型输出视为测量值的场景中，现有评价框架存在局限性，并提出需要引入新的维度以更好地评估测量功能。"}}
{"id": "2601.18275", "pdf": "https://arxiv.org/pdf/2601.18275", "abs": "https://arxiv.org/abs/2601.18275", "authors": ["Qiufang Yu", "Mengmeng Wu", "Xingyu Lan"], "title": "When Nobody Around Is Real: Exploring Public Opinions and User Experiences On the Multi-Agent AI Social Platform", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "Powered by large language models, a new genre of multi-agent social platforms has emerged. Apps such as Social.AI deploy numerous AI agents that emulate human behavior, creating unprecedented bot-centric social networks. Yet, existing research has predominantly focused on one-on-one chatbots, leaving multi-agent AI platforms underexplored. To bridge this gap, we took Social.AI as a case study and performed a two-stage investigation: (i) content analysis of 883 user comments; (ii) a 7-day diary study with 20 participants to document their firsthand platform experiences. While public discourse expressed greater skepticism, the diary study found that users did project a range of social expectations onto the AI agents. While some user expectations were met, the AI-dominant social environment introduces distinct problems, such as attention overload and homogenized interaction. These tensions signal a future where AI functions not merely as a tool or an anthropomorphized actor, but as the dominant medium of sociality itself-a paradigm shift that foregrounds new forms of architected social life.", "AI": {"tldr": "研究探讨了基于大型语言模型的多代理AI社交平台上的公众意见和用户体验。", "motivation": "当前研究主要集中在一对一聊天机器人上，忽略了新兴的多代理AI社交平台的研究。这项研究旨在填补这一空白。", "method": "通过分析883条评论以及为期7天、涉及20名参与者的日记研究来探讨用户在Social.AI上的体验。", "result": "公众对于该类平台存在怀疑态度，但参与者在研究中发现他们对AI代理投射了各种社交期望。虽然一些期望得以满足，但也出现了注意力过载和互动同质化等问题。", "conclusion": "这些挑战预示着未来社会性交往方式将发生转变：人工智能不再是工具或人类化的角色，而是作为主导的社交媒介出现，这标志着新的架构社会生活的模式的到来。"}}
{"id": "2601.18274", "pdf": "https://arxiv.org/pdf/2601.18274", "abs": "https://arxiv.org/abs/2601.18274", "authors": ["Sicheng Shen", "Mingyang Lv", "Bing Han", "Dongcheng Zhao", "Guobin Shen", "Feifei Zhao", "Yi Zeng"], "title": "TEFormer: Structured Bidirectional Temporal Enhancement Modeling in Spiking Transformers", "categories": ["cs.NE"], "comment": "15pages, 2 figures", "summary": "In recent years, Spiking Neural Networks (SNNs) have achieved remarkable progress, with Spiking Transformers emerging as a promising architecture for energy-efficient sequence modeling. However, existing Spiking Transformers still lack a principled mechanism for effective temporal fusion, limiting their ability to fully exploit spatiotemporal dependencies. Inspired by feedforward-feedback modulation in the human visual pathway, we propose TEFormer, the first Spiking Transformer framework that achieves bidirectional temporal fusion by decoupling temporal modeling across its core components. Specifically, TEFormer employs a lightweight and hyperparameter-free forward temporal fusion mechanism in the attention module, enabling fully parallel computation, while incorporating a backward gated recurrent structure in the MLP to aggregate temporal information in reverse order and reinforce temporal consistency. Extensive experiments across a wide range of benchmarks demonstrate that TEFormer consistently and significantly outperforms strong SNN and Spiking Transformer baselines under diverse datasets. Moreover, through the first systematic evaluation of Spiking Transformers under different neural encoding schemes, we show that the performance gains of TEFormer remain stable across encoding choices, indicating that the improved temporal modeling directly translates into reliable accuracy improvements across varied spiking representations. These results collectively establish TEFormer as an effective and general framework for temporal modeling in Spiking Transformers.", "AI": {"tldr": "TEFormer提出了一个用于脉冲变压器的双向时间融合模型，以更好地利用时空依赖性。", "motivation": "现有脉冲变压器缺乏有效的时序融合机制，限制了它们对时空依赖性的充分利用。TEFormer通过模仿人类视觉通路中的前馈反馈调节来解决这个问题。", "method": "TEFormer采用轻量级且无超参数的前向时间融合机制在注意力模块中实现完全并行计算，并在MLP中引入反向门控递归结构以聚合逆序的时间信息，从而增强时序一致性。", "result": "实验结果表明，TEFormer在各种基准测试下一致显著优于强大的SNN和脉冲变压器基线。此外，在不同神经编码方案下的系统性评估显示其性能提升保持稳定。", "conclusion": "这些结果显示TEFormer是一个有效的通用框架，用于脉冲变压器中的时序建模。"}}
{"id": "2601.18266", "pdf": "https://arxiv.org/pdf/2601.18266", "abs": "https://arxiv.org/abs/2601.18266", "authors": ["Steven Vander Eeckt", "Hugo Van hamme"], "title": "Efficient Rehearsal for Continual Learning in ASR via Singular Value Tuning", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted for publication in IEEE Transactions on Audio, Speech, and Language Processing", "summary": "Continual Learning (CL) in Automatic Speech Recognition (ASR) suffers from catastrophic forgetting when adapting to new tasks, domains, or speakers. A common strategy to mitigate this is to store a subset of past data in memory for rehearsal. However, rehearsal-based methods face key limitations: storing data is often costly, infeasible with pre-trained models, or restricted by privacy regulations. Running existing rehearsal-based methods with smaller memory sizes to alleviate these issues usually leads to degraded performance. We propose a rehearsal-based CL method that remains effective even with minimal memory. It operates in two stages: first, fine-tuning on the new task; second, applying Singular Value Decomposition (SVD) to the changes in linear layers and, in a parameter-efficient manner, retraining only gating vectors on the singular values, which control to extent to which updates from the first stage are accepted, using rehearsal. We extensively test and analyze our method on two monolingual and two multilingual benchmarks. Our method reduces forgetting and outperforms state-of-the-art CL approaches for ASR, even when limited to a single utterance per previous task.", "AI": {"tldr": "该论文提出了一种新的基于重演的连续学习方法，用于自动语音识别中的灾难性遗忘问题，并在较小的记忆容量下保持高性能。", "motivation": "传统的基于重演的连续学习方法需要大量的存储空间并且可能受到隐私限制，这使得它们难以应用于实际场景。现有解决方案通常通过减少内存大小来应对这些问题但会导致性能下降。", "method": "该论文提出了一种新的重演策略，在微调后应用奇异值分解（SVD）于线性层变化，并以参数高效的方式仅重新训练控制更新接受程度的门向量，从而在较小的记忆容量下有效缓解灾难性遗忘问题。", "result": "实验结果显示该方法能够减少遗忘并超越现有的自动语音识别连续学习方法，在每个先前任务限制为单个话语的情况下依然表现优异。", "conclusion": "所提出的方法证明了即使在小内存环境下，通过参数高效的门向量重训练也可以实现有效的基于重演的连续学习，从而克服传统方法面临的存储和隐私问题。"}}
{"id": "2601.18264", "pdf": "https://arxiv.org/pdf/2601.18264", "abs": "https://arxiv.org/abs/2601.18264", "authors": ["ZeYu Li", "ShiJun Zhang", "TieYong Zeng", "FengLei Fan"], "title": "Neural Network Approximation: A View from Polytope Decomposition", "categories": ["cs.LG", "cs.AI"], "comment": ":68Q25; 68Q32; 68T99", "summary": "Universal approximation theory offers a foundational framework to verify neural network expressiveness, enabling principled utilization in real-world applications. However, most existing theoretical constructions are established by uniformly dividing the input space into tiny hypercubes without considering the local regularity of the target function. In this work, we investigate the universal approximation capabilities of ReLU networks from a view of polytope decomposition, which offers a more realistic and task-oriented approach compared to current methods. To achieve this, we develop an explicit kernel polynomial method to derive an universal approximation of continuous functions, which is characterized not only by the refined Totik-Ditzian-type modulus of continuity, but also by polytopical domain decomposition. Then, a ReLU network is constructed to approximate the kernel polynomial in each subdomain separately. Furthermore, we find that polytope decomposition makes our approximation more efficient and flexible than existing methods in many cases, especially near singular points of the objective function. Lastly, we extend our approach to analytic functions to reach a higher approximation rate.", "AI": {"tldr": "该论文通过多面体分解的角度研究了ReLU网络的普遍逼近能力，并提出了一种基于内核多项式方法的新框架。", "motivation": "现有理论构造大多是在输入空间上均匀划分，未考虑目标函数的局部规律性。本文提出了一个多面体分解的方法来提高神经网络逼近效率和灵活性。", "method": "通过开发显式的核多项式方法，该论文将连续函数的普遍逼近描述为由精细化Totik-Ditzian型连续模及多面体域分解共同定义。然后，在每个子区域内单独构造ReLU网络以近似内核多项式。", "result": "在许多情况下，特别是在目标函数奇异点附近，基于多面体分解的方法比现有方法更有效灵活，并且该方法已扩展到解析函数以实现更高的逼近率。", "conclusion": "论文提出了一种新的基于多面体分解的ReLU网络普遍逼近框架，证明了其优越性并扩展到了解析函数领域。"}}
{"id": "2601.18263", "pdf": "https://arxiv.org/pdf/2601.18263", "abs": "https://arxiv.org/abs/2601.18263", "authors": ["Subhajeet Das", "Susmita Ghosh", "Abhiroop Chatterjee"], "title": "Revisiting Aerial Scene Classification on the AID Benchmark", "categories": ["cs.CV"], "comment": "Presented at the IEEE India Geoscience and Remote Sensing Symposium 2025 and accepted for publication in IEEE Xplore", "summary": "Aerial images play a vital role in urban planning and environmental preservation, as they consist of various structures, representing different types of buildings, forests, mountains, and unoccupied lands. Due to its heterogeneous nature, developing robust models for scene classification remains a challenge. In this study, we conduct a literature review of various machine learning methods for aerial image classification. Our survey covers a range of approaches from handcrafted features (e.g., SIFT, LBP) to traditional CNNs (e.g., VGG, GoogLeNet), and advanced deep hybrid networks. In this connection, we have also designed Aerial-Y-Net, a spatial attention-enhanced CNN with multi-scale feature fusion mechanism, which acts as an attention-based model and helps us to better understand the complexities of aerial images. Evaluated on the AID dataset, our model achieves 91.72% accuracy, outperforming several baseline architectures.", "AI": {"tldr": "本文研究了基于AID数据集的遥感图像分类任务，提出了一种新的网络结构Aerial-Y-Net，并验证其有效性。", "motivation": "由于遥感图像包含不同类型建筑物、森林等复杂场景，开发用于场景分类的鲁棒模型仍是一个挑战。因此，作者进行了文献综述，总结了各种机器学习方法，并设计了一个增强的空间注意力机制与多尺度特征融合网络以提升性能。", "method": "本文提出了Aerial-Y-Net，这是一种基于空间注意和多尺度特征融合机制的CNN结构，用于遥感图像分类任务。", "result": "在AID数据集上评估，所提出的模型达到了91.72%的准确率，超过了多个基线架构。", "conclusion": "通过设计新的网络结构Aerial-Y-Net，本文有效提升了基于AID基准的数据集中场景分类任务的表现。"}}
{"id": "2601.18260", "pdf": "https://arxiv.org/pdf/2601.18260", "abs": "https://arxiv.org/abs/2601.18260", "authors": ["Eytan Kats", "Kai Geissler", "Daniel Mensing", "Jochen G. Hirsch", "Stefan Heldman", "Mattias P. Heinrich"], "title": "Depth to Anatomy: Learning Internal Organ Locations from Surface Depth Images", "categories": ["cs.CV"], "comment": "preprint", "summary": "Automated patient positioning plays an important role in optimizing scanning procedure and improving patient throughput. Leveraging depth information captured by RGB-D cameras presents a promising approach for estimating internal organ positions, thereby enabling more accurate and efficient positioning. In this work, we propose a learning-based framework that directly predicts the 3D locations and shapes of multiple internal organs from single 2D depth images of the body surface. Utilizing a large-scale dataset of full-body MRI scans, we synthesize depth images paired with corresponding anatomical segmentations to train a unified convolutional neural network architecture. Our method accurately localizes a diverse set of anatomical structures, including bones and soft tissues, without requiring explicit surface reconstruction. Experimental results demonstrate the potential of integrating depth sensors into radiology workflows to streamline scanning procedures and enhance patient experience through automated patient positioning.", "AI": {"tldr": "通过单个深度图像预测体内器官的位置和形状", "motivation": "提高扫描过程的效率，改善患者体验，优化自动定位系统", "method": "利用大规模MRI数据集合成深度图与解剖分割对应对，训练统一卷积神经网络架构以直接从2D深度图像中预测3D位置和形态", "result": "方法能够准确地定位包括骨骼和软组织在内的多样化解剖结构", "conclusion": "集成深度传感器到放射工作流程中有潜力通过自动化患者定位简化扫描过程并提高患者体验"}}
{"id": "2601.18255", "pdf": "https://arxiv.org/pdf/2601.18255", "abs": "https://arxiv.org/abs/2601.18255", "authors": ["Fei Meng"], "title": "Beyond Retention: Orchestrating Structural Safety and Plasticity in Continual Learning for LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Continual learning in Large Language Models (LLMs) faces the critical challenge of balancing stability (retaining old knowledge) and plasticity (learning new tasks). While Experience Replay (ER) is a standard countermeasure against catastrophic forgetting, its impact across diverse capabilities remains underexplored. In this work, we uncover a critical dichotomy in ER's behavior: while it induces positive backward transfer on robust, unstructured tasks (e.g., boosting performance on previous NLP classification tasks through repeated rehearsal), it causes severe negative transfer on fragile, structured domains like code generation (e.g., a significant relative drop in coding accuracy). This reveals that ER trades structural integrity for broad consolidation. To address this dilemma, we propose \\textbf{Orthogonal Subspace Wake-up (OSW)}. OSW identifies essential parameter subspaces of previous tasks via a brief \"wake-up\" phase and enforces orthogonal updates for new tasks, providing a mathematically grounded \"safety guarantee\" for established knowledge structures. Empirical results across a diverse four-task sequence demonstrate that OSW uniquely succeeds in preserving fragile coding abilities where Replay fails, while simultaneously maintaining high plasticity for novel tasks. Our findings emphasize the necessity of evaluating structural safety alongside average retention in LLM continual learning.", "AI": {"tldr": "提出了一种新的方法Orthogonal Subspace Wake-up (OSW)，以解决经验重播（ER）在持续学习中的结构完整性和可塑性之间的矛盾问题。", "motivation": "研究发现经验重播虽然可以增强模型对先前任务的泛化能力，但在某些特定领域如代码生成方面会导致性能下降。因此，需要一种新的方法来确保模型在新旧任务之间保持平衡。", "method": "通过短暂的“唤醒”阶段识别先前任务的关键参数子空间，并为新任务执行正交更新，以此保证已知知识结构的安全性。", "result": "实验结果表明，OSW能够保护代码生成等脆弱领域的能力，同时也能适应新的任务需求。", "conclusion": "研究强调了评估LLM持续学习中的结构性安全性的重要性。"}}
{"id": "2601.18253", "pdf": "https://arxiv.org/pdf/2601.18253", "abs": "https://arxiv.org/abs/2601.18253", "authors": ["Peng Sun", "Xiangyu Zhang", "Duan Wu"], "title": "BoRP: Bootstrapped Regression Probing for Scalable and Human-Aligned LLM Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": "This is a pre-print", "summary": "Accurate evaluation of user satisfaction is critical for iterative development of conversational AI. However, for open-ended assistants, traditional A/B testing lacks reliable metrics: explicit feedback is sparse, while implicit metrics are ambiguous. To bridge this gap, we introduce BoRP (Bootstrapped Regression Probing), a scalable framework for high-fidelity satisfaction evaluation. Unlike generative approaches, BoRP leverages the geometric properties of LLM latent space. It employs a polarization-index-based bootstrapping mechanism to automate rubric generation and utilizes Partial Least Squares (PLS) to map hidden states to continuous scores. Experiments on industrial datasets show that BoRP (Qwen3-8B/14B) significantly outperforms generative baselines (even Qwen3-Max) in alignment with human judgments. Furthermore, BoRP reduces inference costs by orders of magnitude, enabling full-scale monitoring and highly sensitive A/B testing via CUPED.", "AI": {"tldr": "介绍了一种用于评估对话AI满意度的可扩展框架BoRP。", "motivation": "传统A/B测试对于开放性助手而言缺乏可靠指标，显式反馈稀少且隐式度量不明确。为了弥补这一差距，引入了BoRP以提供高保真满意度评估。", "method": "通过利用LLM潜在空间的几何属性，采用基于极化指数的自助法机制自动化评分标准生成，并使用偏最小二乘回归将隐藏状态映射到连续分数。", "result": "实验表明，BoRP在与人类判断的一致性上显著优于生成式基线模型，同时大幅减少了推断成本。", "conclusion": "BoRP提供了一种高效且准确的评估方法，适用于大规模监控和敏感度测试。"}}
{"id": "2601.18252", "pdf": "https://arxiv.org/pdf/2601.18252", "abs": "https://arxiv.org/abs/2601.18252", "authors": ["Chao Wang", "Xuanying Li", "Cheng Dai", "Jinglei Feng", "Yuxiang Luo", "Yuqi Ouyang", "Hao Qin"], "title": "Co-PLNet: A Collaborative Point-Line Network for Prompt-Guided Wireframe Parsing", "categories": ["cs.CV", "cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "Wireframe parsing aims to recover line segments and their junctions to form a structured geometric representation useful for downstream tasks such as Simultaneous Localization and Mapping (SLAM). Existing methods predict lines and junctions separately and reconcile them post-hoc, causing mismatches and reduced robustness. We present Co-PLNet, a point-line collaborative framework that exchanges spatial cues between the two tasks, where early detections are converted into spatial prompts via a Point-Line Prompt Encoder (PLP-Encoder), which encodes geometric attributes into compact and spatially aligned maps. A Cross-Guidance Line Decoder (CGL-Decoder) then refines predictions with sparse attention conditioned on complementary prompts, enforcing point-line consistency and efficiency. Experiments on Wireframe and YorkUrban show consistent improvements in accuracy and robustness, together with favorable real-time efficiency, demonstrating our effectiveness for structured geometry perception.", "AI": {"tldr": "本文提出了一种点线协作框架Co-PLNet，用于提示引导的轮廓解析。", "motivation": "现有的方法预测线条和节点是分离进行的，并在后处理阶段协调它们，导致不一致性和减少的鲁棒性。为了改善这一问题，提出了Co-PLNet。", "method": "Co-PLNet通过点线协作框架交换空间提示，利用Point-Line Prompt Encoder编码几何属性成紧凑且空间对齐的地图；然后使用Cross-Guidance Line Decoder在稀疏注意下根据互补提示细化预测，提高点线一致性和效率。", "result": "实验显示Co-PLNet在精度和鲁棒性方面均有所提升，并具有实时效率。", "conclusion": "实验结果表明Co-PLNet有效提高了结构化几何感知的精度、鲁棒性和实时性能。"}}
{"id": "2601.18250", "pdf": "https://arxiv.org/pdf/2601.18250", "abs": "https://arxiv.org/abs/2601.18250", "authors": ["Kang Yu", "Dingyu Wang", "Zimu Yuan", "Nan Zhou", "Jiajun Liu", "Jiaxin Liu", "Shanggui Liu", "Yaoyan Zheng", "Huishu Yuan", "Di Huang", "Dong Jiang"], "title": "A multimodal vision foundation model for generalizable knee pathology", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Musculoskeletal disorders represent a leading cause of global disability, creating an urgent demand for precise interpretation of medical imaging. Current artificial intelligence (AI) approaches in orthopedics predominantly rely on task-specific, supervised learning paradigms. These methods are inherently fragmented, require extensive annotated datasets, and often lack generalizability across different modalities and clinical scenarios. The development of foundation models in this field has been constrained by the scarcity of large-scale, curated, and open-source musculoskeletal datasets. To address these challenges, we introduce OrthoFoundation, a multimodal vision foundation model optimized for musculoskeletal pathology. We constructed a pre-training dataset of 1.2 million unlabeled knee X-ray and MRI images from internal and public databases. Utilizing a Dinov3 backbone, the model was trained via self-supervised contrastive learning to capture robust radiological representations. OrthoFoundation achieves state-of-the-art (SOTA) performance across 14 downstream tasks. It attained superior accuracy in X-ray osteoarthritis diagnosis and ranked first in MRI structural injury detection. The model demonstrated remarkable label efficiency, matching supervised baselines using only 50% of labeled data. Furthermore, despite being pre-trained on knee images, OrthoFoundation exhibited exceptional cross-anatomy generalization to the hip, shoulder, and ankle. OrthoFoundation represents a significant advancement toward general-purpose AI for musculoskeletal imaging. By learning fundamental, joint-agnostic radiological semantics from large-scale multimodal data, it overcomes the limitations of conventional models, which provides a robust framework for reducing annotation burdens and enhancing diagnostic accuracy in clinical practice.", "AI": {"tldr": "介绍了一种多模态视觉基础模型OrthoFoundation，用于提高膝关节病理诊断的准确性和泛化能力。", "motivation": "当前AI方法在骨科中主要依赖特定任务、监督学习模式，这些方式存在数据需求大、标注繁琐和泛化性差的问题。为解决这些问题，提出一种多模态视觉基础模型OrthoFoundation。", "method": "使用1.2百万无标记的膝关节X光片和MRI图像构建预训练数据集，并通过自监督对比学习方法对Dinov3骨干网络进行训练。", "result": "OrthoFoundation在下游任务上达到SOTA水平，尤其在膝关节骨性关节炎诊断和MRI结构损伤检测中表现优越。它还展示了强大的跨解剖部位泛化能力。", "conclusion": "通过学习大规模多模态数据中的基本放射学语义，OrthoFoundation提供了一个减少标注负担、提高临床实践中诊断准确性的强大框架。"}}
{"id": "2601.18242", "pdf": "https://arxiv.org/pdf/2601.18242", "abs": "https://arxiv.org/abs/2601.18242", "authors": ["Zerui Kang", "Yishen Lim", "Zhouyou Gu", "Seung-Woo Ko", "Tony Q. S. Quek", "Jihong Park"], "title": "Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation", "categories": ["cs.CV", "cs.NI"], "comment": null, "summary": "Accurate radio-frequency (RF) material parameters are essential for electromagnetic digital twins in 6G systems, yet gradient-based inverse ray tracing (RT) remains sensitive to initialization and costly under limited measurements. This paper proposes a vision-language-model (VLM) guided framework that accelerates and stabilizes multi-material parameter estimation in a differentiable RT (DRT) engine. A VLM parses scene images to infer material categories and maps them to quantitative priors via an ITU-R material table, yielding informed conductivity initializations. The VLM further selects informative transmitter/receiver placements that promote diverse, material-discriminative paths. Starting from these priors, the DRT performs gradient-based refinement using measured received signal strengths. Experiments in NVIDIA Sionna on indoor scenes show 2-4$\\times$ faster convergence and 10-100$\\times$ lower final parameter error compared with uniform or random initialization and random placement baselines, achieving sub-0.1\\% mean relative error with only a few receivers. Complexity analyses indicate per-iteration time scales near-linearly with the number of materials and measurement setups, while VLM-guided placement reduces the measurements required for accurate recovery. Ablations over RT depth and ray counts confirm further accuracy gains without significant per-iteration overhead. Results demonstrate that semantic priors from VLMs effectively guide physics-based optimization for fast and reliable RF material estimation.", "AI": {"tldr": "提出了一种基于视觉语言模型的可微分光线追踪框架，以加速和稳定多材料射频参数估计。", "motivation": "准确的射频材料参数对6G系统的电磁数字孪生至关重要，但现有的基于梯度的反向光线追踪技术在初始化敏感且测量受限时成本高昂。为此提出了一种新的方法来解决这些问题。", "method": "利用视觉语言模型解析场景图像以推断材料类别，并通过ITU-R材料表将其映射到定量先验值上。该模型还选择信息丰富的发射器/接收器位置，促进多样化的材料分辨路径。基于这些先验知识，可微分光线追踪引擎执行梯度细化。", "result": "实验表明，在NVIDIA Sionna上的室内场景中，与均匀或随机初始化和放置基线相比，该方法实现了2-4倍的收敛速度提高和10-100倍的最终参数误差降低。复杂性分析显示每轮迭代时间几乎线性地随材料数量和测量设置增加。", "conclusion": "结果表明，视觉语言模型提供的语义先验能够有效地指导基于物理的优化过程，从而实现快速且可靠的射频材料估计。"}}
{"id": "2601.18241", "pdf": "https://arxiv.org/pdf/2601.18241", "abs": "https://arxiv.org/abs/2601.18241", "authors": ["Elena Bruches", "Vadim Alperovich", "Dari Baturova", "Roman Derunets", "Daniil Grebenkin", "Georgy Mkrtchyan", "Oleg Sedukhin", "Mikhail Klementev", "Ivan Bondarenko", "Nikolay Bushkov", "Stanislav Moiseev"], "title": "TAM-Eval: Evaluating LLMs for Automated Unit Test Maintenance", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted for publication at the 9th Workshop on Validation, Analysis and Evolution of Software Tests (VST 2026), co-located with the the 33rd IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER 2026)", "summary": "While Large Language Models (LLMs) have shown promise in software engineering, their application to unit testing remains largely confined to isolated test generation or oracle prediction, neglecting the broader challenge of test suite maintenance. We introduce TAM-Eval (Test Automated Maintenance Evaluation), a framework and benchmark designed to evaluate model performance across three core test maintenance scenarios: creation, repair, and updating of test suites. Unlike prior work limited to function-level tasks, TAM-Eval operates at the test file level, while maintaining access to full repository context during isolated evaluation, better reflecting real-world maintenance workflows. Our benchmark comprises 1,539 automatically extracted and validated scenarios from Python, Java, and Go projects. TAM-Eval supports system-agnostic evaluation of both raw LLMs and agentic workflows, using a reference-free protocol based on test suite pass rate, code coverage, and mutation testing. Empirical results indicate that state-of-the-art LLMs have limited capabilities in realistic test maintenance processes and yield only marginal improvements in test effectiveness. We release TAM-Eval as an open-source framework to support future research in automated software testing. Our data and code are publicly available at https://github.com/trndcenter/TAM-Eval.", "AI": {"tldr": "TAM-Eval框架用于评估大型语言模型在自动化单元测试维护方面的性能，包括创建、修复和更新测试套件。", "motivation": "现有的研究主要集中在孤立的测试生成或预言预测上，忽略了更广泛的测试套件维护挑战。因此需要一个全面评估LLM能力的新框架。", "method": "TAM-Eval是一个基准框架，包含1539个从Python、Java和Go项目中自动提取并验证过的场景。它在测试文件级别操作，并保持对完整仓库上下文的访问。采用基于通过率、代码覆盖率和变异测试的无参考协议进行评估。", "result": "最先进的LLM在现实世界的测试维护过程中表现出有限的能力，仅能提供边际改善。", "conclusion": "TAM-Eval作为一个开源框架被发布以支持未来在自动化软件测试方面的研究。数据和代码已公开提供。"}}
{"id": "2601.18240", "pdf": "https://arxiv.org/pdf/2601.18240", "abs": "https://arxiv.org/abs/2601.18240", "authors": ["Mengyuan Jin", "Zehui Liao", "Yong Xia"], "title": "V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have shown remarkable capability in assisting disease diagnosis in medical visual question answering (VQA). However, their outputs remain vulnerable to hallucinations (i.e., responses that contradict visual facts), posing significant risks in high-stakes medical scenarios. Recent introspective detection methods, particularly uncertainty-based approaches, offer computational efficiency but are fundamentally indirect, as they estimate predictive uncertainty for an image-question pair rather than verifying the factual correctness of a specific answer. To address this limitation, we propose Visual Logical Loop Verification (V-Loop), a training-free and plug-and-play framework for hallucination detection in medical VQA. V-Loop introduces a bidirectional reasoning process that forms a visually grounded logical loop to verify factual correctness. Given an input, the MLLM produces an answer for the primary input pair. V-Loop extracts semantic units from the primary QA pair, generates a verification question by conditioning on the answer unit to re-query the question unit, and enforces visual attention consistency to ensure answering both primary question and verification question rely on the same image evidence. If the verification answer matches the expected semantic content, the logical loop closes, indicating factual grounding; otherwise, the primary answer is flagged as hallucinated. Extensive experiments on multiple medical VQA benchmarks and MLLMs show that V-Loop consistently outperforms existing introspective methods, remains highly efficient, and further boosts uncertainty-based approaches when used in combination.", "AI": {"tldr": "V-Loop提出了一种用于医疗视觉问答中幻觉检测的训练免费和可插拔框架。", "motivation": "多模态大语言模型在辅助疾病诊断中的输出易受违反视觉事实的幻觉影响，现有基于不确定性的方法虽高效但间接，因此开发直接验证答案正确性的方法至关重要。", "method": "V-Loop通过双向推理过程形成视觉逻辑循环来验证答案的事实准确性。它从原始问答对中提取语义单元，生成验证问题并强制执行视觉注意力一致性，以确保两个问题的回答基于相同图像证据。", "result": "实验显示，V-Loop在多个医疗视觉问答基准和多模态大语言模型上优于现有方法，并且与不确定性方法结合使用时进一步提升性能。", "conclusion": "通过引入视觉逻辑循环验证机制，V-Loop有效地检测了幻觉问题并提高了答案的准确性。"}}
{"id": "2601.18239", "pdf": "https://arxiv.org/pdf/2601.18239", "abs": "https://arxiv.org/abs/2601.18239", "authors": ["Sizhe Cheng", "Feng Liang", "Yuhan Wen", "Xipei Yu", "Yong Wang"], "title": "Probing the Future of Meta-Analysis: Eliciting Design Principles via an Agentic Research IDE", "categories": ["cs.HC"], "comment": null, "summary": "Meta-analyses and systematic reviews demand rigorous abductive reasoning to build, test, and refine hypotheses across vast, heterogeneous literature. While NLP advancements have automated parts of this pipeline, existing tools often detach researchers from the cognitive loop or function merely as retrieval engines, leading to loss of intellectual ownership and frequent context switching. We present Research IDE, a prototype reimagining authoring environments through the \"Research as Code\" metaphor. Research IDE embeds a multi-agent backend into the writing flow, enabling in-situ verification via \"hypothesis breakpoints.\" A one-week field deployment with 8 domain experts, followed by a reflective workshop, as a Research through Design (RtD) probe, reveals that users strongly preferred this verification workflow, actively leveraged prior knowledge for confirmation, and reported that breakpoints sparked insights. Drawing from participant feedback and suggestions, we derive design implications for future AI-assisted research tools that fully preserve researcher autonomy and intellectual ownership while harnessing computational scale.", "AI": {"tldr": "本文提出了一种新的研究工具Research IDE，它通过“代码写作”的比喻来重塑作者环境，并在撰写过程中嵌入多代理后台以实现即时验证。", "motivation": "现有NLP工具往往将研究人员排除在认知循环之外或仅作为检索引擎使用，导致了知识所有权的丧失和频繁切换上下文的问题。本文旨在开发一种新的研究辅助工具，既能利用计算规模又能完全保护研究人员的自主权和知识所有权。", "method": "通过一周的领域部署与8位领域的专家合作，并后续进行反思工作坊，作为设计探针来评估这种新的写作环境的有效性。", "result": "用户强烈偏好这种即时验证的工作流，能够积极利用先前的知识来进行确认，并报告说这些停顿激发了洞察力。", "conclusion": "基于参与者反馈和建议，未来的人工智能辅助研究工具应当全面保留研究人员的自主权和知识所有权的同时利用计算规模。"}}
{"id": "2601.18238", "pdf": "https://arxiv.org/pdf/2601.18238", "abs": "https://arxiv.org/abs/2601.18238", "authors": ["Tafazzul Nadeem", "Bhavik Shangari", "Manish Rai", "Gagan Raj Gupta", "Ashutosh Modi"], "title": "TechING: Towards Real World Technical Image Understanding via VLMs", "categories": ["cs.CL", "cs.CV", "cs.LG"], "comment": "Accepted at Findings of EACL 2026, 30 Pages (9 Pages main paper + 4 pages references + 17 pages appendix)", "summary": "Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x.", "AI": {"tldr": "通过生成大量合成技术图像数据集来提升视觉语言模型对实际手绘图的理解能力。", "motivation": "现代VLM在理解技术图纸方面表现不佳，无法有效辅助专业人员后期编辑图纸。为此，研究者希望通过自监督任务和人工标注的小规模真实世界图像集合提高现有模型的能力。", "method": "构建了一个大型合成数据集，模仿实际手绘图片，并引入了几个新的自我监督任务来训练视觉语言模型；最终使用Llama 3.2 11B-instruct模型进行了微调，产生了LLama-VL-TUG模型。", "result": "实验表明，与基线模型相比，LLama-VL-TUG模型在合成图像上的ROUGE-L性能提高了2.14倍，并且在真实世界的手绘图上实现了更低的编译错误率和更高的F1得分（提升了6.97倍）。", "conclusion": "这项工作证明了通过自监督任务训练及微调视觉语言模型，可以在实际手绘技术图像理解方面取得显著进步。"}}
{"id": "2601.18234", "pdf": "https://arxiv.org/pdf/2601.18234", "abs": "https://arxiv.org/abs/2601.18234", "authors": ["Abdulaziz AlDakheel", "Ali Alshehre", "Esraa Alamoudi", "Moslim AlKhabbaz", "Ahmed Aljohani", "Raed Alharbi"], "title": "Generative AI in Saudi Arabia: A National Survey of Adoption, Risks, and Public Perceptions", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": null, "summary": "Generative Artificial Intelligence (GenAI) is rapidly becoming embedded in Saudi Arabia's digital transformation under Vision 2030, yet public awareness, adoption, and concerns surrounding these tools remain underexplored. This study provides an early snapshot of GenAI engagement among Saudi nationals. Using a nationwide survey of 330 participants across regions, age groups, and employment sectors, we examine seven dimensions of GenAI use: awareness and understanding, adoption patterns, perceived impacts, training needs, risks and barriers, data-sharing behaviors, and future expectations. Findings show that 93% of respondents actively use GenAI primarily for text-based tasks, while more advanced uses such as programming or multimodal generation are less common. Despite the prevalence of use, overall awareness and conceptual understanding remain uneven, with many reporting limited technical knowledge. Participants recognize GenAI's benefits for productivity, work quality, and understanding complex information, yet caution that sustained reliance may undermine critical thinking and key professional skills. Trust in AI-generated outputs remains cautious, with widespread concerns about privacy, misinformation, and ethical misuse, including potential job displacement. Respondents show strong interest in structured GenAI training that combines foundational skills, domain-specific applications, and clear guidance on privacy, ethics, and responsible use. These results establish a baseline for GenAI engagement in Saudi Arabia and highlight priorities for policymakers and developers: expanding AI literacy, ensuring culturally and linguistically aligned GenAI solutions, and strengthening frameworks for privacy and responsible deployment.", "AI": {"tldr": "该研究通过全国范围内的调查，探讨了沙特阿拉伯国民对生成式人工智能（GenAI）的认知、使用模式以及对其风险和未来的期望。", "motivation": "在沙特阿拉伯的数字化转型背景下，生成式人工智能正在迅速普及，但其公众认知、采用情况及潜在风险尚未充分探索。该研究旨在填补这一空白，并为政策制定者提供初步见解。", "method": "通过全国范围内对330名参与者进行调查，从七个维度评估了GenAI的使用：意识和理解、采纳模式、感知影响、培训需求、风险与障碍、数据共享行为及未来期望。", "result": "结果显示，93%受访者积极使用GenAI主要用于文本任务；尽管普及率高，但整体认知和技术知识仍存在差距。参与者认为GenAI能提升生产力和工作质量，并担忧其对批判性思维的潜在负面影响。隐私与伦理问题是主要顾虑点。", "conclusion": "该研究为沙特阿拉伯国民在生成式人工智能领域的参与情况提供了基准数据，并强调了政策制定者需关注扩大AI素养、确保文化及语言适应性的解决方案，以及加强隐私和负责任使用框架的重要性。"}}
{"id": "2601.18231", "pdf": "https://arxiv.org/pdf/2601.18231", "abs": "https://arxiv.org/abs/2601.18231", "authors": ["Trong Khiem Tran", "Manh Cuong Dao", "Phi Le Nguyen", "Thao Nguyen Truong", "Trong Nghia Hoang"], "title": "Rethinking Cross-Modal Fine-Tuning: Optimizing the Interaction between Feature Alignment and Target Fitting", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted AISTATS 20226. Preprint version", "summary": "Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration.~A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer.~This requires combining feature alignment with target fine-tuning, but uncalibrated combinations can exacerbate misalignment between the source and target feature-label structures and reduce target generalization.~Existing work however lacks a theoretical understanding of this critical interaction between feature alignment and target fitting.~To bridge this gap, we develop a principled framework that establishes a provable generalization bound on the target error, which explains the interaction between feature alignment and target fitting through a novel concept of feature-label distortion.~This bound offers actionable insights into how this interaction should be optimized for practical algorithm design. The resulting approach achieves significantly improved performance over state-of-the-art methods across a wide range of benchmark datasets.", "AI": {"tldr": "重新思考跨模态微调，优化特征对齐与目标拟合之间的交互", "motivation": "现有工作在理解和结合特征对齐与目标拟合方面存在理论空白，导致知识迁移中的误差增大和泛化能力下降。", "method": "通过引入一个新的概念——特征标签失真来解释两者间的相互作用，并建立了可证明的一般化界限，为优化算法设计提供了实用见解。", "result": "所提出的方法在一系列基准数据集上显著优于现有最佳方法", "conclusion": "该研究填补了关于跨模态微调中关键交互理论理解的空白，提供了一种新的视角来理解和改进这一过程。"}}
{"id": "2601.18228", "pdf": "https://arxiv.org/pdf/2601.18228", "abs": "https://arxiv.org/abs/2601.18228", "authors": ["Sahil Naik", "Soham Bagayatkar", "Pavankumar Singh"], "title": "Facial Emotion Recognition on FER-2013 using an EfficientNetB2-Based Approach", "categories": ["cs.CV", "cs.LG"], "comment": "6 pages, 4 figures", "summary": "Detection of human emotions based on facial images in real-world scenarios is a difficult task due to low image quality, variations in lighting, pose changes, background distractions, small inter-class variations, noisy crowd-sourced labels, and severe class imbalance, as observed in the FER-2013 dataset of 48x48 grayscale images. Although recent approaches using large CNNs such as VGG and ResNet achieve reasonable accuracy, they are computationally expensive and memory-intensive, limiting their practicality for real-time applications. We address these challenges using a lightweight and efficient facial emotion recognition pipeline based on EfficientNetB2, trained using a two-stage warm-up and fine-tuning strategy. The model is enhanced with AdamW optimization, decoupled weight decay, label smoothing (epsilon = 0.06) to reduce annotation noise, and clipped class weights to mitigate class imbalance, along with dropout, mixed-precision training, and extensive real-time data augmentation. The model is trained using a stratified 87.5%/12.5% train-validation split while keeping the official test set intact, achieving a test accuracy of 68.78% with nearly ten times fewer parameters than VGG16-based baselines. Experimental results, including per-class metrics and learning dynamics, demonstrate stable training and strong generalization, making the proposed approach suitable for real-time and edge-based applications.", "AI": {"tldr": "基于EfficientNetB2的轻量级面部情感识别方法", "motivation": "提高在FER-2013数据集上的面部表情识别准确性，同时解决计算和内存消耗高的问题，以适应实时应用的需求。", "method": "采用两阶段预热和微调策略训练模型，并使用AdamW优化、去耦权重衰减、标签平滑等技术增强模型性能；引入dropout、混合精度训练以及大量的实时数据增强来改善模型泛化能力。", "result": "测试准确率达到68.78%，参数量仅为VGG16基线的十分之一，表现出良好的稳定性和泛化性。", "conclusion": "提出的方法在FER-2013数据集上实现了高精度和低资源消耗，适用于实时和边缘计算环境。"}}
{"id": "2601.18226", "pdf": "https://arxiv.org/pdf/2601.18226", "abs": "https://arxiv.org/abs/2601.18226", "authors": ["Haotian Li", "Shijun Yang", "Weizhen Qi", "Silei Zhao", "Rui Hua", "Mingzhu Song", "Xiaojian Yang", "Chao Peng"], "title": "Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks", "categories": ["cs.AI"], "comment": null, "summary": "Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.", "AI": {"tldr": "提出了一种名为Yunjue Agent的系统，该系统能够在开放环境下通过自我进化来解决任务。", "motivation": "传统代理系统在动态、无监督的环境中的适应性差，因此提出了In-Situ Self-Evolving范式以增强其持续学习能力。", "method": "开发了Yunjue Agent系统，采用迭代合成和优化工具的方法来处理新出现的任务挑战，并引入并行批量进化策略以提高效率。", "result": "在零起点设置下进行的实证评估显示，在五个不同的基准测试中表现出显著优于现有方法的表现。此外，积累的知识能够转移到新的领域。", "conclusion": "Yunjue Agent系统为开发自适应、自我演化的智能代理提供了一个有效的方法，并公开了代码库和工具以供未来研究使用。"}}
{"id": "2601.18225", "pdf": "https://arxiv.org/pdf/2601.18225", "abs": "https://arxiv.org/abs/2601.18225", "authors": ["Pei Wang", "Yanan Wu", "Xiaoshuai Song", "Weixun Wang", "Gengru Chen", "Zhongwen Li", "Kezhong Yan", "Ken Deng", "Qi Liu", "Shuaibing Zhao", "Shaopan Xiong", "Xuepeng Liu", "Xuefeng Chen", "Wanxi Deng", "Wenbo Su", "Bo Zheng"], "title": "ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants", "categories": ["cs.AI"], "comment": null, "summary": "Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator.", "AI": {"tldr": "论文介绍了ShopSimulator，一个用于评估和训练大型语言模型（LLM）代理的购物模拟环境。", "motivation": "现有的研究缺乏一个统一的模拟环境来全面捕捉所有这些方面，并且只关注于评价基准而没有训练支持。因此，本文提出了一个大规模和具有挑战性的中文购物环境ShopSimulator。", "method": "通过ShopSimulator评估LLM代理在各种场景中的表现，发现即使是最好的模型也仅能达到不到40%的成功率。进一步探索了如何克服这些弱点的培训方法，并发现在监督微调（SFT）与强化学习（RL）结合的情况下性能有显著提高。", "result": "实验结果显示，即使是最优秀的模型在深度搜索和产品选择等任务中成功率也低于40%，并且难以平衡个性化信息使用和有效互动。通过进一步探索训练方法，发现将监督微调（SFT）与强化学习（RL）相结合能显着提升性能。", "conclusion": "论文提出了一个用于评估LLM代理的ShopSimulator环境，并通过对模型表现的深入分析提供了实用指导来改进其能力。"}}
{"id": "2601.18222", "pdf": "https://arxiv.org/pdf/2601.18222", "abs": "https://arxiv.org/abs/2601.18222", "authors": ["Mengfan He", "Liangzheng Sun", "Chunyu Li", "Ziyang Meng"], "title": "HomoFM: Deep Homography Estimation with Flow Matching", "categories": ["cs.CV"], "comment": null, "summary": "Deep homography estimation has broad applications in computer vision and robotics. Remarkable progresses have been achieved while the existing methods typically treat it as a direct regression or iterative refinement problem and often struggling to capture complex geometric transformations or generalize across different domains. In this work, we propose HomoFM, a new framework that introduces the flow matching technique from generative modeling into the homography estimation task for the first time. Unlike the existing methods, we formulate homography estimation problem as a velocity field learning problem. By modeling a continuous and point-wise velocity field that transforms noisy distributions into registered coordinates, the proposed network recovers high-precision transformations through a conditional flow trajectory. Furthermore, to address the challenge of domain shifts issue, e.g., the cases of multimodal matching or varying illumination scenarios, we integrate a gradient reversal layer (GRL) into the feature extraction backbone. This domain adaptation strategy explicitly constrains the encoder to learn domain-invariant representations, significantly enhancing the network's robustness. Extensive experiments demonstrate the effectiveness of the proposed method, showing that HomoFM outperforms state-of-the-art methods in both estimation accuracy and robustness on standard benchmarks. Code and data resource are available at https://github.com/hmf21/HomoFM.", "AI": {"tldr": "提出了一种新的框架HomoFM，用于深度同态变换估计。", "motivation": "现有的方法通常将同态变换估计视为直接回归或迭代优化问题，并且难以捕捉复杂的几何变换或者在不同场景下泛化。", "method": "引入了流匹配技术来解决同态变换估计的问题。通过建模连续的点对点速度场，该框架可以恢复出高精度的变换并通过条件流量轨迹进行学习。此外，集成梯度反转层以提高特征提取器的领域不变性。", "result": "实验结果表明，HomoFM在标准基准测试上的表现优于现有的最先进方法，在估计准确性和鲁棒性方面都有提升。", "conclusion": "所提出的流匹配框架显著增强了同态变换估计的能力，并且通过梯度反转层提高了网络的领域适应能力。"}}
{"id": "2601.18220", "pdf": "https://arxiv.org/pdf/2601.18220", "abs": "https://arxiv.org/abs/2601.18220", "authors": ["Bingshen Mu", "Xian Shi", "Xiong Wang", "Hexin Liu", "Jin Xu", "Lei Xie"], "title": "LLM-ForcedAligner: A Non-Autoregressive and Accurate LLM-Based Forced Aligner for Multilingual and Long-Form Speech", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Forced alignment (FA) predicts start and end timestamps for words or characters in speech, but existing methods are language-specific and prone to cumulative temporal shifts. The multilingual speech understanding and long-sequence processing abilities of speech large language models (SLLMs) make them promising for FA in multilingual, crosslingual, and long-form speech settings. However, directly applying the next-token prediction paradigm of SLLMs to FA results in hallucinations and slow inference. To bridge the gap, we propose LLM-ForcedAligner, reformulating FA as a slot-filling paradigm: timestamps are treated as discrete indices, and special timestamp tokens are inserted as slots into the transcript. Conditioned on the speech embeddings and the transcript with slots, the SLLM directly predicts the time indices at slots. During training, causal attention masking with non-shifted input and label sequences allows each slot to predict its own timestamp index based on itself and preceding context, with loss computed only at slot positions. Dynamic slot insertion enables FA at arbitrary positions. Moreover, non-autoregressive inference is supported, avoiding hallucinations and improving speed. Experiments across multilingual, crosslingual, and long-form speech scenarios show that LLM-ForcedAligner achieves a 69%~78% relative reduction in accumulated averaging shift compared with prior methods. The checkpoint and inference code will be released later.", "AI": {"tldr": "本文提出了一种基于大语言模型的非自回归强制对齐器LLM-ForcedAligner，用于解决多语种和长文本语音对齐问题。", "motivation": "现有强制对准时方法是语言特定且易累积时间偏差。利用SLLMs在多语言、跨语言及长序列处理能力的优势进行改进。", "method": "通过将强制对齐任务重新定义为插槽填充范式，直接预测插入位置的时间戳索引，采用非自回归推理避免幻觉和提高速度。", "result": "实验显示，LLM-ForcedAligner相比先前方法在多语言、跨语言及长文本语音场景中减少了69%~78%的累积平均时间偏差。", "conclusion": "提出了高效的非自回归强制对齐器LLM-ForcedAligner，在多种语音处理任务中表现出色。"}}
{"id": "2601.18219", "pdf": "https://arxiv.org/pdf/2601.18219", "abs": "https://arxiv.org/abs/2601.18219", "authors": ["Che-Yung Shen", "Xilin Yang", "Yuzhu Li", "Leon Lenk", "Aydogan Ozcan"], "title": "Automated HER2 scoring with uncertainty quantification using lensfree holography and deep learning", "categories": ["physics.med-ph", "cs.CV", "cs.LG"], "comment": "23 Pages, 6 Figures, 1 Table", "summary": "Accurate assessment of human epidermal growth factor receptor 2 (HER2) expression is critical for breast cancer diagnosis, prognosis, and therapy selection; yet, most existing digital HER2 scoring methods rely on bulky and expensive optical systems. Here, we present a compact and cost-effective lensfree holography platform integrated with deep learning for automated HER2 scoring of immunohistochemically stained breast tissue sections. The system captures lensfree diffraction patterns of stained HER2 tissue sections under RGB laser illumination and acquires complex field information over a sample area of ~1,250 mm^2 at an effective throughput of ~84 mm^2 per minute. To enhance diagnostic reliability, we incorporated an uncertainty quantification strategy based on Bayesian Monte Carlo dropout, which provides autonomous uncertainty estimates for each prediction and supports reliable, robust HER2 scoring, with an overall correction rate of 30.4%. Using a blinded test set of 412 unique tissue samples, our approach achieved a testing accuracy of 84.9% for 4-class (0, 1+, 2+, 3+) HER2 classification and 94.8% for binary (0/1+ vs. 2+/3+) HER2 scoring with uncertainty quantification. Overall, this lensfree holography approach provides a practical pathway toward portable, high-throughput, and cost-effective HER2 scoring, particularly suited for resource-limited settings, where traditional digital pathology infrastructure is unavailable.", "AI": {"tldr": "本文提出了一种基于镜头自由全息技术和深度学习的自动化HER2评分方法，用于乳腺癌组织切片评估。", "motivation": "准确评估HER2表达对乳腺癌诊断、预后及治疗选择至关重要。大多数现有的数字HER2评分方法依赖于体积大且昂贵的光学系统。因此，开发一种便携式、高通量和成本效益高的HER2评分方案的需求迫切。", "method": "研究利用镜头自由全息技术捕获激光照射下的样品衍射图案，并结合RGB光源信息获取样本区域内的复杂场信息。引入基于贝叶斯蒙特卡罗的不确定性量化策略，提高诊断可靠性。", "result": "该方法在412个盲测组织样本中实现了84.9%的整体分类准确率和高达94.8%的二元HER2评分准确性，并提供了每个预测的自主不确定性估计。", "conclusion": "所提出的镜头自由全息法为资源受限环境中的便携式、高通量和成本效益高的HER2评分提供了一种可行途径。"}}
{"id": "2601.18218", "pdf": "https://arxiv.org/pdf/2601.18218", "abs": "https://arxiv.org/abs/2601.18218", "authors": ["Meziah Ruby Cristobal", "Hyeonjeong Byeon", "Tze-Yu Chen", "Ruoxi Shang", "Donghoon Shin", "Ruican Zhong", "Tony Zhou", "Gary Hsieh"], "title": "PaperTok: Exploring the Use of Generative AI for Creating Short-form Videos for Research Communication", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": ":H.5.2; I.2.7", "summary": "The dissemination of scholarly research is critical, yet researchers often lack the time and skills to create engaging content for popular media such as short-form videos. To address this gap, we explore the use of generative AI to help researchers transform their academic papers into accessible video content. Informed by a formative study with science communicators and content creators (N=8), we designed PaperTok, an end-to-end system that automates the initial creative labor by generating script options and corresponding audiovisual content from a source paper. Researchers can then refine based on their preferences with further prompting. A mixed-methods user study (N=18) and crowdsourced evaluation (N=100) demonstrate that PaperTok's workflow can help researchers create engaging and informative short-form videos. We also identified the need for more fine-grained controls in the creation process. To this end, we offer implications for future generative tools that support science outreach.", "AI": {"tldr": "研究介绍了PaperTok系统，该系统利用生成式AI将学术论文转化为短视频。", "motivation": "研究人员缺乏时间与技能制作吸引人的短视频内容来传播研究成果。为解决这一问题，作者探索了使用生成式人工智能来帮助研究员把他们的科研成果转化成易于理解的视频。", "method": "基于对8名科学传播者和内容创作者的研究，设计了一个端到端系统PaperTok，该系统可以自动生成脚本选项以及相应的视听材料。用户可以通过进一步提示进行修改以符合个人偏好。之后通过混合方法用户研究（N=18）及众包评估（N=100）来验证其效果。", "result": "研究表明，PaperTok的工作流程可以帮助研究人员创作出引人入胜且具有信息量的短视频。同时发现需要更细致的过程控制功能以优化生成过程。", "conclusion": "研究展示了使用AI工具支持科研成果传播的可能性，并提出未来工作方向以增强此类工具的功能和效果"}}
{"id": "2601.18217", "pdf": "https://arxiv.org/pdf/2601.18217", "abs": "https://arxiv.org/abs/2601.18217", "authors": ["Zhihan Liu", "Lin Guan", "Yixin Nie", "Kai Zhang", "Zhuoqun Hao", "Lin Chen", "Asli Celikyilmaz", "Zhaoran Wang", "Na Zhang"], "title": "Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.", "AI": {"tldr": "研究了在未知测试域中，强化学习环境和建模选择如何影响通用语言模型代理的跨领域泛化能力。", "motivation": "探讨了通用语言模型代理在未经见的环境中部署时的表现挑战，并分析了哪些因素对跨领域性能有显著影响。", "method": "通过增加状态信息丰富度来提升跨域鲁棒性，提出了向环境添加少量无关特征的方法。同时研究了SFT预训练和逐步思考策略的影响。", "result": "发现状态信息丰富度与规划复杂性是主要因素，而领域真实性和文本相似性不是关键因素；在RL中增加状态信息可以有效提高跨域泛化能力；SFT预训练有助于防止遗忘但会降低未包含任务的泛化性能。", "conclusion": "揭示了影响通用语言模型代理跨领域泛化的环境和建模选择的关键要素，提出了改进策略以增强其适应性。"}}
{"id": "2601.18207", "pdf": "https://arxiv.org/pdf/2601.18207", "abs": "https://arxiv.org/abs/2601.18207", "authors": ["James Burgess", "Jan N. Hansen", "Duo Peng", "Yuhui Zhang", "Alejandro Lozano", "Min Woo Sun", "Emma Lundberg", "Serena Yeung-Levy"], "title": "PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "comment": "EACL 2026", "summary": "Search agents are language models (LMs) that reason and search knowledge bases (or the web) to answer questions; recent methods supervise only the final answer accuracy using reinforcement learning with verifiable rewards (RLVR). Most RLVR search agents tackle general-domain QA, which limits their relevance to technical AI systems in science, engineering, and medicine. In this work we propose training agents to search and reason over scientific papers -- this tests technical question-answering, it is directly relevant to real scientists, and the capabilities will be crucial to future AI Scientist systems. Concretely, we release a search corpus of 16 million biomedical paper abstracts and construct a challenging factoid QA dataset called PaperSearchQA with 60k samples answerable from the corpus, along with benchmarks. We train search agents in this environment to outperform non-RL retrieval baselines; we also perform further quantitative analysis and observe interesting agent behaviors like planning, reasoning, and self-verification. Our corpus, datasets, and benchmarks are usable with the popular Search-R1 codebase for RLVR training and released on https://huggingface.co/collections/jmhb/papersearchqa. Finally, our data creation methods are scalable and easily extendable to other scientific domains.", "AI": {"tldr": "提出了一种新的搜索和推理科学论文的方法，使用强化学习验证奖励（RLVR）训练智能代理。", "motivation": "现有方法主要关注通用领域的问答任务，忽略了对技术AI系统的重要性。本文旨在通过训练能够搜索并推理科学论文的代理来解决这一问题。", "method": "构建了一个包含1600万篇生物医学论文摘要的数据集和一个具有挑战性的PaperSearchQA数据集，并使用RLVR方法进行实验。", "result": "所提出的智能代理在技术问答任务上优于非RL检索基线，表现出计划、推理和自我验证的能力。", "conclusion": "提出的方法为未来AI科学家系统提供了关键能力，并且创建的数据集及其生成方法具有可扩展性和易用性。"}}
{"id": "2601.18202", "pdf": "https://arxiv.org/pdf/2601.18202", "abs": "https://arxiv.org/abs/2601.18202", "authors": ["Fangyuan Xu", "Rujun Han", "Yanfei Chen", "Zifeng Wang", "I-Hung Hsu", "Jun Yan", "Vishy Tirumalashetty", "Eunsol Choi", "Tomas Pfister", "Chen-Yu Lee"], "title": "SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback", "categories": ["cs.AI"], "comment": null, "summary": "Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training.", "AI": {"tldr": "SAGE是一种用于深度搜索代理的自动生成高质量问题答案对的方法，通过交互式反馈提高数据质量和难度。", "motivation": "收集复杂探索路径的人类注释对于训练能够回答跨多文档推理问题的深度搜索代理来说成本过高。因此需要一种自动方法来生成这些问题的答案对以降低人力成本。", "method": "SAGE由一个提出QA对的数据生成器和一个试图解决所提问题并提供执行反馈的搜索引擎组成，通过多次迭代改进数据的质量和难度。", "result": "实验表明，SAGE能够生成需要多样化推理策略的问题，并且显著提高了合成数据的正确性和复杂度。在流行深度搜索基准上训练时，性能提升了23%。", "conclusion": "SAGE为自动生成适合特定难度水平的数据提供了一种有效的方法，使得代理能够在不额外训练的情况下适应从固定文档检索到通用搜索引擎环境的任务迁移。"}}
{"id": "2601.18200", "pdf": "https://arxiv.org/pdf/2601.18200", "abs": "https://arxiv.org/abs/2601.18200", "authors": ["Chenyu Zhang", "Xinchen Lyu", "Chenshan Ren", "Shuhan Liu", "Qimei Cui", "Xiaofeng Tao"], "title": "HeterCSI: Channel-Adaptive Heterogeneous CSI Pretraining Framework for Generalized Wireless Foundation Models", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 8 figures", "summary": "Wireless foundation models promise transformative capabilities for channel state information (CSI) processing across diverse 6G network applications, yet face fundamental challenges due to the inherent dual heterogeneity of CSI across both scale and scenario dimensions. However, current pretraining approaches either constrain inputs to fixed dimensions or isolate training by scale, limiting the generalization and scalability of wireless foundation models. In this paper, we propose HeterCSI, a channel-adaptive pretraining framework that reconciles training efficiency with robust cross-scenario generalization via a new understanding of gradient dynamics in heterogeneous CSI pretraining. Our key insight reveals that CSI scale heterogeneity primarily causes destructive gradient interference, while scenario diversity actually promotes constructive gradient alignment when properly managed. Specifically, we formulate heterogeneous CSI batch construction as a partitioning optimization problem that minimizes zero-padding overhead while preserving scenario diversity. To solve this, we develop a scale-aware adaptive batching strategy that aligns CSI samples of similar scales, and design a double-masking mechanism to isolate valid signals from padding artifacts. Extensive experiments on 12 datasets demonstrate that HeterCSI establishes a generalized foundation model without scenario-specific finetuning, achieving superior average performance over full-shot baselines. Compared to the state-of-the-art zero-shot benchmark WiFo, it reduces NMSE by 7.19 dB, 4.08 dB, and 5.27 dB for CSI reconstruction, time-domain, and frequency-domain prediction, respectively. The proposed HeterCSI framework also reduces training latency by 53% compared to existing approaches while improving generalization performance by 1.53 dB on average.", "AI": {"tldr": "HeterCSI是一种针对6G网络应用中异构信道状态信息(CSI)处理的通用无线基础模型预训练框架。", "motivation": "现有的预训练方法在输入固定维度或按规模隔离训练时，限制了无线基础模型的泛化和可扩展性。因此，提出了HeterCSI以解决这些问题，并提高跨场景泛化的效率与性能。", "method": "通过将异构CSI批处理构建为零填充冗余最小化同时保持情景多样性的优化问题，设计了一种尺度感知自适应批量策略来对齐类似尺度的CSI样本。并开发了一种双掩蔽机制以隔离有效信号和填充伪影。", "result": "HeterCSI在12个数据集上表现出了优越的平均性能，相比全镜头基准线降低了NMSE，并且减少了53%的训练延迟，同时提升了1.53dB的泛化性能。与最先进的零镜头基准WiFo相比，在CSI重建、时域预测和频域预测方面分别降低7.19 dB、4.08 dB和5.27 dB。", "conclusion": "HeterCSI框架通过解决异构CSI预训练中的梯度动态问题，建立了无需场景特定微调的通用基础模型，并在多个关键性能指标上超越了现有方法。"}}
{"id": "2601.18197", "pdf": "https://arxiv.org/pdf/2601.18197", "abs": "https://arxiv.org/abs/2601.18197", "authors": ["Shaokang Wang", "Pei Fu", "Ruoceng Zhang", "Shaojie Zhang", "Xiuwen Xi", "Jiahui Yang", "Bin Qin", "Ying Huang", "Zhenbo Luo", "Jian Luan"], "title": "GAIA: A Data Flywheel System for Training GUI Test-Time Scaling Critic Models", "categories": ["cs.AI"], "comment": null, "summary": "While Large Vision-Language Models (LVLMs) have significantly advanced GUI agents' capabilities in parsing textual instructions, interpreting screen content, and executing tasks, a critical challenge persists: the irreversibility of agent operations, where a single erroneous action can trigger catastrophic deviations. To address this, we propose the GUI Action Critic's Data Flywheel System (GAIA), a training framework that enables the models to have iterative critic capabilities, which are used to improve the Test-Time Scaling (TTS) of basic GUI agents' performance. Specifically, we train an Intuitive Critic Model (ICM) using positive and negative action examples from a base agent first. This critic evaluates the immediate correctness of the agent's intended actions, thereby selecting operations with higher success probability. Then, the initial critic guides agent actions to collect refined positive/negative samples, initiating the self-improving cycle. The augmented data then trains a second-round critic with enhanced discernment capability. We conduct experiments on various datasets and demonstrate that the proposed ICM can improve the test-time performance of various closed-source and open-source models, and the performance can be gradually improved as the data is recycled. The code and dataset will be publicly released.", "AI": {"tldr": "提出了一种GUI行动批评家数据飞轮系统(GAIA)，用于改善大型视觉语言模型的测试时间扩展能力。", "motivation": "解决大型视觉语言模型在执行操作时出现不可逆错误的问题，提高其准确性和稳定性。", "method": "通过训练直观批评模型(ICM)评估代理的操作并选择更可能成功的行动，形成自改进循环以提升性能。", "result": "实验表明ICM可以逐步改善各种封闭源和开源模型的测试时间表现。", "conclusion": "GAIA系统能够显著提高大型视觉语言模型在执行GUI任务时的表现。"}}
{"id": "2601.18195", "pdf": "https://arxiv.org/pdf/2601.18195", "abs": "https://arxiv.org/abs/2601.18195", "authors": ["Linhan Cao", "Wei Sun", "Weixia Zhang", "Xiangyang Zhu", "Kaiwei Zhang", "Jun Jia", "Dandan Zhu", "Guangtao Zhai", "Xiongkuo Min"], "title": "QualiRAG: Retrieval-Augmented Generation for Visual Quality Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Visual quality assessment (VQA) is increasingly shifting from scalar score prediction toward interpretable quality understanding -- a paradigm that demands \\textit{fine-grained spatiotemporal perception} and \\textit{auxiliary contextual information}. Current approaches rely on supervised fine-tuning or reinforcement learning on curated instruction datasets, which involve labor-intensive annotation and are prone to dataset-specific biases. To address these challenges, we propose \\textbf{QualiRAG}, a \\textit{training-free} \\textbf{R}etrieval-\\textbf{A}ugmented \\textbf{G}eneration \\textbf{(RAG)} framework that systematically leverages the latent perceptual knowledge of large multimodal models (LMMs) for visual quality perception. Unlike conventional RAG that retrieves from static corpora, QualiRAG dynamically generates auxiliary knowledge by decomposing questions into structured requests and constructing four complementary knowledge sources: \\textit{visual metadata}, \\textit{subject localization}, \\textit{global quality summaries}, and \\textit{local quality descriptions}, followed by relevance-aware retrieval for evidence-grounded reasoning. Extensive experiments show that QualiRAG achieves substantial improvements over open-source general-purpose LMMs and VQA-finetuned LMMs on visual quality understanding tasks, and delivers competitive performance on visual quality comparison tasks, demonstrating robust quality assessment capabilities without any task-specific training. The code will be publicly available at https://github.com/clh124/QualiRAG.", "AI": {"tldr": "QualiRAG是一种无需训练的检索增强生成框架，用于视觉质量理解。", "motivation": "当前的方法依赖于监督微调或强化学习，在注释和数据集特定偏见方面存在挑战。为了解决这些问题，提出了QualiRAG。", "method": "QualiRAG通过将问题分解成结构化请求并构建四类互补的知识来源（视觉元数据、主体定位、全局质量概要以及局部质量描述），动态生成辅助知识，并进行相关性感知检索以实现基于证据的推理。", "result": "实验表明，QualiRAG在视觉质量理解任务中优于开源通用LMMs和微调后的VQA LMMs，在视觉质量比较任务上表现良好。", "conclusion": "QualiRAG展示了无需任何特定任务训练的强大评估能力，并将公开代码。"}}
{"id": "2601.18193", "pdf": "https://arxiv.org/pdf/2601.18193", "abs": "https://arxiv.org/abs/2601.18193", "authors": ["Shiwei Wu", "Ziyao Gao", "Zhendong He", "Zongtan He", "Zhupeng Huang", "Xia Chen", "Wei Zeng", "Xiaojuan Ma", "Zhenhui Peng"], "title": "InkIdeator: Supporting Chinese-Style Visual Design Ideation via AI-Infused Exploration of Chinese Paintings", "categories": ["cs.HC"], "comment": "21 pages, 15 figures, CHI 2026", "summary": "Visual designers often seek inspiration from Chinese paintings when tasked with creating Chinese-style illustrations, posters, etc. Our formative study (N=10) reveals that during ideation, designers learn the cultural symbols, emotions, compositions, and styles in Chinese paintings but face challenges in searching, analyzing, and integrating these dimensions. This paper leverages multi-modal large models to annotate the value of each dimension in 16,315 Chinese paintings, built on which we propose InkIdeator, an ideation support system for Chinese-style visual designs. InkIdeator suggests cultural symbols associated with the task theme, provides dimensional keywords to help analyze Chinese paintings, and generates visual examples integrating user-selected keywords. Our within-subjects study (N=12) using a baseline system without extracted dimensional keywords, along with two extended use cases by Chinese painters, indicates InkIdeator's effectiveness in creative ideation support, helping users efficiently explore cultural dimensions in Chinese paintings and visualize their ideas. We discuss implications for supporting culture-related visual design ideation with generative AI.", "AI": {"tldr": "提出了一种支持中国风格视觉设计构思的系统InkIdeator，该系统通过分析大量中国画来提供灵感和创意。", "motivation": "设计师在创作中寻求中国文化元素时面临挑战，包括难以搜索、理解和整合这些文化维度。因此开发了一个基于AI的支持系统以提高这一过程效率。", "method": "利用多模态大型模型注释16,315幅中国画的文化价值，并提出InkIdeator系统以提供与中国任务主题相关的文化符号建议，帮助分析中国绘画的关键词以及根据用户选择的关键字生成视觉示例。", "result": "通过对照基准系统的实验（N=12）和两个实际案例研究证实了该系统在支持创造性构思方面具有明显优势。", "conclusion": "InkIdeator提高了设计师探索中国文化维度并可视化其创意的能力，展示了用AI辅助文化相关视觉设计构思的潜力。"}}
{"id": "2601.18192", "pdf": "https://arxiv.org/pdf/2601.18192", "abs": "https://arxiv.org/abs/2601.18192", "authors": ["Tian-Yi Zhou", "Xuan-Hao Liu", "Bao-Liang Lu", "Wei-Long Zheng"], "title": "MindCine: Multimodal EEG-to-Video Reconstruction with Large-Scale Pretrained Models", "categories": ["cs.CV", "cs.HC", "cs.MM"], "comment": null, "summary": "Reconstructing human dynamic visual perception from electroencephalography (EEG) signals is of great research significance since EEG's non-invasiveness and high temporal resolution. However, EEG-to-video reconstruction remains challenging due to: 1) Single Modality: existing studies solely align EEG signals with the text modality, which ignores other modalities and are prone to suffer from overfitting problems; 2) Data Scarcity: current methods often have difficulty training to converge with limited EEG-video data. To solve the above problems, we propose a novel framework MindCine to achieve high-fidelity video reconstructions on limited data. We employ a multimodal joint learning strategy to incorporate beyond-text modalities in the training stage and leverage a pre-trained large EEG model to relieve the data scarcity issue for decoding semantic information, while a Seq2Seq model with causal attention is specifically designed for decoding perceptual information. Extensive experiments demonstrate that our model outperforms state-of-the-art methods both qualitatively and quantitatively. Additionally, the results underscore the effectiveness of the complementary strengths of different modalities and demonstrate that leveraging a large-scale EEG model can further enhance reconstruction performance by alleviating the challenges associated with limited data.", "AI": {"tldr": "提出了一种多模态EEG到视频重建框架MindCine，利用大规模预训练模型和因果注意力的Seq2Seq模型提高有限数据下的重建效果。", "motivation": "EEG-视频重建由于单一模态和数据稀缺问题而具有挑战性。为解决这些问题，本研究提出了一个新框架以实现高质量视频重建。", "method": "采用多模态联合学习策略引入文本以外的模式，并利用大规模预训练模型缓解数据稀疏性，同时设计Seq2Seq模型专门用于解码感知信息。", "result": "实验结果表明，该方法在定性和定量评估中均优于现有技术。", "conclusion": "研究证明了不同模态互补优势的有效性以及利用大规模EEG预训练模型可以进一步提升重建性能。"}}
{"id": "2601.18190", "pdf": "https://arxiv.org/pdf/2601.18190", "abs": "https://arxiv.org/abs/2601.18190", "authors": ["Yifan Li", "Shiying Wang", "Jianqiang Huang"], "title": "Multi-Perspective Subimage CLIP with Keyword Guidance for Remote Sensing Image-Text Retrieval", "categories": ["cs.CV"], "comment": "7 pages, 3 figures. Code: https://github.com/Lcrucial1f/MPS-CLIP", "summary": "Vision-Language Pre-training (VLP) models like CLIP have significantly advanced Remote Sensing Image-Text Retrieval (RSITR). However, existing methods predominantly rely on coarse-grained global alignment, which often overlooks the dense, multi-scale semantics inherent in overhead imagery. Moreover, adapting these heavy models via full fine-tuning incurs prohibitive computational costs and risks catastrophic forgetting. To address these challenges, we propose MPS-CLIP, a parameter-efficient framework designed to shift the retrieval paradigm from global matching to keyword-guided fine-grained alignment. Specifically, we leverage a Large Language Model (LLM) to extract core semantic keywords, guiding the Segment Anything Model (SamGeo) to generate semantically relevant sub-perspectives. To efficiently adapt the frozen backbone, we introduce a Gated Global Attention (G^2A) adapter, which captures global context and long-range dependencies with minimal overhead. Furthermore, a Multi-Perspective Representation (MPR) module aggregates these local cues into robust multi-perspective embeddings. The framework is optimized via a hybrid objective combining multi-perspective contrastive and weighted triplet losses, which dynamically selects maximum-response perspectives to suppress noise and enforce precise semantic matching. Extensive experiments on the RSICD and RSITMD benchmarks demonstrate that MPS-CLIP achieves state-of-the-art performance with 35.18% and 48.40% mean Recall (mR), respectively, significantly outperforming full fine-tuning baselines and recent competitive methods. Code is available at https://github.com/Lcrucial1f/MPS-CLIP.", "AI": {"tldr": "本文提出了MPS-CLIP框架，用于解决遥感图像-文本检索任务中的细粒度对齐和计算成本问题。", "motivation": "现有的遥感图像-文本检索方法主要依赖于粗粒度全局对齐，这忽略了高层影像的密集多尺度语义。同时，通过全量微调模型会导致高昂的成本并可能产生灾难性遗忘。", "method": "MPS-CLIP利用大型语言模型提取核心语义关键词，引导Segment Anything Model生成相关子视角，并引入Gated Global Attention适配器来有效适应冻结的骨干网络，采用多视角表示模块聚合局部线索。框架通过结合多视角对比损失和加权三元组损失进行优化。", "result": "在RSICD和RSITMD基准测试上，MPS-CLIP分别达到了35.18%和48.40%的平均召回率，优于全量微调基线和其他最近的方法。", "conclusion": "该框架通过引入细粒度对齐方法，并采用计算效率高的适配器技术，在遥感图像文本检索任务中取得了显著改进。"}}
{"id": "2601.18188", "pdf": "https://arxiv.org/pdf/2601.18188", "abs": "https://arxiv.org/abs/2601.18188", "authors": ["Weiye Zhu", "Zekai Zhang", "Xiangchen Wang", "Hewei Pan", "Teng Wang", "Tiantian Geng", "Rongtao Xu", "Feng Zheng"], "title": "\\textsc{NaVIDA}: Vision-Language Navigation with Inverse Dynamics Augmentation", "categories": ["cs.CV", "cs.AI"], "comment": "18 pages, 14 figures", "summary": "Vision-and-Language Navigation (VLN) requires agents to interpret natural language instructions and act coherently in visually rich environments. However, most existing methods rely on reactive state-action mappings without explicitly modeling how actions causally transform subsequent visual observations. Lacking such vision-action causality, agents cannot anticipate the visual changes induced by its own actions, leading to unstable behaviors, weak generalization, and cumulative error along trajectory. To address these issues, we introduce \\textsc{NaVIDA} (\\textbf{Nav}igation with \\textbf{I}nverse \\textbf{D}ynamics \\textbf{A}ugmentation), a unified VLN framework that couples policy learning with action-grounded visual dynamics and adaptive execution. \\textsc{NaVIDA} augments training with chunk-based inverse-dynamics supervision to learn causal relationship between visual changes and corresponding actions. To structure this supervision and extend the effective planning range, \\textsc{NaVIDA} employs hierarchical probabilistic action chunking (HPAC), which organizes trajectories into multi-step chunks and provides discriminative, longer-range visual-change cues. To further curb error accumulation and stabilize behavior at inference, an entropy-guided mechanism adaptively sets the execution horizon of action chunks. Extensive experiments show that \\textsc{NaVIDA} achieves superior navigation performance compared to state-of-the-art methods with fewer parameters (3B vs. 8B). Real-world robot evaluations further validate the practical feasibility and effectiveness of our approach. Code and data will be available upon acceptance.", "AI": {"tldr": "提出了\textsc{NaVIDA}方法，用于增强视觉语言导航中的逆动力学监督。", "motivation": "现有方法依赖于反应性的状态-动作映射，并未明确建模因果关系导致行为不稳定、泛化能力弱和累积误差。", "method": "\textsc{NaVIDA}通过层次化的概率性动作分组（HPAC）来学习视觉变化与相应动作之间的因果关系，采用熵引导机制来控制执行范围以减少错误积累。", "result": "\textsc{NaVIDA}在导航性能上超过了最先进的方法，并且使用较少的参数(3B vs. 8B)，真实世界机器人实验进一步验证了该方法的有效性。", "conclusion": "\textsc{NaVIDA}提供了一种有效的框架，通过逆动力学监督和结构化的方法增强视觉语言导航任务的表现。"}}
{"id": "2601.18184", "pdf": "https://arxiv.org/pdf/2601.18184", "abs": "https://arxiv.org/abs/2601.18184", "authors": ["Zhiliang Peng", "Jianwei Yu", "Yaoyao Chang", "Zilong Wang", "Li Dong", "Yingbo Hao", "Yujie Tu", "Chenyu Yang", "Wenhui Wang", "Songchen Xu", "Yutao Sun", "Hangbo Bao", "Weijiang Xu", "Yi Zhu", "Zehua Wang", "Ting Song", "Yan Xia", "Zewen Chi", "Shaohan Huang", "Liang Wang", "Chuang Ding", "Shuai Wang", "Xie Chen", "Furu Wei"], "title": "VIBEVOICE-ASR Technical Report", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "This report presents VibeVoice-ASR, a general-purpose speech understanding framework built upon VibeVoice, designed to address the persistent challenges of context fragmentation and multi-speaker complexity in long-form audio (e.g., meetings, podcasts) that remain despite recent advancements in short-form speech recognition. Unlike traditional pipelined approaches that rely on audio chunking, VibeVoice-ASRsupports single-pass processing for up to 60 minutes of audio. It unifies Automatic Speech Recognition, Speaker Diarization, and Timestamping into a single end-to-end generation task. In addition, VibeVoice-ASR supports over 50 languages, requires no explicit language setting, and natively handles code-switching within and across utterances. Furthermore, we introduce a prompt-based context injection mechanism that allows users to supply customized conetxt, significantly improving accuracy on domain-specific terminology and polyphonic character disambiguation.", "AI": {"tldr": "本文介绍了VibeVoice-ASR，一种针对长时语音（如会议、播客）的通用语音理解框架，能够统一处理自动语音识别、说话人区分和时间戳插入。", "motivation": "为了解决现有技术在应对上下文碎片化和多说话者复杂性挑战方面的不足，尤其是在长时间音频中。VibeVoice-ASR旨在提供一种更加高效和准确的方法来处理这些场景。", "method": "VibeVoice-ASR采用了单一的端到端生成任务来实现自动语音识别、说话人区分和时间戳插入，并且支持60分钟连续录音的单次通过处理。此外，它还引入了一种基于提示的上下文注入机制，以提高特定领域术语的准确性。", "result": "VibeVoice-ASR在多语言环境下表现良好，无需显式设置语言，并能自然地处理语内和跨句的语言切换。", "conclusion": "通过提出一种新的语音理解框架，VibeVoice-ASR有效地解决了长时间音频中的关键挑战，提高了自动语音识别的效率与准确性。"}}
{"id": "2601.18179", "pdf": "https://arxiv.org/pdf/2601.18179", "abs": "https://arxiv.org/abs/2601.18179", "authors": ["Yimeng Wang", "Liabette Escamilla", "Yinzhou Wang", "Bianca R. Augustine", "Yixuan Zhang"], "title": "Exploring Customizable Interactive Tools for Therapeutic Homework Support in Mental Health Counseling", "categories": ["cs.HC"], "comment": "22 pages, 4 figures", "summary": "Therapeutic homework (i.e., tasks assigned by therapists for clients to complete between sessions) is essential for effective psychotherapy, yet therapists often interpret fragmented client logs, assessments, and reflections within limited preparation time. Our formative study with licensed therapists revealed three critical design requirements: support for interpreting unstructured client self-reports, customization aligned with clinical objectives, and seamless integration across multiple data sources. We then designed and developed TheraTrack, a customizable, therapist-facing tool that integrates multi-dimensional data and leverages large language models to generate traceable summaries and support natural-language queries, to streamline between-session homework tracking. Our pilot study with 14 therapists showed that TheraTrack reduced their cognitive load, enabled verification through direct navigation from AI summaries to original data entries, and was adapted differently for private analysis compared to in-session use, with dependence varying based on therapist experience and usage duration. We also discuss design implications for clinician-centered AI for mental health.", "AI": {"tldr": "设计并开发了一种用于精神健康咨询的个性化交互工具TheraTrack，以支持治疗作业跟踪。", "motivation": "通过调查发现精神健康顾问在准备时间有限的情况下难以解读不结构化的客户报告。为此，研究者们希望提供一种能够整合多维度数据、生成可追溯总结并适应临床目标的技术解决方案。", "method": "进行了形成性研究以确定设计要求，并开发了TheraTrack工具来满足这些需求。该工具利用大型语言模型来支持自然语言查询，通过直接导航从AI摘要到原始数据条目进行验证，从而减少认知负荷。", "result": "在14位顾问的试点研究中显示，TheraTrack减少了他们的认知负担，并且被用于私人分析和会话使用中的适应性不同，依赖程度根据顾问的经验和使用时间而变化。", "conclusion": "TheraTrack通过整合多维度数据、利用大型语言模型生成可追溯摘要和支持自然语言查询来减轻精神健康顾问的认知负担。"}}
{"id": "2601.18177", "pdf": "https://arxiv.org/pdf/2601.18177", "abs": "https://arxiv.org/abs/2601.18177", "authors": ["Ye Tian", "Haohua Du", "Chao Gu", "Junyang Zhang", "Shanyue Wang", "Hao Zhou", "Jiahui Hou", "Xiang-Yang Li"], "title": "Lip-Siri: Contactless Open-Sentence Silent Speech with Wi-Fi Backscatter", "categories": ["cs.HC"], "comment": null, "summary": "Silent speech interfaces (SSIs) enable silent interaction in noise-sensitive or privacy-sensitive settings. However, existing SSIs face practical deployment trade-offs among privacy, user experience, and energy consumption, and most remain limited to closed-set recognition over small, pre-defined vocabularies of words or sentences, which restricts real-world expressiveness. In this paper, we present Lip-Siri, to the best of our knowledge, the first Wi-Fi backscatter--based SSI that supports open-vocabulary sentence recognition via lexicon-guided subword decoding. Lip-Siri designs a frequency-shifted backscatter tag to isolate tag-modulated reflections and suppress interference from non-target motions, enabling reliable extraction of lip-motion traces from ubiquitous Wi-Fi signals. We then segment continuous traces into lip-motion units, cluster them, learn robust unit representations via cluster-based self-supervision, and finally propose a lexicon-guided Transformer encoder--decoder with beam search to decode variable-length sentence sequences. We implement an end-to-end prototype and evaluate it with 15 participants on 340 sentences and 3,398 words across multiple scenarios. Lip-Siri achieves 85.61% accuracy on word prediction and a WER of 36.87% on continuous sentence recognition, approaching the performance of representative vision-based lip-reading systems.", "AI": {"tldr": "研究开发了一种基于Wi-Fi回波散射的无声语音接口（SSI），可以实现开放词汇句子识别。", "motivation": "现有的无声语音接口在隐私保护，用户体验和能量消耗方面存在折衷，并且大多数只能进行有限的小词汇量或短语识别，这限制了它们的实际表达能力。为此，研究人员开发了一种新的系统以支持开放式词汇句识别。", "method": "设计了一个频率偏移的回波散射标签来隔离目标信号并抑制非目标运动干扰；通过连续跟踪唇部动作并将这些单元聚类化，学习出稳健的单位表示，并提出基于字典引导的Transformer编码器-解码器模型进行可变长度句子序列解码。", "result": "实现了端到端原型并在包含340个句子和3,398个单词的不同场景下的实验中达到了85.61%的词汇预测准确率，以及36.87%的连续句识别WERS值。", "conclusion": "Lip-Siri是首个支持开放词汇句子识别的Wi-Fi回波散射无声语音接口系统，其性能接近现有的基于视觉的唇语阅读系统。"}}
{"id": "2601.18175", "pdf": "https://arxiv.org/pdf/2601.18175", "abs": "https://arxiv.org/abs/2601.18175", "authors": ["Daniel Russo"], "title": "Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success", "categories": ["cs.AI", "cs.LG", "eess.SY", "stat.ML"], "comment": null, "summary": "A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $χ^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective.", "AI": {"tldr": "论文探讨了成功条件策略改进在信任区域优化问题中的作用，证明其能够在不降低性能的情况下最大化策略改善。", "motivation": "理解成功条件策略改进方法背后的数学原理以及它解决了什么样的优化问题。", "method": "通过理论分析和推导，展示了成功条件策略改进如何解决一个特定的优化问题，并定义了衡量策略变化程度的新量度——行动影响力。", "result": "证明了成功条件策略改进能够最大化策略改善同时保持性能不降低，明确了相对策略改进、政策变更幅度及行动影响力三者相等的关系。", "conclusion": "通过理论分析表明，成功条件策略改进是一种保守的策略改进操作，在不会导致性能下降或分布偏移的情况下实现优化。"}}
{"id": "2601.18172", "pdf": "https://arxiv.org/pdf/2601.18172", "abs": "https://arxiv.org/abs/2601.18172", "authors": ["Lin Huang", "Yujuan Tan", "Weisheng Li", "Shitai Shan", "Liu Liu", "Bo Liu", "Linlin Shen", "Jing Yu", "Yue Niu"], "title": "YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "One-stage object detection, particularly the YOLO series, strikes a favorable balance between accuracy and efficiency. However, existing YOLO detectors lack explicit modeling of heterogeneous object responses within shared feature channels, which limits further performance gains. To address this, we propose YOLO-DS, a framework built around a novel Dual-Statistic Synergy Operator (DSO). The DSO decouples object features by jointly modeling the channel-wise mean and the peak-to-mean difference. Building upon the DSO, we design two lightweight gating modules: the Dual-Statistic Synergy Gating (DSG) module for adaptive channel-wise feature selection, and the Multi-Path Segmented Gating (MSG) module for depth-wise feature weighting. On the MS-COCO benchmark, YOLO-DS consistently outperforms YOLOv8 across five model scales (N, S, M, L, X), achieving AP gains of 1.1% to 1.7% with only a minimal increase in inference latency. Extensive visualization, ablation, and comparative studies validate the effectiveness of our approach, demonstrating its superior capability in discriminating heterogeneous objects with high efficiency.", "AI": {"tldr": "提出了一种新的YOLO-DS框架，通过双统计协同算子（DSO）分离对象特征，并设计了两种轻量级门控模块以提高检测性能。", "motivation": "现有的YOLO检测器在共享特征通道中缺乏对异质物体响应的显式建模，限制了进一步的性能提升。为此提出了YOLO-DS框架来解决这一问题。", "method": "提出了一种双统计协同算子（DSO）通过同时建模通道均值和峰值到均值差来分离对象特征，并设计了两种轻量级门控模块：双统计协同门控(DSG)模块用于自适应的通道级特征选择，多路径分段门控(MSG)模块用于深度级特征加权。", "result": "在MS-COCO基准测试上，YOLO-DS优于YOLOv8，模型规模从N到X都有性能提升（AP值提升1.1%至1.7%，推断延迟增加很小）。大量的可视化、消融和对比研究验证了此方法的有效性。", "conclusion": "通过双统计协同算子和轻量级门控模块的引入，YOLO-DS框架不仅提高了检测性能而且保持了较高的效率。"}}
{"id": "2601.18168", "pdf": "https://arxiv.org/pdf/2601.18168", "abs": "https://arxiv.org/abs/2601.18168", "authors": ["Zehua Liu", "Shihao Zou", "Jincai Huang", "Yanfang Zhang", "Chao Tong", "Weixin Si"], "title": "TempDiffReg: Temporal Diffusion Model for Non-Rigid 2D-3D Vascular Registration", "categories": ["cs.CV"], "comment": "Accepted by IEEE BIBM 2025", "summary": "Transarterial chemoembolization (TACE) is a preferred treatment option for hepatocellular carcinoma and other liver malignancies, yet it remains a highly challenging procedure due to complex intra-operative vascular navigation and anatomical variability. Accurate and robust 2D-3D vessel registration is essential to guide microcatheter and instruments during TACE, enabling precise localization of vascular structures and optimal therapeutic targeting. To tackle this issue, we develop a coarse-to-fine registration strategy. First, we introduce a global alignment module, structure-aware perspective n-point (SA-PnP), to establish correspondence between 2D and 3D vessel structures. Second, we propose TempDiffReg, a temporal diffusion model that performs vessel deformation iteratively by leveraging temporal context to capture complex anatomical variations and local structural changes. We collected data from 23 patients and constructed 626 paired multi-frame samples for comprehensive evaluation. Experimental results demonstrate that the proposed method consistently outperforms state-of-the-art (SOTA) methods in both accuracy and anatomical plausibility. Specifically, our method achieves a mean squared error (MSE) of 0.63 mm and a mean absolute error (MAE) of 0.51 mm in registration accuracy, representing 66.7\\% lower MSE and 17.7\\% lower MAE compared to the most competitive existing approaches. It has the potential to assist less-experienced clinicians in safely and efficiently performing complex TACE procedures, ultimately enhancing both surgical outcomes and patient care. Code and data are available at: \\textcolor{blue}{https://github.com/LZH970328/TempDiffReg.git}", "AI": {"tldr": "该论文提出了一种新的血管配准策略，用于二维和三维血管结构的准确对应。", "motivation": "为了提高肝细胞癌等肝脏恶性肿瘤的治疗效果，解决复杂的术中血管导航问题以及解剖变异性的挑战，需要一种准确且鲁棒的2D-3D血管注册方法来指导微导管和其他仪器。", "method": "首先提出了一种全局对齐模块SA-PnP，用于建立二维和三维血管结构之间的对应关系。接着提出了一个时序扩散模型TempDiffReg，通过迭代方式利用时间上下文信息捕捉复杂的解剖变化和局部结构变化来进行血管变形。", "result": "实验结果显示该方法在精度和解剖合理性上均优于现有最先进的方法。具体来说，在注册精度上实现了0.63毫米的平均平方误差(MSE)和0.51毫米的平均绝对误差(MAE)，分别比最竞争的方法低了66.7%和17.7%。", "conclusion": "该研究开发了一种新的2D-3D血管配准策略，有助于经验较少的临床医生安全高效地执行复杂的TACE程序，并最终提高手术结果和患者护理。"}}
{"id": "2601.18157", "pdf": "https://arxiv.org/pdf/2601.18157", "abs": "https://arxiv.org/abs/2601.18157", "authors": ["Aniket Rege", "Arka Sadhu", "Yuliang Li", "Kejie Li", "Ramya Korlakai Vinayak", "Yuning Chai", "Yong Jae Lee", "Hyo Jin Kim"], "title": "Agentic Very Long Video Understanding", "categories": ["cs.CV", "cs.LG"], "comment": "26 pages, 7 figures, 8 tables", "summary": "The advent of always-on personal AI assistants, enabled by all-day wearable devices such as smart glasses, demands a new level of contextual understanding, one that goes beyond short, isolated events to encompass the continuous, longitudinal stream of egocentric video. Achieving this vision requires advances in long-horizon video understanding, where systems must interpret and recall visual and audio information spanning days or even weeks. Existing methods, including large language models and retrieval-augmented generation, are constrained by limited context windows and lack the ability to perform compositional, multi-hop reasoning over very long video streams. In this work, we address these challenges through EGAgent, an enhanced agentic framework centered on entity scene graphs, which represent people, places, objects, and their relationships over time. Our system equips a planning agent with tools for structured search and reasoning over these graphs, as well as hybrid visual and audio search capabilities, enabling detailed, cross-modal, and temporally coherent reasoning. Experiments on the EgoLifeQA and Video-MME (Long) datasets show that our method achieves state-of-the-art performance on EgoLifeQA (57.5%) and competitive performance on Video-MME (Long) (74.1%) for complex longitudinal video understanding tasks.", "AI": {"tldr": "该论文提出了一种新的框架EGAgent，用于理解和分析长时间的个人视频流。", "motivation": "为了应对穿戴设备如智能眼镜带来的全天候个人AI助手的需求，需要一种能够理解持续、纵向的自我中心视频的新方法。现有的方法在处理长时视频和多步推理方面存在局限性。", "method": "论文提出了EGAgent框架，该框架基于实体场景图进行增强代理式搜索与推理，并结合视觉和音频搜索能力实现跨模态、时间一致性的详细推理。", "result": "实验显示，该方法在EgoLifeQA数据集上达到57.5%的SOTA性能，在Video-MME（Long）数据集上的表现也十分出色，为复杂纵向视频理解任务提供了有力支持。", "conclusion": "EGAgent框架展示了处理长时间、跨模态视频流的强大能力，并且在多个基准测试中取得了领先或接近领先的性能。"}}
{"id": "2601.18156", "pdf": "https://arxiv.org/pdf/2601.18156", "abs": "https://arxiv.org/abs/2601.18156", "authors": ["Anirban Mukherjee", "Hannah Hanwen Chang"], "title": "Beyond Pairwise Comparisons: A Distributional Test of Distinctiveness for Machine-Generated Works in Intellectual Property Law", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Key doctrines, including novelty (patent), originality (copyright), and distinctiveness (trademark), turn on a shared empirical question: whether a body of work is meaningfully distinct from a relevant reference class. Yet analyses typically operationalize this set-level inquiry using item-level evidence: pairwise comparisons among exemplars. That unit-of-analysis mismatch may be manageable for finite corpora of human-created works, where it can be bridged by ad hoc aggregations. But it becomes acute for machine-generated works, where the object of evaluation is not a fixed set of works but a generative process with an effectively unbounded output space. We propose a distributional alternative: a two-sample test based on maximum mean discrepancy computed on semantic embeddings to determine if two creative processes-whether human or machine-produce statistically distinguishable output distributions. The test requires no task-specific training-obviating the need for discovery of proprietary training data to characterize the generative process-and is sample-efficient, often detecting differences with as few as 5-10 images and 7-20 texts. We validate the framework across three domains: handwritten digits (controlled images), patent abstracts (text), and AI-generated art (real-world images). We reveal a perceptual paradox: even when human evaluators distinguish AI outputs from human-created art with only about 58% accuracy, our method detects distributional distinctiveness. Our results present evidence contrary to the view that generative models act as mere regurgitators of training data. Rather than producing outputs statistically indistinguishable from a human baseline-as simple regurgitation would predict-they produce outputs that are semantically human-like yet stochastically distinct, suggesting their dominant function is as a semantic interpolator within a learned latent space.", "AI": {"tldr": "提出了一种基于最大均值差异的分布测试方法，用于评估机器生成作品与人类创作的作品之间的区别性。", "motivation": "现有分析通常依赖于两样本比较来判断作品的独特性，这种方法在处理有限的人类作品时可以适用，但在面对无限输出空间的机器生成作品时显得不足。因此，提出了一个基于语义嵌入的最大均值差异测试的方法来解决这一问题。", "method": "利用最大均值差异计算出两个创作过程产生的输出分布是否具有统计显著性区别。该方法无需任务特定训练，并且样本效率高，通常只需5-10个图像和7-20个文本即可检测到差异。", "result": "在三个领域验证了此框架的有效性：手写数字、专利摘要和AI生成的艺术作品。结果显示即使人类评估者只能以大约58%的准确性区分AI输出与人工艺术，该方法仍能识别出分布上的显著区别。", "conclusion": "研究表明，生成模型并非仅仅是训练数据的简单复制品，而是产生了在语义上类似于人的输出，但在统计学上有别于人创作的作品。这表明其主要功能是在学习到的空间内作为语义插值器。"}}
{"id": "2601.18154", "pdf": "https://arxiv.org/pdf/2601.18154", "abs": "https://arxiv.org/abs/2601.18154", "authors": ["Haiyi Li", "Yiyang Zhao", "Yutong Li", "Alison Deslandes", "Jodie Avery", "Mary Louise Hull", "Hsiang-Ting Chen"], "title": "EndoExtract: Co-Designing Structured Text Extraction from Endometriosis Ultrasound Reports", "categories": ["cs.HC"], "comment": null, "summary": "Endometriosis ultrasound reports are often unstructured free-text documents that require manual abstraction for downstream tasks such as analytics, machine learning model training, and clinical auditing. We present \\textbf{EndoExtract}, an on-premise LLM-powered system that extracts structured data from these reports and surfaces interpretive fields for human review. Through contextual inquiry with research assistants, we identified key workflow pain points: asymmetric trust between numerical and interpretive fields, repetitive manual highlighting, fatigue from sustained comparison, and terminology inconsistency across radiologists. These findings informed an interface that surfaces only interpretive fields for mandatory review, automatically highlights source evidence within PDFs, and separates batch extraction from human-paced verification. A formative workshop revealed that \\textbf{EndoExtract} supports a shift from field-by-field data entry to supervisory validation, though participants noted risks of over-skimming and challenges in managing missing data.", "AI": {"tldr": "本文介绍了EndoExtract系统，该系统通过大型语言模型从子宫内膜异位症的超声报告中提取结构化数据，并提供人类审查所需解释性字段。", "motivation": "为了简化下游任务（如数据分析、机器学习模型训练和临床审计），需要一种方法来处理目前多为未结构化的自由文本形式的子宫内膜异位症超声报告。通过研究助理的上下文调查，发现了关键的工作流程痛点，包括数值与解释性字段之间的信任不对称、重复的手动高亮显示任务、持续比较时的疲劳以及放射科医师之间术语的一致性问题。", "method": "EndoExtract系统是一个基于大型语言模型的在地化解决方案。它通过上下文调查确定了关键的工作流程痛点，并设计了一个界面，只对解释性字段进行强制审查，自动高亮显示PDF中的来源证据，并将批量提取与人类验证分开。", "result": "EndoExtract支持从逐个字段的数据录入向监督验证的转变，尽管参与者指出存在过度略读的风险和管理缺失数据的挑战。", "conclusion": "通过EndoExtract系统，实现了子宫内膜异位症超声报告结构化提取，并改进了工作流程。此系统为处理医疗文档提供了有效的解决方案。"}}
{"id": "2601.18151", "pdf": "https://arxiv.org/pdf/2601.18151", "abs": "https://arxiv.org/abs/2601.18151", "authors": ["Yicong Li", "Shan Jin", "Qi Liu", "Shuo Wang", "Jiaying Liu", "Shuo Yu", "Qiang Zhang", "Kuanjiu Zhou", "Feng Xia"], "title": "Explaining Synergistic Effects in Social Recommendations", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "In social recommenders, the inherent nonlinearity and opacity of synergistic effects across multiple social networks hinders users from understanding how diverse information is leveraged for recommendations, consequently diminishing explainability. However, existing explainers can only identify the topological information in social networks that significantly influences recommendations, failing to further explain the synergistic effects among this information. Inspired by existing findings that synergistic effects enhance mutual information between inputs and predictions to generate information gain, we extend this discovery to graph data. We quantify graph information gain to identify subgraphs embodying synergistic effects. Based on the theoretical insights, we propose SemExplainer, which explains synergistic effects by identifying subgraphs that embody them. SemExplainer first extracts explanatory subgraphs from multi-view social networks to generate preliminary importance explanations for recommendations. A conditional entropy optimization strategy to maximize information gain is developed, thereby further identifying subgraphs that embody synergistic effects from explanatory subgraphs. Finally, SemExplainer searches for paths from users to recommended items within the synergistic subgraphs to generate explanations for the recommendations. Extensive experiments on three datasets demonstrate the superiority of SemExplainer over baseline methods, providing superior explanations of synergistic effects.", "AI": {"tldr": "研究提出了SemExplainer模型，用于解释社交推荐系统中的协同效应。", "motivation": "现有的解释器只能识别社交网络中对推荐有显著影响的拓扑信息，而无法进一步解释这些信息之间的协同效应。这种现象削弱了系统的可理解性。", "method": "通过量化图的信息增益来识别体现协同效应的子图。SemExplainer首先从多视角的社会网络中提取解释性的子图，然后利用条件熵优化策略最大化信息增益，从而进一步确定具有协同效应的子图。最后，在这些子图中寻找用户到推荐项目之间的路径以生成解释。", "result": "实验结果表明，与基线方法相比，SemExplainer在解释社交推荐中的协同效应方面表现出优越性。", "conclusion": "通过提出SemExplainer模型，该研究成功地解决了现有解释器无法充分说明社交网络中信息之间协同效应的问题。"}}
{"id": "2601.18137", "pdf": "https://arxiv.org/pdf/2601.18137", "abs": "https://arxiv.org/abs/2601.18137", "authors": ["Yinger Zhang", "Shutong Jiang", "Renhao Li", "Jianhong Tu", "Yang Su", "Lianghao Deng", "Xudong Guo", "Chenxu Lv", "Junyang Lin"], "title": "DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.", "AI": {"tldr": "该论文介绍了DeepPlanning，一个用于评估长时域规划的基准测试。", "motivation": "现有代理评估任务倾向于局部步骤推理而非全局约束优化，且忽视了真实场景中的信息获取和细粒度本地约束。为了填补这一空白，作者提出了DeepPlanning来更好地模拟现实世界的长期规划挑战。", "method": "通过多日旅行规划和多产品购物等任务，测试前沿的代理LLM是否具备主动的信息收集能力、局部受限推理能力和全局优化能力。", "result": "实验结果显示，即使是先进的代理LLM在这些具有挑战性的长时域问题上也表现不佳，表明了可靠显式推理模式和并行工具使用的重要性。", "conclusion": "DeepPlanning揭示了代理LLM在未来改进的方向，并开放源代码支持进一步的研究。"}}
{"id": "2601.18135", "pdf": "https://arxiv.org/pdf/2601.18135", "abs": "https://arxiv.org/abs/2601.18135", "authors": ["Jiahao Lyu", "Minghua Zhao", "Xuewen Huang", "Yifei Chen", "Shuangli Du", "Jing Hu", "Cheng Shi", "Zhiyong Lv"], "title": "Forward Consistency Learning with Gated Context Aggregation for Video Anomaly Detection", "categories": ["cs.CV"], "comment": "It has been submitted to the KBS journal", "summary": "As a crucial element of public security, video anomaly detection (VAD) aims to measure deviations from normal patterns for various events in real-time surveillance systems. However, most existing VAD methods rely on large-scale models to pursue extreme accuracy, limiting their feasibility on resource-limited edge devices. Moreover, mainstream prediction-based VAD detects anomalies using only single-frame future prediction errors, overlooking the richer constraints from longer-term temporal forward information. In this paper, we introduce FoGA, a lightweight VAD model that performs Forward consistency learning with Gated context Aggregation, containing about 2M parameters and tailored for potential edge devices. Specifically, we propose a Unet-based method that performs feature extraction on consecutive frames to generate both immediate and forward predictions. Then, we introduce a gated context aggregation module into the skip connections to dynamically fuse encoder and decoder features at the same spatial scale. Finally, the model is jointly optimized with a novel forward consistency loss, and a hybrid anomaly measurement strategy is adopted to integrate errors from both immediate and forward frames for more accurate detection. Extensive experiments demonstrate the effectiveness of the proposed method, which substantially outperforms state-of-the-art competing methods, running up to 155 FPS. Hence, our FoGA achieves an excellent trade-off between performance and the efficiency metric.", "AI": {"tldr": "提出了一种轻量级的视频异常检测模型FoGA，该模型采用前向一致性学习和门控上下文聚合技术以提高实时性和准确性。", "motivation": "现有的视频异常检测方法依赖大规模模型追求极致准确度，限制了其在资源受限设备上的应用。主流基于预测的方法仅使用单帧未来预测误差来检测异常，忽略了长期时间序列的前向信息约束。", "method": "利用Unet架构对连续帧进行特征提取以生成即时和前向预测，并引入门控上下文聚合模块动态融合编码器与解码器在同一空间尺度上的特征。模型通过新的前向一致性损失联合优化，并采用混合异常度量策略，结合来自即刻及前向帧的误差。", "result": "实验表明所提出方法显著优于现有的先进算法，最高可达到每秒155帧的速度，实现了性能与效率的良好平衡。", "conclusion": "FoGA模型通过引入门控上下文聚合和前向一致性学习技术，在保持较低计算资源需求的同时提高了视频异常检测的准确性。"}}
{"id": "2601.18132", "pdf": "https://arxiv.org/pdf/2601.18132", "abs": "https://arxiv.org/abs/2601.18132", "authors": ["Xi Chen", "Hongru Zhou", "Huahui Yi", "Shiyu Feng", "Hanyu Zhou", "Tiancheng He", "Mingke You", "Li Wang", "Qiankun Li", "Kun Wang", "Weili Fu", "Kang Li", "Jian Li"], "title": "RareAlert: Aligning heterogeneous large language model reasoning for early rare disease risk screening", "categories": ["cs.AI"], "comment": "28 page, 3 figures", "summary": "Missed and delayed diagnosis remains a major challenge in rare disease care. At the initial clinical encounters, physicians assess rare disease risk using only limited information under high uncertainty. When high-risk patients are not recognised at this stage, targeted diagnostic testing is often not initiated, resulting in missed diagnosis. Existing primary care triage processes are structurally insufficient to reliably identify patients with rare diseases at initial clinical presentation and universal screening is needed to reduce diagnostic delay. Here we present RareAlert, an early screening system which predict patient-level rare disease risk from routinely available primary-visit information. RareAlert integrates reasoning generated by ten LLMs, calibrates and weights these signals using machine learning, and distils the aligned reasoning into a single locally deployable model. To develop and evaluate RareAlert, we curated RareBench, a real-world dataset of 158,666 cases covering 33 Orphanet disease categories and more than 7,000 rare conditions, including both rare and non-rare presentations. The results showed that rare disease identification can be reconceptualised as a universal uncertainty resolution process applied to the general patient population. On an independent test set, RareAlert, a Qwen3-4B based model trained with calibrated reasoning signals, achieved an AUC of 0.917, outperforming the best machine learning ensemble and all evaluated LLMs, including GPT-5, DeepSeek-R1, Claude-3.7-Sonnet, o3-mini, Gemini-2.5-Pro, and Qwen3-235B. These findings demonstrate the diversity in LLM medical reasoning and the effectiveness of aligning such reasoning in highly uncertain clinical tasks. By incorporating calibrated reasoning into a single model, RareAlert enables accurate, privacy-preserving, and scalable rare disease risk screening suitable for large-scale local deployment.", "AI": {"tldr": "RareAlert 是一个早期筛查系统，通过整合和校准十个大语言模型的推理来预测患者罕见病风险。", "motivation": "由于初期临床诊断中医生可用信息有限且不确定性高，导致罕见疾病患者未能及时识别并进行针对性检测，进而造成误诊或漏诊。因此，需要一种通用筛查方法以减少诊断延迟。", "method": "RareAlert 集成了由十个大语言模型生成的推理，并通过机器学习校准和加权这些信号，最终将对齐后的推理浓缩成一个单一的本地可部署模型。", "result": "在独立测试集中，基于 Qwen3-4B 并训练了校准推理信号的 RareAlert 达到了 AUC 0.917 的成绩，优于所有评估的大语言模型和机器学习集成方法。", "conclusion": "该研究展示了大语言模型医学推理的多样性，并证明对齐这些推理在高不确定性临床任务中的有效性。通过将校准后的推理整合到一个单一模型中，RareAlert 实现了准确、隐私保护且可大规模部署的罕见病风险筛查。"}}
{"id": "2601.18130", "pdf": "https://arxiv.org/pdf/2601.18130", "abs": "https://arxiv.org/abs/2601.18130", "authors": ["Jize Wang", "Han Wu", "Zhiyuan You", "Yiming Song", "Yijun Wang", "Zifei Shan", "Yining Li", "Songyang Zhang", "Xinyi Le", "Cailian Chen", "Xinping Guan", "Dacheng Tao"], "title": "RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents", "categories": ["cs.AI"], "comment": null, "summary": "Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.", "AI": {"tldr": "提出了一种高效的动态路由框架RouteMoA，通过轻量级筛选和评分机制减少推理成本和延迟。", "motivation": "现有的Mixture-of-Agents（MoA）方法需要所有模型进行完整推理才能筛选响应，导致成本高且延迟大。RouteMoA旨在解决这一问题，提高效率。", "method": "采用轻量级评分器预测查询性能，并初步筛选候选者；随后通过混合裁判对现有输出进行自我和交叉评估以优化选择；最终根据性能、成本和延迟平衡选择模型。", "result": "在不同任务和模型池大小上优于MoA，减少了89.8%的成本并降低了63.6%的延迟。", "conclusion": "RouteMoA通过动态路由机制显著提高了Mixture-of-Agents框架的效率，大幅降低成本和延迟。"}}
{"id": "2601.18129", "pdf": "https://arxiv.org/pdf/2601.18129", "abs": "https://arxiv.org/abs/2601.18129", "authors": ["Kunat Pipatanakul", "Pittawat Taveekitworachai"], "title": "Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages. Code is publicly available at https://github.com/scb-10x/typhoon-s . Datasets and model weights are available at https://huggingface.co/collections/typhoon-ai/typhoon-s", "summary": "Large language models (LLMs) have progressed rapidly; however, most state-of-the-art models are trained and evaluated primarily in high-resource languages such as English and Chinese, and are often developed by a small number of organizations with access to large-scale compute and data. This gatekeeping creates a practical barrier for sovereign settings in which a regional- or national-scale institution or domain owner must retain control and understanding of model weights, training data, and deployment while operating under limited resources and strict transparency constraints. To this end, we identify two core requirements: (1) adoptability, the ability to transform a base model into a general-purpose assistant, and (2) sovereign capability, the ability to perform high-stakes, region-specific tasks (e.g., legal reasoning in local languages and cultural knowledge). We investigate whether these requirements can be achieved without scaling massive instruction corpora or relying on complex preference tuning pipelines and large-scale reinforcement fine-tuning (RFT). We present Typhoon S, a minimal and open post-training recipe that combines supervised fine-tuning, on-policy distillation, and small-scale RFT. Using Thai as a representative case study, we demonstrate that our approach transforms both sovereign-adapted and general-purpose base models into instruction-tuned models with strong general performance. We further show that small-scale RFT with InK-GRPO -- an extension of GRPO that augments the GRPO loss with a next-word prediction loss -- improves Thai legal reasoning and Thai-specific knowledge while preserving general capabilities. Our results suggest that a carefully designed post-training strategy can reduce the required scale of instruction data and computation, providing a practical path toward high-quality sovereign LLMs under academic-scale resources.", "AI": {"tldr": "本文提出了一种名为Typhoon-S的最小化开放后训练方法，旨在使大型语言模型在资源有限和严格透明度约束的情况下能够适应主权环境。", "motivation": "当前最先进的语言模型主要针对英语、中文等高资源语言进行训练，并且大多数由少数拥有大规模计算能力和数据集的组织开发。这种封闭性为需要保留对模型权重、训练数据及部署控制权并具备有限资源和严格透明度要求的主权设置带来了实际障碍。", "method": "Typhoon-S是一种最小化开放后训练方法，结合了监督微调、策略内蒸馏以及小规模强化学习精调（RFT），以提高语言模型在特定区域任务中的表现能力。这种方法通过使用泰语作为案例研究，证明了它能够将基础模型转化为适应主权环境的指令调整型模型。", "result": "实验结果表明，在采用较小规模指令数据和计算资源的情况下，Typhoon-S方法能够显著提升泰国法律推理以及与泰国相关的特定知识水平，并保持模型的一般性能能力。这为在学术级资源环境下构建高质量的主权大型语言模型提供了切实可行的道路。", "conclusion": "通过精心设计的后训练策略，可以大幅减少对大规模指令数据和计算资源的需求，从而实现高效、适应性强且符合主权要求的语言模型开发与部署。"}}
{"id": "2601.18127", "pdf": "https://arxiv.org/pdf/2601.18127", "abs": "https://arxiv.org/abs/2601.18127", "authors": ["Judy Hanwen Shen", "Ken Liu", "Angelina Wang", "Sarah H. Cen", "Andy K. Zhang", "Caroline Meinhardt", "Daniel Zhang", "Kevin Klyman", "Rishi Bommasani", "Daniel E. Ho"], "title": "The Limits of AI Data Transparency Policy: Three Disclosure Fallacies", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Data transparency has emerged as a rallying cry for addressing concerns about AI: data quality, privacy, and copyright chief among them. Yet while these calls are crucial for accountability, current transparency policies often fall short of their intended aims. Similar to nutrition facts for food, policies aimed at nutrition facts for AI currently suffer from a limited consideration of research on effective disclosures. We offer an institutional perspective and identify three common fallacies in policy implementations of data disclosures for AI. First, many data transparency proposals exhibit a specification gap between the stated goals of data transparency and the actual disclosures necessary to achieve such goals. Second, reform attempts exhibit an enforcement gap between required disclosures on paper and enforcement to ensure compliance in fact. Third, policy proposals manifest an impact gap between disclosed information and meaningful changes in developer practices and public understanding. Informed by the social science on transparency, our analysis identifies affirmative paths for transparency that are effective rather than merely symbolic.", "AI": {"tldr": "本文分析了人工智能数据透明政策中存在的三个披露谬误，提出了有效的透明路径建议。", "motivation": "鉴于当前的数据透明政策在实现其目的方面存在不足，作者旨在通过机构视角识别并解决这些政策中的问题。", "method": "通过对现有AI数据透明提案的审查和批判性分析，指出了它们存在的三个主要谬误，并借鉴社会科学研究成果提出了改进措施。", "result": "确定了关于AI数据披露的目标与实际所需披露内容之间的差距、法规要求与实际执行之间的差距以及公开信息对开发者实践及公众理解的实际影响之间的差距。", "conclusion": "文章强调有效的透明路径应注重解决上述三个谬误，提出具体的建议来改善当前的政策实施效果。"}}
{"id": "2601.18125", "pdf": "https://arxiv.org/pdf/2601.18125", "abs": "https://arxiv.org/abs/2601.18125", "authors": ["Mohammad Hadi Nezhad", "Francisco Enrique Vicente Castro", "Ivon Arroyo"], "title": "Understanding Users' Privacy Reasoning and Behaviors During Chatbot Use to Support Meaningful Agency in Privacy", "categories": ["cs.HC", "cs.AI"], "comment": "Preprint of a paper under review", "summary": "Conversational agents (CAs) (e.g., chatbots) are increasingly used in settings where users disclose sensitive information, raising significant privacy concerns. Because privacy judgments are highly contextual, supporting users to engage in privacy-protective actions during chatbot interactions is essential. However, enabling meaningful engagement requires a deeper understanding of how users currently reason about and manage sensitive information during realistic chatbot use scenarios. To investigate this, we qualitatively examined computer science (undergraduate and masters) students' in-the-moment disclosure and protection behaviors, as well as the reasoning underlying these behaviors, across a range of realistic chatbot tasks. Participants used a simulated ChatGPT interface with and without a privacy notice panel that intercepts message submissions, highlights potentially sensitive information, and offers privacy protective actions. The panel supports anonymization through retracting, faking, and generalizing, and surfaces two of ChatGPT's built-in privacy controls to improve their discoverability. Drawing on interaction logs, think-alouds, and survey responses, we analyzed how the panel fostered privacy awareness, encouraged protective actions, and supported context-specific reasoning about what information to protect and how. We further discuss design opportunities for tools that provide users greater and more meaningful agency in protecting sensitive information during CA interactions.", "AI": {"tldr": "研究通过模拟的ChatGPT界面和隐私通知面板，探讨用户在使用聊天机器人时的隐私行为及背后的原因，以支持更有效的隐私保护措施。", "motivation": "随着对话代理（如聊天机器人）被用于需要披露敏感信息的场景中，用户的隐私面临重大挑战。为了提高用户对这些情境中的隐私保护能力，作者希望通过深入理解用户当前如何在现实情况下处理和管理敏感信息来促进有意义的参与。", "method": "研究者通过定性分析计算机科学专业（本科和研究生）学生的实时披露行为和隐私保护措施，并探讨背后的原因。参与者在一个模拟ChatGPT界面中使用了带有或不带隐私通知面板的任务，该面板可以拦截消息提交、突出显示可能敏感的信息并提供隐私防护行动。", "result": "隐私通知面板促进了隐私意识的提高、鼓励用户采取保护性行动，并支持根据具体情境进行有关如何保护信息的具体推理。研究还发现了设计机会，为用户提供更多和更具意义的能力来在对话代理互动中保护敏感信息。", "conclusion": "通过深入理解用户对聊天机器人使用的隐私行为及其背后的原因，可以有效提升用户的隐私意识及采取保护措施的主动性，同时提供更有针对性的设计建议以增强用户体验的安全性和隐私性。"}}
{"id": "2601.18123", "pdf": "https://arxiv.org/pdf/2601.18123", "abs": "https://arxiv.org/abs/2601.18123", "authors": ["Muhammad Ibrahim Khan", "Bivin Pradeep", "James Brusey"], "title": "Deadline-Aware, Energy-Efficient Control of Domestic Immersion Hot Water Heaters", "categories": ["cs.AI"], "comment": "Accepted at AAAI 2026", "summary": "Typical domestic immersion water heater systems are often operated continuously during winter, heating quickly rather than efficiently and ignoring predictable demand windows and ambient losses. We study deadline-aware control, where the aim is to reach a target temperature at a specified time while minimising energy consumption. We introduce an efficient Gymnasium environment that models an immersion hot water heater with first-order thermal losses and discrete on and off actions of 0 W and 6000 W applied every 120 seconds. Methods include a time-optimal bang-bang baseline, a zero-shot Monte Carlo Tree Search planner, and a Proximal Policy Optimisation policy. We report total energy consumption in watt-hours under identical physical dynamics. Across sweeps of initial temperature from 10 to 30 degrees Celsius, deadline from 30 to 90 steps, and target temperature from 40 to 80 degrees Celsius, PPO achieves the most energy-efficient performance at a 60-step horizon of 2 hours, using 3.23 kilowatt-hours, compared to 4.37 to 10.45 kilowatt-hours for bang-bang control and 4.18 to 6.46 kilowatt-hours for MCTS. This corresponds to energy savings of 26 percent at 30 steps and 69 percent at 90 steps. In a representative trajectory with a 50 kg water mass, 20 degrees Celsius ambient temperature, and a 60 degrees Celsius target, PPO consumes 54 percent less energy than bang-bang control and 33 percent less than MCTS. These results show that learned deadline-aware control reduces energy consumption under identical physical assumptions, while planners provide partial savings without training and learned policies offer near-zero inference cost once trained.", "AI": {"tldr": "研究了一种基于时间截止的高效控制方法，用于家庭电热水壶，在保证达到目标温度的同时减少能源消耗。", "motivation": "传统家庭电热水壶系统通常在冬季连续运行，加热速度较快但不节能，忽视了可预测的需求窗口和环境热损失。因此需要一种更高效的控制系统来降低能耗。", "method": "使用Gymnasium模拟器模型电热水壶的控制问题，并采用时间最优开关（bang-bang）基线、无训练蒙特卡洛树搜索规划者以及近端策略优化策略进行比较研究。", "result": "在相同的物理假设下，PPO算法在60步预测期达到最佳节能效果，能耗为3.23千瓦时，相比之下，时间最优开关和MCTS的能耗分别介于4.18到10.45千瓦时不等。这意味着与传统方法相比，PPO可以节省高达69%的能量。", "conclusion": "实验表明通过学习截止时间感知控制策略，在确保物理条件一致的情况下显著减少了能源消耗；而规划者虽然不需要训练也能提供部分节能效果，但一旦完成训练后，学习到的政策几乎不产生推理成本。"}}
{"id": "2601.18121", "pdf": "https://arxiv.org/pdf/2601.18121", "abs": "https://arxiv.org/abs/2601.18121", "authors": ["Byeonggyeol Choi", "Woojin Oh", "Jongwoo Lim"], "title": "Grasp-and-Lift: Executable 3D Hand-Object Interaction Reconstruction via Physics-in-the-Loop Optimization", "categories": ["cs.RO", "cs.CV"], "comment": "13 pages, 7 figures", "summary": "Dexterous hand manipulation increasingly relies on large-scale motion datasets with precise hand-object trajectory data. However, existing resources such as DexYCB and HO3D are primarily optimized for visual alignment but often yield physically implausible interactions when replayed in physics simulators, including penetration, missed contact, and unstable grasps. We propose a simulation-in-the-loop refinement framework that converts these visually aligned trajectories into physically executable ones. Our core contribution is to formulate this as a tractable black-box optimization problem. We parameterize the hand's motion using a low-dimensional, spline-based representation built on sparse temporal keyframes. This allows us to use a powerful gradient-free optimizer, CMA-ES, to treat the high-fidelity physics engine as a black-box objective function. Our method finds motions that simultaneously maximize physical success (e.g., stable grasp and lift) while minimizing deviation from the original human demonstration. Compared to MANIPTRANS-recent transfer pipelines, our approach achieves lower hand and object pose errors during replay and more accurately recovers hand-object physical interactions. Our approach provides a general and scalable method for converting visual demonstrations into physically valid trajectories, enabling the generation of high-fidelity data crucial for robust policy learning.", "AI": {"tldr": "本文提出了一种基于物理仿真的循环优化框架，将视觉对齐的手部操作轨迹转换为可执行的物理交互。", "motivation": "现有的手部物体互动数据集虽然在视觉上精确但物理仿真时出现穿透、接触失败和不稳定抓取等不真实情况。因此需要一种方法使这些数据集中的动作具有物理上的可行性。", "method": "通过参数化低维样条表示的手部运动，并使用无梯度优化器CMA-ES处理高保真物理引擎作为目标函数，实现视觉对齐轨迹向物理可执行的转换。", "result": "与最近的迁移管道相比，该方法在回放时降低了手部和物体的姿态误差，更准确地恢复了手部对象的物理交互。", "conclusion": "提出的方法为将视觉演示转化为物理有效轨迹提供了一种通用且可扩展的方式，生成高保真数据对于稳健策略学习至关重要。"}}
{"id": "2601.18119", "pdf": "https://arxiv.org/pdf/2601.18119", "abs": "https://arxiv.org/abs/2601.18119", "authors": ["Jing Ye", "Yiwen Duan", "Yonghong Yu", "Victor Ma", "Yang Gao", "Xing Chen"], "title": "Beyond Text-to-SQL: Can LLMs Really Debug Enterprise ETL SQL?", "categories": ["cs.AI"], "comment": null, "summary": "SQL is central to enterprise data engineering, yet generating fully correct SQL code in a single attempt remains difficult, even for experienced developers and advanced text-to-SQL LLMs, often requiring multiple debugging iterations. We introduce OurBench, the first benchmark for enterprise-level SQL reasoning and debugging. Our benchmark is built on two key innovations: (1) an automated construction workflow that uses reverse engineering to systematically inject realistic bugs into large-scale SQL code, enabling scalable and diverse benchmark generation; and (2) an execution-free evaluation framework tailored to enterprise settings, providing fast, accurate, and resource-efficient assessment. OurBench comprises 469 OurBenchSyn queries featuring syntax errors with explicit error messages, and 516 OurBenchSem queries targeting semantic errors in which the code fails to meet user intent. The queries are highly complex, averaging over 140 lines and featuring deep and wide abstract syntax trees. Evaluation of nearly 30 LLMs reveals a substantial performance gap: the best-performing model, Claude-4-Sonnet, achieves only 36.46 percent accuracy on OurBenchSyn and 32.17 percent on OurBenchSem, while most models score below 20 percent. We further explore four solution strategies, identify key challenges, and outline promising directions for enterprise SQL debugging with LLMs.", "AI": {"tldr": "介绍了一个用于企业级SQL推理和调试的基准测试OurBench，并评估了LLMs在处理复杂SQL代码中的错误的能力。", "motivation": "生成完全正确的SQL代码仍然具有挑战性，即使对于高级的文本到SQL的大规模语言模型（LLM），这需要多次调试迭代。作者希望通过这个基准测试来推动企业级SQL推理和调试的研究进展。", "method": "创建了一个自动化的构造工作流，并使用反向工程系统地将实际错误注入大规模SQL代码中。此外，他们还提出了一种无需执行的评估框架，以提供快速、准确且资源高效的评估。", "result": "最好的模型Claude-4-Sonnet在OurBenchSyn上仅达到36.46％的准确性，在OurBenchSem上为32.17％，大多数模型得分低于20％。", "conclusion": "研究揭示了LLMs在企业级SQL调试中的性能差距，并提出了四种解决方案策略和未来的研究方向。"}}
{"id": "2601.18118", "pdf": "https://arxiv.org/pdf/2601.18118", "abs": "https://arxiv.org/abs/2601.18118", "authors": ["Daeyoung Kim"], "title": "LungCRCT: Causal Representation based Lung CT Processing for Lung Cancer Treatment", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Due to silence in early stages, lung cancer has been one of the most leading causes of mortality in cancer patients world-wide. Moreover, major symptoms of lung cancer are hard to differentiate with other respiratory disease symptoms such as COPD, further leading patients to overlook cancer progression in early stages. Thus, to enhance survival rates in lung cancer, early detection from consistent proactive respiratory system monitoring becomes crucial. One of the most prevalent and effective methods for lung cancer monitoring would be low-dose computed tomography(LDCT) chest scans, which led to remarkable enhancements in lung cancer detection or tumor classification tasks under rapid advancements and applications of computer vision based AI models such as EfficientNet or ResNet in image processing. However, though advanced CNN models under transfer learning or ViT based models led to high performing lung cancer detections, due to its intrinsic limitations in terms of correlation dependence and low interpretability due to complexity, expansions of deep learning models to lung cancer treatment analysis or causal intervention analysis simulations are still limited. Therefore, this research introduced LungCRCT: a latent causal representation learning based lung cancer analysis framework that retrieves causal representations of factors within the physical causal mechanism of lung cancer progression. With the use of advanced graph autoencoder based causal discovery algorithms with distance Correlation disentanglement and entropy-based image reconstruction refinement, LungCRCT not only enables causal intervention analysis for lung cancer treatments, but also leads to robust, yet extremely light downstream models in malignant tumor classification tasks with an AUC score of 93.91%.", "AI": {"tldr": "提出LungCRCT框架，基于因果表示学习进行肺癌分析。", "motivation": "提高肺癌早期检测率和生存率，克服现有深度学习模型在解释性和因果干预分析上的局限性。", "method": "利用先进的图自编码器结合距离相关解耦技术和熵基图像重建技术来提取肺癌进展中的因果表示。", "result": "实现了对恶性肿瘤分类任务的高准确度（AUC得分93.91%）以及因果干预分析能力。", "conclusion": "LungCRCT框架提供了有效的肺癌治疗因果分析工具，并支持下游模型在肿瘤分类上的优异性能。"}}
{"id": "2601.18115", "pdf": "https://arxiv.org/pdf/2601.18115", "abs": "https://arxiv.org/abs/2601.18115", "authors": ["Guyang Cao", "Shuyao Li", "Sushrut Karmalkar", "Jelena Diakonikolas"], "title": "Robust Learning of a Group DRO Neuron", "categories": ["cs.LG", "cs.DS", "math.OC"], "comment": null, "summary": "We study the problem of learning a single neuron under standard squared loss in the presence of arbitrary label noise and group-level distributional shifts, for a broad family of covariate distributions. Our goal is to identify a ''best-fit'' neuron parameterized by $\\mathbf{w}_*$ that performs well under the most challenging reweighting of the groups. Specifically, we address a Group Distributionally Robust Optimization problem: given sample access to $K$ distinct distributions $\\mathcal p_{[1]},\\dots,\\mathcal p_{[K]}$, we seek to approximate $\\mathbf{w}_*$ that minimizes the worst-case objective over convex combinations of group distributions $\\boldsymbolλ \\in Δ_K$, where the objective is $\\sum_{i \\in [K]}λ_{[i]}\\,\\mathbb E_{(\\mathbf x,y)\\sim\\mathcal p_{[i]}}(σ(\\mathbf w\\cdot\\mathbf x)-y)^2 - νd_f(\\boldsymbolλ,\\frac{1}{K}\\mathbf1)$ and $d_f$ is an $f$-divergence that imposes (optional) penalty on deviations from uniform group weights, scaled by a parameter $ν\\geq 0$. We develop a computationally efficient primal-dual algorithm that outputs a vector $\\widehat{\\mathbf w}$ that is constant-factor competitive with $\\mathbf{w}_*$ under the worst-case group weighting. Our analytical framework directly confronts the inherent nonconvexity of the loss function, providing robust learning guarantees in the face of arbitrary label corruptions and group-specific distributional shifts. The implementation of the dual extrapolation update motivated by our algorithmic framework shows promise on LLM pre-training benchmarks.", "AI": {"tldr": "研究在存在任意标签噪声和群体级分布偏移的情况下，学习单个神经元的最佳参数。", "motivation": "针对标准平方损失下的单一神经元，在存在任意标签噪声及群体级别分布偏差的环境中找到最合适的拟合神经元参数。", "method": "提出了一种处理广义协变量分布下单一神经元学习问题的方法，通过解决组分布鲁棒优化问题来近似最优权重，采用一种计算效率高的原对偶算法输出常数因子竞争性结果。", "result": "开发了一个高效求解的原对偶算法，该算法在最坏情况下的群体加权下仍能保证学习效果，并且通过实验验证了此框架对抗标签腐败和群体特定分布偏移的有效性。", "conclusion": "提出的方法为解决单一神经元鲁棒优化问题提供了一种有效途径，在面对任意标签噪声与分布偏差时，能够实现稳健的学习性能。"}}
{"id": "2601.18113", "pdf": "https://arxiv.org/pdf/2601.18113", "abs": "https://arxiv.org/abs/2601.18113", "authors": ["Dezhang Kong", "Zhuxi Wu", "Shiqi Liu", "Zhicheng Tan", "Kuichen Lu", "Minghao Li", "Qichen Liu", "Shengyu Chu", "Zhenhua Xu", "Xuan Liu", "Meng Han"], "title": "MalURLBench: A Benchmark Evaluating Agents' Vulnerabilities When Processing Web URLs", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "LLM-based web agents have become increasingly popular for their utility in daily life and work. However, they exhibit critical vulnerabilities when processing malicious URLs: accepting a disguised malicious URL enables subsequent access to unsafe webpages, which can cause severe damage to service providers and users. Despite this risk, no benchmark currently targets this emerging threat. To address this gap, we propose MalURLBench, the first benchmark for evaluating LLMs' vulnerabilities to malicious URLs. MalURLBench contains 61,845 attack instances spanning 10 real-world scenarios and 7 categories of real malicious websites. Experiments with 12 popular LLMs reveal that existing models struggle to detect elaborately disguised malicious URLs. We further identify and analyze key factors that impact attack success rates and propose URLGuard, a lightweight defense module. We believe this work will provide a foundational resource for advancing the security of web agents. Our code is available at https://github.com/JiangYingEr/MalURLBench.", "AI": {"tldr": "提出MalURLBench，评估LLM处理恶意网址的能力。", "motivation": "由于缺乏针对恶意网址的评估基准，现有模型难以检测到精心伪装的恶意网址，造成安全隐患。", "method": "构建包含61,845个攻击实例和7类真实恶意网站的MalURLBench，并测试了12种流行LLM的表现；分析影响成功率的关键因素，提出URLGuard轻量级防御模块。", "result": "现有模型难以准确识别伪装的恶意网址，揭示了关键影响因素并开发出有效防御方案。", "conclusion": "MalURLBench为评估和提升LLM处理恶意网址的能力提供了基础资源。"}}
{"id": "2601.18111", "pdf": "https://arxiv.org/pdf/2601.18111", "abs": "https://arxiv.org/abs/2601.18111", "authors": ["Jean Kossaifi", "Nikola Kovachki", "Morteza Mardani", "Daniel Leibovici", "Suman Ravuri", "Ira Shokar", "Edoardo Calvello", "Mohammad Shoaib Abbas", "Peter Harrington", "Ashay Subramaniam", "Noah Brenowitz", "Boris Bonev", "Wonmin Byeon", "Karsten Kreis", "Dale Durran", "Arash Vahdat", "Mike Pritchard", "Jan Kautz"], "title": "Demystifying Data-Driven Probabilistic Medium-Range Weather Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The recent revolution in data-driven methods for weather forecasting has lead to a fragmented landscape of complex, bespoke architectures and training strategies, obscuring the fundamental drivers of forecast accuracy. Here, we demonstrate that state-of-the-art probabilistic skill requires neither intricate architectural constraints nor specialized training heuristics. We introduce a scalable framework for learning multi-scale atmospheric dynamics by combining a directly downsampled latent space with a history-conditioned local projector that resolves high-resolution physics. We find that our framework design is robust to the choice of probabilistic estimator, seamlessly supporting stochastic interpolants, diffusion models, and CRPS-based ensemble training. Validated against the Integrated Forecasting System and the deep learning probabilistic model GenCast, our framework achieves statistically significant improvements on most of the variables. These results suggest scaling a general-purpose model is sufficient for state-of-the-art medium-range prediction, eliminating the need for tailored training recipes and proving effective across the full spectrum of probabilistic frameworks.", "AI": {"tldr": "本文提出了一个可扩展的框架，用于学习多尺度的大气动力学，并展示了该框架在中长期天气预报中的优越性能。", "motivation": "近年来数据驱动方法的发展使得气象预报变得复杂且难以理解。作者希望通过简化架构和训练策略来提高预报准确性的根本驱动力。", "method": "结合直接下采样的潜在空间与历史条件下的局部投影器，以解决高分辨率物理问题的框架设计，并证明了该设计对于概率估计的选择具有鲁棒性。", "result": "在与综合预测系统和深度学习模型GenCast比较时，本文提出的框架在大多数变量上实现了统计显著性的改进。", "conclusion": "一般通用模型可以达到最先进的中长期预报精度，无需定制的训练方案，并且适用于全概率框架。"}}
{"id": "2601.18107", "pdf": "https://arxiv.org/pdf/2601.18107", "abs": "https://arxiv.org/abs/2601.18107", "authors": ["Pedram Agand", "Mo Chen"], "title": "Beyond Static Datasets: Robust Offline Policy Optimization via Vetted Synthetic Transitions", "categories": ["cs.LG", "cs.HC", "cs.RO"], "comment": "11 pages, 2 figures, 2 tables", "summary": "Offline Reinforcement Learning (ORL) holds immense promise for safety-critical domains like industrial robotics, where real-time environmental interaction is often prohibitive. A primary obstacle in ORL remains the distributional shift between the static dataset and the learned policy, which typically mandates high degrees of conservatism that can restrain potential policy improvements. We present MoReBRAC, a model-based framework that addresses this limitation through Uncertainty-Aware latent synthesis. Instead of relying solely on the fixed data, MoReBRAC utilizes a dual-recurrent world model to synthesize high-fidelity transitions that augment the training manifold. To ensure the reliability of this synthetic data, we implement a hierarchical uncertainty pipeline integrating Variational Autoencoder (VAE) manifold detection, model sensitivity analysis, and Monte Carlo (MC) dropout. This multi-layered filtering process guarantees that only transitions residing within high-confidence regions of the learned dynamics are utilized. Our results on D4RL Gym-MuJoCo benchmarks reveal significant performance gains, particularly in ``random'' and ``suboptimal'' data regimes. We further provide insights into the role of the VAE as a geometric anchor and discuss the distributional trade-offs encountered when learning from near-optimal datasets.", "AI": {"tldr": "该论文提出了MoReBRAC框架，利用不确定性感知的合成数据增强离线强化学习中的训练。", "motivation": "旨在解决静态数据集与学习策略之间的分布偏移问题，提高离线强化学习在安全关键领域的应用效果。", "method": "通过双循环世界模型生成高保真过渡状态，并采用多层不确定性过滤确保合成数据的可靠性。使用变分自编码器检测流形、模型敏感性分析和蒙特卡洛丢弃方法进行过滤。", "result": "在D4RL Gym-MuJoCo基准测试中，显示出显著性能提升，特别是在随机和亚最优的数据集上表现突出。", "conclusion": "提出了MoReBRAC框架，通过生成高保真合成数据解决离线强化学习中的分布偏移问题。"}}
{"id": "2601.18105", "pdf": "https://arxiv.org/pdf/2601.18105", "abs": "https://arxiv.org/abs/2601.18105", "authors": ["Mohammad Fasha", "Faisal Abul Rub", "Nasim Matar", "Bilal Sowan", "Mohammad Al Khaldy"], "title": "Mitigating the OWASP Top 10 For Large Language Models Applications using Intelligent Agents", "categories": ["cs.CR", "cs.AI"], "comment": "5 pages", "summary": "Large Language Models (LLMs) have emerged as a transformative and disruptive technology, enabling a wide range of applications in natural language processing, machine translation, and beyond. However, this widespread integration of LLMs also raised several security concerns highlighted by the Open Web Application Security Project (OWASP), which has identified the top 10 security vulnerabilities inherent in LLM applications. Addressing these vulnerabilities is crucial, given the increasing reliance on LLMs and the potential threats to data integrity, confidentiality, and service availability. This paper presents a framework designed to mitigate the security risks outlined in the OWASP Top 10. Our proposed model leverages LLM-enabled intelligent agents, offering a new approach to proactively identify, assess, and counteract security threats in real-time. The proposed framework serves as an initial blueprint for future research and development, aiming to enhance the security measures of LLMs and protect against emerging threats in this rapidly evolving landscape.", "AI": {"tldr": "本文提出了一个框架，利用大型语言模型（LLM）驱动的智能代理来减轻OWASP十大安全漏洞的风险。", "motivation": "随着大型语言模型在各种应用中的广泛应用，其安全性问题日益突出。本文旨在通过一种新的方法来应对这些威胁，保障数据完整性和服务可用性。", "method": "论文提出了一种框架，该框架利用LLM驱动的智能代理来实时识别和对抗安全威胁。", "result": "研究结果表明，所提出的模型可以有效减轻OWASP十大漏洞的风险，为未来的研究提供了初步蓝图。", "conclusion": "通过引入智能代理，本文提供了一个新的视角来提升大型语言模型的安全性，并应对不断变化的威胁环境。"}}
{"id": "2601.18100", "pdf": "https://arxiv.org/pdf/2601.18100", "abs": "https://arxiv.org/abs/2601.18100", "authors": ["James Tribble", "Hao Wang", "Si-En Hong", "Chaoyi Zhou", "Ashish Bastola", "Siyu Huang", "Abolfazl Razi"], "title": "Spatial-Conditioned Reasoning in Long-Egocentric Videos", "categories": ["cs.CV"], "comment": null, "summary": "Long-horizon egocentric video presents significant challenges for visual navigation due to viewpoint drift and the absence of persistent geometric context. Although recent vision-language models perform well on image and short-video reasoning, their spatial reasoning capability in long egocentric sequences remains limited. In this work, we study how explicit spatial signals influence VLM-based video understanding without modifying model architectures or inference procedures. We introduce Sanpo-D, a fine-grained re-annotation of the Google Sanpo dataset, and benchmark multiple VLMs on navigation-oriented spatial queries. To examine input-level inductive bias, we further fuse depth maps with RGB frames and evaluate their impact on spatial reasoning. Our results reveal a trade-off between general-purpose accuracy and spatial specialization, showing that depth-aware and spatially grounded representations can improve performance on safety-critical tasks such as pedestrian and obstruction detection.", "AI": {"tldr": "本文研究了显式空间信号如何影响基于视觉语言模型的视频理解，特别是在长时间的第一人称视角视频中的空间推理能力。", "motivation": "当前的视觉语言模型在图像和短视频推理中表现良好，但在长第一人称视角序列的空间推理方面存在局限性。为了解决这一问题并提高安全关键任务的表现（如行人和障碍物检测），本文探究了显式空间信号的作用。", "method": "本文引入了Sanpo-D数据集的细化注释，并评估了几种视觉语言模型在导航相关空间查询上的性能；进一步通过融合深度图与RGB图像帧来考察输入级归纳偏差的影响。", "result": "研究结果揭示了一个权衡：通用准确率和空间专门化之间的平衡，显示加入深度信息的空间导向表示可以增强安全关键任务的性能。", "conclusion": "显式空间信号对于提高基于视觉语言模型在长时间第一人称视角视频中的空间推理能力至关重要，而这种改进对执行安全关键任务特别有利。"}}
{"id": "2601.18099", "pdf": "https://arxiv.org/pdf/2601.18099", "abs": "https://arxiv.org/abs/2601.18099", "authors": ["Akbar Saadat"], "title": "Computational Framework for Estimating Relative Gaussian Blur Kernels between Image Pairs", "categories": ["cs.CV"], "comment": "9 pages, 14 input images, 3 TikZ images. arXiv admin note: substantial text overlap with arXiv:2601.04779. substantial text overlap with arXiv:2601.04779. substantial text overlap with arXiv:2601.04779. substantial text overlap with arXiv:2601.04779", "summary": "Following the earlier verification for Gaussian model in \\cite{ASaa2026}, this paper introduces a zero training forward computational framework for the model to realize it in real time applications. The framework is based on discrete calculation of the analytic expression of the defocused image from the sharper one for the application range of the standard deviation of the Gaussian kernels and selecting the best matches. The analytic expression yields multiple solutions at certain image points, but is filtered down to a single solution using similarity measures over neighboring points.The framework is structured to handle cases where two given images are partial blurred versions of each other. Experimental evaluations on real images demonstrate that the proposed framework achieves a mean absolute error (MAE) below $1.7\\%$ in estimating synthetic blur values. Furthermore, the discrepancy between actual blurred image intensities and their corresponding estimates remains under $2\\%$, obtained by applying the extracted defocus filters to less blurred images.", "AI": {"tldr": "提出了一种用于实时应用的计算框架，以估计图像对之间的相对高斯模糊核。", "motivation": "为了验证在实际应用场景中使用高斯模型的可能性，并实现无需训练的即时估计方法。", "method": "通过分析表达式计算从锐图到模糊图的变化，并利用相似度测度筛选解。框架能够处理部分模糊图像，通过选择最佳匹配来降低误差。", "result": "实验结果显示，在估算合成模糊值方面，该框架的平均绝对误差（MAE）低于1.7%；实际模糊强度与估计值之间的差异保持在2%以内。", "conclusion": "所提出的计算框架能够有效且准确地估计图像对之间的高斯模糊核，并应用于实时场景中。"}}
{"id": "2601.18098", "pdf": "https://arxiv.org/pdf/2601.18098", "abs": "https://arxiv.org/abs/2601.18098", "authors": ["Chuang Yang", "Haozhao Ma", "Xu Han", "Yuan Yuan", "Qi Wang"], "title": "Text-Pass Filter: An Efficient Scene Text Detector", "categories": ["cs.CV"], "comment": null, "summary": "To pursue an efficient text assembling process, existing methods detect texts via the shrink-mask expansion strategy. However, the shrinking operation loses the visual features of text margins and confuses the foreground and background difference, which brings intrinsic limitations to recognize text features. We follow this issue and design Text-Pass Filter (TPF) for arbitrary-shaped text detection. It segments the whole text directly, which avoids the intrinsic limitations. It is noteworthy that different from previous whole text region-based methods, TPF can separate adhesive texts naturally without complex decoding or post-processing processes, which makes it possible for real-time text detection. Concretely, we find that the band-pass filter allows through components in a specified band of frequencies, called its passband but blocks components with frequencies above or below this band. It provides a natural idea for extracting whole texts separately. By simulating the band-pass filter, TPF constructs a unique feature-filter pair for each text. In the inference stage, every filter extracts the corresponding matched text by passing its pass-feature and blocking other features. Meanwhile, considering the large aspect ratio problem of ribbon-like texts makes it hard to recognize texts wholly, a Reinforcement Ensemble Unit (REU) is designed to enhance the feature consistency of the same text and to enlarge the filter's recognition field to help recognize whole texts. Furthermore, a Foreground Prior Unit (FPU) is introduced to encourage TPF to discriminate the difference between the foreground and background, which improves the feature-filter pair quality. Experiments demonstrate the effectiveness of REU and FPU while showing the TPF's superiority.", "AI": {"tldr": "设计了一种名为Text-Pass Filter (TPF)的文本检测算法，用于高效地检测任意形状的文字。", "motivation": "现有方法通过缩小掩模扩展策略来检测文字，这会导致视觉特征丢失和前景背景混淆的问题。因此提出TPF以直接分割整个文本区域，并且可以自然区分粘连的文字，实现实时检测。", "method": "TPF模拟带通滤波器的概念，为每个文本构建一个独特的特征-过滤器对，在推理阶段通过匹配的特性并通过阻塞其他特性来提取对应的文本。为了处理细长文字识别困难的问题设计了Reinforcement Ensemble Unit (REU)，以增强同一文本的特征一致性，并扩大过滤器的识别范围；同时引入Foreground Prior Unit (FPU)来鼓励TPF区分前景和背景，提高特征-过滤器对的质量。", "result": "实验表明TPF可以有效地分离粘连的文字，并且比现有方法有更好的性能。REU和FPU的加入进一步提高了文本检测的效果。", "conclusion": "TPF通过直接分割整个文本区域而不是缩小掩模的方法解决了现有技术中的一些固有限制，实现了更准确、高效的任意形状文字识别任务。"}}
{"id": "2601.18094", "pdf": "https://arxiv.org/pdf/2601.18094", "abs": "https://arxiv.org/abs/2601.18094", "authors": ["Zhichao Wang", "Tao Li", "Wenshuo Ge", "Zihao Cui", "Shilei Zhang", "Junlan Feng"], "title": "OneVoice: One Model, Triple Scenarios-Towards Unified Zero-shot Voice Conversion", "categories": ["eess.AS", "cs.SD"], "comment": "Work in progress", "summary": "Recent progress of voice conversion~(VC) has achieved a new milestone in speaker cloning and linguistic preservation. But the field remains fragmented, relying on specialized models for linguistic-preserving, expressive, and singing scenarios. We propose OneVoice, a unified zero-shot framework capable of handling all three scenarios within a single model. OneVoice is built upon a continuous language model trained with VAE-free next-patch diffusion, ensuring high fidelity and efficient sequence modeling. Its core design for unification lies in a Mixture-of-Experts (MoE) designed to explicitly model shared conversion knowledge and scenario-specific expressivity. Expert selection is coordinated by a dual-path routing mechanism, including shared expert isolation and scenario-aware domain expert assignment with global-local cues. For precise conditioning, scenario-specific prosodic features are fused into each layer via a gated mechanism, allowing adaptive usage of prosody information. Furthermore, to enable the core idea and alleviate the imbalanced issue (abundant speech vs. scarce singing), we adopt a two-stage progressive training that includes foundational pre-training and scenario enhancement with LoRA-based domain experts. Experiments show that OneVoice matches or surpasses specialized models across all three scenarios, while verifying flexible control over scenarios and offering a fast decoding version as few as 2 steps. Code and model will be released soon.", "AI": {"tldr": "本文提出了一种统一的零样本语音转换框架OneVoice，能够在单一模型中处理语言保持、表达性和歌唱三种场景。", "motivation": "当前语音转换领域存在碎片化问题，需要专用模型分别处理不同场景。作者旨在通过一个统一模型解决这一挑战，提高效率和通用性。", "method": "OneVoice基于连续语言模型构建，并采用VAE-free next-patch扩散训练。其核心设计为Mixture-of-Experts（MoE），用于显式建模共享转换知识及特定场景的表达能力。通过双路径路由机制协调专家选择，结合全局和局部线索分配领域专家。此外，融合特定场景韵律特征以精准控制。", "result": "实验结果显示，OneVoice在所有三种场景下表现与专用模型相当或更优，并验证了其对场景的灵活控制能力及快速解码特性。", "conclusion": "本文提出的OneVoice框架成功实现了统一语音转换模型的目标，展示了跨场景的通用性和优越性能。"}}
{"id": "2601.18092", "pdf": "https://arxiv.org/pdf/2601.18092", "abs": "https://arxiv.org/abs/2601.18092", "authors": ["Nan Chen", "Jing Lu", "Zilong Wang", "Luna K. Qiu", "Siming Chen", "Yuqing Yang"], "title": "From Struggle to Success: Context-Aware Guidance for Screen Reader Users in Computer Use", "categories": ["cs.HC"], "comment": "Conditionally accepted to ACM CHI 2026", "summary": "Equal access to digital technologies is critical for education, employment, and social participation. However, mainstream interfaces are visually oriented, creating steep learning curves and frequent obstacles for screen reader users, and limiting their independence and opportunities. Existing support is inadequate -- tutorials mainly target sighted users, while human assistance lacks real-time availability. We introduce AskEase, an on-demand AI assistant that provides step-by-step, screen reader user-friendly guidance for computer use. AskEase manages multiple sources of context to infer user intent and deliver precise, situation-specific guidance. Its seamless interaction design minimizes disruption and reduces the effort of seeking help. We demonstrated its effectiveness through representative usage scenarios and robustness tests. In a within-subjects study with 12 screen reader users, AskEase significantly improved task success while reducing perceived workload, including physical demand, effort, and frustration. These results demonstrate the potential of LLM-powered assistants to promote accessible computing and expand opportunities for users with visual impairments.", "AI": {"tldr": "本文介绍了一种名为AskEase的AI助手，旨在为屏幕阅读器用户提供实时、个性化的计算机使用指导。", "motivation": "主流界面视觉导向性强，导致屏幕阅读器用户面临学习困难和频繁障碍，影响其独立性和机会。现有辅助工具不足，教程主要针对视力正常者，且人工帮助无法实时提供。", "method": "AskEase通过整合多种上下文信息来推断用户意图，并提供精确的、情境特定的指导。该系统采用无缝交互设计，减少干扰并降低求助努力，在代表性使用场景和鲁棒性测试中展示了有效性。", "result": "在12名屏幕阅读器用户的实验中，AskEase显著提高了任务成功率，同时减少了感知工作量，包括物理需求、努力和挫折感。", "conclusion": "这些结果表明，基于LLM的辅助工具具有促进可访问计算和扩大视力障碍用户机会的巨大潜力。"}}
{"id": "2601.18089", "pdf": "https://arxiv.org/pdf/2601.18089", "abs": "https://arxiv.org/abs/2601.18089", "authors": ["Venmugil Elango", "Nidhi Bhatia", "Roger Waleffe", "Rasoul Shafipour", "Tomer Asida", "Abhinav Khattar", "Nave Assaf", "Maximilian Golub", "Joey Guman", "Tiyasa Mitra", "Ritchie Zhao", "Ritika Borkar", "Ran Zilberstein", "Mostofa Patwary", "Mohammad Shoeybi", "Bita Rouhani"], "title": "LatentMoE: Toward Optimal Accuracy per FLOP and Parameter in Mixture of Experts", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mixture of Experts (MoEs) have become a central component of many state-of-the-art open-source and proprietary large language models. Despite their widespread adoption, it remains unclear how close existing MoE architectures are to optimal with respect to inference cost, as measured by accuracy per floating-point operation and per parameter. In this work, we revisit MoE design from a hardware-software co-design perspective, grounded in empirical and theoretical considerations. We characterize key performance bottlenecks across diverse deployment regimes, spanning offline high-throughput execution and online, latency-critical inference. Guided by these insights, we introduce LatentMoE, a new model architecture resulting from systematic design exploration and optimized for maximal accuracy per unit of compute. Empirical design space exploration at scales of up to 95B parameters and over a 1T-token training horizon, together with supporting theoretical analysis, shows that LatentMoE consistently outperforms standard MoE architectures in terms of accuracy per FLOP and per parameter. Given its strong performance, the LatentMoE architecture has been adopted by the flagship Nemotron-3 Super and Ultra models and scaled to substantially larger regimes, including longer token horizons and larger model sizes, as reported in Nvidia et al. (arXiv:2512.20856).", "AI": {"tldr": "研究提出一种新的Mixture of Experts（MoE）架构LatentMoE，旨在优化计算资源利用率，实现更优的精度-算力比。", "motivation": "现有的MoE架构在准确性与计算成本之间的权衡尚不明确。本文通过软硬件协同设计方法，探索如何提高现有架构的效率，并提出了新的模型架构以期达到最优性能。", "method": "从实验和理论角度重新审视MoE的设计，识别关键瓶颈，并引入LatentMoE进行系统化设计优化，实现最大化的精度-算力比。通过大规模训练和分析支持该方法的有效性。", "result": "实证研究表明，无论是在高吞吐量执行还是低延迟推理场景下，LatentMoE在精度与计算成本之间提供了更好的权衡，优于标准的MoE架构。", "conclusion": "LatentMoE架构已被用于Nemotron-3 Super和Ultra模型，并扩展到更大的规模上。该设计展示了其强大的性能潜力和发展前景。"}}
{"id": "2601.18088", "pdf": "https://arxiv.org/pdf/2601.18088", "abs": "https://arxiv.org/abs/2601.18088", "authors": ["Jianshu Chao", "Tianhua Lv", "Qiqiong Ma", "Yunfei Qiu", "Li Fang", "Huifang Shen", "Wei Yao"], "title": "Cross-Domain Transfer with Self-Supervised Spectral-Spatial Modeling for Hyperspectral Image Classification", "categories": ["cs.CV"], "comment": null, "summary": "Self-supervised learning has demonstrated considerable potential in hyperspectral representation, yet its application in cross-domain transfer scenarios remains under-explored. Existing methods, however, still rely on source domain annotations and are susceptible to distribution shifts, leading to degraded generalization performance in the target domain. To address this, this paper proposes a self-supervised cross-domain transfer framework that learns transferable spectral-spatial joint representations without source labels and achieves efficient adaptation under few samples in the target domain. During the self-supervised pre-training phase, a Spatial-Spectral Transformer (S2Former) module is designed. It adopts a dual-branch spatial-spectral transformer and introduces a bidirectional cross-attention mechanism to achieve spectral-spatial collaborative modeling: the spatial branch enhances structural awareness through random masking, while the spectral branch captures fine-grained differences. Both branches mutually guide each other to improve semantic consistency. We further propose a Frequency Domain Constraint (FDC) to maintain frequency-domain consistency through real Fast Fourier Transform (rFFT) and high-frequency magnitude loss, thereby enhancing the model's capability to discern fine details and boundaries. During the fine-tuning phase, we introduce a Diffusion-Aligned Fine-tuning (DAFT) distillation mechanism. This aligns semantic evolution trajectories through a teacher-student structure, enabling robust transfer learning under low-label conditions. Experimental results demonstrate stable classification performance and strong cross-domain adaptability across four hyperspectral datasets, validating the method's effectiveness under resource-constrained conditions.", "AI": {"tldr": "提出了一种无源标签的自监督跨域迁移框架，用于高光谱图像分类。", "motivation": "现有的方法依赖于源领域的标注，并且在目标领域中容易受到分布偏移的影响。因此需要一种新的方法来提高在目标领域中的泛化性能。", "method": "设计了空间-光谱变换器（S2Former）模块，采用双向交叉注意机制实现光谱和空间的协作建模；同时引入频率域约束以保持频率一致性。此外，在微调阶段提出了扩散对齐微调（DAFT）蒸馏机制以增强在低标签条件下的稳健迁移学习能力。", "result": "实验结果表明该方法具有稳定分类性能及强跨域适应性，验证了其在资源受限条件下的有效性。", "conclusion": "所提的自监督跨域传输框架能够提高高光谱图像分类的准确性，在少样本条件下实现高效的迁移学习。"}}
{"id": "2601.18086", "pdf": "https://arxiv.org/pdf/2601.18086", "abs": "https://arxiv.org/abs/2601.18086", "authors": ["Mengcheng Huang", "Xue Zhou", "Chen Xu", "Dapeng Man"], "title": "From Human Speech to Ocean Signals: Transferring Speech Large Models for Underwater Acoustic Target Recognition", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Underwater acoustic target recognition (UATR) plays a vital role in marine applications but remains challenging due to limited labeled data and the complexity of ocean environments. This paper explores a central question: can speech large models (SLMs), trained on massive human speech corpora, be effectively transferred to underwater acoustics? To investigate this, we propose UATR-SLM, a simple framework that reuses the speech feature pipeline, adapts the SLM as an acoustic encoder, and adds a lightweight classifier.Experiments on the DeepShip and ShipsEar benchmarks show that UATR-SLM achieves over 99% in-domain accuracy, maintains strong robustness across variable signal lengths, and reaches up to 96.67% accuracy in cross-domain evaluation. These results highlight the strong transferability of SLMs to UATR, establishing a promising paradigm for leveraging speech foundation models in underwater acoustics.", "AI": {"tldr": "本文探讨了将大规模语音模型（SLM）转移到水下声学目标识别中的可行性。", "motivation": "水下声学目标识别面临标注数据少和海洋环境复杂的问题，探索能否利用大规模训练的语音模型来提升其性能。", "method": "提出UATR-SLM框架，复用语音特征管道，将SLM作为声学编码器，并添加轻量级分类器进行适应性调整。", "result": "在DeepShip和ShipsEar基准测试中，UATR-SLM达到了超过99%的领域内准确率，对信号长度变化具有较强的鲁棒性，在跨域评估中可达最高96.67%的准确率。", "conclusion": "研究结果表明SLM具有很强的水下声学目标识别迁移能力，为利用语音基础模型在水下声学中的应用提供了新思路。"}}
{"id": "2601.18085", "pdf": "https://arxiv.org/pdf/2601.18085", "abs": "https://arxiv.org/abs/2601.18085", "authors": ["Brian Gin", "Ahreum Lim", "Flávia Silva e Oliveira", "Kuan Xing", "Xiaomei Song", "Gayana Amiyangoda", "Thilanka Seneviratne", "Alison F. Doubleday", "Ananya Gangopadhyaya", "Bob Kiser", "Lukas Shum-Tim", "Dhruva Patel", "Kosala Marambe", "Lauren Maggio", "Ara Tekian", "Yoon Soo Park"], "title": "\"Crash Test Dummies\" for AI-Enabled Clinical Assessment: Validating Virtual Patient Scenarios with Virtual Learners", "categories": ["cs.HC", "cs.AI", "stat.AP"], "comment": null, "summary": "Background: In medical and health professions education (HPE), AI is increasingly used to assess clinical competencies, including via virtual standardized patients. However, most evaluations rely on AI-human interrater reliability and lack a measurement framework for how cases, learners, and raters jointly shape scores. This leaves robustness uncertain and can expose learners to misguidance from unvalidated systems. We address this by using AI \"simulated learners\" to stress-test and psychometrically characterize assessment pipelines before human use. Objective: Develop an open-source AI virtual patient platform and measurement model for robust competency evaluation across cases and rating conditions. Methods: We built a platform with virtual patients, virtual learners with tunable ACGME-aligned competency profiles, and multiple independent AI raters scoring encounters with structured Key-Features items. Transcripts were analyzed with a Bayesian HRM-SDT model that treats ratings as decisions under uncertainty and separates learner ability, case performance, and rater behavior; parameters were estimated with MCMC. Results: The model recovered simulated learners' competencies, with significant correlations to the generating competencies across all ACGME domains despite a non-deterministic pipeline. It estimated case difficulty by competency and showed stable rater detection (sensitivity) and criteria (severity/leniency thresholds) across AI raters using identical models/prompts but different seeds. We also propose a staged \"safety blueprint\" for deploying AI tools with learners, tied to entrustment-based validation milestones. Conclusions: Combining a purpose-built virtual patient platform with a principled psychometric model enables robust, interpretable, generalizable competency estimates and supports validation of AI-assisted assessment prior to use with human learners.", "AI": {"tldr": "开发一种使用AI虚拟患者和学习者的开放平台，以评估临床能力并确保评分系统的可靠性。", "motivation": "在医学教育中，虽然人工智能越来越多地用于评估临床技能，但缺乏一个测量框架来验证这些系统。因此，本文旨在通过使用AI虚拟学习者来进行压力测试，以确保评分系统的可靠性和有效性。", "method": "构建了一个包含虚拟患者、具有可调AAMC标准能力配置文件的虚拟学生以及多个独立的人工智能评估者的平台。利用贝叶斯HRM-SDT模型对评分进行分析，并使用马尔科夫链蒙特卡洛方法估计参数，以区分学习者的能力、案例难度和评价人行为。", "result": "该模型能够恢复模拟学员的技能水平，即使在不确定性的评估管道中也具有显著的相关性。此外，它还能估算案例难度并显示稳定的人工智能评估者的检测能力与评分标准。", "conclusion": "结合专门设计的虚拟患者平台和原理驱动的心理测量模型，可以提供稳健、可解释且通用的能力估计，并支持在实际使用前对AI辅助评估工具进行验证。"}}
{"id": "2601.18069", "pdf": "https://arxiv.org/pdf/2601.18069", "abs": "https://arxiv.org/abs/2601.18069", "authors": ["Haoyuan Pan", "Sizhao Chen", "Zhaorui Wang", "Tse-Tin Chan"], "title": "Diffusion Model-based Reinforcement Learning for Version Age of Information Scheduling: Average and Tail-Risk-Sensitive Control", "categories": ["cs.NI", "cs.AI"], "comment": "16 pages, 11 figures", "summary": "Ensuring timely and semantically accurate information delivery is critical in real-time wireless systems. While Age of Information (AoI) quantifies temporal freshness, Version Age of Information (VAoI) captures semantic staleness by accounting for version evolution between transmitters and receivers. Existing VAoI scheduling approaches primarily focus on minimizing average VAoI, overlooking rare but severe staleness events that can compromise reliability under stochastic packet arrivals and unreliable channels. This paper investigates both average-oriented and tail-risk-sensitive VAoI scheduling in a multi-user status update system with long-term transmission cost constraints. We first formulate the average VAoI minimization problem as a constrained Markov decision process and introduce a deep diffusion-based Soft Actor-Critic (D2SAC) algorithm. By generating actions through a diffusion-based denoising process, D2SAC enhances policy expressiveness and establishes a strong baseline for mean performance. Building on this foundation, we put forth RS-D3SAC, a risk-sensitive deep distributional diffusion-based Soft Actor-Critic algorithm. RS-D3SAC integrates a diffusion-based actor with a quantile-based distributional critic, explicitly modeling the full VAoI return distribution. This enables principled tail-risk optimization via Conditional Value-at-Risk (CVaR) while satisfying long-term transmission cost constraints. Extensive simulations show that, while D2SAC reduces average VAoI, RS-D3SAC consistently achieves substantial reductions in CVaR without sacrificing mean performance. The dominant gain in tail-risk reduction stems from the distributional critic, with the diffusion-based actor providing complementary refinement to stabilize and enrich policy decisions, highlighting their effectiveness for robust and risk-aware VAoI scheduling in multi-user wireless systems.", "AI": {"tldr": "本文研究了基于平均和尾部风险敏感的VAoI调度问题，并提出了一种新的深度扩散模型辅助强化学习算法。", "motivation": "现有的VAoI调度方法主要关注于最小化平均VAoI，忽略了罕见但严重的信息过时事件，在随机分组到达和不可靠信道的情况下可能会损害可靠性。本文旨在解决这些问题，引入了风险敏感的VAoI调度方案。", "method": "通过将平均VAoI最小化问题形式化为受限马尔科夫决策过程，并提出了一种深度扩散模型辅助Soft Actor-Critic算法（D2SAC），进一步发展出一种风险敏感的分布式深度扩散辅助Soft Actor-Critic算法（RS-D3SAC）。", "result": "实验结果表明，虽然D2SAC降低了平均VAoI，但RS-D3SAC在不牺牲均值性能的情况下显著减少了CVaR。这种改进主要归功于基于分布的批评者，并且扩散辅助演员提供了互补的细化以稳定和丰富政策决策。", "conclusion": "本文提出的算法不仅增强了策略表达能力，还通过建立风险敏感性优化实现了VAoI调度的有效性和鲁棒性。"}}
{"id": "2601.18067", "pdf": "https://arxiv.org/pdf/2601.18067", "abs": "https://arxiv.org/abs/2601.18067", "authors": ["Wei-Po Hsin", "Ren-Hao Deng", "Yao-Ting Hsieh", "En-Ming Huang", "Shih-Hao Hung"], "title": "EvolVE: Evolutionary Search for LLM-based Verilog Generation and Optimization", "categories": ["cs.AI", "cs.NE", "cs.PL"], "comment": "17 pages, 6 figures, 8 tables", "summary": "Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL.", "AI": {"tldr": "提出了EvolVE框架，利用进化策略和大型语言模型生成和优化Verilog代码。", "motivation": "现有的大型语言模型在硬件设计中的应用受限于其训练数据有限及推理能力不足。为了提高自动化设计流程的效率和质量，提出了一种新的框架来解决这些问题。", "method": "EvolVE结合了多种进化策略（如蒙特卡洛树搜索MCTS和指导性思想优化IGR），并利用结构化测试生成STG加速演化过程。通过引入IC-RTL基准集针对大规模设计问题进行验证。", "result": "实验结果显示，该方法在VerilogEval v2和RTLLM v2上的准确性分别达到了98.1%和92%，并且在IC-RTL工业规模测试套件中相较于参赛者实现的参考实施，性能、功耗及面积（PPA）改进了66%。", "conclusion": "EvolVE框架有效提升了基于大型语言模型生成Verilog代码的质量与效率，在复杂设计任务中的优化效果显著。"}}
{"id": "2601.18064", "pdf": "https://arxiv.org/pdf/2601.18064", "abs": "https://arxiv.org/abs/2601.18064", "authors": ["Hasi Hays"], "title": "Resonant Sparse Geometry Networks", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "We introduce Resonant Sparse Geometry Networks (RSGN), a brain-inspired architecture with self-organizing sparse hierarchical input-dependent connectivity. Unlike Transformer architectures that employ dense attention mechanisms with O(n^2) computational complexity, RSGN embeds computational nodes in learned hyperbolic space where connection strength decays with geodesic distance, achieving dynamic sparsity that adapts to each input. The architecture operates on two distinct timescales: fast differentiable activation propagation optimized through gradient descent, and slow Hebbian-inspired structural learning for connectivity adaptation through local correlation rules. We provide rigorous mathematical analysis demonstrating that RSGN achieves O(n*k) computational complexity, where k << n represents the average active neighborhood size. Experimental evaluation on hierarchical classification and long-range dependency tasks demonstrates that RSGN achieves 96.5% accuracy on long-range dependency tasks while using approximately 15x fewer parameters than standard Transformers. On challenging hierarchical classification with 20 classes, RSGN achieves 23.8% accuracy (compared to 5% random baseline) with only 41,672 parameters, nearly 10x fewer than the Transformer baselines which require 403,348 parameters to achieve 30.1% accuracy. Our ablation studies confirm the contribution of each architectural component, with Hebbian learning providing consistent improvements. These results suggest that brain-inspired principles of sparse, geometrically-organized computation offer a promising direction toward more efficient and biologically plausible neural architectures.", "AI": {"tldr": "介绍了一种称为共振稀疏几何网络（RSGN）的新型架构，该架构通过自组织稀疏层次输入依赖连接实现高效计算。", "motivation": "旨在开发一种更高效的神经网络架构，这种架构能够适应每个输入并减少计算复杂性。传统Transformer模型的密集注意力机制具有O(n^2)的时间复杂度，而RSGN则采用稀疏几何结构来降低计算成本。", "method": "将计算节点嵌入学习到的双曲空间中，并通过地心距离衰减连接强度实现动态稀疏化；该架构在两种不同时间尺度上工作：快速可微激活传播和慢速赫布式学习规则，以适应输入结构。数学分析证明RSGN具有O(n*k)的时间复杂度。", "result": "实验结果显示，在长程依赖任务中，RSGN达到96.5%的准确率，参数数量仅为标准Transformer模型的十五分之一；在20类层次分类任务上，仅使用41,672个参数即可达到23.8％的准确率，显著低于基准线。", "conclusion": "研究表明，基于大脑原理的稀疏、几何组织计算为更高效和生物现实的神经网络架构提供了有希望的方向。"}}
{"id": "2601.18061", "pdf": "https://arxiv.org/pdf/2601.18061", "abs": "https://arxiv.org/abs/2601.18061", "authors": ["Kiana Jafari", "Paul Ulrich Nikolaus Rust", "Duncan Eddy", "Robbie Fraser", "Nina Vasan", "Darja Djordjevic", "Akanksha Dadlani", "Max Lamparth", "Eugenia Kim", "Mykel Kochenderfer"], "title": "Expert Evaluation and the Limits of Human Feedback in Mental Health AI Safety Testing", "categories": ["cs.AI", "cs.HC"], "comment": "17 pages, 7 pages of appendix, 21 tables", "summary": "Learning from human feedback~(LHF) assumes that expert judgments, appropriately aggregated, yield valid ground truth for training and evaluating AI systems. We tested this assumption in mental health, where high safety stakes make expert consensus essential. Three certified psychiatrists independently evaluated LLM-generated responses using a calibrated rubric. Despite similar training and shared instructions, inter-rater reliability was consistently poor ($ICC$ $0.087$--$0.295$), falling below thresholds considered acceptable for consequential assessment. Disagreement was highest on the most safety-critical items. Suicide and self-harm responses produced greater divergence than any other category, and was systematic rather than random. One factor yielded negative reliability (Krippendorff's $α= -0.203$), indicating structured disagreement worse than chance. Qualitative interviews revealed that disagreement reflects coherent but incompatible individual clinical frameworks, safety-first, engagement-centered, and culturally-informed orientations, rather than measurement error. By demonstrating that experts rely on holistic risk heuristics rather than granular factor discrimination, these findings suggest that aggregated labels function as arithmetic compromises that effectively erase grounded professional philosophies. Our results characterize expert disagreement in safety-critical AI as a sociotechnical phenomenon where professional experience introduces sophisticated layers of principled divergence. We discuss implications for reward modeling, safety classification, and evaluation benchmarks, recommending that practitioners shift from consensus-based aggregation to alignment methods that preserve and learn from expert disagreement.", "AI": {"tldr": "研究探讨了在精神健康领域中专家反馈的一致性和可靠性，揭示了使用人类反馈训练和评估AI系统的局限性。", "motivation": "鉴于心理健康领域的高安全性要求，专家共识至关重要。LHF方法假设专家判断可以提供有效的基准，但需要验证这一假设。", "method": "三位认证的精神科医生独立评价LLM生成的回答，并使用校准量表进行评分，评估一致性并进行了深入的定性访谈以了解分歧的原因。", "result": "尽管受训背景相似且有相同指导方针，专家之间的评分一致性和可靠性较差（ICC 0.087-0.295），尤其在自杀和自我伤害等关键安全问题上表现最差。专家间的差异是由不同的临床框架造成的，并不是测量误差。", "conclusion": "研究结果表明，在精神健康AI中，专家之间的分歧是复杂的社会技术现象，这种分歧需要通过新的方法来解决，而不是简单地寻求一致性。"}}
{"id": "2601.18058", "pdf": "https://arxiv.org/pdf/2601.18058", "abs": "https://arxiv.org/abs/2601.18058", "authors": ["Mohamed Afane", "Quanjiang Long", "Haoting Shen", "Ying Mao", "Junaid Farooq", "Ying Wang", "Juntao Chen"], "title": "Differentiable Architecture Search for Adversarially Robust Quantum Computer Vision", "categories": ["quant-ph", "cs.CV"], "comment": "Published in Quantum Machine Intelligence", "summary": "Current quantum neural networks suffer from extreme sensitivity to both adversarial perturbations and hardware noise, creating a significant barrier to real-world deployment. Existing robustness techniques typically sacrifice clean accuracy or require prohibitive computational resources. We propose a hybrid quantum-classical Differentiable Quantum Architecture Search (DQAS) framework that addresses these limitations by jointly optimizing circuit structure and robustness through gradient-based methods. Our approach enhances traditional DQAS with a lightweight Classical Noise Layer applied before quantum processing, enabling simultaneous optimization of gate selection and noise parameters. This design preserves the quantum circuit's integrity while introducing trainable perturbations that enhance robustness without compromising standard performance. Experimental validation on MNIST, FashionMNIST, and CIFAR datasets shows consistent improvements in both clean and adversarial accuracy compared to existing quantum architecture search methods. Under various attack scenarios, including Fast Gradient Sign Method (FGSM), Projected Gradient Descent (PGD), Basic Iterative Method (BIM), and Momentum Iterative Method (MIM), and under realistic quantum noise conditions, our hybrid framework maintains superior performance. Testing on actual quantum hardware confirms the practical viability of discovered architectures. These results demonstrate that strategic classical preprocessing combined with differentiable quantum architecture optimization can significantly enhance quantum neural network robustness while maintaining computational efficiency.", "AI": {"tldr": "提出了一种混合量子经典可微架构搜索(DQAS)框架，用于提高量子神经网络的鲁棒性。", "motivation": "现有量子神经网络在对抗攻击和硬件噪声下表现敏感，限制了其实用性。需要一种既能优化电路结构又能提升鲁棒性的方法。", "method": "通过引入轻量级经典噪音层来增强传统DQAS，实现了对门选择和噪音参数的同时优化。", "result": "实验结果表明，在MNIST、FashionMNIST和CIFAR数据集上，该框架在干净样本和对抗样本的准确性方面均优于现有方法，并且在实际量子硬件上的表现也得到了验证。", "conclusion": "结合经典预处理与可微量子架构优化可以显著提高量子神经网络的鲁棒性并保持计算效率。"}}
{"id": "2601.18053", "pdf": "https://arxiv.org/pdf/2601.18053", "abs": "https://arxiv.org/abs/2601.18053", "authors": ["Pulin Agrawal", "Prasoon Goyal"], "title": "Addressing LLM Diversity by Infusing Random Concepts", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) are known to produce outputs with limited diversity. In this work, we study whether infusing random concepts in the prompts can improve the diversity of the generated outputs. To benchmark the approach, we design a systematic evaluation protocol which involves prompting an LLM with questions of the form \"Name 10 Hollywood actors\", and analyzing diversity measures of the resulting LLM outputs. Our experiments on multiple LLMs show that prepending random words/sentences unrelated to the prompt result in greater diversity in the outputs of LLMs. We believe that this promising result and the evaluation protocol opens up interesting avenues for future work, such as how infusing randomness into LLMs could be applied to other domains. Further, the evaluation protocol could also inspire research into benchmarking LLM diversity more systematically.", "AI": {"tldr": "通过在提示中引入随机概念来研究是否可以提高大语言模型生成输出的多样性。", "motivation": "解决大型语言模型产生输出时多样性的限制问题，探索如何通过引入无关或随机的内容来增加模型生成内容的丰富性。", "method": "设计了一种评估协议，在提示中加入“列出10位好莱坞演员”的形式，并分析了由此产生的大语言模型输出的多样性指标。实验结果显示在提示前添加与主题无关的随机单词/句子可以提高模型输出的多样性。", "result": "实验结果表明，通过向提示中添加随机单词或句子能够有效增加生成输出内容的多样性。", "conclusion": "该研究认为引入随机性的方法对未来工作有启示意义，比如在其他领域应用这种方法以及更系统地评估大语言模型的多样性。"}}
{"id": "2601.18049", "pdf": "https://arxiv.org/pdf/2601.18049", "abs": "https://arxiv.org/abs/2601.18049", "authors": ["Yunfei Qiu", "Qiqiong Ma", "Tianhua Lv", "Li Fang", "Shudong Zhou", "Wei Yao"], "title": "Semi-Supervised Hyperspectral Image Classification with Edge-Aware Superpixel Label Propagation and Adaptive Pseudo-Labeling", "categories": ["cs.CV"], "comment": null, "summary": "Significant progress has been made in semi-supervised hyperspectral image (HSI) classification regarding feature extraction and classification performance. However, due to high annotation costs and limited sample availability, semi-supervised learning still faces challenges such as boundary label diffusion and pseudo-label instability. To address these issues, this paper proposes a novel semi-supervised hyperspectral classification framework integrating spatial prior information with a dynamic learning mechanism. First, we design an Edge-Aware Superpixel Label Propagation (EASLP) module. By integrating edge intensity penalty with neighborhood correction strategy, it mitigates label diffusion from superpixel segmentation while enhancing classification robustness in boundary regions. Second, we introduce a Dynamic History-Fused Prediction (DHP) method. By maintaining historical predictions and dynamically weighting them with current results, DHP smoothens pseudo-label fluctuations and improves temporal consistency and noise resistance. Concurrently, incorporating condifence and consistency measures, the Adaptive Tripartite Sample Categorization (ATSC) strategy implements hierarchical utilization of easy, ambiguous, and hard samples, leading to enhanced pseudo-label quality and learning efficiency. The Dynamic Reliability-Enhanced Pseudo-Label Framework (DREPL), composed of DHP and ATSC, strengthens pseudo-label stability across temporal and sample domains. Through synergizes operation with EASLP, it achieves spatio-temporal consistency optimization. Evaluations on four benchmark datasets demonstrate its capability to maintain superior classification performance.", "AI": {"tldr": "该论文提出了一种新的半监督高光谱图像分类框架，结合了空间先验信息和动态学习机制。", "motivation": "由于标注成本高昂且样本数量有限，半监督学习在边界标签扩散和伪标签不稳定性方面仍面临挑战。因此，本文旨在解决这些问题，并提高分类性能。", "method": "该方法设计了一个边意识超像素标签传播（EASLP）模块来缓解边界区域的标签扩散问题；同时引入了一种动态历史融合预测（DHP）法以平滑伪标签波动并增强时间一致性。此外，通过自适应三样本分类策略(ATS)利用容易、模棱两可和困难样本来提高伪标签质量。", "result": "该方法在四个基准数据集上的评估结果展示了其保持高光谱图像分类性能的能力。", "conclusion": "所提出的方法能够有效应对半监督学习中的边界扩散问题，通过结合空间先验信息和动态机制改进了伪标签的稳定性和时间一致性。"}}
{"id": "2601.18047", "pdf": "https://arxiv.org/pdf/2601.18047", "abs": "https://arxiv.org/abs/2601.18047", "authors": ["Amanuel Anteneh", "Kyungeun Kim", "J. M. Schwarz", "Israel Klich", "Olivier Pfister"], "title": "Laser interferometry as a robust neuromorphic platform for machine learning", "categories": ["physics.optics", "cs.ET", "cs.LG"], "comment": null, "summary": "We present a method for implementing an optical neural network using only linear optical resources, namely field displacement and interferometry applied to coherent states of light. The nonlinearity required for learning in a neural network is realized via an encoding of the input into phase shifts allowing for far more straightforward experimental implementation compared to previous proposals for, and demonstrations of, $\\textit{in situ}$ inference. Beyond $\\textit{in situ}$ inference, the method enables $\\textit{in situ}$ training by utilizing established techniques like parameter shift rules or physical backpropagation to extract gradients directly from measurements of the linear optical circuit. We also investigate the effect of photon losses and find the model to be very resilient to these.", "AI": {"tldr": "使用线性光学资源实现光神经网络的方法，包括场位移和干涉应用于相干态的光。", "motivation": "通过将输入编码为相移来实现在神经网络中所需的非线性，从而简化了实验实施。此外，在现场推理的基础上，该方法还能够进行在场训练，使用已建立的技术如参数偏移规则或物理反向传播直接从线性光学电路的测量结果中提取梯度。", "method": "利用光干涉和相位编码来实现神经网络的非线性处理，并通过损失函数优化来调整系统参数以适应训练任务。", "result": "实验表明，该模型对光子损耗表现出极高的鲁棒性，能够实现在场学习与推理。", "conclusion": "这种方法提供了一种使用光学资源进行机器学习的强大平台，不仅简化了硬件设计和实施难度，而且具有很强的抗干扰能力。"}}
{"id": "2601.18045", "pdf": "https://arxiv.org/pdf/2601.18045", "abs": "https://arxiv.org/abs/2601.18045", "authors": ["Zhuangzhi Gao", "Feixiang Zhou", "He Zhao", "Xiuju Chen", "Xiaoxin Li", "Qinkai Yu", "Yitian Zhao", "Alena Shantsila", "Gregory Y. H. Lip", "Eduard Shantsila", "Yalin Zheng"], "title": "Leveraging Persistence Image to Enhance Robustness and Performance in Curvilinear Structure Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by IEEE International Symposium on Biomedical Imaging (ISBI) 2026. 5 pages, 3 figures", "summary": "Segmenting curvilinear structures in medical images is essential for analyzing morphological patterns in clinical applications. Integrating topological properties, such as connectivity, improves segmentation accuracy and consistency. However, extracting and embedding such properties - especially from Persistence Diagrams (PD) - is challenging due to their non-differentiability and computational cost. Existing approaches mostly encode topology through handcrafted loss functions, which generalize poorly across tasks. In this paper, we propose PIs-Regressor, a simple yet effective module that learns persistence image (PI) - finite, differentiable representations of topological features - directly from data. Together with Topology SegNet, which fuses these features in both downsampling and upsampling stages, our framework integrates topology into the network architecture itself rather than auxiliary losses. Unlike existing methods that depend heavily on handcrafted loss functions, our approach directly incorporates topological information into the network structure, leading to more robust segmentation. Our design is flexible and can be seamlessly combined with other topology-based methods to further enhance segmentation performance. Experimental results show that integrating topological features enhances model robustness, effectively handling challenges like overexposure and blurring in medical imaging. Our approach on three curvilinear benchmarks demonstrate state-of-the-art performance in both pixel-level accuracy and topological fidelity.", "AI": {"tldr": "利用持久图像增强医学影像中曲线结构分割的鲁棒性和性能。", "motivation": "在医学图像中，提取和融合拓扑属性（如连通性）可以提高分割准确性。然而，现有的方法大多通过手工设计损失函数来编码这些信息，这限制了其泛化能力。因此，需要一种直接将拓扑特征融入网络结构的方法。", "method": "提出了PIs-Regressor模块，从数据中学习持久图像以表示拓扑特征，并将其与Topology SegNet融合，在下采样和上采样阶段都包含这些特征的融合。", "result": "实验结果表明，所提出方法在处理过曝光、模糊等医学影像挑战时增强了模型鲁棒性，展示了在像素级精度和拓扑准确性方面的最佳性能。", "conclusion": "通过直接将拓扑信息融入网络结构而非辅助损失函数的方法，提高了曲线结构分割的鲁棒性和性能。"}}
{"id": "2601.18037", "pdf": "https://arxiv.org/pdf/2601.18037", "abs": "https://arxiv.org/abs/2601.18037", "authors": ["Yiwen Shao", "Yong Xu", "Sanjeev Khudanpur", "Dong Yu"], "title": "SpatialEmb: Extract and Encode Spatial Information for 1-Stage Multi-channel Multi-speaker ASR on Arbitrary Microphone Arrays", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": "SLT 2024", "summary": "Spatial information is a critical clue for multi-channel multi-speaker target speech recognition. Most state-of-the-art multi-channel Automatic Speech Recognition (ASR) systems extract spatial features only during the speech separation stage, followed by standard single-channel ASR on the separated speech. This approach results in an inefficient, lengthy pipeline and sub-optimal ASR performance due to the accumulated errors from preprocessing modules. Furthermore, most spatial feature extraction methods depend on the knowledge of speaker positions and microphone topology, making the systems reliant on specific settings and challenging to adapt to new equipment. In this work, we propose a solution to these issues with a lightweight embedding module named SpatialEmb, which extracts and encodes spatial information directly for the ASR model, supporting both fixed and arbitrary microphone topology. We conduct comprehensive experiments on AliMeeting, a real meeting corpus, to determine the optimal model design for SpatialEmb in terms of both performance and efficiency. Our best model trained with 105 hours Train-Ali-far achieves 17.04% and 20.32% character error rates (CER) on the Eval and Test sets, establishing a new state-of-the-art result with the same training data.", "AI": {"tldr": "提出了一种名为SpatialEmb的轻量级嵌入模块，用于直接提取和编码ASR模型中的空间信息。", "motivation": "传统多通道自动语音识别系统在语音分离阶段仅提取空间特征，并且依赖于特定的扬声器位置和麦克风拓扑结构，这导致了冗长的工作流程和较差的性能。为了提高效率并适应新的设备配置，提出了SpatialEmb模块来直接编码空间信息。", "method": "设计了一种轻量级嵌入模块SpatialEmb，该模块可以直接从多通道输入中提取空间特征，并将其编码为可被ASR模型利用的信息。通过在实际会议数据集上进行实验以确定最佳的模型设计。", "result": "使用105小时训练数据的最佳模型在评估和测试集中分别达到了17.04%和20.32%的字符错误率，建立了新的最先进结果。", "conclusion": "SpatialEmb模块通过直接编码空间信息提高了ASR性能，并且能够适应任意麦克风拓扑结构。"}}
{"id": "2601.18033", "pdf": "https://arxiv.org/pdf/2601.18033", "abs": "https://arxiv.org/abs/2601.18033", "authors": ["Ahana Ghosh", "Advait Sarkar", "Siân Lindley", "Christian Poelitz"], "title": "An Experimental Comparison of Cognitive Forcing Functions for Execution Plans in AI-Assisted Writing: Effects On Trust, Overreliance, and Perceived Critical Thinking", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Generative AI (GenAI) tools improve productivity in knowledge workflows such as writing, but also risk overreliance and reduced critical thinking. Cognitive forcing functions (CFFs) mitigate these risks by requiring active engagement with AI output. As GenAI workflows grow more complex, systems increasingly present execution plans for user review. However, these plans are themselves AI-generated and prone to overreliance, and the effectiveness of applying CFFs to AI plans remains underexplored. We conduct a controlled experiment in which participants completed AI-assisted writing tasks while reviewing AI-generated plans under four CFF conditions: Assumption (argument analysis), WhatIf (hypothesis testing), Both, and a no-CFF control. A follow-up think-aloud and interview study qualitatively compared these conditions. Results show that the Assumption CFF most effectively reduced overreliance without increasing cognitive load, while participants perceived the WhatIf CFF as most helpful. These findings highlight the value of plan-focused CFFs for supporting critical reflection in GenAI-assisted knowledge work.", "AI": {"tldr": "实验比较了认知强迫函数在AI辅助写作中的执行计划效果，探讨其对信任、过度依赖和感知批判性思维的影响。", "motivation": "生成式人工智能工具提高了知识工作流程的生产力，但也会导致过度依赖和减少批判性思考。为了降低这些风险，需要研究如何通过应用认知强迫函数来提高用户与AI输出的互动。", "method": "进行了一项对照实验，在实验中参与者完成AI辅助写作任务时审查由AI生成的执行计划，并在四种不同条件（假设、WhatIf、两者结合和无CFF控制）下工作。随后进行了思维声音录制和访谈，以定性比较这些条件。", "result": "结果表明，假设强迫函数最有效地减少了过度依赖而不增加认知负担；参与者认为WhatIf强迫函数最有帮助。", "conclusion": "研究强调了计划导向的认知强迫函数在支持生成式人工智能辅助知识工作中的批判性反思的价值。"}}
{"id": "2601.18027", "pdf": "https://arxiv.org/pdf/2601.18027", "abs": "https://arxiv.org/abs/2601.18027", "authors": ["Chiyuan Fu", "Lyuhao Chen", "Yunze Xiao", "Weihao Xuan", "Carlos Busso", "Mona Diab"], "title": "Sentipolis: Emotion-Aware Agents for Social Simulations", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "LLM agents are increasingly used for social simulation, yet emotion is often treated as a transient cue, causing emotional amnesia and weak long-horizon continuity. We present Sentipolis, a framework for emotionally stateful agents that integrates continuous Pleasure-Arousal-Dominance (PAD) representation, dual-speed emotion dynamics, and emotion--memory coupling. Across thousands of interactions over multiple base models and evaluators, Sentipolis improves emotionally grounded behavior, boosting communication, and emotional continuity. Gains are model-dependent: believability increases for higher-capacity models but can drop for smaller ones, and emotion-awareness can mildly reduce adherence to social norms, reflecting a human-like tension between emotion-driven behavior and rule compliance in social simulation. Network-level diagnostics show reciprocal, moderately clustered, and temporally stable relationship structures, supporting the study of cumulative social dynamics such as alliance formation and gradual relationship change.", "AI": {"tldr": "Sentipolis是一个框架，用于创建情感连续性更好的社会仿真代理。", "motivation": "当前的社会仿真人员认为情绪是短暂的信号，导致了情绪遗忘和长期行为缺乏连贯性。因此，设计了一个新的系统来改善这种状态。", "method": "提出了一个称为Sentipolis的新框架，该框架结合了持续的情感PAD表示、双速情感动态以及情感与记忆之间的耦合。", "result": "通过在多个基础模型上进行成千上万次的交互实验，证明Sentipolis提高了情绪接地行为和沟通质量，并增强了长期的情绪连贯性。", "conclusion": "Sentipolis框架展示了更好的社交互动和累积社会动力学的研究能力。但是，对于较小的能力模型来说，情感意识可能会略微降低对规则遵守的程度。"}}
{"id": "2601.18018", "pdf": "https://arxiv.org/pdf/2601.18018", "abs": "https://arxiv.org/abs/2601.18018", "authors": ["Boran A. Kilic", "Ozgur B. Akan"], "title": "Neural-Inspired Multi-Agent Molecular Communication Networks for Collective Intelligence", "categories": ["nlin.AO", "cs.ET", "eess.SP", "physics.data-an"], "comment": "5 pages, 4 figures, submitted for MOLCOM 26 Workshop", "summary": "Molecular Communication (MC) is a pivotal enabler for the Internet of Bio-Nano Things (IoBNT). However, current research often relies on super-capable individual agents with complex transceiver architectures that defy the energy and processing constraints of realistic nanomachines. This paper proposes a paradigm shift towards collective intelligence, inspired by the cortical networks of the biological brain. We introduce a decentralized network architecture where simple nanomachines interact via a diffusive medium using a threshold-based firing mechanism modeled by Greenberg-Hastings (GH) cellular automata. We derive fixed-point equations for steady-state populations via mean-field analysis and validate them against stochastic simulations. We demonstrate that the network undergoes a second-order phase transition at a specific activation threshold. Crucially, we show that both pairwise and collective mutual information peak exactly at this critical transition point, confirming that the system maximizes information propagation and processing capacity at the edge of chaos.", "AI": {"tldr": "本文提出了一个受大脑皮层网络启发的去中心化分子通讯网络架构，利用简单的纳米机器通过阈值触发机制进行通信。", "motivation": "现有的研究依赖于复杂的接收器和发射机结构，这与实际纳米机器的能量和处理约束相矛盾。作者希望通过集体智能来克服这些限制。", "method": "引入了基于格林伯格-哈斯廷斯（GH）细胞自动机的阈值触发机制，使用均场分析推导固定点方程，并通过随机模拟进行验证。", "result": "网络在特定激活阈值下经历了二阶相变。成对和集体互信息在此临界转换点达到峰值，表明系统的信息传播和处理能力最大化处于混沌边缘。", "conclusion": "该模型成功展示了在网络的临界过渡点处最大化的信息传递能力和处理容量，证明了集体智能在分子通讯网络中的有效性。"}}
{"id": "2601.18015", "pdf": "https://arxiv.org/pdf/2601.18015", "abs": "https://arxiv.org/abs/2601.18015", "authors": ["Hyun-Gee Jei", "Mustafa Demir", "Farzan Sasangohar"], "title": "Eyes on the Mission: Mixed Methods Assessment of Eye-Tracker-Enabled Interactive Decision Support in a Simulated Unmanned Aerial Vehicle System", "categories": ["cs.ET", "cs.CC", "cs.HC", "cs.MA"], "comment": "27 pages, 6 figures, 4 tables, under review", "summary": "Supervisors in military command and control (C2) environments face dynamic conditions. Dynamically changing information continuously flows to the supervisors through multiple displays. In this environment, important pieces of information can be overlooked due to the complexity of tasks and environments. This study examined the efficacy of an eye-tracker-based adaptive attention-guided decision support tool (DST) for supervisors in a simulated C2 environment. The DST monitors supervisors' visual attention allocation in real time and displays visually salient cues if critical changes or events are missed. Twenty-five military students participated in a simulated intelligence task. Results indicated significant performance enhancement when the adaptive DST was present. Eye-tracking analysis also showed that longer, more frequent fixations on critical areas of interest were negatively correlated with performance. Additionally, post-experiment interviews revealed that the adaptive DST was unobtrusive and positively received. These findings underscore the potential of real-time gaze-based interventions to optimize supervisory decision-making. Future research could incorporate AI-driven approaches to better support supervisors in complex task environments.", "AI": {"tldr": "研究评估了一种基于眼动追踪的自适应注意力导向决策支持工具在模拟军事指挥和控制环境中的有效性。", "motivation": "为了提高动态环境下监督人员的任务表现，通过提供实时的眼动反馈来优化他们对关键信息的关注。", "method": "使用了25名军事学生参与模拟情报任务，并利用眼动追踪技术监测其视觉注意力分配情况，同时进行实验前后访谈收集反馈。", "result": "结果表明，自适应决策支持工具显著提高了参与者的表现。眼动分析显示，在感兴趣的关键区域的长时间、频繁注视与表现呈负相关。", "conclusion": "该研究证明了实时基于眼动干预在优化监督人员决策中的潜力，并建议未来可以结合人工智能的方法来进一步改进复杂环境下的任务支持。"}}
{"id": "2601.18014", "pdf": "https://arxiv.org/pdf/2601.18014", "abs": "https://arxiv.org/abs/2601.18014", "authors": ["Adeeba Tarannum", "Muzakkiruddin Ahmed Mohammed", "Mert Can Cakmak", "Shames Al Mandalawi", "John Talburt"], "title": "A System for Name and Address Parsing with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reliable transformation of unstructured person and address text into structured data remains a key challenge in large-scale information systems. Traditional rule-based and probabilistic approaches perform well on clean inputs but fail under noisy or multilingual conditions, while neural and large language models (LLMs) often lack deterministic control and reproducibility. This paper introduces a prompt-driven, validation-centered framework that converts free-text records into a consistent 17-field schema without fine-tuning. The method integrates input normalisation, structured prompting, constrained decoding, and strict rule-based validation under fixed experimental settings to ensure reproducibility. Evaluations on heterogeneous real-world address data show high field-level accuracy, strong schema adherence, and stable confidence calibration. The results demonstrate that combining deterministic validation with generative prompting provides a robust, interpretable, and scalable solution for structured information extraction, offering a practical alternative to training-heavy or domain-specific models.", "AI": {"tldr": "论文提出了一种通过大型语言模型进行姓名和地址解析的系统。", "motivation": "传统基于规则和概率的方法在处理不干净或多语言输入时表现不佳，而神经网络及大规模语言模型缺乏确定性和可重复性。因此需要一种新的方法来解决结构化数据提取的问题。", "method": "论文提出了一种基于提示、验证为中心的框架，通过输入规范化、结构化提示、约束解码和严格的规则验证来将自由文本记录转换为一致的17字段模式。", "result": "实验结果表明该模型在异构的真实世界地址数据上具有高字段级准确性和强大的模式一致性，并且保持了稳定的置信度校准。", "conclusion": "结合确定性验证与生成提示的方法提供了结构化信息提取的一种稳健、可解释和可扩展的解决方案，为训练密集型或领域特定模型提供了一个实用的替代方案。"}}
{"id": "2601.18012", "pdf": "https://arxiv.org/pdf/2601.18012", "abs": "https://arxiv.org/abs/2601.18012", "authors": ["Hendrika Maclean", "Mert Can Cakmak", "Muzakkiruddin Ahmed Mohammed", "Shames Al Mandalawi", "John Talburt"], "title": "Evaluating Semantic and Syntactic Understanding in Large Language Models for Payroll Systems", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models are now used daily for writing, search, and analysis, and their natural language understanding continues to improve. However, they remain unreliable on exact numerical calculation and on producing outputs that are straightforward to audit. We study synthetic payroll system as a focused, high-stakes example and evaluate whether models can understand a payroll schema, apply rules in the right order, and deliver cent-accurate results. Our experiments span a tiered dataset from basic to complex cases, a spectrum of prompts from minimal baselines to schema-guided and reasoning variants, and multiple model families including GPT, Claude, Perplexity, Grok and Gemini. Results indicate clear regimes where careful prompting is sufficient and regimes where explicit computation is required. The work offers a compact, reproducible framework and practical guidance for deploying LLMs in settings that demand both accuracy and assurance.", "AI": {"tldr": "研究大型语言模型在工资系统中的语义和句法理解能力。", "motivation": "评估大语言模型在精确数值计算和审计输出方面的可靠性，特别是在高风险场景下的表现。", "method": "使用从基础到复杂的工资系统数据集，并通过不同类型的提示来测试各种模型家族的性能。", "result": "结果显示谨慎的提示能够在某些情况下满足要求，而在其他情况下则需要明确的计算。", "conclusion": "提供了用于在需要准确性和保证性的场景中部署LLMs的可重复框架和实际指导。"}}
{"id": "2601.18010", "pdf": "https://arxiv.org/pdf/2601.18010", "abs": "https://arxiv.org/abs/2601.18010", "authors": ["Jingyao Wu", "Grace Lin", "Yinuo Song", "Rosalind Picard"], "title": "AmbER$^2$: Dual Ambiguity-Aware Emotion Recognition Applied to Speech and Text", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted in ICASSP 2026", "summary": "Emotion recognition is inherently ambiguous, with uncertainty arising both from rater disagreement and from discrepancies across modalities such as speech and text. There is growing interest in modeling rater ambiguity using label distributions. However, modality ambiguity remains underexplored, and multimodal approaches often rely on simple feature fusion without explicitly addressing conflicts between modalities. In this work, we propose AmbER$^2$, a dual ambiguity-aware framework that simultaneously models rater-level and modality-level ambiguity through a teacher-student architecture with a distribution-wise training objective. Evaluations on IEMOCAP and MSP-Podcast show that AmbER$^2$ consistently improves distributional fidelity over conventional cross-entropy baselines and achieves performance competitive with, or superior to, recent state-of-the-art systems. For example, on IEMOCAP, AmbER$^2$ achieves relative improvements of 20.3% on Bhattacharyya coefficient (0.83 vs. 0.69), 13.6% on R$^2$ (0.67 vs. 0.59), 3.8% on accuracy (0.683 vs. 0.658), and 4.5% on F1 (0.675 vs. 0.646). Further analysis across ambiguity levels shows that explicitly modeling ambiguity is particularly beneficial for highly uncertain samples. These findings highlight the importance of jointly addressing rater and modality ambiguity when building robust emotion recognition systems.", "AI": {"tldr": "提出了一种同时处理评分者和模态模糊性的双重情感识别框架AmbER$^2$。", "motivation": "当前的情感识别模型忽视了跨模态的模糊性，并且多模态方法通常简单地进行特征融合，未能解决不同模态之间的冲突问题。", "method": "使用教师-学生架构和分布训练目标同时建模评分者级和模态级模糊性。", "result": "实验结果表明AmbER$^2$在多个指标上优于传统基线模型，并且对于高度不确定的样本表现出特别的优势。", "conclusion": "研究强调了在同一情感识别系统中同时处理评分者和模态模糊性的关键作用，以构建稳健的情感识别系统。"}}
{"id": "2601.18008", "pdf": "https://arxiv.org/pdf/2601.18008", "abs": "https://arxiv.org/abs/2601.18008", "authors": ["Asiegbu Miracle Kanu-Asiegbu", "Nitin Jotwani", "Xiaoxiao Du"], "title": "Strip-Fusion: Spatiotemporal Fusion for Multispectral Pedestrian Detection", "categories": ["cs.CV"], "comment": "This work has been accepted for publication in IEEE Robotics and Automation Letters (RA-L). Code available at: https://github.com/akanuasiegbu/stripfusion", "summary": "Pedestrian detection is a critical task in robot perception. Multispectral modalities (visible light and thermal) can boost pedestrian detection performance by providing complementary visual information. Several gaps remain with multispectral pedestrian detection methods. First, existing approaches primarily focus on spatial fusion and often neglect temporal information. Second, RGB and thermal image pairs in multispectral benchmarks may not always be perfectly aligned. Pedestrians are also challenging to detect due to varying lighting conditions, occlusion, etc. This work proposes Strip-Fusion, a spatial-temporal fusion network that is robust to misalignment in input images, as well as varying lighting conditions and heavy occlusions. The Strip-Fusion pipeline integrates temporally adaptive convolutions to dynamically weigh spatial-temporal features, enabling our model to better capture pedestrian motion and context over time. A novel Kullback-Leibler divergence loss was designed to mitigate modality imbalance between visible and thermal inputs, guiding feature alignment toward the more informative modality during training. Furthermore, a novel post-processing algorithm was developed to reduce false positives. Extensive experimental results show that our method performs competitively for both the KAIST and the CVC-14 benchmarks. We also observed significant improvements compared to previous state-of-the-art on challenging conditions such as heavy occlusion and misalignment.", "AI": {"tldr": "本文提出了一种时空融合网络Strip-Fusion，用于解决多光谱行人检测中的问题。", "motivation": "现有方法主要集中在空间融合上，并且忽略了时间信息。多光谱数据集中的RGB和热图图像对可能不完全对齐，增加了检测难度。", "method": "Strip-Fusion引入了适应性时空卷积以动态加权空间-时间特征，通过KL散度损失减轻模态失衡问题并指导训练过程中的特征对齐。同时开发了一种新的后处理算法减少假阳性。", "result": "实验结果表明，该方法在KAIST和CVC-14基准数据集上表现优异，在重遮挡和图像错位等挑战性条件下优于现有最佳方法。", "conclusion": "Strip-Fusion通过时空融合提高了多光谱行人检测的鲁棒性和准确性。"}}
{"id": "2601.18001", "pdf": "https://arxiv.org/pdf/2601.18001", "abs": "https://arxiv.org/abs/2601.18001", "authors": ["Aqsa Yousaf", "Sint Sint Win", "Megan Coffee", "Habeeb Olufowobi"], "title": "MorphXAI: An Explainable Framework for Morphological Analysis of Parasites in Blood Smear Images", "categories": ["cs.CV"], "comment": "Accepted at WACV 2026", "summary": "Parasitic infections remain a pressing global health challenge, particularly in low-resource settings where diagnosis still depends on labor-intensive manual inspection of blood smears and the availability of expert domain knowledge. While deep learning models have shown strong performance in automating parasite detection, their clinical usefulness is constrained by limited interpretability. Existing explainability methods are largely restricted to visual heatmaps or attention maps, which highlight regions of interest but fail to capture the morphological traits that clinicians rely on for diagnosis. In this work, we present MorphXAI, an explainable framework that unifies parasite detection with fine-grained morphological analysis. MorphXAI integrates morphological supervision directly into the prediction pipeline, enabling the model to localize parasites while simultaneously characterizing clinically relevant attributes such as shape, curvature, visible dot count, flagellum presence, and developmental stage. To support this task, we curate a clinician-annotated dataset of three parasite species (Leishmania, Trypanosoma brucei, and Trypanosoma cruzi) with detailed morphological labels, establishing a new benchmark for interpretable parasite analysis. Experimental results show that MorphXAI not only improves detection performance over the baseline but also provides structured, biologically meaningful explanations.", "AI": {"tldr": "本文提出了一个名为MorphXAI的框架，用于解释寄生虫血涂片图像中的形态分析。", "motivation": "现有的深度学习模型虽然在自动化检测寄生虫方面表现出色，但由于缺乏可解释性，在临床应用中受到了限制。为了克服这个问题，并提供对临床诊断有用的细粒度形态特征分析，本文提出了MorphXAI框架。", "method": "MorphXAI框架将形态监督直接集成到预测过程中，使其能够同时定位寄生虫并描述形状、曲率等生物相关属性。为此，作者收集了一个包含三种寄生虫物种的临床注释数据集。", "result": "实验结果显示，与基线方法相比，MorphXAI不仅提高了检测性能，还提供了结构化且具有生物学意义的解释。", "conclusion": "MorphXAI框架在提高寄生虫血涂片图像中形态分析的同时，为临床诊断提供了一种新的可解释性解决方案。"}}
{"id": "2601.17998", "pdf": "https://arxiv.org/pdf/2601.17998", "abs": "https://arxiv.org/abs/2601.17998", "authors": ["Benjamin Mako Hill", "Aaron Shaw"], "title": "The Most Important Laboratory for Social Scientific and Computing Research in History", "categories": ["cs.CY", "cs.HC"], "comment": "Published in Wikipedia @ 20: Stories of an Incomplete Revolution, 2020, Edited by Joseph Reagle and Jackie Koerner. The MIT Press. ISBN electronic: 9780262360593", "summary": "Wikipedia's founders could not have dreamed they were creating the most important laboratory for social scientific and computing research in history but that is exactly what happened. Hill and Shaw take account of Wikipedia's enormous effect on academic scholarship", "AI": {"tldr": "分析维基百科对社会科学和计算研究的影响", "motivation": "探讨维基百科作为学术研究实验室的重要性", "method": "未详细说明具体方法，可能是文献回顾与数据分析相结合的方式", "result": "揭示了维基百科在推动相关领域学术成果方面的重要作用", "conclusion": "确认维基百科成为了历史上最重要的社会科学研究和计算研究的实验场所"}}
{"id": "2601.17995", "pdf": "https://arxiv.org/pdf/2601.17995", "abs": "https://arxiv.org/abs/2601.17995", "authors": ["Shudi Weng", "Ming Xiao", "Mikael Skoglund"], "title": "Coding-Enforced Resilient and Secure Aggregation for Hierarchical Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Hierarchical federated learning (HFL) has emerged as an effective paradigm to enhance link quality between clients and the server. However, ensuring model accuracy while preserving privacy under unreliable communication remains a key challenge in HFL, as the coordination among privacy noise can be randomly disrupted. To address this limitation, we propose a robust hierarchical secure aggregation scheme, termed H-SecCoGC, which integrates coding strategies to enforce structured aggregation. The proposed scheme not only ensures accurate global model construction under varying levels of privacy, but also avoids the partial participation issue, thereby significantly improving robustness, privacy preservation, and learning efficiency. Both theoretical analyses and experimental results demonstrate the superiority of our scheme under unreliable communication across arbitrarily strong privacy guarantees", "AI": {"tldr": "提出了一种基于编码策略的鲁棒分层安全聚合方案，以增强在不可靠通信条件下的模型准确性和隐私保护。", "motivation": "为了克服层次化联邦学习中模型准确性与隐私保护之间的挑战，在不可靠通信条件下确保全局模型构建的有效性并且避免部分参与问题。", "method": "提出了H-SecCoGC方案，它通过集成编码策略来执行结构化聚合，以提高在不同级别隐私下模型的准确性、隐私保持和学习效率。", "result": "理论分析和实验结果表明，在任意强隐私保证下的不可靠通信条件下，所提出的方案优于现有方法。", "conclusion": "H-SecCoGC方案成功解决了层次化联邦学习中的主要挑战，并在提高全局模型准确性和保护参与者隐私的同时增强了系统的鲁棒性。"}}
{"id": "2601.17993", "pdf": "https://arxiv.org/pdf/2601.17993", "abs": "https://arxiv.org/abs/2601.17993", "authors": ["Marina Zavertiaeva", "Petr Parshakov", "Mikhail Usanin", "Aleksei Smirnov", "Sofia Paklina", "Anastasiia Kibardina"], "title": "AI-based approach to burnout identification from textual data", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 2 figures", "summary": "This study introduces an AI-based methodology that utilizes natural language processing (NLP) to detect burnout from textual data. The approach relies on a RuBERT model originally trained for sentiment analysis and subsequently fine-tuned for burnout detection using two data sources: synthetic sentences generated with ChatGPT and user comments collected from Russian YouTube videos about burnout. The resulting model assigns a burnout probability to input texts and can be applied to process large volumes of written communication for monitoring burnout-related language signals in high-stress work environments.", "AI": {"tldr": "本研究提出了一种基于AI的方法，使用自然语言处理（NLP）从文本数据中检测职业倦怠。", "motivation": "通过识别员工在高压力工作环境中表达的职业倦怠迹象，提高对职业倦怠的认识并采取预防措施。", "method": "利用RuBERT模型进行情感分析的预训练，并用合成句子和YouTube评论中的真实用户反馈对该模型进行微调以检测职业倦怠。最终模型能够为输入文本分配一个职业倦怠概率。", "result": "该方法可以应用于处理大量书写交流，以便在高压力工作环境中监测与职业倦怠相关的语言信号。", "conclusion": "基于AI的自然语言处理技术可以在识别和预防职业倦怠方面发挥重要作用。"}}
{"id": "2601.17991", "pdf": "https://arxiv.org/pdf/2601.17991", "abs": "https://arxiv.org/abs/2601.17991", "authors": ["Roman Akinshin", "Elizaveta Lopatina", "Kirill Bogatikov", "Nikolai Kiz", "Anna V. Makarova", "Mikhail Lebedev", "Miguel Altamirano Cabrera", "Dzmitry Tsetserukou", "Valerii Kangler"], "title": "NeuroManip: Prosthetic Hand Manipulation System Based on EMG and Eye Tracking Powered by the Neuromorphic Processor AltAi", "categories": ["cs.RO"], "comment": "This paper has been accepted for publication at LBR of HRI 2026 conference", "summary": "This paper presents a novel neuromorphic control architecture for upper-limb prostheses that combines surface electromyography (sEMG) with gaze-guided computer vision. The system uses a spiking neural network deployed on the neuromorphic processor AltAi to classify EMG patterns in real time while an eye-tracking headset and scene camera identify the object within the user's focus. In our prototype, the same EMG recognition model that was originally developed for a conventional GPU is deployed as a spiking network on AltAi, achieving comparable accuracy while operating in a sub-watt power regime, which enables a lightweight, wearable implementation. For six distinct functional gestures recorded from upper-limb amputees, the system achieves robust recognition performance comparable to state-of-the-art myoelectric interfaces. When the vision pipeline restricts the decision space to three context-appropriate gestures for the currently viewed object, recognition accuracy increases to roughly 95% while excluding unsafe, object-inappropriate grasps. These results indicate that the proposed neuromorphic, context-aware controller can provide energy-efficient and reliable prosthesis control and has the potential to improve safety and usability in everyday activities for people with upper-limb amputation.", "AI": {"tldr": "提出了一种基于神经形态处理器AltAi的结合表面肌电图（sEMG）和眼动追踪的上肢假手控制系统。", "motivation": "为了提高能量效率和可靠性，开发一个能够提供上下文感知控制并且可穿戴的能量高效且可靠的假手系统。", "method": "利用部署在神经形态处理器AltAi上的尖峰神经网络实时分类肌电图模式，同时通过眼动追踪头戴设备和场景相机识别用户关注的对象。将原始为常规GPU开发的EMG识别模型转换为尖峰网络，在亚瓦特功耗下实现了与现有最佳系统相当的准确度。", "result": "该系统对于六种不同功能手势记录来自上肢截肢者的数据，其识别性能可媲美现有的肌电控制界面。当视觉管线限制当前可视对象的相关手势决策空间为三个适当选项时，识别精度提高至约95%。", "conclusion": "表明所提出的神经形态上下文感知控制器具有提供能量效率和可靠假手控制的潜力，并有望改善上肢截肢者在日常活动中的安全性和易用性。"}}
{"id": "2601.17987", "pdf": "https://arxiv.org/pdf/2601.17987", "abs": "https://arxiv.org/abs/2601.17987", "authors": ["Ziwei Zheng", "Huizhi Liang", "Vaclav Snasel", "Vito Latora", "Panos Pardalos", "Giuseppe Nicosia", "Varun Ojha"], "title": "Systematic Characterization of Minimal Deep Learning Architectures: A Unified Analysis of Convergence, Pruning, and Quantization", "categories": ["cs.LG", "cs.CV"], "comment": "ef:IEEE Conference on Artificial Intelligence 2026 (IEEE CAI 2026)", "summary": "Deep learning networks excel at classification, yet identifying minimal architectures that reliably solve a task remains challenging. We present a computational methodology for systematically exploring and analyzing the relationships among convergence, pruning, and quantization. The workflow first performs a structured design sweep across a large set of architectures, then evaluates convergence behavior, pruning sensitivity, and quantization robustness on representative models. Focusing on well-known image classification of increasing complexity, and across Deep Neural Networks, Convolutional Neural Networks, and Vision Transformers, our initial results show that, despite architectural diversity, performance is largely invariant and learning dynamics consistently exhibit three regimes: unstable, learning, and overfitting. We further characterize the minimal learnable parameters required for stable learning, uncover distinct convergence and pruning phases, and quantify the effect of reduced numeric precision on trainable parameters. Aligning with intuition, the results confirm that deeper architectures are more resilient to pruning than shallower ones, with parameter redundancy as high as 60%, and quantization impacts models with fewer learnable parameters more severely and has a larger effect on harder image datasets. These findings provide actionable guidance for selecting compact, stable models under pruning and low-precision constraints in image classification.", "AI": {"tldr": "该论文提出了一种计算方法，用于系统地探索和分析深度学习网络在收敛性、裁剪敏感性和量化稳健性方面的关系。", "motivation": "识别能够可靠解决问题的最小化架构仍然具有挑战性。作者希望通过研究这些特性之间的联系来指导选择紧凑且稳定的模型。", "method": "该方法首先对大量架构进行结构化设计扫描，然后评估代表性的模型在收敛行为、裁剪敏感性和量化稳健性方面的表现。", "result": "发现尽管存在架构多样性，性能基本不变，并表现出不稳定、学习和过拟合三个阶段。较深的网络比浅层网络更能抵抗修剪，参数冗余率高达60%，而量化对较少可训练参数影响更大。", "conclusion": "结果提供了在图像分类中选择紧凑且稳定的模型以适应低精度约束的实际指导。"}}
{"id": "2601.17982", "pdf": "https://arxiv.org/pdf/2601.17982", "abs": "https://arxiv.org/abs/2601.17982", "authors": ["Kshitij Mishra", "Nils Lukas", "Salem Lahlou"], "title": "SD-E$^2$: Semantic Exploration for Reasoning Under Token Budgets", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at EACL 2026", "summary": "Small language models (SLMs) struggle with complex reasoning because exploration is expensive under tight compute budgets. We introduce Semantic Diversity-Exploration-Exploitation (SD-E$^2$), a reinforcement learning framework that makes exploration explicit by optimizing semantic diversity in generated reasoning trajectories. Using a frozen sentence-embedding model, SD-E$^2$ assigns a diversity reward that captures (i) the coverage of semantically distinct solution strategies and (ii) their average pairwise dissimilarity in embedding space, rather than surface-form novelty. This diversity reward is combined with outcome correctness and solution efficiency in a z-score-normalized multi-objective objective that stabilizes training. On GSM8K, SD-E$^2$ surpasses the base Qwen2.5-3B-Instruct and strong GRPO baselines (GRPO-CFL and GRPO-CFEE) by +27.4, +5.2, and +1.5 percentage points, respectively, while discovering on average 9.8 semantically distinct strategies per question. We further improve MedMCQA to 49.64% versus 38.37% for the base model and show gains on the harder AIME benchmark (1983-2025), reaching 13.28% versus 6.74% for the base. These results indicate that rewarding semantic novelty yields a more compute-efficient exploration-exploitation signal for training reasoning-capable SLMs. By introducing cognitive adaptation-adjusting the reasoning process structure rather than per-token computation-SD-E$^2$ offers a complementary path to efficiency gains in resource-constrained models.", "AI": {"tldr": "本文介绍了SD-E$^2$，一种通过优化生成推理轨迹中的语义多样性来增强小型语言模型复杂推理能力的强化学习框架。", "motivation": "小规模语言模型在处理复杂的推理任务时面临挑战，因为探索过程在计算预算紧缩的情况下变得昂贵。为此，作者提出了一种新的方法来平衡探索和利用的关系，以提高这些模型的表现。", "method": "SD-E$^2$通过使用冻结的句子嵌入模型来分配多样性奖励，该奖励不仅捕捉到了语义上不同的解决方案策略覆盖范围，也考虑了它们在嵌入空间中的平均成对差异。这种多样性的奖励与其他目标（如结果正确性和解题效率）结合，并进行了z-score标准化以稳定训练。", "result": "SD-E$^2$在GSM8K数据集上的表现优于基线模型Qwen2.5-3B-Instruct和GRPO变体，分别提高了27.4、5.2和1.5个百分点。此外，它还改进了MedMCQA的表现，并且在更难的AIME基准测试中也表现出色。", "conclusion": "奖励语义新颖性可以为训练推理能力强的小型语言模型提供一种计算效率更高的探索-利用信号。SD-E$^2$通过调整认知适应过程，而不是每个令牌的计算量，提供了资源受限模型效率提升的一种补充途径。"}}
{"id": "2601.17977", "pdf": "https://arxiv.org/pdf/2601.17977", "abs": "https://arxiv.org/abs/2601.17977", "authors": ["Jinchen Gu", "Nan Zhao", "Lei Qiu", "Lu Zhang"], "title": "Domain-Expert-Guided Hybrid Mixture-of-Experts for Medical AI: Integrating Data-Driven Learning with Clinical Priors", "categories": ["cs.CV"], "comment": "4 pages; 3 figures; accepted by International Symposium on Biomedical Imaging (ISBI) 2026", "summary": "Mixture-of-Experts (MoE) models increase representational capacity with modest computational cost, but their effectiveness in specialized domains such as medicine is limited by small datasets. In contrast, clinical practice offers rich expert knowledge, such as physician gaze patterns and diagnostic heuristics, that models cannot reliably learn from limited data. Combining data-driven experts, which capture novel patterns, with domain-expert-guided experts, which encode accumulated clinical insights, provides complementary strengths for robust and clinically meaningful learning. To this end, we propose Domain-Knowledge-Guided Hybrid MoE (DKGH-MoE), a plug-and-play and interpretable module that unifies data-driven learning with domain expertise. DKGH-MoE integrates a data-driven MoE to extract novel features from raw imaging data, and a domain-expert-guided MoE incorporates clinical priors, specifically clinician eye-gaze cues, to emphasize regions of high diagnostic relevance. By integrating domain expert insights with data-driven features, DKGH-MoE improves both performance and interpretability.", "AI": {"tldr": "该论文提出了一种结合数据驱动学习与临床专业知识的混合专家模型，旨在提高医疗AI在小样本数据集上的性能和可解释性。", "motivation": "传统的Mixture-of-Experts（MoE）模型由于医学领域的小样本问题而效果受限。通过整合丰富的临床知识，可以克服有限数据带来的挑战，并增强模型的实际应用价值。", "method": "提出Domain-Knowledge-Guided Hybrid MoE (DKGH-MoE)模型，该模型结合了数据驱动的专家网络和基于医生经验的知识引导专家网络，前者从原始图像中提取新颖特征，后者根据临床指导信息强调重要区域。", "result": "DKGH-MoE通过整合领域知识提升了性能并增强了可解释性，在实验结果中显示出了优势。", "conclusion": "通过结合数据驱动的学习方法与专业领域的丰富经验，可以在医疗AI应用中获得更好的效果和更高的临床意义。"}}
{"id": "2601.17975", "pdf": "https://arxiv.org/pdf/2601.17975", "abs": "https://arxiv.org/abs/2601.17975", "authors": ["Bryan Min", "Peiling Jiang", "Zhicheng Huang", "Haijun Xia"], "title": "Gradual Generation of User Interfaces as a Design Method for Malleable Software", "categories": ["cs.HC"], "comment": "5 pages, 3 figures", "summary": "AI is growing increasingly capable of automatically generating user interfaces (GenUI) from user prompts. However, designing GenUI applications that enable users to discover diverse customizations while preserving GenUI's expressiveness remains challenging. Current design methods -- presenting prompt boxes and leveraging context -- lack affordances for customization discovery, while traditional menu-based approaches become overly complex given GenUI's vast customization space. We propose Gradually Generating User Interfaces -- a design method that structures customizations into intermediate UI layers that AI gradually loads during interface generation. These intermediate stages expose different customization features along specific dimensions, making them discoverable to users. Users can wind back the generation process to access customizations. We demonstrate this approach through three prototype websites, showing how designers can support GenUI's expanded customization capabilities while maintaining visual simplicity and discoverability. Our work offers a practical method for integrating customization features into GenUI applications, contributing an approach to designing malleable software.", "AI": {"tldr": "本文提出了渐进生成用户界面的设计方法，以支持GenUI应用程序的多样化定制同时保持视觉简洁性和可发现性。", "motivation": "现有的设计方法缺乏对多样化的个性化定制的支持。传统的菜单式方法在面对广泛的定制空间时变得过于复杂。因此，需要一种新的方法来提高用户体验并促进发现各种可能的定制选项。", "method": "渐进生成用户界面的设计方法将定制功能分层，并通过AI逐步加载这些层级，在生成过程中逐渐展示不同的定制特性。这种方法使得用户可以回溯到之前的状态以访问定制功能。", "result": "通过三个原型网站展示了这种设计方法的应用，表明了其在支持GenUI应用程序的扩展定制能力的同时保持视觉简洁性和发现性方面的能力。", "conclusion": "本文提出的设计方法为将定制特性集成到GenUI应用程序中提供了一个实用的方法，并贡献了一种可塑软件设计的新途径。"}}
{"id": "2601.17966", "pdf": "https://arxiv.org/pdf/2601.17966", "abs": "https://arxiv.org/abs/2601.17966", "authors": ["Naman Gupta", "Sophie Stephenson", "Chung Chi Yeung", "Wei Ting Wu", "Jeneile Luebke", "Kate Walsh", "Rahul Chatterjee"], "title": "\"Lighting The Way For Those Not Here\": How Technology Researchers Can Help Fight the Missing and Murdered Indigenous Relatives (MMIR) Crisis", "categories": ["cs.CY", "cs.HC"], "comment": null, "summary": "Indigenous peoples across Turtle Island (North America) face disproportionate rates of disappearance and murder, a \"genocide\" rooted in settler-colonial violence and systemic erasure. Technology plays a crucial role in the Missing and Murdered Indigenous Relatives (MMIR) crisis: perpetuating harm and impeding investigations, yet enabling advocacy and resistance. Communities utilize technologies such as AMBER alerts, news websites, social media groups, and campaigns (like #MMIW, #MMIWR, #NoMoreStolenSisters, and #NoMoreStolenDaughters) to mobilize searches, amplify awareness, and honor missing relatives. Yet, little research in HCI has critically examined technology's role in shaping the MMIR crisis by centering community voices. Through a large-scale study, we analyze 140 webpages to identify systemic, technological, and institutional barriers that hinder communities' efforts, while highlighting socio-technical actions that foster healing and safety. Finally, we amplify Indigenous voices by providing a dataset of stories that resist epistemic erasure, along with recommendations for HCI researchers to support Indigenous-led initiatives with cultural sensitivity, accountability, and self-determination.", "AI": {"tldr": "通过分析网站页面，研究技术在MMIR危机中的作用，并为HCI研究人员提供支持土著社区的建议。", "motivation": "探讨技术如何加剧或缓解失踪和被谋杀的土著亲属问题，同时强调需要尊重土著文化和自主权的研究。", "method": "进行了大规模研究，分析了140个网页以识别阻碍社区努力的技术、制度和社会系统障碍，并提出了基于社区声音的数据集和建议。", "result": "发现了影响MMIR危机的技术和社会技术因素，为HCI研究人员提供了支持土著倡议的方法和数据。", "conclusion": "呼吁科技界采取文化敏感性、责任与自主权相结合的方式参与解决MMIR问题。"}}
{"id": "2601.17962", "pdf": "https://arxiv.org/pdf/2601.17962", "abs": "https://arxiv.org/abs/2601.17962", "authors": ["Wenhan Lyu", "Yimeng Wang", "Murong Yue", "Yifan Sun", "Jennifer Suh", "Meredith Kier", "Ziyu Yao", "Yixuan Zhang"], "title": "Designing AI Peers for Collaborative Mathematical Problem Solving with Middle School Students: A Participatory Design Study", "categories": ["cs.HC"], "comment": "Accepted by ACM CHI 2026", "summary": "Collaborative problem solving (CPS) is a fundamental practice in middle-school mathematics education; however, student groups frequently stall or struggle without ongoing teacher support. Recent work has explored how Generative AI tools can be designed to support one-on-one tutoring, but little is known about how AI can be designed as peer learning partners in collaborative learning contexts. We conducted a participatory design study with 24 middle school students, who first engaged in mathematics CPS tasks with AI peers in a technology probe, and then collaboratively designed their ideal AI peer. Our findings reveal that students envision an AI peer as competent in mathematics yet explicitly deferential, providing progressive scaffolds such as hints and checks under clear student control. Students preferred a tone of friendly expertise over exaggerated personas. We also discuss design recommendations and implications for AI peers in middle school mathematics CPS.", "AI": {"tldr": "设计AI同伴以支持中学生在数学问题解决中的协作学习", "motivation": "探讨如何通过AI设计促进中学生在缺乏教师指导下的合作解决问题能力", "method": "进行参与式设计研究，24名中学生首先与AI同伴完成数学任务，然后共同设计理想化的AI同伴", "result": "学生希望AI同伴具备数学知识且表现出明确的谦逊态度，并提供逐步支持如提示和检查等功能；偏好友好的专家语气而非夸张的角色设定", "conclusion": "提出AI同伴在中学数学合作解决问题中的设计建议与应用前景"}}
{"id": "2601.17952", "pdf": "https://arxiv.org/pdf/2601.17952", "abs": "https://arxiv.org/abs/2601.17952", "authors": ["Michail Mamalakis", "Tiago Azevedo", "Cristian Cosentino", "Chiara D'Ercoli", "Subati Abulikemu", "Zhongtian Sun", "Richard Bethlehem", "Pietro Lio"], "title": "A Monosemantic Attribution Framework for Stable Interpretability in Clinical Neuroscience Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Interpretability remains a key challenge for deploying large language models (LLMs) in clinical settings such as Alzheimer's disease progression diagnosis, where early and trustworthy predictions are essential. Existing attribution methods exhibit high inter-method variability and unstable explanations due to the polysemantic nature of LLM representations, while mechanistic interpretability approaches lack direct alignment with model inputs and outputs and do not provide explicit importance scores. We introduce a unified interpretability framework that integrates attributional and mechanistic perspectives through monosemantic feature extraction. By constructing a monosemantic embedding space at the level of an LLM layer and optimizing the framework to explicitly reduce inter-method variability, our approach produces stable input-level importance scores and highlights salient features via a decompressed representation of the layer of interest, advancing the safe and trustworthy application of LLMs in cognitive health and neurodegenerative disease.", "AI": {"tldr": "本文提出了一种统一的可解释性框架，用于在临床神经科学大规模语言模型中获得稳定的可解释性。", "motivation": "现有的归因方法由于大规模语言模型表示的多义性而表现出高度的方法间变异性，并且机制可解释性方法缺乏与模型输入和输出的直接对齐，无法提供明确的重要性评分。", "method": "通过在LLM层构建单义嵌入空间并优化框架以显式减少方法间的变异性，本文提出了一种集成归因性和机制性的统一解释框架，生成稳定的输入级重要性评分，并突出显示感兴趣的层级的显著特征。", "result": "该方法产生了稳定的输入级重要性评分和显著特征，提高了大规模语言模型在认知健康和神经退行性疾病中的安全、可信应用。", "conclusion": "本文提出的单义归因框架解决了现有可解释性方法的问题，并为临床环境中大规模语言模型的可靠使用提供了基础。"}}
{"id": "2601.17950", "pdf": "https://arxiv.org/pdf/2601.17950", "abs": "https://arxiv.org/abs/2601.17950", "authors": ["Matthew Walmer", "Saksham Suri", "Anirud Aggarwal", "Abhinav Shrivastava"], "title": "UPLiFT: Efficient Pixel-Dense Feature Upsampling with Local Attenders", "categories": ["cs.CV"], "comment": null, "summary": "The space of task-agnostic feature upsampling has emerged as a promising area of research to efficiently create denser features from pre-trained visual backbones. These methods act as a shortcut to achieve dense features for a fraction of the cost by learning to map low-resolution features to high-resolution versions. While early works in this space used iterative upsampling approaches, more recent works have switched to cross-attention-based methods, which risk falling into the same efficiency scaling problems of the backbones they are upsampling. In this work, we demonstrate that iterative upsampling methods can still compete with cross-attention-based methods; moreover, they can achieve state-of-the-art performance with lower inference costs. We propose UPLiFT, an architecture for Universal Pixel-dense Lightweight Feature Transforms. We also propose an efficient Local Attender operator to overcome the limitations of prior iterative feature upsampling methods. This operator uses an alternative attentional pooling formulation defined fully locally. We show that our Local Attender allows UPLiFT to maintain stable features throughout upsampling, enabling state-of-the-art performance with lower inference costs than existing pixel-dense feature upsamplers. In addition, we apply UPLiFT to generative downstream tasks and show that it achieves competitive performance with state-of-the-art Coupled Flow Matching models for VAE feature upsampling. Altogether, UPLiFT offers a versatile and efficient approach to creating denser features.", "AI": {"tldr": "提出了一种名为UPLiFT的架构，用于高效生成密集特征。", "motivation": "展示迭代上采样方法仍然可以与基于交叉注意力的方法竞争，并且在推理成本较低的情况下实现最先进的性能。", "method": "提出了一个称为Local Attender的操作符来克服先前迭代特征上采样方法的局限性。此操作符使用完全本地定义的替代注意池化公式。", "result": "显示了UPLiFT能够通过上采样保持稳定的特征，从而以较低的推理成本实现最先进的性能。此外，还证明了将UPLiFT应用于生成下游任务时可与VAE特征上采样的Coupled Flow Matching模型竞争。", "conclusion": "总的来说，UPLiFT提供了一种灵活且高效的创建更密集特征的方法。"}}
{"id": "2601.17947", "pdf": "https://arxiv.org/pdf/2601.17947", "abs": "https://arxiv.org/abs/2601.17947", "authors": ["Bora Yimenicioglu", "Vishal Manikanden"], "title": "FlowMorph: Physics-Consistent Self-Supervision for Label-Free Single-Cell Mechanics in Microfluidic Videos", "categories": ["cs.CV"], "comment": null, "summary": "Mechanical properties of red blood cells (RBCs) are promising biomarkers for hematologic and systemic disease, motivating microfluidic assays that probe deformability at throughputs of $10^3$--$10^6$ cells per experiment. However, existing pipelines rely on supervised segmentation or hand-crafted kymographs and rarely encode the laminar Stokes-flow physics that governs RBC shape evolution. We introduce FlowMorph, a physics-consistent self-supervised framework that learns a label-free scalar mechanics proxy $k$ for each tracked RBC from short brightfield microfluidic videos. FlowMorph models each cell by a low-dimensional parametric contour, advances boundary points through a differentiable ''capsule-in-flow'' combining laminar advection and curvature-regularized elastic relaxation, and optimizes a loss coupling silhouette overlap, intra-cellular flow agreement, area conservation, wall constraints, and temporal smoothness, using only automatically derived silhouettes and optical flow. Across four public RBC microfluidic datasets, FlowMorph achieves a mean silhouette IoU of $0.905$ on physics-rich videos with provided velocity fields and markedly improves area conservation and wall violations over purely data-driven baselines. On $\\sim 1.5\\times 10^5$ centered sequences, the scalar $k$ alone separates tank-treading from flipping dynamics with an AUC of $0.863$. Using only $200$ real-time deformability cytometry (RT-DC) events for calibration, a monotone map $E=g(k)$ predicts apparent Young's modulus with a mean absolute error of $0.118$\\,MPa on $600$ held-out cells and degrades gracefully under shifts in channel geometry, optics, and frame rate.", "AI": {"tldr": "FlowMorph是一种物理一致的自监督框架，用于从微流体视频中无标签地预测红细胞机械特性。", "motivation": "现有的管道依赖于有监督分割或手动构建的kymographs，并且很少编码支配红细胞形状演变的层流斯托克斯流动物理学。因此，需要一种不需要标签就能提取物理信息的方法来提高微流体实验中细胞力学特性的准确性。", "method": "FlowMorph通过低维参数轮廓模型每个细胞，结合可微分'胶囊在流动'方法模拟边界点的演化，并使用仅基于自动导出轮廓和光学流优化损失函数。该框架实现了物理一致性、形状匹配、流量一致性和时间连续性等约束。", "result": "FlowMorph在四个公开的红细胞微流体数据集上达到了0.905的平均剪影IoU，并且单个标量$k$能够以AUC为0.863区分罐翻转和倒置动态。通过200次实时变形细胞计数校准，它能预测出表观杨氏模量，误差仅为0.118MPa。", "conclusion": "FlowMorph证明了物理一致性的自监督学习方法在微流体视频中的红细胞机械特性识别中具有优越性，并且能够处理不同的几何、光学和帧率变化。"}}
{"id": "2601.17946", "pdf": "https://arxiv.org/pdf/2601.17946", "abs": "https://arxiv.org/abs/2601.17946", "authors": ["Renkai Ma", "Ben Z. Zhang", "Chen Chen", "Fan Yang", "Xiaoshan Huang", "Haolun Wu", "Lingyao Li"], "title": "\"I use ChatGPT to humanize my words\": Affordances and Risks of ChatGPT to Autistic Users", "categories": ["cs.HC"], "comment": null, "summary": "Large Language Model (LLM) chatbots like ChatGPT have emerged as cognitive scaffolding for autistic users, yet the tension between their utility and risk remains under-articulated. Through an inductive thematic analysis of 3,984 social media posts by self-identified autistic users, we apply the Technology Affordance framework to examine this duality. We found that while users leveraged ChatGPT to offload executive dysfunction, regulate emotions, translate neurotypical communication, and validate their autistic identity, these affordances coexist with significant risks: reinforcing delusional thinking, erasing authentic identity through automated masking, and triggering conflicts with the autistic sense of justice. This poster identifies these trade-offs in autistic users' interactions with ChatGPT and concludes by outlining our future work on developing neuro-inclusive technologies that address these tensions through beneficial friction and bidirectional translation.", "AI": {"tldr": "本论文通过分析自认患有自闭症用户的社交媒体帖子，探讨了ChatGPT对自闭症用户的好处与风险。", "motivation": "大型语言模型聊天机器人如ChatGPT作为认知辅助工具被自闭症患者使用，但其效用和风险之间的平衡仍不明确。本研究旨在通过技术潜能框架分析这种潜在的利弊共存问题。", "method": "采用归纳主题分析方法对3,984条由自我识别为自闭症用户的社交媒体帖子进行分析。", "result": "用户利用ChatGPT减轻执行功能障碍、调节情绪、翻译典型沟通方式并验证其身份。然而，这伴随着引发幻觉思维、通过自动化屏蔽抹去真实身份以及触发与正义感冲突的风险。", "conclusion": "该论文识别了自闭症患者使用ChatGPT时存在的利弊权衡，并提出了未来开发具有有益摩擦和双向翻译的神经包容性技术的工作计划。"}}
{"id": "2601.17944", "pdf": "https://arxiv.org/pdf/2601.17944", "abs": "https://arxiv.org/abs/2601.17944", "authors": ["Seyed Majid Zahedi", "Rupert Freeman"], "title": "Credit Fairness: Online Fairness In Shared Resource Pools", "categories": ["cs.GT", "cs.AI", "cs.OS"], "comment": null, "summary": "We consider a setting in which a group of agents share resources that must be allocated among them in each discrete time period. Agents have time-varying demands and derive constant marginal utility from each unit of resource received up to their demand, with zero utility for any additional resources. In this setting, it is known that independently maximizing the minimum utility in each round satisfies sharing incentives (agents weakly prefer participating in the mechanism to not participating), strategyproofness (agents have no incentive to misreport their demands), and Pareto efficiency (Freeman et al. 2018). However, recent work (Vuppalapati et al. 2023) has shown that this max-min mechanism can lead to large disparities in the total resources received by agents, even when they have the same average demand. In this paper, we introduce credit fairness, a strengthening of sharing incentives that ensures agents who lend resources in early rounds are able to recoup them in later rounds. Credit fairness can be achieved in conjunction with either Pareto efficiency or strategyproofness, but not both. We propose a mechanism that is credit fair and Pareto efficient, and we evaluate its performance in a computational resource-sharing setting.", "AI": {"tldr": "本文提出了信用公平性，并设计了一个机制以确保资源分配的长期公平性和效率。", "motivation": "传统最大最小机制可能导致即使平均需求相同，不同用户之间资源分配的巨大差异。为了纠正这种不公平现象，提出了一种新的公平标准——信用公平性。", "method": "作者提出了一个能够实现信用公平和帕累托有效性的新机制，并在计算资源共享环境中对其进行了评估。", "result": "所提出的机制能够在满足信用公平的同时保持资源分配的效率。", "conclusion": "通过引入信用公平，可以更好地保障用户之间长期的资源使用权平衡。"}}
{"id": "2601.17942", "pdf": "https://arxiv.org/pdf/2601.17942", "abs": "https://arxiv.org/abs/2601.17942", "authors": ["Yu-Jie Yang", "Hung-Fu Chang", "Po-An Chen"], "title": "LLM-Based SQL Generation: Prompting, Self-Refinement, and Adaptive Weighted Majority Voting", "categories": ["cs.AI", "cs.DB"], "comment": "29 pages, 22 figures", "summary": "Text-to-SQL has emerged as a prominent research area, particularly with the rapid advancement of large language models (LLMs). By enabling users to query databases through natural language rather than SQL, this technology significantly lowers the barrier to data analysis. However, generating accurate SQL from natural language remains challenging due to ambiguity in user queries, the complexity of schema linking, limited generalization across SQL dialects, and the need for domain-specific understanding. In this study, we propose a Single-Agent Self-Refinement with Ensemble Voting (SSEV) pipeline built on PET-SQL that operates without ground-truth data, integrating self-refinement with Weighted Majority Voting (WMV) and its randomized variant (RWMA). Experimental results show that the SSEV achieves competitive performance across multiple benchmarks, attaining execution accuracies of 85.5% on Spider 1.0-Dev, 86.4% on Spider 1.0-Test, and 66.3% on BIRD-Dev. Building on insights from the SSEV pipeline, we further propose ReCAPAgent-SQL (Refinement-Critique-Act-Plan agent-based SQL framework) to address the growing complexity of enterprise databases and real-world Text-to-SQL tasks. The framework integrates multiple specialized agents for planning, external knowledge retrieval, critique, action generation, self-refinement, schema linking, and result validation, enabling iterative refinement of SQL predictions through agent collaboration. ReCAPAgent-SQL's WMA results achieve 31% execution accuracy on the first 100 queries of Spider 2.0-Lite, demonstrating significant improvements in handling real-world enterprise scenarios. Overall, our work facilitates the deployment of scalable Text-to-SQL systems in practical settings, supporting better data-driven decision-making at lower cost and with greater efficiency.", "AI": {"tldr": "本文提出了一种基于大语言模型的SQL生成方法，包括单代理自我精炼和集成投票的方法，并进一步提出了ReCAPAgent-SQL框架以应对更复杂的现实场景。", "motivation": "由于自然语言查询中的歧义、模式链接复杂性及领域特定知识的需求，从文本到SQL的转换依然面临挑战。因此，本文旨在通过提出新的方法来提高生成准确SQL的能力。", "method": "文中提出了SSEV管道，该管道基于PET-SQL，在没有地面真值数据的情况下工作，结合自我精炼和加权多数投票（WMV）及其随机变体（RWMA）。此外还提到了ReCAPAgent-SQL框架，它整合了多个专门代理来处理规划、外部知识检索、批评、行动生成等任务。", "result": "实验结果显示，在Spider 1.0-Dev上达到了85.5%的执行准确性，而ReCAPAgent-SQL在Spider 2.0-Lite前100个查询中实现了31%的执行准确率。", "conclusion": "本文的工作促进了可扩展文本到SQL系统的实际部署，在降低成本和提高效率的同时支持更好的数据驱动决策。"}}
{"id": "2601.17939", "pdf": "https://arxiv.org/pdf/2601.17939", "abs": "https://arxiv.org/abs/2601.17939", "authors": ["Chengkun Sun", "Jinqian Pan", "Renjie Liang", "Zhengkang Fan", "Xin Miao", "Jiang Bian", "Jie Xu"], "title": "DTC: A Deformable Transposed Convolution Module for Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "In medical image segmentation, particularly in UNet-like architectures, upsampling is primarily used to transform smaller feature maps into larger ones, enabling feature fusion between encoder and decoder features and supporting multi-scale prediction. Conventional upsampling methods, such as transposed convolution and linear interpolation, operate on fixed positions: transposed convolution applies kernel elements to predetermined pixel or voxel locations, while linear interpolation assigns values based on fixed coordinates in the original feature map. These fixed-position approaches may fail to capture structural information beyond predefined sampling positions and can lead to artifacts or loss of detail. Inspired by deformable convolutions, we propose a novel upsampling method, Deformable Transposed Convolution (DTC), which learns dynamic coordinates (i.e., sampling positions) to generate high-resolution feature maps for both 2D and 3D medical image segmentation tasks. Experiments on 3D (e.g., BTCV15) and 2D datasets (e.g., ISIC18, BUSI) demonstrate that DTC can be effectively integrated into existing medical image segmentation models, consistently improving the decoder's feature reconstruction and detail recovery capability.", "AI": {"tldr": "提出了一种新的上采样方法DTC，用于改进医疗图像分割任务中的特征重构和细节恢复能力。", "motivation": "传统的上采样方法（如转置卷积、线性插值）基于固定位置的操作可能导致结构信息丢失或产生伪影。通过引入可学习动态坐标的Deformable Transposed Convolution (DTC)，以期改善医疗图像分割模型的性能。", "method": "设计了一种新的上采样模块，称之为DTC，该模块能够根据输入特征自适应地调整采样位置，从而生成高分辨率特征图，适用于2D和3D医学影像分割任务。", "result": "实验表明，将DTC集成到现有的医疗图像分割模型中可以有效提升解码器的特征重构及细节恢复能力，在多个数据集上实现了性能改进。", "conclusion": "通过引入可学习动态坐标的DTC方法，能够显著改善现有UNet架构在医学影像分割任务中的表现。"}}
{"id": "2601.17937", "pdf": "https://arxiv.org/pdf/2601.17937", "abs": "https://arxiv.org/abs/2601.17937", "authors": ["Anne Arzberger", "Celine Offerman", "Ujwal Gadiraju", "Alessandro Bozzon", "Jie Yang"], "title": "\"Label from Somewhere\": Reflexive Annotating for Situated AI Alignment", "categories": ["cs.HC"], "comment": null, "summary": "AI alignment relies on annotator judgments, yet annotation pipelines often treat annotators as interchangeable, obscuring how their social position shapes annotation. We introduce reflexive annotating as a probe that invites crowd workers to reflect on how their positionality informs subjective annotation judgments in a language model alignment context. Through a qualitative study with crowd workers (N=30) and follow-up interviews (N=5), we examine how our probe shapes annotators' behaviour, experience, and the situated metadata it elicits. We find that reflexive annotating captures epistemic metadata beyond static demographics by eliciting intersectional reasoning, surfacing positional humility, and nudging viewpoint change. Crucially, we also denote tensions between reflexive engagement and affective demands such as emotional exposure. We discuss the implications of our work for richer value elicitation and alignment practices that treat annotator judgments as situated and selectively integrate positional metadata.", "AI": {"tldr": "本文提出了一种名为反射式标注的方法，用于探讨注释者在语言模型对齐中的主观判断是如何受其社会地位影响的。", "motivation": "人工智能对齐依赖于注释者的判断，但现有的标注流程往往忽略了注释者之间的差异性以及他们的社会位置如何塑造了这些判断。本文旨在通过反射式标注来探究这一问题。", "method": "作者进行了一项定性研究（N=30）和后续访谈(N=5)，邀请众包工人反思其主观标注判断是如何受到他们自身社会地位的影响的。", "result": "研究发现，反射式标注能够捕捉到超越静态人口统计学数据的知识元数据，激发了交叉领域推理、揭示了位置谦逊并推动了观点变化。同时也指出了这种参与方式与情感需求之间存在紧张关系，如情绪暴露。", "conclusion": "本文讨论了其工作对更丰富的价值提取和将注释者判断视为情境化的对齐实践的含义，并建议有选择地整合位置元数据。"}}
{"id": "2601.17934", "pdf": "https://arxiv.org/pdf/2601.17934", "abs": "https://arxiv.org/abs/2601.17934", "authors": ["Vi Vu", "Thanh-Huy Nguyen", "Tien-Thinh Nguyen", "Ba-Thinh Lam", "Hoang-Thien Nguyen", "Tianyang Wang", "Xingjian Li", "Min Xu"], "title": "From Specialist to Generalist: Unlocking SAM's Learning Potential on Unlabeled Medical Images", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to ISBI 2026", "summary": "Foundation models like the Segment Anything Model (SAM) show strong generalization, yet adapting them to medical images remains difficult due to domain shift, scarce labels, and the inability of Parameter-Efficient Fine-Tuning (PEFT) to exploit unlabeled data. While conventional models like U-Net excel in semi-supervised medical learning, their potential to assist a PEFT SAM has been largely overlooked. We introduce SC-SAM, a specialist-generalist framework where U-Net provides point-based prompts and pseudo-labels to guide SAM's adaptation, while SAM serves as a powerful generalist supervisor to regularize U-Net. This reciprocal guidance forms a bidirectional co-training loop that allows both models to effectively exploit the unlabeled data. Across prostate MRI and polyp segmentation benchmarks, our method achieves state-of-the-art results, outperforming other existing semi-supervised SAM variants and even medical foundation models like MedSAM, highlighting the value of specialist-generalist cooperation for label-efficient medical image segmentation. Our code is available at https://github.com/vnlvi2k3/SC-SAM.", "AI": {"tldr": "本文提出了一种名为SC-SAM的框架，用于利用未标记的医疗图像来改进SAM模型在医学影像分割任务中的表现。", "motivation": "基础模型如Segment Anything Model (SAM) 在面对医学图像时难以适应，原因是领域差异、标注不足以及参数高效微调(PEFT)无法充分利用无标签数据。本文旨在通过引入U-Net与SAM的双向指导来解决这些问题，并提高医学影像分割的效果。", "method": "SC-SAM框架中，U-Net提供点提示和伪标签以引导SAM适应医疗图像，而SAM则作为强有力的监督模型来规范U-Net的行为。两者之间形成了一个相互促进的学习循环，有效地利用了无标签数据。", "result": "在前列腺MRI及息肉分割基准上，SC-SAM方法取得了最先进的结果，并且优于其他现有的半监督SAM变体和医学基础模型如MedSAM。", "conclusion": "通过结合专家（U-Net）与通用者（SAM），本文展示了如何利用少量标注数据进行高效的医疗影像分割任务。"}}
{"id": "2601.17933", "pdf": "https://arxiv.org/pdf/2601.17933", "abs": "https://arxiv.org/abs/2601.17933", "authors": ["Laurent Caraffa"], "title": "Dissipative Learning: A Framework for Viable Adaptive Systems", "categories": ["cs.LG", "cs.CV"], "comment": "68 pages, 14 figures", "summary": "We propose a perspective in which learning is an intrinsically dissipative process. Forgetting and regularization are not heuristic add-ons but structural requirements for adaptive systems. Drawing on information theory, thermodynamics, and information geometry, we introduce the BEDS (Bayesian Emergent Dissipative Structures) framework, modeling learning as the evolution of compressed belief states under dissipation constraints. A central contribution is the Conditional Optimality Theorem, showing that Fisher-Rao regularization measuring change via information divergence rather than Euclidean distance is the unique thermodynamically optimal regularization strategy, achieving minimal dissipation. Euclidean regularization is shown to be structurally suboptimal. The framework unifies existing methods (Ridge, SIGReg, EMA, SAC) as special cases of a single governing equation. Within this view, overfitting corresponds to over-crystallization, while catastrophic forgetting reflects insufficient dissipation control. The framework distinguishes BEDS-crystallizable problems, where beliefs converge to stable equilibria, from BEDS-maintainable problems, which require continual adaptation. It extends naturally to continual and multi-agent systems, where viability, stability under adaptation and finite resources replaces asymptotic optimality as the primary criterion. Overall, this work reframes learning as maintaining viable belief states under dissipation constraints, providing a principled lens on forgetting, regularization, and stability.", "AI": {"tldr": "该论文提出了一种将学习视为耗散过程的框架，称为BEDS（贝叶斯涌现耗散结构），并通过信息几何等理论证明了其优越性。", "motivation": "动机是重新审视遗忘和正则化在适应系统中的作用，并提供一种新的视角来理解学习、稳定性和适应性的关系。", "method": "方法包括使用信息论、热力学和信息几何提出了BEDS框架，该框架将学习建模为压缩信念状态下的耗散过程。此外还推导了条件最优性定理，证明了Fisher-Rao正则化优于传统的欧几里得距离的策略。", "result": "结果表明，BEDS框架统一了许多现有的方法，并提供了理解过度拟合和灾难性遗忘的新视角。同时区分出需要稳定状态的问题和需要持续适应的问题。", "conclusion": "结论是该工作通过引入新的概念框架，重新定义了学习在耗散约束下的原理，为理解和解决机器学习中的稳定性问题提供了一种新思路。"}}
{"id": "2601.17927", "pdf": "https://arxiv.org/pdf/2601.17927", "abs": "https://arxiv.org/abs/2601.17927", "authors": ["Eashan Adhikarla", "Brian D. Davison"], "title": "RemEdit: Efficient Diffusion Editing with Riemannian Geometry", "categories": ["cs.CV", "cs.MM"], "comment": "ef:IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2026", "summary": "Controllable image generation is fundamental to the success of modern generative AI, yet it faces a critical trade-off between semantic fidelity and inference speed. The RemEdit diffusion-based framework addresses this trade-off with two synergistic innovations. First, for editing fidelity, we navigate the latent space as a Riemannian manifold. A mamba-based module efficiently learns the manifold's structure, enabling direct and accurate geodesic path computation for smooth semantic edits. This control is further refined by a dual-SLERP blending technique and a goal-aware prompt enrichment pass from a Vision-Language Model. Second, for additional acceleration, we introduce a novel task-specific attention pruning mechanism. A lightweight pruning head learns to retain tokens essential to the edit, enabling effective optimization without the semantic degradation common in content-agnostic approaches. RemEdit surpasses prior state-of-the-art editing frameworks while maintaining real-time performance under 50% pruning. Consequently, RemEdit establishes a new benchmark for practical and powerful image editing. Source code: https://www.github.com/eashanadhikarla/RemEdit.", "AI": {"tldr": "RemEdit框架利用黎曼几何和注意力修剪机制，实现了高效且保真的图像编辑。", "motivation": "当前的图像生成技术在语义准确性和推理速度之间存在权衡。论文旨在通过创新的方法解决这一问题，以实现更高效的可控图像生成。", "method": "RemEdit框架利用黎曼几何导航潜在空间并计算测地线路径，结合双SLERP插值技术和语言视觉模型的提示增强技术来提高编辑精度，并引入任务特定注意力修剪机制加速推理。", "result": "该方法在保持实时性能的同时超越了现有的图像编辑基准。", "conclusion": "RemEdit框架通过创新的技术实现了高效和强大的图像编辑，为可控图像生成领域树立了新的标准。"}}
{"id": "2601.17923", "pdf": "https://arxiv.org/pdf/2601.17923", "abs": "https://arxiv.org/abs/2601.17923", "authors": ["Ali Najar"], "title": "Learning Transferable Skills in Action RPGs via Directed Skill Graphs and Selective Adaptation", "categories": ["cs.AI"], "comment": "5 pages", "summary": "Lifelong agents should expand their competence over time without retraining from scratch or overwriting previously learned behaviors. We investigate this in a challenging real-time control setting (Dark Souls III) by representing combat as a directed skill graph and training its components in a hierarchical curriculum. The resulting agent decomposes control into five reusable skills: camera control, target lock-on, movement, dodging, and a heal-attack decision policy, each optimized for a narrow responsibility. This factorization improves sample efficiency by reducing the burden on any single policy and supports selective post-training: when the environment shifts from Phase 1 to Phase 2, only a subset of skills must be adapted, while upstream skills remain transferable. Empirically, we find that targeted fine-tuning of just two skills rapidly recovers performance under a limited interaction budget, suggesting that skill-graph curricula together with selective fine-tuning offer a practical pathway toward evolving, continually learning agents in complex real-time environments.", "AI": {"tldr": "本文研究了在动作角色扮演游戏《黑暗之魂III》中，通过技能图和选择性适应来学习可转移的技能。", "motivation": "长期代理应随时间扩展其能力而不需从头开始重新训练或覆盖先前已学的行为。本文通过一种挑战性的实时控制设置（Dark Souls III）探讨了该问题。", "method": "将战斗表示为有向技能图，并采用分层课程培训其组件，形成可分解的五项复用技能：相机控制、目标锁定、移动、回避和治疗攻击策略，每项技能专注于一个特定职责。", "result": "实验表明，在环境从第一阶段转换到第二阶段时，仅需对两项技能进行有针对性的微调即可快速恢复性能，并且在有限互动预算下表现优异。", "conclusion": "本文提出的方法结合了技能图课程与选择性适应训练，为复杂实时环境中演进、持续学习代理提供了一条实用路径。"}}
{"id": "2601.17920", "pdf": "https://arxiv.org/pdf/2601.17920", "abs": "https://arxiv.org/abs/2601.17920", "authors": ["Xuanzhou Chen", "Audrey Wang", "Stanley Yin", "Hanyang Jiang", "Dong Zhang"], "title": "Agentic AI for Self-Driving Laboratories in Soft Matter: Taxonomy, Benchmarks,and Open Challenges", "categories": ["cs.AI"], "comment": null, "summary": "Self-driving laboratories (SDLs) close the loop between experiment design, automated execution, and data-driven decision making, and they provide a demanding testbed for agentic AI under expensive actions, noisy and delayed feedback, strict feasibility and safety constraints, and non-stationarity. This survey uses soft matter as a representative setting but focuses on the AI questions that arise in real laboratories. We frame SDL autonomy as an agent environment interaction problem with explicit observations, actions, costs, and constraints, and we use this formulation to connect common SDL pipelines to established AI principles. We review the main method families that enable closed loop experimentation, including Bayesian optimization and active learning for sample efficient experiment selection, planning and reinforcement learning for long horizon protocol optimization, and tool using agents that orchestrate heterogeneous instruments and software. We emphasize verifiable and provenance aware policies that support debugging, reproducibility, and safe operation. We then propose a capability driven taxonomy that organizes systems by decision horizon, uncertainty modeling, action parameterization, constraint handling, failure recovery, and human involvement. To enable meaningful comparison, we synthesize benchmark task templates and evaluation metrics that prioritize cost aware performance, robustness to drift, constraint violation behavior, and reproducibility. Finally, we distill lessons from deployed SDLs and outline open challenges in multi-modal representation, calibrated uncertainty, safe exploration, and shared benchmark infrastructure.", "AI": {"tldr": "本文综述了自驾驶实验室在软物质研究中的应用，重点讨论了代理人工智能的关键问题和方法论。", "motivation": "文章旨在通过软物质实验来探讨真实实验室中自我驱动实验室的自主性和挑战性，推动更高效、更安全的研究实践。", "method": "该论文提出了一个能力导向的分类法，并结合典型任务模板及评估标准来比较不同方法的有效性与局限性。", "result": "总结了现有的研究经验并指出未来多模态表示、校准不确定性等关键领域的发展方向和开放挑战。", "conclusion": "强调了自驾驶实验室中代理人工智能的重要性，以及如何通过技术改进提升实验效率和安全性。"}}
{"id": "2601.17918", "pdf": "https://arxiv.org/pdf/2601.17918", "abs": "https://arxiv.org/abs/2601.17918", "authors": ["Dain Kim", "Jiwoo Lee", "Jaehoon Yun", "Yong Hoe Koo", "Qingyu Chen", "Hyunjae Kim", "Jaewoo Kang"], "title": "Benchmarking Direct Preference Optimization for Medical Large Vision-Language Models", "categories": ["cs.CV", "cs.CL"], "comment": "EACL 2026 (Findings)", "summary": "Large Vision-Language Models (LVLMs) hold significant promise for medical applications, yet their deployment is often constrained by insufficient alignment and reliability. While Direct Preference Optimization (DPO) has emerged as a potent framework for refining model responses, its efficacy in high-stakes medical contexts remains underexplored, lacking the rigorous empirical groundwork necessary to guide future methodological advances. To bridge this gap, we present the first comprehensive examination of diverse DPO variants within the medical domain, evaluating nine distinct formulations across two medical LVLMs: LLaVA-Med and HuatuoGPT-Vision. Our results reveal several critical limitations: current DPO approaches often yield inconsistent gains over supervised fine-tuning, with their efficacy varying significantly across different tasks and backbones. Furthermore, they frequently fail to resolve fundamental visual misinterpretation errors. Building on these insights, we present a targeted preference construction strategy as a proof-of-concept that explicitly addresses visual misinterpretation errors frequently observed in existing DPO models. This design yields a 3.6% improvement over the strongest existing DPO baseline on visual question-answering tasks. To support future research, we release our complete framework, including all training data, model checkpoints, and our codebase at https://github.com/dmis-lab/med-vlm-dpo.", "AI": {"tldr": "评估和改进直接偏好优化在医疗大视觉语言模型中的应用", "motivation": "研究直接偏好优化方法在医学领域的有效性和局限性，以推动未来的研究进展", "method": "对九种不同的DPO变体进行系统评估，并提出一种针对性的偏好数值构造策略来解决常见的视觉误解错误", "result": "发现现有的DPO方法对于监督微调的优势不一致且在处理特定任务时存在显著差异，提出的改进方案在视觉问答任务上提升了3.6%的表现", "conclusion": "证明了直接偏好优化在医疗应用中具有潜在价值，并指出了其局限性和未来的研究方向"}}
{"id": "2601.17917", "pdf": "https://arxiv.org/pdf/2601.17917", "abs": "https://arxiv.org/abs/2601.17917", "authors": ["Zhongyu Xiao", "Zhiwei Hao", "Jianyuan Guo", "Yong Luo", "Jia Liu", "Jie Xu", "Han Hu"], "title": "Streaming-dLLM: Accelerating Diffusion LLMs via Suffix Pruning and Dynamic Decoding", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": "Tech report. Code is available at https://github.com/xiaoshideta/Streaming-dLLM", "summary": "Diffusion Large Language Models (dLLMs) offer a compelling paradigm for natural language generation, leveraging parallel decoding and bidirectional attention to achieve superior global coherence compared to autoregressive models. While recent works have accelerated inference via KV cache reuse or heuristic decoding, they overlook the intrinsic inefficiencies within the block-wise diffusion process. Specifically, they suffer from spatial redundancy by modeling informative-sparse suffix regions uniformly and temporal inefficiency by applying fixed denoising schedules across all the decoding process. To address this, we propose Streaming-dLLM, a training-free framework that streamlines inference across both spatial and temporal dimensions. Spatially, we introduce attenuation guided suffix modeling to approximate the full context by pruning redundant mask tokens. Temporally, we employ a dynamic confidence aware strategy with an early exit mechanism, allowing the model to skip unnecessary iterations for converged tokens. Extensive experiments show that Streaming-dLLM achieves up to 68.2X speedup while maintaining generation quality, highlighting its effectiveness in diffusion decoding. The code is available at https://github.com/xiaoshideta/Streaming-dLLM.", "AI": {"tldr": "本文提出了一种名为Streaming-dLLM的框架，通过空间和时间两个维度优化扩散大型语言模型（dLLMs）的推理过程。", "motivation": "现有的工作虽然加速了dLLMs的推断，但未能解决块式扩散过程中固有的低效问题。这些问题包括对信息稀疏区域进行统一建模的空间冗余以及在整个解码过程中应用固定去噪时间表的时间效率低下。", "method": "引入衰减引导后缀建模以通过剪枝冗余掩码令牌来近似完整上下文，从而实现空间优化；并采用动态信心感知策略和提前退出机制以跳过不必要的迭代，实现了时间优化。", "result": "实验结果表明，Streaming-dLLM能够提供高达68.2倍的加速，并且保持了生成质量。", "conclusion": "本文提出了一种有效的扩散解码框架，显著提高了dLLMs在推理阶段的速度和效率。"}}
{"id": "2601.17915", "pdf": "https://arxiv.org/pdf/2601.17915", "abs": "https://arxiv.org/abs/2601.17915", "authors": ["Saurabh Jha", "Rohan Arora", "Bhavya", "Noah Zheutlin", "Paulina Toro Isaza", "Laura Shwartz", "Yu Deng", "Daby Sow", "Ruchi Mahindru", "Ruchir Puri"], "title": "Think Locally, Explain Globally: Graph-Guided LLM Investigations via Local Reasoning and Belief Propagation", "categories": ["cs.AI", "cs.LG", "cs.LO"], "comment": null, "summary": "LLM agents excel when environments are mostly static and the needed information fits in a model's context window, but they often fail in open-ended investigations where explanations must be constructed by iteratively mining evidence from massive, heterogeneous operational data. These investigations exhibit hidden dependency structure: entities interact, signals co-vary, and the importance of a fact may only become clear after other evidence is discovered. Because the context window is bounded, agents must summarize intermediate findings before their significance is known, increasing the risk of discarding key evidence. ReAct-style agents are especially brittle in this regime. Their retrieve-summarize-reason loop makes conclusions sensitive to exploration order and introduces run-to-run non-determinism, producing a reliability gap where Pass-at-k may be high but Majority-at-k remains low. Simply sampling more rollouts or generating longer reasoning traces does not reliably stabilize results, since hypotheses cannot be autonomously checked as new evidence arrives and there is no explicit mechanism for belief bookkeeping and revision. In addition, ReAct entangles semantic reasoning with controller duties such as tool orchestration and state tracking, so execution errors and plan drift degrade reasoning while consuming scarce context. We address these issues by formulating investigation as abductive reasoning over a dependency graph and proposing EoG (Explanations over Graphs), a disaggregated framework in which an LLM performs bounded local evidence mining and labeling (cause vs symptom) while a deterministic controller manages traversal, state, and belief propagation to compute a minimal explanatory frontier. On a representative ITBench diagnostics task, EoG improves both accuracy and run-to-run consistency over ReAct baselines, including a 7x average gain in Majority-at-k entity F1.", "AI": {"tldr": "该论文提出了一种新的框架EoG，用于通过依赖图进行推理和证据传播来解决大型语言模型在开放性调查中的表现问题。", "motivation": "大型语言模型在静态环境和有限上下文窗口中表现出色，但在需要从大量异构数据中迭代挖掘证据的开放性任务上存在困难。这些任务中的隐含依赖结构可能导致中间结果被错误地总结或丢弃，影响最终结论的可靠性。", "method": "论文提出了一种新的框架EoG（图上的解释），该框架通过局部证据挖掘和标记来解决这些问题，并使用确定性的控制器进行遍历、状态管理和信念传播。", "result": "在ITBench诊断任务中，EoG框架比现有的ReAct方法提高了准确性和运行间的一致性，特别是在Majority-at-k实体F1指标上有了7倍的平均改进。", "conclusion": "通过将推理问题转化为基于依赖图的归纳推理，并分离语义推理和控制器职责，论文成功地解决了大型语言模型在开放性任务中的表现问题。"}}
{"id": "2601.17912", "pdf": "https://arxiv.org/pdf/2601.17912", "abs": "https://arxiv.org/abs/2601.17912", "authors": ["Qinyi Liu", "Mohammad Khalil", "Naman Goel"], "title": "Causal Pre-training Under the Fairness Lens: An Empirical Study of TabPFN", "categories": ["cs.LG", "cs.AI"], "comment": "ef:Proceedings of the ACM Web Conference 2026 (WWW '26), April 13--17, 2026, Dubai, United Arab Emirates", "summary": "Foundation models for tabular data, such as the Tabular Prior-data Fitted Network (TabPFN), are pre-trained on a massive number of synthetic datasets generated by structural causal models (SCM). They leverage in-context learning to offer high predictive accuracy in real-world tasks. However, the fairness properties of these foundational models, which incorporate ideas from causal reasoning during pre-training, remain underexplored. In this work, we conduct a comprehensive empirical evaluation of TabPFN and its fine-tuned variants, assessing predictive performance, fairness, and robustness across varying dataset sizes and distributional shifts. Our results reveal that while TabPFN achieves stronger predictive accuracy compared to baselines and exhibits robustness to spurious correlations, improvements in fairness are moderate and inconsistent, particularly under missing-not-at-random (MNAR) covariate shifts. These findings suggest that the causal pre-training in TabPFN is helpful but insufficient for algorithmic fairness, highlighting implications for deploying TabPFN (and similar) models in practice and the need for further fairness interventions.", "AI": {"tldr": "本文研究了基于结构因果模型预训练的TabPFN在处理不同规模数据集和分布偏移时的表现，特别是其预测准确性、公平性和鲁棒性。", "motivation": "尽管基础模型如TabPFN在合成数据上进行了因果推理相关的预训练，并能提供较高的实际任务预测准确度，但这些模型的公平性特性仍缺乏充分的研究。因此，本文旨在全面评估TabPFN及其微调变体在不同情境下的表现情况。", "method": "通过生成多个具有不同程度数据偏移的数据集，对TabPFN和其变体进行性能、公平性和鲁棒性的综合实证测试。", "result": "结果显示，尽管TabPFN比基线模型表现出更强的预测准确度，并且能抵御虚假相关性的影响，但在面对缺失值不随机（MNAR）的数据时，其改进后的公平性表现有限并且不稳定。", "conclusion": "研究结果表明，在算法公平性的提高方面，因果预训练虽然有帮助但并不足够。这提示了在实际部署TabPFN等类似模型时需要进一步采取措施来提升公平性。"}}
{"id": "2601.17905", "pdf": "https://arxiv.org/pdf/2601.17905", "abs": "https://arxiv.org/abs/2601.17905", "authors": ["Jack Foster", "Kirill Paramonov", "Mete Ozay", "Umberto Michieli"], "title": "Feature-Space Generative Models for One-Shot Class-Incremental Learning", "categories": ["cs.CV", "cs.AI", "stat.ML"], "comment": null, "summary": "Few-shot class-incremental learning (FSCIL) is a paradigm where a model, initially trained on a dataset of base classes, must adapt to an expanding problem space by recognizing novel classes with limited data. We focus on the challenging FSCIL setup where a model receives only a single sample (1-shot) for each novel class and no further training or model alterations are allowed after the base training phase. This makes generalization to novel classes particularly difficult. We propose a novel approach predicated on the hypothesis that base and novel class embeddings have structural similarity. We map the original embedding space into a residual space by subtracting the class prototype (i.e., the average class embedding) of input samples. Then, we leverage generative modeling with VAE or diffusion models to learn the multi-modal distribution of residuals over the base classes, and we use this as a valuable structural prior to improve recognition of novel classes. Our approach, Gen1S, consistently improves novel class recognition over the state of the art across multiple benchmarks and backbone architectures.", "AI": {"tldr": "提出了一种名为Gen1S的新方法，用于解决一示例类增量学习中的挑战。", "motivation": "针对一示例类增量学习任务中模型难以泛化到新类别的问题进行研究", "method": "通过生成对抗网络或扩散模型在剩余空间里训练多模态分布来提升对新类别的识别能力。", "result": "该方法在多个基准测试和骨干架构上优于现有技术，显著提升了对新类别的识别精度。", "conclusion": "Gen1S能够有效解决一示例类增量学习中的问题，并且具有广泛的适用性。"}}
{"id": "2601.17902", "pdf": "https://arxiv.org/pdf/2601.17902", "abs": "https://arxiv.org/abs/2601.17902", "authors": ["Wenjie Tian", "Bingshen Mu", "Guobin Ma", "Xuelong Geng", "Zhixian Zhao", "Lei Xie"], "title": "dLLM-ASR: A Faster Diffusion LLM-based Framework for Speech Recognition", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Automatic speech recognition (ASR) systems based on large language models (LLMs) achieve superior performance by leveraging pretrained LLMs as decoders, but their token-by-token generation mechanism leads to inference latency that grows linearly with sequence length. Meanwhile, discrete diffusion large language models (dLLMs) offer a promising alternative, enabling high-quality parallel sequence generation with pretrained decoders. However, directly applying native text-oriented dLLMs to ASR leads to a fundamental mismatch between open-ended text generation and the acoustically conditioned transcription paradigm required by ASR. As a result, it introduces unnecessary difficulty and computational redundancy, such as denoising from pure noise, inflexible generation lengths, and fixed denoising steps. We propose dLLM-ASR, an efficient dLLM-based ASR framework that formulates dLLM's decoding as a prior-guided and adaptive denoising process. It leverages an ASR prior to initialize the denoising process and provide an anchor for sequence length. Building upon this prior, length-adaptive pruning dynamically removes redundant tokens, while confidence-based denoising allows converged tokens to exit the denoising loop early, enabling token-level adaptive computation. Experiments demonstrate that dLLM-ASR achieves recognition accuracy comparable to autoregressive LLM-based ASR systems and delivers a 4.44$\\times$ inference speedup, establishing a practical and efficient paradigm for ASR.", "AI": {"tldr": "提出了一种基于扩散大语言模型的自动语音识别框架dLLM-ASR，该框架通过自适应去噪和长度剪枝来提高推断效率。", "motivation": "现有的基于大型语言模型的自动语音识别系统存在延迟问题，并且直接应用文本导向的扩散大语言模型到语音识别中会导致不匹配的问题，影响性能。", "method": "提出了一种新的框架dLLM-ASR，利用了一个语音先验来初始化去噪过程并确定序列长度。通过长度自适应剪枝删除冗余令牌，并采用基于置信度的去噪使收敛的令牌提前退出循环，实现了令牌级计算的自适应。", "result": "实验表明，dLLM-ASR在识别准确率上与自回归大语言模型自动语音识别系统相当，同时提供了4.44倍的推断加速。", "conclusion": "提出了一个基于扩散大语言模型的高效自动语音识别框架，并通过实验验证了其有效性和效率。"}}
{"id": "2601.17901", "pdf": "https://arxiv.org/pdf/2601.17901", "abs": "https://arxiv.org/abs/2601.17901", "authors": ["Yuanchao Li"], "title": "Speech Emotion Recognition with ASR Integration", "categories": ["eess.AS", "cs.SD"], "comment": "PhD Thesis", "summary": "Speech Emotion Recognition (SER) plays a pivotal role in understanding human communication, enabling emotionally intelligent systems, and serving as a fundamental component in the development of Artificial General Intelligence (AGI). However, deploying SER in real-world, spontaneous, and low-resource scenarios remains a significant challenge due to the complexity of emotional expression and the limitations of current speech and language technologies. This thesis investigates the integration of Automatic Speech Recognition (ASR) into SER, with the goal of enhancing the robustness, scalability, and practical applicability of emotion recognition from spoken language.", "AI": {"tldr": "研究将自动语音识别（ASR）集成到语音情感识别（SER）中，以提高其鲁棒性、可扩展性和实用性。", "motivation": "解决在现实世界中的自发和低资源场景下部署语音情感识别的挑战。", "method": "通过集成自动语音识别技术来改进情感识别系统。", "result": "增强了情感识别系统的鲁棒性、可扩展性和实际应用能力。", "conclusion": "ASR与SER的结合可以有效提升情感识别的效果，适用于更多应用场景。"}}
{"id": "2601.17900", "pdf": "https://arxiv.org/pdf/2601.17900", "abs": "https://arxiv.org/abs/2601.17900", "authors": ["Shengjun Zhang", "Min Chen", "Yibo Wei", "Mingyu Dong", "Yueqi Duan"], "title": "Revisiting 3D Reconstruction Kernels as Low-Pass Filters", "categories": ["cs.CV"], "comment": "14 pages, 5 figures", "summary": "3D reconstruction is to recover 3D signals from the sampled discrete 2D pixels, with the goal to converge continuous 3D spaces. In this paper, we revisit 3D reconstruction from the perspective of signal processing, identifying the periodic spectral extension induced by discrete sampling as the fundamental challenge. Previous 3D reconstruction kernels, such as Gaussians, Exponential functions, and Student's t distributions, serve as the low pass filters to isolate the baseband spectrum. However, their unideal low-pass property results in the overlap of high-frequency components with low-frequency components in the discrete-time signal's spectrum. To this end, we introduce Jinc kernel with an instantaneous drop to zero magnitude exactly at the cutoff frequency, which is corresponding to the ideal low pass filters. As Jinc kernel suffers from low decay speed in the spatial domain, we further propose modulated kernels to strick an effective balance, and achieves superior rendering performance by reconciling spatial efficiency and frequency-domain fidelity. Experimental results have demonstrated the effectiveness of our Jinc and modulated kernels.", "AI": {"tldr": "重新审视并改进了三维重建中的低通滤波器技术，引入Jinc核函数和调制的核函数以提高渲染性能。", "motivation": "现有的3D重建内核无法有效隔离频谱中的高低频分量，导致信号重建质量不佳。因此需要一种新的内核来解决这个问题。", "method": "提出使用具有理想低通滤波特性的Jinc核函数，并通过调制技术改善其空间衰减特性，以平衡空间效率和频率域的准确性。", "result": "实验结果表明所提出的Jinc和调制的核函数在三维重建任务中取得了更好的渲染性能。", "conclusion": "新的内核方法显著提升了3D信号恢复的质量，为未来的3D图像处理提供了新思路。"}}
{"id": "2601.17899", "pdf": "https://arxiv.org/pdf/2601.17899", "abs": "https://arxiv.org/abs/2601.17899", "authors": ["Junhao Qiu", "Xin Chen", "Liang Ge", "Liyong Lin", "Zhichao Lu", "Qingfu Zhang"], "title": "Evolving Interdependent Operators with Large Language Models for Multi-Objective Combinatorial Optimization", "categories": ["cs.NE"], "comment": null, "summary": "Neighborhood search operators are critical to the performance of Multi-Objective Evolutionary Algorithms (MOEAs) and rely heavily on expert design. Although recent LLM-based Automated Heuristic Design (AHD) methods have made notable progress, they primarily optimize individual heuristics or components independently, lacking explicit exploration and exploitation of dynamic coupling relationships between multiple operators. In this paper, multi-operator optimization in MOEAs is formulated as a Markov decision process, enabling the improvement of interdependent operators through sequential decision-making. To address this, we propose the Evolution of Operator Combination (E2OC) framework for MOEAs, which achieves the co-evolution of design strategies and executable codes. E2OC employs Monte Carlo Tree Search to progressively search combinations of operator design strategies and adopts an operator rotation mechanism to identify effective operator configurations while supporting the integration of mainstream AHD methods as the underlying designer. Experimental results across AHD tasks with varying objectives and problem scales show that E2OC consistently outperforms state-of-the-art AHD and other multi-heuristic co-design frameworks, demonstrating strong generalization and sustained optimization capability.", "AI": {"tldr": "本文提出了一种基于大语言模型的多目标组合优化框架E2OC，该框架通过协同进化策略和可执行代码的设计来改进MOEA中的互依赖算子。", "motivation": "现有的LLM-based AHD方法主要独立优化单个启发式或组件，并未充分探索多个操作符之间的动态耦合关系。因此，本文旨在利用强化学习解决多目标组合问题中互依赖操作符的协同进化。", "method": "E2OC框架将多算子优化表述为马尔可夫决策过程，通过蒙特卡洛树搜索方法进行序列决策来改进互依赖的操作符设计策略，并采用操作符轮换机制以发现有效的操作符配置。同时支持主流AHD方法作为底层设计者。", "result": "实验结果表明，在不同目标和问题规模的AHD任务中，E2OC框架的表现优于最先进的AHD和其他多启发式协同设计框架，展示了强大的泛化能力和持续优化能力。", "conclusion": "本文提出的E2OC框架成功地实现了MOEA中互依赖操作符的有效配置，并且在各种实验设置下均表现出色，证明了其作为未来研究方向的潜力。"}}
{"id": "2601.17897", "pdf": "https://arxiv.org/pdf/2601.17897", "abs": "https://arxiv.org/abs/2601.17897", "authors": ["Jiayu Liu", "Yinhe Long", "Zhenya Huang", "Enhong Chen"], "title": "UniCog: Uncovering Cognitive Abilities of LLMs through Latent Mind Space Analysis", "categories": ["cs.AI"], "comment": null, "summary": "A growing body of research suggests that the cognitive processes of large language models (LLMs) differ fundamentally from those of humans. However, existing interpretability methods remain limited in explaining how cognitive abilities are engaged during LLM reasoning. In this paper, we propose UniCog, a unified framework that analyzes LLM cognition via a latent mind space. Formulated as a latent variable model, UniCog encodes diverse abilities from dense model activations into sparse, disentangled latent dimensions. Through extensive analysis on six advanced LLMs, including DeepSeek-V3.2 and GPT-4o, we reveal a Pareto principle of LLM cognition, where a shared reasoning core is complemented by ability-specific signatures. Furthermore, we discover that reasoning failures often manifest as anomalous intensity in latent activations. These findings opens a new paradigm in LLM analysis, providing a cognition grounded view of reasoning dynamics. Finally, leveraging these insights, we introduce a latent-informed candidate prioritization strategy, which improves reasoning performance by up to 7.5% across challenging benchmarks. Our code is available at https://github.com/milksalute/unicog.", "AI": {"tldr": "UniCog通过潜意识空间分析大型语言模型的认知能力。", "motivation": "现有可解释性方法在解释大型语言模型认知能力的参与方面存在局限，本文旨在提出一种新的框架来深入理解这些模型的认知过程。", "method": "UniCog是一种将多样化的认知能力编码到稀疏、解耦的潜在维度中的统一框架。它通过六种先进LLM进行广泛分析，揭示了它们的认知特性。", "result": "发现了一种帕累托原理，表明共有的推理核心与特定技能标记相结合。此外，推理错误常常表现为潜意识激活异常强度。利用这些见解，提出了改进性能的策略。", "conclusion": "UniCog提供了一个基于认知的新分析范式，并通过引入潜在信息候选优先级策略提高了模型在挑战性基准上的表现。"}}
{"id": "2601.17895", "pdf": "https://arxiv.org/pdf/2601.17895", "abs": "https://arxiv.org/abs/2601.17895", "authors": ["Bin Tan", "Changjiang Sun", "Xiage Qin", "Hanat Adai", "Zelin Fu", "Tianxiang Zhou", "Han Zhang", "Yinghao Xu", "Xing Zhu", "Yujun Shen", "Nan Xue"], "title": "Masked Depth Modeling for Spatial Perception", "categories": ["cs.CV", "cs.RO"], "comment": "Tech report, 19 pages, 15 figures and 4 tables", "summary": "Spatial visual perception is a fundamental requirement in physical-world applications like autonomous driving and robotic manipulation, driven by the need to interact with 3D environments. Capturing pixel-aligned metric depth using RGB-D cameras would be the most viable way, yet it usually faces obstacles posed by hardware limitations and challenging imaging conditions, especially in the presence of specular or texture-less surfaces. In this work, we argue that the inaccuracies from depth sensors can be viewed as \"masked\" signals that inherently reflect underlying geometric ambiguities. Building on this motivation, we present LingBot-Depth, a depth completion model which leverages visual context to refine depth maps through masked depth modeling and incorporates an automated data curation pipeline for scalable training. It is encouraging to see that our model outperforms top-tier RGB-D cameras in terms of both depth precision and pixel coverage. Experimental results on a range of downstream tasks further suggest that LingBot-Depth offers an aligned latent representation across RGB and depth modalities. We release the code, checkpoint, and 3M RGB-depth pairs (including 2M real data and 1M simulated data) to the community of spatial perception.", "AI": {"tldr": "本文提出了一种基于视觉上下文的深度完成模型LingBot-Depth，以改进深度传感器在复杂条件下的准确性。", "motivation": "传统RGB-D相机在处理具有镜面或无纹理表面的情况下存在硬件限制和成像挑战。作者认为这些不准确可以被视为“掩藏”信号，并且可以通过利用视觉上下文来改善。", "method": "LingBot-Depth模型通过掩模深度建模改进深度图，同时集成自动数据整理流程以支持大规模训练。", "result": "实验结果显示，该方法在深度精度和像素覆盖方面优于顶级RGB-D相机。此外，在多个下游任务中也展示了跨RGB和深度模式的一致表示。", "conclusion": "研究提出了一种新的深度完成模型LingBot-Depth，并通过大量数据验证了其有效性。相关代码、检查点以及3M张的RGB-D图像对已向社区开放。"}}
{"id": "2601.17893", "pdf": "https://arxiv.org/pdf/2601.17893", "abs": "https://arxiv.org/abs/2601.17893", "authors": ["Sarmistha Sarna Gomasta", "Mahmood Jasim", "Hossein Hadisi", "Yvonne Jansen", "Pierre Dragicevic", "Narges Mahyar", "Ali Sarvghad"], "title": "Investigating How Music Affects Persuasion, Engagement, and Emotion in Data Videos", "categories": ["cs.HC"], "comment": null, "summary": "Data videos have become a prominent vessel for communicating data to broad audiences, and a common object of study in information visualization. Many of these videos include music, yet the impact of music on how people experience data videos remains largely unexplored. We conducted a preregistered study into the effect of music across three dimensions: persuasion, engagement, and emotion. We showed online participants an existing data video (1) without any music, (2) with its generic default music, and (3) with custom music designed by a professional composer. We found that the default music helped make the data video more persuasive. However, the effects of custom music were more mixed, and we did not find that music increased engagement. In addition, and contrary to our expectations, our participants reported more intense emotions without music. Our study contributes new insights into the intersection of music and data visualization and is a first step toward guiding designers in creating impactful data-driven narratives.", "AI": {"tldr": "研究音乐对数据视频说服力、参与度和情感的影响。", "motivation": "探索音乐在数据视频中的影响，以提高数据可视化设计的有效性。", "method": "通过在线参与者观看三种不同背景音的数据视频（无音乐、默认音乐、定制音乐）来进行实验。", "result": "发现默认音乐有助于增强说服力，但定制音乐的效果较为复杂。此外，没有音乐时报告的情感强度更高，并未提高参与度。", "conclusion": "研究揭示了音乐与数据可视化的互动关系，为设计师提供指导以创造更具影响力的数据叙事。"}}
{"id": "2601.17892", "pdf": "https://arxiv.org/pdf/2601.17892", "abs": "https://arxiv.org/abs/2601.17892", "authors": ["Sahibpreet Singh", "Manjit Singh"], "title": "Artificial Intelligence and Intellectual Property Rights: Comparative Transnational Policy Analysis", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "comment": "Published in Journal of University Institute of Legal Studies, Vol. 19, Issue 1, pp. 182-208, 2025", "summary": "Artificial intelligence's rapid integration with intellectual property rights necessitates assessment of its impact on trade secrets, copyrights and patents. This study addresses lacunae in existing laws where India lacks AI-specific provisions, creating doctrinal inconsistencies and enforcement inefficacies. Global discourse on AI-IPR protections remains nascent. The research identifies gaps in Indian IP laws' adaptability to AI-generated outputs: trade secret protection is inadequate against AI threats; standardized inventorship criteria are absent. Employing doctrinal and comparative methodology, it scrutinizes legislative texts, judicial precedents and policy instruments across India, US, UK and EU. Preliminary findings reveal shortcomings: India's contract law creates fragmented trade secret regime; Section 3(k) of Indian Patents Act blocks AI invention patenting; copyright varies in authorship attribution. The study proposes harmonized legal taxonomy accommodating AI's role while preserving innovation incentives. India's National AI Strategy (2024) shows progress but legislative clarity is imperative. This contributes to global discourse with AI-specific IP protections ensuring resilience and equitable innovation. Promising results underscore recalibrating India's IP jurisprudence for global alignment.", "AI": {"tldr": "本文评估了人工智能对知识产权的影响，并比较分析印度、美国、英国和欧盟的相关法律制度，提出适应AI的统一法律框架。", "motivation": "随着人工智能与知识产权的快速融合，现有法律法规存在不足，特别是在贸易秘密保护、发明者认定标准和版权方面，需要通过立法调整来应对这些挑战。", "method": "本文采用理论研究和比较分析的方法，审视不同国家和地区的法律规定、司法先例和政策工具，并提出适应人工智能发展需求的新框架。", "result": "初步发现表明印度的合同法对贸易秘密保护不足；专利法案第3（k）条限制了AI发明的可专利性；版权在作者认定方面存在差异。研究建议制定统一的法律体系以更好地适应AI技术的发展。", "conclusion": "研究成果强调，重新调整知识产权法可以促进全球范围内的技术创新和公平竞争，并为印度国家人工智能战略提供指导和支持。"}}
{"id": "2601.17890", "pdf": "https://arxiv.org/pdf/2601.17890", "abs": "https://arxiv.org/abs/2601.17890", "authors": ["Ailin Liu", "Francesco Chiossi", "Felix Henninger", "Lisa Bondo Andersen", "Tobias Wistuba", "Sonja Greven", "Frauke Kreuter", "Fiona Draxler"], "title": "Physiological and Behavioral Modeling of Stress and Cognitive Load in Web-Based Question Answering", "categories": ["cs.HC"], "comment": null, "summary": "Time pressure and question difficulty can trigger stress and cognitive overload in web-based surveys, compromising data quality and user experience. Most stress detection methods are based on low-resolution self-reports, which are poorly suited for capturing fast, moment-to-moment changes during short online tasks. Addressing this gap, we conducted a 2x2 within-subjects study (N = 29), manipulating question difficulty and time pressure in a web-based multiple-choice task. Participants completed general knowledge and cognitive questions while we collected multimodal data: mouse dynamics, eye tracking, electrocardiogram, and electrodermal activity. Using condition-based and self-reported labels, we used statistical and machine learning models to model stress and question difficulty. Our results show distinct physiological and behavioral patterns within very short timeframes. This work demonstrates the feasibility of rapidly detecting cognitive-affective states in digital environments, paving the way for more adaptive, ethical, and user-aware survey interfaces.", "AI": {"tldr": "研究通过收集多模态数据，探究了在线问答任务中时间压力和问题难度对用户心理生理状态的影响。", "motivation": "大多数压力检测方法依赖于低分辨率的自我报告，不适合捕捉快速变化的情绪。本研究旨在改进这一现状，更好地理解用户的实时情感体验。", "method": "通过2x2内部对照实验（N=29），在时间压力和问题难度之间进行操作性控制，收集了眼动、鼠标轨迹、心电图等多模态数据，并利用统计模型和机器学习算法分析了用户的心理生理状态。", "result": "结果显示，在极短的时间内存在明显且独特的行为和生理模式，表明检测认知情绪状态的可行性。", "conclusion": "研究证明在数字环境中快速检测认知情感状态是可能的，为构建更适应用户、伦理和技术兼容性的在线调查界面提供了可能性。"}}
{"id": "2601.17887", "pdf": "https://arxiv.org/pdf/2601.17887", "abs": "https://arxiv.org/abs/2601.17887", "authors": ["Jiahe Guo", "Xiangran Guo", "Yulin Hu", "Zimo Long", "Xingyu Sui", "Xuda Zhi", "Yongbo Huang", "Hao He", "Weixiang Zhao", "Yanyan Zhao", "Bing Qin"], "title": "When Personalization Legitimizes Risks: Uncovering Safety Vulnerabilities in Personalized Dialogue Agents", "categories": ["cs.AI"], "comment": null, "summary": "Long-term memory enables large language model (LLM) agents to support personalized and sustained interactions. However, most work on personalized agents prioritizes utility and user experience, treating memory as a neutral component and largely overlooking its safety implications. In this paper, we reveal intent legitimation, a previously underexplored safety failure in personalized agents, where benign personal memories bias intent inference and cause models to legitimize inherently harmful queries. To study this phenomenon, we introduce PS-Bench, a benchmark designed to identify and quantify intent legitimation in personalized interactions. Across multiple memory-augmented agent frameworks and base LLMs, personalization increases attack success rates by 15.8%-243.7% relative to stateless baselines. We further provide mechanistic evidence for intent legitimation from internal representations space, and propose a lightweight detection-reflection method that effectively reduces safety degradation. Overall, our work provides the first systematic exploration and evaluation of intent legitimation as a safety failure mode that naturally arises from benign, real-world personalization, highlighting the importance of assessing safety under long-term personal context. WARNING: This paper may contain harmful content.", "AI": {"tldr": "揭示个性化对话代理中意图合法化的安全漏洞，并提出一种减轻此问题的方法。", "motivation": "大多数关于个性化代理的研究侧重于实用性和用户体验，而忽略了记忆对安全性的潜在影响。本文旨在探索和评估意图为个人化交互中的安全风险模式。", "method": "引入PS-Bench基准来识别并量化意图合法化的现象，并通过内部表示空间提供机理证据。同时提出一种轻量级的检测-反思方法以减少安全损害。", "result": "个性化增加了攻击成功率15.8%-243.7%，相对无状态基线而言。所提出的检测-反射方法有效降低了这种风险。", "conclusion": "研究表明，意图合法化是由于长期个人背景而自然产生的安全问题，强调了在长期上下文中评估安全性的重要性。"}}
{"id": "2601.17885", "pdf": "https://arxiv.org/pdf/2601.17885", "abs": "https://arxiv.org/abs/2601.17885", "authors": ["Qingyu Fan", "Zhaoxiang Li", "Yi Lu", "Wang Chen", "Qiu Shen", "Xiao-xiao Long", "Yinghao Cai", "Tao Lu", "Shuo Wang", "Xun Cao"], "title": "PEAfowl: Perception-Enhanced Multi-View Vision-Language-Action for Bimanual Manipulation", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Bimanual manipulation in cluttered scenes requires policies that remain stable under occlusions, viewpoint and scene variations. Existing vision-language-action models often fail to generalize because (i) multi-view features are fused via view-agnostic token concatenation, yielding weak 3D-consistent spatial understanding, and (ii) language is injected as global conditioning, resulting in coarse instruction grounding. In this paper, we introduce PEAfowl, a perception-enhanced multi-view VLA policy for bimanual manipulation. For spatial reasoning, PEAfowl predicts per-token depth distributions, performs differentiable 3D lifting, and aggregates local cross-view neighbors to form geometrically grounded, cross-view consistent representations. For instruction grounding, we propose to replace global conditioning with a Perceiver-style text-aware readout over frozen CLIP visual features, enabling iterative evidence accumulation. To overcome noisy and incomplete commodity depth without adding inference overhead, we apply training-only depth distillation from a pretrained depth teacher to supervise the depth-distribution head, providing perception front-end with geometry-aware priors. On RoboTwin 2.0 under domain-randomized setting, PEAfowl improves the strongest baseline by 23.0 pp in success rate, and real-robot experiments further demonstrate reliable sim-to-real transfer and consistent improvements from depth distillation. Project website: https://peafowlvla.github.io/.", "AI": {"tldr": "提出了一种增强感知的多视角视觉语言行动策略（PEAfowl），用于双臂操作。", "motivation": "现有的视觉-语言-动作模型在处理遮挡、视点和场景变化时，由于多视角特征融合弱以及指令匹配粗糙等问题，无法很好地泛化。", "method": "通过预测每个标记的深度分布进行空间推理，并利用可微分3D提升技术结合局部跨视角邻居形成几何基础且一致的表示。采用Perceiver风格的文本感知读出替代全局条件控制，实现迭代证据积累。应用训练期间的深度蒸馏来监督深度分布头部。", "result": "在RoboTwin 2.0上，PEAfowl将最强基线的成功率提高了23.0个百分点，并通过真实的机器人实验验证了从仿真到现实的有效转移以及深度蒸馏的一致改进。", "conclusion": "提出的PEAfowl策略能够增强感知能力，有效改善双臂操作任务中的遮挡问题和视点变化，具有良好的泛化性能。"}}
{"id": "2601.17883", "pdf": "https://arxiv.org/pdf/2601.17883", "abs": "https://arxiv.org/abs/2601.17883", "authors": ["Dingkun Liu", "Yuheng Chen", "Zhu Chen", "Zhenyao Cui", "Yaozhi Wen", "Jiayu An", "Jingwei Luo", "Dongrui Wu"], "title": "EEG Foundation Models: Progresses, Benchmarking, and Open Problems", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Electroencephalography (EEG) foundation models have recently emerged as a promising paradigm for brain-computer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper fills this gap. We first review 50 representative models and organize their design choices into a unified taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under a leave-one-subject-out protocol and rapid calibration under a within-subject few-shot setting. We further compare full-parameter fine-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufficient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices.", "AI": {"tldr": "该论文对50个代表性EEG基础模型进行综述，并评估了12个开源的EEG基础模型和竞争性的专业基线模型，旨在填补现有方法比较不足的空白。", "motivation": "由于预训练目标、预处理选择和下游评估协议不一致，目前缺乏对现有EEG基础模型的公平且全面的比较。论文希望通过综述和评测来解决这个问题。", "method": "首先回顾了50个代表性模型并将其设计选择组织成一个统一的分类框架；然后在13个EEG数据集上评估了12种开源的基础模型及专业基线模型，考虑跨被试泛化与快速校准。使用全参数微调和线性探针来评估预训练表示的转移性能，并研究模型规模与下游表现之间的关系。", "result": "结果显示：1) 线性探针经常不足；2) 从头开始训练的专业模型在许多任务中仍然具有竞争力；3) 在当前数据集和训练实践中，更大的基础模型不一定能带来更好的泛化性能。", "conclusion": "该研究填补了EEG基础模型评估的空白，并强调了线性探针与全参数微调的区别，同时指出了现有模型规模下跨被试泛化的局限性。"}}
{"id": "2601.17880", "pdf": "https://arxiv.org/pdf/2601.17880", "abs": "https://arxiv.org/abs/2601.17880", "authors": ["Muhammad Umar Salman", "Mohammad Areeb Qazi", "Mohammed Talha Alam"], "title": "Quran-MD: A Fine-Grained Multilingual Multimodal Dataset of the Quran", "categories": ["cs.CV"], "comment": "6 pages, 2 tables and 2 figures", "summary": "We present Quran MD, a comprehensive multimodal dataset of the Quran that integrates textual, linguistic, and audio dimensions at the verse and word levels. For each verse (ayah), the dataset provides its original Arabic text, English translation, and phonetic transliteration. To capture the rich oral tradition of Quranic recitation, we include verse-level audio from 32 distinct reciters, reflecting diverse recitation styles and dialectical nuances. At the word level, each token is paired with its corresponding Arabic script, English translation, transliteration, and an aligned audio recording, allowing fine-grained analysis of pronunciation, phonology, and semantic context. This dataset supports various applications, including natural language processing, speech recognition, text-to-speech synthesis, linguistic analysis, and digital Islamic studies. Bridging text and audio modalities across multiple reciters, this dataset provides a unique resource to advance computational approaches to Quranic recitation and study. Beyond enabling tasks such as ASR, tajweed detection, and Quranic TTS, it lays the foundation for multimodal embeddings, semantic retrieval, style transfer, and personalized tutoring systems that can support both research and community applications. The dataset is available at https://huggingface.co/datasets/Buraaq/quran-audio-text-dataset", "AI": {"tldr": "该论文介绍了Quran-MD，这是一个集成了《古兰经》的文本、语言和音频维度的多模态数据集。", "motivation": "为了捕捉《古兰经》丰富的口语传统，并支持自然语言处理、语音识别、文字转语音合成等多种应用，本文提出了一个细粒度的多语种多模式的数据集Quran-MD。", "method": "该数据集为每个节（ayah）提供了原始阿拉伯文文本、英文翻译和音标转写。此外，在单词层面，每令牌都配对有其对应的阿拉伯文字本、英文翻译、转写以及与之对齐的音频记录。", "result": "通过桥接多个诵读者之间的文本和音频模式，该数据集为《古兰经》的计算方法提供了独特资源，并支持各种任务如ASR（自动语音识别）、Tajweed检测和文字转语音合成等。", "conclusion": "Quran-MD是一个独特的资源，旨在推进对《古兰经》诵读的研究以及数字化伊斯兰研究。"}}
{"id": "2601.17879", "pdf": "https://arxiv.org/pdf/2601.17879", "abs": "https://arxiv.org/abs/2601.17879", "authors": ["Yilong Xu", "Zhi Zheng", "Xiang Long", "Yujun Cai", "Yiwei Wang"], "title": "Self-Manager: Parallel Agent Loop for Long-form Deep Research", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Long-form deep research requires multi-faceted investigations over extended horizons to get a comprehensive report. When handling such complex tasks, existing agents manage context at the subtask level to overcome linear context accumulation and information loss. However, they still adhere to a single context window and sequential execution paradigm, which results in mutual interference and blocking behavior, restricting scalability and adaptability. To address this issue, this paper introduces Self-Manager, a parallel agent loop that enables asynchronous and concurrent execution. The main thread can create multiple subthreads, each with its own isolated context, and manage them iteratively through Thread Control Blocks, allowing for more focused and flexible parallel agent execution. To assess its effectiveness, we benchmark Self-Manager on DeepResearch Bench, where it consistently outperforms existing single-agent loop baselines across all metrics. Furthermore, we conduct extensive analytical experiments to demonstrate the necessity of Self-Manager's design choices, as well as its advantages in contextual capacity, efficiency, and generalization.", "AI": {"tldr": "介绍了一个名为Self-Manager的平行代理循环，用于解决长形式深度研究中的线性上下文累积和信息丢失问题。", "motivation": "现有代理在处理复杂任务时会遇到上下文积累和信息损失的问题，并且它们仍然依赖单一上下文窗口和顺序执行模式，这导致了互干扰和阻塞行为，限制了可扩展性和适应性。", "method": "引入了一种名为Self-Manager的平行代理循环机制，它允许异步并行执行。主线程可以创建多个子线程，每个子线程拥有自己的隔离上下文，并通过线程控制块进行迭代管理，从而实现更聚焦和灵活的并行代理执行。", "result": "在DeepResearch Bench上评估了Self-Manager的有效性，结果表明它比现有的单个代理循环基准在线下所有指标方面表现更好。此外还进行了广泛的分析实验以展示Self-Manager设计选择的重要性及其上下文容量、效率和泛化能力的优势。", "conclusion": "Self-Manager通过提供异步并行执行机制解决了现有代理在长形式深度研究中面临的挑战，提高了系统性能，适应性更强且具有更好的一般化能力。"}}
{"id": "2601.17877", "pdf": "https://arxiv.org/pdf/2601.17877", "abs": "https://arxiv.org/abs/2601.17877", "authors": ["Sahibpreet Singh"], "title": "Comparative Algorithmic Governance of Public Health Instruments across India, EU, US and LMICs", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "Chapter in \"Law and Medicine\" (Pacific Books International, 2025), pp. 409-423", "summary": "The study investigates the juridico-technological architecture of international public health instruments, focusing on their implementation across India, the European Union, the United States and low- and middle-income countries (LMICs), particularly in Sub-Saharan Africa. It addresses a research lacuna: the insufficient harmonisation between normative health law and algorithmic public health infrastructures in resource-constrained jurisdictions. The principal objective is to assess how artificial intelligence augments implementation of instruments grounded in IHR 2005 and the WHO FCTC while identifying doctrinal and infrastructural bottlenecks. Using comparative doctrinal analysis and legal-normative mapping, the study triangulates legislative instruments, WHO monitoring frameworks, AI systems including BlueDot, Aarogya Setu and EIOS, and compliance metrics. Preliminary results show that AI has improved early detection, surveillance precision and responsiveness in high-capacity jurisdictions, whereas LMICs face infrastructural deficits, data privacy gaps and fragmented legal scaffolding. The findings highlight the relevance of the EU Artificial Intelligence Act and GDPR as regulatory prototypes for health-oriented algorithmic governance and contrast them with embryonic AI integration and limited internet penetration in many LMICs. The study argues for embedding AI within a rights-compliant, supranationally coordinated regulatory framework to secure equitable health outcomes and stronger compliance. It proposes a model for algorithmic treaty-making inspired by FCTC architecture and calls for WHO-led compliance mechanisms modelled on the WTO Dispute Settlement Body to enhance pandemic preparedness, surveillance equity and transnational governance resilience.", "AI": {"tldr": "研究比较了印度、欧盟、美国和低收入及中等收入国家（LMICs）在公共卫生仪器中的算法治理架构。", "motivation": "探讨国际公共卫生工具实施过程中的法律和技术框架的不协调，尤其是在资源有限的司法管辖区。", "method": "采用比较法理分析和法律规范图谱方法，研究立法文件、世卫组织监督框架及各类AI系统，并评估合规标准。", "result": "结果显示，在高容量地区，人工智能提高了早期检测和监测准确性；而在低收入国家则面临基础设施不足、数据隐私差距和零散的法律体系等问题。", "conclusion": "建议在尊重人权的基础上制定一个跨国协调的监管框架以实现健康公平并提升合规性。呼吁世界卫生组织主导建立类似世贸组织争端解决机制来提高流行病准备能力和监测平等性。"}}
{"id": "2601.17868", "pdf": "https://arxiv.org/pdf/2601.17868", "abs": "https://arxiv.org/abs/2601.17868", "authors": ["Zhihao He", "Tieyuan Chen", "Kangyu Wang", "Ziran Qin", "Yang Shao", "Chaofan Gan", "Shijie Li", "Zuxuan Wu", "Weiyao Lin"], "title": "VidLaDA: Bidirectional Diffusion Large Language Models for Efficient Video Understanding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Standard Autoregressive Video LLMs inevitably suffer from causal masking biases that hinder global spatiotemporal modeling, leading to suboptimal understanding efficiency. We propose VidLaDA, a Video LLM based on Diffusion Language Model utilizing bidirectional attention to capture bidirectional dependencies. To further tackle the inference bottleneck of diffusion decoding on massive video tokens, we introduce MARS-Cache. This framework accelerates inference by combining asynchronous visual cache refreshing with frame-wise chunk attention, effectively pruning redundancy while preserving global connectivity via anchor tokens. Extensive experiments show VidLaDA outperforms diffusion baselines and rivals state-of-the-art autoregressive models (e.g., Qwen2.5-VL and LLaVA-Video), with MARS-Cache delivering over 12x speedup without compromising reasoning accuracy. Code and checkpoints are open-sourced at https://github.com/ziHoHe/VidLaDA.", "AI": {"tldr": "该论文提出了VidLaDA，一种基于双向注意力的视频理解大语言模型，并引入MARS-Cache框架来加速推理。", "motivation": "传统的自回归视频LLMs由于因果遮蔽偏见导致全局时空建模能力受限。因此需要一个能够捕捉双向依赖性并提高效率的方法。", "method": "VidLaDA基于扩散语言模型，利用双向注意力机制捕捉全局时空信息，并通过MARS-Cache框架加速推理过程。", "result": "实验结果表明，VidLaDA在理解效率上优于其他扩散基线模型，并能与最先进的自回归模型（如Qwen2.5-VL和LLaVA-Video）相媲美，同时MARS-Cache提供了超过12倍的加速而不会影响推理准确性。", "conclusion": "VidLaDA通过引入双向注意力机制解决了因果遮蔽偏见问题，并且结合MARS-Cache框架显著提高了模型的速度。"}}
{"id": "2601.17866", "pdf": "https://arxiv.org/pdf/2601.17866", "abs": "https://arxiv.org/abs/2601.17866", "authors": ["Yoonwoo Jeong", "Cheng Sun", "Yu-Chiang Frank Wang", "Minsu Cho", "Jaesung Choe"], "title": "MV-SAM: Multi-view Promptable Segmentation using Pointmap Guidance", "categories": ["cs.CV"], "comment": "Project page, https://jaesung-choe.github.io/mv_sam/index.html", "summary": "Promptable segmentation has emerged as a powerful paradigm in computer vision, enabling users to guide models in parsing complex scenes with prompts such as clicks, boxes, or textual cues. Recent advances, exemplified by the Segment Anything Model (SAM), have extended this paradigm to videos and multi-view images. However, the lack of 3D awareness often leads to inconsistent results, necessitating costly per-scene optimization to enforce 3D consistency. In this work, we introduce MV-SAM, a framework for multi-view segmentation that achieves 3D consistency using pointmaps -- 3D points reconstructed from unposed images by recent visual geometry models. Leveraging the pixel-point one-to-one correspondence of pointmaps, MV-SAM lifts images and prompts into 3D space, eliminating the need for explicit 3D networks or annotated 3D data. Specifically, MV-SAM extends SAM by lifting image embeddings from its pretrained encoder into 3D point embeddings, which are decoded by a transformer using cross-attention with 3D prompt embeddings. This design aligns 2D interactions with 3D geometry, enabling the model to implicitly learn consistent masks across views through 3D positional embeddings. Trained on the SA-1B dataset, our method generalizes well across domains, outperforming SAM2-Video and achieving comparable performance with per-scene optimization baselines on NVOS, SPIn-NeRF, ScanNet++, uCo3D, and DL3DV benchmarks. Code will be released.", "AI": {"tldr": "本文介绍了一种名为MV-SAM的多视图分割框架，它使用点地图指导模型在多个视角下进行一致性的三维分割。", "motivation": "现有的可引导分割方法缺乏对三维空间的理解，在处理多视角图像时会导致一致性问题。需要通过昂贵的场景优化来解决这些问题。", "method": "MV-SAM利用点图将二维图像和提示信息提升到三维空间，从而在没有明确使用三维网络或标注数据的情况下实现了三维一致性的分割结果。", "result": "实验表明，MV-SAM不仅在多个基准测试中表现优异，并且超过了SAM2-Video，与基于场景优化的基线方法性能相当。", "conclusion": "MV-SAM通过点地图指导实现了一种有效的一致性多视角分割方法。该技术可以广泛应用于不同领域并提供卓越的性能。"}}
{"id": "2601.17862", "pdf": "https://arxiv.org/pdf/2601.17862", "abs": "https://arxiv.org/abs/2601.17862", "authors": ["Jingsong Xia", "Siqi Wang"], "title": "Domain Generalization with Quantum Enhancement for Medical Image Classification: A Lightweight Approach for Cross-Center Deployment", "categories": ["cs.CV"], "comment": null, "summary": "Medical image artificial intelligence models often achieve strong performance in single-center or single-device settings, yet their effectiveness frequently deteriorates in real-world cross-center deployment due to domain shift, limiting clinical generalizability. To address this challenge, we propose a lightweight domain generalization framework with quantum-enhanced collaborative learning, enabling robust generalization to unseen target domains without relying on real multi-center labeled data. Specifically, a MobileNetV2-based domain-invariant encoder is constructed and optimized through three key components: (1) multi-domain imaging shift simulation using brightness, contrast, sharpening, and noise perturbations to emulate heterogeneous acquisition conditions; (2) domain-adversarial training with gradient reversal to suppress domain-discriminative features; and (3) a lightweight quantum feature enhancement layer that applies parameterized quantum circuits for nonlinear feature mapping and entanglement modeling. In addition, a test-time adaptation strategy is employed during inference to further alleviate distribution shifts. Experiments on simulated multi-center medical imaging datasets demonstrate that the proposed method significantly outperforms baseline models without domain generalization or quantum enhancement on unseen domains, achieving reduced domain-specific performance variance and improved AUC and sensitivity. These results highlight the clinical potential of quantum-enhanced domain generalization under constrained computational resources and provide a feasible paradigm for hybrid quantum--classical medical imaging systems.", "AI": {"tldr": "提出了一个轻量级的量子增强领域泛化框架，用于跨中心部署医疗图像分类。", "motivation": "为了克服单中心或单一设备环境下训练的人工智能模型在实际跨中心部署中性能下降的问题，研究提出了一种新的方法来解决领域漂移带来的临床适用性限制。", "method": "构建了一个基于MobileNetV2的域不变编码器，并通过三个关键组件进行优化：模拟多领域的成像偏移；使用对抗性训练压制领域区分特征；应用参数化量子电路实现非线性特征映射和纠缠建模。此外，在推理时采用了测试时间自适应策略。", "result": "实验结果显示，提出的模型在未见过的域上显著优于没有领域泛化或量子增强的基线模型，实现了减少领域的性能差异和提高了AUC及敏感度。", "conclusion": "结果展示了量子增强领域泛化的临床潜力，并为混合量子-经典医疗成像系统提供了可行范例。"}}
{"id": "2601.17858", "pdf": "https://arxiv.org/pdf/2601.17858", "abs": "https://arxiv.org/abs/2601.17858", "authors": ["Jiapeng Wang", "Changxin Tian", "Kunlong Chen", "Ziqi Liu", "Jiaxin Mao", "Wayne Xin Zhao", "Zhiqiang Zhang", "Jun Zhou"], "title": "MergeMix: Optimizing Mid-Training Data Mixtures via Learnable Model Merging", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Optimizing data mixtures is essential for unlocking the full potential of large language models (LLMs), yet identifying the optimal composition remains computationally prohibitive due to reliance on heuristic trials or expensive proxy training. To address this, we introduce \\textbf{MergeMix}, a novel approach that efficiently determines optimal data mixing ratios by repurposing model merging weights as a high-fidelity, low-cost performance proxy. By training domain-specific experts on minimal tokens and optimizing their merging weights against downstream benchmarks, MergeMix effectively optimizes the performance of data mixtures without incurring the cost of full-scale training. Extensive experiments on models with 8B and 16B parameters validate that MergeMix achieves performance comparable to or surpassing exhaustive manual tuning while drastically reducing search costs. Furthermore, MergeMix exhibits high rank consistency (Spearman $ρ> 0.9$) and strong cross-scale transferability, offering a scalable, automated solution for data mixture optimization.", "AI": {"tldr": "通过模型合并权重作为性能代理，优化数据混合比例。", "motivation": "识别最优的数据混合比例计算复杂度高，该方法旨在降低搜索成本并提高数据混合效果。", "method": "引入MergeMix，利用领域特定专家的训练和优化合并权重以最小化token使用量，并与下游基准进行对比。", "result": "实验结果表明，在8B和16B参数模型上，性能可媲美或超越手动调整，且搜索成本显著降低。具有高秩一致性（Spearman ρ>0.9）和跨规模传输能力。", "conclusion": "MergeMix提供了一种高效、自动化的数据混合优化解决方案"}}
{"id": "2601.17857", "pdf": "https://arxiv.org/pdf/2601.17857", "abs": "https://arxiv.org/abs/2601.17857", "authors": ["Lan Yang", "Minghan Yang", "Ke Li", "Honggang Zhang", "Kaiyue Pang", "Yi-Zhe Song"], "title": "SynMind: Reducing Semantic Hallucination in fMRI-Based Image Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in fMRI-based image reconstruction have achieved remarkable photo-realistic fidelity. Yet, a persistent limitation remains: while reconstructed images often appear naturalistic and holistically similar to the target stimuli, they frequently suffer from severe semantic misalignment -- salient objects are often replaced or hallucinated despite high visual quality. In this work, we address this limitation by rethinking the role of explicit semantic interpretation in fMRI decoding. We argue that existing methods rely too heavily on entangled visual embeddings which prioritize low-level appearance cues -- such as texture and global gist -- over explicit semantic identity. To overcome this, we parse fMRI signals into rich, sentence-level semantic descriptions that mirror the hierarchical and compositional nature of human visual understanding. We achieve this by leveraging grounded VLMs to generate synthetic, human-like, multi-granularity textual representations that capture object identities and spatial organization. Built upon this foundation, we propose SynMind, a framework that integrates these explicit semantic encodings with visual priors to condition a pretrained diffusion model. Extensive experiments demonstrate that SynMind outperforms state-of-the-art methods across most quantitative metrics. Notably, by offloading semantic reasoning to our text-alignment module, SynMind surpasses competing methods based on SDXL while using the much smaller Stable Diffusion 1.4 and a single consumer GPU. Large-scale human evaluations further confirm that SynMind produces reconstructions more consistent with human visual perception. Neurovisualization analyses reveal that SynMind engages broader and more semantically relevant brain regions, mitigating the over-reliance on high-level visual areas.", "AI": {"tldr": "本文提出了一种新框架SynMind，用于减少基于fMRI的图像重建中的语义幻觉。", "motivation": "当前基于fMRI的图像重构技术虽然在视觉质量上取得了显著进展，但仍存在严重的语义错位问题。为了解决这个问题，作者提出了利用丰富的语义描述来指导图像重建的新方法。", "method": "通过解析fMRI信号生成详细的语义描述，并结合文本对齐模块和预训练的扩散模型，该框架能够更好地捕捉图像中的对象身份和空间组织。", "result": "实验结果表明，SynMind在大多数定量指标上优于现有的最佳方法。此外，大规模的人类评估确认其重建更加符合人类视觉感知。", "conclusion": "本文展示了通过结合语义描述和视觉先验条件化预训练模型可以显著提高基于fMRI的图像重构的质量，并减少幻觉现象的发生。"}}
{"id": "2601.17846", "pdf": "https://arxiv.org/pdf/2601.17846", "abs": "https://arxiv.org/abs/2601.17846", "authors": ["Peinuan Qin", "Chi-Lan Yang", "Nattapat Boonprakong", "Jingzhu Chen", "Yugin Tan", "Yi-Chieh Lee"], "title": "AI Personalization Paradox: Personalized AI Increases Superficial Engagement in Reading while Undermines Autonomy and Ownership in Writing", "categories": ["cs.HC"], "comment": "This paper has been accepted for publication at ACM CHI 2026", "summary": "AI-assisted writing raises concerns about autonomy and ownership when benefiting writers. Personalization has been proposed as an effective solution while also risking writers' reliance on AI and behavior shifting. For better personalization design, existing studies rely on interaction and information solely within the writing phase; however, few studies have examined how reading behaviors can inform personalized writing. This study investigates the effects of integrating reading highlights for personalization on AI-assisted writing. A between-subjects study with 46 participants revealed that the personalization condition encouraged participants to produce more highlights. However, highlighting unexpectedly shifted from a sense-making strategy to an instrumental act of \"feeding the AI,\" leading to significant reliance on AI and declines in writers' sense of autonomy, ownership, and self-credit. These findings indicate personalization risks in AI-assisted writing, emphasize the importance of personalization strategies, and provide design implications.", "AI": {"tldr": "研究探讨了在AI辅助写作中整合阅读高亮个性化设计的效果。", "motivation": "现有研究主要关注写作阶段内的交互和个人信息，而鲜有考察阅读行为如何影响个性化的写作。该研究旨在填补这一空白，并探究个性化对作者自主性和所有权的影响。", "method": "采用组间实验设计，招募46名参与者评估整合阅读高亮的个性化对AI辅助写作的影响。", "result": "结果显示，在个性化条件下，参与者的高亮行为增加了，但这种行为从理解策略转变为“喂养AI”的工具性行动，导致了更多依赖于AI的行为以及作者自主性和所有权感的下降。", "conclusion": "研究揭示了AI辅助写作中的个性化设计所存在的风险，并强调了合理使用个人化策略的重要性。"}}
{"id": "2601.17845", "pdf": "https://arxiv.org/pdf/2601.17845", "abs": "https://arxiv.org/abs/2601.17845", "authors": ["Killian Davitt", "Dan Ristea", "Steven J. Murdoch"], "title": "Are we collaborative yet? A Usability Perspective on Mixnet Latency for Real-Time Applications", "categories": ["cs.HC"], "comment": null, "summary": "Mixnet networks deliberately induce additional latency to communications to provide anonymity. Recent developments have allowed mixnets to reduce their latency from hours to seconds while maintaining the same level of anonymity. As a result, real-time communications are now possible on mixnets. There has been limited research on how users tolerate different levels of delay, and it is unclear what latency levels mixnet operators should choose. Previous studies about latency do not apply to these 'mid-latency' mixnet scenarios. Our paper contributes the first measurement of users' tolerance to real-time applications under mixnet delay. We design a text-based collaborative quiz system to test user response to latency where participants complete a set of question tasks in collaboration with a simulated second user. Different levels of latency are added, analogous to a modern mixnet system. We show that average delay parameters of 1s and 4s maintain usability, a mean delay of 7s shows some difficulty and a mean delay of 10s is detrimental to user experience. Using these delay parameters, mixnet operators can ensure that most types of real-time communication applications are usable. Mixnets thus can balance usability and anonymity without compromising either.", "AI": {"tldr": "本文通过设计一种基于文本的协作答题系统来测试用户对延迟的容忍度，以确定混合网络在保持匿名性的同时如何确保实时通信应用程序的可用性。", "motivation": "近年来，混合网络已将延迟从小时缩短到秒，同时维持相同的匿名水平。目前尚不清楚操作员应选择何种延迟参数，因为关于延迟的研究并不适用于这些'中等延迟'的混合网络场景。", "method": "设计了一个基于文本的合作答题系统来测试用户对不同延迟级别的反应，参与者在模拟第二用户的协作下完成一系列问题任务，并加入与现代混合网络系统对应的延迟级别。", "result": "平均延迟参数为1秒和4秒时保持可用性；平均延迟7秒显示一些困难；而平均延迟10秒则损害用户体验。使用这些延迟参数，混合网络操作员可以确保大多数实时通信应用的可用性。", "conclusion": "本文研究表明，通过选择适当的延迟参数，混合网络可以在不牺牲匿名性和可用性的前提下平衡两者之间的关系"}}
