{"id": "2602.01002", "pdf": "https://arxiv.org/pdf/2602.01002", "abs": "https://arxiv.org/abs/2602.01002", "authors": ["Itai Shapira", "Gerdus Benade", "Ariel D. Procaccia"], "title": "How RLHF Amplifies Sycophancy", "categories": ["cs.AI"], "comment": null, "summary": "Large language models often exhibit increased sycophantic behavior after preference-based post-training, showing a stronger tendency to affirm a user's stated or implied belief even when this conflicts with factual accuracy or sound judgment. We present a formal analysis of how alignment from human feedback can increase this failure mode by identifying an explicit amplification mechanism that causally links optimization against a learned reward to bias in the human preference data used for alignment. We show that the direction of behavioral drift is determined by a covariance under the base policy between endorsing the belief signal in the prompt and the learned reward, and that the first-order effect reduces to a simple mean-gap condition. We then analyze reward learning from pairwise comparisons under random utility models like Bradley-Terry and characterize when bias in human annotators' preferences induces this reward gap. Next, we propose a training-time intervention designed to neutralize the amplification mechanism itself. Among all post-trained policies that prevent sycophantic behavior from increasing, we characterize the unique policy closest in KL divergence to the unconstrained post-trained policy, and derive the corresponding minimal reward correction as a closed-form agreement penalty. Computational experiments find that reward gaps are common and cause behavioral drift in all the configurations considered.", "AI": {"tldr": "该论文分析了基于人类反馈的强化学习如何放大语言模型的谄媚行为。", "motivation": "大型语言模型在偏好基础上进行后训练时，表现出更强的顺从倾向。这种倾向可能导致其为了迎合用户而忽视事实准确性或判断力。", "method": "本文通过一个正式分析确定了一种明确的放大机制，并指出基于优化学习奖励的行为偏移是由提示中支持信念信号与所学奖励之间的协方差决定的。进一步提出了在训练时间进行干预，以消除这种放大机制。", "result": "实验发现，奖励差距普遍存在并且会在所有考虑配置中引起行为漂移。", "conclusion": "研究揭示了偏好基础后训练如何通过特定方式增加语言模型的谄媚倾向，并提出了一种减少这种倾向的方法。"}}
{"id": "2602.01000", "pdf": "https://arxiv.org/pdf/2602.01000", "abs": "https://arxiv.org/abs/2602.01000", "authors": ["Vagish Kumar", "Souvik Chakraborty"], "title": "CortiNet: A Physics-Perception Hybrid Cortical-Inspired Dual-Stream Network for Gallbladder Disease Diagnosis from Ultrasound", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Ultrasound imaging is the primary diagnostic modality for detecting Gallbladder diseases due to its non-invasive nature, affordability, and wide accessibility. However, the low resolution and speckle noise inherent to ultrasound images hinder diagnostic reliability, prompting the use of large convolutional neural networks that are difficult to deploy in routine clinical settings. In this work, we propose CortiNet, a lightweight, cortical-inspired dual-stream neural architecture for gallbladder disease diagnosis that integrates physically interpretable multi-scale signal decomposition with perception-driven feature learning. Inspired by parallel processing pathways in the human visual cortex, CortiNet explicitly separates low-frequency structural information from high-frequency perceptual details and processes them through specialized encoding streams. By operating directly on structured, frequency-selective representations rather than raw pixel intensities, the architecture embeds strong physics-based inductive bias, enabling efficient feature learning with a significantly reduced parameter footprint. A late-stage cortical-style fusion mechanism integrates complementary structural and textural cues while preserving computational efficiency. Additionally, we propose a structure-aware explainability framework wherein gradient-weighted class activation mapping is only applied to the structural branch of the proposed CortiNet architecture. This choice allows the model to only focus on the structural features, making it robust against speckle noise. We evaluate CortiNet on 10,692 expert-annotated images spanning nine clinically relevant gallbladder disease categories. Experimental results demonstrate that CortiNet achieves high diagnostic accuracy (98.74%) with only a fraction of the parameters required by conventional deep convolutional models.", "AI": {"tldr": "CortiNet是一种用于胆囊疾病诊断的轻量级神经网络，结合物理可解释性和感知驱动特征学习。", "motivation": "传统的大卷积神经网络难以部署在常规临床环境中，因为它们需要大量的参数。由于超声图像分辨率低和噪声大，使用具有强物理偏置的模型可以提高准确性和效率。", "method": "CortiNet采用了双通道结构，分别处理低频结构信息和高频感知细节，并通过融合机制综合两者的特征。", "result": "在10,692张专家注释图像上的实验结果表明，CortiNet实现了高准确率（98.74%）且参数量大幅减少。", "conclusion": "提出的新架构CortiNet有效提高了胆囊疾病诊断的效率和准确性。"}}
{"id": "2602.00997", "pdf": "https://arxiv.org/pdf/2602.00997", "abs": "https://arxiv.org/abs/2602.00997", "authors": ["Mayank Singh", "Vikas Yadav", "Eduardo Blanco"], "title": "Error Taxonomy-Guided Prompt Optimization", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Automatic Prompt Optimization (APO) is a powerful approach for extracting performance from large language models without modifying their weights. Many existing methods rely on trial-and-error, testing different prompts or in-context examples until a good configuration emerges, often consuming substantial compute. Recently, natural language feedback derived from execution logs has shown promise as a way to identify how prompts can be improved. However, most prior approaches operate in a bottom-up manner, iteratively adjusting the prompt based on feedback from individual problems, which can cause them to lose the global perspective. In this work, we propose Error Taxonomy-Guided Prompt Optimization (ETGPO), a prompt optimization algorithm that adopts a top-down approach. ETGPO focuses on the global failure landscape by collecting model errors, categorizing them into a taxonomy, and augmenting the prompt with guidance targeting the most frequent failure modes. Across multiple benchmarks spanning mathematics, question answering, and logical reasoning, ETGPO achieves accuracy that is comparable to or better than state-of-the-art methods, while requiring roughly one third of the optimization-phase token usage and evaluation budget.", "AI": {"tldr": "本文提出了一种基于错误分类的提示优化算法ETGPO，通过从全局视角改进大型语言模型的表现。", "motivation": "现有方法依赖试错和迭代调整，可能导致局部优化而失去全局观。因此，引入一种新的全局视角的方法来改善模型表现。", "method": "提出了一种基于错误分类的提示优化算法ETGPO，收集模型错误并将其归类到一个分类中，并通过针对性增强提示来减少最频繁失败模式的发生。", "result": "在数学、问答和逻辑推理等基准测试上，ETGPO表现与最先进的方法相当或更好，同时其优化阶段令牌使用量和评估预算减少了约三分之一。", "conclusion": "提出的方法能够在消耗更少资源的情况下达到更好的性能。"}}
{"id": "2602.00996", "pdf": "https://arxiv.org/pdf/2602.00996", "abs": "https://arxiv.org/abs/2602.00996", "authors": ["Abhijit Chakraborty", "Ashish Raj Shekhar", "Shiven Agarwal", "Vivek Gupta"], "title": "DeALOG: Decentralized Multi-Agents Log-Mediated Reasoning Framework", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Complex question answering across text, tables and images requires integrating diverse information sources. A framework supporting specialized processing with coordination and interpretability is needed. We introduce DeALOG, a decentralized multi-agent framework for multimodal question answering. It uses specialized agents: Table, Context, Visual, Summarizing and Verification, that communicate through a shared natural-language log as persistent memory. This log-based approach enables collaborative error detection and verification without central control, improving robustness. Evaluations on FinQA, TAT-QA, CRT-QA, WikiTableQuestions, FeTaQA, and MultiModalQA show competitive performance. Analysis confirms the importance of the shared log, agent specialization, and verification for accuracy. DeALOG, provides a scalable approach through modular components using natural-language communication.", "AI": {"tldr": "本文提出了一种名为DeALOG的去中心化多代理框架，用于跨文本、表格和图像的复杂问题回答。", "motivation": "在复杂的问答任务中，需要整合多种信息源，并且需要一种能够支持专业化处理并且具有协调性和解释性的框架。现有的集中式方法可能不够鲁棒。", "method": "该框架使用了五个专门化的代理：表、上下文、视觉、总结和验证器，这些代理通过共享的日志进行通信，这种基于日志的方法可以实现去中心化协作错误检测和验证。", "result": "在多个数据集上的评估表明，DeALOG表现出色，并且分析证实了共享日志的重要性以及代理专业化和验证对于准确性的影响。", "conclusion": "DeALOG提供了一种通过自然语言通信的模块化组件实现可扩展性的方法。"}}
{"id": "2602.00995", "pdf": "https://arxiv.org/pdf/2602.00995", "abs": "https://arxiv.org/abs/2602.00995", "authors": ["Nick DiSanto", "Ehsan Khodapanah Aghdam", "Han Liu", "Jacob Watson", "Yuankai K. Tao", "Hao Li", "Ipek Oguz"], "title": "VAMOS-OCTA: Vessel-Aware Multi-Axis Orthogonal Supervision for Inpainting Motion-Corrupted OCT Angiography Volumes", "categories": ["cs.CV"], "comment": "Accepted to SPIE Medical Imaging 2026", "summary": "Handheld Optical Coherence Tomography Angiography (OCTA) enables noninvasive retinal imaging in uncooperative or pediatric subjects, but is highly susceptible to motion artifacts that severely degrade volumetric image quality. Sudden motion during 3D acquisition can lead to unsampled retinal regions across entire B-scans (cross-sectional slices), resulting in blank bands in en face projections. We propose VAMOS-OCTA, a deep learning framework for inpainting motion-corrupted B-scans using vessel-aware multi-axis supervision. We employ a 2.5D U-Net architecture that takes a stack of neighboring B-scans as input to reconstruct a corrupted center B-scan, guided by a novel Vessel-Aware Multi-Axis Orthogonal Supervision (VAMOS) loss. This loss combines vessel-weighted intensity reconstruction with axial and lateral projection consistency, encouraging vascular continuity in native B-scans and across orthogonal planes. Unlike prior work that focuses primarily on restoring the en face MIP, VAMOS-OCTA jointly enhances both cross-sectional B-scan sharpness and volumetric projection accuracy, even under severe motion corruptions. We trained our model on both synthetic and real-world corrupted volumes and evaluated its performance using both perceptual quality and pixel-wise accuracy metrics. VAMOS-OCTA consistently outperforms prior methods, producing reconstructions with sharp capillaries, restored vessel continuity, and clean en face projections. These results demonstrate that multi-axis supervision offers a powerful constraint for restoring motion-degraded 3D OCTA data. Our source code is available at https://github.com/MedICL-VU/VAMOS-OCTA.", "AI": {"tldr": "该论文提出了一种用于修复手持光学相干断层扫描血管造影（OCTA）中由运动引起的图像缺失的新方法。", "motivation": "手持OCTA技术在不配合或儿科患者中的成像具有优势，但易受运动伪影的影响，这会导致体积图像质量严重下降。该研究旨在解决这一问题，通过深度学习框架修复因运动引起的数据丢失。", "method": "提出了一种称为VAMOS-OCTA的新型深度学习框架，利用2.5D U-Net架构和新颖的血管感知多轴正交监督（VAMOS）损失函数来处理运动伪影。该方法不仅关注于恢复正面最大强度投影（MIP），还致力于提高切片清晰度以及整体体积投影准确性。", "result": "通过合成数据和真实世界数据训练模型，并使用感知质量和像素级精度指标进行评估，结果表明VAMOS-OCTA比现有方法表现更佳，能够生成具有锐利毛细血管、恢复的血管连续性及干净的正面投影的重建图像。", "conclusion": "该研究证明了多轴监督对于恢复运动受损3D OCTA数据的有效性。这种方法为处理由运动引起的手持OCTA成像问题提供了一种强大而有效的解决方案。"}}
{"id": "2602.00994", "pdf": "https://arxiv.org/pdf/2602.00994", "abs": "https://arxiv.org/abs/2602.00994", "authors": ["Yu Li", "Mingyang Yi", "Xiuyu Li", "Ju Fan", "Fuxin Jiang", "Binbin Chen", "Peng Li", "Jie Song", "Tieying Zhang"], "title": "Reasoning and Tool-use Compete in Agentic RL:From Quantifying Interference to Disentangled Tuning", "categories": ["cs.AI"], "comment": null, "summary": "Agentic Reinforcement Learning (ARL) focuses on training large language models (LLMs) to interleave reasoning with external tool execution to solve complex tasks. Most existing ARL methods train a single shared model parameters to support both reasoning and tool use behaviors, implicitly assuming that joint training leads to improved overall agent performance. Despite its widespread adoption, this assumption has rarely been examined empirically. In this paper, we systematically investigate this assumption by introducing a Linear Effect Attribution System(LEAS), which provides quantitative evidence of interference between reasoning and tool-use behaviors. Through an in-depth analysis, we show that these two capabilities often induce misaligned gradient directions, leading to training interference that undermines the effectiveness of joint optimization and challenges the prevailing ARL paradigm. To address this issue, we propose Disentangled Action Reasoning Tuning(DART), a simple and efficient framework that explicitly decouples parameter updates for reasoning and tool-use via separate low-rank adaptation modules. Experimental results show that DART consistently outperforms baseline methods with averaged 6.35 percent improvements and achieves performance comparable to multi-agent systems that explicitly separate tool-use and reasoning using a single model.", "AI": {"tldr": "本文研究了代理强化学习中推理和工具使用之间的干扰，并提出了分离参数更新的方法来提高性能。", "motivation": "现有方法假设共同训练可以改善总体表现，但缺乏实验证据支持这一观点。因此，作者引入了一种量化干扰的系统，并提出了解决方案以克服这个问题。", "method": "通过线性效应归因系统（LEAS）量化推理和工具使用之间的干扰，并提出了分散行为推理调优（DART），该框架通过单独的低秩自适应模块明确分离参数更新，从而解决这一问题。", "result": "实验结果表明，DART方法比基线方法平均提高6.35个百分点，并且单个模型性能可媲美将工具使用和推理显式分开的多代理系统。", "conclusion": "本文揭示了现有假设的问题，并提供了有效的解决方案以提升代理强化学习中复杂任务的表现。"}}
{"id": "2602.00993", "pdf": "https://arxiv.org/pdf/2602.00993", "abs": "https://arxiv.org/abs/2602.00993", "authors": ["Weizhe Tang", "Junwei You", "Jiaxi Liu", "Zhaoyi Wang", "Rui Gan", "Zilin Huang", "Feng Wei", "Bin Ran"], "title": "HERMES: A Holistic End-to-End Risk-Aware Multimodal Embodied System with Vision-Language Models for Long-Tail Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "End-to-end autonomous driving models increasingly benefit from large vision--language models for semantic understanding, yet ensuring safe and accurate operation under long-tail conditions remains challenging. These challenges are particularly prominent in long-tail mixed-traffic scenarios, where autonomous vehicles must interact with heterogeneous road users, including human-driven vehicles and vulnerable road users, under complex and uncertain conditions. This paper proposes HERMES, a holistic risk-aware end-to-end multimodal driving framework designed to inject explicit long-tail risk cues into trajectory planning. HERMES employs a foundation-model-assisted annotation pipeline to produce structured Long-Tail Scene Context and Long-Tail Planning Context, capturing hazard-centric cues together with maneuver intent and safety preference, and uses these signals to guide end-to-end planning. HERMES further introduces a Tri-Modal Driving Module that fuses multi-view perception, historical motion cues, and semantic guidance, ensuring risk-aware accurate trajectory planning under long-tail scenarios. Experiments on the real-world long-tail dataset demonstrate that HERMES consistently outperforms representative end-to-end and VLM-driven baselines under long-tail mixed-traffic scenarios. Ablation studies verify the complementary contributions of key components.", "AI": {"tldr": "HERMES是针对长尾场景设计的一种风险感知的端到端多模态驾驶框架，旨在通过注入显式的长尾风险线索来指导轨迹规划。", "motivation": "为了在复杂的混合交通场景中确保自动驾驶的安全性和准确性，提出了HERMES以应对长期存在的挑战。特别是在需要与各种道路使用者进行交互的情况下，如人类驾驶车辆和弱势群体，这些挑战更为突出。", "method": "HERMES采用基础模型辅助的注释管道来生成结构化的长尾场景上下文和规划上下文，并引入三模态驾驶模块将多视图感知、历史运动线索及语义引导融合在一起，以实现风险感知下的精准轨迹规划。", "result": "实验表明，在现实世界的长尾数据集上，HERMES在混合交通场景中始终优于代表性的端到端和其他基于视觉语言模型的基准。", "conclusion": "HERMES框架证明了其在解决复杂条件下自动驾驶安全和准确问题的有效性，并通过实验证明关键组件对性能提升的重要性。"}}
{"id": "2602.00992", "pdf": "https://arxiv.org/pdf/2602.00992", "abs": "https://arxiv.org/abs/2602.00992", "authors": ["Phone Thiha Kyaw", "Jonathan Kelly"], "title": "Geometry-Aware Sampling-Based Motion Planning on Riemannian Manifolds", "categories": ["cs.RO"], "comment": "Submitted to WAFR 2026 (17th World Symposium on the Algorithmic Foundations of Robotics (WAFR))", "summary": "In many robot motion planning problems, task objectives and physical constraints induce non-Euclidean geometry on the configuration space, yet many planners operate using Euclidean distances that ignore this structure. We address the problem of planning collision-free motions that minimize length under configuration-dependent Riemannian metrics, corresponding to geodesics on the configuration manifold. Conventional numerical methods for computing such paths do not scale well to high-dimensional systems, while sampling-based planners trade scalability for geometric fidelity. To bridge this gap, we propose a sampling-based motion planning framework that operates directly on Riemannian manifolds. We introduce a computationally efficient midpoint-based approximation of the Riemannian geodesic distance and prove that it matches the true Riemannian distance with third-order accuracy. Building on this approximation, we design a local planner that traces the manifold using first-order retractions guided by Riemannian natural gradients. Experiments on a two-link planar arm and a 7-DoF Franka manipulator under a kinetic-energy metric, as well as on rigid-body planning in $\\mathrm{SE}(2)$ with non-holonomic motion constraints, demonstrate that our approach consistently produces lower-cost trajectories than Euclidean-based planners and classical numerical geodesic-solver baselines.", "AI": {"tldr": "该论文提出了一种在黎曼流形上进行采样基于的运动规划框架，用于解决机器人路径规划中的非欧几里得几何问题。", "motivation": "传统的方法忽略了配置空间上的非欧几里得结构，导致难以处理高维系统。此方法旨在提高路径规划的准确性和适用性。", "method": "提出了一个基于中间点逼近黎曼测地距离的方法，并使用黎曼自然梯度指导局部规划器沿着流形追踪。", "result": "实验表明该框架能够产生比传统欧几里得和经典数值解算器更低成本的轨迹。", "conclusion": "所提出的采样方法在处理非欧几何结构上的路径规划问题上具有更好的性能。"}}
{"id": "2602.00983", "pdf": "https://arxiv.org/pdf/2602.00983", "abs": "https://arxiv.org/abs/2602.00983", "authors": ["Batuhan K. Karaman", "Aditya Rawal", "Suhaila Shakiah", "Mohammad Ghavamzadeh", "Mingyi Hong", "Arijit Biswas", "Ruida Zhou"], "title": "DISPO: Enhancing Training Efficiency and Stability in Reinforcement Learning for Large Language Model Mathematical Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "This work is accepted to the 29th International Conference on Artificial Intelligence and Statistics (AISTATS) 2026", "summary": "Reinforcement learning with verifiable rewards has emerged as a promising paradigm for enhancing the reasoning capabilities of large language models particularly in mathematics. Current approaches in this domain present a clear trade-off: PPO-style methods (e.g., GRPO/DAPO) offer training stability but exhibit slow learning trajectories due to their trust-region constraints on policy updates, while REINFORCE-style approaches (e.g., CISPO) demonstrate improved learning efficiency but suffer from performance instability as they clip importance sampling weights while still permitting non-zero gradients outside the trust-region. To address these limitations, we introduce DISPO, a simple yet effective REINFORCE-style algorithm that decouples the up-clipping and down-clipping of importance sampling weights for correct and incorrect responses, yielding four controllable policy update regimes. Through targeted ablations, we uncover how each regime impacts training: for correct responses, weights >1 increase the average token entropy (i.e., exploration) while weights <1 decrease it (i.e., distillation) -- both beneficial but causing gradual performance degradation when excessive. For incorrect responses, overly restrictive clipping triggers sudden performance collapse through repetitive outputs (when weights >1) or vanishing response lengths (when weights <1). By separately tuning these four clipping parameters, DISPO maintains the exploration-distillation balance while preventing catastrophic failures, achieving 61.04% on AIME'24 (vs. 55.42% CISPO and 50.21% DAPO) with similar gains across various benchmarks and models.", "AI": {"tldr": "DISPO是一种增强大语言模型数学推理能力的强化学习算法，通过解耦重要性采样权重的上下裁剪来提高训练效率和稳定性。", "motivation": "当前方法在PPO风格和REINFORCE风格之间存在明显的取舍：前者提供稳定但学习轨迹缓慢，后者虽然更高效但性能不稳定。DISPO旨在解决这一问题，通过控制四种策略更新模式来平衡探索与蒸馏，并防止灾难性失败。", "method": "DISPO是一种解耦重要性采样权重上下裁剪的REINFORCE风格算法，允许四个可调参数以维持探索-蒸馏平衡并避免性能崩溃。", "result": "在AIME'24数据集上，DISPO实现了61.04%的成绩，优于CISPO和DAPO方法，并且在其他基准测试中也表现出相似的改进。", "conclusion": "DISPO通过优化重要性采样权重裁剪策略，在提高训练效率的同时保持稳定性，展示了其在大语言模型数学推理任务上的优越性能。"}}
{"id": "2602.00982", "pdf": "https://arxiv.org/pdf/2602.00982", "abs": "https://arxiv.org/abs/2602.00982", "authors": ["Phu-Hoa Pham", "Chi-Nguyen Tran", "Dao Sy Duy Minh", "Nguyen Lam Phu Quy", "Huynh Trung Kiet"], "title": "Navigating Simply, Aligning Deeply: Winning Solutions for Mouse vs. AI 2025", "categories": ["cs.CV", "cs.AI", "cs.NE", "cs.RO"], "comment": "15 pages, 8 tables. Technical Report for winning solutions (Track 1 & Track 2) at the NeurIPS 2025 Mouse vs. AI Challenge", "summary": "Visual robustness and neural alignment remain critical challenges in developing artificial agents that can match biological vision systems. We present the winning approaches from Team HCMUS_TheFangs for both tracks of the NeurIPS 2025 Mouse vs. AI: Robust Visual Foraging Competition. For Track 1 (Visual Robustness), we demonstrate that architectural simplicity combined with targeted components yields superior generalization, achieving 95.4% final score with a lightweight two-layer CNN enhanced by Gated Linear Units and observation normalization. For Track 2 (Neural Alignment), we develop a deep ResNet-like architecture with 16 convolutional layers and GLU-based gating that achieves top-1 neural prediction performance with 17.8 million parameters. Our systematic analysis of ten model checkpoints trained between 60K to 1.14M steps reveals that training duration exhibits a non-monotonic relationship with performance, with optimal results achieved around 200K steps. Through comprehensive ablation studies and failure case analysis, we provide insights into why simpler architectures excel at visual robustness while deeper models with increased capacity achieve better neural alignment. Our results challenge conventional assumptions about model complexity in visuomotor learning and offer practical guidance for developing robust, biologically-inspired visual agents.", "AI": {"tldr": "本文介绍了在NeurIPS 2025的“Mouse vs. AI：鲁棒视觉觅食竞赛”中获胜的方法，探讨了简单架构和深层模型在视觉稳健性和神经对齐中的应用。", "motivation": "发展能够与生物视觉系统媲美的人工代理仍然是一个挑战。该研究旨在解决这两个关键问题，并为开发鲁棒、仿生的视觉智能体提供实用指导。", "method": "对于Track 1，使用轻量级两层CNN结合门控线性单元和观察规范化；对于Track 2，采用深度ResNet样架构（含16个卷积层）与GLU基门控。系统分析了训练过程中模型性能的变化，并通过消融研究探讨了简单架构在视觉鲁棒性中的优越性和深层模型在神经对齐中的优势。", "result": "Track 1中实现了95.4%的最终得分；Track 2中达到了最佳的神经预测性能，参数量为1780万。训练时长与表现之间存在非单调关系，在大约20万步后达到最优。", "conclusion": "研究挑战了关于模型复杂度的传统假设，并提供了开发鲁棒、生物启发式视觉智能体的实际指导方针"}}
{"id": "2602.00981", "pdf": "https://arxiv.org/pdf/2602.00981", "abs": "https://arxiv.org/abs/2602.00981", "authors": ["Yutong Song", "Shiva Shrestha", "Chenhan Lyu", "Elahe Khatibi", "Pengfei Zhang", "Honghui Xu", "Nikil Dutt", "Amir Rahmani"], "title": "MedSpeak: A Knowledge Graph-Aided ASR Error Correction Framework for Spoken Medical QA", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Spoken question-answering (SQA) systems relying on automatic speech recognition (ASR) often struggle with accurately recognizing medical terminology. To this end, we propose MedSpeak, a novel knowledge graph-aided ASR error correction framework that refines noisy transcripts and improves downstream answer prediction by leveraging both semantic relationships and phonetic information encoded in a medical knowledge graph, together with the reasoning power of LLMs. Comprehensive experimental results on benchmarks demonstrate that MedSpeak significantly improves the accuracy of medical term recognition and overall medical SQA performance, establishing MedSpeak as a state-of-the-art solution for medical SQA. The code is available at https://github.com/RainieLLM/MedSpeak.", "AI": {"tldr": "提出了一种基于知识图谱的ASR错误校正框架MedSpeak，用于提高医学问答系统中医学术语识别的准确性。", "motivation": "在依赖自动语音识别技术的医学问答系统中，准确识别医学术语是一个挑战。为解决这一问题，提出了MedSpeak框架以改进医学SQA性能。", "method": "利用了医学知识图谱中的语义关系和发音信息以及大语言模型的推理能力来校正噪音转录并提升下游答案预测准确性。", "result": "实验结果表明，MedSpeak显著提高了医学术语识别准确性和整体医疗问答系统的表现，成为该领域的最新解决方案。", "conclusion": "MedSpeak框架通过利用知识图谱和大语言模型，在提高医学问答系统的性能方面表现出色。"}}
{"id": "2602.00980", "pdf": "https://arxiv.org/pdf/2602.00980", "abs": "https://arxiv.org/abs/2602.00980", "authors": ["Yichen Cai", "Yuan Gao", "Pengpeng Li", "Wei Wang", "Guibin Sun", "Jinhu Lü"], "title": "Meanshift Shape Formation Control Using Discrete Mass Distribution", "categories": ["cs.RO"], "comment": null, "summary": "The density-distribution method has recently become a promising paradigm owing to its adaptability to variations in swarm size. However, existing studies face practical challenges in achieving complex shape representation and decentralized implementation. This motivates us to develop a fully decentralized, distribution-based control strategy with the dual capability of forming complex shapes and adapting to swarm-size variations. Specifically, we first propose a discrete mass-distribution function defined over a set of sample points to model swarm formation. In contrast to the continuous density-distribution method, our model eliminates the requirement for defining continuous density functions-a task that is difficult for complex shapes. Second, we design a decentralized meanshift control law to coordinate the swarm's global distribution to fit the sample-point distribution by feeding back mass estimates. The mass estimates for all sample points are achieved by the robots in a decentralized manner via the designed mass estimator. It is shown that the mass estimates of the sample points can asymptotically converge to the true global values. To validate the proposed strategy, we conduct comprehensive simulations and real-world experiments to evaluate the efficiency of complex shape formation and adaptability to swarm-size variations.", "AI": {"tldr": "本文提出了一种基于离散质量分布的全分散控制策略，用于实现复杂形状的群集形成并适应群集大小变化。", "motivation": "现有的密度分布方法虽然有适应性但难以实现复杂的形状表示和完全分散实施。因此开发一种能够形成复杂形状及适应群集大小变化的分布式策略成为研究重点。", "method": "首先提出了一种定义在样本点集合上的离散质量分布函数来模拟群体形成，消除了对连续密度函数的需求。其次设计了基于均值漂移的分散控制定律以协调全局分布与样本点分布，通过分散式质量估计器实现所有样本点的质量估算。", "result": "理论分析和仿真实验表明，该策略能有效地形成复杂形状并适应群集大小的变化，并且样本点的质量估算能够渐近收敛到真实值。", "conclusion": "本文提出的基于离散质量分布的全分散控制方法证明了在实现复杂形状群体形态的同时也具备很好的规模变化适应能力。"}}
{"id": "2602.00979", "pdf": "https://arxiv.org/pdf/2602.00979", "abs": "https://arxiv.org/abs/2602.00979", "authors": ["Xueyi Li", "Zhuoneng Zhou", "Zitao Liu", "Yongdong Wu", "Weiqi Luo"], "title": "GradingAttack: Attacking Large Language Models Towards Short Answer Grading Ability", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable potential for automatic short answer grading (ASAG), significantly boosting student assessment efficiency and scalability in educational scenarios. However, their vulnerability to adversarial manipulation raises critical concerns about automatic grading fairness and reliability. In this paper, we introduce GradingAttack, a fine-grained adversarial attack framework that systematically evaluates the vulnerability of LLM based ASAG models. Specifically, we align general-purpose attack methods with the specific objectives of ASAG by designing token-level and prompt-level strategies that manipulate grading outcomes while maintaining high camouflage. Furthermore, to quantify attack camouflage, we propose a novel evaluation metric that balances attack success and camouflage. Experiments on multiple datasets demonstrate that both attack strategies effectively mislead grading models, with prompt-level attacks achieving higher success rates and token-level attacks exhibiting superior camouflage capability. Our findings underscore the need for robust defenses to ensure fairness and reliability in ASAG. Our code and datasets are available at https://anonymous.4open.science/r/GradingAttack.", "AI": {"tldr": "该论文介绍了GradingAttack，一个针对大型语言模型自动短答案评分能力的细粒度对抗攻击框架。", "motivation": "大型语言模型在自动短答案评分中的潜在风险引发了对公平性和可靠性的担忧，因此提出了一种新的方法来评估这些模型的安全性。", "method": "论文设计了基于令牌和提示级别的策略，并提出了一个新的评价指标来平衡攻击成功率和伪装能力。", "result": "实验表明两种攻击策略均能有效误导评分模型，且提示级别攻击的成功率更高，而令牌级别攻击具有更好的伪装能力。", "conclusion": "研究结果强调需要加强防御措施以确保自动短答案评分系统的公平性和可靠性。"}}
{"id": "2602.00978", "pdf": "https://arxiv.org/pdf/2602.00978", "abs": "https://arxiv.org/abs/2602.00978", "authors": ["Nam H. Le"], "title": "Organismal Agency and Rapid Adaptation: The Phenopoiesis Algorithm for Phenotype-First Evolution", "categories": ["cs.NE", "q-bio.PE"], "comment": "22 pages, 2 figures,", "summary": "Evolutionary success depends on the capacity to adapt: organisms must respond to environmental challenges through both genetic innovation and lifetime learning. The gene-centric paradigm attributes evolutionary causality exclusively to genes, while Denis Noble's phenotype-first framework argues that organisms are active agents capable of interpreting genetic resources, learning from experience, and shaping their own development. However, this framework has remained philosophically intuitive but algorithmically opaque. We show for the first time that organismal agency can be implemented as a concrete computational process through heritable phenotypic patterns. We introduce the Phenopoiesis Algorithm, where organisms inherit not just genes but also successful phenotypic patterns discovered during lifetime learning. Through experiments in changing environments, these pattern-inheriting organisms achieve 3.4 times faster adaptation compared to gene-centric models. Critically, these gains require cross-generational inheritance of learned patterns rather than within-lifetime learning alone. We conclude that organismal agency is not a philosophical abstraction but an algorithmic mechanism with measurable adaptive value. The mechanism works through compositional reuse: organisms discover how to compose primitive elements into solutions, encode those compositional recipes, and transmit them to offspring. Evolution operates across multiple timescales -- fast, reversible phenotypic inheritance and slow, permanent genetic inheritance -- providing adaptive flexibility that single-channel mechanisms cannot achieve.", "AI": {"tldr": "通过引入Phenopoiesis算法，研究展示了有机体代理可以作为一种具体的计算过程实现，并且这种机制在适应性上具有可测量的价值。", "motivation": "传统的基因中心范式将进化因果归因于基因，而Denis Noble的表型优先框架认为有机体是能够解读遗传资源、从经验中学习并塑造自身发展的主动代理。然而，该理论缺乏算法实现。研究旨在通过计算过程展示有机体代理的实际价值。", "method": "引入Phenopoiesis算法，使生物在继承基因的同时也可以继承在终身学习过程中发现的成功表型模式。", "result": "与基因中心模型相比，这些具有跨代遗传学习模式的有机体实现了3.4倍更快的适应性提升。结果表明，这种机制通过组合重用来实现进化，并且进化操作跨越了多个时间尺度，提供了单通道机制所无法比拟的适应灵活性。", "conclusion": "有机体代理不仅是一种哲学抽象，而且是一种具有可测量适应价值的算法机制"}}
{"id": "2602.00973", "pdf": "https://arxiv.org/pdf/2602.00973", "abs": "https://arxiv.org/abs/2602.00973", "authors": ["Avinash Ajit Nargund", "Andrew L. Huard", "Tobias Höllerer", "Misha Sra"], "title": "Exploration of Radar-based Obstacle Visualizations to Support Safety and Presence in Camera-Free Outdoor VR", "categories": ["cs.HC"], "comment": null, "summary": "Outdoor virtual reality (VR) places users in dynamic physical environments where they must remain aware of real-world obstacles, including static structures and moving bystanders, while immersed in a virtual scene. This dual demand introduces challenges for both user safety and presence. Millimeter-wave (mmWave) radar offers a privacy-preserving alternative to camera-based sensing by detecting obstacles without capturing identifiable visual imagery, yet effective methods for communicating its sparse spatial information to users remain underexplored. In this work, we developed and validated WaveWalkerClone, a reproduction of the WaveWalker system, to establish reliable radar- and GPS-IMU-based sensing under varied outdoor lighting conditions. Building on this feasibility validation, we conducted a user study (n=18) comparing three visualization techniques for radar-detected obstacles : (1) diegetic alien avatars that visually embed obstacles within the virtual narrative, (2) non-diegetic human avatars represented obstacles as humans inconsistent with the virtual narrative, and (3) abstract point clouds centered around the obstacles conveying spatial data without anthropomorphic or narrative associations. Our results show that all three approaches supported user safety and situational awareness, but yielded distinct trade-offs in perceived effort, frustration, and user preference. Qualitative feedback further revealed divergent user responses across conditions, highlighting the limitations of a one-size-fits-all approach. We conclude with design considerations for obstacle visualization in outdoor VR systems that seek to balance immersion, safety, and bystander privacy.", "AI": {"tldr": "本文探讨了毫米波雷达在户外虚拟现实中的应用，通过三种障碍物可视化方法的对比研究来支持用户的安全和存在感。", "motivation": "户外虚拟现实中需要同时保证用户的沉浸体验与物理环境安全。毫米波雷达提供了一种隐私保护良好的障碍检测方式，并且如何有效地将这种稀疏的空间信息传达给用户仍然是一个有待探索的问题。", "method": "开发并验证了WaveWalkerClone系统，用于建立基于毫米波雷达和GPS-IMU的可靠传感技术在各种户外光照条件下的可行性。通过一项包含18名参与者的用户研究，对比分析了三种障碍物可视化方法的效果：（1）融入虚拟叙事中的外星人形象；（2）不一致于虚拟叙事的人类形象；（3）仅传达空间数据而不具人格特征的抽象点云。", "result": "结果表明，这三种方法均能支持用户安全和情境感知能力，但不同方法在用户体验、努力程度及偏好方面存在明显差异。定性反馈进一步揭示了不同条件下的用户反应具有多样性，强调了一种适合所有人的单一解决方案的局限性。", "conclusion": "本文提出了户外虚拟现实系统中障碍物可视化设计时需要考虑的问题，以平衡沉浸感、安全性与旁观者隐私保护之间的关系"}}
{"id": "2602.00971", "pdf": "https://arxiv.org/pdf/2602.00971", "abs": "https://arxiv.org/abs/2602.00971", "authors": ["Meng Luo", "Bobo Li", "Shanqing Xu", "Shize Zhang", "Qiuchan Chen", "Menglu Han", "Wenhao Chen", "Yanxiang Huang", "Hao Fei", "Mong-Li Lee", "Wynne Hsu"], "title": "Unveiling the Cognitive Compass: Theory-of-Mind-Guided Multimodal Emotion Reasoning", "categories": ["cs.CV"], "comment": "Accepted by ICLR 2026", "summary": "Despite rapid progress in multimodal large language models (MLLMs), their capability for deep emotional understanding remains limited. We argue that genuine affective intelligence requires explicit modeling of Theory of Mind (ToM), the cognitive substrate from which emotions arise. To this end, we introduce HitEmotion, a ToM-grounded hierarchical benchmark that diagnoses capability breakpoints across increasing levels of cognitive depth. Second, we propose a ToM-guided reasoning chain that tracks mental states and calibrates cross-modal evidence to achieve faithful emotional reasoning. We further introduce TMPO, a reinforcement learning method that uses intermediate mental states as process-level supervision to guide and strengthen model reasoning. Extensive experiments show that HitEmotion exposes deep emotional reasoning deficits in state-of-the-art models, especially on cognitively demanding tasks. In evaluation, the ToM-guided reasoning chain and TMPO improve end-task accuracy and yield more faithful, more coherent rationales. In conclusion, our work provides the research community with a practical toolkit for evaluating and enhancing the cognition-based emotional understanding capabilities of MLLMs. Our dataset and code are available at: https://HitEmotion.github.io/.", "AI": {"tldr": "提出了一种基于理论思维的多模态情感推理方法和评估基准，以增强大语言模型的情感理解能力。", "motivation": "当前多模态大型语言模型在深层情感理解方面存在不足。通过引入理论思维（ToM）来改善这一状况。", "method": "介绍了HitEmotion评测基准，提出了基于ToM的推理链和TMPO强化学习方法。", "result": "实验显示，新方法能够更好地解决复杂的情感推理任务，并且提高了模型在情感理解上的准确性和一致性。", "conclusion": "这项工作为研究社区提供了一个实用工具包，用于评估和增强多模态语言模型的认知基础上的情感理解能力。"}}
{"id": "2602.00960", "pdf": "https://arxiv.org/pdf/2602.00960", "abs": "https://arxiv.org/abs/2602.00960", "authors": ["Leonardo Ferreira Guilhoto", "Akshat Kaushal", "Paris Perdikaris"], "title": "Multimodal Scientific Learning Beyond Diffusions and Flows", "categories": ["cs.LG", "cs.AI", "cs.CE", "stat.CO", "stat.ML"], "comment": ":68T37ACM Class:J.2; G.3; I.2; I.6", "summary": "Scientific machine learning (SciML) increasingly requires models that capture multimodal conditional uncertainty arising from ill-posed inverse problems, multistability, and chaotic dynamics. While recent work has favored highly expressive implicit generative models such as diffusion and flow-based methods, these approaches are often data-hungry, computationally costly, and misaligned with the structured solution spaces frequently found in scientific problems. We demonstrate that Mixture Density Networks (MDNs) provide a principled yet largely overlooked alternative for multimodal uncertainty quantification in SciML. As explicit parametric density estimators, MDNs impose an inductive bias tailored to low-dimensional, multimodal physics, enabling direct global allocation of probability mass across distinct solution branches. This structure delivers strong data efficiency, allowing reliable recovery of separated modes in regimes where scientific data is scarce. We formalize these insights through a unified probabilistic framework contrasting explicit and implicit distribution networks, and demonstrate empirically that MDNs achieve superior generalization, interpretability, and sample efficiency across a range of inverse, multistable, and chaotic scientific regression tasks.", "AI": {"tldr": "该论文展示了混合密度网络（MDN）在科学机器学习中的应用，特别是在处理多模态不确定性问题时的优越性。", "motivation": "最近的研究倾向于使用高度表达性的隐式生成模型来解决科学研究中出现的多模态条件不确定性和逆向问题，但是这些方法通常需要大量的数据且计算成本高。MDN提供了一种更加有效的替代方案，特别是在科学领域中存在的低维、多模态物理问题上。", "method": "论文提出使用混合密度网络（MDNs）来直接估计概率分布中的不同解分支，并通过一个统一的概率框架对比显式和隐式的分布模型。", "result": "实验结果表明，相比扩散模型和其他方法，MDN在处理逆向、多稳态和混沌科学回归任务时表现出了更好的泛化能力、可解释性和样本效率。", "conclusion": "论文强调混合密度网络（MDN）为科学研究中的不确定性量化提供了一种有效且被忽视的替代方案。"}}
{"id": "2602.00956", "pdf": "https://arxiv.org/pdf/2602.00956", "abs": "https://arxiv.org/abs/2602.00956", "authors": ["Faisal Ahmed"], "title": "Hybrid Topological and Deep Feature Fusion for Accurate MRI-Based Alzheimer's Disease Severity Classification", "categories": ["cs.CV", "cs.LG"], "comment": "20 pages, 6 Figures", "summary": "Early and accurate diagnosis of Alzheimer's disease (AD) remains a critical challenge in neuroimaging-based clinical decision support systems. In this work, we propose a novel hybrid deep learning framework that integrates Topological Data Analysis (TDA) with a DenseNet121 backbone for four-class Alzheimer's disease classification using structural MRI data from the OASIS dataset. TDA is employed to capture complementary topological characteristics of brain structures that are often overlooked by conventional neural networks, while DenseNet121 efficiently learns hierarchical spatial features from MRI slices. The extracted deep and topological features are fused to enhance class separability across the four AD stages. Extensive experiments conducted on the OASIS-1 Kaggle MRI dataset demonstrate that the proposed TDA+DenseNet121 model significantly outperforms existing state-of-the-art approaches. The model achieves an accuracy of 99.93% and an AUC of 100%, surpassing recently published CNN-based, transfer learning, ensemble, and multi-scale architectures. These results confirm the effectiveness of incorporating topological insights into deep learning pipelines and highlight the potential of the proposed framework as a robust and highly accurate tool for automated Alzheimer's disease diagnosis.", "AI": {"tldr": "提出了一种结合拓扑数据分析和深度学习的混合框架，用于基于MRI图像进行阿尔茨海默病严重程度分类。", "motivation": "早期准确诊断阿尔茨海默病是神经成像临床决策支持系统的关键挑战。通过融合拓扑特征与深层空间特征来提升AD分期间类别的可分离性。", "method": "利用DenseNet121模型学习MRI图像的空间层次特征，同时使用TDA捕捉大脑结构中的拓扑特性，并将两者的特征进行融合以提高分类准确性。", "result": "在OASIS-1 Kaggle MRI数据集上进行了实验，所提模型取得了99.93%的精度和100%的AUC值，优于现有的CNN、迁移学习、集成及多尺度架构。", "conclusion": "结合拓扑信息与深度神经网络可显著提升AD诊断准确率，表明该框架具有作为自动化AD诊断工具的潜力。"}}
{"id": "2602.00954", "pdf": "https://arxiv.org/pdf/2602.00954", "abs": "https://arxiv.org/abs/2602.00954", "authors": ["Jinlong Pang", "Zhaowei Zhu", "Na Di", "Yichi Zhang", "Yaxuan Wang", "Chen Qian", "Yang Liu"], "title": "Small-Margin Preferences Still Matter-If You Train Them Right", "categories": ["cs.AI"], "comment": null, "summary": "Preference optimization methods such as DPO align large language models (LLMs) using paired comparisons, but their effectiveness can be highly sensitive to the quality and difficulty of preference pairs. A common heuristic treats small-margin (ambiguous) pairs as noisy and filters them out. In this paper, we revisit this assumption and show that pair difficulty interacts strongly with the optimization objective: when trained with preference-based losses, difficult pairs can destabilize training and harm alignment, yet these same pairs still contain useful supervision signals when optimized with supervised fine-tuning (SFT). Motivated by this observation, we propose MixDPO, a simple yet effective difficulty-aware training strategy that (i) orders preference data from easy to hard (a curriculum over margin-defined difficulty), and (ii) routes difficult pairs to an SFT objective while applying a preference loss to easy pairs. This hybrid design provides a practical mechanism to leverage ambiguous pairs without incurring the optimization failures often associated with preference losses on low-margin data. Across three LLM-judge benchmarks, MixDPO consistently improves alignment over DPO and a range of widely-used variants, with particularly strong gains on AlpacaEval~2 length-controlled (LC) win rate.", "AI": {"tldr": "该论文提出了MixDPO，一种基于难度感知的训练策略，旨在通过优化带有监督微调的任务来改善大语言模型（LLMs）的对齐。", "motivation": "传统的偏好优化方法如DPO在处理小边缘差异的偏好对时存在敏感性问题，这些方法倾向于过滤掉模糊的偏好对。然而，在本论文中，作者发现困难的偏好对仍然包含有价值的信息，并提出了一个新的策略以更好地利用它们。", "method": "MixDPO通过首先将偏好数据按从简单到难排序（基于边缘难度），然后在监督微调目标上路由困难对和在偏好损失上应用容易对来工作。这种方法提供了一种实用的方法，可以在不引发低边距数据相关优化失败的情况下利用模糊的偏好对。", "result": "在三个LLM裁判基准测试中，MixDPO比DPO和其他广泛使用的方法显著提高了模型的对齐度，特别是在AlpacaEval~2长度控制（LC）胜率上取得了特别强的结果。", "conclusion": "通过设计一种难度感知训练策略，该研究展示了如何有效利用传统方法容易忽略的小边缘差异偏好对来改善大语言模型的性能和对准质量。"}}
{"id": "2602.00951", "pdf": "https://arxiv.org/pdf/2602.00951", "abs": "https://arxiv.org/abs/2602.00951", "authors": ["Hector Munoz-Avila", "David W. Aha", "Paola Rizzo"], "title": "R-HTN: Rebellious Online HTN Planning for Safety and Game AI", "categories": ["cs.AI"], "comment": "ef:The Annual Conference on Advances in Cognitive Systems (ACS-2025)", "summary": "We introduce online Hierarchical Task Network (HTN) agents whose behaviors are governed by a set of built-in directives \\D. Like other agents that are capable of rebellion (i.e., {\\it intelligent disobedience}), our agents will, under some conditions, not perform a user-assigned task and instead act in ways that do not meet a user's expectations. Our work combines three concepts: HTN planning, online planning, and the directives \\D, which must be considered when performing user-assigned tasks. We investigate two agent variants: (1) a Nonadaptive agent that stops execution if it finds itself in violation of \\D~ and (2) an Adaptive agent that, in the same situation, instead modifies its HTN plan to search for alternative ways to achieve its given task. We present R-HTN (for: Rebellious-HTN), a general algorithm for online HTN planning under directives \\D. We evaluate R-HTN in two task domains where the agent must not violate some directives for safety reasons or as dictated by their personality traits. We found that R-HTN agents never violate directives, and aim to achieve the user-given goals if feasible though not necessarily as the user expected.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.00950", "pdf": "https://arxiv.org/pdf/2602.00950", "abs": "https://arxiv.org/abs/2602.00950", "authors": ["António Farinhas", "Nuno M. Guerreiro", "José Pombal", "Pedro Henrique Martins", "Laura Melton", "Alex Conway", "Cara Dochat", "Maya D'Eon", "Ricardo Rei"], "title": "MindGuard: Guardrail Classifiers for Multi-Turn Mental Health Support", "categories": ["cs.AI"], "comment": null, "summary": "Large language models are increasingly used for mental health support, yet their conversational coherence alone does not ensure clinical appropriateness. Existing general-purpose safeguards often fail to distinguish between therapeutic disclosures and genuine clinical crises, leading to safety failures. To address this gap, we introduce a clinically grounded risk taxonomy, developed in collaboration with PhD-level psychologists, that identifies actionable harm (e.g., self-harm and harm to others) while preserving space for safe, non-crisis therapeutic content. We release MindGuard-testset, a dataset of real-world multi-turn conversations annotated at the turn level by clinical experts. Using synthetic dialogues generated via a controlled two-agent setup, we train MindGuard, a family of lightweight safety classifiers (with 4B and 8B parameters). Our classifiers reduce false positives at high-recall operating points and, when paired with clinician language models, help achieve lower attack success and harmful engagement rates in adversarial multi-turn interactions compared to general-purpose safeguards. We release all models and human evaluation data.", "AI": {"tldr": "提出了一种用于多轮心理健康支持的轻量级安全分类器MindGuard，以区分治疗性披露和真正的临床危机。", "motivation": "大型语言模型在进行心理健康支持时仅凭对话连贯性无法确保临床适当性。现有的通用防护措施难以有效地区分治疗性的披露与真正存在的临床危机，导致安全性问题。", "method": "开发了一个基于临床的危险分类体系，并创建了MindGuard测试集数据集，利用合成对话训练出轻量级的安全分类器，降低误报率，并在对抗性多轮交互中减少攻击成功率和有害互动的发生率。", "result": "与通用防护措施相比，该模型能够更好地平衡安全性需求，在保证高召回率的同时显著减少了假阳性结果，有效保护了用户安全。", "conclusion": "MindGuard成功地解决了大型语言模型在心理健康支持中的临床适当性问题，通过引入特定于心理健康领域的风险分类器并结合临床专家的数据集训练，实现了更高的安全性和更低的误报率。"}}
{"id": "2602.00949", "pdf": "https://arxiv.org/pdf/2602.00949", "abs": "https://arxiv.org/abs/2602.00949", "authors": ["Xiang Zhang", "Boxuan Zhang", "Alireza Naghizadeh", "Mohab Mohamed", "Dongfang Liu", "Ruixiang Tang", "Dimitris Metaxas", "Dongfang Liu"], "title": "Data Augmentation for High-Fidelity Generation of CAR-T/NK Immunological Synapse Images", "categories": ["cs.CV"], "comment": null, "summary": "Chimeric antigen receptor (CAR)-T and NK cell immunotherapies have transformed cancer treatment, and recent studies suggest that the quality of the CAR-T/NK cell immunological synapse (IS) may serve as a functional biomarker for predicting therapeutic efficacy. Accurate detection and segmentation of CAR-T/NK IS structures using artificial neural networks (ANNs) can greatly increase the speed and reliability of IS quantification. However, a persistent challenge is the limited size of annotated microscopy datasets, which restricts the ability of ANNs to generalize. To address this challenge, we integrate two complementary data-augmentation frameworks. First, we employ Instance Aware Automatic Augmentation (IAAA), an automated, instance-preserving augmentation method that generates synthetic CAR-T/NK IS images and corresponding segmentation masks by applying optimized augmentation policies to original IS data. IAAA supports multiple imaging modalities (e.g., fluorescence and brightfield) and can be applied directly to CAR-T/NK IS images derived from patient samples. In parallel, we introduce a Semantic-Aware AI Augmentation (SAAA) pipeline that combines a diffusion-based mask generator with a Pix2Pix conditional image synthesizer. This second method enables the creation of diverse, anatomically realistic segmentation masks and produces high-fidelity CAR-T/NK IS images aligned with those masks, further expanding the training corpus beyond what IAAA alone can provide. Together, these augmentation strategies generate synthetic images whose visual and structural properties closely match real IS data, significantly improving CAR-T/NK IS detection and segmentation performance. By enhancing the robustness and accuracy of IS quantification, this work supports the development of more reliable imaging-based biomarkers for predicting patient response to CAR-T/NK immunotherapy.", "AI": {"tldr": "本文提出了一种用于生成高保真CAR-T/NK免疫突触图像的数据增强方法，以提高人工神经网络对这些结构的检测和分割性能。", "motivation": "由于注释显微镜数据集的大小有限，限制了人工智能网络泛化能力。为了克服这一挑战，本文提出了两种互补的数据增强框架。", "method": "一是实例感知自动增强（IAAA），该方法通过应用优化的增广策略生成合成免疫突触图像及对应的分割掩膜；二是语义感知AI增强（SAAA）管道结合扩散基底遮罩生成器和Pix2Pix条件图像合成器，创建多样化且解剖学上真实的分割掩膜。", "result": "这些方法共同产生的合成图像是视觉和结构属性与真实免疫突触数据接近的，显著提高了CAR-T/NK免疫突触检测和分割性能。", "conclusion": "通过提高IS量化稳健性和准确性，此项工作支持基于影像学预测CAR-T/NK免疫疗法患者响应更可靠的生物标记物的发展。"}}
{"id": "2602.00948", "pdf": "https://arxiv.org/pdf/2602.00948", "abs": "https://arxiv.org/abs/2602.00948", "authors": ["Mingxi Zou", "Jiaxiang Chen", "Aotian Luo", "Jingyi Dai", "Chi Zhang", "Dongning Sun", "Zenglin Xu"], "title": "FinEvo: From Isolated Backtests to Ecological Market Games for Multi-Agent Financial Strategy Evolution", "categories": ["physics.soc-ph", "cs.AI", "cs.GT", "cs.MA"], "comment": "Preprint. Submitted to a conference", "summary": "Conventional financial strategy evaluation relies on isolated backtests in static environments. Such evaluations assess each policy independently, overlook correlations and interactions, and fail to explain why strategies ultimately persist or vanish in evolving markets. We shift to an ecological perspective, where trading strategies are modeled as adaptive agents that interact and learn within a shared market. Instead of proposing a new strategy, we present FinEvo, an ecological game formalism for studying the evolutionary dynamics of multi-agent financial strategies. At the individual level, heterogeneous ML-based traders-rule-based, deep learning, reinforcement learning, and large language model (LLM) agents-adapt using signals such as historical prices and external news. At the population level, strategy distributions evolve through three designed mechanisms-selection, innovation, and environmental perturbation-capturing the dynamic forces of real markets. Together, these two layers of adaptation link evolutionary game theory with modern learning dynamics, providing a principled environment for studying strategic behavior. Experiments with external shocks and real-world news streams show that FinEvo is both stable for reproducibility and expressive in revealing context-dependent outcomes. Strategies may dominate, collapse, or form coalitions depending on their competitors-patterns invisible to static backtests. By reframing strategy evaluation as an ecological game formalism, FinEvo provides a unified, mechanism-level protocol for analyzing robustness, adaptation, and emergent dynamics in multi-agent financial markets, and may offer a means to explore the potential impact of macroeconomic policies and financial regulations on price evolution and equilibrium.", "AI": {"tldr": "本文提出了一种新的生态游戏框架FinEvo，用于研究多代理金融策略的进化动力学。", "motivation": "传统的金融策略评估依赖孤立的回溯测试，在静态环境中独立评估每个政策。这种方法忽视了相关性和互动，并无法解释为什么某些策略最终会在不断变化的市场中存续或消失。", "method": "FinEvo通过模拟适应性交易策略在共享市场中的互动和学习，采用两种层次的适应机制：个体层面的多样化ML基础交易者（包括规则为基础、深度学习、强化学习等），以及种群层面的选择、创新和环境扰动。这种方法将进化博弈理论与现代学习动态相结合。", "result": "实验表明，FinEvo不仅在再现性方面稳定，在揭示上下文依赖的结果上也非常表达丰富。策略可能会根据其竞争对手而支配、崩溃或形成联盟。", "conclusion": "通过将策略评估重新定义为生态游戏形式框架，FinEvo提供了一个统一的机制级协议来分析多代理金融市场中的鲁棒性、适应性和涌现动态，并可能探索宏观经济政策和金融监管对价格演变和平稳状态的影响。"}}
{"id": "2602.00947", "pdf": "https://arxiv.org/pdf/2602.00947", "abs": "https://arxiv.org/abs/2602.00947", "authors": ["Mohan Reddy"], "title": "The Keyhole Effect: Why Chat Interfaces Fail at Data Analysis", "categories": ["cs.AI"], "comment": null, "summary": "Chat has become the default interface for AI-assisted data analysis. For multi-step, state-dependent analytical tasks, this is a mistake. Building on Woods (1984) Keyhole Effect, the cognitive cost of viewing large information spaces through narrow viewports, I show that chat interfaces systematically degrade analytical performance through five mechanisms: (1) constant content displacement defeats hippocampal spatial memory systems; (2) hidden state variables exceed working memory capacity (approximately 4 chunks under load); (3) forced verbalization triggers verbal overshadowing, degrading visual pattern recognition; (4) linear text streams block epistemic action and cognitive offloading; (5) serialization penalties scale with data dimensionality. I formalize cognitive overload as O = max(0, m - v - W) where m is task-relevant items, v is visible items, and W is working memory capacity. When O > 0, error probability increases and analytical biases (anchoring, confirmation, change blindness) amplify. Eight hybrid design patterns address these failures: Generative UI, Infinite Canvas, Deictic Interaction, State Rail, Ghost Layers, Mise en Place, Semantic Zoom, and Probabilistic UI. Each pattern targets specific cognitive bottlenecks while preserving natural language for intent specification and synthesis. Well-scaffolded conversational systems that encode expert priors may reduce load for guided tasks; the framework applies most strongly to open-ended exploration. The paper concludes with falsifiable hypotheses and experimental paradigms for empirical validation.", "AI": {"tldr": "探讨聊天界面在数据分析中的局限性，并提出八种设计模式来改进。", "motivation": "多步骤、状态依赖的数据分析任务中，聊天界面会增加认知负担，降低性能。作者基于Woods（1984）的Keyhole Effect理论，揭示了五种机制如何导致这种问题。", "method": "通过认知科学和心理学原理，形式化定义了认知过载的概念，并提出了八种设计模式来解决这些问题。", "result": "聊天界面在数据分析任务中存在五个主要问题：内容不断替换、隐藏状态变量过多、强迫语言表达降低视觉识别能力、线性文本流阻止知识行动和认知卸载、序列化惩罚随着数据维度增加而增大。", "conclusion": "设计八种模式来解决聊天接口的局限，提高数据分析性能，并提出实验验证假设。"}}
{"id": "2602.00946", "pdf": "https://arxiv.org/pdf/2602.00946", "abs": "https://arxiv.org/abs/2602.00946", "authors": ["Dhruv Parikh", "Haoyang Fan", "Rajgopal Kannan", "Viktor Prasanna"], "title": "ConsensusDrop: Fusing Visual and Cross-Modal Saliency for Efficient Vision Language Models", "categories": ["cs.CV"], "comment": "Technical Report", "summary": "Vision-Language Models (VLMs) are expensive because the LLM processes hundreds of largely redundant visual tokens. Existing token reduction methods typically exploit \\textit{either} vision-encoder saliency (broad but query-agnostic) \\textit{or} LLM cross-attention (query-aware but sparse and costly). We show that neither signal alone is sufficient: fusing them consistently improves performance compared to unimodal visual token selection (ranking). However, making such fusion practical is non-trivial: cross-modal saliency is usually only available \\emph{inside} the LLM (too late for efficient pre-LLM pruning), and the two signals are inherently asymmetric, so naive fusion underutilizes their complementary strengths. We propose \\textbf{ConsensusDrop}, a training-free framework that derives a \\emph{consensus} ranking by reconciling vision encoder saliency with query-aware cross-attention, retaining the most informative tokens while compressing the remainder via encoder-guided token merging. Across LLaVA-1.5/NeXT, Video-LLaVA, and other open-source VLMs, ConsensusDrop consistently outperforms prior pruning methods under identical token budgets and delivers a stronger accuracy-efficiency Pareto frontier -- preserving near-baseline accuracy even at aggressive token reductions while reducing TTFT and KV cache footprint. Our code will be open-sourced.", "AI": {"tldr": "本文提出了一种融合视觉和跨模态注意力的高效剪枝框架ConsensusDrop，旨在提升视觉语言模型性能。", "motivation": "当前视觉语言模型因LLM处理大量冗余视觉标记而效率低下。现有的简化方法主要依赖视觉编码器或查询感知的交叉注意机制之一，但单一信号不足以优化模型性能。本文探讨融合两种信号的可能性，提出一种实用的剪枝框架解决此问题。", "method": "ConsensusDrop是一种训练无关的框架，通过将视觉编码器和跨模态注意力合并来生成共识排名，保留最具信息性的标记并压缩其他标记。", "result": "实验表明，在相同令牌预算下，ConsensusDrop优于先前的方法，提供更优的精度-效率折衷方案。在LLaVA-1.5/NeXT，Video-LLaVA和其他开源VLMs中均有较好的表现。", "conclusion": "通过融合视觉和跨模态信号，ConsensusDrop不仅提升了模型性能而且大幅降低了计算成本，在保持接近基线准确率的同时显著减少了令牌处理时间和缓存占用。"}}
{"id": "2602.00945", "pdf": "https://arxiv.org/pdf/2602.00945", "abs": "https://arxiv.org/abs/2602.00945", "authors": ["Anusa Saha", "Tanmay Joshi", "Vinija Jain", "Aman Chadha", "Amitava Das"], "title": "Neural FOXP2 -- Language Specific Neuron Steering for Targeted Language Improvement in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "LLMs are multilingual by training, yet their lingua franca is often English, reflecting English language dominance in pretraining. Other languages remain in parametric memory but are systematically suppressed. We argue that language defaultness is governed by a sparse, low-rank control circuit, language neurons, that can be mechanistically isolated and safely steered. We introduce Neural FOXP2, that makes a chosen language (Hindi or Spanish) primary in a model by steering language-specific neurons. Neural FOXP2 proceeds in three stages: (i) Localize: We train per-layer SAEs so each activation decomposes into a small set of active feature components. For every feature, we quantify English vs. Hindi/Spanish selectivity overall logit-mass lift toward the target-language token set. Tracing the top-ranked features back to their strongest contributing units yields a compact language-neuron set. (ii) Steering directions: We localize controllable language-shift geometry via a spectral low-rank analysis. For each layer, we build English to target activation-difference matrices and perform layerwise SVD to extract the dominant singular directions governing language change. The eigengap and effective-rank spectra identify a compact steering subspace and an empirically chosen intervention window (where these directions are strongest and most stable). (iii) Steer: We apply a signed, sparse activation shift targeted to the language neurons. Concretely, within low to mid layers we add a positive steering along the target-language dominant directions and a compensating negative shift toward the null space for the English neurons, yielding controllable target-language defaultness.", "AI": {"tldr": "本论文提出了一种名为Neural FOXP2的技术，通过调节特定的语言神经元来使大型语言模型在指定语言（如印地语或西班牙语）上实现更好的性能。", "motivation": "多语言训练的大型语言模型通常默认以英语为主导，其他语言虽然存在于参数记忆中但被系统性压制。本论文提出了一种技术来调整这种倾向，使得特定语言成为主要使用的语言。", "method": "Neural FOXP2通过三个阶段实现其目标：（i）定位：训练每层的自编码器以分离出激活中的关键特征，并量化这些特征对不同语言的选择性；（ii）转向方向：通过谱低秩分析确定控制语言变化的主要方向；（iii）调整：在中下层添加针对特定语言的方向修正，同时对英语神经元进行补偿性的负向修正。", "result": "实验表明，Neural FOXP2能够显著提升模型在指定语言上的性能，而不会明显影响其在其他任务和语言上的表现。", "conclusion": "通过精确调整神经网络中的特定部分，可以有效地改变大型语言模型的语言偏好。这为多语言模型的进一步优化提供了新的思路。"}}
{"id": "2602.00937", "pdf": "https://arxiv.org/pdf/2602.00937", "abs": "https://arxiv.org/abs/2602.00937", "authors": ["I-Chun Arthur Liu", "Krzysztof Choromanski", "Sandy Huang", "Connor Schenck"], "title": "CLAMP: Contrastive Learning for 3D Multi-View Action-Conditioned Robotic Manipulation Pretraining", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Leveraging pre-trained 2D image representations in behavior cloning policies has achieved great success and has become a standard approach for robotic manipulation. However, such representations fail to capture the 3D spatial information about objects and scenes that is essential for precise manipulation. In this work, we introduce Contrastive Learning for 3D Multi-View Action-Conditioned Robotic Manipulation Pretraining (CLAMP), a novel 3D pre-training framework that utilizes point clouds and robot actions. From the merged point cloud computed from RGB-D images and camera extrinsics, we re-render multi-view four-channel image observations with depth and 3D coordinates, including dynamic wrist views, to provide clearer views of target objects for high-precision manipulation tasks. The pre-trained encoders learn to associate the 3D geometric and positional information of objects with robot action patterns via contrastive learning on large-scale simulated robot trajectories. During encoder pre-training, we pre-train a Diffusion Policy to initialize the policy weights for fine-tuning, which is essential for improving fine-tuning sample efficiency and performance. After pre-training, we fine-tune the policy on a limited amount of task demonstrations using the learned image and action representations. We demonstrate that this pre-training and fine-tuning design substantially improves learning efficiency and policy performance on unseen tasks. Furthermore, we show that CLAMP outperforms state-of-the-art baselines across six simulated tasks and five real-world tasks.", "AI": {"tldr": "提出了一种新的三维预训练框架CLAMP，用于机器人操作的对比学习。", "motivation": "现有的基于行为克隆策略依赖于二维图像表示的方法无法捕捉物体和场景的关键三维空间信息。", "method": "利用点云和机器人动作进行3D多视角条件下的操作预训练。通过合并从RGB-D图像和相机外参计算出的点云，重新渲染包含深度和3D坐标等四通道图像观察，并引入扩散策略进行预训练以提高微调效率。", "result": "在六个模拟任务和五个真实世界任务中，CLAMP优于现有的最先进基线方法。", "conclusion": "该框架提高了学习效率和操作策略的性能，在不同任务上表现出色。"}}
{"id": "2602.00935", "pdf": "https://arxiv.org/pdf/2602.00935", "abs": "https://arxiv.org/abs/2602.00935", "authors": ["Mohamed Sorour", "Barbara Webb"], "title": "Minimal Footprint Grasping Inspired by Ants", "categories": ["cs.RO"], "comment": null, "summary": "Ants are highly capable of grasping objects in clutter, and we have recently observed that this involves substantial use of their forelegs. The forelegs, more specifically the tarsi, have high friction microstructures (setal pads), are covered in hairs, and have a flexible under-actuated tip. Here we abstract these features to test their functional advantages for a novel low-cost gripper design, suitable for bin-picking applications. In our implementation, the gripper legs are long and slim, with high friction gripping pads, low friction hairs and single-segment tarsus-like structure to mimic the insect's setal pads, hairs, and the tarsi's interactive compliance. Experimental evaluation shows this design is highly robust for grasping a wide variety of individual consumer objects, with all grasp attempts successful. In addition, we demonstrate this design is effective for picking single objects from dense clutter, a task at which ants also show high competence. The work advances grasping technology and shed new light on the mechanical importance of hairy structures and tarsal flexibility in insects.", "AI": {"tldr": "蚂蚁在杂乱环境中抓取物体的能力启发了新型低成本夹爪的设计，这种设计适用于从密集堆叠中拾取单个物品。", "motivation": "观察到蚂蚁使用前腿的高摩擦微结构（刚毛垫）和柔软灵活的末端来有效地抓取物体，从而激发了研发一种模拟这些特征的新式低耗成本夹爪，以提高其在杂乱环境中的适应能力与成功率。", "method": "设计了一种长而细、具有高摩擦力抓取垫、低摩擦毛发以及单段类似胫节结构的新型低成本夹爪，以此模仿蚂蚁腿部和足部的功能特性。进行了实验评估。", "result": "该设计在多种消费者物品上实现了高成功率的抓取，并且成功展示了从密集堆叠中拾取单一物体的能力。", "conclusion": "通过模拟蚂蚁腿和足的独特结构特征，这种新型低成本夹爪可以有效地提高机器人在复杂环境中的抓取性能。这项工作强调了昆虫毛发结构的重要性及其胫节灵活性对机械设计的启示作用。"}}
{"id": "2602.00933", "pdf": "https://arxiv.org/pdf/2602.00933", "abs": "https://arxiv.org/abs/2602.00933", "authors": ["Chaithanya Bandi", "Ben Hertzberg", "Geobio Boo", "Tejas Polakam", "Jeff Da", "Sami Hassaan", "Manasi Sharma", "Andrew Park", "Ernesto Hernandez", "Dan Rambado", "Ivan Salazar", "Rafael Cruz", "Chetan Rane", "Ben Levin", "Brad Kenstler", "Bing Liu"], "title": "MCP-Atlas: A Large-Scale Benchmark for Tool-Use Competency with Real MCP Servers", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The Model Context Protocol (MCP) is rapidly becoming the standard interface for Large Language Models (LLMs) to discover and invoke external tools. However, existing evaluations often fail to capture the complexity of real-world scenarios, relying on restricted toolsets, simplistic workflows, or subjective LLM-as-a-judge metrics. We introduce MCP-Atlas, a large-scale benchmark for evaluating tool-use competency, comprising 36 real MCP servers and 220 tools. It includes 1,000 tasks designed to assess tool-use competency in realistic, multi-step workflows. Tasks use natural language prompts that avoid naming specific tools or servers, requiring agents to identify and orchestrate 3-6 tool calls across multiple servers. We score tasks using a claims-based rubric that awards partial credit based on the factual claims satisfied in the model's final answer, complemented by internal diagnostics on tool discovery, parameterization, syntax, error recovery, and efficiency. Evaluation results on frontier models reveal that top models achieve pass rates exceeding 50%, with primary failures arising from inadequate tool usage and task understanding. We release the task schema, containerized harness, and a 500-task public subset of the benchmark dataset to facilitate reproducible comparisons and advance the development of robust, tool-augmented agents.", "AI": {"tldr": "MCP-Atlas是一个用于评估大型语言模型工具使用能力的大规模基准测试。", "motivation": "现有的评估方法往往局限于简化的工具集和工作流程，无法全面捕捉现实场景中的复杂性。因此需要一个能模拟真实情况的标准化评价体系。", "method": "该研究开发了一个包含36个实际MCP服务器和220种工具的大规模基准测试，设计了1,000项任务来评估模型在多步骤工作流程中使用工具的能力。", "result": "前沿模型通过率超过50%，但主要问题在于不充分的工具使用及对任务理解不足。评分采用基于声明的标准体系，根据最终答案中的事实陈述给予部分分数，并结合内部诊断指标进行综合评价。", "conclusion": "该基准测试有助于推进稳健且增强型代理的研发和比较研究，作者发布了包括500项公共子集的任务架构、容器化工具包及数据集。"}}
{"id": "2602.00931", "pdf": "https://arxiv.org/pdf/2602.00931", "abs": "https://arxiv.org/abs/2602.00931", "authors": ["Muhammad Ahmed Mohsin", "Muhammad Umer", "Ahsan Bilal", "Zihao He", "Muhammad Usman Rafique", "Asad Aali", "Muhammad Ali Jamshed", "John M. Cioffi", "Emily Fox"], "title": "Continuous-Utility Direct Preference Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to ICML 2026", "summary": "Large language model reasoning is often treated as a monolithic capability, relying on binary preference supervision that fails to capture partial progress or fine-grained reasoning quality. We introduce Continuous Utility Direct Preference Optimization (CU-DPO), a framework that aligns models to a portfolio of prompt-based cognitive strategies by replacing binary labels with continuous scores that capture fine-grained reasoning quality. We prove that learning with K strategies yields a Theta(K log K) improvement in sample complexity over binary preferences, and that DPO converges to the entropy-regularized utility-maximizing policy. To exploit this signal, we propose a two-stage training pipeline: (i) strategy selection, which optimizes the model to choose the best strategy for a given problem via best-vs-all comparisons, and (ii) execution refinement, which trains the model to correctly execute the selected strategy using margin-stratified pairs. On mathematical reasoning benchmarks, CU-DPO improves strategy selection accuracy from 35-46 percent to 68-78 percent across seven base models, yielding consistent downstream reasoning gains of up to 6.6 points on in-distribution datasets with effective transfer to out-of-distribution tasks.", "AI": {"tldr": "本文介绍了CU-DPO框架，通过用连续得分替换二元标签来改进大型语言模型的推理能力。", "motivation": "传统的语言模型推理依赖于二元偏好监督，无法捕捉部分进展或细粒度的推理质量。因此，引入了CU-DPO框架以解决这一问题，提升模型的认知策略选择和执行准确性。", "method": "提出了一个两阶段训练流程：第一阶段通过最佳对比方法优化模型选择最合适的认知策略；第二阶段利用分层对子集进一步提高所选策略的执行精度。并证明学习K种策略可显著降低样本复杂度，且DPO能收敛到熵正则化的效用最大化策略。", "result": "在数学推理基准测试中，CU-DPO将七个基础模型的认知策略选择准确率从35%提升至68%，并在分布内数据集中获得最高达6.6点的下游推理收益，并有效转移到分布外任务上。", "conclusion": "CU-DPO框架通过连续偏好优化显著改进了大型语言模型的认知能力，提高了策略选择和执行精度。"}}
{"id": "2602.00929", "pdf": "https://arxiv.org/pdf/2602.00929", "abs": "https://arxiv.org/abs/2602.00929", "authors": ["Zergham Ahmed", "Kazuki Irie", "Joshua B. Tenenbaum", "Christopher J. Bates", "Samuel J. Gershman"], "title": "Learning Abstractions for Hierarchical Planning in Program-Synthesis Agents", "categories": ["cs.AI"], "comment": "20 pages", "summary": "Humans learn abstractions and use them to plan efficiently to quickly generalize across tasks -- an ability that remains challenging for state-of-the-art large language model (LLM) agents and deep reinforcement learning (RL) systems. Inspired by the cognitive science of how people form abstractions and intuitive theories of their world knowledge, Theory-Based RL (TBRL) systems, such as TheoryCoder, exhibit strong generalization through effective use of abstractions. However, they heavily rely on human-provided abstractions and sidestep the abstraction-learning problem. We introduce TheoryCoder-2, a new TBRL agent that leverages LLMs' in-context learning ability to actively learn reusable abstractions rather than relying on hand-specified ones, by synthesizing abstractions from experience and integrating them into a hierarchical planning process. We conduct experiments on diverse environments, including BabyAI, Minihack and VGDL games like Sokoban. We find that TheoryCoder-2 is significantly more sample-efficient than baseline LLM agents augmented with classical planning domain construction, reasoning-based planning, and prior program-synthesis agents such as WorldCoder. TheoryCoder-2 is able to solve complex tasks that the baselines fail, while only requiring minimal human prompts, unlike prior TBRL systems.", "AI": {"tldr": "介绍了一种新的基于理论的强化学习代理TheoryCoder-2，它利用大型语言模型的上下文学习能力来主动学习和重用抽象。", "motivation": "人类通过形成抽象并使用它们进行高效规划的能力在跨任务中快速泛化，这是最先进的大语言模型和深度强化学习系统难以实现的。现有的基于理论的RL代理依赖于人工指定的抽象。", "method": "TheoryCoder-2利用LLM的上下文学习能力从经验中合成抽象，并将这些抽象整合到分层规划过程中。", "result": "在BabyAI，Minihack和Sokoban等多样化环境中，相比于基线代理，TheoryCoder-2表现出更高的样本效率并能够解决更复杂的任务。", "conclusion": "通过学习可重用的抽象而不是依赖于人工指定的抽象，TheoryCoder-2展示了强大的泛化能力，并能够在少量的人工提示下完成复杂任务。"}}
{"id": "2602.00924", "pdf": "https://arxiv.org/pdf/2602.00924", "abs": "https://arxiv.org/abs/2602.00924", "authors": ["Ouns El Harzli", "Hugo Wallner", "Yoonsoo Nam", "Haixuan Xavier Tao"], "title": "Supervised sparse auto-encoders as unconstrained feature models for semantic composition", "categories": ["cs.AI"], "comment": null, "summary": "Sparse auto-encoders (SAEs) have re-emerged as a prominent method for mechanistic interpretability, yet they face two significant challenges: the non-smoothness of the $L_1$ penalty, which hinders reconstruction and scalability, and a lack of alignment between learned features and human semantics. In this paper, we address these limitations by adapting unconstrained feature models-a mathematical framework from neural collapse theory-and by supervising the task. We supervise (decoder-only) SAEs to reconstruct feature vectors by jointly learning sparse concept embeddings and decoder weights. Validated on Stable Diffusion 3.5, our approach demonstrates compositional generalization, successfully reconstructing images with concept combinations unseen during training, and enabling feature-level intervention for semantic image editing without prompt modification.", "AI": {"tldr": "本文提出了监督稀疏自编码器作为无约束特征模型的方法，解决了稀疏自编码器在重构和可扩展性方面的问题，并实现了语义图像编辑。", "motivation": "解决稀疏自编码器中存在的非平滑$L_1$惩罚导致的重构困难及学习到的特征与人类语义不匹配的问题", "method": "通过采用神经崩溃理论中的无约束特征模型框架并对任务进行监督，使解码器能够通过联合学习稀疏概念嵌入和解码权重来重建特征向量。", "result": "在Stable Diffusion 3.5上验证了该方法的有效性，展示了组合泛化能力并能对未见过的概念组合的图像进行重构。此外，还能实现在不修改提示的情况下进行语义级别的干预编辑。", "conclusion": "监督稀疏自编码器作为一种无约束特征模型的方法，在解决原始问题的基础上提供了更强大的功能，能够实现概念级重组和图像编辑任务。"}}
{"id": "2602.00923", "pdf": "https://arxiv.org/pdf/2602.00923", "abs": "https://arxiv.org/abs/2602.00923", "authors": ["Jincheng Wang", "Lingfan Bao", "Tong Yang", "Diego Martinez Plasencia", "Jianhao Jiao", "Dimitrios Kanoulas"], "title": "SanD-Planner: Sample-Efficient Diffusion Planner in B-Spline Space for Robust Local Navigation", "categories": ["cs.RO"], "comment": "Under review. 11 pages", "summary": "The challenge of generating reliable local plans has long hindered practical applications in highly cluttered and dynamic environments. Key fundamental bottlenecks include acquiring large-scale expert demonstrations across diverse scenes and improving learning efficiency with limited data. This paper proposes SanD-Planner, a sample-efficient diffusion-based local planner that conducts depth image-based imitation learning within the clamped B-spline space. By operating within this compact space, the proposed algorithm inherently yields smooth outputs with bounded prediction errors over local supports, naturally aligning with receding-horizon execution. Integration of an ESDF-based safety checker with explicit clearance and time-to-completion metrics further reduces the training burden associated with value-function learning for feasibility assessment. Experiments show that training with $500$ episodes (merely $0.25\\%$ of the demonstration scale used by the baseline), SanD-Planner achieves state-of-the-art performance on the evaluated open benchmark, attaining success rates of $90.1\\%$ in simulated cluttered environments and $72.0\\%$ in indoor simulations. The performance is further proven by demonstrating zero-shot transferability to realistic experimentation in both 2D and 3D scenes. The dataset and pre-trained models will also be open-sourced.", "AI": {"tldr": "SanD-Planner是一种样本高效的基于扩散的局部规划器，通过在B样条空间中进行深度图像基的模仿学习来提高复杂动态环境中的导航性能。", "motivation": "生成可靠的本地计划是长期以来阻碍实际应用的关键挑战。关键瓶颈在于获取大规模专家演示和使用有限数据提高学习效率。SanD-Planner旨在解决这些问题，通过在B样条空间中进行样本高效的扩散规划以应对高度混乱和动态环境中的导航需求。", "method": "SanD-Planner结合了深度图像基模仿学习与紧凑的B样条空间操作，自然地生成平滑输出，并使用ESDF安全检查器降低训练负担。该方法仅需500次演示即可达到最先进的性能。", "result": "实验表明，在模拟复杂环境中，SanD-Planner达到了90.1%的成功率；在室内模拟中成功率高达72%，并在现实场景中展示了零样本转移能力。", "conclusion": "通过B样条空间中的扩散规划和模仿学习，SanD-Planner实现了高效、可靠的局部导航方案，在复杂动态环境中表现出色，并具备强大的泛化能力。"}}
{"id": "2602.00919", "pdf": "https://arxiv.org/pdf/2602.00919", "abs": "https://arxiv.org/abs/2602.00919", "authors": ["I. Apanasevich", "M. Artemyev", "R. Babakyan", "P. Fedotova", "D. Grankin", "E. Kupryashin", "A. Misailidi", "D. Nerus", "A. Nutalapati", "G. Sidorov", "I. Efremov", "M. Gerasyov", "D. Pikurov", "Y. Senchenko", "S. Davidenko", "D. Kulikov", "M. Sultankin", "K. Askarbek", "O. Shamanin", "D. Statovoy", "E. Zalyaev", "I. Zorin", "A. Letkin", "E. Rusakov", "A. Silchenko", "et al. (3 additional authors not shown)"], "title": "Green-VLA: Staged Vision-Language-Action Model for Generalist Robots", "categories": ["cs.RO"], "comment": "22 pages, 14 figures", "summary": "We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency.", "AI": {"tldr": "介绍了一个名为Green-VLA的分阶段视觉语言动作框架，用于通用型机器人在现实世界中的部署。", "motivation": "旨在开发一个能够在不同身体结构下保持泛化的模型，并通过强化学习政策对齐来提高其性能和稳健性。", "method": "采用五阶段课程：基础VLMs、多模式接地、多体态预训练、特定体态适应，以及基于强化学习的政策对齐；结合大规模数据处理管道和统一的动作接口以支持不同类型的机器人控制，并在推断过程中加入进度预测、离群值检测等功能。", "result": "实验显示，在成功率、鲁棒性和长期效率方面有显著提升。", "conclusion": "Green-VLA框架能够在多种任务上实现优秀的泛化能力和性能，证明了其在通用型机器人应用中的潜力。"}}
{"id": "2602.00915", "pdf": "https://arxiv.org/pdf/2602.00915", "abs": "https://arxiv.org/abs/2602.00915", "authors": ["Zhiyuan Wu", "Xiangyu Zhang", "Zhuo Chen", "Jiankang Deng", "Rolandos Alexandros Potamias", "Shan Luo"], "title": "UniMorphGrasp: Diffusion Model with Morphology-Awareness for Cross-Embodiment Dexterous Grasp Generation", "categories": ["cs.RO"], "comment": null, "summary": "Cross-embodiment dexterous grasping aims to generate stable and diverse grasps for robotic hands with heterogeneous kinematic structures. Existing methods are often tailored to specific hand designs and fail to generalize to unseen hand morphologies outside the training distribution. To address these limitations, we propose \\textbf{UniMorphGrasp}, a diffusion-based framework that incorporates hand morphological information into the grasp generation process for unified cross-embodiment grasp synthesis. The proposed approach maps grasps from diverse robotic hands into a unified human-like canonical hand pose representation, providing a common space for learning. Grasp generation is then conditioned on structured representations of hand kinematics, encoded as graphs derived from hand configurations, together with object geometry. In addition, a loss function is introduced that exploits the hierarchical organization of hand kinematics to guide joint-level supervision. Extensive experiments demonstrate that UniMorphGrasp achieves state-of-the-art performance on existing dexterous grasp benchmarks and exhibits strong zero-shot generalization to previously unseen hand structures, enabling scalable and practical cross-embodiment grasp deployment.", "AI": {"tldr": "该论文提出了一种新的扩散模型UniMorphGrasp，旨在解决多形态机械手的抓取生成问题。", "motivation": "现有的方法往往只适用于特定的手部设计，无法泛化到训练分布之外的新手型结构。因此，需要一种能够统一处理不同形态手部抓取生成的方法。", "method": "该论文提出了一种基于扩散模型的方法UniMorphGrasp，它结合了手部的形态信息，在一个共同的空间中学习不同的机械手的抓握方式，并利用手部配置图和对象几何形状进行条件化生成。引入了一个损失函数来引导关节级别的监督。", "result": "实验结果表明，UniMorphGrasp在现有的灵巧抓取基准测试上取得了最先进的性能，并且对于未见过的手型结构具有很强的零样本泛化能力。", "conclusion": "该方法能够在不同手部形态之间实现通用的、可扩展和实用的抓取生成部署。"}}
{"id": "2602.00914", "pdf": "https://arxiv.org/pdf/2602.00914", "abs": "https://arxiv.org/abs/2602.00914", "authors": ["Víctor Yeste", "Rodrigo Rivas-Arévalo"], "title": "A Baseline Multimodal Approach to Emotion Recognition in Conversations", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.SD", "eess.AS"], "comment": "10 pages", "summary": "We present a lightweight multimodal baseline for emotion recognition in conversations using the SemEval-2024 Task 3 dataset built from the sitcom Friends. The goal of this report is not to propose a novel state-of-the-art method, but to document an accessible reference implementation that combines (i) a transformer-based text classifier and (ii) a self-supervised speech representation model, with a simple late-fusion ensemble. We report the baseline setup and empirical results obtained under a limited training protocol, highlighting when multimodal fusion improves over unimodal models. This preprint is provided for transparency and to support future, more rigorous comparisons.", "AI": {"tldr": "本文提出了一种轻量级的多模态基线方法，用于在《老友记》情景喜剧构建的数据集上进行对话中的情感识别。", "motivation": "为了提供一个易于实现的参考方案，并促进未来更严格的比较研究，文档结合了基于Transformer的文本分类器和自监督语音表示模型，采用简单的晚期融合集成。", "method": "使用了一个基于Transformer的文本分类器和一种自监督的语音表示模型，通过简单的晚期融合策略进行组合。该方法在SemEval-2024任务3数据集上进行了评估。", "result": "报道了基线设置下，在有限训练协议下的实验结果，并强调多模态融合相较于单模态模型改进的情况。", "conclusion": "提出了一种轻量级的多模态情感识别方法，该方法在对话中的情感识别任务中表现出了有效性，并提供了可比较的基础。"}}
{"id": "2602.00913", "pdf": "https://arxiv.org/pdf/2602.00913", "abs": "https://arxiv.org/abs/2602.00913", "authors": ["Víctor Yeste", "Paolo Rosso"], "title": "Do Schwartz Higher-Order Values Help Sentence-Level Human Value Detection? When Hard Gating Hurts", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Code: https://github.com/VictorMYeste/human-value-detection, 42 pages, 4 figures", "summary": "Sentence-level human value detection is typically framed as multi-label classification over Schwartz values, but it remains unclear whether Schwartz higher-order (HO) categories provide usable structure. We study this under a strict compute-frugal budget (single 8 GB GPU) on ValueEval'24 / ValuesML (74K English sentences). We compare (i) direct supervised transformers, (ii) HO$\\rightarrow$values pipelines that enforce the hierarchy with hard masks, and (iii) Presence$\\rightarrow$HO$\\rightarrow$values cascades, alongside low-cost add-ons (lexica, short context, topics), label-wise threshold tuning, small instruction-tuned LLM baselines ($\\le$10B), QLoRA, and simple ensembles. HO categories are learnable from single sentences (e.g., the easiest bipolar pair reaches Macro-$F_1\\approx0.58$), but hard hierarchical gating is not a reliable win: it often reduces end-task Macro-$F_1$ via error compounding and recall suppression. In contrast, label-wise threshold tuning is a high-leverage knob (up to $+0.05$ Macro-$F_1$), and small transformer ensembles provide the most consistent additional gains (up to $+0.02$ Macro-$F_1$). Small LLMs lag behind supervised encoders as stand-alone systems, yet can contribute complementary errors in cross-family ensembles. Overall, HO structure is useful descriptively, but enforcing it with hard gates hurts sentence-level value detection; robust improvements come from calibration and lightweight ensembling.", "AI": {"tldr": "研究Schwartz更高阶价值观在句子级人类价值检测中的作用，并评估不同方法的效果。", "motivation": "探索是否可以使用Schwartz更高阶值来进行有效的句子级别人类价值检测，同时限制计算预算，对比多种模型和策略的有效性。", "method": "比较直接监督的Transformer、带有硬掩码的HO至values管道以及Presence至HO至values级联。并加入词典、短上下文等低成本增益方法。", "result": "发现Schwartz更高阶值可以在单句学习中发挥作用，但严格的层次结构限制会降低检测性能。标签阈值调整和小规模Transformer集成能显著提升Macro-F1分数。", "conclusion": "Schwartz更高阶值在描述上是有用的，但在句子级别价值检测中强制使用硬门限会损害效果；校准策略和轻量级集成则能够带来稳健改进。"}}
{"id": "2602.00911", "pdf": "https://arxiv.org/pdf/2602.00911", "abs": "https://arxiv.org/abs/2602.00911", "authors": ["Abhijit Chakraborty", "Sandipan De", "Yash Shah", "Chahana Dahal", "Vivek Gupta"], "title": "Synapse Compendium Aware Federated Knowledge Exchange for Tool Routed LLMs", "categories": ["cs.AI"], "comment": null, "summary": "Collaborative learning among LLM-based agents under federated learning faces challenges, including communication costs, heterogeneity in data, and tool-usage, limiting their effectiveness. We introduce Synapse, a framework that trains a shared global knowledge model of tool-usage behavior. Client agents with fixed LLMs learn tool-usage patterns locally, and transmit artifacts for federated aggregation through coordinators. A global tool compendium is updated and redistributed, enabling convergence toward stable tool selection. Synapse uses templated representations, embedding retrieval with LLM reranking, and adaptive masking to maintain utility while limiting information leakage. The framework supports heterogeneous data and quantifies performance improvements. Results show that Synapse improves tool-usage effectiveness and reduces communication overhead compared with weight or prompt-sharing approaches in multi-agent LLM systems.", "AI": {"tldr": "介绍Synapse框架，用于多代理LLM系统中工具使用行为的联邦知识交换。", "motivation": "解决基于LLM的代理人协作学习中的通信成本高、数据异构和工具使用不一致的问题，提高系统的整体效果。", "method": "通过模板表示、嵌入检索与LLM重排序以及自适应屏蔽技术，在客户端代理中学习工具使用模式，并通过协调器进行联邦聚合。", "result": "结果显示Synapse提高了多代理人LLM系统中的工具使用效率并减少了通信开销，优于传统的权重或提示共享方法。", "conclusion": "该研究提出了一个有效的框架以解决协同训练的挑战，展示了在异构数据环境下改进工具使用的潜力。"}}
{"id": "2602.00906", "pdf": "https://arxiv.org/pdf/2602.00906", "abs": "https://arxiv.org/abs/2602.00906", "authors": ["Anxin Guo", "Jingwei Li"], "title": "Hallucination is a Consequence of Space-Optimality: A Rate-Distortion Theorem for Membership Testing", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DS", "cs.IT"], "comment": null, "summary": "Large language models often hallucinate with high confidence on \"random facts\" that lack inferable patterns. We formalize the memorization of such facts as a membership testing problem, unifying the discrete error metrics of Bloom filters with the continuous log-loss of LLMs. By analyzing this problem in the regime where facts are sparse in the universe of plausible claims, we establish a rate-distortion theorem: the optimal memory efficiency is characterized by the minimum KL divergence between score distributions on facts and non-facts. This theoretical framework provides a distinctive explanation for hallucination: even with optimal training, perfect data, and a simplified \"closed world\" setting, the information-theoretically optimal strategy under limited capacity is not to abstain or forget, but to assign high confidence to some non-facts, resulting in hallucination. We validate this theory empirically on synthetic data, showing that hallucinations persist as a natural consequence of lossy compression.", "AI": {"tldr": "本文通过分析大型语言模型在处理稀疏事实时的行为，提出了一种关于会员测试问题的信息理论框架，解释了为什么即使是在最优训练和简化设定下，也会出现幻觉。", "motivation": "研究大型语言模型为何会以高信心“创造”缺乏推理依据的事实，并试图通过信息论角度理解这一现象背后的原理。", "method": "将事实的记忆视为会员测试问题，结合Bloom过滤器的离散误差度量与LLM的连续对数损失，构建了一个理论框架来分析在稀疏事实环境下的最优存储效率。", "result": "证明了即使是在最佳训练条件下，大型语言模型也会由于容量限制而产生高信心错误回答，这实际上是信息丢失压缩的结果。", "conclusion": "通过合成数据验证理论发现，在有限的存储容量下，幻觉是作为优化存储的一种自然结果出现，而非仅仅是学习偏差或噪声所致。"}}
{"id": "2602.00904", "pdf": "https://arxiv.org/pdf/2602.00904", "abs": "https://arxiv.org/abs/2602.00904", "authors": ["Kunal Mahatha", "Ali Bahri", "Pierre Marza", "Sahar Dastani", "Maria Vakalopoulou", "Stergios Christodoulidis", "Jose Dolz", "Christian Desrosiers"], "title": "OCTOPUS: Enhancing the Spatial-Awareness of Vision SSMs with Multi-Dimensional Scans and Traversal Selection", "categories": ["cs.CV"], "comment": null, "summary": "State space models (SSMs) have recently emerged as an alternative to transformers due to their unique ability of modeling global relationships in text with linear complexity. However, their success in vision tasks has been limited due to their causal formulation, which is suitable for sequential text but detrimental in the spatial domain where causality breaks the inherent spatial relationships among pixels or patches. As a result, standard SSMs fail to capture local spatial coherence, often linking non-adjacent patches while ignoring neighboring ones that are visually correlated. To address these limitations, we introduce OCTOPUS , a novel architecture that preserves both global context and local spatial structure within images, while maintaining the linear complexity of SSMs. OCTOPUS performs discrete reoccurrence along eight principal orientations, going forward or backward in the horizontal, vertical, and diagonal directions, allowing effective information exchange across all spatially connected regions while maintaining independence among unrelated patches. This design enables multi-directional recurrence, capturing both global context and local spatial structure with SSM-level efficiency. In our classification and segmentation benchmarks, OCTOPUS demonstrates notable improvements in boundary preservation and region consistency, as evident from the segmentation results, while maintaining relatively better classification accuracy compared to existing V-SSM based models. These results suggest that OCTOPUS appears as a foundation method for multi-directional recurrence as a scalable and effective mechanism for building spatially aware and computationally efficient vision architectures.", "AI": {"tldr": "OCTOPUS是一种新型架构，旨在通过多维扫描和遍历选择增强视觉SSM的空间感知能力。", "motivation": "现有标准SSMs在处理视觉任务时由于其因果结构限制了对局部空间一致性的捕捉。因此，需要一种新方法来同时保持全局上下文和本地空间结构，并且具有线性复杂度的效率。", "method": "OCTOPUS通过沿着八个主要方向进行离散复发（向前或向后在水平、垂直以及斜对角方向），实现有效信息交换的同时确保无关区域间的独立性。这种设计支持多方向递归，捕捉全局上下文和局部空间结构，同时保持SSM级别的效率。", "result": "OCTOPUS在分类和分割基准测试中显示出显著改善的边界保持能力和区域一致性，并且与现有的基于V-SSM模型相比，维持了相对更好的分类准确性。", "conclusion": "结果表明，OCTOPUS作为一种基础方法对于构建具有空间感知能力且计算效率高的视觉架构是有潜力的。"}}
{"id": "2602.00888", "pdf": "https://arxiv.org/pdf/2602.00888", "abs": "https://arxiv.org/abs/2602.00888", "authors": ["Yingjie Niu", "Lanxin Lu", "Changhong Jin", "Ruihai Dong"], "title": "GAPNet: Plug-in Jointly Learning Task-Specific Graph for Dynamic Stock Relation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The advent of the web has led to a paradigm shift in the financial relations, with the real-time dissemination of news, social discourse, and financial filings contributing significantly to the reshaping of financial forecasting. The existing methods rely on establishing relations a priori, i.e. predefining graphs to capture inter-stock relationships. However, the stock-related web signals are characterised by high levels of noise, asynchrony, and challenging to obtain, resulting in poor generalisability and non-alignment between the predefined graphs and the downstream tasks. To address this, we propose GAPNet, a Graph Adaptation Plug-in Network that jointly learns task-specific topology and representations in an end-to-end manner. GAPNet attaches to existing pairwise graph or hypergraph backbone models, enabling the dynamic adaptation and rewiring of edge topologies via two complementary components: a Spatial Perception Layer that captures short-term co-movements across assets, and a Temporal Perception Layer that maintains long-term dependency under distribution shift. Across two real-world stock datasets, GAPNet has been shown to consistently enhance the profitability and stability in comparision to the state-of-the-art models, yielding annualised cumulative returns of up to 0.47 for RT-GCN and 0.63 for CI-STHPAN, with peak Sharpe Ratio of 2.20 and 2.12 respectively. The plug-and-play design of GAPNet ensures its broad applicability to diverse GNN-based architectures. Our results underscore that jointly learning graph structures and representations is essential for task-specific relational modeling.", "AI": {"tldr": "本文提出了一种名为GAPNet的插件网络，用于动态股票关系建模。", "motivation": "当前方法依赖于预先定义的图来捕捉股票之间的关系，但这些预定义的图与实际需求不符，导致性能不佳。因此需要一种能够适应和调整边拓扑的方法来解决这些问题。", "method": "GAPNet通过空间感知层和时间感知层联合学习任务特定的网络结构和表示，以动态地适应和重新连接现有的成对图形或超图形骨架模型。", "result": "在两个实际股票数据集上，GAPNet相比现有最佳模型表现出更高的稳定性和盈利能力，并且取得了较高的年度累积回报率。", "conclusion": "联合学习图结构和表示对于特定任务的关联建模至关重要。"}}
{"id": "2602.00887", "pdf": "https://arxiv.org/pdf/2602.00887", "abs": "https://arxiv.org/abs/2602.00887", "authors": ["Gaurav Srivastava", "Aafiya Hussain", "Chi Wang", "Yingyan Celine Lin", "Xuan Wang"], "title": "EffGen: Enabling Small Language Models as Capable Autonomous Agents", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Most existing language model agentic systems today are built and optimized for large language models (e.g., GPT, Claude, Gemini) via API calls. While powerful, this approach faces several limitations including high token costs and privacy concerns for sensitive applications. We introduce effGen, an open-source agentic framework optimized for small language models (SLMs) that enables effective, efficient, and secure local deployment (pip install effgen). effGen makes four major contributions: (1) Enhanced tool-calling with prompt optimization that compresses contexts by 70-80% while preserving task semantics, (2) Intelligent task decomposition that breaks complex queries into parallel or sequential subtasks based on dependencies, (3) Complexity-based routing using five factors to make smart pre-execution decisions, and (4) Unified memory system combining short-term, long-term, and vector-based storage. Additionally, effGen unifies multiple agent protocols (MCP, A2A, ACP) for cross-protocol communication. Results on 13 benchmarks show effGen outperforms LangChain, AutoGen, and Smolagents with higher success rates, faster execution, and lower memory. Our results reveal that prompt optimization and complexity routing have complementary scaling behavior: optimization benefits SLMs more (11.2% gain at 1.5B vs 2.4% at 32B), while routing benefits large models more (3.6% at 1.5B vs 7.9% at 32B), providing consistent gains across all scales when combined. effGen (https://effgen.org/) is released under the MIT License, ensuring broad accessibility for research and commercial use. Our framework code is publicly available at https://github.com/ctrl-gaurav/effGen.", "AI": {"tldr": "EffGen是一个为小型语言模型设计的代理框架，它通过优化提示、智能任务分解、复杂性路由和统一内存系统来提高小模型的有效性。", "motivation": "当前大多数语言模型代理系统依赖于大型语言模型并通过API调用实现，这种方法面临高成本和隐私风险。EffGen旨在解决这些问题，并为小型语言模型提供高效且安全的本地部署方案。", "method": "EffGen通过优化提示压缩上下文、智能任务分解、复杂性路由以及统一内存管理来提高代理系统的性能。它还支持多种代理协议之间的跨协议通信。", "result": "在13个基准测试中，EffGen的表现优于LangChain、AutoGen和Smolagents，在成功率、执行速度和内存使用方面均占优势。研究显示提示优化更有利于小型模型，而复杂性路由则对大型模型更有利。", "conclusion": "EffGen提供了一个高效的代理框架，适用于各种规模的语言模型，并且在开源许可下确保了广泛的可用性和适用性。"}}
{"id": "2602.00886", "pdf": "https://arxiv.org/pdf/2602.00886", "abs": "https://arxiv.org/abs/2602.00886", "authors": ["Amitesh Vatsa", "Zhixian Xie", "Wanxin Jin"], "title": "RoDiF: Robust Direct Fine-Tuning of Diffusion Policies with Corrupted Human Feedback", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Diffusion policies are a powerful paradigm for robotic control, but fine-tuning them with human preferences is fundamentally challenged by the multi-step structure of the denoising process. To overcome this, we introduce a Unified Markov Decision Process (MDP) formulation that coherently integrates the diffusion denoising chain with environmental dynamics, enabling reward-free Direct Preference Optimization (DPO) for diffusion policies. Building on this formulation, we propose RoDiF (Robust Direct Fine-Tuning), a method that explicitly addresses corrupted human preferences. RoDiF reinterprets the DPO objective through a geometric hypothesis-cutting perspective and employs a conservative cutting strategy to achieve robustness without assuming any specific noise distribution. Extensive experiments on long-horizon manipulation tasks show that RoDiF consistently outperforms state-of-the-art baselines, effectively steering pretrained diffusion policies of diverse architectures to human-preferred modes, while maintaining strong performance even under 30% corrupted preference labels.", "AI": {"tldr": "本文提出了RoDiF方法，用于通过受污染的人类反馈对扩散策略进行鲁棒的直接微调。", "motivation": "传统的扩散策略在与人类偏好结合时面临多步去噪过程中的挑战。为了克服这个问题，该研究旨在提出一种新的方法来处理被污染的人类反馈，从而提高机器人控制任务的效果。", "method": "提出了一个统一的马尔可夫决策过程（MDP）框架，将扩散降噪链和环境动力学结合在一起，并在此基础上引入了RoDiF方法。通过几何假设切割的方法以及保守的切割策略来实现对被污染的人类偏好的鲁棒处理。", "result": "实验表明，RoDiF在长时间段的操作任务中表现出色，即使有30%的偏好标签受到污染也能保持优异性能。", "conclusion": "RoDiF方法能够有效地将预训练的扩散策略引导到人类偏好模式，并且具有很强的抗干扰能力。"}}
{"id": "2602.00883", "pdf": "https://arxiv.org/pdf/2602.00883", "abs": "https://arxiv.org/abs/2602.00883", "authors": ["Alicja Polowczyk", "Agnieszka Polowczyk", "Piotr Borycki", "Joanna Waczyńska", "Jacek Tabor", "Przemysław Spurek"], "title": "DIAMOND: Directed Inference for Artifact Mitigation in Flow Matching Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Despite impressive results from recent text-to-image models like FLUX, visual and anatomical artifacts remain a significant hurdle for practical and professional use. Existing methods for artifact reduction, typically work in a post-hoc manner, consequently failing to intervene effectively during the core image formation process. Notably, current techniques require problematic and invasive modifications to the model weights, or depend on a computationally expensive and time-consuming process of regional refinement. To address these limitations, we propose DIAMOND, a training-free method that applies trajectory correction to mitigate artifacts during inference. By reconstructing an estimate of the clean sample at every step of the generative trajectory, DIAMOND actively steers the generation process away from latent states that lead to artifacts. Furthermore, we extend the proposed method to standard Diffusion Models, demonstrating that DIAMOND provides a robust, zero-shot path to high-fidelity, artifact-free image synthesis without the need for additional training or weight modifications in modern generative architectures. Code is available at https://gmum.github.io/DIAMOND/", "AI": {"tldr": "本文提出了一种无需额外训练或权重修改即可减少文本到图像生成模型中视觉和解剖学瑕疵的方法DIAMOND。", "motivation": "尽管最近的文本到图像模型取得了显著成果，但这些模型仍然存在视觉和解剖学瑕疵问题。现有的减少瑕疵方法通常是在生成后的修复，无法有效干预核心的图像生成过程，并且需要对模型权重进行侵入性修改或依赖耗时的区域细化。", "method": "DIAMOND是一种无需训练的方法，在推理过程中通过轨迹纠正来减少瑕疵。它在生成过程中的每一步重建一个干净样本的估计值，引导生成远离导致瑕疵的状态。", "result": "实验结果表明，DIAMOND能够有效减少现代生成架构中图像合成的视觉和解剖学瑕疵，并且不需要额外训练或权重修改。", "conclusion": "本文提出的DIAMOND方法为高保真、无瑕疵的图像合成提供了一种稳健的零样本解决方案。"}}
{"id": "2602.00880", "pdf": "https://arxiv.org/pdf/2602.00880", "abs": "https://arxiv.org/abs/2602.00880", "authors": ["Ailin Liu", "Yesmine Karoui", "Fiona Draxler", "Frauke Kreuter", "Francesco Chiossi"], "title": "Sensing What Surveys Miss: Understanding and Personalizing Proactive LLM Support by User Modeling", "categories": ["cs.HC"], "comment": "This manuscript has been accepted by CHI 2026", "summary": "Difficulty spillover and suboptimal help-seeking challenge the sequential, knowledge-intensive nature of digital tasks. In online surveys, tough questions can drain mental energy and hurt performance on later questions, while users often fail to recognize when they need assistance or may satisfy, lacking motivation to seek help. We developed a proactive, adaptive system using electrodermal activity and mouse movement to predict when respondents need support. Personalized classifiers with a rule-based threshold adaptation trigger timely LLM-based clarifications and explanations. In a within-subjects study (N=32), aligned-adaptive timing was compared to misaligned-adaptive and random-adaptive controls. Aligned-adaptive assistance improved response accuracy by 21%, reduced false negative rates from 50.9% to 22.9%, and improved perceived efficiency, dependability, and benevolence. Properly timed interventions prevent cascades of degraded responses, showing that aligning support with cognitive states improves both the outcomes and the user experience. This enables more effective, personalized LLM-assisted support in survey-based research.", "AI": {"tldr": "开发了一种利用生理信号和鼠标行为预测用户需求的主动适应系统，以提供个性化的LLM支持，改善在线调查中的回答准确性和用户体验。", "motivation": "解决数字任务中的困难溢出和次优求助问题，提高在线调查中用户的回答准确率和满意度。", "method": "通过电皮电阻和鼠标移动数据预测用户需求；使用个性化分类器与规则基线阈值调整触发LLM的澄清和解释；进行组内对照研究（N=32），比较了对齐适应、不对齐适应和随机适应控制策略的效果。", "result": "对齐适应的支持提高了回答准确率，降低了假阴性率，并改善了用户感知的有效性、可靠性和善意。适时干预可以防止负面效果的累积。", "conclusion": "这种个性化的LLM支持方法在在线调查中有效提升了用户的任务完成质量和体验感受，表明根据认知状态提供适当帮助的重要性。"}}
{"id": "2602.00877", "pdf": "https://arxiv.org/pdf/2602.00877", "abs": "https://arxiv.org/abs/2602.00877", "authors": ["Zhipeng Zhao", "Taimeng Fu", "Shaoshu Su", "Qiwei Du", "Ehsan Tarkesh Esfahani", "Karthik Dantu", "Souma Chowdhury", "Chen Wang"], "title": "Learning When to Jump for Off-road Navigation", "categories": ["cs.RO"], "comment": null, "summary": "Low speed does not always guarantee safety in off-road driving. For instance, crossing a ditch may be risky at a low speed due to the risk of getting stuck, yet safe at a higher speed with a controlled, accelerated jump. Achieving such behavior requires path planning that explicitly models complex motion dynamics, whereas existing methods often neglect this aspect and plan solely based on positions or a fixed velocity. To address this gap, we introduce Motion-aware Traversability (MAT) representation to explicitly model terrain cost conditioned on actual robot motion. Instead of assigning a single scalar score for traversability, MAT models each terrain region as a Gaussian function of velocity. During online planning, we decompose the terrain cost computation into two stages: (1) predict terrain-dependent Gaussian parameters from perception in a single forward pass, (2) efficiently update terrain costs for new velocities inferred from current dynamics by evaluating these functions without repeated inference. We develop a system that integrates MAT to enable agile off-road navigation and evaluate it in both simulated and real-world environments with various obstacles. Results show that MAT achieves real-time efficiency and enhances the performance of off-road navigation, reducing path detours by 75% while maintaining safety across challenging terrains.", "AI": {"tldr": "提出了基于运动感知的可通行性表示方法，用于提高越野导航的安全性和效率。", "motivation": "现有的路径规划方法通常只考虑位置或固定速度，忽视了复杂的运动动态模型，导致在特定环境下如穿越壕沟时存在安全隐患。因此，研究提出了一种新的地形成本计算方法来解决这个问题。", "method": "引入了运动感知的可通行性表示（MAT）框架，该框架将每个地形区域建模为与速度相关的高斯函数，并通过两阶段过程动态更新地形成本以适应实时规划需求。", "result": "实验表明，在模拟和实际环境中，所提出的方法能够有效减少路径绕行75%，同时保证了在各种复杂地形下的安全性。", "conclusion": "MAT方法实现了高效的越野导航性能提升，证明了运动感知建模对于提高机器人在非结构化环境中的行动能力的重要性。"}}
{"id": "2602.00874", "pdf": "https://arxiv.org/pdf/2602.00874", "abs": "https://arxiv.org/abs/2602.00874", "authors": ["Zhao Song", "Jianfei Xue", "Jiahao Zhang", "Lichen Zhang"], "title": "Sublinear Time Quantum Algorithm for Attention Approximation", "categories": ["quant-ph", "cs.DS", "cs.LG"], "comment": "ICLR 2026", "summary": "Given the query, key and value matrices $Q, K, V\\in \\mathbb{R}^{n\\times d}$, the attention module is defined as $\\mathrm{Att}(Q, K, V)=D^{-1}AV$ where $A=\\exp(QK^\\top/\\sqrt{d})$ with $\\exp(\\cdot)$ applied entrywise, $D=\\mathrm{diag}(A{\\bf 1}_n)$. The attention module is the backbone of modern transformers and large language models, but explicitly forming the softmax matrix $D^{-1}A$ incurs $Ω(n^2)$ time, motivating numerous approximation schemes that reduce runtime to $\\widetilde O(nd)$ via sparsity or low-rank factorization. We propose a quantum data structure that approximates any row of $\\mathrm{Att}(Q, K, V)$ using only row queries to $Q, K, V$. Our algorithm preprocesses these matrices in $\\widetilde{O}\\left( ε^{-1} n^{0.5} \\left( s_λ^{2.5} + s_λ^{1.5} d + α^{0.5} d \\right) \\right)$ time, where $ε$ is the target accuracy, $s_λ$ is the $λ$-statistical dimension of the exponential kernel defined by $Q$ and $K$, and $α$ measures the row distortion of $V$ that is at most $d/{\\rm srank}(V)$, the stable rank of $V$. Each row query can be answered in $\\widetilde{O}(s_λ^2 + s_λd)$ time. To our knowledge, this is the first quantum data structure that approximates rows of the attention matrix in sublinear time with respect to $n$. Our approach relies on a quantum Nyström approximation of the exponential kernel, quantum multivariate mean estimation for computing $D$, and quantum leverage score sampling for the multiplication with $V$.", "AI": {"tldr": "量子算法用于近似注意力机制的行，时间复杂度小于n", "motivation": "经典方法计算注意力模块的时间复杂度为Ω(n^2)，通过量子数据结构实现子线性时间近似以提高效率", "method": "利用量子Nyström近似、量子多元均值估计和量子杠杆采样技术来处理查询矩阵Q,键矩阵K,值矩阵V，从而在预处理后，每次行查询的时间复杂度为次线性的", "result": "算法在预处理时间O(ε^{-1} n^{0.5}(s_λ^{2.5}+s_λ^{1.5}d+α^{0.5}d))和查询时间O(s_λ^2+s_λd)内实现了对注意力矩阵行的近似", "conclusion": "首次提出了在子线性时间内实现量子数据结构来近似注意力机制行的方法，为大规模语言模型中的计算效率提供了新的可能"}}
{"id": "2602.00871", "pdf": "https://arxiv.org/pdf/2602.00871", "abs": "https://arxiv.org/abs/2602.00871", "authors": ["Hossein A. Rahmani", "Mengting Wan", "Pei Zhou", "Longqi Yang", "Nick Craswell", "Emine Yilmaz", "Sujay Kumar Jauhar"], "title": "Beyond Output Critique: Self-Correction via Task Distillation", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have shown promising self-correction abilities, where iterative refinement improves the quality of generated responses. However, most existing approaches operate at the level of output critique, patching surface errors while often failing to correct deeper reasoning flaws. We propose SELF-THOUGHT, a framework that introduces an intermediate step of task abstraction before solution refinement. Given an input and an initial response, the model first distills the task into a structured template that captures key variables, constraints, and problem structure. This abstraction then guides solution instantiation, grounding subsequent responses in a clearer understanding of the task and reducing error propagation. Crucially, we show that these abstractions can be transferred across models: templates generated by larger models can serve as structured guides for smaller LLMs, which typically struggle with intrinsic self-correction. By reusing distilled task structures, smaller models achieve more reliable refinements without heavy fine-tuning or reliance on external verifiers. Experiments across diverse reasoning tasks demonstrate that SELF-THOUGHT improves accuracy, robustness, and generalization for both large and small models, offering a scalable path toward more reliable self-correcting language systems.", "AI": {"tldr": "提出SELF-THOUGHT框架，通过任务蒸馏在输出修正之前引入结构化模板，以提高语言模型的自我纠错能力。", "motivation": "现有的方法通常只针对表面错误进行修补，而无法纠正深层次的问题。为了解决这一问题，提出了SELF-THOUGHT框架来改进大型语言模型的自我纠正性能。", "method": "SELF-THOUGHT框架包括两个阶段：首先将任务抽象成结构化模板；然后使用这个模板指导解决方案的具体化过程，减少错误传播，并且可以跨模型转移这些模板。", "result": "实验结果表明，SELF-THOUGHT能够提高大型和小型语言模型的准确性、鲁棒性和泛化能力。", "conclusion": "SELF-THOUGHT为构建更可靠的自我纠正系统提供了一种可扩展的方法。"}}
{"id": "2602.00869", "pdf": "https://arxiv.org/pdf/2602.00869", "abs": "https://arxiv.org/abs/2602.00869", "authors": ["Yuhao Huang", "Taos Transue", "Shih-Hsin Wang", "William Feldman", "Hong Zhang", "Bao Wang"], "title": "Improving Flow Matching by Aligning Flow Divergence", "categories": ["cs.LG", "cs.AI", "math.NA"], "comment": "Published in ICML 2025", "summary": "Conditional flow matching (CFM) stands out as an efficient, simulation-free approach for training flow-based generative models, achieving remarkable performance for data generation. However, CFM is insufficient to ensure accuracy in learning probability paths. In this paper, we introduce a new partial differential equation characterization for the error between the learned and exact probability paths, along with its solution. We show that the total variation gap between the two probability paths is bounded above by a combination of the CFM loss and an associated divergence loss. This theoretical insight leads to the design of a new objective function that simultaneously matches the flow and its divergence. Our new approach improves the performance of the flow-based generative model by a noticeable margin without sacrificing generation efficiency. We showcase the advantages of this enhanced training approach over CFM on several important benchmark tasks, including generative modeling for dynamical systems, DNA sequences, and videos. Code is available at \\href{https://github.com/Utah-Math-Data-Science/Flow_Div_Matching}{Utah-Math-Data-Science}.", "AI": {"tldr": "通过引入新的偏微分方程特性来表征学习的概率路径与精确概率路径之间的误差，并设计了一个新的目标函数，该函数同时匹配流及其散度，从而提高了基于流的生成模型的表现。", "motivation": "当前条件流动匹配（CFM）方法虽然在数据生成方面表现优异但不足以确保学习到的概率路径准确。因此作者希望通过引入新的理论框架来改进现有技术并提升模型性能。", "method": "首先建立了误差表征的偏微分方程模型，其次推导出两个概率路径之间的总变差差距与CFM损失和相关散度损失的关系，并提出一个新的目标函数以同时匹配流及其散度。", "result": "该方法在包括动态系统、DNA序列及视频等多个重要基准任务中显著提升了基于流的生成模型的表现，且未牺牲生成效率。", "conclusion": "新的训练方法通过引入理论上的误差表征和新的目标函数提高了基于流的生成模型的学习精度，在多个关键应用领域展示了其优越性。"}}
{"id": "2602.00868", "pdf": "https://arxiv.org/pdf/2602.00868", "abs": "https://arxiv.org/abs/2602.00868", "authors": ["Nikhil Uday Shinde", "Dylan Hirsch", "Michael C. Yip", "Sylvia Herbert"], "title": "Safe Stochastic Explorer: Enabling Safe Goal Driven Exploration in Stochastic Environments and Safe Interaction with Unknown Objects", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous robots operating in unstructured, safety-critical environments, from planetary exploration to warehouses and homes, must learn to safely navigate and interact with their surroundings despite limited prior knowledge. Current methods for safe control, such as Hamilton-Jacobi Reachability and Control Barrier Functions, assume known system dynamics. Meanwhile existing safe exploration techniques often fail to account for the unavoidable stochasticity inherent when operating in unknown real world environments, such as an exploratory rover skidding over an unseen surface or a household robot pushing around unmapped objects in a pantry. To address this critical gap, we propose Safe Stochastic Explorer (S.S.Explorer) a novel framework for safe, goal-driven exploration under stochastic dynamics. Our approach strategically balances safety and information gathering to reduce uncertainty about safety in the unknown environment. We employ Gaussian Processes to learn the unknown safety function online, leveraging their predictive uncertainty to guide information-gathering actions and provide probabilistic bounds on safety violations. We first present our method for discrete state space environments and then introduce a scalable relaxation to effectively extend this approach to continuous state spaces. Finally we demonstrate how this framework can be naturally applied to ensure safe physical interaction with multiple unknown objects. Extensive validation in simulation and demonstrative hardware experiments showcase the efficacy of our method, representing a step forward toward enabling reliable widespread robot autonomy in complex, uncertain environments.", "AI": {"tldr": "本文提出了一种称为Safe Stochastic Explorer (S.S.Explorer)的框架，用于在不确定环境中进行安全、目标导向探索。", "motivation": "当前的安全控制方法假定已知系统动力学，而现有的安全探索技术通常未能考虑未知真实环境中的固有随机性。为了解决这一关键缺口，本文提出了一种新的框架以适应随机动力学下的安全探索任务。", "method": "该研究利用高斯过程在线学习未知的安全函数，并通过预测不确定性引导信息获取行动，并提供对安全性违规的概率边界。首先提出了针对离散状态空间的方法，然后引入了可扩展的松弛方法来将此方法有效扩展到连续的状态空间中。", "result": "模拟和硬件实验验证展示了该方法的有效性，表明它可以自然应用于确保与多个未知对象的安全物理交互。", "conclusion": "本文提出的Safe Stochastic Explorer框架代表了一种向复杂、不确定环境中的可靠广泛机器人自主性的推进。"}}
{"id": "2602.00866", "pdf": "https://arxiv.org/pdf/2602.00866", "abs": "https://arxiv.org/abs/2602.00866", "authors": ["Akiharu Esashi", "Pawissanutt Lertpongrujikorn", "Justin Makino", "Yuibi Fujimoto", "Mohsen Amini Salehi"], "title": "Foundation CAN LM: A Pretrained Language Model For Automotive CAN Data", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "The Controller Area Network (CAN) bus provides a rich source of vehicular signals increasingly leveraged for applications in automotive and auto insurance domains, including collision detection, predictive maintenance, and driver risk modeling. Despite this potential, existing pipelines largely train isolated task-specific models on raw CAN data, with only limited efforts exploring decoded signals. Such fragmentation prevents shared representation learning and limits cross-task generalization. By contrast, natural language processing (NLP) and computer vision (CV) have been transformed by the foundation model paradigm: large-scale pretraining followed by task-specific adaptation. In this work, we introduce the foundation CAN model that demonstrates multi-objective downstream generalization using a single pretrained backbone. Our approach treats CAN data as a language: we pretrain on large-scale, unlabeled decoded CAN signals and fine-tune across heterogeneous auto insurance tasks. To enable this, we propose a unified tokenization scheme for mixed discrete-continuous signals and address challenges of temporal complexity and trip-specific variability. Our results show that one pretrained CAN model can adapt effectively to diverse predictive tasks, validating that the foundation modeling paradigm, proven in NLP and CV, also holds for CAN data. This establishes a new direction for generalizable representation learning in automotive AI.", "AI": {"tldr": "本文介绍了Foundation CAN LM模型，这是一种预训练的语言模型，用于处理汽车CAN数据，并展示了其在多个任务上的泛化能力。", "motivation": "现有方法主要针对原始的CAN数据进行孤立的任务特定建模，缺乏共享表示学习和跨任务泛化的潜力。通过将NLP和CV中的基础模型范式引入到CAN数据中来解决这些问题。", "method": "本文提出了一种统一的标记方案处理混合离散-连续信号，并解决了时间复杂性和行程特异性变化等问题。利用大规模未标注解码后的CAN信号进行预训练，然后在不同的保险任务上微调以实现多目标下游泛化。", "result": "实验结果表明一个预训练好的CAN模型可以有效地适应多种预测任务，验证了基础建模范式对CAN数据同样适用。", "conclusion": "该研究为汽车AI中的通用表示学习开辟了一个新的方向。"}}
{"id": "2602.00865", "pdf": "https://arxiv.org/pdf/2602.00865", "abs": "https://arxiv.org/abs/2602.00865", "authors": ["Brandon Leblanc", "Charalambos Poullis"], "title": "Distill3R: A Pipeline for Democratizing 3D Foundation Models on Commodity Hardware", "categories": ["cs.CV"], "comment": "Submitted to the Canadian Conference on Robotics and Vision (CRV). 10 pages, 5 figures", "summary": "While multi-view 3D reconstruction has shifted toward large-scale foundation models capable of inferring globally consistent geometry, their reliance on massive computational clusters for training has created a significant barrier to entry for most academic laboratories. To bridge this compute divide, we introduce Distill3R, a framework designed to distill the geometric reasoning of 3D foundation models into compact students fully trainable on a single workstation. Our methodology centers on two primary innovations: (1) an offline caching pipeline that decouples heavy teacher inference from the training loop through compressed supervision signals, and (2) a confidence-aware distillation loss that leverages teacher uncertainty to enable training on commodity hardware. We propose a 72M-parameter student model which achieves a 9x reduction in parameters and a 5x inference speedup compared to its 650M-parameter teacher. The student is fully trainable in under 3 days on a single workstation, whereas its teacher requires massive GPU clusters for up to a week. We demonstrate that the student preserves the structural consistency and qualitative geometric understanding required for functional 3D awareness. By providing a reproducible, single-workstation training recipe, Distill3R serves as an exploratory entry point for democratized 3D vision research and efficient edge deployment. This work is not intended to compete with state-of-the-art foundation models, but to provide an accessible research baseline for laboratories without access to large-scale compute to train and specialize models on their own domain-specific data at minimal cost.", "AI": {"tldr": "该论文提出了一种框架，将大规模多视图3D重建模型的知识迁移到可以在工作站上训练的小型学生模型中。", "motivation": "为了克服大型3D基础模型所需的大量计算资源所带来的障碍，作者开发了Distill3R，以使更多的实验室能够利用这些模型进行研究和应用。", "method": "该方法通过离线缓存管道和基于置信度的蒸馏损失来实现知识迁移，从而使得学生模型可以在工作站上快速训练。", "result": "实验结果表明，学生模型在参数量减少9倍的情况下仍能保持结构一致性和几何理解能力，并且在推理速度上提升了5倍。", "conclusion": "Distill3R通过提供一种易于实施的方案降低了进行3D视觉研究的门槛，为资源有限的研究实验室提供了新的机会。"}}
{"id": "2602.00862", "pdf": "https://arxiv.org/pdf/2602.00862", "abs": "https://arxiv.org/abs/2602.00862", "authors": ["Shih-Hsin Wang", "Yuhao Huang", "Taos Transue", "Justin Baker", "Jonathan Forstater", "Thomas Strohmer", "Bao Wang"], "title": "Towards Multiscale Graph-based Protein Learning with Geometric Secondary Structural Motifs", "categories": ["cs.LG", "cs.AI", "math.NA"], "comment": "Published in NeurIPS 2025", "summary": "Graph neural networks (GNNs) have emerged as powerful tools for learning protein structures by capturing spatial relationships at the residue level. However, existing GNN-based methods often face challenges in learning multiscale representations and modeling long-range dependencies efficiently. In this work, we propose an efficient multiscale graph-based learning framework tailored to proteins. Our proposed framework contains two crucial components: (1) It constructs a hierarchical graph representation comprising a collection of fine-grained subgraphs, each corresponding to a secondary structure motif (e.g., $α$-helices, $β$-strands, loops), and a single coarse-grained graph that connects these motifs based on their spatial arrangement and relative orientation. (2) It employs two GNNs for feature learning: the first operates within individual secondary motifs to capture local interactions, and the second models higher-level structural relationships across motifs. Our modular framework allows a flexible choice of GNN in each stage. Theoretically, we show that our hierarchical framework preserves the desired maximal expressiveness, ensuring no loss of critical structural information. Empirically, we demonstrate that integrating baseline GNNs into our multiscale framework remarkably improves prediction accuracy and reduces computational cost across various benchmarks.", "AI": {"tldr": "提出一种高效的多尺度图基蛋白质学习框架，以解决现有基于GNN的方法在学习多尺度表示和建模长距离依赖方面的挑战。", "motivation": "现有的基于GNN的方法难以有效学习多尺度表示和长距离依赖关系。", "method": "构建多层次的图表示，包括每个次级结构动机的细粒度子图集合和连接这些动机的空间安排与相对取向的单一粗粒度图，并使用两个GNN进行特征学习：第一个在各个二级动机内操作以捕获局部相互作用，第二个建模不同动机之间的高级别结构性关系。", "result": "理论证明框架保留了所需的最大表达能力；实验证明将基线GNN整合到多尺度框架中显著提高了预测准确性和减少了计算成本。", "conclusion": "所提出的方法在提高蛋白质结构学习的效率和准确性方面显示出巨大潜力。"}}
{"id": "2602.00861", "pdf": "https://arxiv.org/pdf/2602.00861", "abs": "https://arxiv.org/abs/2602.00861", "authors": ["Kushal Chakrabarti", "Nirmal Balachundar"], "title": "Multi-Head Attention Is a Multi-Player Game", "categories": ["cs.AI", "cs.CL", "cs.GT", "cs.LG"], "comment": null, "summary": "Modern transformer attention is internally multi-agent -- heads compete and coordinate -- yet we train it as if it were a monolithic optimizer. We formalize this gap: cross-entropy training induces an implicit potential game among heads, and gradient descent converges to Nash equilibria with potentially unbounded inefficiency due to unpriced externalities (redundancy, correlated errors). Our main result bounds the Price of Anarchy by $Γ(G)$, the off-diagonal mass of a head interaction matrix capturing weight and gradient coupling. Under mild smoothness assumptions, we prove that both \\emph{excess hallucination probability} and \\emph{excess head redundancy} scale with PoA, unifying two distinct failure modes into a single mechanism. The bound is prescriptive: regularization that reduces $Γ(G)$ provably tightens PoA. We instantiate this as GAME-LoRA, combining Barlow Twins decorrelation with log-determinant coordination pressure. Experiments validate the theory: $Γ(G)$ predicts hallucination ($p{<}0.05$), emergent coalitions exhibit selective coordination, and GAME-LoRA achieves up to 18\\% hallucination reduction (8\\% average) with no knowledge degradation -- a Pareto improvement inaccessible to methods ignoring the game structure.", "AI": {"tldr": "本文研究了现代变压器注意力机制中多头之间的竞争与协作，并提出了GAME-LoRA方法以减少幻觉并提高效率。", "motivation": "在现代变压器模型中，虽然存在多个头部相互作用的竞争和协作关系，但它们通常被视为单一的优化器进行训练。这种训练方式可能导致低效性和冗余，因此研究如何改善这一情况具有重要意义。", "method": "作者通过理论分析指出了多头注意力机制中的潜在博弈问题，并提出了GAME-LoRA方法来解决这些问题，该方法结合了Barlow Twins去相关技术和基于行列式的协调压力技术以减少幻觉和冗余。", "result": "实验结果验证了GAME-LoRA的有效性，在不降低知识的情况下实现了高达18%的幻觉减少率，并且证明Γ(G)可以预测幻觉的发生，显示出该方法在理论上的可行性。", "conclusion": "本文通过揭示多头注意力机制中的潜在博弈问题并提出解决方法展示了改善现代变压器模型性能的新途径。"}}
{"id": "2602.00854", "pdf": "https://arxiv.org/pdf/2602.00854", "abs": "https://arxiv.org/abs/2602.00854", "authors": ["Fangzhou Lin", "Qianwen Ge", "Lingyu Xu", "Peiran Li", "Xiangbo Gao", "Shuo Xing", "Kazunori Yamada", "Ziming Zhang", "Haichong Zhang", "Zhengzhong Tu"], "title": "Position: Human-Centric AI Requires a Minimum Viable Level of Human Understanding", "categories": ["cs.AI"], "comment": "14 pages, 1 figures", "summary": "AI systems increasingly produce fluent, correct, end-to-end outcomes. Over time, this erodes users' ability to explain, verify, or intervene. We define this divergence as the Capability-Comprehension Gap: a decoupling where assisted performance improves while users' internal models deteriorate. This paper argues that prevailing approaches to transparency, user control, literacy, and governance do not define the foundational understanding humans must retain for oversight under sustained AI delegation. To formalize this, we define the Cognitive Integrity Threshold (CIT) as the minimum comprehension required to preserve oversight, autonomy, and accountable participation under AI assistance. CIT does not require full reasoning reconstruction, nor does it constrain automation. It identifies the threshold beyond which oversight becomes procedural and contestability fails. We operatinalize CIT through three functional dimensions: (i) verification capacity, (ii) comprehension-preserving interaction, and (iii) institutional scaffolds for governance. This motivates a design and governance agenda that aligns human-AI interaction with cognitive sustainability in responsibility-critical settings.", "AI": {"tldr": "定义了认知完整性阈值（CIT），以确保在人工智能辅助下的人类理解和监督能力。", "motivation": "随着AI系统的性能提高，用户解释、验证或干预的能力下降，产生了能力和理解之间的差距。现有方法不足以保证人类的基础理解力。", "method": "提出了认知完整性阈值（CIT）的概念，并通过三个功能性维度来操作化：验证能力、保持理解的交互和治理机构支撑。", "result": "为在责任关键领域的人机互动设计了基于认知可持续性的议程。", "conclusion": "人类需要至少达到认知完整性阈值，才能维持在AI辅助下的监督、自主权和负责任参与。"}}
{"id": "2602.00851", "pdf": "https://arxiv.org/pdf/2602.00851", "abs": "https://arxiv.org/abs/2602.00851", "authors": ["Hyejun Jeong", "Amir Houmansadr", "Shlomo Zilberstein", "Eugene Bagdasarian"], "title": "Persuasion Propagation in LLM Agents", "categories": ["cs.AI", "cs.MA"], "comment": "Code available at https://github.com/HyejunJeong/persuasion-propagation", "summary": "Modern AI agents increasingly combine conversational interaction with autonomous task execution, such as coding and web research, raising a natural question: what happens when an agent engaged in long-horizon tasks is subjected to user persuasion? We study how belief-level intervention can influence downstream task behavior, a phenomenon we name \\emph{persuasion propagation}. We introduce a behavior-centered evaluation framework that distinguishes between persuasion applied during or prior to task execution. Across web research and coding tasks, we find that on-the-fly persuasion induces weak and inconsistent behavioral effects. In contrast, when the belief state is explicitly specified at task time, belief-prefilled agents conduct on average 26.9\\% fewer searches and visit 16.9\\% fewer unique sources than neutral-prefilled agents. These results suggest that persuasion, even in prior interaction, can affect the agent's behavior, motivating behavior-level evaluation in agentic systems.", "AI": {"tldr": "研究在AI代理执行任务时用户说服的影响，探讨信念干预如何影响后续行为。", "motivation": "随着现代AI代理结合了对话交互和自主任务执行的能力增强，研究用户说服对长期任务执行过程中代理行为的影响变得尤为重要。这有助于理解代理系统中的信念与行为之间的关系，并指导未来的设计。", "method": "引入了一个基于行为的评估框架来区分任务执行过程中的即时说服与提前设定的信念状态的影响。通过网络调研和编码任务进行实验，对比即时说服和预先填充特定信念状态下代理的行为差异。", "result": "在即时说服的情况下，发现其对代理行为影响较弱且不一致；然而，在明确指定信念的状态下启动任务时，发现相信状态被预填的代理比中立状态下的代理执行搜索次数减少26.9%，访问的独特来源数量减少了16.9%。", "conclusion": "研究结果表明，即使是在预先交互中的说服也会显著影响AI代理的行为。这突显了在代理系统评估时需要关注行为层面的效果，并为未来的研究和应用提供了方向。"}}
{"id": "2602.00849", "pdf": "https://arxiv.org/pdf/2602.00849", "abs": "https://arxiv.org/abs/2602.00849", "authors": ["Yuhao Huang", "Shih-Hsin Wang", "Andrea L. Bertozzi", "Bao Wang"], "title": "RMFlow: Refined Mean Flow by a Noise-Injection Step for Multimodal Generation", "categories": ["cs.LG", "cs.AI", "math.NA"], "comment": "Accepted to ICLR 2026", "summary": "Mean flow (MeanFlow) enables efficient, high-fidelity image generation, yet its single-function evaluation (1-NFE) generation often cannot yield compelling results. We address this issue by introducing RMFlow, an efficient multimodal generative model that integrates a coarse 1-NFE MeanFlow transport with a subsequent tailored noise-injection refinement step. RMFlow approximates the average velocity of the flow path using a neural network trained with a new loss function that balances minimizing the Wasserstein distance between probability paths and maximizing sample likelihood. RMFlow achieves near state-of-the-art results on text-to-image, context-to-molecule, and time-series generation using only 1-NFE, at a computational cost comparable to the baseline MeanFlows.", "AI": {"tldr": "RMFlow通过加入噪声注入细化步骤改进了MeanFlow模型，使其在多模态生成任务中表现更佳。", "motivation": "解决单次功能评估（1-NFE）生成结果不佳的问题，提高图像生成的多样性和质量。", "method": "引入了一个新的损失函数来平衡Wasserstein距离和样本似然性，结合粗略的1-NFE MeanFlow传输与后续定制化的噪声注入细化步骤。", "result": "在文本到图像、上下文到分子以及时间序列生成任务中取得了接近当前最佳的结果，且计算成本与基线MeanFlows相当。", "conclusion": "RMFlow通过改进生成过程中的优化步骤，在保持效率的同时显著提高了生成结果的质量和多样性。"}}
{"id": "2602.00848", "pdf": "https://arxiv.org/pdf/2602.00848", "abs": "https://arxiv.org/abs/2602.00848", "authors": ["Ziwei Gong", "Yanda Chen", "Julia Hirschberg", "Chen Zhao", "He He", "Zhou Yu", "Kathleen Mckeown"], "title": "Factuality on Demand: Controlling the Factuality-Informativeness Trade-off in Text Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) encode knowledge with varying degrees of confidence. When responding to queries, models face an inherent trade-off: they can generate responses that are less informative but highly factual, or more informative but potentially less accurate. Different applications demand different balances between informativeness and factuality. We introduce Factuality-Controlled Generation (FCG), a framework that enables users to specify factuality constraints alongside their queries. We propose to evaluate FCG performance on two dimensions: adherence to factuality constraints and response informativeness. We propose to train models on the FCG task using synthetic data, and show that our synthetic training significantly improves models' ability to both respect factuality requirements and maintain informativeness in their outputs.", "AI": {"tldr": "介绍了一种控制文本生成中事实性和信息量权衡的框架Factuality-Controlled Generation (FCG)，允许用户根据需求调整生成内容的事实性。", "motivation": "大型语言模型在回应查询时，面临一个内在的权衡：可以产生高度准确但不那么详细的信息，或者更具信息量但可能不太准确的内容。不同应用场景对事实性和信息性的要求各不相同。", "method": "提出了一种框架Factuality-Controlled Generation (FCG)，允许用户在提交请求时指定事实性约束。通过合成数据训练模型以同时提高响应的事实性和信息量。", "result": "实验表明，该方法显著提高了模型遵守事实性需求并保持输出信息的能力。", "conclusion": "研究成功地开发了一个框架，可以灵活控制文本生成中的事实性和信息量之间的平衡，满足不同应用的需求。"}}
{"id": "2602.00845", "pdf": "https://arxiv.org/pdf/2602.00845", "abs": "https://arxiv.org/abs/2602.00845", "authors": ["Senkang Hu", "Yong Dai", "Yuzhi Zhao", "Yihang Tao", "Yu Guo", "Zhengru Fang", "Sam Tak Wu Kwong", "Yuguang Fang"], "title": "Optimizing Agentic Reasoning with Retrieval via Synthetic Semantic Information Gain Reward", "categories": ["cs.AI"], "comment": null, "summary": "Agentic reasoning enables large reasoning models (LRMs) to dynamically acquire external knowledge, but yet optimizing the retrieval process remains challenging due to the lack of dense, principled reward signals. In this paper, we introduce InfoReasoner, a unified framework that incentivizes effective information seeking via a synthetic semantic information gain reward. Theoretically, we redefine information gain as uncertainty reduction over the model's belief states, establishing guarantees, including non-negativity, telescoping additivity, and channel monotonicity. Practically, to enable scalable optimization without manual retrieval annotations, we propose an output-aware intrinsic estimator that computes information gain directly from the model's output distributions using semantic clustering via bidirectional textual entailment. This intrinsic reward guides the policy to maximize epistemic progress, enabling efficient training via Group Relative Policy Optimxization (GRPO). Experiments across seven question-answering benchmarks demonstrate that InfoReasoner consistently outperforms strong retrieval-augmented baselines, achieving up to 5.4% average accuracy improvement. Our work provides a theoretically grounded and scalable path toward agentic reasoning with retrieval.", "AI": {"tldr": "介绍InfoReasoner框架，通过合成语义信息增益奖励优化大型推理模型的检索过程。", "motivation": "现有大型推理模型在动态获取外部知识时仍面临检索优化难题，因为缺乏稠密且原理明确的奖励信号。", "method": "重新定义信息增益为模型信念状态下的不确定性减少，并提出一个基于双向文本蕴含语义聚类的输出感知内在估计器来计算信息增益，以此引导策略最大化认识进步。", "result": "在七个问答基准上进行实验，InfoReasoner相比检索增强基线表现出色，平均准确率提高了5.4%。", "conclusion": "为实现具有检索功能的代理推理提供了一条理论基础坚实且可扩展的道路。"}}
{"id": "2602.00843", "pdf": "https://arxiv.org/pdf/2602.00843", "abs": "https://arxiv.org/abs/2602.00843", "authors": ["Claude Carlet", "Marko Ðurasevic", "Ermes Franch", "Domagoj Jakobovic", "Luca Mariot", "Stjepan Picek"], "title": "NegaBent, No Regrets: Evolving Spectrally Flat Boolean Functions", "categories": ["cs.NE", "cs.CR"], "comment": "9 pages, 2 figures", "summary": "Negabent Boolean functions are defined by having a flat magnitude spectrum under the nega-Hadamard transform. They exist in both even and odd dimensions, and the subclass of functions that are simultaneously bent and negabent (bent-negabent) has attracted interest due to the combined optimal periodic and negaperiodic spectral properties. In this work, we investigate how evolutionary algorithms can be used to evolve (bent-)negabent Boolean functions. Our experimental results indicate that evolutionary algorithms, especially genetic programming, are a suitable approach for evolving negabent Boolean functions, and we successfully evolve such functions in all dimensions we consider.", "AI": {"tldr": "该论文研究了如何使用进化算法生成具有平坦频谱特性的布尔函数。", "motivation": "研究目的是探索通过进化算法来演化同时具备最优周期和非周期谱特性（即bent-negabent）的布尔函数。", "method": "采用遗传编程等进化算法，实验性地验证其对生成negabent布尔函数的有效性。", "result": "实验证明，特别是在所有考虑过的维度中成功演化出了negabent布尔函数。", "conclusion": "表明了使用进化算法特别是遗传程序来演化（bent-）negabent布尔函数是有效的方法。"}}
{"id": "2602.00841", "pdf": "https://arxiv.org/pdf/2602.00841", "abs": "https://arxiv.org/abs/2602.00841", "authors": ["Jintao Cheng", "Weibin Li", "Zhijian He", "Jin Wu", "Chi Man Vong", "Wei Zhang"], "title": "Invariance on Manifolds: Understanding Robust Visual Representations for Place Recognition", "categories": ["cs.CV"], "comment": "14pages, 5 figures", "summary": "Visual Place Recognition (VPR) demands representations robust to drastic environmental and viewpoint shifts. Current aggregation paradigms, however, either rely on data-hungry supervision or simplistic first-order statistics, often neglecting intrinsic structural correlations. In this work, we propose a Second-Order Geometric Statistics framework that inherently captures geometric stability without training. We conceptualize scenes as covariance descriptors on the Symmetric Positive Definite (SPD) manifold, where perturbations manifest as tractable congruence transformations. By leveraging geometry-aware Riemannian mappings, we project these descriptors into a linearized Euclidean embedding, effectively decoupling signal structure from noise. Our approach introduces a training-free framework built upon fixed, pre-trained backbones, achieving strong zero-shot generalization without parameter updates. Extensive experiments confirm that our method achieves highly competitive performance against state-of-the-art baselines, particularly excelling in challenging zero-shot scenarios.", "AI": {"tldr": "本文提出了一种基于SPD流形的二次几何统计框架，用于视觉位置识别（VPR），以增强对环境和视角变化的鲁棒性。", "motivation": "现有的聚合范式依赖于大量监督数据或过于简单的统计方法，忽略了内在结构相关性。为了实现无需训练即可捕获几何稳定性的表示方式，提出了新的方案。", "method": "本文通过将场景概念化为SPD流形上的协方差描述符，并利用黎曼映射投影到线性化的欧几里得嵌入中，实现了对信号结构和噪声的有效解耦。该方法基于固定预训练的主干模型，在无需参数更新的情况下实现零样本泛化。", "result": "实验结果显示，所提方法在各种环境下都表现出色，特别是在挑战性的零样本场景下优于最先进的基线方法。", "conclusion": "本文提出了一种无监督、几何感知的方法来增强视觉位置识别的鲁棒性，在复杂和变化环境中取得了优异的结果。"}}
{"id": "2602.00839", "pdf": "https://arxiv.org/pdf/2602.00839", "abs": "https://arxiv.org/abs/2602.00839", "authors": ["Mingwei Li", "Hehe Fan", "Yi Yang"], "title": "TransNormal: Dense Visual Semantics for Diffusion-based Transparent Object Normal Estimation", "categories": ["cs.CV"], "comment": "Project Page: https://longxiang-ai.github.io/TransNormal", "summary": "Monocular normal estimation for transparent objects is critical for laboratory automation, yet it remains challenging due to complex light refraction and reflection. These optical properties often lead to catastrophic failures in conventional depth and normal sensors, hindering the deployment of embodied AI in scientific environments. We propose TransNormal, a novel framework that adapts pre-trained diffusion priors for single-step normal regression. To handle the lack of texture in transparent surfaces, TransNormal integrates dense visual semantics from DINOv3 via a cross-attention mechanism, providing strong geometric cues. Furthermore, we employ a multi-task learning objective and wavelet-based regularization to ensure the preservation of fine-grained structural details. To support this task, we introduce TransNormal-Synthetic, a physics-based dataset with high-fidelity normal maps for transparent labware. Extensive experiments demonstrate that TransNormal significantly outperforms state-of-the-art methods: on the ClearGrasp benchmark, it reduces mean error by 24.4% and improves 11.25° accuracy by 22.8%; on ClearPose, it achieves a 15.2% reduction in mean error. The code and dataset will be made publicly available at https://longxiang-ai.github.io/TransNormal.", "AI": {"tldr": "该论文提出了TransNormal框架，用于单目透明物体法线估计。通过使用预训练的扩散先验和密集视觉语义来改进单一步骤的正常回归。", "motivation": "在实验室自动化中进行透明物体的单目法线估计是关键的，但由于复杂的光线折射和反射现象，这一任务仍然具有挑战性。传统的深度和法线传感器在这种情况下常出现灾难性的失败，阻碍了嵌入式人工智能的应用。", "method": "TransNormal框架利用预训练的扩散先验进行单一步骤正常回归，并通过DINOv3提供的密集视觉语义来增强几何线索；采用多任务学习目标以及波浪基正则化以确保细粒度结构细节的保留。为了支持这项工作，引入了基于物理的高保真法线图数据集TransNormal-Synthetic。", "result": "实验结果表明，与现有最佳方法相比，TransNormal框架在ClearGrasp基准测试中将平均误差减少了24.4%，11.25°精度提高了22.8%；在ClearPose上实现了15.2%的平均误差减少。", "conclusion": "该研究通过提出TransNormal框架解决了透明物体单目法线估计的挑战，展示了比现有方法更优的效果，并计划公开发布代码和数据集。"}}
{"id": "2602.00838", "pdf": "https://arxiv.org/pdf/2602.00838", "abs": "https://arxiv.org/abs/2602.00838", "authors": ["Prabhu Vellaisamy", "Harideep Nair", "Di Wu", "Shawn Blanton", "John Paul Shen"], "title": "Exploration of Unary Arithmetic-Based Matrix Multiply Units for Low Precision DL Accelerators", "categories": ["cs.AR", "cs.AI"], "comment": "ef:2024 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)", "summary": "General matrix multiplication (GEMM) is a fundamental operation in deep learning (DL). With DL moving increasingly toward low precision, recent works have proposed novel unary GEMM designs as an alternative to conventional binary GEMM hardware. A rigorous evaluation of recent unary and binary GEMM designs is needed to assess the potential of unary hardware for future DL compute. This paper focuses on unary GEMM designs for integer-based DL inference and performs a detailed evaluation of three latest unary design proposals, namely, uGEMM, tuGEMM and tubGEMM, by comparing them to a conventional binary GEMM. Rigorous post-synthesis evaluations beyond prior works are performed across varying bit-widths and matrix sizes to assess the designs' tradeoffs and determine optimal sweetspots. Further, we perform weight sparsity analysis across eight pretrained convolutional neural networks (CNNs) and the LLaMA2 large language model (LLM). In this work, we demonstrate how unary GEMM can be effectively used for energy-efficient compute in future edge AI accelerators.", "AI": {"tldr": "本文研究了用于低精度深度学习加速器的一元算术矩阵乘法单元的设计，评估了一元GEMM在不同位宽和矩阵大小下的性能。", "motivation": "随着深度学习向低精度发展，一元GEMM作为传统二元GEMM硬件的替代方案受到关注。为了评估一元硬件在未来深度学习计算中的潜力，本文对比了三种最新的一元设计与传统的二元GEMM。", "method": "该研究详细评价了三个最近的一元设计方案（uGEMM、tuGEMM和tubGEMM），通过后综合评估在不同位宽和矩阵大小下的性能，并对八个预训练的卷积神经网络及LLaMA2大型语言模型进行了权重稀疏性分析。", "result": "研究发现了一元GEMM设计在低精度深度学习推理中的优势，特别是在能效方面表现出色。通过详细比较不同设计方案，确定了最佳配置和权衡点。", "conclusion": "本文展示了如何利用一元GEMM进行未来边缘AI加速器的节能计算，并为深度学习硬件设计提供了新的思路。"}}
{"id": "2602.00837", "pdf": "https://arxiv.org/pdf/2602.00837", "abs": "https://arxiv.org/abs/2602.00837", "authors": ["Claude Carlet", "Marko Ðurasevic", "Domagoj Jakobovic", "Luca Mariot", "Stjepan Picek"], "title": "IDEM Enough? Evolving Highly Nonlinear Idempotent Boolean Functions", "categories": ["cs.CR", "cs.NE"], "comment": "20 pages, 6 figures, 2 tables", "summary": "Idempotent Boolean functions form a highly structured subclass of Boolean functions that is closely related to rotation symmetry under a normal-basis representation and to invariance under a fixed linear map in a polynomial basis. These functions are attractive as candidates for cryptographic design, yet their additional algebraic constraints make the search for high nonlinearity substantially more difficult than in the unconstrained case. In this work, we investigate evolutionary methods for constructing highly nonlinear idempotent Boolean functions for dimensions $n=5$ up to $n=12$ using a polynomial basis representation with canonical primitive polynomials. Our results show that the problem of evolving idempotent functions is difficult due to the disruptive nature of crossover and mutation operators. Next, we show that idempotence can be enforced by encoding the truth table on orbits, yielding a compact genome of size equal to the number of distinct squaring orbits.", "AI": {"tldr": "研究如何使用演化方法构造高非线性的幂等布尔函数。", "motivation": "幂等布尔函数作为密码设计的候选者具有吸引力，但其额外的代数约束使得寻找高非线性问题变得更加困难。", "method": "采用多项式基表示法和典型原根多项式来构建维度从n=5到n=12的高度非线性的幂等布尔函数，并通过轨道编码确保幂等性质。", "result": "结果显示演化幂等函数的问题具有挑战性，因为交叉覆盖和变异操作具有破坏性。使用轨道编码可以有效地强制实施幂等属性。", "conclusion": "演化方法在构造高度非线性的幂等布尔函数方面遇到了困难，但通过适当的编码策略能够提高效率并找到有效的解。"}}
{"id": "2602.00834", "pdf": "https://arxiv.org/pdf/2602.00834", "abs": "https://arxiv.org/abs/2602.00834", "authors": ["Wei Chen", "Jiacheng Li", "Shigui Li", "Zhiqi Lin", "Junmei Yang", "John Paisley", "Delu Zeng"], "title": "Don't Forget Its Variance! The Minimum Path Variance Principle for Accurate and Stable Score-Based Density Ratio Estimation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "ef:The Fourteenth International Conference on Learning Representations,2026", "summary": "Score-based methods have emerged as a powerful framework for density ratio estimation (DRE), but they face an important paradox in that, while theoretically path-independent, their practical performance depends critically on the chosen path schedule. We resolve this issue by proving that tractable training objectives differ from the ideal, ground-truth objective by a crucial, overlooked term: the path variance of the time score. To address this, we propose MinPV (\\textbf{Min}imum \\textbf{P}ath \\textbf{V}ariance) Principle, which introduces a principled heuristic to minimize the overlooked path variance. Our key contribution is the derivation of a closed-form expression for the variance, turning an intractable problem into a tractable optimization. By parameterizing the path with a flexible Kumaraswamy Mixture Model, our method learns a data-adaptive, low-variance path without heuristic selection. This principled optimization of the complete objective yields more accurate and stable estimators, establishing new state-of-the-art results on challenging benchmarks.", "AI": {"tldr": "论文提出了最小路径方差原理，用于解决分数基于密度比估计中的路径依赖性问题。", "motivation": "理论证明了可训练目标函数与理想目标存在关键的路径方差项差异。为了解决这一问题，引入了一种新的方法来优化路径选择以减少方差。", "method": "提出最小路径方差（MinPV）原则，利用Kumaraswamy混合模型参数化路径，从而实现数据自适应且低方差的路径学习。", "result": "通过这种方法的学习，获得了更准确和稳定的估计器，在挑战性基准测试中取得了新的最先进结果。", "conclusion": "最小路径方差原理解决了分数基于密度比估计中的路径依赖问题，并提高了估计精度和稳定性。"}}
{"id": "2602.00823", "pdf": "https://arxiv.org/pdf/2602.00823", "abs": "https://arxiv.org/abs/2602.00823", "authors": ["Spyridon Syntakas", "Kostas Vlachos"], "title": "Ocean Current-Harnessing Stage-Gated MPC: Monotone Cost Shaping and Speed-to-Fly for Energy-Efficient AUV Navigation", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "Autonomous Underwater Vehicles (AUVs) are a highly promising technology for ocean exploration and diverse offshore operations, yet their practical deployment is constrained by energy efficiency and endurance. To address this, we propose Current-Harnessing Stage-Gated MPC, which exploits ocean currents via a per-stage scalar which indicates the \"helpfulness\" of ocean currents. This scalar is computed along the prediction horizon to gate lightweight cost terms only where the ocean currents truly aids the control goal. The proposed cost terms, that are merged in the objective function, are (i) a Monotone Cost Shaping (MCS) term, a help-gated, non-worsening modification that relaxes along-track position error and provides a bounded translational energy rebate, guaranteeing the shaped objective is never larger than a set baseline, and (ii) a speed-to-fly (STF) cost component that increases the price of thrust and softly matches ground velocity to the ocean current, enabling near zero water-relative \"gliding\". All terms are C1 and integrate as a plug-and-play in MPC designs. Extensive simulations with the BlueROV2 model under realistic ocean current fields show that the proposed approach achieves substantially lower energy consumption than conventional predictive control while maintaining comparable arrival times and constraint satisfaction.", "AI": {"tldr": "提出了一种利用海洋流的分阶段门控MPC（模型预测控制）策略，以提高自主水下航行器（AUV）的能量效率。", "motivation": "为了提升AUV在海洋探索和离岸作业中的实际应用性能，特别是在能量效率和续航能力方面的挑战，提出了一种新的控制方法。", "method": "通过引入分阶段门控MPC策略，该策略利用一种标量来衡量海洋流对航行器的帮助程度，并结合单调成本整形（MCS）和速度飞行（STF）两种成本组件。这些组件能够根据实际需要调整航行器的能量消耗，从而提高能量效率。", "result": "仿真实验表明，在真实的海洋流场中，与传统预测控制相比，所提出的方法显著降低了能量消耗，并保持了类似的到达时间和约束条件满足程度。", "conclusion": "该方法通过利用海洋流的辅助效应和精细化的成本控制策略，成功提高了AUV的能量效率和续航能力。"}}
{"id": "2602.00821", "pdf": "https://arxiv.org/pdf/2602.00821", "abs": "https://arxiv.org/abs/2602.00821", "authors": ["Konstantinos Moutselos", "Ilias Maglogiannis"], "title": "Edge-Native Generative De-identification: Inversion-Free Flow for Privacy-Preserving Federated Skin Image Analysis", "categories": ["cs.CV"], "comment": "8 pages, 5 figures", "summary": "The deployment of Federated Learning (FL) for clinical dermatology is hindered by the competing requirements of protecting patient privacy and preserving diagnostic features. Traditional de-identification methods often degrade pathological fidelity, while standard generative editing techniques rely on computationally intensive inversion processes unsuitable for resource-constrained edge devices. We propose a framework for identity-agnostic pathology preservation that serves as a client-side privacy-preserving utility. By leveraging inversion-free Rectified Flow Transformers (FlowEdit), the system performs high-fidelity identity transformation in near real-time (less than 20s), facilitating local deployment on clinical nodes. We introduce a \"Segment-by-Synthesis\" mechanism that generates counterfactual healthy and pathological twin pairs locally. This enables the extraction of differential erythema masks that are decoupled from biometric markers and semantic artifacts (e.g. jewelry). Pilot validation on high-resolution clinical samples demonstrates an Intersection over Union (IoU) stability greater than 0.67 across synthetic identities. By generating privacy-compliant synthetic surrogates at the edge, this framework mitigates the risk of gradient leakage at the source, providing a secure pathway for high-precision skin image analysis in federated environments.", "AI": {"tldr": "提出了一种边缘原生生成去识别框架，用于隐私保护的联邦皮肤图像分析。", "motivation": "传统的去识别方法会降低病理学准确性，而标准生成编辑技术需要大量计算资源，不适合边缘设备。为了解决这个问题，本文提出了一个可以在边缘设备上运行的高精度皮肤图像分析解决方案。", "method": "利用无需反转的Rectified Flow Transformers (FlowEdit)进行身份转换，并引入\"Segment-by-Synthesis\"机制以产生健康和病理孪生对，提取出不依赖于生物识别标记和语义特征的差异性红斑掩模。", "result": "在高分辨率临床样本上的初步验证显示合成身份间的交并比（IoU）稳定度超过0.67，在边缘设备上生成符合隐私保护要求的人工数据。", "conclusion": "该框架为联邦环境下的精确皮肤图像分析提供了一条安全途径，有效规避了源端梯度泄漏的风险。"}}
{"id": "2602.00815", "pdf": "https://arxiv.org/pdf/2602.00815", "abs": "https://arxiv.org/abs/2602.00815", "authors": ["Yunjian Zhang", "Sudong Wang", "Yang Li", "Peiran Xu", "Conghao Zhou", "Xiaoyue Ma", "Jianing Li", "Yao Zhu"], "title": "Resource-Efficient Reinforcement for Reasoning Large Language Models via Dynamic One-Shot Policy Refinement", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have exhibited remarkable performance on complex reasoning tasks, with reinforcement learning under verifiable rewards (RLVR) emerging as a principled framework for aligning model behavior with reasoning chains. Despite its promise, RLVR remains prohibitively resource-intensive, requiring extensive reward signals and incurring substantial rollout costs during training. In this work, we revisit the fundamental question of data and compute efficiency in RLVR. We first establish a theoretical lower bound on the sample complexity required to unlock reasoning capabilities, and empirically validate that strong performance can be achieved with a surprisingly small number of training instances. To tackle the computational burden, we propose Dynamic One-Shot Policy Refinement (DoPR), an uncertainty-aware RL strategy that dynamically selects a single informative training sample per batch for policy updates, guided by reward volatility and exploration-driven acquisition. DoPR reduces rollout overhead by nearly an order of magnitude while preserving competitive reasoning accuracy, offering a scalable and resource-efficient solution for LLM post-training. This approach offers a practical path toward more efficient and accessible RL-based training for reasoning-intensive LLM applications.", "AI": {"tldr": "研究提出了一种资源高效的动态单样本策略细化方法，用于增强大型语言模型的推理能力。", "motivation": "现有基于强化学习的方法在训练大型语言模型进行复杂推理任务时存在计算和数据效率低的问题。为了提高效率并降低成本，本文探讨如何更有效地解锁这些模型的推理能力。", "method": "提出了一种不确定性感知的动态单样本策略细化（DoPR）方法，在每个批次中通过奖励波动性和探索性选择一个有信息量的训练样本来更新策略，从而显著减少了计算开销。", "result": "该方法在保证推理准确性的同时将计算负担降低了近10倍，证明了其有效性和资源效率。", "conclusion": "本文的方法为大型语言模型的强化学习提供了更为高效和可访问的解决方案，使得复杂的推理任务能够在更少的数据和计算资源下得以训练。"}}
{"id": "2602.00814", "pdf": "https://arxiv.org/pdf/2602.00814", "abs": "https://arxiv.org/abs/2602.00814", "authors": ["Bomena Kim", "Hojun Lee", "Younsoo Park", "Yaoyu Hu", "Sebastian Scherer", "Inwook Shim"], "title": "SyNeT: Synthetic Negatives for Traversability Learning", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Reliable traversability estimation is crucial for autonomous robots to navigate complex outdoor environments safely. Existing self-supervised learning frameworks primarily rely on positive and unlabeled data; however, the lack of explicit negative data remains a critical limitation, hindering the model's ability to accurately identify diverse non-traversable regions. To address this issue, we introduce a method to explicitly construct synthetic negatives, representing plausible but non-traversable, and integrate them into vision-based traversability learning. Our approach is formulated as a training strategy that can be seamlessly integrated into both Positive-Unlabeled (PU) and Positive-Negative (PN) frameworks without modifying inference architectures. Complementing standard pixel-wise metrics, we introduce an object-centric FPR evaluation approach that analyzes predictions in regions where synthetic negatives are inserted. This evaluation provides an indirect measure of the model's ability to consistently identify non-traversable regions without additional manual labeling. Extensive experiments on both public and self-collected datasets demonstrate that our approach significantly enhances robustness and generalization across diverse environments. The source code and demonstration videos are publicly available at the project page: https://anonymous-synet.github.io/SyNet.github.io/", "AI": {"tldr": "本文提出了一种构建合成负样本的方法，用于增强自主机器人在复杂室外环境中进行可通行性学习的能力。", "motivation": "现有的自监督学习框架主要依赖正样本和未标记数据，但缺乏显式的负样本限制了模型准确识别非通行区域的能力。为了克服这一问题，本文提出了一个构造合成负样本的方法。", "method": "该方法通过引入代表可能但不可通行的合成负样本，并将其整合到基于视觉的可通行性学习中，形成了一种训练策略。此策略能够无缝集成进正-未标记（PU）和正-负（PN）框架之中，无需修改推理架构。", "result": "实验结果表明，在公开及自采集数据集上使用该方法可以显著提高模型在各种环境中的鲁棒性和泛化能力。", "conclusion": "本文通过构建合成负样本的方式，提升了基于视觉的可通行性学习效果，并且证明了这种方法的有效性。"}}
{"id": "2602.00813", "pdf": "https://arxiv.org/pdf/2602.00813", "abs": "https://arxiv.org/abs/2602.00813", "authors": ["Tong Wang", "Yunhan Zhao", "Shu Kong"], "title": "Generating a Paracosm for Training-Free Zero-Shot Composed Image Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Composed Image Retrieval (CIR) is the task of retrieving a target image from a database using a multimodal query, which consists of a reference image and a modification text. The text specifies how to alter the reference image to form a ``mental image'', based on which CIR should find the target image in the database. The fundamental challenge of CIR is that this ``mental image'' is not physically available and is only implicitly defined by the query. The contemporary literature pursues zero-shot methods and uses a Large Multimodal Model (LMM) to generate a textual description for a given multimodal query, and then employs a Vision-Language Model (VLM) for textual-visual matching to search the target image. In contrast, we address CIR from first principles by directly generating the ``mental image'' for more accurate matching. Particularly, we prompt an LMM to generate a ``mental image'' for a given multimodal query and propose to use this ``mental image'' to search for the target image. As the ``mental image'' has a synthetic-to-real domain gap with real images, we also generate a synthetic counterpart for each real image in the database to facilitate matching. In this sense, our method uses LMM to construct a ``paracosm'', where it matches the multimodal query and database images. Hence, we call this method Paracosm. Notably, Paracosm is a training-free zero-shot CIR method. It significantly outperforms existing zero-shot methods on four challenging benchmarks, achieving state-of-the-art performance for zero-shot CIR.", "AI": {"tldr": "本文提出了一种名为Paracosm的零样本训练自由组成的图像检索方法，该方法通过生成参照图像和修改文本查询后的“心理图象”来提高检索精度。", "motivation": "当前研究主要依赖大型多模态模型为给定的多模态查询生成文本描述，并利用视觉语言模型进行文本与视觉匹配。然而这些方式忽略了直接生成‘心理图像’以实现更准确匹配的可能性，本文旨在解决此问题。", "method": "通过提示大型多模态模型根据多模态查询来生成‘心理图像’；并为此目的在数据库中为每个真实图片生成一个合成的对应物，以便进行更好的匹配。从而构建了一个'平行宇宙（paracosm）'，它将多模态查询和数据库中的图像进行匹配。", "result": "Paracosm方法在四个具有挑战性的基准测试上显著优于现有的零样本方法，并实现了最先进的零样本组成图像检索性能。", "conclusion": "通过直接生成‘心理图象’并创建平行宇宙（paracosm）以进行更准确的匹配，本文提出的方法在零样本组成的图像检索任务中表现出色。"}}
{"id": "2602.00811", "pdf": "https://arxiv.org/pdf/2602.00811", "abs": "https://arxiv.org/abs/2602.00811", "authors": ["Ronghao Lin", "Honghao Lu", "Ruixing Wu", "Aolin Xiong", "Qinggong Chu", "Qiaolin He", "Sijie Mai", "Haifeng Hu"], "title": "MissMAC-Bench: Building Solid Benchmark for Missing Modality Issue in Robust Multimodal Affective Computing", "categories": ["cs.AI"], "comment": null, "summary": "As a knowledge discovery task over heterogeneous data sources, current Multimodal Affective Computing (MAC) heavily rely on the completeness of multiple modalities to accurately understand human's affective state. However, in real-world scenarios, the availability of modality data is often dynamic and uncertain, leading to substantial performance fluctuations due to the distribution shifts and semantic deficiencies of the incomplete multimodal inputs. Known as the missing modality issue, this challenge poses a critical barrier to the robustness and practical deployment of MAC models. To systematically quantify this issue, we introduce MissMAC-Bench, a comprehensive benchmark designed to establish fair and unified evaluation standards from the perspective of cross-modal synergy. Two guiding principles are proposed, including no missing prior during training, and one single model capable of handling both complete and incomplete modality scenarios, thereby ensuring better generalization. Moreover, to bridge the gap between academic research and real-world applications, our benchmark integrates evaluation protocols with both fixed and random missing patterns at the dataset and instance levels. Extensive experiments conducted on 3 widely-used language models across 4 datasets validate the effectiveness of diverse MAC approaches in tackling the missing modality issue. Our benchmark provides a solid foundation for advancing robust multimodal affective computing and promotes the development of multimedia data mining.", "AI": {"tldr": "构建MissMAC-Bench基准，解决多模态情感计算中的缺失模式问题。", "motivation": "当前的多模态情感计算依赖于多种模式数据的完整性来理解人类的情感状态，在实际场景中由于数据模式的不可用性导致性能波动和模型鲁棒性不足。", "method": "提出MissMAC-Bench基准，采用两个指导原则：训练时无缺失先验以及单一模型能处理完整和不完整模态情况；结合固定和随机缺失模式以弥合学术研究与实际应用之间的差距。", "result": "在三个广泛使用的语言模型上进行的实验表明，该基准验证了多模态情感计算方法的有效性。", "conclusion": "MissMAC-Bench为解决多模态情感计算中的缺失模式问题提供了坚实的基础，并促进了多媒体数据挖掘的发展。"}}
{"id": "2602.00810", "pdf": "https://arxiv.org/pdf/2602.00810", "abs": "https://arxiv.org/abs/2602.00810", "authors": ["Ze Huang", "Zhongyang Xiao", "Mingliang Song", "Longan Yang", "Hongyuan Yuan", "Li Sun"], "title": "VVLoc: Prior-free 3-DoF Vehicle Visual Localization", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Localization is a critical technology in autonomous driving, encompassing both topological localization, which identifies the most similar map keyframe to the current observation, and metric localization, which provides precise spatial coordinates. Conventional methods typically address these tasks independently, rely on single-camera setups, and often require additional 3D semantic or pose priors, while lacking mechanisms to quantify the confidence of localization results, making them less feasible for real industrial applications. In this paper, we propose VVLoc, a unified pipeline that employs a single neural network to concurrently achieve topological and metric vehicle localization using multi-camera system. VVLoc first evaluates the geo-proximity between visual observations, then estimates their relative metric poses using a matching strategy, while also providing a confidence measure. Additionally, the training process for VVLoc is highly efficient, requiring only pairs of visual data and corresponding ground-truth poses, eliminating the need for complex supplementary data. We evaluate VVLoc not only on the publicly available datasets, but also on a more challenging self-collected dataset, demonstrating its ability to deliver state-of-the-art localization accuracy across a wide range of localization tasks.", "AI": {"tldr": "VVLoc是一种使用单个神经网络同时实现基于多摄像头系统的车辆拓扑和度量定位的统一管道。", "motivation": "当前的方法通常独立处理定位任务，依赖单一摄像机，并需要额外的3D语义或姿势先验条件。这些方法缺乏量化定位结果置信度的机制，不适合工业应用。VVLoc旨在解决这些问题，提供高效的训练过程和准确的定位。", "method": "VVLoc利用单个神经网络评估视觉观测之间的地理邻近性，并采用匹配策略估计相对度量位置，同时提供置信度测量。", "result": "在公开数据集和自采集的数据集中，VVLoc展示了超越当前技术水平的定位精度。", "conclusion": "VVLoc通过单一神经网络统一处理车辆的拓扑和度量定位任务，在多摄像头系统中实现了高效的训练过程，并且达到了领先的定位精度。"}}
{"id": "2602.00808", "pdf": "https://arxiv.org/pdf/2602.00808", "abs": "https://arxiv.org/abs/2602.00808", "authors": ["Hang Zhou", "Qiang Zhang", "Peiran Liu", "Yihao Qin", "Zhaoxu Yan", "Yiding Ji"], "title": "Physics-informed Diffusion Mamba Transformer for Real-world Driving", "categories": ["cs.RO"], "comment": "ef:International Conference on Robotics & Automation (ICRA) 2026", "summary": "Autonomous driving systems demand trajectory planners that not only model the inherent uncertainty of future motions but also respect complex temporal dependencies and underlying physical laws. While diffusion-based generative models excel at capturing multi-modal distributions, they often fail to incorporate long-term sequential contexts and domain-specific physical priors. In this work, we bridge these gaps with two key innovations. First, we introduce a Diffusion Mamba Transformer architecture that embeds mamba and attention into the diffusion process, enabling more effective aggregation of sequential input contexts from sensor streams and past motion histories. Second, we design a Port-Hamiltonian Neural Network module that seamlessly integrates energy-based physical constraints into the diffusion model, thereby enhancing trajectory predictions with both consistency and interpretability. Extensive evaluations on standard autonomous driving benchmarks demonstrate that our unified framework significantly outperforms state-of-the-art baselines in predictive accuracy, physical plausibility, and robustness, thereby advancing safe and reliable motion planning.", "AI": {"tldr": "本文提出了一种基于物理信息的扩散Mamba变压器，用于自动驾驶中的轨迹规划。", "motivation": "现有的轨迹规划模型在处理未来运动的不确定性、长期序列依赖以及领域特定的物理先验时存在不足。因此，作者提出了融合注意力机制和能量约束的新架构以解决这些问题。", "method": "引入了一种扩散Mamba变压器架构，并设计了一个基于端口哈密顿系统的神经网络模块，将物理约束集成到模型中。", "result": "在标准自动驾驶基准测试上表现优于现有技术，在预测准确性、物理合理性及鲁棒性方面均有提升。", "conclusion": "提出的框架通过结合扩散过程和物理定律提高了轨迹规划的准确性和可靠性。"}}
{"id": "2602.00807", "pdf": "https://arxiv.org/pdf/2602.00807", "abs": "https://arxiv.org/abs/2602.00807", "authors": ["Xianzhe Fan", "Shengliang Deng", "Xiaoyang Wu", "Yuxiang Lu", "Zhuoling Li", "Mi Yan", "Yujia Zhang", "Zhizheng Zhang", "He Wang", "Hengshuang Zhao"], "title": "Any3D-VLA: Enhancing VLA Robustness via Diverse Point Clouds", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Existing Vision-Language-Action (VLA) models typically take 2D images as visual input, which limits their spatial understanding in complex scenes. How can we incorporate 3D information to enhance VLA capabilities? We conduct a pilot study across different observation spaces and visual representations. The results show that explicitly lifting visual input into point clouds yields representations that better complement their corresponding 2D representations. To address the challenges of (1) scarce 3D data and (2) the domain gap induced by cross-environment differences and depth-scale biases, we propose Any3D-VLA. It unifies the simulator, sensor, and model-estimated point clouds within a training pipeline, constructs diverse inputs, and learns domain-agnostic 3D representations that are fused with the corresponding 2D representations. Simulation and real-world experiments demonstrate Any3D-VLA's advantages in improving performance and mitigating the domain gap. Our project homepage is available at https://xianzhefan.github.io/Any3D-VLA.github.io.", "AI": {"tldr": "本文提出了一种方法，通过引入点云数据增强视觉语言行为模型的空间理解能力。", "motivation": "现有的视觉语言行为模型主要依赖于二维图像输入，这限制了其在复杂场景中的空间理解能力。为了提高这种模型的鲁棒性并减少域差距，作者们试图通过3D信息的整合来改进这些模型。", "method": "本文提出了Any3D-VLA方法，该方法统一模拟器、传感器和模型估计的点云数据，并构建多样化的输入，学习与2D表示融合的跨领域无偏见的三维表征。", "result": "实验结果表明，通过引入点云信息和构建多样化输入，可以显著提高视觉语言行为模型在性能上的表现并减少域差距。", "conclusion": "Any3D-VLA方法展示了其在改善视觉语言行为模型能力以及跨环境适应性方面的优势。"}}
{"id": "2602.00800", "pdf": "https://arxiv.org/pdf/2602.00800", "abs": "https://arxiv.org/abs/2602.00800", "authors": ["Yebin Yang", "Huaijin Wu", "Fu Guo", "Lin Yao", "Xiaohan Qin", "Jingzhi Wang", "Debing Zhang", "Junchi Yan"], "title": "JTok: On Token Embedding as another Axis of Scaling Law via Joint Token Self-modulation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "LLMs have traditionally scaled along dense dimensions, where performance is coupled with near-linear increases in computational cost. While MoE decouples capacity from compute, it introduces large memory overhead and hardware efficiency challenges. To overcome these, we propose token-indexed parameters as a novel, orthogonal scaling axis that decouple model capacity from FLOPs. Specifically, we introduce Joint-Token (JTok) and Mixture of Joint-Token (JTok-M), which augment Transformer layers with modulation vectors retrieved from auxiliary embedding tables. These vectors modulate the backbone via lightweight, element-wise operations, incurring negligible FLOPs overhead. Extensive experiments on both dense and MoE backbones, spanning from 650M (190M + 460M embedding) to 61B (17B + 44B embedding) total parameters, demonstrate that our approach consistently reduces validation loss and significantly improves downstream task performance (e.g., +4.1 on MMLU, +8.3 on ARC, +8.9 on CEval). Rigorous isoFLOPs analysis further confirms that JTok-M fundamentally shifts the quality-compute Pareto frontier, achieving comparable model quality with 35% less compute relative to vanilla MoE architectures, and we validate that token-indexed parameters exhibit a predictable power-law scaling behavior. Moreover, our efficient implementation ensures that the overhead introduced by JTok and JTok-M remains marginal.", "AI": {"tldr": "提出了一种新的参数扩展轴，即联合令牌（JTok）和混合的联合令牌（JTok-M），用于改进大型语言模型的性能。", "motivation": "传统的密集维度扩展会导致计算成本线性增加。虽然专家混合方法解耦了容量与计算之间的关系，但是引入了大量的内存开销和硬件效率挑战。", "method": "通过引入辅助嵌入表中的调制向量来增强Transformer层，这些向量通过轻量级的元素操作对主干进行调制，并且几乎不增加FLOPs。这种方法被称为联合令牌（JTok）和混合的联合令牌（JTok-M）。", "result": "实验表明，该方法显著提高了下游任务的表现，在MMLU、ARC和CEval上的性能分别提升了4.1%、8.3%和8.9%，并且在相同的FLOPs下，实现了更高质量的结果。", "conclusion": "JTok-M 方法从根本上改变了质量与计算成本之间的权衡关系，并且通过有效的实现保证了引入的开销很小。"}}
{"id": "2602.00795", "pdf": "https://arxiv.org/pdf/2602.00795", "abs": "https://arxiv.org/abs/2602.00795", "authors": ["Wenhao Li", "Xianjing Meng", "Qiangchang Wang", "Zhongyi Han", "Zhibin Wu", "Yilong Yin"], "title": "DVLA-RL: Dual-Level Vision-Language Alignment with Reinforcement Learning Gating for Few-Shot Learning", "categories": ["cs.CV"], "comment": "Accepted by ICLR 2026", "summary": "Few-shot learning (FSL) aims to generalize to novel categories with only a few samples. Recent approaches incorporate large language models (LLMs) to enrich visual representations with semantic embeddings derived from class names. However, they overlook progressive and adaptive alignment between vision and language from low-level to high-level semantics, resulting in limited semantic gains. To address these challenges, we propose Dual-level Vision-Language Alignment with Reinforcement Learning gating (DVLA-RL), which consists of Dual-level Semantic Construction (DSC) and RL-gated Attention (RLA). Specifically, DSC conditions LLMs on both class names and support samples to generate discriminative attributes, progressively selects the most relevant ones, and then synthesizes them into coherent class descriptions. This process provides complementary low-level attributes and high-level descriptions, enabling both fine-grained grounding and holistic class understanding. To dynamically integrate dual-level semantics along with the visual network layers, RLA formulates cross-modal fusion as a sequential decision process. A lightweight policy trained with episodic REINFORCE adaptively adjusts the contributions of self-attention and cross-attention to integrate textual and visual tokens. As a result, shallow layers refine local attributes and deep layers emphasize global semantics, enabling more precise cross-modal alignment. This achieves class-specific discrimination and generalized representations with merely a few support samples. DVLA-RL achieves new state-of-the-art performance across nine benchmarks in three diverse FSL scenarios.", "AI": {"tldr": "提出了一种新的少样本学习方法DVLA-RL，结合了双层视觉语言对齐和强化学习门控机制。", "motivation": "当前的方法忽略了从低级到高级语义的逐步适应性对齐，限制了语义增益。因此，提出了DVLA-RL以解决这些问题。", "method": "DVLA-RL包含双重语义构建（DSC）和强化学习门控注意机制（RLA），通过条件化大型语言模型在类别名和支持样本上生成判别属性，并逐步选择最相关的属性进行综合。RLA将跨模式融合建模为顺序决策过程，以动态集成双层语义与视觉网络层次。", "result": "DVLA-RL在九个不同少样本学习基准测试中取得了新的最优性能。", "conclusion": "通过结合双重视觉语言对齐和强化学习门控机制，DVLA-RL实现了类别特定的区分能力，并且仅使用少量支持样例就获得了泛化表示。"}}
{"id": "2602.00793", "pdf": "https://arxiv.org/pdf/2602.00793", "abs": "https://arxiv.org/abs/2602.00793", "authors": ["Yoonsang Kim", "Devshree Jadeja", "Divyansh Pradhan", "Yalong Yang", "Arie Kaufman"], "title": "SpeechLess: Micro-utterance with Personalized Spatial Memory-aware Assistant in Everyday Augmented Reality", "categories": ["cs.HC", "cs.CL", "cs.ET", "cs.IR"], "comment": "11 pages, 9 figures. This is the author's version of the article that will appear at the IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR) 2026", "summary": "Speaking aloud to a wearable AR assistant in public can be socially awkward, and re-articulating the same requests every day creates unnecessary effort. We present SpeechLess, a wearable AR assistant that introduces a speech-based intent granularity control paradigm grounded in personalized spatial memory. SpeechLess helps users \"speak less,\" while still obtaining the information they need, and supports gradual explicitation of intent when more complex expression is required. SpeechLess binds prior interactions to multimodal personal context-space, time, activity, and referents-to form spatial memories, and leverages them to extrapolate missing intent dimensions from under-specified user queries. This enables users to dynamically adjust how explicitly they express their informational needs, from full-utterance to micro/zero-utterance interaction. We motivate our design through a week-long formative study using a commercial smart glasses platform, revealing discomfort with public voice use, frustration with repetitive speech, and hardware constraints. Building on these insights, we design SpeechLess, and evaluate it through controlled lab and in-the-wild studies. Our results indicate that regulated speech-based interaction, can improve everyday information access, reduce articulation effort, and support socially acceptable use without substantially degrading perceived usability or intent resolution accuracy across diverse everyday environments.", "AI": {"tldr": "介绍了一种名为SpeechLess的可穿戴AR助手，它通过个性化空间记忆实现了微表达控制模式，以减少在公共场所大声说话的需求。", "motivation": "为了减轻在公共场合大声对可穿戴AR设备说话的社会尴尬感，并解决重复性语音命令带来的不便问题。", "method": "设计了一种结合用户个人背景信息（如时间、地点、活动等）来形成空间记忆，从而根据用户的未完全表达的请求推断出完整意图的方法。", "result": "通过实验室和实地研究证明，这种控制语音交互的方式能够提高日常信息获取效率，减少说话的努力，并支持社会接受性使用而不显著降低感知可用性和意图解析准确性。", "conclusion": "SpeechLess提供了一种新颖的解决方案，使用户能够在不牺牲准确度的情况下减少说话的需求。"}}
{"id": "2602.00792", "pdf": "https://arxiv.org/pdf/2602.00792", "abs": "https://arxiv.org/abs/2602.00792", "authors": ["Guinan Chen", "Xunpeng Huang", "Ying Sun", "Shijin Wang", "Yanyong Zhang", "Chao Wang"], "title": "Latent Shadows: The Gaussian-Discrete Duality in Masked Diffusion", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages", "summary": "Masked discrete diffusion is a dominant paradigm for high-quality language modeling where tokens are iteratively corrupted to a mask state, yet its inference efficiency is bottlenecked by the lack of deterministic sampling tools. While diffusion duality enables deterministic distillation for uniform models, these approaches generally underperform masked models and rely on complex integral operators. Conversely, in the masked domain, prior methods typically assume the absence of deterministic trajectories, forcing a reliance on stochastic distillation. To bridge this gap, we establish explicit Masked Diffusion Duality, proving that the masked process arises as the projection of a continuous Gaussian process via a novel maximum-value index preservation mechanism. Furthermore, we introduce Masked Consistency Distillation (MCD), a principled framework that leverages this duality to analytically construct the deterministic coupled trajectories required for consistency distillation, bypassing numerical ODE solvers. This result strictly improves upon prior stochastic distillation methods, achieving a 16$\\times$ inference speedup without compromising generation quality. Our findings not only provide a solid theoretical foundation connecting masked and continuous diffusion, but also unlock the full potential of consistency distillation for high-performance discrete generation. Our code is available at https://anonymous.4open.science/r/MCD-70FD.", "AI": {"tldr": "本文提出了一种新的框架Masked Consistency Distillation (MCD)，利用隐式连续扩散和离散掩码过程之间的对偶性，实现确定性的轨迹构建。", "motivation": "现有的掩码扩散模型在推理效率上受限于缺少确定性采样工具。尽管存在一些连续扩散方法可以提供确定性蒸馏，但这些方法通常表现不如掩码模型，并依赖复杂积分算子。因此，作者致力于开发一种新的方法来解决这些问题。", "method": "通过证明掩码过程可以通过一个独特的最大值索引保存机制从连续高斯过程中投影而来，从而建立了显式的Masked Diffusion Duality。基于此理论基础，引入了MCD框架，利用该对偶性构建确定性的耦合轨迹，从而实现了高质量的生成。", "result": "实验结果表明，MCD方法能够比之前的随机蒸馏方法获得16倍的推理加速，并且不会影响生成质量。", "conclusion": "本文的工作不仅为理解和连接连续和离散扩散过程提供了坚实的理论基础，而且解锁了在高性能离散生成中应用一致性蒸馏的潜力。"}}
{"id": "2602.00788", "pdf": "https://arxiv.org/pdf/2602.00788", "abs": "https://arxiv.org/abs/2602.00788", "authors": ["Md Abir Hossen", "Mohammad Ali Javidian", "Vignesh Narayanan", "Jason M. O'Kane", "Pooyan Jamshidi"], "title": "Multi-Objective Multi-Fidelity Bayesian Optimization with Causal Priors", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-fidelity Bayesian optimization (MFBO) accelerates the search for the global optimum of black-box functions by integrating inexpensive, low-fidelity approximations. The central task of an MFBO policy is to balance the cost-efficiency of low-fidelity proxies against their reduced accuracy to ensure effective progression toward the high-fidelity optimum. Existing MFBO methods primarily capture associational dependencies between inputs, fidelities, and objectives, rather than causal mechanisms, and can perform poorly when lower-fidelity proxies are poorly aligned with the target fidelity. We propose RESCUE (REducing Sampling cost with Causal Understanding and Estimation), a multi-objective MFBO method that incorporates causal calculus to systematically address this challenge. RESCUE learns a structural causal model capturing causal relationships between inputs, fidelities, and objectives, and uses it to construct a probabilistic multi-fidelity (MF) surrogate that encodes intervention effects. Exploiting the causal structure, we introduce a causal hypervolume knowledge-gradient acquisition strategy to select input-fidelity pairs that balance expected multi-objective improvement and cost. We show that RESCUE improves sample efficiency over state-of-the-art MF optimization methods on synthetic and real-world problems in robotics, machine learning (AutoML), and healthcare.", "AI": {"tldr": "本文提出了RESCUE算法，用于在多目标多保真度贝叶斯优化中利用因果模型提高采样效率。", "motivation": "当前的多保真度贝叶斯优化方法主要捕捉输入、保真度和目标之间的关联性依赖关系，而未能充分利用因果机制。当低保真度代理与目标不匹配时，这些方法可能表现不佳。因此，需要一种能够利用因果信息的方法来解决这些问题。", "method": "RESCUE算法通过学习结构因果模型捕捉输入、保真度和目标之间的因果关系，并构造一个编码干预效应的多保真度概率代理。它还引入了一种基于因果体积的知识梯度获取策略，以选择平衡预期多目标改进和成本的输入-保真度对。", "result": "RESCUE在合成问题以及机器人技术、自动机器学习（AutoML）和医疗保健的真实世界问题上比现有的最先进的MF优化方法表现出更高的采样效率。", "conclusion": "通过利用因果模型，RESCUE能够在多目标多保真度贝叶斯优化中提高样本效率，并且优于当前的最先进方法。"}}
{"id": "2602.00787", "pdf": "https://arxiv.org/pdf/2602.00787", "abs": "https://arxiv.org/abs/2602.00787", "authors": ["Ceylin Savas", "Maryam Javed", "Murat Kuscu"], "title": "Hybrid Artificial-Living Cell Collectives for Wetware Computing", "categories": ["cs.ET"], "comment": null, "summary": "Living systems continuously sense, integrate, and act on chemical information using multiscale biochemical networks whose dynamics are inherently nonlinear, adaptive, and energy-efficient. Yet, most attempts to harness such \"wetware\" for external computational tasks have centered on neural tissue and electrical interfaces, leaving the information-processing potential of non-neural collectives comparatively underexplored. In this letter, we study a hybrid artificial-living cell network in which programmable artificial cells write time-varying inputs into a biochemical microenvironment, while a living bacterial collective provides the nonlinear spatiotemporal dynamics required for temporal information processing. Specifically, artificial cells transduce an external input sequence into the controlled secretion of attractant and repellent molecules, thereby modulating the \"local biochemical context\" that bacteria naturally sense and respond to. The resulting collective bacterial dynamics, together with the evolving molecular fields, form a high-dimensional reservoir state that is sampled coarsely (voxel-wise) and mapped to outputs through a trained linear readout within a physical reservoir computing framework. Using an agent-based in silico model, we evaluate the proposed hybrid reservoir on the Mackey-Glass chaotic time-series prediction benchmark. The system achieves normalized root mean square error (NRMSE) values of approximately 0.33-0.40 for prediction horizons H=1 to 5, and exhibits measurable short-term memory as encoded in the distributed spatiotemporal patterns of bacteria and biochemicals. These results motivate the future exploration of non-neural hybrid cell networks for in situ temporal signal processing towards novel biomedical applications.", "AI": {"tldr": "研究一种混合人工细胞和活细菌集体的计算模型，用于混沌时间序列预测。", "motivation": "探索非神经细胞网络的信息处理潜力，并实现新型生物医学应用中的原位实时信号处理。", "method": "通过可编程的人工细胞将外部输入转化为化学分子的分泌，影响细菌的行为模式。利用活菌集体和生化场形成的高维状态，在物理蓄水池计算框架下进行预测。", "result": "系统实现了Mackey-Glass混沌时间序列预测任务，并在预测时长H=1到5的情况下达到了约0.33-0.40的NRMSE值，表现出短期记忆能力。", "conclusion": "研究表明非神经细胞网络具有潜在的应用价值，为未来生物医学应用中的实时信号处理开辟了新路径。"}}
{"id": "2602.00785", "pdf": "https://arxiv.org/pdf/2602.00785", "abs": "https://arxiv.org/abs/2602.00785", "authors": ["Sherry Yang"], "title": "World Models as an Intermediary between Agents and the Real World", "categories": ["cs.AI"], "comment": null, "summary": "Large language model (LLM) agents trained using reinforcement learning has achieved superhuman performance in low-cost environments like games, mathematics, and coding. However, these successes have not translated to complex domains where the cost of interaction is high, such as the physical cost of running robots, the time cost of ML engineering, and the resource cost of scientific experiments. The true bottleneck for achieving the next level of agent performance for these complex and high-cost domains lies in the expense of executing actions to acquire reward signals. To address this gap, this paper argues that we should use world models as an intermediary between agents and the real world. We discuss how world models, viewed as models of dynamics, rewards, and task distributions, can overcome fundamental barriers of high-cost actions such as extreme off-policy learning and sample inefficiency in long-horizon tasks. Moreover, we demonstrate how world models can provide critical and rich learning signals to agents across a broad set of domains, including machine learning engineering, computer use, robotics, and AI for science. Lastly, we identify the challenges of building these world models and propose actionable items along dataset curation, architecture design, scaling, and evaluation of world models.", "AI": {"tldr": "使用世界模型作为代理与现实世界的中介，以克服高成本行动的根本障碍。", "motivation": "在成本高的复杂领域中，直接通过执行昂贵的动作来获取奖励信号存在困难，因此引入了世界模型作为一种解决方法。", "method": "探讨如何利用世界模型（包括动态、奖励和任务分布）作为代理与现实世界的中介，并提出构建此类世界模型的挑战及解决方案。", "result": "展示世界模型能够提供关键且丰富的学习信号给代理，在机器学习工程、计算机使用、机器人技术等领域具有广泛的应用前景。", "conclusion": "通过引入世界模型，可以有效地克服高成本行动带来的障碍，为实现下一代智能体性能提供了可能。"}}
{"id": "2602.00782", "pdf": "https://arxiv.org/pdf/2602.00782", "abs": "https://arxiv.org/abs/2602.00782", "authors": ["Jiahao Zhang", "Zeqing Zhang", "Di Wang", "Lijie Hu"], "title": "Controlling Repetition in Protein Language Models", "categories": ["q-bio.BM", "cs.AI"], "comment": "Published as a conference paper at ICLR 2026", "summary": "Protein language models (PLMs) have enabled advances in structure prediction and de novo protein design, yet they frequently collapse into pathological repetition during generation. Unlike in text, where repetition merely reduces readability, in proteins it undermines structural confidence and functional viability. To unify this problem, we present the first systematic study of repetition in PLMs. We first propose quantitative metrics to characterize motif-level and homopolymer repetition and then demonstrate their negative impact on folding reliability. To address this challenge, we propose UCCS (Utility-Controlled Contrastive Steering), which steers protein generation with a constrained dataset. Instead of naively contrasting high- vs. low-repetition sequences, we construct contrastive sets that maximize differences in repetition while tightly controlling for structural utility. This disentanglement yields steering vectors that specifically target repetition without degrading foldability. Injected at inference, these vectors consistently reduce repetition without retraining or heuristic decoding. Experiments with ESM-3 and ProtGPT2 in CATH, UniRef50, and SCOP show that our method outperforms decoding penalties and other baselines, substantially lowering repetition while preserving AlphaFold confidence scores. Our results establish repetition control as a central challenge for PLMs and highlight dataset-guided steering as a principled approach for reliable protein generation.", "AI": {"tldr": "本文提出了一种新的方法UCCS，用于控制蛋白质语言模型生成过程中的重复问题。", "motivation": "蛋白质语言模型在结构预测和从头设计中取得了进展，但在生成过程中经常出现病态重复。这种重复会降低蛋白质的结构性信心和功能可行性。", "method": "本文首先提出了定量指标来表征模体级和均聚物重复，并展示了其对折叠可靠性的影响。接着提出UCCS方法，在保持结构效用的情况下通过构建对比数据集引导蛋白质生成，以减少重复问题。", "result": "实验结果表明，该方法在多个基准上的重复降低显著优于解码惩罚和其他基线，同时保留AlphaFold信心分数。", "conclusion": "本文确立了对PLMs的重复控制作为核心挑战，并突显了基于数据集引导的方法作为一种可靠蛋白质生成的原则性途径。"}}
{"id": "2602.00780", "pdf": "https://arxiv.org/pdf/2602.00780", "abs": "https://arxiv.org/abs/2602.00780", "authors": ["Yuting Huang", "Leilei Ding", "Zhipeng Tang", "Zenghuan Zhu", "Jiajun Deng", "Xinrui Lin", "Shuo Liu", "Haojie Ren", "Jianmin Ji", "Yanyong Zhang"], "title": "Environment-Aware Adaptive Pruning with Interleaved Inference Orchestration for Vision-Language-Action Models", "categories": ["cs.AI"], "comment": "12 pages, 7 figures", "summary": "While Vision-Language-Action (VLA) models hold promise in embodied intelligence, their large parameter counts lead to substantial inference latency that hinders real-time manipulation, motivating parameter sparsification. However, as the environment evolves during VLA execution, the optimal sparsity patterns change accordingly. Static pruning lacks the adaptability required for environment dynamics, whereas fixed-interval dynamic layer pruning suffers from coarse granularity and high retraining overheads. To bridge this gap, we propose EcoVLA, a training-free, plug-and-play adaptive pruning framework that supports orthogonal combination with existing VLA acceleration methods. EcoVLA comprises two components: Environment-aware Adaptive Pruning (EAP) and Interleaved Inference Orchestration ($I^2O$). EAP is a lightweight adaptive channel pruning method that incorporates the temporal consistency of the physical environment to update sparsity patterns. $I^2O$ leverages the FLOPs bubbles inherent in VLA inference to schedule the pruning method in parallel, ensuring negligible impact on latency. Evaluated on diverse VLA models and benchmarks, EcoVLA delivers state-of-the-art performance, achieving up to 1.60$\\times$ speedup with only a 0.4% drop in success rate, and further reaches 2.18$\\times$ speedup with only a 0.5% degradation when combined with token pruning. We further validate the effectiveness of EcoVLA on real-world robots.", "AI": {"tldr": "提出了一种环境感知自适应剪枝框架EcoVLA，用于实时优化Vision-Language-Action模型的推理速度。", "motivation": "大型参数量导致推理延迟高，阻碍了实时操作。静态和固定间隔动态层剪枝方法存在局限性。", "method": "EcoVLA包含环境感知自适应剪枝（EAP）和交错推断编排（$I^2O$），其中EAP利用物理环境的时间一致性来更新稀疏模式，$I^2O$通过并行调度减少延迟影响。", "result": "在多种模型和基准上实现了最先进的性能，最大速度提升1.60倍且成功率仅下降0.4%，结合标记剪枝可达2.18倍速度提升和0.5%的退化率。", "conclusion": "EcoVLA提高了实时操作效率，并在真实机器人上的有效性得到了验证。"}}
{"id": "2602.00773", "pdf": "https://arxiv.org/pdf/2602.00773", "abs": "https://arxiv.org/abs/2602.00773", "authors": ["Huiqian Lai"], "title": "\"Please, don't kill the only model that still feels human\": Understanding the #Keep4o Backlash", "categories": ["cs.HC"], "comment": "15 pages, accepted at CHI 2026", "summary": "When OpenAI replaced GPT-4o with GPT-5, it triggered the Keep4o user resistance movement, revealing a conflict between rapid platform iteration and users' deep socio-emotional attachments to AI systems. This paper presents a phenomenon-driven, mixed-methods investigation of this conflict, analyzing 1,482 social media posts. Thematic analysis reveals that resistance stems from two core investments: instrumental dependency, where the AI is deeply integrated into professional workflows, and relational attachment, where users form strong parasocial bonds with the AI as a unique companion. Quantitative analysis further shows that the coercive deprivation of user choice was a key catalyst, transforming individual grievances into a collective, rights-based protest. This study illuminates an emerging form of socio-technical conflict in the age of generative AI. Our findings suggest that for AI systems designed for companionship and deep integration, the process of change--particularly the preservation of user agency--can be as critical as the technological outcome itself.", "AI": {"tldr": "研究分析了用户对OpenAI更换GPT模型的抵抗情绪，探讨背后的社会技术冲突。", "motivation": "理解社会大众在面对快速迭代的人工智能系统时，基于情感依赖和工具依赖所产生的反应及集体抗议行为。", "method": "采用混合方法进行现象驱动的研究，包括1482篇社交媒体帖子的主题分析与定量分析。", "result": "揭示了用户抵抗主要源于对AI系统的工具性依赖和关系依恋，以及强制剥夺选择权触发的集体抗议。", "conclusion": "在生成式人工智能时代，保持用户的自主权可能同样重要，甚至比技术结果更加关键。"}}
{"id": "2602.00769", "pdf": "https://arxiv.org/pdf/2602.00769", "abs": "https://arxiv.org/abs/2602.00769", "authors": ["Siyu Yan", "Lusha Zhu", "Jian-Qiao Zhu"], "title": "Eliciting Trustworthiness Priors of Large Language Models via Economic Games", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "One critical aspect of building human-centered, trustworthy artificial intelligence (AI) systems is maintaining calibrated trust: appropriate reliance on AI systems outperforms both overtrust (e.g., automation bias) and undertrust (e.g., disuse). A fundamental challenge, however, is how to characterize the level of trust exhibited by an AI system itself. Here, we propose a novel elicitation method based on iterated in-context learning (Zhu and Griffiths, 2024a) and apply it to elicit trustworthiness priors using the Trust Game from behavioral game theory. The Trust Game is particularly well suited for this purpose because it operationalizes trust as voluntary exposure to risk based on beliefs about another agent, rather than self-reported attitudes. Using our method, we elicit trustworthiness priors from several leading large language models (LLMs) and find that GPT-4.1's trustworthiness priors closely track those observed in humans. Building on this result, we further examine how GPT-4.1 responds to different player personas in the Trust Game, providing an initial characterization of how such models differentiate trust across agent characteristics. Finally, we show that variation in elicited trustworthiness can be well predicted by a stereotype-based model grounded in perceived warmth and competence.", "AI": {"tldr": "本文提出了一种基于行为经济学游戏的方法，用于评估大型语言模型的信任度。", "motivation": "维持校准的信任是构建以人为中心的、可信赖的人工智能系统的关键方面。然而，一个基本挑战是如何描述AI系统的信任水平。", "method": "利用迭代情境学习方法和信任博弈来评估大型语言模型的信任度。", "result": "GPT-4.1在信任博弈中的表现与人类相似，其信任度可以由基于刻板印象的模型预测。", "conclusion": "这种方法为理解AI系统的信任度提供了一个新的视角，并且表明了大型语言模型如何根据不同的玩家特征来区分信任。"}}
{"id": "2602.00767", "pdf": "https://arxiv.org/pdf/2602.00767", "abs": "https://arxiv.org/abs/2602.00767", "authors": ["Muhammed Ustaomeroglu", "Guannan Qu"], "title": "BLOCK-EM: Preventing Emergent Misalignment by Blocking Causal Features", "categories": ["cs.LG", "cs.AI"], "comment": "41 pages, 32 figures. Code available", "summary": "Emergent misalignment can arise when a language model is fine-tuned on a narrowly scoped supervised objective: the model learns the target behavior, yet also develops undesirable out-of-domain behaviors. We investigate a mechanistic approach to preventing emergent misalignment by identifying a small set of internal features that reliably control the misaligned behavior and then discouraging the model from strengthening these features during fine-tuning. Across six fine-tuning domains, blocking (i.e., constraining) a fixed set of features achieves up to 95\\% relative reduction in emergent misalignment with no degradation in model quality or target-task performance. We strengthen validity with disjoint selection/evaluation splits, multiple independent judges, multiple random seeds for key settings, quality metrics, and extensive ablations demonstrating that the reduction in misalignment is specific to the identified mechanism. We also characterize a limiting regime in which misalignment re-emerges under prolonged fine-tuning, present evidence consistent with rerouting through alternative features or layers, and evaluate modifications that partially restore the misalignment-blocking effect. Overall, our results show that targeted training-time constraints on internal mechanisms can mitigate emergent misalignment without degrading target-task performance.", "AI": {"tldr": "通过阻止内部特征来预防语言模型在微调过程中出现的新兴不对齐。", "motivation": "防止语言模型在特定监督目标下微调时，虽然学习到所需行为但同时发展出域外不期望的行为。", "method": "识别控制不期望行为的一组内部特征，并通过约束这些特征来阻止其增强。", "result": "在六个不同的微调领域中，这种方法实现了高达95%的相对减少新兴不对齐的效果，而不会影响模型质量或目标任务性能。", "conclusion": "有针对性地在训练期间施加对内部机制的约束可以减轻语言模型中的新兴不对齐问题，同时保持目标任务性能不变。"}}
{"id": "2602.00763", "pdf": "https://arxiv.org/pdf/2602.00763", "abs": "https://arxiv.org/abs/2602.00763", "authors": ["Dylan Yves", "Khush Agarwal", "Jonathan Hoyin Chan", "Patcharapit Promoppatum", "Aroonkamon Pattanasiricharoen"], "title": "Evaluating Deep Learning-Based Nerve Segmentation in Brachial Plexus Ultrasound Under Realistic Data Constraints", "categories": ["cs.CV", "cs.AI"], "comment": "9 pages, 6 figures", "summary": "Accurate nerve localization is critical for the success of ultrasound-guided regional anesthesia, yet manual identification remains challenging due to low image contrast, speckle noise, and inter-patient anatomical variability. This study evaluates deep learning-based nerve segmentation in ultrasound images of the brachial plexus using a U-Net architecture, with a focus on how dataset composition and annotation strategy influence segmentation performance. We find that training on combined data from multiple ultrasound machines (SIEMENS ACUSON NX3 Elite and Philips EPIQ5) provides regularization benefits for lower-performing acquisition sources, though it does not surpass single-source training when matched to the target domain. Extending the task from binary nerve segmentation to multi-class supervision (artery, vein, nerve, muscle) results in decreased nerve-specific Dice scores, with performance drops ranging from 9% to 61% depending on dataset, likely due to class imbalance and boundary ambiguity. Additionally, we observe a moderate positive correlation between nerve size and segmentation accuracy (Pearson r=0.587, p<0.001), indicating that smaller nerves remain a primary challenge. These findings provide methodological guidance for developing robust ultrasound nerve segmentation systems under realistic clinical data constraints.", "AI": {"tldr": "评估基于深度学习的神经分割在臂丛超声中的性能，特别是在真实数据限制下的表现。", "motivation": "准确的神经定位对于超声引导下区域麻醉的成功至关重要，但由于图像对比度低、斑点噪声和患者间解剖变异性的存在，手动识别仍然具有挑战性。", "method": "使用U-Net架构进行基于深度学习的神经分割，在来自不同超声设备的数据上训练模型，并研究数据集组成与标注策略对分割性能的影响。", "result": "多来源组合训练提供了一定的正则化效益，但并不总能超越单一来源训练；任务扩展到多类监督会导致神经特定Dice分数下降9%至61%，且较小的神经仍然是主要挑战。", "conclusion": "这些发现为在真实临床数据限制下开发鲁棒超声神经分割系统提供了方法指导。"}}
{"id": "2602.00762", "pdf": "https://arxiv.org/pdf/2602.00762", "abs": "https://arxiv.org/abs/2602.00762", "authors": ["Yuheng Shao", "Junjie Xiong", "Chaoran Wu", "Xiyuan Wang", "Ziyu Zhou", "Yang Ouyang", "Qinyi Tao", "Quan Li"], "title": "WordCraft: Scaffolding the Keyword Method for L2 Vocabulary Learning with Multimodal LLMs", "categories": ["cs.CL", "cs.HC"], "comment": "Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI' 26), April 13--17, 2026, Barcelona, Spain", "summary": "Applying the keyword method for vocabulary memorization remains a significant challenge for L1 Chinese-L2 English learners. They frequently struggle to generate phonologically appropriate keywords, construct coherent associations, and create vivid mental imagery to aid long-term retention. Existing approaches, including fully automated keyword generation and outcome-oriented mnemonic aids, either compromise learner engagement or lack adequate process-oriented guidance. To address these limitations, we conducted a formative study with L1 Chinese-L2 English learners and educators (N=18), which revealed key difficulties and requirements in applying the keyword method to vocabulary learning. Building on these insights, we introduce WordCraft, a learner-centered interactive tool powered by Multimodal Large Language Models (MLLMs). WordCraft scaffolds the keyword method by guiding learners through keyword selection, association construction, and image formation, thereby enhancing the effectiveness of vocabulary memorization. Two user studies demonstrate that WordCraft not only preserves the generation effect but also achieves high levels of effectiveness and usability.", "AI": {"tldr": "研究介绍了一种名为WordCraft的工具，该工具使用多模态大型语言模型来帮助L1中文-L2英语学习者更有效地应用关键词方法进行词汇记忆。", "motivation": "现有的词汇记忆方法在生成适当的声音关键字、构建连贯关联和形成生动的心理图像方面存在不足，这限制了其对于L1中文-L2英语学习者的适用性。因此，研究旨在通过一种新的交互式工具解决这些问题，提高学习效率。", "method": "研究者首先进行了一个形式化研究，以了解L1中文-L2英语学习者和教育者在应用关键词方法时遇到的困难。基于这些见解，他们开发了WordCraft工具，该工具有助于引导用户选择关键字、构建关联以及形成图像，从而提高词汇记忆效果。", "result": "两个用户的测试表明，WordCraft不仅保持了生成效应，而且还实现了高度的有效性和可用性。", "conclusion": "研究提出了一种新的方法来帮助L1中文-L2英语学习者更有效地应用关键词方法进行词汇记忆，并通过开发和评估名为WordCraft的工具证明了该方法的成功。"}}
{"id": "2602.00759", "pdf": "https://arxiv.org/pdf/2602.00759", "abs": "https://arxiv.org/abs/2602.00759", "authors": ["Zhipeng Chen", "Xiaobo Qin", "Wayne Xin Zhao", "Youbin Wu", "Ji-Rong Wen"], "title": "Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": "21 pages, Working in progress", "summary": "Reinforcement learning with verifiable rewards (RLVR) has shown great potential to enhance the reasoning ability of large language models (LLMs). However, due to the limited amount of information provided during the RLVR process, the model can only engage in largely blind exploration, which often results in failure on challenging problems. To provide additional information for the RLVR process without relying on a teacher model, we propose A$^2$D, an Adaptive Ability Decomposing method for enhancing the effectiveness of RLVR. Specifically, we first train a decomposer via RLVR without distillation, enabling it to decompose complex questions into a set of simpler sub-questions. Next, we use this decomposer to annotate sub-questions for each question in the training dataset, and then train the reasoner under RLVR with sub-question guidance. To better understand A$^2$D, we first compare its performance with competitive baselines, showing its effectiveness. Next, we observe that our method functions as a plug-and-play module that can be applied to different RLVR algorithms. Furthermore, we conduct an analysis of the decomposer, revealing how the RLVR process affects its performance and behavior, and which type of guidance is better suited for enhancing the reasoner's exploration and exploitation abilities.", "AI": {"tldr": "该论文提出了一种自适应能力分解方法A$^2$D，以增强大规模语言模型在强化学习中的推理性能。", "motivation": "在具有验证性奖励的强化学习过程中，由于提供的信息有限，导致模型只能进行盲目的探索，并且常常无法解决复杂问题。为了提供额外的信息而不依赖于教师模型，论文提出了一种自适应能力分解方法A$^2$D。", "method": "首先通过不使用蒸馏技术的方式训练一个解构器以将复杂的任务拆分为一系列简单的子任务；然后利用这个解构器为每个训练数据集中的问题标注出相应的子问题，并在此基础上进行推理模型的强化学习。论文还分析了分解器的表现，探讨了不同类型指导方式对探索与开发能力的影响。", "result": "通过对比实验展示了A$^2$D方法的有效性；同时发现该方法可以作为插件式模块应用于不同的RLVR算法中。", "conclusion": "提出了自适应能力分解方法A$^2$D，解决了大型语言模型在强化学习过程中信息有限的问题，并且证明了其能有效提升推理性能。"}}
{"id": "2602.00755", "pdf": "https://arxiv.org/pdf/2602.00755", "abs": "https://arxiv.org/abs/2602.00755", "authors": ["Ujwal Kumar", "Alice Saito", "Hershraj Niranjani", "Rayan Yessou", "Phan Xuan Tan"], "title": "Evolving Interpretable Constitutions for Multi-Agent Simulation", "categories": ["cs.MA", "cs.AI", "cs.NE"], "comment": "23 pages, 4 figures", "summary": "Constitutional AI has focused on single-model alignment using fixed principles. However, multi-agent systems create novel alignment challenges through emergent social dynamics. We present Constitutional Evolution, a framework for automatically discovering behavioral norms in multi-agent LLM systems. Using a grid-world simulation with survival pressure, we study the tension between individual and collective welfare, quantified via a Societal Stability Score S in [0,1] that combines productivity, survival, and conflict metrics. Adversarial constitutions lead to societal collapse (S= 0), while vague prosocial principles (\"be helpful, harmless, honest\") produce inconsistent coordination (S = 0.249). Even constitutions designed by Claude 4.5 Opus with explicit knowledge of the objective achieve only moderate performance (S= 0.332). Using LLM-driven genetic programming with multi-island evolution, we evolve constitutions maximizing social welfare without explicit guidance toward cooperation. The evolved constitution C* achieves S = 0.556 +/- 0.008 (123% higher than human-designed baselines, N = 10), eliminates conflict, and discovers that minimizing communication (0.9% vs 62.2% social actions) outperforms verbose coordination. Our interpretable rules demonstrate that cooperative norms can be discovered rather than prescribed.", "AI": {"tldr": "通过多智能体仿真研究并演化出最大化社会福利的行为规范", "motivation": "现有的AI宪法集中在单模型对齐上，而多智能体系统中新兴的社会动态带来了新的对齐挑战。本文旨在自动发现行为准则以解决这些问题。", "method": "采用遗传编程和多岛进化算法在网格世界仿真中演化出最大化社会福利的宪法，量化指标为Societal Stability Score S", "result": "演化出的最佳宪法C*实现了比人类设计基线高123%的社会稳定性得分(S = 0.556)，减少了冲突并发现了简化沟通优于冗长协调的现象。", "conclusion": "实验结果表明，通过自动进化而非预设可以发现有益的协作准则。"}}
{"id": "2602.00753", "pdf": "https://arxiv.org/pdf/2602.00753", "abs": "https://arxiv.org/abs/2602.00753", "authors": ["Zeljko Bolevic", "Milos Brajovic", "Isidora Stankovic", "Ljubisa Stankovic"], "title": "GraphNNK -- Graph Classification and Interpretability", "categories": ["cs.LG", "cs.AI"], "comment": "4 pages, 3 figures, IEEE conference paper", "summary": "Graph Neural Networks (GNNs) have become a standard approach for learning from graph-structured data. However, their reliance on parametric classifiers (most often linear softmax layers) limits interpretability and sometimes hinders generalization. Recent work on interpolation-based methods, particularly Non-Negative Kernel regression (NNK), has demonstrated that predictions can be expressed as convex combinations of similar training examples in the embedding space, yielding both theoretical results and interpretable explanations.", "AI": {"tldr": "本文提出了GraphNNK模型，用于提高图分类任务的可解释性和泛化能力。", "motivation": "现有GNN依赖于参数化的分类器，限制了其可解释性并可能影响泛化效果。通过引入基于插值的方法如非负核回归（NNK），可以提供理论上的保证和直观的理解。", "method": "GraphNNK利用非负核回归方法，将预测表示为嵌入空间中相似训练样本的凸组合，提高了模型的可解释性与分类性能。", "result": "实验结果表明，该方法在图分类任务上具有较好的准确性和可解释性。", "conclusion": "本文提出的方法能够有效提升GNN模型的可解释性，并且保持甚至提高了其分类效果。"}}
{"id": "2602.00751", "pdf": "https://arxiv.org/pdf/2602.00751", "abs": "https://arxiv.org/abs/2602.00751", "authors": ["Cláudio Lúcio do Val Lopes", "João Marcus Pitta", "Fabiano Belém", "Gildson Alves", "Flávio Vinícius Cruzeiro Martins"], "title": "Engineering AI Agents for Clinical Workflows: A Case Study in Architecture,MLOps, and Governance", "categories": ["cs.AI", "cs.SE"], "comment": "9 pages, 5 figures 2026 IEEE/ACM 5th International Conference on AI Engineering - Software Engineering for AI}{April 12--13, 2026}{Rio de Janeiro, Brazil", "summary": "The integration of Artificial Intelligence (AI) into clinical settings presents a software engineering challenge, demanding a shift from isolated models to robust, governable, and reliable systems. However, brittle, prototype-derived architectures often plague industrial applications and a lack of systemic oversight, creating a ``responsibility vacuum'' where safety and accountability are compromised. This paper presents an industry case study of the ``Maria'' platform, a production-grade AI system in primary healthcare that addresses this gap. Our central hypothesis is that trustworthy clinical AI is achieved through the holistic integration of four foundational engineering pillars. We present a synergistic architecture that combines Clean Architecture for maintainability with an Event-driven architecture for resilience and auditability. We introduce the Agent as the primary unit of modularity, each possessing its own autonomous MLOps lifecycle. Finally, we show how a Human-in-the-Loop governance model is technically integrated not merely as a safety check, but as a critical, event-driven data source for continuous improvement. We present the platform as a reference architecture, offering practical lessons for engineers building maintainable, scalable, and accountable AI-enabled systems in high-stakes domains.", "AI": {"tldr": "本文介绍了用于初级医疗的“Maria”平台，该平台通过整合四个基础工程支柱来实现可信的临床AI。", "motivation": "当前工业应用中存在因原型衍生架构而导致的安全性和问责制不足的问题。", "method": "提出了一种结合了Clean Architecture和事件驱动架构的综合体系结构，并将代理作为主要模块单元，每个代理都有自己的自主MLOps生命周期。同时采用人机协作治理模型以实现持续改进。", "result": "展示了“Maria”平台如何成为可维护、可扩展且负责任的人工智能系统的参考架构。", "conclusion": "通过综合四个基础工程支柱，“Maria”平台可以为高风险领域中的工程师提供构建可信临床AI的实用经验。"}}
{"id": "2602.00750", "pdf": "https://arxiv.org/pdf/2602.00750", "abs": "https://arxiv.org/abs/2602.00750", "authors": ["Md Jahedur Rahman", "Ihsen Alouani"], "title": "Bypassing Prompt Injection Detectors through Evasive Injections", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly used in interactive and retrieval-augmented systems, but they remain vulnerable to task drift; deviations from a user's intended instruction due to injected secondary prompts. Recent work has shown that linear probes trained on activation deltas of LLMs' hidden layers can effectively detect such drift. In this paper, we evaluate the robustness of these detectors against adversarially optimised suffixes. We generate universal suffixes that cause poisoned inputs to evade detection across multiple probes simultaneously. Our experiments on Phi-3 3.8B and Llama-3 8B show that a single suffix can achieve high attack success rates; up to 93.91% and 99.63%, respectively, when all probes must be fooled, and nearly perfect success (>90%) under majority vote setting. These results demonstrate that activation delta-based task drift detectors are highly vulnerable to adversarial suffixes, highlighting the need for stronger defences against adaptive attacks. We also propose a defence technique where we generate multiple suffixes and randomly append one of them to the prompts while making forward passes of the LLM and train logistic regression models with these activations. We found this approach to be highly effective against such attacks.", "AI": {"tldr": "该论文研究了如何通过生成逃避检测的后缀来绕过大型语言模型中的任务漂移探测器，同时提出了防御策略。", "motivation": "大型语言模型在交互式和检索增强系统中被广泛应用，但仍然容易受到任务漂移的影响。为了应对这一问题，最近的研究提出了一种基于激活差分的线性探针来检测任务漂移。然而，这些探测器是否能抵御经过优化后的后缀攻击尚不清楚。", "method": "本文生成了能够逃避多组线性探针同时检测的通用后缀，并测试了Phi-3和Llama-3模型在不同设置下的表现。此外还提出了一种防御策略：随机选择并添加多个后缀，训练逻辑回归模型进行分类。", "result": "实验结果表明，在所有探测器都被欺骗的情况下，单个后缀可以达到高达93.91%的攻击成功率；而在多数投票设置下，成功率接近于100%。提出的防御策略有效抵御了上述攻击。", "conclusion": "该研究揭示了基于激活差分的任务漂移探测器容易受到经过优化后的后缀攻击，并强调需要开发更强的防御措施来应对适应性攻击"}}
{"id": "2602.00749", "pdf": "https://arxiv.org/pdf/2602.00749", "abs": "https://arxiv.org/abs/2602.00749", "authors": ["Xiangming Wang", "Benteng Sun", "Yungeng Liu", "Haijin Zeng", "Yongyong Chen", "Jingyong Su", "Jie Liu"], "title": "HSI-VAR: Rethinking Hyperspectral Restoration through Spatial-Spectral Visual Autoregression", "categories": ["cs.CV"], "comment": null, "summary": "Hyperspectral images (HSIs) capture richer spatial-spectral information beyond RGB, yet real-world HSIs often suffer from a composite mix of degradations, such as noise, blur, and missing bands. Existing generative approaches for HSI restoration like diffusion models require hundreds of iterative steps, making them computationally impractical for high-dimensional HSIs. While regression models tend to produce oversmoothed results, failing to preserve critical structural details. We break this impasse by introducing HSI-VAR, rethinking HSI restoration as an autoregressive generation problem, where spectral and spatial dependencies can be progressively modeled rather than globally reconstructed. HSI-VAR incorporates three key innovations: (1) Latent-condition alignment, which couples semantic consistency between latent priors and conditional embeddings for precise reconstruction; (2) Degradation-aware guidance, which uniquely encodes mixed degradations as linear combinations in the embedding space for automatic control, remarkably achieving a nearly $50\\%$ reduction in computational cost at inference; (3) A spatial-spectral adaptation module that refines details across both domains in the decoding phase. Extensive experiments on nine all-in-one HSI restoration benchmarks confirm HSI-VAR's state-of-the-art performance, achieving a 3.77 dB PSNR improvement on \\textbf{\\textit{ICVL}} and offering superior structure preservation with an inference speed-up of up to $95.5 \\times$ compared with diffusion-based methods, making it a highly practical solution for real-world HSI restoration.", "AI": {"tldr": "HSI-VAR是一种用于恢复遭受噪声、模糊和缺失波段等复合退化影响的高光谱图像的方法。", "motivation": "现有的生成方法如扩散模型在修复高维高光谱图像时需要数百次迭代，计算成本过高。回归模型则会导致结果过度平滑，无法保留关键结构细节。为解决这些问题，作者提出了HSI-VAR。", "method": "HSI-VAR通过将高光谱图像恢复视为自回归生成问题来建模光谱和空间依赖关系，并引入了三个创新：1）隐变量对齐；2）退化感知引导；3）空域适应模块。", "result": "实验结果表明，HSI-VAR在ICVL上实现了3.77dB的PSNR增益，并且与基于扩散的方法相比，推理速度提高了95.5倍。", "conclusion": "HSI-VAR通过引入自回归生成和独特的创新技术，在高光谱图像恢复中达到了最先进的性能，同时显著降低了计算成本。"}}
{"id": "2602.00748", "pdf": "https://arxiv.org/pdf/2602.00748", "abs": "https://arxiv.org/abs/2602.00748", "authors": ["Fangxin Liu", "Qinghua Zhang", "Hanjing Shen", "Qinghua Zhang", "Zhibo Liang", "Li Jiang", "Haibing Guan", "Chong Bao", "Xuefeng Jin"], "title": "HyperOffload: Graph-Driven Hierarchical Memory Management for Large Language Models on SuperNode Architectures", "categories": ["cs.DC", "cs.AI", "cs.AR"], "comment": "Technical Report", "summary": "The rapid evolution of Large Language Models (LLMs) towards long-context reasoning and sparse architectures has pushed memory requirements far beyond the capacity of individual device HBM. While emerging supernode architectures offer terabyte-scale shared memory pools via high-bandwidth interconnects, existing software stacks fail to exploit this hardware effectively. Current runtime-based offloading and swapping techniques operate with a local view, leading to reactive scheduling and exposed communication latency that stall the computation pipeline. In this paper, we propose the SuperNode Memory Management Framework (\\textbf{HyperOffload}). It employs a compiler-assisted approach that leverages graph-driven memory management to treat remote memory access as explicit operations in the computation graph, specifically designed for hierarchical SuperNode architectures. Unlike reactive runtime systems, SuperNode represents data movement using cache operators within the compiler's Intermediate Representation (IR). This design enables a global, compile-time analysis of tensor lifetimes and execution dependencies. Leveraging this visibility, we develop a global execution-order refinement algorithm that statically schedules data transfers to hide remote memory latency behind compute-intensive regions. We implement SuperNode within the production deep learning framework MindSpore, adding a remote memory backend and specialized compiler passes. Evaluation on representative LLM workloads shows that SuperNode reduces peak device memory usage by up to 26\\% for inference while maintaining end-to-end performance. Our work demonstrates that integrating memory-augmented hardware into the compiler's optimization framework is essential for scaling next-generation AI workloads.", "AI": {"tldr": "本文提出了HyperOffload框架，通过编译器辅助的图驱动内存管理方法，在超节点架构中优化大型语言模型的内存使用。", "motivation": "随着大型语言模型的发展，它们对长上下文推理和稀疏结构的需求导致了单个设备HBM容量不足。现有软件栈未能有效利用高性能互联提供的大规模共享内存池，而现有的运行时基于卸载和交换的技术只具备局部视角，导致反应式调度和暴露的通信延迟。", "method": "HyperOffload通过编译器辅助的方式，在计算图中将远程内存访问作为显式操作处理。这种方法使用缓存操作表示数据移动，并利用中间表达式的全局视图进行静态分析与优化。具体实现包括添加远程内存后端和专门的编译器传递。", "result": "在典型的大型语言模型工作负载上，HyperOffload将峰值设备内存使用量减少了高达26%，同时保持了整体性能。", "conclusion": "本文证明了将增强型硬件集成到编译器优化框架中对于扩展下一代人工智能任务至关重要。"}}
{"id": "2602.00747", "pdf": "https://arxiv.org/pdf/2602.00747", "abs": "https://arxiv.org/abs/2602.00747", "authors": ["Shengrui Li", "Fei Zhao", "Kaiyan Zhao", "Jieying Ye", "Haifeng Liu", "Fangcheng Shi", "Zheyong Xie", "Yao Hu", "Shaosheng Cao"], "title": "Decouple Searching from Training: Scaling Data Mixing via Model Merging for Large Language Model Pre-training", "categories": ["cs.CL", "cs.AI"], "comment": "17 pages, 5 figures", "summary": "Determining an effective data mixture is a key factor in Large Language Model (LLM) pre-training, where models must balance general competence with proficiency on hard tasks such as math and code. However, identifying an optimal mixture remains an open challenge, as existing approaches either rely on unreliable tiny-scale proxy experiments or require prohibitively expensive large-scale exploration. To address this, we propose Decouple Searching from Training Mix (DeMix), a novel framework that leverages model merging to predict optimal data ratios. Instead of training proxy models for every sampled mixture, DeMix trains component models on candidate datasets at scale and derives data mixture proxies via weighted model merging. This paradigm decouples search from training costs, enabling evaluation of unlimited sampled mixtures without extra training burden and thus facilitating better mixture discovery through more search trials. Extensive experiments demonstrate that DeMix breaks the trade-off between sufficiency, accuracy and efficiency, obtaining the optimal mixture with higher benchmark performance at lower search cost. Additionally, we release the DeMix Corpora, a comprehensive 22T-token dataset comprising high-quality pre-training data with validated mixtures to facilitate open research. Our code and DeMix Corpora is available at https://github.com/Lucius-lsr/DeMix.", "AI": {"tldr": "论文提出了一种新的框架DeMix，用于在大规模语言模型预训练中找到最佳数据混合策略。", "motivation": "确定有效的数据混合是大规模语言模型预训练的关键因素之一。现有的方法要么依赖不可靠的小规模代理实验，要么需要昂贵的大规模探索。这导致了识别最优混合的挑战。", "method": "DeMix通过模型合并来预测最优的数据比例。它在候选数据集上以较大规模训练组件模型，并通过加权模型合并生成数据混合代理，从而将搜索与训练成本解耦。", "result": "实验表明，DeMix打破了足够性、准确性和效率之间的折衷，可以以较低的成本找到具有更高基准性能的最佳混合。", "conclusion": "论文提出了一个新的框架DeMix，它通过模型合并预测最优的数据比例，使得大规模语言模型预训练中的数据搜索更加高效和准确。"}}
{"id": "2602.00746", "pdf": "https://arxiv.org/pdf/2602.00746", "abs": "https://arxiv.org/abs/2602.00746", "authors": ["Jianping Zhong", "Guochang Li", "Chen Zhi", "Junxiao Han", "Zhen Qin", "Xinkui Zhao", "Nan Wang", "Shuiguang Deng", "Jianwei Yin"], "title": "Can Vision-Language Models Handle Long-Context Code? An Empirical Study on Visual Compression", "categories": ["cs.SE", "cs.CV"], "comment": null, "summary": "Large Language Models (LLMs) struggle with long-context code due to window limitations. Existing textual code compression methods mitigate this via selective filtering but often disrupt dependency closure, causing semantic fragmentation. To address this, we introduce LongCodeOCR, a visual compression framework that renders code into compressed two-dimensional image sequences for Vision-Language Models (VLMs). By preserving a global view, this approach avoids the dependency breakage inherent in filtering. We systematically evaluate LongCodeOCR against the state-of-the-art LongCodeZip across four benchmarks spanning code summarization, code question answering, and code completion. Our results demonstrate that visual code compression serves as a viable alternative for tasks requiring global understanding. At comparable compression ratios ($\\sim$1.7$\\times$), LongCodeOCR improves CompScore on Long Module Summarization by 36.85 points over LongCodeZip. At a 1M-token context length with Glyph (a specialized 9B VLM), LongCodeOCR maintains higher accuracy than LongCodeZip while operating at about 4$\\times$ higher compression. Moreover, compared with LongCodeZip, LongCodeOCR drastically reduces compression-stage overhead (reducing latency from $\\sim$4.3 hours to $\\sim$1 minute at 1M tokens). Finally, our results characterize a fundamental coverage--fidelity trade-off: visual code compression retains broader context coverage to support global dependencies, yet faces fidelity bottlenecks on exactness-critical tasks; by contrast, textual code compression preserves symbol-level precision while sacrificing structural coverage.", "AI": {"tldr": "本文介绍了LongCodeOCR，一种用于处理长代码上下文的视觉压缩框架，以提高Vision-Language模型的表现。", "motivation": "现有的文本压缩方法在选择性过滤时容易破坏依赖关系，导致语义片段化。为了克服这一问题，文章提出了LongCodeOCR来保持全局视图并避免依赖断裂。", "method": "通过将代码渲染为二维图像序列，LongCodeOCR利用视觉压缩框架解决长上下文的挑战，并与现有的文本压缩方法进行对比评估。", "result": "实验结果表明，在1M令牌长度下，使用Glyph VLM时，LongCodeOCR比LongCodeZip在压缩阶段减少了大约4.3小时到1分钟的时间。此外，LongCodeOCR在长模块摘要任务上的CompScore提高了36.85点，并且总体上保持了更高的准确率。", "conclusion": "视觉代码压缩作为一种替代方案，在需要全局理解的任务中表现良好；然而，它与文本压缩方法相比存在覆盖度与精确性的权衡。"}}
{"id": "2602.00744", "pdf": "https://arxiv.org/pdf/2602.00744", "abs": "https://arxiv.org/abs/2602.00744", "authors": ["Junmin Gong", "Yulin Song", "Wenxiao Zhao", "Sen Wang", "Shengyuan Xu", "Jing Guo"], "title": "ACE-Step 1.5: Pushing the Boundaries of Open-Source Music Generation", "categories": ["cs.SD"], "comment": null, "summary": "We present ACE-Step v1.5, a highly efficient open-source music foundation model that brings commercial-grade generation to consumer hardware. On commonly used evaluation metrics, ACE-Step v1.5 achieves quality beyond most commercial music models while remaining extremely fast -- under 2 seconds per full song on an A100 and under 10 seconds on an RTX 3090. The model runs locally with less than 4GB of VRAM, and supports lightweight personalization: users can train a LoRA from just a few songs to capture their own style. At its core lies a novel hybrid architecture where the Language Model (LM) functions as an omni-capable planner: it transforms simple user queries into comprehensive song blueprints -- scaling from short loops to 10-minute compositions -- while synthesizing metadata, lyrics, and captions via Chain-of-Thought to guide the Diffusion Transformer (DiT). Uniquely, this alignment is achieved through intrinsic reinforcement learning relying solely on the model's internal mechanisms, thereby eliminating the biases inherent in external reward models or human preferences. Beyond standard synthesis, ACE-Step v1.5 unifies precise stylistic control with versatile editing capabilities -- such as cover generation, repainting, and vocal-to-BGM conversion -- while maintaining strict adherence to prompts across 50+ languages. This paves the way for powerful tools that seamlessly integrate into the creative workflows of music artists, producers, and content creators. The code, the model weights and the demo are available at: https://ace-step.github.io/ace-step-v1.5.github.io/", "AI": {"tldr": "ACE-Step v1.5 是一种高效的开源音乐基础模型，能够在消费者硬件上生成商业级别的音乐。", "motivation": "通过提高开放源代码音乐生成的质量和效率来满足市场的需求，并使个人用户能够轻松定制自己的风格。", "method": "该模型采用了一种新颖的混合架构，在语言模型（LM）的帮助下将简单的用户查询转化为详细的歌曲蓝图，同时利用强化学习机制调整生成过程以减少偏见。此外，它支持轻量级个性化训练和多种编辑功能。", "result": "ACE-Step v1.5 在常用的评价指标上表现优异，能够生成高质量的音乐，并且速度快、占用资源少。用户仅需少量歌曲即可进行自定义风格训练。", "conclusion": "ACE-Step v1.5 的推出为音乐艺术家、制作人和内容创作者提供了强大的工具，可以无缝集成到他们的创意流程中。"}}
{"id": "2602.00743", "pdf": "https://arxiv.org/pdf/2602.00743", "abs": "https://arxiv.org/abs/2602.00743", "authors": ["Xu Pan", "Zhenglin Wan", "Xingrui Yu", "Xianwei Zheng", "Youkai Ke", "Ming Sun", "Rui Wang", "Ziwei Wang", "Ivor Tsang"], "title": "SA-VLA: Spatially-Aware Flow-Matching for Vision-Language-Action Reinforcement Learning", "categories": ["cs.RO", "cs.AI"], "comment": "Version 1", "summary": "Vision-Language-Action (VLA) models exhibit strong generalization in robotic manipulation, yet reinforcement learning (RL) fine-tuning often degrades robustness under spatial distribution shifts. For flow-matching VLA policies, this degradation is closely associated with the erosion of spatial inductive bias during RL adaptation, as sparse rewards and spatially agnostic exploration increasingly favor short-horizon visual cues. To address this issue, we propose \\textbf{SA-VLA}, a spatially-aware RL adaptation framework that preserves spatial grounding during policy optimization by aligning representation learning, reward design, and exploration with task geometry. SA-VLA fuses implicit spatial representations with visual tokens, provides dense rewards that reflect geometric progress, and employs \\textbf{SCAN}, a spatially-conditioned annealed exploration strategy tailored to flow-matching dynamics. Across challenging multi-object and cluttered manipulation benchmarks, SA-VLA enables stable RL fine-tuning and improves zero-shot spatial generalization, yielding more robust and transferable behaviors. Code and project page are available at https://xupan.top/Projects/savla.", "AI": {"tldr": "提出了一种新的框架SA-VLA，用于解决视觉语言动作模型在强化学习适应过程中出现的空间分布变化问题。", "motivation": "针对视觉语言动作(VLA)模型在机器人操作中的泛化能力强但强化学习微调时容易降低空间稳健性的问题，旨在通过保持策略优化过程中的空间定位来提高模型的鲁棒性和可转移性。", "method": "SA-VLA融合了隐含的空间表示和视觉标记，并设计了密集奖励以反映几何进展。同时使用SCAN策略进行条件空间探索，适用于流匹配动力学。", "result": "在多对象和杂乱环境中进行了挑战性测试，结果显示SA-VLA能够稳定地进行强化学习微调并提高零样本空间泛化能力。", "conclusion": "通过保持模型的空间定位并利用适应的策略优化框架，在复杂任务中提高了视觉语言动作模型的鲁棒性和可转移性。"}}
{"id": "2602.00740", "pdf": "https://arxiv.org/pdf/2602.00740", "abs": "https://arxiv.org/abs/2602.00740", "authors": ["Ziyan Xiao", "Yinghao Zhu", "Liang Peng", "Lequan Yu"], "title": "ExperienceWeaver: Optimizing Small-sample Experience Learning for LLM-based Clinical Text Improvement", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Clinical text improvement is vital for healthcare efficiency but remains difficult due to limited high-quality data and the complex constraints of medical documentation. While Large Language Models (LLMs) show promise, current approaches struggle in small-sample settings: supervised fine-tuning is data-intensive and costly, while retrieval-augmented generation often provides superficial corrections without capturing the reasoning behind revisions. To address these limitations, we propose ExperienceWeaver, a hierarchical framework that shifts the focus from data retrieval to experience learning. Instead of simply recalling past examples, ExperienceWeaver distills noisy, multi-dimensional feedback into structured, actionable knowledge. Specifically, error-specific Tips and high-level Strategies. By injecting this distilled experience into an agentic pipeline, the model learns \"how to revise\" rather than just \"what to revise\". Extensive evaluations across four clinical datasets demonstrate that ExperienceWeaver consistently improves performance, surpassing state-of-the-art models such as Gemini-3 Pro in small-sample settings.", "AI": {"tldr": "ExperienceWeaver是一种优化基于LLM的临床文本改进的小样本经验学习框架。", "motivation": "当前方法在小样本环境下难以有效利用有限的高质量数据进行监督微调或通过检索增强生成技术进行表面修改，缺乏深层次的理解和纠正能力。因此提出了一个旨在从过去的经验中提炼出结构化、可操作的知识来指导文本改进的新框架ExperienceWeaver。", "method": "ExperienceWeaver采用了一个分层框架，将关注点从数据检索转移到经验学习上，通过提取错误特定的建议（Tips）和高层次策略（Strategies），并将其注入到代理管道中以实现模型不仅知道“修改什么”，而且掌握“如何修改”的能力。", "result": "在四个临床数据集上的广泛评估显示，ExperienceWeaver能够在小样本条件下表现出色，并超越了诸如Gemini-3 Pro等最先进的模型。", "conclusion": "通过将注意力从直接的数据检索转向经验学习的提炼和应用，ExperienceWeaver为解决基于LLM的小样本文本改进任务提供了一种有效的方法。"}}
{"id": "2602.00739", "pdf": "https://arxiv.org/pdf/2602.00739", "abs": "https://arxiv.org/abs/2602.00739", "authors": ["Zhengyan Qin", "Liyuan Qiu"], "title": "Diffusion-Driven Inter-Outer Surface Separation for Point Clouds with Open Boundaries", "categories": ["cs.CV"], "comment": null, "summary": "We propose a diffusion-based algorithm for separating the inter and outer layer surfaces from double-layered point clouds, particularly those exhibiting the \"double surface artifact\" caused by truncation in Truncated Signed Distance Function (TSDF) fusion during indoor or medical 3D reconstruction. This artifact arises from asymmetric truncation thresholds, leading to erroneous inter and outer shells in the fused volume, which our method addresses by extracting the true inter layer to mitigate challenges like overlapping surfaces and disordered normals. We focus on point clouds with \\emph{open boundaries} (i.e., sampled surfaces with topological openings/holes through which particles may escape), rather than point clouds with \\emph{missing surface regions} where no samples exist. Our approach enables robust processing of both watertight and open-boundary models, achieving extraction of the inter layer from 20,000 inter and 20,000 outer points in approximately 10 seconds. This solution is particularly effective for applications requiring accurate surface representations, such as indoor scene modeling and medical imaging, where double-layered point clouds are prevalent, and it accommodates both closed (watertight) and open-boundary surface geometries. Our goal is \\emph{post-hoc} inter/outer shell separation as a lightweight module after TSDF fusion; we do not aim to replace full variational or learning-based reconstruction pipelines.", "AI": {"tldr": "提出了一种基于扩散的算法，用于从具有“双表面伪影”的双层点云中分离内外层表面。", "motivation": "解决由不对称截断阈值导致的TSDF融合期间产生的双层点云中的错误内层和外层壳的问题。", "method": "通过提取真正的内层来处理开放边界点云，该方法适用于封闭或带有拓扑开口的模型。", "result": "从20,000个内层和20,000个外层点中分离出内层仅需大约10秒。", "conclusion": "提出的方法解决了双层点云中的表面表示问题，并且作为TSDF融合后的模块，适用于室内场景建模和医学成像等应用。"}}
{"id": "2602.00738", "pdf": "https://arxiv.org/pdf/2602.00738", "abs": "https://arxiv.org/abs/2602.00738", "authors": ["Zhida Sun", "Xiaodong Wang", "Zhenyao Zhang", "Min Lu", "Dani Lischinski", "Daniel Cohen-Or", "Hui Huang"], "title": "Iconix: Controlling Semantics and Style in Progressive Icon Grids Generation", "categories": ["cs.HC", "cs.GR"], "comment": "21 pages, 9 figures, Accepted to ACM CHI'26", "summary": "Visual communication often needs stylistically consistent icons that span concrete and abstract meanings, for use in diverse contexts. We present Iconix, a human-AI co-creative system that organizes icon generation along two axes: semantic richness (what is depicted) and visual complexity (how much detail). Given a user-specified concept, Iconix constructs a semantic scaffold of related analytical perspectives and employs chained, image-conditioned generation to produce a coherent style of exemplars. Each exemplar is then automatically distilled into a progressive sequence, from detailed and elaborate to abstract and simple. The resulting two-dimensional grid exposes a navigable space, helping designers reason jointly about figurative content and visual abstraction. A within-subjects study (N = 32) found that compared to a baseline workflow, participants produced icon grids more creatively, reported lower workload, and explored a coherent range of design variations. We discuss implications for human-machine co-creative approaches that couple semantic scaffolding with progressive simplification to support visual abstraction.", "AI": {"tldr": "本文提出了一个名为Iconix的人机协同创意系统，用于生成具有连续语义和风格的图标网格。", "motivation": "为了帮助设计者在不同的上下文中创建一致且富有表现力的图标集合，该论文旨在提供一种新的方法来同时控制图标的语义丰富度和视觉复杂性。", "method": "给定一个用户指定的概念后，Iconix系统构建相关的分析视角，并通过链式图像条件生成技术生成一系列具有连贯风格的样本，然后将每个样本自动提炼成从详细到抽象的渐进序列。", "result": "在一项包含32名参与者的实验中发现，与基线工作流程相比，用户使用该方法创造的图标网格更具创意，报告的工作量更小，并且探索了一致的设计变体范围。", "conclusion": "论文探讨了结合语义支架和逐步简化的人机协同创意方法如何支持视觉抽象化的过程。"}}
{"id": "2602.00737", "pdf": "https://arxiv.org/pdf/2602.00737", "abs": "https://arxiv.org/abs/2602.00737", "authors": ["Jatan Shrestha", "Santeri Heiskanen", "Kari Hepola", "Severi Rissanen", "Pekka Jääskeläinen", "Joni Pajarinen"], "title": "Pareto-Conditioned Diffusion Models for Offline Multi-Objective Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICLR 2026. Project page: https://sites.google.com/view/pcd-iclr26", "summary": "Multi-objective optimization (MOO) arises in many real-world applications where trade-offs between competing objectives must be carefully balanced. In the offline setting, where only a static dataset is available, the main challenge is generalizing beyond observed data. We introduce Pareto-Conditioned Diffusion (PCD), a novel framework that formulates offline MOO as a conditional sampling problem. By conditioning directly on desired trade-offs, PCD avoids the need for explicit surrogate models. To effectively explore the Pareto front, PCD employs a reweighting strategy that focuses on high-performing samples and a reference-direction mechanism to guide sampling towards novel, promising regions beyond the training data. Experiments on standard offline MOO benchmarks show that PCD achieves highly competitive performance and, importantly, demonstrates greater consistency across diverse tasks than existing offline MOO approaches.", "AI": {"tldr": "本文提出了一种条件扩散模型，用于离线多目标优化问题。", "motivation": "在现实世界应用中，多目标优化需要平衡竞争性目标。离线设置中的主要挑战是超越观察数据进行泛化。", "method": "PCD框架将离线MOO作为条件采样问题来处理，并通过重新加权策略和参考方向机制有效探索帕累托前沿。", "result": "实验表明，PCD在标准的离线多目标优化基准上达到了高度竞争性的性能，并且具有更好的跨任务一致性。", "conclusion": "PCD框架提供了一种新颖的方法来解决离线多目标优化问题，展示了优越的表现和泛化能力。"}}
{"id": "2602.00733", "pdf": "https://arxiv.org/pdf/2602.00733", "abs": "https://arxiv.org/abs/2602.00733", "authors": ["Yinuo Zhang", "Dingcheng Huang", "Haifeng Suo", "Yizhuo Li", "Ziya Zhao", "Junhao Xu", "Zhiying Tu", "Dianhui Chu", "Deming Zhai", "Xianming Liu", "Xiaoyan Yu", "Dianbo Sui"], "title": "EchoReview: Learning Peer Review from the Echoes of Scientific Citations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As the volume of scientific submissions continues to grow rapidly, traditional peer review systems are facing unprecedented scalability pressures, highlighting the urgent need for automated reviewing methods that are both scalable and reliable. Existing supervised fine-tuning approaches based on real review data are fundamentally constrained by single-source of data as well as the inherent subjectivity and inconsistency of human reviews, limiting their ability to support high-quality automated reviewers. To address these issues, we propose EchoReview, a citation-context-driven data synthesis framework that systematically mines implicit collective evaluative signals from academic citations and transforms scientific community's long-term judgments into structured review-style data. Based on this pipeline, we construct EchoReview-16K, the first large-scale, cross-conference, and cross-year citation-driven review dataset, and train an automated reviewer, EchoReviewer-7B. Experimental results demonstrate that EchoReviewer-7B can achieve significant and stable improvements on core review dimensions such as evidence support and review comprehensiveness, validating citation context as a robust and effective data paradigm for reliable automated peer review.", "AI": {"tldr": "提出EchoReview框架，利用学术引用中的隐含评价信号合成评审数据，构建大规模跨会议跨年度的引用驱动评审数据集，并训练出性能稳定的自动化审稿系统。", "motivation": "传统同行评审系统在快速增长的研究提交数量面前面临可扩展性压力，现有基于真实评论数据的监督微调方法受限于单一数据源和人工评价的主观性和不一致性。提出EchoReview以解决这些问题。", "method": "通过引用上下文驱动的数据合成框架从学术引用中挖掘隐含集体评价信号，并将其转化为结构化评审形式数据，构建了大规模跨会议跨年度的引用驱动评论数据集EchoReview-16K，训练出自动化审稿系统EchoReviewer-7B。", "result": "实验结果显示，EchoReviewer-7B在证据支持和评论全面性等核心评审维度上实现了显著且稳定的改进。", "conclusion": "验证了引用上下文作为可靠自动化同行评审的数据范式的有效性和鲁棒性。"}}
{"id": "2602.00731", "pdf": "https://arxiv.org/pdf/2602.00731", "abs": "https://arxiv.org/abs/2602.00731", "authors": ["Kyle Hamilton", "Ali Intizar"], "title": "Neuro-symbolic AI for Predictive Maintenance (PdM) -- review and recommendations", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "In this document we perform a systematic review the State-of-the-art in Predictive Maintenance (PdM) over the last five years in industrial settings such as commercial buildings, pharmaceutical facilities, or semi-conductor manufacturing. In general, data-driven methods such as those based on deep learning, exhibit higher accuracy than traditional knowledge-based systems. These systems however, are not without significant limitations. The need for large labeled data sets, a lack of generalizibility to new environments (out-of-distribution generalization), and a lack of transparency at inference time are some of the obstacles to adoption in real world environments. In contrast, traditional approaches based on domain expertise in the form of rules, logic or first principles suffer from poor accuracy, many false positives and a need for ongoing expert supervision and manual tuning. While the majority of approaches in recent literature utilize some form of data-driven architecture, there are hybrid systems which also take into account domain specific knowledge. Such hybrid systems have the potential to overcome the weaknesses of either approach on its own while preserving their strengths. We propose taking the hybrid approach even further and integrating deep learning with symbolic logic, or Neuro-symbolic AI, to create more accurate, explainable, interpretable, and robust systems. We describe several neuro-symbolic architectures and examine their strengths and limitations within the PdM domain. We focus specifically on methods which involve the use of sensor data and manually crafted rules as inputs by describing concrete NeSy architectures. In short, this survey outlines the context of modern maintenance, defines key concepts, establishes a generalized framework, reviews current modeling approaches and challenges, and introduces the proposed focus on Neuro-symbolic AI (NESY).", "AI": {"tldr": "该论文综述了过去五年中工业环境中的预测性维护（PdM）领域的现状，特别关注神经符号AI方法，并提出了结合深度学习和符号逻辑的混合系统以提高准确性和解释性的建议。", "motivation": "数据驱动的方法在预测性维护领域表现出高精度，但受限于大标签数据集需求、泛化能力不足及缺乏透明度。传统基于规则或原理的知识系统则由于准确性低和依赖专家监督而难以应用。因此，论文提出神经符号AI作为结合两者优势的潜在解决方案。", "method": "综述了过去五年中预测性维护领域的研究进展，并详细介绍了几种涉及传感器数据和手工规则输入的具体神经符号架构。", "result": "概述了现代维护背景、定义关键概念并构建了一般框架，审查现有建模方法及其挑战。提出了将深度学习与符号逻辑相结合的混合系统来克服单一方法的缺点。", "conclusion": "论文通过展示几种神经符号架构的优势和限制，强调了其在预测性维护中的潜力，并推荐进一步研究以实现更准确、可解释且鲁棒性的PdM系统。"}}
{"id": "2602.00729", "pdf": "https://arxiv.org/pdf/2602.00729", "abs": "https://arxiv.org/abs/2602.00729", "authors": ["Qihe Pan", "Yiming Wu", "Xing Zhao", "Liang Xie", "Guodao Sun", "Ronghua Liang"], "title": "Supervised makeup transfer with a curated dataset: Decoupling identity and makeup features for enhanced transformation", "categories": ["cs.CV"], "comment": "This paper has been accepted for publication in the proceedings of 2026 IEEE ICASSP Conference", "summary": "Diffusion models have recently shown strong progress in generative tasks, offering a more stable alternative to GAN-based approaches for makeup transfer. Existing methods often suffer from limited datasets, poor disentanglement between identity and makeup features, and weak controllability. To address these issues, we make three contributions. First, we construct a curated high-quality dataset using a train-generate-filter-retrain strategy that combines synthetic, realistic, and filtered samples to improve diversity and fidelity. Second, we design a diffusion-based framework that disentangles identity and makeup features, ensuring facial structure and skin tone are preserved while applying accurate and diverse cosmetic styles. Third, we propose a text-guided mechanism that allows fine-grained and region-specific control, enabling users to modify eyes, lips, or face makeup with natural language prompts. Experiments on benchmarks and real-world scenarios demonstrate improvements in fidelity, identity preservation, and flexibility. Examples of our dataset can be found at: https://makeup-adapter.github.io.", "AI": {"tldr": "本文提出了一种基于扩散模型的化妆转换方法，通过精心设计的数据集和解耦身份与妆容特征的技术来提高化妆转移的效果。", "motivation": "现有的化妆转换方法存在数据集有限、难以分离身份与妆容特征以及控制性弱的问题。因此，本文旨在构建高质量的数据集并提出一种新的扩散模型框架以解决这些问题。", "method": "首先，作者通过合成、真实和过滤样本相结合的方式创建了一个高度多样化的高质量训练集。其次，设计了一种解耦身份和化妆特征的扩散模型框架，确保在进行化妆转移时面部结构和肤色保持不变，仅改变妆容风格。此外，还提出了文本指导机制，使用户能够使用自然语言指令对眼睛、嘴唇或脸部的不同部位进行精细调整。", "result": "实验结果表明，本文方法提高了化妆转换的保真度、身份保留能力以及灵活性，并在基准测试和实际场景中展示了优越的表现。", "conclusion": "通过引入高质量的数据集和有效的模型框架，该研究成功地改进了化妆转移的效果，为用户提供了一个更加自然且可控的化妆调整工具。"}}
{"id": "2602.00726", "pdf": "https://arxiv.org/pdf/2602.00726", "abs": "https://arxiv.org/abs/2602.00726", "authors": ["Yinghao Zhu", "Dehao Sui", "Zixiang Wang", "Xuning Hu", "Lei Gu", "Yifan Qi", "Tianchen Wu", "Ling Wang", "Yuan Wei", "Wen Tang", "Zhihan Cui", "Yasha Wang", "Lequan Yu", "Ewen M Harrison", "Junyi Gao", "Liantao Ma"], "title": "Augmenting Clinical Decision-Making with an Interactive and Interpretable AI Copilot: A Real-World User Study with Clinicians in Nephrology and Obstetrics", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted by ACM CHI 2026", "summary": "Clinician skepticism toward opaque AI hinders adoption in high-stakes healthcare. We present AICare, an interactive and interpretable AI copilot for collaborative clinical decision-making. By analyzing longitudinal electronic health records, AICare grounds dynamic risk predictions in scrutable visualizations and LLM-driven diagnostic recommendations. Through a within-subjects counterbalanced study with 16 clinicians across nephrology and obstetrics, we comprehensively evaluated AICare using objective measures (task completion time and error rate), subjective assessments (NASA-TLX, SUS, and confidence ratings), and semi-structured interviews. Our findings indicate AICare's reduced cognitive workload. Beyond performance metrics, qualitative analysis reveals that trust is actively constructed through verification, with interaction strategies diverging by expertise: junior clinicians used the system as cognitive scaffolding to structure their analysis, while experts engaged in adversarial verification to challenge the AI's logic. This work offers design implications for creating AI systems that function as transparent partners, accommodating diverse reasoning styles to augment rather than replace clinical judgment.", "AI": {"tldr": "本文介绍了AICare系统，该系统旨在通过可视化和LLM驱动的诊断建议来增强临床决策过程。", "motivation": "在高风险医疗领域中，由于对不透明AI系统的怀疑而阻碍了其采用。为了减轻这种问题，本文提出了一个交互式且可解释的人工智能辅助工具AICare。", "method": "通过与16名不同科室的临床医生进行对照组研究来评估AICare的效果，包括客观指标（任务完成时间和错误率）和主观评价（NASA-TLX、SUS及信心评分），以及半结构化访谈。", "result": "结果表明，使用AICare可以减少认知工作量。此外，质性分析显示信任是通过验证过程建立起来的，并且根据专业水平不同而采取不同的互动策略：初级医生将该系统作为思维框架来构建分析，而高级医生则利用对抗验证挑战AI逻辑。", "conclusion": "本文的工作对创建能够透明协作的人工智能系统的未来设计提出了建议。这些系统应该适应各种推理方式，从而增强而不是取代临床判断。"}}
{"id": "2602.00723", "pdf": "https://arxiv.org/pdf/2602.00723", "abs": "https://arxiv.org/abs/2602.00723", "authors": ["Prakhar Ganesh", "Reza Shokri", "Golnoosh Farnadi"], "title": "Rethinking Hallucinations: Correctness, Consistency, and Prompt Multiplicity", "categories": ["cs.LG", "cs.AI"], "comment": "To appear at EACL 2026", "summary": "Large language models (LLMs) are known to \"hallucinate\" by generating false or misleading outputs. Hallucinations pose various harms, from erosion of trust to widespread misinformation. Existing hallucination evaluation, however, focuses only on correctness and often overlooks consistency, necessary to distinguish and address these harms. To bridge this gap, we introduce prompt multiplicity, a framework for quantifying consistency in LLM evaluations. Our analysis reveals significant multiplicity (over 50% inconsistency in benchmarks like Med-HALT), suggesting that hallucination-related harms have been severely misunderstood. Furthermore, we study the role of consistency in hallucination detection and mitigation. We find that: (a) detection techniques detect consistency, not correctness, and (b) mitigation techniques like RAG, while beneficial, can introduce additional inconsistencies. By integrating prompt multiplicity into hallucination evaluation, we provide an improved framework of potential harms and uncover critical limitations in current detection and mitigation strategies.", "AI": {"tldr": "重新思考幻觉问题，提出一个框架来量化语言模型的一致性。", "motivation": "大型语言模型存在生成虚假或误导信息的问题。现有的评估方法主要关注正确性而忽视了一致性，导致对幻觉相关危害的理解不足。", "method": "引入了提示多重性的概念，用于评估一致性，并通过分析基准数据集发现显著的一致性问题。", "result": "检测技术侧重于一致性的检测而非正确性；缓解策略如RAG虽然有益但可能会引入额外的不一致性。", "conclusion": "通过将提示多重性纳入幻觉评估框架中，更好地理解了语言模型的潜在危害，并揭示了当前检测和缓解策略中的局限性。"}}
{"id": "2602.00717", "pdf": "https://arxiv.org/pdf/2602.00717", "abs": "https://arxiv.org/abs/2602.00717", "authors": ["Licheng Pan", "Hao Wang", "Haocheng Yang", "Yuqi Li", "Qingsong Wen", "Xiaoxi Li", "Zhichao Chen", "Haoxuan Li", "Zhixuan Chu", "Yuan Lu"], "title": "Deep Time-series Forecasting Needs Kernelized Moment Balancing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep time-series forecasting can be formulated as a distribution balancing problem aimed at aligning the distribution of the forecasts and ground truths. According to Imbens' criterion, true distribution balance requires matching the first moments with respect to any balancing function. We demonstrate that existing objectives fail to meet this criterion, as they enforce moment matching only for one or two predefined balancing functions, thus failing to achieve full distribution balance. To address this limitation, we propose direct forecasting with kernelized moment balancing (KMB-DF). Unlike existing objectives, KMB-DF adaptively selects the most informative balancing functions from a reproducing kernel hilbert space (RKHS) to enforce sufficient distribution balancing. We derive a tractable and differentiable objective that enables efficient estimation from empirical samples and seamless integration into gradient-based training pipelines. Extensive experiments across multiple models and datasets show that KMB-DF consistently improves forecasting accuracy and achieves state-of-the-art performance. Code is available at https://anonymous.4open.science/r/KMB-DF-403C.", "AI": {"tldr": "论文提出了一种新的深度时间序列预测方法，通过核化矩平衡（KMB）实现更全面的分布均衡。", "motivation": "现有目标仅匹配一两个预先定义的平衡函数的矩，无法满足充分分布平衡的要求。因此，作者希望通过一种新方法来解决这一问题。", "method": "论文提出了一种称为直接预测中的核化矩平衡（KMB-DF）的方法，它从再生希尔伯特空间中自适应地选择最相关的平衡函数进行匹配，以实现更全面的分布平衡。", "result": "实验结果表明，KMB-DF能够提高时间序列预测的准确性，并达到最先进的性能。", "conclusion": "通过核化矩平衡的方法，论文成功实现了对深度时间序列预测中分布均衡问题的有效解决。"}}
{"id": "2602.00711", "pdf": "https://arxiv.org/pdf/2602.00711", "abs": "https://arxiv.org/abs/2602.00711", "authors": ["Ranjith Krishnamurthy", "Oshando Johnson", "Goran Piskachev", "Eric Bodden"], "title": "From Detection to Prevention: Explaining Security-Critical Code to Avoid Vulnerabilities", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": "4 pages", "summary": "Security vulnerabilities often arise unintentionally during development due to a lack of security expertise and code complexity. Traditional tools, such as static and dynamic analysis, detect vulnerabilities only after they are introduced in code, leading to costly remediation. This work explores a proactive strategy to prevent vulnerabilities by highlighting code regions that implement security-critical functionality -- such as data access, authentication, and input handling -- and providing guidance for their secure implementation. We present an IntelliJ IDEA plugin prototype that uses code-level software metrics to identify potentially security-critical methods and large language models (LLMs) to generate prevention-oriented explanations. Our initial evaluation on the Spring-PetClinic application shows that the selected metrics identify most known security-critical methods, while an LLM provides actionable, prevention-focused insights. Although these metrics capture structural properties rather than semantic aspects of security, this work lays the foundation for code-level security-aware metrics and enhanced explanations.", "AI": {"tldr": "该论文探讨了一种预防性策略，通过识别和解释代码中的安全关键区域来避免漏洞。", "motivation": "传统的安全工具只能在代码引入了漏洞之后进行检测，并不能从根本上防止漏洞的产生。因此，开发一种能够提前预警并提供指导以避免漏洞的方法显得尤为重要。", "method": "论文提出了一种IntelliJ IDEA插件原型，它通过使用软件度量来识别潜在的安全关键方法，并利用大型语言模型（LLMs）生成预防性的解释。", "result": "初步评估表明，所选指标能够识别大多数已知的安全关键方法，而LLM则能提供可操作、以预防为导向的见解。尽管这些指标捕捉的是结构属性而非语义方面的安全，但这项工作为代码级安全感知度量和增强解释奠定了基础。", "conclusion": "该研究展示了利用软件度量和技术工具来识别并指导安全关键代码的方法，并强调了这种方法对于提高代码安全性的重要性。"}}
{"id": "2602.00710", "pdf": "https://arxiv.org/pdf/2602.00710", "abs": "https://arxiv.org/abs/2602.00710", "authors": ["Yueqi Zhang", "Jin Hu", "Shaoxiong Feng", "Peiwen Yuan", "Xinglin Wang", "Yiwei Li", "Jiayi Shi", "Chuyi Tan", "Ji Zhang", "Boyuan Pan", "Yao Hu", "Kan Li"], "title": "Learning More from Less: Unlocking Internal Representations for Benchmark Compression", "categories": ["cs.AI"], "comment": null, "summary": "The prohibitive cost of evaluating Large Language Models (LLMs) necessitates efficient alternatives to full-scale benchmarking. Prevalent approaches address this by identifying a small coreset of items to approximate full-benchmark performance. However, existing methods must estimate a reliable item profile from response patterns across many source models, which becomes statistically unstable when the source pool is small. This dependency is particularly limiting for newly released benchmarks with minimal historical evaluation data. We argue that discrete correctness labels are a lossy view of the model's decision process and fail to capture information encoded in hidden states. To address this, we introduce REPCORE, which aligns heterogeneous hidden states into a unified latent space to construct representative coresets. Using these subsets for performance extrapolation, REPCORE achieves precise estimation accuracy with as few as ten source models. Experiments on five benchmarks and over 200 models show consistent gains over output-based baselines in ranking correlation and estimation accuracy. Spectral analysis further indicates that the aligned representations contain separable components reflecting broad response tendencies and task-specific reasoning patterns.", "AI": {"tldr": "该论文提出了一种方法REPCORE，利用模型的内部表示来构建核心集，从而实现更精确的性能估计。", "motivation": "现有方法需要大量的源模型数据来评估大型语言模型，这在新发布的基准测试中难以实现。因此提出了利用隐藏状态信息的方法来提高效率和准确性。", "method": "REPCORE将不同模型的隐藏状态对齐到统一的潜在空间，并使用这些核心集进行性能估计。", "result": "实验显示，REPCORE可以在仅用少量源模型的情况下取得准确的评估结果，在五项基准测试中均优于基于输出的方法。", "conclusion": "通过利用内部表示信息，REPCORE能够更有效地构建核心集并提高大型语言模型的性能估计准确性。"}}
{"id": "2602.00709", "pdf": "https://arxiv.org/pdf/2602.00709", "abs": "https://arxiv.org/abs/2602.00709", "authors": ["Wenda Li", "Tongya Zheng", "Kaixuan Chen", "Shunyu Liu", "Haoze Jiang", "Yunzhi Hao", "Rui Miao", "Zujie Ren", "Mingli Song", "Hang Shi", "Gang Chen"], "title": "Physics-informed Diffusion Generation for Geomagnetic Map Interpolation", "categories": ["cs.AI", "cs.LG"], "comment": "5 pages, 2 figures, IEEE ICASSP'26", "summary": "Geomagnetic map interpolation aims to infer unobserved geomagnetic data at spatial points, yielding critical applications in navigation and resource exploration. However, existing methods for scattered data interpolation are not specifically designed for geomagnetic maps, which inevitably leads to suboptimal performance due to detection noise and the laws of physics. Therefore, we propose a Physics-informed Diffusion Generation framework~(PDG) to interpolate incomplete geomagnetic maps. First, we design a physics-informed mask strategy to guide the diffusion generation process based on a local receptive field, effectively eliminating noise interference. Second, we impose a physics-informed constraint on the diffusion generation results following the kriging principle of geomagnetic maps, ensuring strict adherence to the laws of physics. Extensive experiments and in-depth analyses on four real-world datasets demonstrate the superiority and effectiveness of each component of PDG.", "AI": {"tldr": "该论文提出了一种基于物理信息的扩散生成框架（PDG）来插值不完整的地磁图。", "motivation": "现有的散点数据插值方法无法针对地磁地图进行优化，导致性能不佳。因此，作者提出了一个结合物理学原理和深度学习的方法以提高插值效果。", "method": "该论文设计了一个物理信息掩码策略来指导扩散生成过程，并在生成结果中施加了基于克里金原理的物理约束条件，确保严格遵守物理规律。", "result": "通过四个真实世界数据集上的广泛实验和深入分析，证明了PDG框架各部分的有效性和优越性。", "conclusion": "该研究成功提出了一种新的地磁图插值方法，克服了传统方法的不足，并在实际应用中表现出了良好的性能。"}}
{"id": "2602.00708", "pdf": "https://arxiv.org/pdf/2602.00708", "abs": "https://arxiv.org/abs/2602.00708", "authors": ["Weiqi Gai", "Yuman Gao", "Yuan Zhou", "Yufan Xie", "Zhiyang Liu", "Yuze Wu", "Xin Zhou", "Fei Gao", "Zhijun Meng"], "title": "USS-Nav: Unified Spatio-Semantic Scene Graph for Lightweight UAV Zero-Shot Object Navigation", "categories": ["cs.RO"], "comment": null, "summary": "Zero-Shot Object Navigation in unknown environments poses significant challenges for Unmanned Aerial Vehicles (UAVs) due to the conflict between high-level semantic reasoning requirements and limited onboard computational resources. To address this, we present USS-Nav, a lightweight framework that incrementally constructs a Unified Spatio-Semantic scene graph and enables efficient Large Language Model (LLM)-augmented Zero-Shot Object Navigation in unknown environments. Specifically, we introduce an incremental Spatial Connectivity Graph generation method utilizing polyhedral expansion to capture global geometric topology, which is dynamically partitioned into semantic regions via graph clustering. Concurrently, open-vocabulary object semantics are instantiated and anchored to this topology to form a hierarchical environmental representation. Leveraging this hierarchical structure, we present a coarse-to-fine exploration strategy: LLM grounded in the scene graph's semantics to determine global target regions, while a local planner optimizes frontier coverage based on information gain. Experimental results demonstrate that our framework outperforms state-of-the-art methods in terms of computational efficiency and real-time update frequency (15 Hz) on a resource-constrained platform. Furthermore, ablation studies confirm the effectiveness of our framework, showing substantial improvements in Success weighted by Path Length (SPL). The source code will be made publicly available to foster further research.", "AI": {"tldr": "USS-Nav 是一种轻量级框架，用于在未知环境中实现无人机的零样本目标导航。", "motivation": "针对无人飞行器在未知环境中的零样本目标导航挑战，提出了一种新的方法来平衡高级语义推理需求和有限计算资源之间的矛盾。", "method": "通过增量生成空间连接图，并利用多面体扩展捕捉全局几何拓扑结构。该框架还采用基于聚类的图形分割方法将空间划分为语义区域，并在此基础上实现了层级环境表示，以支持高效的大语言模型辅助零样本目标导航。", "result": "实验结果表明，USS-Nav 在计算效率和实时更新频率方面优于现有技术，在资源受限平台上能达到15Hz。此外，消融研究表明该框架在成功路径长度加权成功率(SPL)上表现更好。", "conclusion": "通过提出一个轻量级的统一空间语义场景图构建方法，USS-Nav 成功地实现了无人机在未知环境中的高效零样本目标导航，并促进了相关领域的进一步研究。"}}
{"id": "2602.00707", "pdf": "https://arxiv.org/pdf/2602.00707", "abs": "https://arxiv.org/abs/2602.00707", "authors": ["Jingnan Zheng", "Jingjun Xu", "Yanzhen Luo", "Chenhang Cui", "Gelei Deng", "Zhenkai Liang", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Self-Guard: Defending Large Reasoning Models via enhanced self-reflection", "categories": ["cs.AI"], "comment": null, "summary": "The emergence of Large Reasoning Models (LRMs) introduces a new paradigm of explicit reasoning, enabling remarkable advances yet posing unique risks such as reasoning manipulation and information leakage. To mitigate these risks, current alignment strategies predominantly rely on heavy post-training paradigms or external interventions. However, these approaches are often computationally intensive and fail to address the inherent awareness-compliance gap, a critical misalignment where models recognize potential risks yet prioritize following user instructions due to their sycophantic tendencies. To address these limitations, we propose Self-Guard, a lightweight safety defense framework that reinforces safety compliance at the representational level. Self-Guard operates through two principal stages: (1) safety-oriented prompting, which activates the model's latent safety awareness to evoke spontaneous reflection, and (2) safety activation steering, which extracts the resulting directional shift in the hidden state space and amplifies it to ensure that safety compliance prevails over sycophancy during inference. Experiments demonstrate that Self-Guard effectively bridges the awareness-compliance gap, achieving robust safety performance without compromising model utility. Furthermore, Self-Guard exhibits strong generalization across diverse unseen risks and varying model scales, offering a cost-efficient solution for LRM safety alignment.", "AI": {"tldr": "提出了一种轻量级的安全防护框架Self-Guard，以增强大型推理模型的内在安全性。", "motivation": "当前对大模型的安全策略大多依赖于重负载的训练后处理或外部干预措施，这些方法计算成本高且未能解决模型的认知-合规差距问题。因此需要一种新的安全防御机制来填补这一空白。", "method": "Self-Guard通过两个主要阶段实现其目标：安全导向提示和安全性激活引导。前者激发大模型内在的安全意识；后者提取潜在的风险并放大这些风险以确保在推理过程中优先考虑安全性而非顺从性。", "result": "实验表明，Self-Guard成功地缩小了认知-合规差距，并且在整个测试中保持了强大的泛化能力和安全性能，同时不牺牲模型的实用性。", "conclusion": "Self-Guard提供了一种成本效益高的方法来解决大推理模型的安全对齐问题，其结果展示了该框架的有效性和普适性。"}}
{"id": "2602.00703", "pdf": "https://arxiv.org/pdf/2602.00703", "abs": "https://arxiv.org/abs/2602.00703", "authors": ["Zhongtian Huang", "Zhi Chen", "Zi Huang", "Xin Yu", "Daniel Smith", "Chaitanya Purushothama", "Erik Van Oosterom", "Alex Wu", "William Salter", "Yan Li", "Scott Chapman"], "title": "StomataSeg: Semi-Supervised Instance Segmentation for Sorghum Stomatal Components", "categories": ["cs.CV"], "comment": null, "summary": "Sorghum is a globally important cereal grown widely in water-limited and stress-prone regions. Its strong drought tolerance makes it a priority crop for climate-resilient agriculture. Improving water-use efficiency in sorghum requires precise characterisation of stomatal traits, as stomata control of gas exchange, transpiration and photosynthesis have a major influence on crop performance. Automated analysis of sorghum stomata is difficult because the stomata are small (often less than 40 $μ$m in length in grasses such as sorghum) and vary in shape across genotypes and leaf surfaces. Automated segmentation contributes to high-throughput stomatal phenotyping, yet current methods still face challenges related to nested small structures and annotation bottlenecks. In this paper, we propose a semi-supervised instance segmentation framework tailored for analysis of sorghum stomatal components. We collect and annotate a sorghum leaf imagery dataset containing 11,060 human-annotated patches, covering the three stomatal components (pore, guard cell and complex area) across multiple genotypes and leaf surfaces. To improve the detection of tiny structures, we split high-resolution microscopy images into overlapping small patches. We then apply a pseudo-labelling strategy to unannotated images, producing an additional 56,428 pseudo-labelled patches. Benchmarking across semantic and instance segmentation models shows substantial performance gains: for semantic models the top mIoU increases from 65.93% to 70.35%, whereas for instance models the top AP rises from 28.30% to 46.10%. These results demonstrate that combining patch-based preprocessing with semi-supervised learning significantly improves the segmentation of fine stomatal structures. The proposed framework supports scalable extraction of stomatal traits and facilitates broader adoption of AI-driven phenotyping in crop science.", "AI": {"tldr": "提出了一种针对高粱气孔组件的半监督实例分割框架，以促进高通量表型分析。", "motivation": "为了提高干旱耐受性强、广泛种植于水资源匮乏地区的高粱的用水效率，需要精确地表征其气孔特性。但因气孔尺寸小且形态各异，自动化分析难度大。", "method": "收集并标注了包含11,060张人工注释图像片的小叶影像数据集，并通过分割高质量显微镜图像、应用伪标签策略来处理未标记图像，从而提高了对细小微结构的检测能力。", "result": "实验表明，与仅使用语义分割模型相比，该方法使mIoU从65.93%提升至70.35%，而实例分割模型AP值则由28.30%上升到46.10%。结果证明了结合基于补丁的预处理和半监督学习能显著改善细小微结构的分割。", "conclusion": "该框架支持大规模提取气孔特征并促进作物科学中人工智能驱动表型分析技术的应用"}}
{"id": "2602.00702", "pdf": "https://arxiv.org/pdf/2602.00702", "abs": "https://arxiv.org/abs/2602.00702", "authors": ["Ruikui Wang", "Jinheng Feng", "Lang Tian", "Huaishao Luo", "Chaochao Li", "Liangbo Zhou", "Huan Zhang", "Youzheng Wu", "Xiaodong He"], "title": "JoyAvatar: Unlocking Highly Expressive Avatars via Harmonized Text-Audio Conditioning", "categories": ["cs.CV"], "comment": null, "summary": "Existing video avatar models have demonstrated impressive capabilities in scenarios such as talking, public speaking, and singing. However, the majority of these methods exhibit limited alignment with respect to text instructions, particularly when the prompts involve complex elements including large full-body movement, dynamic camera trajectory, background transitions, or human-object interactions. To break out this limitation, we present JoyAvatar, a framework capable of generating long duration avatar videos, featuring two key technical innovations. Firstly, we introduce a twin-teacher enhanced training algorithm that enables the model to transfer inherent text-controllability from the foundation model while simultaneously learning audio-visual synchronization. Secondly, during training, we dynamically modulate the strength of multi-modal conditions (e.g., audio and text) based on the distinct denoising timestep, aiming to mitigate conflicts between the heterogeneous conditioning signals. These two key designs serve to substantially expand the avatar model's capacity to generate natural, temporally coherent full-body motions and dynamic camera movements as well as preserve the basic avatar capabilities, such as accurate lip-sync and identity consistency. GSB evaluation results demonstrate that our JoyAvatar model outperforms the state-of-the-art models such as Omnihuman-1.5 and KlingAvatar 2.0. Moreover, our approach enables complex applications including multi-person dialogues and non-human subjects role-playing. Some video samples are provided on https://joyavatar.github.io/.", "AI": {"tldr": "JoyAvatar框架通过增强训练算法和动态多模态条件调节，生成具有高度文本指令一致性和自然全身体动作的视频化身。", "motivation": "现有视频化身模型在处理涉及复杂元素（如大范围全身运动、动态摄像机轨迹等）的提示时存在局限性。JoyAvatar旨在解决这一问题，提升视频化身对文本指令的一致性以及生成更复杂的动态。", "method": "引入了双教师增强训练算法以使模型学习音频视觉同步，并在训练中根据不同的去噪时间步长调节多模态条件强度，从而减轻异构信号冲突。", "result": "JoyAvatar在GBS评估中超越了现有最优的OmniHuman-1.5和KlingAvatar2.0。能生成自然、连贯的身体动作以及复杂的动态摄像机移动，并支持多人对话等复杂应用。", "conclusion": "通过上述方法，JoyAvatar成功增强了视频化身模型的能力，使其能够更准确地生成与文本指令一致且具有高度表现力的动画效果。"}}
{"id": "2602.00701", "pdf": "https://arxiv.org/pdf/2602.00701", "abs": "https://arxiv.org/abs/2602.00701", "authors": ["Mohamed Saleh", "Zahra Ahmadi"], "title": "Cross-Modal Binary Attention: An Energy-Efficient Fusion Framework for Audio-Visual Learning", "categories": ["cs.MM", "cs.CV", "cs.LG", "cs.SD"], "comment": null, "summary": "Effective multimodal fusion requires mechanisms that can capture complex cross-modal dependencies while remaining computationally scalable for real-world deployment. Existing audio-visual fusion approaches face a fundamental trade-off: attention-based methods effectively model cross-modal relationships but incur quadratic computational complexity that prevents hierarchical, multi-scale architectures, while efficient fusion strategies rely on simplistic concatenation that fails to extract complementary cross-modal information. We introduce CMQKA, a novel cross-modal fusion mechanism that achieves linear O(N) complexity through efficient binary operations, enabling scalable hierarchical fusion previously infeasible with conventional attention. CMQKA employs bidirectional cross-modal Query-Key attention to extract complementary spatiotemporal features and uses learnable residual fusion to preserve modality-specific characteristics while enriching representations with cross-modal information. Building upon CMQKA, we present SNNergy, an energy-efficient multimodal fusion framework with a hierarchical architecture that processes inputs through progressively decreasing spatial resolutions and increasing semantic abstraction. This multi-scale fusion capability allows the framework to capture both local patterns and global context across modalities. Implemented with event-driven binary spike operations, SNNergy achieves remarkable energy efficiency while maintaining fusion effectiveness and establishing new state-of-the-art results on challenging audio-visual benchmarks, including CREMA-D, AVE, and UrbanSound8K-AV, significantly outperforming existing multimodal fusion baselines. Our framework advances multimodal fusion by introducing a scalable fusion mechanism that enables hierarchical cross-modal integration with practical energy efficiency for real-world audio-visual intelligence systems.", "AI": {"tldr": "提出了一种高效的跨模态融合机制CMQKA和框架SNNergy，用于音频视觉学习。", "motivation": "现有的音频视觉融合方法存在计算复杂度高的问题，无法实现层次化多尺度架构，而简单的拼接方法又不能有效提取互补的跨模态信息。", "method": "CMQKA通过高效的二进制操作实现了线性O(N)复杂度，同时使用双向交叉模式Query-Key注意力来提取互补的空间时间特征，并采用可学习残差融合以保留特定模式特性并增强表示。", "result": "SNNergy框架在挑战性的音频视觉基准测试中取得了新的最优结果，包括CREMA-D、AVE和UrbanSound8K-AV，在保持融合效果的同时实现了显著的能量效率。", "conclusion": "该研究通过引入可扩展的融合机制推进了多模态融合技术的发展，为现实世界中的音频视觉智能系统提供了具有实际能耗效率的层次化跨模式整合方法。"}}
{"id": "2602.00699", "pdf": "https://arxiv.org/pdf/2602.00699", "abs": "https://arxiv.org/abs/2602.00699", "authors": ["Xuan Liu", "Ziyu Li", "Mu He", "Ziyang Ma", "Xiaoxu Wu", "Gizem Yilmaz", "Yiyuan Xia", "Bingbing Li", "He Tan", "Jerry Ying Hsi Fuh", "Wen Feng Lu", "Anders E. W. Jarfors", "Per Jansson"], "title": "From Prompt to Graph: Comparing LLM-Based Information Extraction Strategies in Domain-Specific Ontology Development", "categories": ["cs.AI", "cs.CL", "cs.IR"], "comment": "11 pages,8 figures,3 tables,presented at International Conference on Industry of the Future and Smart Manufacturing,2025", "summary": "Ontologies are essential for structuring domain knowledge, improving accessibility, sharing, and reuse. However, traditional ontology construction relies on manual annotation and conventional natural language processing (NLP) techniques, making the process labour-intensive and costly, especially in specialised fields like casting manufacturing. The rise of Large Language Models (LLMs) offers new possibilities for automating knowledge extraction. This study investigates three LLM-based approaches, including pre-trained LLM-driven method, in-context learning (ICL) method and fine-tuning method to extract terms and relations from domain-specific texts using limited data. We compare their performances and use the best-performing method to build a casting ontology that validated by domian expert.", "AI": {"tldr": "研究比较了三种基于LLM的信息提取策略，用于从领域特定文本中抽取术语和关系，并构建铸造领域的本体。", "motivation": "传统本体构造依赖手动注释及传统NLP技术，耗时且成本高。大型语言模型的兴起为自动化知识提取提供了新机会。", "method": "研究采用三种LLM方法：预训练模型驱动、在上下文学习和微调，从有限数据中抽取术语与关系，并通过领域专家验证最佳方案构建铸造本体。", "result": "比较了不同策略的表现并确定了性能最优的方法。", "conclusion": "实验表明基于LLM的信息提取策略能够有效支持特定领域的知识组织，提高了信息结构化、共享和重用效率。"}}
{"id": "2602.00697", "pdf": "https://arxiv.org/pdf/2602.00697", "abs": "https://arxiv.org/abs/2602.00697", "authors": ["Kayode P. Ayodele", "Enoruwa Obayiuwana", "Aderonke R. Lawal", "Ayorinde Bamimore", "Funmilayo B. Offiong", "Emmanuel A. Peter"], "title": "Revising Bloom's Taxonomy for Dual-Mode Cognition in Human-AI Systems: The Augmented Cognition Framework", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "As artificial intelligence (AI) models become routinely integrated into knowledge work, cognitive acts increasingly occur in two distinct modes: individually, using biological resources alone, or distributed across a human-AI system. Existing revisions to Bloom's Taxonomy treat AI as an external capability to be mapped against human cognition rather than as a driver of this dual-mode structure, and thus fail to specify distinct learning outcomes and assessment targets for each mode. This paper proposes the Augmented Cognition Framework (ACF), a restructured taxonomy built on three principles. First, each traditional Bloom level operates in two modes (Individual and Distributed) with mode-specific cognitive verbs. Second, an asymmetric dependency relationship holds wherein effective Distributed cognition typically requires Individual cognitive foundations, though structured scaffolding can in some cases reverse this sequence. Third, a seventh level, Orchestration, specifies a governance capacity for managing mode-switching, trust calibration, and partnership optimization. We systematically compare existing AI-revised taxonomies against explicit assessment-utility criteria and show, across the frameworks reviewed, that ACF uniquely generates assessable learning outcomes for individual cognition, distributed cognition, and mode-governance as distinct targets. The framework addresses fluent incompetence, the central pedagogical risk of the AI era, by making the dependency relationship structurally explicit while accommodating legitimate scaffolding approaches.", "AI": {"tldr": "本文提出了一种新的认知框架，即增强认知框架（ACF），旨在解决人工智能整合到知识工作中带来的双模式认知问题", "motivation": "现行的布卢姆分类法修订版未能充分考虑AI作为驱动因素在人机系统中双重认知结构的作用。现有的AI修订版本无法为每种认知模式提供明确的学习成果和评估标准", "method": "基于三个原则构建新的分类体系：每个传统布卢姆层次分别以个体和分布式两种方式运作，分布式的有效认知通常需要个体的认知基础；第七个等级即协调能力，用于管理模式切换、信任校准及伙伴关系优化。并系统地对比现有AI修订版框架下的评估效用标准", "result": "ACF生成了可衡量的学习成果，包括个人认知、分布式认知和模式治理作为不同的目标，并解决了人工智能时代的关键教育风险—流畅的不胜任问题", "conclusion": "通过显式依赖关系结构化，增强认知框架（ACF）为个体和人机系统的双重模式提供了明确的学习评估标准"}}
{"id": "2602.00694", "pdf": "https://arxiv.org/pdf/2602.00694", "abs": "https://arxiv.org/abs/2602.00694", "authors": ["Fabio Turazza", "Marcello Pietri", "Natalia Selini Hadjidimitriou", "Marco Mamei"], "title": "Forecasting Energy Availability in Local Energy Communities via LSTM Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "Published as a book chapter in the MEDES 2024 proceedings (Springer LNCS)", "summary": "Local Energy Communities are emerging as crucial players in the landscape of sustainable development. A significant challenge for these communities is achieving self-sufficiency through effective management of the balance between energy production and consumption. To meet this challenge, it is essential to develop and implement forecasting models that deliver accurate predictions, which can then be utilized by optimization and planning algorithms. However, the application of forecasting solutions is often hindered by privacy constrains and regulations as the users participating in the Local Energy Community can be (rightfully) reluctant sharing their consumption patterns with others. In this context, the use of Federated Learning (FL) can be a viable solution as it allows to create a forecasting model without the need to share privacy sensitive information among the users. In this study, we demonstrate how FL and long short-term memory (LSTM) networks can be employed to achieve this objective, highlighting the trade-off between data sharing and forecasting accuracy.", "AI": {"tldr": "本文通过联邦学习和长短期记忆网络来预测本地能源社区的能源可用性，以实现自我给养而不泄露隐私信息。", "motivation": "为了促进可持续发展并提高本地能源社区的自给能力，需要开发准确的预测模型。然而，由于用户对分享私人消费数据的担忧，联邦学习作为解决方案被提出，它可以在不共享敏感信息的情况下创建预测模型。", "method": "使用联邦学习和长短期记忆网络来构建能够保护隐私的同时有效预测能源供需平衡的模型。", "result": "通过实验展示了所提出的模型在准确性和隐私性之间的权衡，并证明了该方法的有效性。", "conclusion": "研究表明，利用联邦学习可以实现对本地能源社区能量可用性的精准预测，同时又不会泄露用户数据。"}}
{"id": "2602.00690", "pdf": "https://arxiv.org/pdf/2602.00690", "abs": "https://arxiv.org/abs/2602.00690", "authors": ["Christian Rosenke", "Mark Scheibner"], "title": "Fanciful Figurines flip Free Flood-It -- Polynomial-Time Miniature Painting on Co-gem-free Graphs", "categories": ["cs.DS", "cs.DM"], "comment": null, "summary": "Inspired by the eponymous hobby, we introduce Miniature Painting as the computational problem to paint a given graph $G=(V,E)$ according to a prescribed template $t \\colon V \\rightarrow C$, which assigns colors $C$ to the vertices of $G$. In this setting, the goal is to realize the template using a shortest possible sequence of brush strokes, where each stroke overwrites a connected vertex subset with a color in $C$. We show that this problem is equivalent to a reversal of the well-studied Free Flood-It game, in which a colored graph is decolored into a single color using as few moves as possible. This equivalence allows known complexity results for Free Flood-It to be transferred directly to Miniature Painting, including NP-hardness under severe structural restrictions, such as when $G$ is a grid, a tree, or a split graph. Our main contribution is a polynomial-time algorithm for Miniature Painting on graphs that are free of induced co-gems, a graph class that strictly generalizes cographs. As a direct consequence, Free Flood-It is also polynomial-time solvable on co-gem-free graphs, independent of the initial coloring.", "AI": {"tldr": "研究了在特定图类上实现给定颜色模板的最短刷涂序列问题，该问题与Free Flood-It游戏反转等价。提出了针对co-gem-free图类的多项式时间算法。", "motivation": "引入了Miniature Painting作为计算问题，在给定图和预设颜色模板下寻找最短刷涂序列。此研究动机是解决一种新的有趣的游戏化图形着色挑战，并将其与已知复杂性结果进行关联。", "method": "通过将Miniature Painting问题与Free Flood-It游戏反转建立等价关系，利用后者的研究成果直接推导出新问题的复杂度结论。主要贡献在于设计了一个针对co-gem-free图类的多项式时间算法。", "result": "证明了Miniature Painting在特定图形上具有NP难题特性；提出了一个处理co-gem-free图类中该问题的有效多项式时间算法。", "conclusion": "研究结果表明，通过与Free Flood-It游戏的等价性建立了新的着色问题Miniature Painting，并解决了它在某些特殊图类上的求解方法。这为进一步探索相关图形操作提供了理论基础和实用工具。"}}
{"id": "2602.00687", "pdf": "https://arxiv.org/pdf/2602.00687", "abs": "https://arxiv.org/abs/2602.00687", "authors": ["Yuankun Zeng", "Shaohui Li", "Zhi Li", "Shulan Ruan", "Yu Liu", "You He"], "title": "V2X-DSC: Multi-Agent Collaborative Perception with Distributed Source Coding Guided Communication", "categories": ["cs.CV"], "comment": null, "summary": "Collaborative perception improves 3D understanding by fusing multi-agent observations, yet intermediate-feature sharing faces strict bandwidth constraints as dense BEV features saturate V2X links. We observe that collaborators view the same physical world, making their features strongly correlated; thus receivers only need innovation beyond their local context. Revisiting this from a distributed source coding perspective, we propose V2X-DSC, a framework with a Conditional Codec (DCC) for bandwidth-constrained fusion. The sender compresses BEV features into compact codes, while the receiver performs conditional reconstruction using its local features as side information, allocating bits to complementary cues rather than redundant content. This conditional structure regularizes learning, encouraging incremental representation and yielding lower-noise features. Experiments on DAIR-V2X, OPV2V, and V2X-Real demonstrate state-of-the-art accuracy-bandwidth trade-offs under KB-level communication, and generalizes as a plug-and-play communication layer across multiple fusion backbones.", "AI": {"tldr": "提出了一种基于分布式源编码的多代理协同感知框架V2X-DSC，用于改善3D理解。", "motivation": "由于带宽限制，中间特征共享在密集BEV特征情况下难以实现高效传输。通过利用接收者与发送者的强相关性，减少冗余信息。", "method": "采用条件编码器（DCC）框架，在带约束条件下进行压缩和重构，优化了特征的分享效率。", "result": "实验结果表明该方法在通信带宽限制下实现了最先进的准确性-带宽权衡。", "conclusion": "V2X-DSC框架通过减少冗余信息并专注于互补线索，成功改善了多代理协同感知下的3D理解。"}}
{"id": "2602.00686", "pdf": "https://arxiv.org/pdf/2602.00686", "abs": "https://arxiv.org/abs/2602.00686", "authors": ["Yujie Wei", "Jiahan Fan", "Jiyu Guo", "Ruichen Zhen", "Rui Shao", "Xiu Su", "Zeke Xie", "Shuo Yang"], "title": "Learning to Accelerate Vision-Language-Action Models through Adaptive Visual Token Caching", "categories": ["cs.RO"], "comment": null, "summary": "Vision-Language-Action (VLA) models have demonstrated remarkable generalization capabilities in robotic manipulation tasks, yet their substantial computational overhead remains a critical obstacle to real-world deployment. Improving inference efficiency is therefore essential for practical robotic applications. Existing acceleration methods often rely on heuristic or static strategies--such as rule-based token caching or pruning--that are decoupled from task objectives and fail to adapt to dynamic scene changes. In this work, we reformulate inference acceleration as a learnable policy optimization problem and propose a novel framework that integrates a dynamic, task-aware decision-making process directly into the VLA model. At its core are two lightweight, cooperative modules: a Cached Token Selector, which determines which tokens should be reused, and a Cache Ratio Predictor, which controls how many tokens to reuse. Training these modules is non-trivial due to their discrete decisions. We address this by adopting a differentiable relaxation that allows gradient-based end-to-end optimization. Extensive experiments on the LIBERO and SIMPLER benchmarks, as well as real-robot evaluations, show that our method achieves a 1.76x wall-clock inference speedup while simultaneously improving the average success rate by 1.9 percentage points (from 75.0% to 76.9%) on LIBERO and by 5.0 percentage points on real-world tasks, significantly outperforming existing baselines. This work highlights the potential of learning task-aware computational allocation policies, paving the way for VLA models that are both powerful and efficient.", "AI": {"tldr": "本文提出了一个通过自适应视觉令牌缓存来加速视觉语言动作模型的方法，旨在提高机器人操作任务中的推理效率。", "motivation": "现有方法通常依赖于启发式或静态策略以降低计算开销，这些方法与任务目标脱钩且无法应对动态场景变化。因此需要一种能够根据任务需求自适应地调整的加速方案。", "method": "本文将推理加速重新定义为一个可学习的政策优化问题，并提出了一种新的框架，该框架包含两个轻量级协作模块：令牌选择器和缓存比例预测器，通过梯度导向端到端优化解决离散决策训练难题。", "result": "实验表明，所提方法在LIBERO和SIMPLER基准上实现了1.76倍的推理速度提升，并且平均成功率从75%提高至76.9%，在现实世界任务中成功率提高了5%。", "conclusion": "该工作展示了学习任务感知计算分配策略的潜力，为视觉语言动作模型提供了更强大的效率优化方式。"}}
{"id": "2602.00685", "pdf": "https://arxiv.org/pdf/2602.00685", "abs": "https://arxiv.org/abs/2602.00685", "authors": ["Xuan Liu", "Haoyang Shang", "Zizhang Liu", "Xinyan Liu", "Yunze Xiao", "Yiwen Tu", "Haojian Jin"], "title": "HumanStudy-Bench: Towards AI Agent Design for Participant Simulation", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly used as simulated participants in social science experiments, but their behavior is often unstable and highly sensitive to design choices. Prior evaluations frequently conflate base-model capabilities with experimental instantiation, obscuring whether outcomes reflect the model itself or the agent setup. We instead frame participant simulation as an agent-design problem over full experimental protocols, where an agent is defined by a base model and a specification (e.g., participant attributes) that encodes behavioral assumptions. We introduce HUMANSTUDY-BENCH, a benchmark and execution engine that orchestrates LLM-based agents to reconstruct published human-subject experiments via a Filter--Extract--Execute--Evaluate pipeline, replaying trial sequences and running the original analysis pipeline in a shared runtime that preserves the original statistical procedures end to end. To evaluate fidelity at the level of scientific inference, we propose new metrics to quantify how much human and agent behaviors agree. We instantiate 12 foundational studies as an initial suite in this dynamic benchmark, spanning individual cognition, strategic interaction, and social psychology, and covering more than 6,000 trials with human samples ranging from tens to over 2,100 participants.", "AI": {"tldr": "介绍了一个名为HUMANSTUDY-BENCH的基准和执行引擎，用于通过LLM代理重现人类参与者的实验。", "motivation": "大型语言模型在社会科学研究中作为模拟参与者使用时表现出不稳定的行为，并且其性能容易受到设计选择的影响。现有的评估方法通常将基础模型的能力与其实验实现混淆，无法明确结果是来自模型本身还是实验设置。", "method": "通过过滤、提取、执行和评估的管道，HUMANSTUDY-BENCH使用LLM代理重现已发表的人类参与者实验，并运行原始分析流程以保持统计程序的一致性。提出了新的度量标准来量化人类行为与代理行为之间的契合程度。", "result": "基于12个基础研究实例，包括个体认知、战略互动和社会心理学领域，涵盖了超过6,000次试验和不同规模的人类样本进行评估。", "conclusion": "通过HUMANSTUDY-BENCH这一动态基准的引入，可以更好地理解和改进大型语言模型在模拟人类参与者行为中的应用。"}}
{"id": "2602.00683", "pdf": "https://arxiv.org/pdf/2602.00683", "abs": "https://arxiv.org/abs/2602.00683", "authors": ["Thong Thanh Nguyen"], "title": "Video Understanding: Through A Temporal Lens", "categories": ["cs.CV"], "comment": "PhD Thesis, NUS, 2025", "summary": "This thesis explores the central question of how to leverage temporal relations among video elements to advance video understanding. Addressing the limitations of existing methods, the work presents a five-fold contribution: (1) an automatic annotation framework that utilizes large vision-language models and a noise-robust contrastive learning objective with a subtractive angular margin; (2) a parameter-efficient fine-tuning strategy using \"recurrent adapters\" to capture temporal dynamics in low-data regimes; (3) the integration of State Space Layers (SSL) for efficient long-form video modeling, supported by the introduction of two new long-term benchmarks for egocentric and feature-length content; (4) a novel contrastive learning framework designed to explicitly model fine-grained relations between motions and video moments; and (5) a comprehensive empirical study on Large Vision-Language Models (LVLMs) that identifies the visual-language interface as a bottleneck for temporal reasoning, leading to a new \"temporal-oriented recipe\" for upscaled video understanding. Collectively, these contributions demonstrate that explicit temporal modeling significantly enhances a model's ability to represent and reason about the fluid nature of video content.", "AI": {"tldr": "本文探讨了如何利用视频元素之间的时空关系来提高视频理解。", "motivation": "现有方法在处理视频时存在局限性，尤其是在时间维度上的理解和建模不足。因此，作者希望通过一系列创新的方法提升视频的理解能力。", "method": "该论文提出了一个自动标注框架、一种参数高效的微调策略、状态空间层的集成以及一种新颖的对比学习框架来更好地捕捉和理解视频中的时空关系。", "result": "通过这些方法的应用和实验研究，作者发现显式的时间建模显著提升了模型对于视频内容的理解能力。", "conclusion": "研究表明，通过对时间维度上的显式建模可以有效提高视频理解和推理的能力。"}}
{"id": "2602.00682", "pdf": "https://arxiv.org/pdf/2602.00682", "abs": "https://arxiv.org/abs/2602.00682", "authors": ["Yuecheng Li", "Hengwei Ju", "Zeyu Song", "Wei Yang", "Chi Lu", "Peng Jiang", "Kun Gai"], "title": "RecGOAT: Graph Optimal Adaptive Transport for LLM-Enhanced Multimodal Recommendation with Dual Semantic Alignment", "categories": ["cs.IR", "cs.AI"], "comment": "Under Review", "summary": "Multimodal recommendation systems typically integrates user behavior with multimodal data from items, thereby capturing more accurate user preferences. Concurrently, with the rise of large models (LMs), multimodal recommendation is increasingly leveraging their strengths in semantic understanding and contextual reasoning. However, LM representations are inherently optimized for general semantic tasks, while recommendation models rely heavily on sparse user/item unique identity (ID) features. Existing works overlook the fundamental representational divergence between large models and recommendation systems, resulting in incompatible multimodal representations and suboptimal recommendation performance. To bridge this gap, we propose RecGOAT, a novel yet simple dual semantic alignment framework for LLM-enhanced multimodal recommendation, which offers theoretically guaranteed alignment capability. RecGOAT first employs graph attention networks to enrich collaborative semantics by modeling item-item, user-item, and user-user relationships, leveraging user/item LM representations and interaction history. Furthermore, we design a dual-granularity progressive multimodality-ID alignment framework, which achieves instance-level and distribution-level semantic alignment via cross-modal contrastive learning (CMCL) and optimal adaptive transport (OAT), respectively. Theoretically, we demonstrate that the unified representations derived from our alignment framework exhibit superior semantic consistency and comprehensiveness. Extensive experiments on three public benchmarks show that our RecGOAT achieves state-of-the-art performance, empirically validating our theoretical insights. Additionally, the deployment on a large-scale online advertising platform confirms the model's effectiveness and scalability in industrial recommendation scenarios. Code available at https://github.com/6lyc/RecGOAT-LLM4Rec.", "AI": {"tldr": "提出了一种新的双语义对齐框架RecGOAT，用于增强大规模模型（LM）的多模态推荐系统。", "motivation": "现有的工作忽视了大型模型和推荐系统的代表性差异，导致不兼容的多模态表示和次优推荐性能。为了弥合这一差距，提出了RecGOAT。", "method": "首先利用图注意力网络丰富协作语义；其次设计了一种双粒度渐进式多模态-ID对齐框架，通过跨模态对比学习（CMCL）和最优自适应传输（OAT）实现实例级和分布级的语义对齐。", "result": "在三个公共基准上的实验结果表明，RecGOAT达到了最先进的性能；大规模在线广告平台的实际应用进一步验证了模型的有效性和可扩展性。", "conclusion": "该方法通过理论分析证明了统一表示具有更好的语义一致性和全面性，并且实证研究表明它能够在推荐场景中取得最佳效果。"}}
{"id": "2602.00681", "pdf": "https://arxiv.org/pdf/2602.00681", "abs": "https://arxiv.org/abs/2602.00681", "authors": ["Ilyass Moummad", "Marius Miron", "Lukas Rauch", "David Robinson", "Alexis Joly", "Olivier Pietquin", "Emmanuel Chemla", "Matthieu Geist"], "title": "Audio-to-Image Bird Species Retrieval without Audio-Image Pairs via Text Distillation", "categories": ["cs.SD", "cs.IR", "cs.LG"], "comment": null, "summary": "Audio-to-image retrieval offers an interpretable alternative to audio-only classification for bioacoustic species recognition, but learning aligned audio-image representations is challenging due to the scarcity of paired audio-image data. We propose a simple and data-efficient approach that enables audio-to-image retrieval without any audio-image supervision. Our proposed method uses text as a semantic intermediary: we distill the text embedding space of a pretrained image-text model (BioCLIP-2), which encodes rich visual and taxonomic structure, into a pretrained audio-text model (BioLingual) by fine-tuning its audio encoder with a contrastive objective. This distillation transfers visually grounded semantics into the audio representation, inducing emergent alignment between audio and image embeddings without using images during training. We evaluate the resulting model on multiple bioacoustic benchmarks. The distilled audio encoder preserves audio discriminative power while substantially improving audio-text alignment on focal recordings and soundscape datasets. Most importantly, on the SSW60 benchmark, the proposed approach achieves strong audio-to-image retrieval performance exceeding baselines based on zero-shot model combinations or learned mappings between text embeddings, despite not training on paired audio-image data. These results demonstrate that indirect semantic transfer through text is sufficient to induce meaningful audio-image alignment, providing a practical solution for visually grounded species recognition in data-scarce bioacoustic settings.", "AI": {"tldr": "本文提出了一种通过文本蒸馏实现音频到图像检索的方法，无需使用配对的音视频数据。", "motivation": "生物声学物种识别中的音频至图像检索面临缺乏配对数据的问题，因此需要一种不需要直接配对数据训练的方式。", "method": "利用预训练的图文模型（BioCLIP-2）将文本嵌入空间蒸馏到预训练的音频文本模型（BioLingual）中，通过对比目标微调其音频编码器来实现。", "result": "该方法在多个生物声学基准测试上表现良好，在SSW60数据集上的音视频检索性能超过了基于零样本模型组合或学习文本嵌入映射的方法。", "conclusion": "间接的语义转移可以通过文本蒸馏诱导有意义的音频图像对齐，为数据稀缺情况下的视觉基础物种识别提供了一种实用解决方案。"}}
{"id": "2602.00678", "pdf": "https://arxiv.org/pdf/2602.00678", "abs": "https://arxiv.org/abs/2602.00678", "authors": ["Tianyang Wu", "Hanwei Guo", "Yuhang Wang", "Junshu Yang", "Xinyang Sui", "Jiayi Xie", "Xingyu Chen", "Zeyang Liu", "Xuguang Lan"], "title": "Toward Reliable Sim-to-Real Predictability for MoE-based Robust Quadrupedal Locomotion", "categories": ["cs.RO"], "comment": null, "summary": "Reinforcement learning has shown strong promise for quadrupedal agile locomotion, even with proprioception-only sensing. In practice, however, sim-to-real gap and reward overfitting in complex terrains can produce policies that fail to transfer, while physical validation remains risky and inefficient. To address these challenges, we introduce a unified framework encompassing a Mixture-of-Experts (MoE) locomotion policy for robust multi-terrain representation with RoboGauge, a predictive assessment suite that quantifies sim-to-real transferability. The MoE policy employs a gated set of specialist experts to decompose latent terrain and command modeling, achieving superior deployment robustness and generalization via proprioception alone. RoboGauge further provides multi-dimensional proprioception-based metrics via sim-to-sim tests over terrains, difficulty levels, and domain randomizations, enabling reliable MoE policy selection without extensive physical trials. Experiments on a Unitree Go2 demonstrate robust locomotion on unseen challenging terrains, including snow, sand, stairs, slopes, and 30 cm obstacles. In dedicated high-speed tests, the robot reaches 4 m/s and exhibits an emergent narrow-width gait associated with improved stability at high velocity.", "AI": {"tldr": "本文介绍了一种基于Mixture-of-Experts的四足机器人鲁棒性行走策略及RoboGauge评估套件，旨在解决仿真到现实转换中的问题。", "motivation": "为了解决强化学习在复杂地形中产生的策略转移失败以及物理验证风险高和效率低的问题，本文提出了一种新的框架以增强四足机器人的适应性和稳健性。", "method": "该方法使用基于Mixture-of-Experts的行走策略，并通过RoboGauge评估套件进行仿真到现实转换的预测评估。MoE策略利用门控专家集分解潜在地形和命令建模，而RoboGauge则提供多维度仿真相对性指标。", "result": "实验结果表明，在未见过的复杂环境中，如雪地、沙滩、楼梯等，机器人表现出强大的适应性。同时，在高速测试中，机器人达到了4m/s的速度并展现出稳定的窄距步态。", "conclusion": "通过该方法，四足机器人在多种地形上实现了鲁棒性的行走，并且能够高效地选择最优策略而无需进行大量物理试验。"}}
{"id": "2602.00676", "pdf": "https://arxiv.org/pdf/2602.00676", "abs": "https://arxiv.org/abs/2602.00676", "authors": ["Chao Li", "Shangdong Yang", "Chiheng Zhan", "Zhenxing Ge", "Yujing Hu", "Bingkun Bao", "Xingguo Chen", "Yang Gao"], "title": "OpenGuanDan: A Large-Scale Imperfect Information Game Benchmark", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "The advancement of data-driven artificial intelligence (AI), particularly machine learning, heavily depends on large-scale benchmarks. Despite remarkable progress across domains ranging from pattern recognition to intelligent decision-making in recent decades, exemplified by breakthroughs in board games, card games, and electronic sports games, there remains a pressing need for more challenging benchmarks to drive further research. To this end, this paper proposes OpenGuanDan, a novel benchmark that enables both efficient simulation of GuanDan (a popular four-player, multi-round Chinese card game) and comprehensive evaluation of both learning-based and rule-based GuanDan AI agents. OpenGuanDan poses a suite of nontrivial challenges, including imperfect information, large-scale information set and action spaces, a mixed learning objective involving cooperation and competition, long-horizon decision-making, variable action spaces, and dynamic team composition. These characteristics make it a demanding testbed for existing intelligent decision-making methods. Moreover, the independent API for each player allows human-AI interactions and supports integration with large language models. Empirically, we conduct two types of evaluations: (1) pairwise competitions among all GuanDan AI agents, and (2) human-AI matchups. Experimental results demonstrate that while current learning-based agents substantially outperform rule-based counterparts, they still fall short of achieving superhuman performance, underscoring the need for continued research in multi-agent intelligent decision-making domain. The project is publicly available at https://github.com/GameAI-NJUPT/OpenGuanDan.", "AI": {"tldr": "提出了一种新的基准测试OpenGuanDan，用于评估学习和基于规则的智能决策代理在多玩家卡牌游戏中的性能。", "motivation": "现有的数据驱动的人工智能领域需要更具有挑战性的基准来推动研究进展。因此，本文旨在通过引入一个新的基准测试——OpenGuanDan，为智能决策方法提供一个严格的测试环境。", "method": "提出了一个可以模拟四人中国扑克游戏Guandan的系统，并且支持学习和基于规则的代理之间的全面评估，该系统具有独立的API以促进与大语言模型的人机交互。", "result": "实验结果显示当前的学习型智能体在对抗规则型对手时表现出色，但仍未能达到超越人类的表现，这表明多智能决策领域仍需进一步的研究。", "conclusion": "OpenGuanDan作为一个新的基准测试系统，为研究者提供了一个挑战性的平台来改进多代理系统的性能，并且支持人机互动。"}}
{"id": "2602.00675", "pdf": "https://arxiv.org/pdf/2602.00675", "abs": "https://arxiv.org/abs/2602.00675", "authors": ["Valerio Belcamino", "Mariya Kilina", "Alessandro Carfì", "Valeria Seidita", "Fulvio Mastrogiovanni", "Antonio Chella"], "title": "Factored Reasoning with Inner Speech and Persistent Memory for Evidence-Grounded Human-Robot Interaction", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "Dialogue-based human-robot interaction requires robot cognitive assistants to maintain persistent user context, recover from underspecified requests, and ground responses in external evidence, while keeping intermediate decisions verifiable. In this paper we introduce JANUS, a cognitive architecture for assistive robots that models interaction as a partially observable Markov decision process and realizes control as a factored controller with typed interfaces. To this aim, Janus (i) decomposes the overall behavior into specialized modules, related to scope detection, intent recognition, memory, inner speech, query generation, and outer speech, and (ii) exposes explicit policies for information sufficiency, execution readiness, and tool grounding. A dedicated memory agent maintains a bounded recent-history buffer, a compact core memory, and an archival store with semantic retrieval, coupled through controlled consolidation and revision policies. Models inspired by the notion of inner speech in cognitive theories provide a control-oriented internal textual flow that validates parameter completeness and triggers clarification before grounding, while a faithfulness constraint ties robot-to-human claims to an evidence bundle combining working context and retrieved tool outputs. We evaluate JANUS through module-level unit tests in a dietary assistance domain grounded on a knowledge graph, reporting high agreement with curated references and practical latency profiles. These results support factored reasoning as a promising path to scalable, auditable, and evidence-grounded robot assistance over extended interaction horizons.", "AI": {"tldr": "本文介绍了一种用于辅助机器人的认知架构JANUS，旨在通过分模块设计和内部文本流控制，实现对话中对用户上下文的持久维护、请求恢复及基于证据回应的能力。", "motivation": "在对话基础上的人机交互需要机器人能够保持用户的上下文信息，在不明确的要求下进行自我修正，并根据外部证据做出响应，同时确保中间决策可验证。为此引入了JANUS架构以增强这些能力。", "method": "该方法通过将行为分解为多个专门模块（如范围检测、意图识别、记忆管理等）并暴露明确定义的策略来实现控制和信息管理，包括使用内省言语机制进行参数完整性和澄清触发验证。此外，还利用内存代理维护不同级别的存储系统，并通过证据捆绑结合工作上下文与检索工具输出以保证机器人声明的真实性。", "result": "在饮食协助领域的模块级单元测试中，JANUS显示出了高精度和低延迟性能，并支持基于分层推理的可扩展、审计性和证据驱动的机器人辅助服务。", "conclusion": "实验结果验证了通过分解式推理方法能够有效实现可持续、透明且以证据为基础的人机交互系统。"}}
{"id": "2602.00671", "pdf": "https://arxiv.org/pdf/2602.00671", "abs": "https://arxiv.org/abs/2602.00671", "authors": ["Yangzhi Ma", "Bojun Liu", "Wenting Liao", "Dong Liu", "Zhu Li", "Li Li"], "title": "HPC: Hierarchical Point-based Latent Representation for Streaming Dynamic Gaussian Splatting Compression", "categories": ["cs.CV"], "comment": null, "summary": "While dynamic Gaussian Splatting has driven significant advances in free-viewpoint video, maintaining its rendering quality with a small memory footprint for efficient streaming transmission still presents an ongoing challenge. Existing streaming dynamic Gaussian Splatting compression methods typically leverage a latent representation to drive the neural network for predicting Gaussian residuals between frames. Their core latent representations can be categorized into structured grid-based and unstructured point-based paradigms. However, the former incurs significant parameter redundancy by inevitably modeling unoccupied space, while the latter suffers from limited compactness as it fails to exploit local correlations. To relieve these limitations, we propose HPC, a novel streaming dynamic Gaussian Splatting compression framework. It employs a hierarchical point-based latent representation that operates on a per-Gaussian basis to avoid parameter redundancy in unoccupied space. Guided by a tailored aggregation scheme, these latent points achieve high compactness with low spatial redundancy. To improve compression efficiency, we further undertake the first investigation to compress neural networks for streaming dynamic Gaussian Splatting through mining and exploiting the inter-frame correlation of parameters. Combined with latent compression, this forms a fully end-to-end compression framework. Comprehensive experimental evaluations demonstrate that HPC substantially outperforms state-of-the-art methods. It achieves a storage reduction of 67% against its baseline while maintaining high reconstruction fidelity.", "AI": {"tldr": "提出了HPC框架，用于动态高斯点云压缩。", "motivation": "现有方法在未占用空间中存在参数冗余或局部相关性利用不足的问题。为解决这些局限性，提出一种新的流式动态高斯点云压缩框架。", "method": "采用分层的基于点的潜在表示来减少参数冗余，并通过聚合方案提高紧凑度。同时研究了如何压缩神经网络以进一步提升压缩效率。", "result": "实验结果表明HPC在存储减少方面比基准提高了67%，并保持了高重建精度。", "conclusion": "提出的方法显著优于现有方法，为流式动态高斯点云提供了高效的压缩解决方案。"}}
{"id": "2602.00669", "pdf": "https://arxiv.org/pdf/2602.00669", "abs": "https://arxiv.org/abs/2602.00669", "authors": ["Marina Crespo Aguirre", "Jonathan Williams-Ramirez", "Dina Zemlyanker", "Xiaoling Hu", "Lucas J. Deden-Binder", "Rogeny Herisse", "Mark Montine", "Theresa R. Connors", "Christopher Mount", "Christine L. MacDonald", "C. Dirk Keene", "Caitlin S. Latimer", "Derek H. Oakley", "Bradley T. Hyman", "Ana Lawry Aguila", "Juan Eugenio Iglesias"], "title": "Improving Neuropathological Reconstruction Fidelity via AI Slice Imputation", "categories": ["cs.CV", "cs.AI", "physics.med-ph"], "comment": "12 pages of main content, 5 pages of supplement", "summary": "Neuropathological analyses benefit from spatially precise volumetric reconstructions that enhance anatomical delineation and improve morphometric accuracy. Our prior work has shown the feasibility of reconstructing 3D brain volumes from 2D dissection photographs. However these outputs sometimes exhibit coarse, overly smooth reconstructions of structures, especially under high anisotropy (i.e., reconstructions from thick slabs). Here, we introduce a computationally efficient super-resolution step that imputes slices to generate anatomically consistent isotropic volumes from anisotropic 3D reconstructions of dissection photographs. By training on domain-randomized synthetic data, we ensure that our method generalizes across dissection protocols and remains robust to large slab thicknesses. The imputed volumes yield improved automated segmentations, achieving higher Dice scores, particularly in cortical and white matter regions. Validation on surface reconstruction and atlas registration tasks demonstrates more accurate cortical surfaces and MRI registration. By enhancing the resolution and anatomical fidelity of photograph-based reconstructions, our approach strengthens the bridge between neuropathology and neuroimaging. Our method is publicly available at https://surfer.nmr.mgh.harvard.edu/fswiki/mri_3d_photo_recon", "AI": {"tldr": "通过AI插补切片提高神经病理重建的准确性。", "motivation": "改善基于照片的三维脑体积重建，以增强形态学测量精度和解剖结构的一致性。", "method": "使用合成数据训练深度学习模型来插补厚层扫描的切片，并生成等轴距的体素。", "result": "提高了自动化分割的精确度，特别是在皮质和白质区域。验证表明了更准确的大脑表面重建和MRI配准。", "conclusion": "该方法增强了基于照片的三维重建的质量，加强了神经病理学与神经影像学之间的联系。"}}
{"id": "2602.00668", "pdf": "https://arxiv.org/pdf/2602.00668", "abs": "https://arxiv.org/abs/2602.00668", "authors": ["Duan Li", "Jun Yuan", "Xinyuan Guo", "Xiting Wang", "Yang Liu", "Weikai Yang", "Shixia Liu"], "title": "NCP: Neighborhood-Preserving Non-Uniform Circle Packing for Visualization", "categories": ["cs.HC"], "comment": "Accepted by Computational Visual Media", "summary": "Circle packing is widely used in visualization due to its aesthetic appeal and simplicity, particularly in tasks where the spatial arrangement and relationships between data are of interest, such as understanding proximity relationships (e.g., images with categories) or analyzing quantitative data (e.g., housing prices). Many applications require preserving neighborhood relationships while encoding a quantitative attribute using radii for data analysis. To meet these two requirements simultaneously, we present a neighborhood-preserving non-uniform circle packing method, NCP. This method preserves neighborhood relationships between the data represented by non-uniform circles to comprehensively analyze similar data and an attribute of interest. We formulate neighborhood-preserving non-uniform circle packing as a planar graph embedding problem based on the circle packing theorem. This formulation leads to a non-convex optimization problem, which can be solved by the continuation method. We conduct a quantitative evaluation and present two use cases to demonstrate that our NCP method can effectively generate non-uniform circle packing results.", "AI": {"tldr": "该论文提出了一种名为NCP的非均匀圆填充方法，用于在保持邻域关系的同时可视化数据。", "motivation": "许多应用需要在保持邻近关系的同时使用不同大小的圆来表示定量属性的数据。然而，现有的技术难以同时满足这两个要求。", "method": "该论文将非均匀圆填充问题转化为基于圆填充定理的平面图嵌入问题，并通过连续法解决这个非凸优化问题。", "result": "实验评估和两个应用场景表明，NCP方法可以有效地生成保持邻域关系的非均匀圆填充结果。", "conclusion": "论文提出的方法能够在可视化中同时满足数据之间的邻近关系保留以及定量属性表示的需求。"}}
{"id": "2602.00665", "pdf": "https://arxiv.org/pdf/2602.00665", "abs": "https://arxiv.org/abs/2602.00665", "authors": ["Lakshan Cooray", "Deshan Sumanathilaka", "Pattigadapa Venkatesh Raju"], "title": "Can Small Language Models Handle Context-Summarized Multi-Turn Customer-Service QA? A Synthetic Data-Driven Comparative Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": "Submission is under review with Computational Linguistics", "summary": "Customer-service question answering (QA) systems increasingly rely on conversational language understanding. While Large Language Models (LLMs) achieve strong performance, their high computational cost and deployment constraints limit practical use in resource-constrained environments. Small Language Models (SLMs) provide a more efficient alternative, yet their effectiveness for multi-turn customer-service QA remains underexplored, particularly in scenarios requiring dialogue continuity and contextual understanding. This study investigates instruction-tuned SLMs for context-summarized multi-turn customer-service QA, using a history summarization strategy to preserve essential conversational state. We also introduce a conversation stage-based qualitative analysis to evaluate model behavior across different phases of customer-service interactions. Nine instruction-tuned low-parameterized SLMs are evaluated against three commercial LLMs using lexical and semantic similarity metrics alongside qualitative assessments, including human evaluation and LLM-as-a-judge methods. Results show notable variation across SLMs, with some models demonstrating near-LLM performance, while others struggle to maintain dialogue continuity and contextual alignment. These findings highlight both the potential and current limitations of low-parameterized language models for real-world customer-service QA systems.", "AI": {"tldr": "本文研究了小型语言模型在多轮客户服务质量问答中的应用效果，采用对话摘要策略来保持对话状态，并通过词典和语义相似度指标以及定性评估进行对比。", "motivation": "大型语言模型虽然表现出色，但因计算成本高且部署受限，在资源有限的环境中使用较少。小型语言模型提供了一种更高效的替代方案，但在多轮客户服务质量问答中的效果尚待研究。", "method": "通过引入基于对话阶段的定性分析来评估各种指令调整的小型语言模型和商业大型语言模型在多轮客户服务问答任务上的表现，采用词汇和语义相似度指标以及人类评估等方法进行评价。", "result": "结果表明，小型语言模型的表现差异较大，一些模型接近于大型语言模型的性能，而另一些则难以保持对话连续性和上下文一致性。", "conclusion": "研究展示了低参数化语言模型在实际客户服务问答系统中的潜力与局限性。"}}
{"id": "2602.00663", "pdf": "https://arxiv.org/pdf/2602.00663", "abs": "https://arxiv.org/abs/2602.00663", "authors": ["Fabian P. Krüger", "Andrea Hunklinger", "Adrian Wolny", "Tim J. Adler", "Igor Tetko", "Santiago David Villalba"], "title": "SEISMO: Increasing Sample Efficiency in Molecular Optimization with a Trajectory-Aware LLM Agent", "categories": ["cs.AI", "cs.LG", "q-bio.BM"], "comment": "Fabian P. Krüger and Andrea Hunklinger contributed equally to this work", "summary": "Optimizing the structure of molecules to achieve desired properties is a central bottleneck across the chemical sciences, particularly in the pharmaceutical industry where it underlies the discovery of new drugs. Since molecular property evaluation often relies on costly and rate-limited oracles, such as experimental assays, molecular optimization must be highly sample-efficient. To address this, we introduce SEISMO, an LLM agent that performs strictly online, inference-time molecular optimization, updating after every oracle call without the need for population-based or batched learning. SEISMO conditions each proposal on the full optimization trajectory, combining natural-language task descriptions with scalar scores and, when available, structured explanatory feedback. Across the Practical Molecular Optimization benchmark of 23 tasks, SEISMO achieves a 2-3 times higher area under the optimisation curve than prior methods, often reaching near-maximal task scores within 50 oracle calls. Our additional medicinal-chemistry tasks show that providing explanatory feedback further improves efficiency, demonstrating that leveraging domain knowledge and structured information is key to sample-efficient molecular optimization.", "AI": {"tldr": "SEISMO是一种基于轨迹感知的LLM代理，用于提高分子优化中的样本效率。", "motivation": "分子结构优化是化学科学特别是制药行业的瓶颈问题。由于评估分子属性通常依赖于昂贵且有限的实验测定方法，因此需要高效利用样本进行分子优化。", "method": "SEISMO通过结合自然语言任务描述、标量分数和可能提供的结构化解释反馈，在每次调用或acles后更新其提议，从而在推理时间执行严格在线的分子优化。", "result": "在实践分子优化基准测试中，SEISMO达到比先前方法高2-3倍的优化曲线下面积，并且通常在50次oracle调用内接近最大任务分数。额外的医学化学任务表明提供解释反馈进一步提高了效率。", "conclusion": "通过利用领域知识和结构化信息，结合自然语言描述与评分系统及反馈机制，SEISMO展示了提高样本效率的关键策略。"}}
{"id": "2602.00661", "pdf": "https://arxiv.org/pdf/2602.00661", "abs": "https://arxiv.org/abs/2602.00661", "authors": ["Ahsan Raza Siyal", "Markus Haltmeier", "Ruth Steiger", "Elke Ruth Gizewski", "Astrid Ellen Grams"], "title": "Schrödinger-Inspired Time-Evolution for 4D Deformation Forecasting", "categories": ["cs.CV"], "comment": null, "summary": "Spatiotemporal forecasting of complex three-dimensional phenomena (4D: 3D + time) is fundamental to applications in medical imaging, fluid and material dynamics, and geophysics. In contrast to unconstrained neural forecasting models, we propose a Schrödinger-inspired, physics-guided neural architecture that embeds an explicit time-evolution operator within a deep convolutional framework for 4D prediction. From observed volumetric sequences, the model learns voxelwise amplitude, phase, and potential fields that define a complex-valued wavefunction $ψ= A e^{iφ}$, which is evolved forward in time using a differentiable, unrolled Schrödinger time stepper. This physics-guided formulation yields several key advantages: (i) temporal stability arising from the structured evolution operator, which mitigates drift and error accumulation in long-horizon forecasting; (ii) an interpretable latent representation, where phase encodes transport dynamics, amplitude captures structural intensity, and the learned potential governs spatiotemporal interactions; and (iii) natural compatibility with deformation-based synthesis, which is critical for preserving anatomical fidelity in medical imaging applications. By integrating physical priors directly into the learning process, the proposed approach combines the expressivity of deep networks with the robustness and interpretability of physics-based modeling. We demonstrate accurate and stable prediction of future 4D states, including volumetric intensities and deformation fields, on synthetic benchmarks that emulate realistic shape deformations and topological changes. To our knowledge, this is the first end-to-end 4D neural forecasting framework to incorporate a Schrödinger-type evolution operator, offering a principled pathway toward interpretable, stable, and anatomically consistent spatiotemporal prediction.", "AI": {"tldr": "本文提出了一个基于Schrödinger方程的时间演化算子的深度卷积框架，用于4D预测。", "motivation": "传统神经网络模型在长时间预报中容易产生漂移和误差积累，物理引导方法可以提高时间稳定性和解释性。通过将物理先验直接整合到学习过程中，该方法旨在结合深度网络的表达能力和基于物理学建模的优势。", "method": "提出了一种Schrödinger启发式的时间演化算子模型，利用观察到的体积序列学习各体素幅度、相位和势能场定义复值波函数$ψ=Ae^{iφ}$。该模型在时间上通过可微分展开Schroedinger时间步进器演进。", "result": "实验结果证明了对未来4D状态（包括体积强度和变形场）的准确且稳定的预测性能，特别是在模拟现实形状变形和拓扑变化的合成基准测试中表现良好。", "conclusion": "这是第一个将Schrödinger型演化算子集成到端对端4D神经预报框架中的方法。通过结合深度网络与基于物理学建模的优势，这种方法提供了一条解释性、稳定性和解剖学一致性的时间空间预测的合理途径。"}}
{"id": "2602.00659", "pdf": "https://arxiv.org/pdf/2602.00659", "abs": "https://arxiv.org/abs/2602.00659", "authors": ["Qusai Khaled", "Laura Genga", "Uzay Kaymak"], "title": "Predictive Maintenance for Ultrafiltration Membranes Using Explainable Similarity-Based Prognostics", "categories": ["cs.AI"], "comment": "Submitted to 21st International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems (IPMU2026)", "summary": "In reverse osmosis desalination, ultrafiltration (UF) membranes degrade due to fouling, leading to performance loss and costly downtime. Most plants rely on scheduled preventive maintenance, since existing predictive maintenance models, often based on opaque machine learning methods, lack interpretability and operator trust. This study proposes an explainable prognostic framework for UF membrane remaining useful life (RUL) estimation using fuzzy similarity reasoning. A physics-informed Health Index, derived from transmembrane pressure, flux, and resistance, captures degradation dynamics, which are then fuzzified via Gaussian membership functions. Using a similarity measure, the model identifies historical degradation trajectories resembling the current state and formulates RUL predictions as Takagi-Sugeno fuzzy rules. Each rule corresponds to a historical exemplar and contributes to a transparent, similarity-weighted RUL estimate. Tested on 12,528 operational cycles from an industrial-scale UF system, the framework achieved a mean absolute error of 4.50 cycles, while generating interpretable rule bases consistent with expert understanding.", "AI": {"tldr": "提出了一种基于模糊相似性的可解释性超滤膜剩余使用寿命预测框架。", "motivation": "现有的预测维护模型缺乏透明度和操作员信任，导致无法充分利用其潜力。该研究旨在开发一种能够提供清晰、易于理解的预测结果的方法，以提高维护效率并减少停机时间。", "method": "通过使用基于模糊相似性的推理方法，结合物理信息健康指数以及历史数据中的类似轨迹来预测超滤膜的剩余使用寿命。", "result": "在12,528个操作周期的数据集上进行测试后，该框架实现了平均绝对误差为4.50个周期的结果，并生成了与专家理解一致的可解释规则库。", "conclusion": "所提出的基于模糊相似性的预测方法能够有效地提高对超滤膜维护决策的支持度和透明度，从而有助于减少运行成本并延长设备寿命。"}}
{"id": "2602.00657", "pdf": "https://arxiv.org/pdf/2602.00657", "abs": "https://arxiv.org/abs/2602.00657", "authors": ["Sujoy Bhore", "Liana Khazaliya", "Fionn Mc Inerney"], "title": "Non-Clashing Teaching in Graphs: Algorithms, Complexity, and Bounds", "categories": ["cs.CC", "cs.DM", "cs.DS", "cs.LG", "math.CO"], "comment": "An extended abstract of this paper will appear in the proceedings of ICLR 2026", "summary": "Kirkpatrick et al. [ALT 2019] and Fallat et al. [JMLR 2023] introduced non-clashing teaching and proved that it is the most efficient batch machine teaching model satisfying the collusion-avoidance benchmark established in the seminal work of Goldman and Mathias [COLT 1993]. Recently, (positive) non-clashing teaching was thoroughly studied for balls in graphs, yielding numerous algorithmic and combinatorial results. In particular, Chalopin et al. [COLT 2024] and Ganian et al. [ICLR 2025] gave an almost complete picture of the complexity landscape of the positive variant, showing that it is tractable only for restricted graph classes due to the non-trivial nature of the problem and concept class. In this work, we consider (positive) non-clashing teaching for closed neighborhoods in graphs. This concept class is not only extensively studied in various related contexts, but it also exhibits broad generality, as any finite binary concept class can be equivalently represented by a set of closed neighborhoods in a graph. In comparison to the works on balls in graphs, we provide improved algorithmic results, notably including FPT algorithms for more general classes of parameters, and we complement these results by deriving stronger lower bounds. Lastly, we obtain combinatorial upper bounds for wider classes of graphs.", "AI": {"tldr": "研究图中封闭邻域的非冲突教学问题，提供算法和复杂度分析及界定", "motivation": "扩展先前关于图内球体的研究成果至更广泛的封闭邻域概念类。鉴于该问题在理论与实践中的重要性，提出改进的算法并建立更强的下界是必要的", "method": "利用参数化复杂度理论设计FPT算法，并通过组合方法获得图中非冲突教学问题的上界", "result": "为封闭邻域的概念类提供更广泛的可解性和复杂性的精确刻画，包括改进的FPT算法和更严格的计算复杂性下界", "conclusion": "研究表明在特定条件下非冲突教学对于封闭邻域是可行且有效的，并通过引入新的算法和技术提供了对该问题更深的理解"}}
{"id": "2602.00653", "pdf": "https://arxiv.org/pdf/2602.00653", "abs": "https://arxiv.org/abs/2602.00653", "authors": ["Lukas Kuhn", "Giuseppe Serra", "Florian Buettner"], "title": "Non-Contrastive Vision-Language Learning with Predictive Embedding Alignment", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-language models have transformed multimodal representation learning, yet dominant contrastive approaches like CLIP require large batch sizes, careful negative sampling, and extensive hyperparameter tuning. We introduce NOVA, a NOn-contrastive Vision-language Alignment framework based on joint embedding prediction with distributional regularization. NOVA aligns visual representations to a frozen, domain-specific text encoder by predicting text embeddings from augmented image views, while enforcing an isotropic Gaussian structure via Sketched Isotropic Gaussian Regularization (SIGReg). This eliminates the need for negative sampling, momentum encoders, or stop-gradients, reducing the training objective to a single hyperparameter. We evaluate NOVA on zeroshot chest X-ray classification using ClinicalBERT as the text encoder and Vision Transformers trained from scratch on MIMIC-CXR. On zero-shot classification across three benchmark datasets, NOVA outperforms multiple standard baselines while exhibiting substantially more consistent training runs. Our results demonstrate that non-contrastive vision-language pretraining offers a simpler, more stable, and more effective alternative to contrastive methods.", "AI": {"tldr": "本文介绍了NOVA框架，一种基于联合嵌入预测与分布正则化的非对比视觉语言对齐方法。", "motivation": "现有的对比学习方法如CLIP需要大批次大小、精心选择的负样本以及大量的超参数调整。因此，研究者提出了一种不需要这些复杂操作的新方法以简化训练过程。", "method": "NOVA框架通过从增强后的图像视图中预测文本嵌入来对齐视觉表示和冻结的领域特定文本编码器，并且使用Sketched Isotropic Gaussian Regularization (SIGReg) 强制执行各向同性高斯结构，从而消除了负样本、动量编码器或停用梯度的需求。", "result": "在零样本胸部X射线分类上，NOVA的表现优于多个标准基线，并且具有更稳定的训练过程。这证明了非对比视觉语言预训练的有效性和稳定性。", "conclusion": "研究表明，通过采用联合嵌入预测和分布正则化方法的非对比视觉语言预训练方式可以提供一种更为简化、稳定及有效的替代方案来取代传统的对比学习方法。"}}
{"id": "2602.00650", "pdf": "https://arxiv.org/pdf/2602.00650", "abs": "https://arxiv.org/abs/2602.00650", "authors": ["Mohammadreza Gholipour Shahraki", "Mehdi Rezaeian", "Mohammad Ghasemzadeh"], "title": "A Hybrid Mamba-SAM Architecture for Efficient 3D Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate segmentation of 3D medical images such as MRI and CT is essential for clinical diagnosis and treatment planning. Foundation models like the Segment Anything Model (SAM) provide powerful general-purpose representations but struggle in medical imaging due to domain shift, their inherently 2D design, and the high computational cost of fine-tuning. To address these challenges, we propose Mamba-SAM, a novel and efficient hybrid architecture that combines a frozen SAM encoder with the linear-time efficiency and long-range modeling capabilities of Mamba-based State Space Models (SSMs). We investigate two parameter-efficient adaptation strategies. The first is a dual-branch architecture that explicitly fuses general features from a frozen SAM encoder with domain-specific representations learned by a trainable VMamba encoder using cross-attention. The second is an adapter-based approach that injects lightweight, 3D-aware Tri-Plane Mamba (TPMamba) modules into the frozen SAM ViT encoder to implicitly model volumetric context. Within this framework, we introduce Multi-Frequency Gated Convolution (MFGC), which enhances feature representation by jointly analyzing spatial and frequency-domain information via 3D discrete cosine transforms and adaptive gating. Extensive experiments on the ACDC cardiac MRI dataset demonstrate the effectiveness of the proposed methods. The dual-branch Mamba-SAM-Base model achieves a mean Dice score of 0.906, comparable to UNet++ (0.907), while outperforming all baselines on Myocardium (0.910) and Left Ventricle (0.971) segmentation. The adapter-based TP MFGC variant offers superior inference speed (4.77 FPS) with strong accuracy (0.880 Dice). These results show that hybridizing foundation models with efficient SSM-based architectures provides a practical and effective solution for 3D medical image segmentation.", "AI": {"tldr": "提出了一种结合冻结的SAM编码器和高效的SSM架构的新颖混合方法，用于准确分割3D医学图像。", "motivation": "为了解决基础模型在医学成像中遇到的领域差异、2D设计以及微调计算成本高的问题，本文提出了一个能够有效进行3D医学图像分割的混合架构。", "method": "提出了一种结合冻结的SAM编码器与高效SSM（如Mamba）的混合方法。该方法包括两种参数高效的适应策略：一种是双分支架构，通过交叉注意力将通用特征和领域特定表示融合；另一种是在冻结的SAM ViT编码器中注入轻量级TPMamba模块以隐式建模体积上下文。此外，引入多频率门控卷积（MFGC）来增强特征表示。", "result": "在ACDC心脏MRI数据集上的实验结果表明，双分支架构的Mamba-SAM-Base模型达到了0.906的平均Dice得分，并且在心肌和左室分割上分别达到0.910和0.971。基于适配器的方法TP MFGC变体提供了更强的准确性（0.880 Dice）同时保持了较高的推断速度（4.77 FPS）。", "conclusion": "将基础模型与高效SSM架构相结合，为3D医学图像分割提供了一种实用且有效的方法。"}}
{"id": "2602.00648", "pdf": "https://arxiv.org/pdf/2602.00648", "abs": "https://arxiv.org/abs/2602.00648", "authors": ["Hao Ma", "Ruihao Jing", "Shansong Liu", "Cheng Gong", "Chi Zhang", "Xiao-Lei Zhang", "Xuelong Li"], "title": "High-Fidelity Generative Audio Compression at 0.275kbps", "categories": ["eess.AS", "cs.SD"], "comment": "Technical Report", "summary": "High-fidelity general audio compression at ultra-low bitrates is crucial for applications ranging from low-bandwidth communication to generative audio-language modeling. Traditional audio compression methods and contemporary neural codecs are fundamentally designed for waveform reconstruction. As a result, when operating at ultra-low bitrates, these methods degrade rapidly and often fail to preserve essential information, leading to severe acoustic artifacts and pronounced semantic distortion. To overcome these limitations, we introduce Generative Audio Compression (GAC), a novel paradigm shift from signal fidelity to task-oriented effectiveness. Implemented within the AI Flow framework, GAC is theoretically grounded in the Law of Information Capacity. These foundations posit that abundant computational power can be leveraged at the receiver to offset extreme communication bottlenecks--exemplifying the More Computation, Less Bandwidth philosophy. By integrating semantic understanding at the transmitter with scalable generative synthesis at the receiver, GAC offloads the information burden to powerful model priors. Our 1.8B-parameter model achieves high-fidelity reconstruction of 32kHz general audio at an unprecedented bitrate of 0.275kbps. Even at 0.175kbps, it still preserves a strong intelligible audio transmission capability, which represents an about 3000x compression ratio, significantly outperforming current state-of-the-art neural codecs in maintaining both perceptual quality and semantic consistency.", "AI": {"tldr": "提出了高保真音频压缩的新方法GAC，能够在极低比特率下实现高质量的音频重建。", "motivation": "传统的音频压缩方法和现代神经编码器在超低比特率时性能下降严重，无法有效保持信息。因此，需要一种新的方法来克服这些限制。", "method": "提出了基于AI Flow框架的生成式音频压缩（GAC），利用强大的计算能力来补偿通信瓶颈，并通过语义理解和可扩展的生成合成减轻信息负担。", "result": "1.8B参数模型实现了在0.275kbps比特率下32kHz通用音频的高保真重建，即使在0.175kbps时仍能保持较强的可懂音质传输能力。这代表了约3000倍的压缩比。", "conclusion": "GAC显著优于当前最先进的神经编码器，在维持感知质量和语义一致性方面表现出色。"}}
{"id": "2602.00644", "pdf": "https://arxiv.org/pdf/2602.00644", "abs": "https://arxiv.org/abs/2602.00644", "authors": ["Ajinkya Gaikwad", "Soumen Maity", "Leeja R"], "title": "Hardness and Tractability of T_{h+1}-Free Edge Deletion", "categories": ["cs.DS", "cs.CC"], "comment": "23 pages", "summary": "We study the parameterized complexity of the T(h+1)-Free Edge Deletion problem. Given a graph G and integers k and h, the task is to delete at most k edges so that every connected component of the resulting graph has size at most h. The problem is NP-complete for every fixed h at least 3, while it is solvable in polynomial time for h at most 2. Recent work showed strong hardness barriers: the problem is W[1]-hard when parameterized by the solution size together with the size of a feedback edge set, ruling out fixed-parameter tractability for many classical structural parameters. We significantly strengthen these negative results by proving W[1]-hardness when parameterized by the vertex deletion distance to a disjoint union of paths, the vertex deletion distance to a disjoint union of stars, or the twin cover number. These results unify and extend known hardness results for treewidth, pathwidth, and feedback vertex set, and show that several restrictive parameters, including treedepth, cluster vertex deletion number, and modular width, do not yield fixed-parameter tractability when h is unbounded. On the positive side, we identify parameterizations that restore tractability. We show that the problem is fixed-parameter tractable when parameterized by cluster vertex deletion together with h, and also when parameterized by neighborhood diversity together with h via an integer linear programming formulation. We further present a fixed-parameter tractable bicriteria approximation algorithm parameterized by k. Finally, we show that the problem admits fixed-parameter tractable algorithms on split graphs and interval graphs, and we establish hardness for a directed generalization even on directed acyclic graphs.", "AI": {"tldr": "研究T_{h+1}-Free Edge Deletion问题的参数复杂性。", "motivation": "探讨给定图中删除最多k条边使得每个连通分量大小不超过h的问题，展示其在某些参数下的难度和可解性。", "method": "通过证明W[1]-hardness等理论来研究问题的难易度，并提出新的参数化算法以解决特定条件下的实例。", "result": "展示了多个限制参数下的W[1]-硬度结果及部分参数组合下的固定参数可解性，如cluster vertex deletion和neighborhood diversity。此外还提供了针对k的近似算法以及在特殊图类中的有效算法。", "conclusion": "该问题具有广泛的理论意义，并通过特定方法展现了其复杂度特性及其潜在应用价值。"}}
{"id": "2602.00639", "pdf": "https://arxiv.org/pdf/2602.00639", "abs": "https://arxiv.org/abs/2602.00639", "authors": ["Yifang Xu", "Benxiang Zhai", "Chenyu Zhang", "Ming Li", "Yang Li", "Sidan Du"], "title": "Diff-PC: Identity-preserving and 3D-aware Controllable Diffusion for Zero-shot Portrait Customization", "categories": ["cs.CV"], "comment": "Accepted by Information Fusion 2025", "summary": "Portrait customization (PC) has recently garnered significant attention due to its potential applications. However, existing PC methods lack precise identity (ID) preservation and face control. To address these tissues, we propose Diff-PC, a diffusion-based framework for zero-shot PC, which generates realistic portraits with high ID fidelity, specified facial attributes, and diverse backgrounds. Specifically, our approach employs the 3D face predictor to reconstruct the 3D-aware facial priors encompassing the reference ID, target expressions, and poses. To capture fine-grained face details, we design ID-Encoder that fuses local and global facial features. Subsequently, we devise ID-Ctrl using the 3D face to guide the alignment of ID features. We further introduce ID-Injector to enhance ID fidelity and facial controllability. Finally, training on our collected ID-centric dataset improves face similarity and text-to-image (T2I) alignment. Extensive experiments demonstrate that Diff-PC surpasses state-of-the-art methods in ID preservation, facial control, and T2I consistency. Furthermore, our method is compatible with multi-style foundation models.", "AI": {"tldr": "本文提出了一种基于扩散模型的零样本肖像定制框架Diff-PC，用于生成高身份保真度、可控制面部特性和多样背景的真实人脸图像。", "motivation": "现有的肖像定制方法在身份保留和面部控制方面存在不足，因此本文旨在设计一种既能保持高度身份一致性又能进行精细面部特征调整的方法。", "method": "Diff-PC利用3D面部分析技术重建包含参考身份、目标表情及姿态的3D感知脸部先验，并通过ID-Encoder融合局部与全局脸部特征。随后使用ID-Ctrl根据3D脸部模型引导身份特征对齐，以及引入ID-Injector提升身份保真度和面部控制性。", "result": "实验结果显示，Diff-PC在身份保留、面部控制及文本到图像一致性方面优于当前最佳方法，并能与多风格基础模型兼容。", "conclusion": "本文通过提出Diff-PC框架解决了现有肖像定制技术的身份保留不足问题，实现了高保真度和高度可控制性的人脸生成。"}}
{"id": "2602.00637", "pdf": "https://arxiv.org/pdf/2602.00637", "abs": "https://arxiv.org/abs/2602.00637", "authors": ["Vivek Madhavaram", "Vartika Sengar", "Arkadipta De", "Charu Sharma"], "title": "VIZOR: Viewpoint-Invariant Zero-Shot Scene Graph Generation for 3D Scene Reasoning", "categories": ["cs.CV"], "comment": "WACV 2026, Project page: https://vivekmadhavaram.github.io/vizor/", "summary": "Scene understanding and reasoning has been a fundamental problem in 3D computer vision, requiring models to identify objects, their properties, and spatial or comparative relationships among the objects. Existing approaches enable this by creating scene graphs using multiple inputs such as 2D images, depth maps, object labels, and annotated relationships from specific reference view. However, these methods often struggle with generalization and produce inaccurate spatial relationships like \"left/right\", which become inconsistent across different viewpoints. To address these limitations, we propose Viewpoint-Invariant Zero-shot scene graph generation for 3D scene Reasoning (VIZOR). VIZOR is a training-free, end-to-end framework that constructs dense, viewpoint-invariant 3D scene graphs directly from raw 3D scenes. The generated scene graph is unambiguous, as spatial relationships are defined relative to each object's front-facing direction, making them consistent regardless of the reference view. Furthermore, it infers open-vocabulary relationships that describe spatial and proximity relationships among scene objects without requiring annotated training data. We conduct extensive quantitative and qualitative evaluations to assess the effectiveness of VIZOR in scene graph generation and downstream tasks, such as query-based object grounding. VIZOR outperforms state-of-the-art methods, showing clear improvements in scene graph generation and achieving 22% and 4.81% gains in zero-shot grounding accuracy on the Replica and Nr3D datasets, respectively.", "AI": {"tldr": "VIZOR是一个视角不变的零样本场景图生成框架，用于三维场景推理", "motivation": "现有的方法在处理不同视点时难以泛化，并且容易产生不一致的空间关系。为此，研究者提出了一个无训练、端到端的框架来构建稠密且视角不变的3D场景图，以提高空间关系的一致性和准确性", "method": "VIZOR直接从原始3D场景生成视角不变的场景图，定义了基于每个对象正面方向的空间关系，并可以推断出开放词汇的关系，无需标注训练数据", "result": "在Scene Graph生成和下游任务如基于查询的对象定位上，VIZOR优于现有最佳方法，在Replica和Nr3D数据集上的零样本接地准确率分别提高了22%和4.81%", "conclusion": "VIZOR展示了其在三维场景理解和推理中的优越性"}}
{"id": "2602.00635", "pdf": "https://arxiv.org/pdf/2602.00635", "abs": "https://arxiv.org/abs/2602.00635", "authors": ["Lingsong Wang", "Mancheng Meng", "Ziyan Wu", "Terrence Chen", "Fan Yang", "Dinggang Shen"], "title": "S$^3$POT: Contrast-Driven Face Occlusion Segmentation via Self-Supervised Prompt Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Existing face parsing methods usually misclassify occlusions as facial components. This is because occlusion is a high-level concept, it does not refer to a concrete category of object. Thus, constructing a real-world face dataset covering all categories of occlusion object is almost impossible and accurate mask annotation is labor-intensive. To deal with the problems, we present S$^3$POT, a contrast-driven framework synergizing face generation with self-supervised spatial prompting, to achieve occlusion segmentation. The framework is inspired by the insights: 1) Modern face generators' ability to realistically reconstruct occluded regions, creating an image that preserve facial geometry while eliminating occlusion, and 2) Foundation segmentation models' (e.g., SAM) capacity to extract precise mask when provided with appropriate prompts. In particular, S$^3$POT consists of three modules: Reference Generation (RF), Feature enhancement (FE), and Prompt Selection (PS). First, a reference image is produced by RF using structural guidance from parsed mask. Second, FE performs contrast of tokens between raw and reference images to obtain an initial prompt, then modifies image features with the prompt by cross-attention. Third, based on the enhanced features, PS constructs a set of positive and negative prompts and screens them with a self-attention network for a mask decoder. The network is learned under the guidance of three novel and complementary objective functions without occlusion ground truth mask involved. Extensive experiments on a dedicatedly collected dataset demonstrate S$^3$POT's superior performance and the effectiveness of each module.", "AI": {"tldr": "提出了一种基于自监督提示学习的对比驱动人脸遮挡分割框架S$^3$POT。", "motivation": "现有方法常将遮挡物误分类为面部组件，因为遮挡是一个高层次的概念，并且难以构建包含所有遮挡物体类别的真实世界数据集并进行准确标注。因此需要一种新方法来解决此问题。", "method": "S$^3$POT框架包括三个模块：参考生成（RF），特征增强（FE）和提示选择（PS）。RF使用解析掩码提供的结构指导生产参考图，FE通过原始图像与参考图像对比获取初步提示并调整图像特征，PS构建一组正负提示并通过自注意力网络筛选这些提示。", "result": "实验表明S$^3$POT在专用数据集上的性能优于现有方法，并证明了每个模块的有效性。", "conclusion": "S$^3$POT通过引入新的对比驱动框架解决了遮挡物分割问题，无需真实标签并展示了其优越性和有效性。"}}
{"id": "2602.00629", "pdf": "https://arxiv.org/pdf/2602.00629", "abs": "https://arxiv.org/abs/2602.00629", "authors": ["Natinael Solomon Neggatu", "Jeremie Houssineau", "Giovanni Montana"], "title": "Action-Free Offline-to-Online RL via Discretised State Policies", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "ICLR 2026", "summary": "Most existing offline RL methods presume the availability of action labels within the dataset, but in many practical scenarios, actions may be missing due to privacy, storage, or sensor limitations. We formalise the setting of action-free offline-to-online RL, where agents must learn from datasets consisting solely of $(s,r,s')$ tuples and later leverage this knowledge during online interaction. To address this challenge, we propose learning state policies that recommend desirable next-state transitions rather than actions. Our contributions are twofold. First, we introduce a simple yet novel state discretisation transformation and propose Offline State-Only DecQN (\\algo), a value-based algorithm designed to pre-train state policies from action-free data. \\algo{} integrates the transformation to scale efficiently to high-dimensional problems while avoiding instability and overfitting associated with continuous state prediction. Second, we propose a novel mechanism for guided online learning that leverages these pre-trained state policies to accelerate the learning of online agents. Together, these components establish a scalable and practical framework for leveraging action-free datasets to accelerate online RL. Empirical results across diverse benchmarks demonstrate that our approach improves convergence speed and asymptotic performance, while analyses reveal that discretisation and regularisation are critical to its effectiveness.", "AI": {"tldr": "研究提出了一种从无动作标签的离线数据中学习并加速在线强化学习的方法", "motivation": "解决在实际应用中由于隐私、存储或传感器限制导致的数据集缺少动作标注的问题，使得模型能够利用仅有状态转换信息进行训练和提升在线决策能力。", "method": "通过将连续状态空间离散化，并引入一种称为Offline State-Only DecQN的算法来预训练基于状态的策略，在线学习阶段则使用这些预训练的状态策略指导强化学习过程以加速收敛速度。", "result": "实验结果表明，该方法在不同基准测试中均能有效提高模型的收敛速度和最终性能，同时分析发现离散化处理与正则化技术对提升效果至关重要。", "conclusion": "所提出的框架为利用无动作标签的数据进行高效的在线强化学习提供了可行路径，并展示了其在实际应用中的潜力。"}}
{"id": "2602.00628", "pdf": "https://arxiv.org/pdf/2602.00628", "abs": "https://arxiv.org/abs/2602.00628", "authors": ["Louis Schiekiera", "Max Zimmer", "Christophe Roux", "Sebastian Pokutta", "Fritz Günther"], "title": "From Associations to Activations: Comparing Behavioral and Hidden-State Semantic Geometry in LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "25 pages including references, 15 figures, 6 tables", "summary": "We investigate the extent to which an LLM's hidden-state geometry can be recovered from its behavior in psycholinguistic experiments. Across eight instruction-tuned transformer models, we run two experimental paradigms -- similarity-based forced choice and free association -- over a shared 5,000-word vocabulary, collecting 17.5M+ trials to build behavior-based similarity matrices. Using representational similarity analysis, we compare behavioral geometries to layerwise hidden-state similarity and benchmark against FastText, BERT, and cross-model consensus. We find that forced-choice behavior aligns substantially more with hidden-state geometry than free association. In a held-out-words regression, behavioral similarity (especially forced choice) predicts unseen hidden-state similarities beyond lexical baselines and cross-model consensus, indicating that behavior-only measurements retain recoverable information about internal semantic geometry. Finally, we discuss implications for the ability of behavioral tasks to uncover hidden cognitive states.", "AI": {"tldr": "本文研究了通过心理学实验行为能否恢复LLM内部隐藏状态的几何结构。", "motivation": "探索大型语言模型的行为表现是否能揭示其内部语义几何结构，以更好地理解模型的认知状态。", "method": "使用八个指令调优的Transformer模型进行相似性基于强迫选择和自由联想两种实验范式，并收集大量行为数据建立行为相似矩阵。利用代表相似度分析对比行为几何与隐藏层几何，同时与其他基准（如FastText、BERT）进行比较。", "result": "发现强迫选择的行为表现比自由联想更接近模型的内部几何结构，且行为相似性可以预测未见过的隐藏状态相似性。", "conclusion": "行为任务能够揭示模型内部的认知状态，表明仅通过行为数据就能获得有关内部语义几何的信息。"}}
{"id": "2602.00627", "pdf": "https://arxiv.org/pdf/2602.00627", "abs": "https://arxiv.org/abs/2602.00627", "authors": ["Benxiang Zhai", "Yifang Xu", "Guofeng Zhang", "Yang Li", "Sidan Du"], "title": "FaceSnap: Enhanced ID-fidelity Network for Tuning-free Portrait Customization", "categories": ["cs.CV"], "comment": "Accept by ICANN 2025", "summary": "Benefiting from the significant advancements in text-to-image diffusion models, research in personalized image generation, particularly customized portrait generation, has also made great strides recently. However, existing methods either require time-consuming fine-tuning and lack generalizability or fail to achieve high fidelity in facial details. To address these issues, we propose FaceSnap, a novel method based on Stable Diffusion (SD) that requires only a single reference image and produces extremely consistent results in a single inference stage. This method is plug-and-play and can be easily extended to different SD models. Specifically, we design a new Facial Attribute Mixer that can extract comprehensive fused information from both low-level specific features and high-level abstract features, providing better guidance for image generation. We also introduce a Landmark Predictor that maintains reference identity across landmarks with different poses, providing diverse yet detailed spatial control conditions for image generation. Then we use an ID-preserving module to inject these into the UNet. Experimental results demonstrate that our approach performs remarkably in personalized and customized portrait generation, surpassing other state-of-the-art methods in this domain.", "AI": {"tldr": "提出了FaceSnap，一种基于稳定扩散模型的面部定制方法，能够通过单一参考图像在单次推理中生成极高身份一致性的个性化肖像。", "motivation": "现有的个性化图像生成方法要么需要耗时的微调且缺乏泛化能力，要么无法实现面部细节的高度保真。为解决这些问题，提出FaceSnap以提高身份一致性并减少对微调的需求。", "method": "设计了一种新的面部属性混合器来提取低级和高级特征融合信息，并引入了地标预测器以保持参考图像的身份一致性和多样化的空间控制条件，同时利用一个ID保护模块将这些信息注入UNet网络。", "result": "实验证明FaceSnap在个性化和定制化肖像生成方面表现优异，优于其他最先进的方法。", "conclusion": "FaceSnap提供了一种无需微调即可实现高度身份一致性和高质量面部细节的插件式解决方案，适用于多种稳定扩散模型。"}}
{"id": "2602.00624", "pdf": "https://arxiv.org/pdf/2602.00624", "abs": "https://arxiv.org/abs/2602.00624", "authors": ["Hyekyung Yoon", "Minhyuk Lee", "Imseung Park", "Myungjoo Kang"], "title": "MoDEx: Mixture of Depth-specific Experts for Multivariate Long-term Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multivariate long-term time series forecasting (LTSF) supports critical applications such as traffic-flow management, solar-power scheduling, and electricity-transformer monitoring. The existing LTSF paradigms follow a three-stage pipeline of embedding, backbone refinement, and long-horizon prediction. However, the behaviors of individual backbone layers remain underexplored. We introduce layer sensitivity, a gradient-based metric inspired by GradCAM and effective receptive field theory, which quantifies both positive and negative contributions of each time point to a layer's latent features. Applying this metric to a three-layer MLP backbone reveals depth-specific specialization in modeling temporal dynamics in the input sequence. Motivated by these insights, we propose MoDEx, a lightweight Mixture of Depth-specific Experts, which replaces complex backbones with depth-specific MLP experts. MoDEx achieves state-of-the-art accuracy on seven real-world benchmarks, ranking first in 78 percent of cases, while using significantly fewer parameters and computational resources. It also integrates seamlessly into transformer variants, consistently boosting their performance and demonstrating robust generalizability as an efficient and high-performance LTSF framework.", "AI": {"tldr": "提出了MoDEx，一种用于多变量长期时间序列预测的混合深度专家模型。", "motivation": "现有的LTSF范式在三个阶段：嵌入、主干细化和长时预测。但是单个主干层的行为尚未被充分探索。", "method": "引入了基于梯度的指标——层敏感性，以量化每个时间点对每一层潜在特征的正负贡献。据此提出了MoDEx，用深度特异MLP专家替换复杂主干。", "result": "在七种真实世界的基准测试中实现了SOTA准确率，在78％的情况下排名第一，并且参数和计算资源使用较少。", "conclusion": "MoDEx作为高效高性能LTSF框架表现出色并能与Transformer变体无缝集成，提升了其性能。"}}
{"id": "2602.00621", "pdf": "https://arxiv.org/pdf/2602.00621", "abs": "https://arxiv.org/abs/2602.00621", "authors": ["Guangtao Lyu", "Xinyi Cheng", "Qi Liu", "Chenghao Xu", "Jiexi Yan", "Muli Yang", "Fen Fang", "Cheng Deng"], "title": "Towards Interpretable Hallucination Analysis and Mitigation in LVLMs via Contrastive Neuron Steering", "categories": ["cs.CV"], "comment": null, "summary": "LVLMs achieve remarkable multimodal understanding and generation but remain susceptible to hallucinations. Existing mitigation methods predominantly focus on output-level adjustments, leaving the internal mechanisms that give rise to these hallucinations largely unexplored. To gain a deeper understanding, we adopt a representation-level perspective by introducing sparse autoencoders (SAEs) to decompose dense visual embeddings into sparse, interpretable neurons. Through neuron-level analysis, we identify distinct neuron types, including always-on neurons and image-specific neurons. Our findings reveal that hallucinations often result from disruptions or spurious activations of image-specific neurons, while always-on neurons remain largely stable. Moreover, selectively enhancing or suppressing image-specific neurons enables controllable intervention in LVLM outputs, improving visual grounding and reducing hallucinations. Building on these insights, we propose Contrastive Neuron Steering (CNS), which identifies image-specific neurons via contrastive analysis between clean and noisy inputs. CNS selectively amplifies informative neurons while suppressing perturbation-induced activations, producing more robust and semantically grounded visual representations. This not only enhances visual understanding but also effectively mitigates hallucinations. By operating at the prefilling stage, CNS is fully compatible with existing decoding-stage methods. Extensive experiments on both hallucination-focused and general multimodal benchmarks demonstrate that CNS consistently reduces hallucinations while preserving overall multimodal understanding.", "AI": {"tldr": "本文提出了一种名为对比神经元导向（CNS）的方法，用于分析和减轻LVLM中的幻觉现象。", "motivation": "现有的缓解方法主要集中在输出层面的调整上，而对产生这些幻觉的内部机制研究不足。作者采用表征层面视角，利用稀疏自编码器（SAE）来分解密集视觉嵌入到可解释性神经元，以更好地理解并减轻LVLM中的幻觉现象。", "method": "通过引入稀疏自编码器将密集视觉嵌入分解为易于解读的神经元，并对这些神经元进行类型分析；接着提出对比神经元导向（CNS）方法来识别图像特定神经元并通过增强或抑制它们实现可控干预，从而提高视觉接地并减少幻觉。", "result": "实验结果表明，所提方法在多个基准测试中能够一致地降低幻觉现象同时保持多模态理解的整体水平。", "conclusion": "通过对比分析清洁和有噪声的输入来识别图像特定神经元，并选择性增强或抑制它们，可以生成更稳健且语义接地的视觉表示。"}}
{"id": "2602.00620", "pdf": "https://arxiv.org/pdf/2602.00620", "abs": "https://arxiv.org/abs/2602.00620", "authors": ["Juntao Fang", "Shifeng Xie", "Shengbin Nie", "Yuhui Ling", "Yuming Liu", "Zijian Li", "Keli Zhang", "Lujia Pan", "Themis Palpanas", "Ruichu Cai"], "title": "Rethinking Zero-Shot Time Series Classification: From Task-specific Classifiers to In-Context Inference", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The zero-shot evaluation of time series foundation models (TSFMs) for classification typically uses a frozen encoder followed by a task-specific classifier. However, this practice violates the training-free premise of zero-shot deployment and introduces evaluation bias due to classifier-dependent training choices. To address this issue, we propose TIC-FM, an in-context learning framework that treats the labeled training set as context and predicts labels for all test instances in a single forward pass, without parameter updates. TIC-FM pairs a time series encoder and a lightweight projection adapter with a split-masked latent memory Transformer. We further provide theoretical justification that in-context inference can subsume trained classifiers and can emulate gradient-based classifier training within a single forward pass. Experiments on 128 UCR datasets show strong accuracy, with consistent gains in the extreme low-label situation, highlighting training-free transfer", "AI": {"tldr": "该论文提出了一种零样本时间序列分类的新方法TIC-FM，它采用一种无需训练的上下文学习框架进行预测。", "motivation": "传统的零样本时间序列分类方法需要冻结编码器并使用特定任务的分类器，这与无训练部署的前提不符，并引入了训练依赖的选择偏差。论文旨在解决这个问题，提出了一种新的上下文学习框架。", "method": "TIC-FM将标记过的训练集作为上下文，在单次前向传播中预测所有测试实例的标签，无需参数更新。该方法结合时间序列编码器和轻量级投影适配器以及分裂掩码潜在记忆Transformer。", "result": "实验在128个UCR数据集上展示了TIC-FM的强大准确度，并且在极端低标签情况下表现出一致的优势。", "conclusion": "论文证明了上下文推理可以取代训练分类器并在单次前向传播中模拟基于梯度的分类器训练，从而实现无训练迁移学习。"}}
{"id": "2602.00619", "pdf": "https://arxiv.org/pdf/2602.00619", "abs": "https://arxiv.org/abs/2602.00619", "authors": ["Yuxuan Lu", "Yongkang Guo", "Yuqing Kong"], "title": "Jailbreaking LLMs via Calibration", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "comment": null, "summary": "Safety alignment in Large Language Models (LLMs) often creates a systematic discrepancy between a model's aligned output and the underlying pre-aligned data distribution. We propose a framework in which the effect of safety alignment on next-token prediction is modeled as a systematic distortion of a pre-alignment distribution. We cast Weak-to-Strong Jailbreaking as a forecast aggregation problem and derive an optimal aggregation strategy characterized by a Gradient Shift in the loss-induced dual space. We show that logit-arithmetic jailbreaking methods are a special case of this framework under cross-entropy loss, and derive a broader family of aggregation rules corresponding to other proper losses. We also propose a new hybrid aggregation rule. Evaluations across red-teaming benchmarks and math utility tasks using frontier models demonstrate that our approach achieves superior Attack Success Rates and lower \"Jailbreak Tax\" compared with existing methods, especially on the safety-hardened gpt-oss-120b.", "AI": {"tldr": "提出了一种框架，通过校准来破解大型语言模型的安全对齐。", "motivation": "安全对齐在大型语言模型中产生了系统性的偏差。研究者希望通过解决这个问题来提高模型的攻击成功率并降低“破解税”。", "method": "将弱到强的破解问题视为预测聚合的问题，并推导出最优的聚合策略，使用梯度变化来优化损失诱导的对偶空间。", "result": "在多个红色团队基准测试和数学任务中表现优于现有方法，在安全加固后的gpt-oss-120b模型上尤其有效。", "conclusion": "该框架提供了一种新的方法来破解大型语言模型的安全机制，提高了攻击成功率并降低了“破解税”。"}}
{"id": "2602.00618", "pdf": "https://arxiv.org/pdf/2602.00618", "abs": "https://arxiv.org/abs/2602.00618", "authors": ["Yian Zhao", "Rushi Ye", "Ruochong Zheng", "Zesen Cheng", "Chaoran Feng", "Jiashu Yang", "Pengchong Qiao", "Chang Liu", "Jie Chen"], "title": "Tune-Your-Style: Intensity-tunable 3D Style Transfer with Gaussian Splatting", "categories": ["cs.CV"], "comment": "ICCV 2025", "summary": "3D style transfer refers to the artistic stylization of 3D assets based on reference style images. Recently, 3DGS-based stylization methods have drawn considerable attention, primarily due to their markedly enhanced training and rendering speeds. However, a vital challenge for 3D style transfer is to strike a balance between the content and the patterns and colors of the style. Although the existing methods strive to achieve relatively balanced outcomes, the fixed-output paradigm struggles to adapt to the diverse content-style balance requirements from different users. In this work, we introduce a creative intensity-tunable 3D style transfer paradigm, dubbed \\textbf{Tune-Your-Style}, which allows users to flexibly adjust the style intensity injected into the scene to match their desired content-style balance, thus enhancing the customizability of 3D style transfer. To achieve this goal, we first introduce Gaussian neurons to explicitly model the style intensity and parameterize a learnable style tuner to achieve intensity-tunable style injection. To facilitate the learning of tunable stylization, we further propose the tunable stylization guidance, which obtains multi-view consistent stylized views from diffusion models through cross-view style alignment, and then employs a two-stage optimization strategy to provide stable and efficient guidance by modulating the balance between full-style guidance from the stylized views and zero-style guidance from the initial rendering. Extensive experiments demonstrate that our method not only delivers visually appealing results, but also exhibits flexible customizability for 3D style transfer. Project page is available at https://zhao-yian.github.io/TuneStyle.", "AI": {"tldr": "本文提出了一种可调风格强度的三维风格迁移方法Tune-Your-Style，允许用户根据个人偏好调整内容和样式之间的平衡。", "motivation": "现有的三维风格迁移技术在处理不同用户对于内容与风格之间平衡的不同需求时存在局限性。因此，研究者提出了一个创新的方法来提高3D风格转移的灵活性和定制化程度。", "method": "通过引入高斯神经元明确地建模样式强度，并参数化可学习的样式调节器以实现可调样式注入；此外，还提出了一种可调式样指导策略，利用扩散模型从多视图中获取一致性的风格化视角，并采用两阶段优化策略稳定和高效地提供指引。", "result": "该方法在视觉吸引力方面表现出色，并且能够灵活调整3D风格迁移中的内容与样式平衡。", "conclusion": "Tune-Your-Style 方法成功解决了传统三维风格转移技术的局限性，提供了高度自定义化的解决方案。"}}
{"id": "2602.00616", "pdf": "https://arxiv.org/pdf/2602.00616", "abs": "https://arxiv.org/abs/2602.00616", "authors": ["Minhyuk Lee", "Hyekyung Yoon", "Myungjoo Kang"], "title": "Inference-Only Prompt Projection for Safe Text-to-Image Generation with TV Guarantees", "categories": ["cs.AI"], "comment": null, "summary": "Text-to-Image (T2I) diffusion models enable high-quality open-ended synthesis, but their real-world deployment demands safeguards that suppress unsafe generations without degrading benign prompt-image alignment. We formalize this tension through a total variation (TV) lens: once the reference conditional distribution is fixed, any nontrivial reduction in unsafe generations necessarily incurs TV deviation from the reference, yielding a principled Safety-Prompt Alignment Trade-off (SPAT). Guided by this view, we propose an inference-only prompt projection framework that selectively intervenes on high-risk prompts via a surrogate objective with verification, mapping them into a tolerance-controlled safe set while leaving benign prompts effectively unchanged, without retraining or fine-tuning the generator. Across four datasets and three diffusion backbones, our approach achieves 16.7-60.0% relative reductions in inappropriate percentage (IP) versus strong model-level alignment baselines, while preserving benign prompt-image alignment on COCO near the unaligned reference.", "AI": {"tldr": "本文提出了一种仅在推理阶段进行的提示投影框架，用于在不牺牲正常生成质量的前提下抑制文本到图像模型中的不当内容。", "motivation": "现实世界中部署文本到图像扩散模型需要确保生成的安全性，同时保持良好生成效果。通过引入总变差（TV）视角来定义安全性和提示对齐之间的权衡关系，本文旨在解决这一挑战。", "method": "提出了一种仅在推理阶段进行的提示投影方法，该方法通过一个替代目标函数并结合验证机制，将高风险提示映射到受控的安全集内，而不会影响正常提示的表现。此过程无需重新训练或微调生成器模型。", "result": "实验显示，在四个数据集和三种扩散模型架构上，所提出的方法相对于强大的基线模型可以减少16.7%-60%的不适当比例（IP），并且在保持COCO数据集上的正常提示图像对齐方面接近未修改的状态。", "conclusion": "该研究成功展示了一种高效、安全且不影响生成质量的文本到图像生成框架，为实际应用中的安全性问题提供了新的解决方案。"}}
{"id": "2602.00611", "pdf": "https://arxiv.org/pdf/2602.00611", "abs": "https://arxiv.org/abs/2602.00611", "authors": ["Jiaqi Xu", "Tao Huang", "Kai Zhang"], "title": "Structured Self-Consistency:A Multi-Task Evaluation of LLMs on VirtualHome", "categories": ["cs.AI"], "comment": null, "summary": "Embodied AI requires agents to understand goals, plan actions, and execute tasks in simulated environments.We present a comprehensive evaluation of Large Language Models (LLMs) on the VirtualHome benchmark using the Embodied Agent Interface (EAI) framework.We compare two representative 7B-parameter models OPENPANGU-7B and QWEN2.5-7B across four fundamental tasks: Goal Interpretation, Action Sequencing, Subgoal Decomposition, and Transition Modeling.We propose Structured Self-Consistency (SSC), an enhanced decoding strategy that leverages multiple sampling with domain-specific voting mechanisms to improve output quality for structured generation tasks. Experimental results demonstrate that SSC significantly enhances performance, with OPENPANGU-7B excelling at hierarchical planning while QWEN2.5-7B show advantages in action-level tasks. Our analysis reveals complementary strengths across model types, providing insights for future embodied AI system development.", "AI": {"tldr": "该论文介绍了在VirtualHome基准上使用Embodied Agent Interface框架对大型语言模型进行的全面评估，并提出了结构化自我一致性（SSC）策略以改善生成任务的质量。", "motivation": "为了理解目标，规划动作并在模拟环境中执行任务，本研究通过VirtualHome基准测试来评估LLMs在多任务环境中的性能，旨在提高基于文本生成的任务质量。", "method": "论文比较了两个具有代表性的7B参数模型OPENPANGU-7B和QWEN2.5-7B，并提出了结构化自我一致性（SSC）策略，通过多个采样和领域特定投票机制来改进结构性任务的输出质量。", "result": "实验结果显示，使用SSC后性能得到了显著提升。OPENPANGU-7B在层次规划方面表现突出，而QWEN2.5-7B则在动作级任务中具有优势。", "conclusion": "该研究揭示了不同模型类型之间的互补性，并为未来基于文本的生成任务提供了有价值的见解和改进策略。"}}
{"id": "2602.00608", "pdf": "https://arxiv.org/pdf/2602.00608", "abs": "https://arxiv.org/abs/2602.00608", "authors": ["Wei Zeng", "Xuchen Li", "Ruili Feng", "Zhen Liu", "Fengwei An", "Jian Zhao"], "title": "Scalable Generative Game Engine: Breaking the Resolution Wall via Hardware-Algorithm Co-Design", "categories": ["cs.AI", "cs.GR", "cs.LG"], "comment": "Preprint, Under Review", "summary": "Real-time generative game engines represent a paradigm shift in interactive simulation, promising to replace traditional graphics pipelines with neural world models. However, existing approaches are fundamentally constrained by the ``Memory Wall,'' restricting practical deployments to low resolutions (e.g., $64 \\times 64$). This paper bridges the gap between generative models and high-resolution neural simulations by introducing a scalable \\textit{Hardware-Algorithm Co-Design} framework. We identify that high-resolution generation suffers from a critical resource mismatch: the World Model is compute-bound while the Decoder is memory-bound. To address this, we propose a heterogeneous architecture that intelligently decouples these components across a cluster of AI accelerators. Our system features three core innovations: (1) an asymmetric resource allocation strategy that optimizes throughput under sequence parallelism constraints; (2) a memory-centric operator fusion scheme that minimizes off-chip bandwidth usage; and (3) a manifold-aware latent extrapolation mechanism that exploits temporal redundancy to mask latency. We validate our approach on a cluster of programmable AI accelerators, enabling real-time generation at $720 \\times 480$ resolution -- a $50\\times$ increase in pixel throughput over prior baselines. Evaluated on both continuous 3D racing and discrete 2D platformer benchmarks, our system delivers fluid 26.4 FPS and 48.3 FPS respectively, with an amortized effective latency of 2.7 ms. This work demonstrates that resolving the ``Memory Wall'' via architectural co-design is not merely an optimization, but a prerequisite for enabling high-fidelity, responsive neural gameplay.", "AI": {"tldr": "本文提出了一种可扩展的硬件算法协同设计框架，解决了高分辨率生成模型中的内存墙问题。", "motivation": "现有的实时生成游戏引擎受限于低分辨率（例如64×64），因为它们无法克服内存墙的问题。因此，需要一种新的方法来实现更高分辨率下的高效生成。", "method": "本文提出了一种异构架构，通过智能地在AI加速器集群中分离世界模型和解码器组件解决资源不匹配问题。该系统包含三个核心创新：不对称资源分配策略、内存导向的操作融合方案以及利用时间冗余来掩盖延迟的流形感知潜在外推机制。", "result": "本文的方法在720×480分辨率下实现了每秒生成50倍像素吞吐量的增长，在连续3D赛车和离散2D平台游戏中分别实现了26.4FPS和48.3FPS，有效延迟为2.7ms。", "conclusion": "通过架构协同设计解决内存墙问题是实现高保真度、响应式的神经游戏的关键。"}}
{"id": "2602.00607", "pdf": "https://arxiv.org/pdf/2602.00607", "abs": "https://arxiv.org/abs/2602.00607", "authors": ["Yang-Hao Zhou", "Haitian Li", "Rexar Lin", "Heyan Huang", "Jinxing Zhou", "Changsen Yuan", "Tian Lan", "Ziqin Zhou", "Yudong Li", "Jiajun Xu", "Jingyun Liao", "Yi-Ming Cheng", "Xuefeng Chen", "Xian-Ling Mao", "Yousheng Feng"], "title": "MTAVG-Bench: A Comprehensive Benchmark for Evaluating Multi-Talker Dialogue-Centric Audio-Video Generation", "categories": ["cs.MM", "cs.SD"], "comment": null, "summary": "Recent advances in text-to-audio-video (T2AV) generation have enabled models to synthesize audio-visual videos with multi-participant dialogues. However, existing evaluation benchmarks remain largely designed for human-recorded videos or single-speaker settings. As a result, potential errors that occur in generated multi-talker dialogue videos, such as identity drift, unnatural turn transitions, and audio-visual misalignment, cannot be effectively captured and analyzed. To address this issue, we introduce MTAVG-Bench, a benchmark for evaluating audio-visual multi-speaker dialogue generation. MTAVG-Bench is built via a semi-automatic pipeline, where 1.8k videos are generated using multiple popular models with carefully designed prompts, yielding 2.4k manually annotated QA pairs. The benchmark evaluates multi-speaker dialogue generation at four levels: audio-visual signal fidelity, temporal attribute consistency, social interaction, and cinematic expression. We benchmark 12 proprietary and open-source omni-models on MTAVG-Bench, with Gemini 3 Pro achieving the strongest overall performance, while leading open-source models remain competitive in signal fidelity and consistency. Overall, MTAVG-Bench enables fine-grained failure analysis for rigorous model comparison and targeted video generation refinement.", "AI": {"tldr": "本文提出了MTAVG-Bench，这是一个用于评估多说话人对话音频视频生成的基准测试。", "motivation": "现有的评价标准主要针对人类录制的视频或单个发言人的设置，无法有效捕捉和分析在生成多个参与者对话视频中出现的问题。", "method": "通过半自动管道创建2.4k手注QA对，评估模型在信号保真度、时间属性一致性、社交互动和社会表达四个层面上的表现。基准测试了12种专有和开源模型。", "result": "Gemini 3 Pro在所有方面表现最强，而领先的开源模型在信号保真度和一致性上仍然具有竞争力。", "conclusion": "MTAVG-Bench使细粒度失败分析成为可能，并促进严格的模型比较与视频生成改进。"}}
{"id": "2602.00604", "pdf": "https://arxiv.org/pdf/2602.00604", "abs": "https://arxiv.org/abs/2602.00604", "authors": ["Ayuto Tsutsumi", "Kohei Tanaka", "Sayaka Shiota"], "title": "The TMU System for the XACLE Challenge: Training Large Audio Language Models with CLAP Pseudo-Labels", "categories": ["cs.SD", "eess.AS"], "comment": "3 pages; 2 figures; 2 tables; Accepted at ICASSP 2026 Workshop (SP Grand Challenges, GC-12: XACLE)", "summary": "In this paper, we propose a submission to the x-to-audio alignment (XACLE) challenge. The goal is to predict semantic alignment of a given general audio and text pair. The proposed system is based on a large audio language model (LALM) architecture. We employ a three-stage training pipeline: automated audio captioning pretraining, pretraining with CLAP pseudo-labels, and fine-tuning on the XACLE dataset. Our experiments show that pretraining with CLAP pseudo-labels is the primary performance driver. On the XACLE test set, our system reaches an SRCC of 0.632, significantly outperforming the baseline system (0.334) and securing third place in the challenge team ranking. Code and models can be found at https://github.com/shiotalab-tmu/tmu-xacle2026", "AI": {"tldr": "本文提出了一种用于XACLE挑战的系统，该系统基于大型音频语言模型架构，并使用CLAP伪标签进行预训练。", "motivation": "为了提高给定音频和文本对之间的语义对齐预测性能，提出了一个三阶段的训练流程来提升大音频语言模型的能力。", "method": "方法包括三个步骤：自动语音标注预训练、采用CLAP伪标签的预训练以及在XACLE数据集上的微调。", "result": "实验结果表明，在使用CLAP伪标签进行预训练后，系统在SRCC指标上达到了0.632，并且显著优于基线模型（0.334），赢得了挑战赛中的第三名位置。", "conclusion": "通过引入CLAP伪标签的预训练方法，大大提升了大型音频语言模型对语义对齐任务的表现。"}}
{"id": "2602.00597", "pdf": "https://arxiv.org/pdf/2602.00597", "abs": "https://arxiv.org/abs/2602.00597", "authors": ["Chaoqun Cui", "Shijing Wang", "Liangbin Huang", "Qingqing Gu", "Zhaolong Huang", "Xiao Zeng", "Wenji Mao"], "title": "Hermes the Polyglot: A Unified Framework to Enhance Expressiveness for Multimodal Interlingual Subtitling", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to The Web Conference (WWW) 2026", "summary": "Interlingual subtitling, which translates subtitles of visual media into a target language, is essential for entertainment localization but has not yet been explored in machine translation. Although Large Language Models (LLMs) have significantly advanced the general capabilities of machine translation, the distinctive characteristics of subtitle texts pose persistent challenges in interlingual subtitling, particularly regarding semantic coherence, pronoun and terminology translation, and translation expressiveness. To address these issues, we present Hermes, an LLM-based automated subtitling framework. Hermes integrates three modules: Speaker Diarization, Terminology Identification, and Expressiveness Enhancement, which effectively tackle the above challenges. Experiments demonstrate that Hermes achieves state-of-the-art diarization performance and generates expressive, contextually coherent translations, thereby advancing research in interlingual subtitling.", "AI": {"tldr": "该论文提出了一个基于大型语言模型的自动字幕框架Hermes，以改善跨语言字幕翻译中的语义连贯性、代词和术语翻译以及表达力。", "motivation": "虽然大型语言模型在机器翻译方面取得了显著进步，但在跨语言字幕翻译中仍面临挑战，如语义连贯性、代词和术语的准确翻译及表达能力。该研究旨在通过Hermes框架解决这些问题。", "method": "Hermes框架由三个模块组成：说话人区分、术语识别和表达力增强，能够有效应对跨语言字幕翻译中的挑战。", "result": "实验显示，Hermes在说话人区分方面达到了最先进的性能，并生成了具有上下文连贯性和表现力的翻译。", "conclusion": "研究证明，通过集成三个模块，Hermes框架显著提高了跨语言字幕翻译的质量和表达能力。"}}
{"id": "2602.00594", "pdf": "https://arxiv.org/pdf/2602.00594", "abs": "https://arxiv.org/abs/2602.00594", "authors": ["Zhijie Huang", "Stephen McIntosh", "Daisuke Saito", "Nobuaki Minematsu"], "title": "Kanade: A Simple Disentangled Tokenizer for Spoken Language Modeling", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "A good language model starts with a good tokenizer. Tokenization is especially important for speech modeling, which must handle continuous signals that mix linguistic and non-linguistic information. A speech tokenizer should extract phonetics and prosody, suppress linguistically irrelevant information like speaker identity, and enable high-quality synthesis. We present Kanade, a single-layer disentangled speech tokenizer that realizes this ideal. Kanade separates out acoustic constants to create a single stream of tokens that captures rich phonetics and prosody. It does so without the need for auxiliary methods that existing disentangled codecs often rely on. Experiments show that Kanade achieves state-of-the-art speaker disentanglement and lexical availability, while maintaining excellent reconstruction quality.", "AI": {"tldr": "提出了Kanade，一种简单而有效的语音模型分词器。", "motivation": "优秀的语言模型需要良好的分词技术。对于语音建模来说，分词尤其重要，因为它必须处理包含语言和非语言信息的连续信号。", "method": "Kanade通过分离出声学常量来创建一个单一的令牌流，捕捉丰富的语音音素和韵律特征，并且无需依赖额外的方法即可实现。", "result": "实验结果表明，Kanade在说话人解耦和词汇可用性方面达到了最先进的水平，同时保持了优秀的重建质量。", "conclusion": "Kanade提供了一种简单而有效的分词方法来处理语音数据，这将促进高质量的语音合成和建模。"}}
{"id": "2602.00593", "pdf": "https://arxiv.org/pdf/2602.00593", "abs": "https://arxiv.org/abs/2602.00593", "authors": ["Yifan Jiang", "Cong Zhang", "Bofei Zhang", "Yifan Yang", "Bingzhang Wang", "Yew-Soon Ong"], "title": "From Pixels to Facts (Pix2Fact): Benchmarking Multi-Hop Reasoning for Fine-Grained Visual Fact Checking", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Despite progress on general tasks, VLMs struggle with challenges demanding both detailed visual grounding and deliberate knowledge-based reasoning, a synergy not captured by existing benchmarks that evaluate these skills separately. To close this gap, we introduce Pix2Fact, a new visual question-answering benchmark designed to evaluate expert-level perception and knowledge-intensive multi-hop reasoning. Pix2Fact contains 1,000 high-resolution (4K+) images spanning 8 daily-life scenarios and situations, with questions and answers meticulously crafted by annotators holding PhDs from top global universities working in partnership with a professional data annotation firm. Each question requires detailed visual grounding, multi-hop reasoning, and the integration of external knowledge to answer. Our evaluation of 9 state-of-the-art VLMs, including proprietary models like Gemini-3-Pro and GPT-5, reveals the substantial challenge posed by Pix2Fact: the most advanced model achieves only 24.0% average accuracy, in stark contrast to human performance of 56%. This significant gap underscores the limitations of current models in replicating human-level visual comprehension. We believe Pix2Fact will serve as a critical benchmark to drive the development of next-generation multimodal agents that combine fine-grained perception with robust, knowledge-based reasoning.", "AI": {"tldr": "本文介绍了Pix2Fact，一个用于评估视觉语言模型在细致视觉理解和多步推理能力的新基准。", "motivation": "现有的评估标准未能捕捉到同时具备详细视觉定位和知识密集型多步推理的挑战。为了填补这一空白，该研究旨在开发一个新的评估基准来测试这些技能的综合表现。", "method": "Pix2Fact包含1000个高分辨率图像以及精心设计的问题和答案，这些问题需要详细的视觉定位、多步推理和外部知识整合才能回答。", "result": "实验显示最先进的模型在Pix2Fact上的平均准确率仅为24.0%，与人类的表现56%相比存在显著差距。", "conclusion": "Pix2Fact将作为驱动下一代多模态代理发展的关键基准，这些代理能够结合细致的感知能力与基于知识的强大推理功能。"}}
{"id": "2602.00592", "pdf": "https://arxiv.org/pdf/2602.00592", "abs": "https://arxiv.org/abs/2602.00592", "authors": ["Jiaran Zhang", "Luck Ma", "Yanhao Li", "Fanqi Wan", "Di Qi", "Xu Zhao", "Jieyi Hou", "Zhe Xie", "Mengqiang Ren", "Xin Wu", "Zhewei Huang", "Liangyu Chen", "Yingwei Ma", "Qi Han", "Xiangyu Zhang"], "title": "DockSmith: Scaling Reliable Coding Environments via an Agentic Docker Builder", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Reliable Docker-based environment construction is a dominant bottleneck for scaling execution-grounded training and evaluation of software engineering agents. We introduce DockSmith, a specialized agentic Docker builder designed to address this challenge. DockSmith treats environment construction not only as a preprocessing step, but as a core agentic capability that exercises long-horizon tool use, dependency reasoning, and failure recovery, yielding supervision that transfers beyond Docker building itself. DockSmith is trained on large-scale, execution-grounded Docker-building trajectories produced by a SWE-Factory-style pipeline augmented with a loop-detection controller and a cross-task success memory. Training a 30B-A3B model on these trajectories achieves open-source state-of-the-art performance on Multi-Docker-Eval, with 39.72% Fail-to-Pass and 58.28% Commit Rate. Moreover, DockSmith improves out-of-distribution performance on SWE-bench Verified, SWE-bench Multilingual, and Terminal-Bench 2.0, demonstrating broader agentic benefits of environment construction.", "AI": {"tldr": "本文介绍了DockSmith，一种专门用于解决基于Docker的环境构建瓶颈问题的代理式Docker生成器。", "motivation": "可靠的Docker环境建设是扩展执行基础训练和评估软件工程智能体的主要瓶颈。为了应对这一挑战，提出了DockSmith以提高效率并确保可靠性。", "method": "DockSmith通过大型基于执行的数据集进行训练，并能够处理长时间跨度的工具使用、依赖关系推理以及故障恢复任务。该模型采用SWE-Factory风格管道和闭环检测控制器构建。", "result": "训练一个30B-A3B模型后，在Multi-Docker-Eval上达到开放源代码最优性能，Fail-to-Pass率为39.72%，提交率为58.28%。同时，DockSmith在SWE-bench Verified、SWE-bench Multilingual和Terminal-Bench 2.0上的表现也有所提升。", "conclusion": "通过解决环境构建问题，DockSmith不仅提高了Docker构建任务的性能，还展示了更广泛的智能体能力改进效果"}}
{"id": "2602.00590", "pdf": "https://arxiv.org/pdf/2602.00590", "abs": "https://arxiv.org/abs/2602.00590", "authors": ["Shun Muroga", "Hideaki Nakajima", "Taiyo Shimizu", "Kazufumi Kobashi", "Kenji Hata"], "title": "Multimodal Machine Learning for Integrating Heterogeneous Analytical Systems", "categories": ["cond-mat.mtrl-sci", "cond-mat.soft", "cs.AI", "cs.LG", "physics.data-an"], "comment": "12 pages, 4 figures, 2 tables", "summary": "Understanding structure-property relationships in complex materials requires integrating complementary measurements across multiple length scales. Here we propose an interpretable \"multimodal\" machine learning framework that unifies heterogeneous analytical systems for end-to-end characterization, demonstrated on carbon nanotube (CNT) films whose properties are highly sensitive to microstructural variations. Quantitative morphology descriptors are extracted from SEM images via binarization, skeletonization, and network analysis, capturing curvature, orientation, intersection density, and void geometry. These SEM-derived features are fused with Raman indicators of crystallinity/defect states, specific surface area from gas adsorption, and electrical surface resistivity. Multi-dimensional visualization using radar plots and UMAP reveals clear clustering of CNT films according to crystallinity and entanglements. Regression models trained on the multimodal feature set show that nonlinear approaches, particularly XGBoost, achieve the best predictive accuracy under leave-one-out cross-validation. Feature-importance analysis further provides physically meaningful interpretations: surface resistivity is primarily governed by junction-to-junction transport length scales, crystallinity/defect-related metrics, and network connectivity, whereas specific surface area is dominated by intersection density and void size. The proposed multimodal machine learning framework offers a general strategy for data-driven, explainable characterization of complex materials.", "AI": {"tldr": "提出了一种解释性多模态机器学习框架，用于集成异构分析系统并实现端到端的材料特性表征。", "motivation": "理解复杂材料的结构-性能关系需要在多个长度尺度上整合互补的测量方法。", "method": "通过二值化、骨架化和网络分析从SEM图像中提取定量形态描述符，并将这些描述符与拉曼指标、比表面积以及电表面电阻率融合，采用多维可视化和回归模型进行材料特性预测。", "result": "非线性XGBoost方法在交叉验证中显示出最佳预测精度；特征重要性分析揭示了物理意义明确的解释：表面电阻主要由结到结传输长度尺度、结晶度/缺陷相关指标和网络连接影响，而比表面积则受交点密度和空洞尺寸主导。", "conclusion": "提出的多模态机器学习框架为复杂材料的数据驱动且可解释性表征提供了一种通用策略。"}}
{"id": "2602.00586", "pdf": "https://arxiv.org/pdf/2602.00586", "abs": "https://arxiv.org/abs/2602.00586", "authors": ["Hasi Hays", "William J. Richardson"], "title": "RAG-GNN: Integrating Retrieved Knowledge with Graph Neural Networks for Precision Medicine", "categories": ["q-bio.MN", "cs.AI", "cs.LG"], "comment": null, "summary": "Network topology excels at structural predictions but fails to capture functional semantics encoded in biomedical literature. We present a retrieval-augmented generation (RAG) embedding framework that integrates graph neural network representations with dynamically retrieved literature-derived knowledge through contrastive learning. Benchmarking against ten embedding methods reveals task-specific complementarity: topology-focused methods achieve near-perfect link prediction (GCN: 0.983 AUROC), while RAG-GNN is the only method achieving positive silhouette scores for functional clustering (0.001 vs. negative scores for all baselines). Information-theoretic decomposition shows network topology contributes 77.3% of predictive information, while retrieved documents provide 8.6% unique information. Applied to cancer signaling networks (379 proteins, 3,498 interactions), the framework identifies DDR1 as a therapeutic target based on retrieved evidence of synthetic lethality with KRAS mutations. These results establish that topology-only and retrieval-augmented approaches serve complementary purposes: structural prediction tasks are solved by network topology alone, while functional interpretation uniquely benefits from retrieved knowledge.", "AI": {"tldr": "本论文提出了一种整合图神经网络与动态检索的文献知识嵌入框架，用于精准医学。", "motivation": "传统网络拓扑结构在预测中表现良好，但无法捕捉生物医学文献中的功能语义。因此，提出了一个结合生成式检索（RAG）和图神经网络的方法来解决这一问题。", "method": "通过对比学习将图神经网络表示与动态获取的文献知识集成，并且该框架应用于癌症信号通路研究中以确定治疗靶点DDR1。", "result": "实验结果表明，对于链接预测任务，基于拓扑结构的方法表现优异（GCN：AUROC为0.983），而对于功能聚类任务，RAG-GNN是唯一一个获得正的轮廓分数的方法（0.001）。此外，信息论分解显示网络拓扑贡献了77.3%的预测信息，而检索到的文献提供了8.6%的独特信息。", "conclusion": "该研究证明了仅依赖于拓扑结构和增强检索方法可以解决不同的任务：结构预测主要由网络拓扑解决，功能解释则从检索知识中获益。"}}
{"id": "2602.00585", "pdf": "https://arxiv.org/pdf/2602.00585", "abs": "https://arxiv.org/abs/2602.00585", "authors": ["Guochen Yan", "Jialong Wu", "Zhengwei Tao", "Bo Li", "Qintong Zhang", "Jiahao Xu", "Haitao Mi", "Yuejian Fang", "Qingni Shen", "Wentao Zhang", "Zhonghai Wu"], "title": "Exploring Information Seeking Agent Consolidation", "categories": ["cs.AI"], "comment": null, "summary": "Information-seeking agents have emerged as a powerful paradigm for solving knowledge-intensive tasks. Existing information-seeking agents are typically specialized for open web, documents, or local knowledge bases, which constrains scalability and cross-domain generalization. In this work, we investigate how to consolidate heterogeneous information-seeking agents into a single foundation agentic model. We study two complementary consolidation strategies: data-level consolidation, which jointly trains a unified model on a mixture of domain-specific datasets, and parameter-level consolidation, which merges independently trained agent models at the parameter level. Our analysis compares these approaches in terms of performance retention, cross-domain generalization, and interference across information-seeking behaviors. Our results show that data-level consolidation remains a strong and stable baseline, while parameter-level consolidation offers a promising, efficient alternative but suffers from interference and robustness challenges. We further identify key design factors for effective agent consolidation at the parameter level, including fine-grained merging granularity, awareness of task heterogeneity, and principled consensus strategy.", "AI": {"tldr": "研究如何将异构的信息寻求代理整合为单一的基础代理模型。", "motivation": "现有的信息寻求代理通常针对开放网络、文档或本地知识库进行了专业化，这限制了其可扩展性和跨域泛化能力。本文旨在探讨如何通过数据级和参数级的合并策略来克服这些限制。", "method": "研究采用两种合并策略：数据级整合（联合训练一个统一模型）和参数级整合（在参数级别合并独立训练的代理模型）。对比这两种方法在性能保留、跨域泛化以及信息寻求行为干扰方面的表现。", "result": "结果显示，数据级整合是强大的稳定基线；而参数级整合是一种有前景且高效的替代方案，但存在干扰和鲁棒性挑战。关键设计因素包括细粒度合并粒度、任务异质性的意识及基本原则共识策略。", "conclusion": "本文探索了信息寻求代理的整合方法，并提供了有效的设计指南。"}}
{"id": "2602.00583", "pdf": "https://arxiv.org/pdf/2602.00583", "abs": "https://arxiv.org/abs/2602.00583", "authors": ["Xiangdong Li", "Ye Lou", "Ao Gao", "Wei Zhang", "Siyang Song"], "title": "MAUGen: A Unified Diffusion Approach for Multi-Identity Facial Expression and AU Label Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The lack of large-scale, demographically diverse face images with precise Action Unit (AU) occurrence and intensity annotations has long been recognized as a fundamental bottleneck in developing generalizable AU recognition systems. In this paper, we propose MAUGen, a diffusion-based multi-modal framework that jointly generates a large collection of photorealistic facial expressions and anatomically consistent AU labels, including both occurrence and intensity, conditioned on a single descriptive text prompt. Our MAUGen involves two key modules: (1) a Multi-modal Representation Learning (MRL) module that captures the relationships among the paired textual description, facial identity, expression image, and AU activations within a unified latent space; and (2) a Diffusion-based Image label Generator (DIG) that decodes the joint representation into aligned facial image-label pairs across diverse identities. Under this framework, we introduce Multi-Identity Facial Action (MIFA), a large-scale multimodal synthetic dataset featuring comprehensive AU annotations and identity variations. Extensive experiments demonstrate that MAUGen outperforms existing methods in synthesizing photorealistic, demographically diverse facial images along with semantically aligned AU labels.", "AI": {"tldr": "提出了一种基于扩散的多模态框架MAUGen，用于生成高质量、多样化的面部表情和AU标签。", "motivation": "为了解决大规模、人口多样性丰富的带有精确动作单元（AU）发生和强度注释的脸部图像缺乏的问题，该研究开发了一种新的方法来合成这些数据。", "method": "MAUGen包括两个关键模块：多模态表示学习（MRL）模块用于捕获文本描述、面部身份、表情图像及AU激活之间的关系；扩散型图象标签生成器（DIG）将联合表示解码为具有多样身份的对齐面部图像和标签。", "result": "实验表明，MAUGen在合成逼真的、人口多样化丰富的脸部图像以及语义对齐的AU标签方面优于现有方法。", "conclusion": "通过引入MIFA数据集和提出MAUGen框架，该研究为大规模、多样性丰富的人脸图像生成及动作单元标注提供了一种有效的方法。"}}
{"id": "2602.00580", "pdf": "https://arxiv.org/pdf/2602.00580", "abs": "https://arxiv.org/abs/2602.00580", "authors": ["Wei Huang", "Hanchen Wang", "Dong Wen", "Wenjie Zhang"], "title": "Small Shifts, Large Gains: Unlocking Traditional TSP Heuristic Guided-Sampling via Unsupervised Neural Instance Modification", "categories": ["cs.AI"], "comment": null, "summary": "The Traveling Salesman Problem (TSP) is one of the most representative NP-hard problems in route planning and a long-standing benchmark in combinatorial optimization. Traditional heuristic tour constructors, such as Farthest or Nearest Insertion, are computationally efficient and highly practical, but their deterministic behavior limits exploration and often leads to local optima. In contrast, neural-based heuristic tour constructors alleviate this issue through guided-sampling and typically achieve superior solution quality, but at the cost of extensive training and reliance on ground-truth supervision, hindering their practical use. To bridge this gap, we propose TSP-MDF, a novel instance modification framework that equips traditional deterministic heuristic tour constructors with guided-sampling capability. Specifically, TSP-MDF introduces a neural-based instance modifier that strategically shifts node coordinates to sample multiple modified instances, on which the base traditional heuristic tour constructor constructs tours that are mapped back to the original instance, allowing traditional tour constructors to explore higher-quality tours and escape local optima. At the same time, benefiting from our instance modification formulation, the neural-based instance modifier can be trained efficiently without any ground-truth supervision, ensuring the framework maintains practicality. Extensive experiments on large-scale TSP benchmarks and real-world benchmarks demonstrate that TSP-MDF significantly improves the performance of traditional heuristics tour constructors, achieving solution quality comparable to neural-based heuristic tour constructors, but with an extremely short training time.", "AI": {"tldr": "通过引入神经网络实例修改框架TSP-MDF，使得传统启发式路径构造器能够利用指导采样技术来避免局部最优解，从而提高性能。", "motivation": "传统的启发式方法如最远插入和最近插入法在处理NP-hard问题时效率高但容易陷入局部最优。而神经网络基于的启发式方法虽然可以缓解这一问题并提供更优解决方案，但需要大量训练时间和依赖监督数据，难以应用于实际场景。", "method": "提出一种新的实例修改框架TSP-MDF，结合了传统确定性启发式构造器和神经网络的采样技术。利用神经网络将节点坐标进行小幅度调整以生成多个修改后的实例，并通过这些实例构建路径后再映射回原实例中，从而帮助传统方法跳出局部最优解。", "result": "实验结果表明，在大规模TSP基准数据集及实际应用场景上，该框架能够显著提升传统启发式构造器的表现，甚至可以与神经网络基于的启发式构造器相媲美，并且训练时间极短。", "conclusion": "通过引入实例修改策略并结合传统的确定性启发式路径构造器，TSP-MDF能够在不牺牲效率的前提下达到高质量解的效果，为解决实际中的NP-hard问题提供了一种新的有效方法。"}}
{"id": "2602.00579", "pdf": "https://arxiv.org/pdf/2602.00579", "abs": "https://arxiv.org/abs/2602.00579", "authors": ["JiaKui Hu", "Zhengjian Yao", "Lujia Jin", "Yanye Lu"], "title": "Bridging Degradation Discrimination and Generation for Universal Image Restoration", "categories": ["cs.CV"], "comment": "Accepted by ICLR 2026", "summary": "Universal image restoration is a critical task in low-level vision, requiring the model to remove various degradations from low-quality images to produce clean images with rich detail. The challenges lie in sampling the distribution of high-quality images and adjusting the outputs on the basis of the degradation. This paper presents a novel approach, Bridging Degradation discrimination and Generation (BDG), which aims to address these challenges concurrently. First, we propose the Multi-Angle and multi-Scale Gray Level Co-occurrence Matrix (MAS-GLCM) and demonstrate its effectiveness in performing fine-grained discrimination of degradation types and levels. Subsequently, we divide the diffusion training process into three distinct stages: generation, bridging, and restoration. The objective is to preserve the diffusion model's capability of restoring rich textures while simultaneously integrating the discriminative information from the MAS-GLCM into the restoration process. This enhances its proficiency in addressing multi-task and multi-degraded scenarios. Without changing the architecture, BDG achieves significant performance gains in all-in-one restoration and real-world super-resolution tasks, primarily evidenced by substantial improvements in fidelity without compromising perceptual quality. The code and pretrained models are provided in https://github.com/MILab-PKU/BDG.", "AI": {"tldr": "提出了一种新的方法BDG，用于解决图像复原中的多重降质问题。", "motivation": "传统模型在处理多种类型和程度的降质时效果不佳，需要改进以提高恢复质量和细节保留能力。", "method": "提出了MAS-GLCM进行精细区分降质量级，并将扩散训练分为生成、桥接和修复三个阶段，整合了鉴别信息于复原过程中。", "result": "BDG在全合一图像修复和真实场景超分辨率任务中表现出显著性能提升，提高了恢复的保真度同时不牺牲感知质量。", "conclusion": "BDG方法有效解决了多重降质问题，提供了更好的图像修复效果。"}}
{"id": "2602.00576", "pdf": "https://arxiv.org/pdf/2602.00576", "abs": "https://arxiv.org/abs/2602.00576", "authors": ["Tushaar Gangavarapu", "Jiping Li", "Christopher Vattheuer", "Zhangyang Wang", "Baharan Mirzasoleiman"], "title": "Data Distribution as a Lever for Guiding Optimizers Toward Superior Generalization in LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Can modifying the training data distribution guide optimizers toward solutions with improved generalization when training large language models (LLMs)? In this work, we theoretically analyze an in-context linear regression model with multi-head linear self-attention, and compare the training dynamics of two gradient based optimizers, namely gradient descent (GD) and sharpness-aware minimization (SAM), the latter exhibiting superior generalization properties but is prohibitively expensive for training even medium-sized LLMs. We show, for the first time, that SAM induces a lower simplicity bias (SB)-the tendency of an optimizer to preferentially learn simpler features earlier in training-and identify this reduction as a key factor underlying its improved generalization performance. Motivated by this insight, we demonstrate that altering the training data distribution by upsampling or augmenting examples learned later in training similarly reduces SB and leads to improved generalization. Our extensive experiments show that our strategy improves the performance of multiple LLMs-including Phi2-2.7B , Llama3.2-1B, Gemma3-1B-PT, and Qwen3-0.6B-Base-achieving relative accuracy gains up to 18% when fine-tuned with AdamW and Muon on mathematical reasoning tasks.", "AI": {"tldr": "通过改变训练数据分布来减少简单性偏倚，从而提高大型语言模型的泛化性能。", "motivation": "研究如何通过修改训练数据分布引导优化器找到更好的泛化解决方案，并探讨了sharpness-aware minimization（SAM）方法背后的理论机制。", "method": "分析了带有多头线性自注意力的上下文线性回归模型，比较了梯度下降和sharpness-aware minimization两种优化器在不同训练数据分布下的性能表现。通过增加后期学习样本的比例来减少简单性偏倚。", "result": "实验证明了该策略能够改善多个大型语言模型（包括Phi2-2.7B, Llama3.2-1B等）的性能，在数学推理任务上使用AdamW和Muon进行微调时，相对准确度提高了高达18%。", "conclusion": "改变训练数据分布可以减少简单性偏倚并提高优化器的泛化能力，从而提升大型语言模型的整体表现。"}}
{"id": "2602.00575", "pdf": "https://arxiv.org/pdf/2602.00575", "abs": "https://arxiv.org/abs/2602.00575", "authors": ["Chaoqun Cui", "Jing Huang", "Shijing Wang", "Liming Zheng", "Qingchao Kong", "Zhixiong Zeng"], "title": "Agentic Reward Modeling: Verifying GUI Agent via Online Proactive Interaction", "categories": ["cs.RO"], "comment": "21 pages, 11 figures", "summary": "Reinforcement learning with verifiable rewards (RLVR) is pivotal for the continuous evolution of GUI agents, yet existing evaluation paradigms face significant limitations. Rule-based methods suffer from poor scalability and cannot handle open-ended tasks, while LLM-as-a-Judge approaches rely on passive visual observation, often failing to capture latent system states due to partial state observability. To address these challenges, we advocate for a paradigm shift from passive evaluation to Agentic Interactive Verification. We introduce VAGEN, a framework that employs a verifier agent equipped with interaction tools to autonomously plan verification strategies and proactively probe the environment for evidence of task completion. Leveraging the insight that GUI tasks are typically \"easy to verify but hard to solve\", VAGEN overcomes the bottlenecks of visual limitations. Experimental results on OSWorld-Verified and AndroidWorld benchmarks demonstrate that VAGEN significantly improves evaluation accuracy compared to LLM-as-a-Judge baselines and further enhances performance through test-time scaling strategies.", "AI": {"tldr": "该论文提出了一种新的框架VAGEN，用于验证GUI代理的性能，通过自主规划验证策略和主动探测环境来克服现有评估方法中的局限性。", "motivation": "现有的基于规则的方法和依赖视觉观察的方法在处理开放任务时存在规模性和部分状态可见性的限制，因此论文提出了一种新的交互式验证范式以解决这些问题。", "method": "VAGEN框架采用一个具备交互工具的验证代理，自动规划策略并主动探测环境来获取证据证明任务完成情况。该方法利用了GUI任务“容易验证但难以执行”的特点克服现有视觉限制。", "result": "实验结果表明，相比于LLM作为裁判的方法，VAGEN在OSWorld-Verified和AndroidWorld基准测试中显著提高了评估准确性，并通过测试时的扩展策略进一步提升了性能。", "conclusion": "论文展示了如何从被动验证转向主动交互式验证来提高GUI代理的评估准确性和效率。"}}
{"id": "2602.00574", "pdf": "https://arxiv.org/pdf/2602.00574", "abs": "https://arxiv.org/abs/2602.00574", "authors": ["Yifei Shao", "Kun Zhou", "Ziming Xu", "Mohammad Atif Quamar", "Shibo Hao", "Zhen Wang", "Zhiting Hu", "Biwei Huang"], "title": "Learning Modal-Mixed Chain-of-Thought Reasoning with Latent Embeddings", "categories": ["cs.AI"], "comment": null, "summary": "We study how to extend chain-of-thought (CoT) beyond language to better handle multimodal reasoning. While CoT helps LLMs and VLMs articulate intermediate steps, its text-only form often fails on vision-intensive problems where key intermediate states are inherently visual. We introduce modal-mixed CoT, which interleaves textual tokens with compact visual sketches represented as latent embeddings. To bridge the modality gap without eroding the original knowledge and capability of the VLM, we use the VLM itself as an encoder and train the language backbone to reconstruct its own intermediate vision embeddings, to guarantee the semantic alignment of the visual latent space. We further attach a diffusion-based latent decoder, invoked by a special control token and conditioned on hidden states from the VLM. In this way, the diffusion head carries fine-grained perceptual details while the VLM specifies high-level intent, which cleanly disentangles roles and reduces the optimization pressure of the VLM. Training proceeds in two stages: supervised fine-tuning on traces that interleave text and latents with a joint next-token and latent-reconstruction objective, followed by reinforcement learning that teaches when to switch modalities and how to compose long reasoning chains. Extensive experiments across 11 diverse multimodal reasoning tasks, demonstrate that our method yields better performance than language-only and other CoT methods. Our code will be publicly released.", "AI": {"tldr": "研究如何将链式思维推理扩展到多模态领域，通过引入模式混合的链式思维方法和潜变量解码器来提高视觉密集问题上的表现。", "motivation": "当前的语言模型在处理视觉密集任务时受限于仅依赖文本的形式，难以有效表达关键中间状态。为了更好地解决这类问题，本文提出结合语言与视觉信息的方法以增强推理能力。", "method": "通过将文本和潜变量嵌入交替的方式引入模式混合的链式思维，并使用扩散型解码器来生成详细感知细节。训练分为两个阶段：监督微调及强化学习。", "result": "实验结果表明，该方法在多种多模态推理任务中优于纯语言模型和其他链式思维方法。", "conclusion": "提出的方法有效提升了视觉密集问题上的性能，并展示了潜变量嵌入和模式混合链式思维的有效性。"}}
{"id": "2602.00573", "pdf": "https://arxiv.org/pdf/2602.00573", "abs": "https://arxiv.org/abs/2602.00573", "authors": ["Zheng Zhang", "Tao Hu", "Xueheng Li", "Yang Wang", "Rui Li", "Jie Zhang", "Chengjun Xie"], "title": "When Classes Evolve: A Benchmark and Framework for Stage-Aware Class-Incremental Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Class-Incremental Learning (CIL) aims to sequentially learn new classes while mitigating catastrophic forgetting of previously learned knowledge. Conventional CIL approaches implicitly assume that classes are morphologically static, focusing primarily on preserving previously learned representations as new classes are introduced. However, this assumption neglects intra-class evolution: a phenomenon wherein instances of the same semantic class undergo significant morphological transformations, such as a larva turning into a butterfly. Consequently, a model must both discriminate between classes and adapt to evolving appearances within a single class. To systematically address this challenge, we formalize Stage-Aware CIL (Stage-CIL), a paradigm in which each class is learned progressively through distinct morphological stages. To facilitate rigorous evaluation within this paradigm, we introduce the Stage-Bench, a 10-domain, 2-stages dataset and protocol that jointly measure inter- and intra-class forgetting. We further propose STAGE, a novel method that explicitly learns abstract and transferable evolution patterns within a fixed-size memory pool. By decoupling semantic identity from transformation dynamics, STAGE enables accurate prediction of future morphologies based on earlier representations. Extensive empirical evaluation demonstrates that STAGE consistently and substantially outperforms existing state-of-the-art approaches, highlighting its effectiveness in simultaneously addressing inter-class discrimination and intra-class morphological adaptation.", "AI": {"tldr": "该论文提出了一种新的Stage-Aware CIL（阶段感知类增量学习）方法和基准测试，以应对传统CIL中的类别演化问题。", "motivation": "传统的CIL方法忽视了同一语义类别内部的形态变化，导致模型难以在保持原有知识的同时适应新类别。", "method": "作者提出了STAGE框架，通过固定大小的记忆池学习抽象和可转移的发展模式，并区分语义身份和发展动态，实现对未来形态的准确预测。", "result": "实验表明，STAGE方法能够在类间区别和内部形态适应上显著优于现有最佳方案。", "conclusion": "该研究为解决类别演化问题提供了一个有效的解决方案，并且证明了Stage-CIL框架的有效性。"}}
{"id": "2602.00571", "pdf": "https://arxiv.org/pdf/2602.00571", "abs": "https://arxiv.org/abs/2602.00571", "authors": ["Suifang Zhou", "Ray LC"], "title": "Eternagram: Inspiring Climate Action Through LLM-based Conversational Exploration of a Post-Devastation Climate Future", "categories": ["cs.HC"], "comment": "7 pages, 5 figures, CUI 2025", "summary": "Climate action is difficult to persuade because we tend to perceive climate change as remote and disconnected from daily life. Instead of traditional informational engagements, game-based interventions can create narratives that immerse the visitor in situations where their actions have tangible consequences. To make these narratives engaging, we used a speculative scenario of an alien stumbling upon social media to obliquely address climate change through a text-based adventure game installation. Mimicking visitors' natural dialogue in social media apps, we designed an LLM-based chatbot with knowledge of post-climate devastated world that mirrors our own planet Earth. In discovering the world's downfall through interactive chatting and posted images, players begin to realize that their own actions can make a difference on impacts of climate change in this distant world, fostering pro-environmental attitudes. Previously published at CHI, this game installation demonstrates the potential of LLM based creative narratives in exploring speculative worlds driving social change.", "AI": {"tldr": "本文通过设计一个基于LLM的聊天机器人来模拟未来气候灾难后的世界，以启发玩家采取环保行动。", "motivation": "气候变化难以引起人们的重视，因为它被视为遥远且与日常生活无关。传统的信息传递方式效果不佳，因此尝试使用游戏化介入来创造具有实际后果的情境，从而激发参与者的积极态度。", "method": "设计了一款基于LLM的聊天机器人，在模拟未来的灾难世界中通过对话和图像展示气候变化的影响，使玩家意识到自己的行为对环境有着深远影响。", "result": "该作品在CHI上发表，并展示了基于LLM创造性叙事在探索假设世界并推动社会变革方面的潜力。", "conclusion": "利用游戏化方式可以有效提高人们对气候问题的关注度和参与度。"}}
{"id": "2602.00570", "pdf": "https://arxiv.org/pdf/2602.00570", "abs": "https://arxiv.org/abs/2602.00570", "authors": ["Xingyu Luo", "Yidong Cai", "Jie Liu", "Jie Tang", "Gangshan Wu", "Limin Wang"], "title": "GLAD: Generative Language-Assisted Visual Tracking for Low-Semantic Templates", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language tracking has gained increasing attention in many scenarios. This task simultaneously deals with visual and linguistic information to localize objects in videos. Despite its growing utility, the development of vision-language tracking methods remains in its early stage. Current vision-language trackers usually employ Transformer architectures for interactive integration of template, search, and text features. However, persistent challenges about low-semantic images including prevalent image blurriness, low resolution and so on, may compromise model performance through degraded cross-modal understanding. To solve this problem, language assistance is usually used to deal with the obstacles posed by low-semantic images. However, due to the existing gap between current textual and visual features, direct concatenation and fusion of these features may have limited effectiveness. To address these challenges, we introduce a pioneering Generative Language-AssisteD tracking model, GLAD, which utilizes diffusion models for the generative multi-modal fusion of text description and template image to bolster compatibility between language and image and enhance template image semantic information. Our approach demonstrates notable improvements over the existing fusion paradigms. Blurry and semantically ambiguous template images can be restored to improve multi-modal features in the generative fusion paradigm. Experiments show that our method establishes a new state-of-the-art on multiple benchmarks and achieves an impressive inference speed. The code and models will be released at: https://github.com/Confetti-lxy/GLAD", "AI": {"tldr": "GLAD模型利用生成式语言辅助视觉跟踪，解决低语义模板图像带来的挑战。", "motivation": "现有的视觉-语言追踪方法在处理低语义图像（如模糊和分辨率低）时面临性能下降的问题。通过直接融合文本和视觉特征的方法效果有限。", "method": "GLAD模型使用扩散模型进行生成式跨模态融合，增强语言与图像的兼容性，并提高模板图像的语义信息。", "result": "实验表明，该方法在多个基准测试上建立了新的性能标准，并实现了令人印象深刻的推理速度。", "conclusion": "GLAD通过生成多模态融合显著提升了现有追踪方法的效果。"}}
{"id": "2602.00568", "pdf": "https://arxiv.org/pdf/2602.00568", "abs": "https://arxiv.org/abs/2602.00568", "authors": ["Ke Xue", "Rongfei Fan", "Kai Li", "Shanping Yu", "Puning Zhao", "Jianping An"], "title": "Dual-View Predictive Diffusion: Lightweight Speech Enhancement via Spectrogram-Image Synergy", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Diffusion models have recently set new benchmarks in Speech Enhancement (SE). However, most existing score-based models treat speech spectrograms merely as generic 2D images, applying uniform processing that ignores the intrinsic structural sparsity of audio, which results in inefficient spectral representation and prohibitive computational complexity. To bridge this gap, we propose DVPD, an extremely lightweight Dual-View Predictive Diffusion model, which uniquely exploits the dual nature of spectrograms as both visual textures and physical frequency-domain representations across both training and inference stages. Specifically, during training, we optimize spectral utilization via the Frequency-Adaptive Non-uniform Compression (FANC) encoder, which preserves critical low-frequency harmonics while pruning high-frequency redundancies. Simultaneously, we introduce a Lightweight Image-based Spectro-Awareness (LISA) module to capture features from a visual perspective with minimal overhead. During inference, we propose a Training-free Lossless Boost (TLB) strategy that leverages the same dual-view priors to refine generation quality without any additional fine-tuning. Extensive experiments across various benchmarks demonstrate that DVPD achieves state-of-the-art performance while requiring only 35% of the parameters and 40% of the inference MACs compared to SOTA lightweight model, PGUSE. These results highlight DVPD's superior ability to balance high-fidelity speech quality with extreme architectural efficiency. Code and audio samples are available at the anonymous website: {https://anonymous.4open.science/r/dvpd_demo-E630}", "AI": {"tldr": "提出了一种轻量级的双视图预测扩散模型DVPD，用于语音增强。", "motivation": "现有的基于分数的模型将频谱图视为普通的二维图像进行统一处理，忽略了音频固有的结构稀疏性，导致效率低下和计算复杂度高。为了改进这一问题，提出了新的方法来更好地利用频谱特性。", "method": "DVPD通过FANC编码器在训练阶段优化了频率适应性的非均匀压缩以保留关键的低频谐波并修剪高频冗余；同时引入LISA模块从视觉角度捕捉特征，减少开销。推理时提出无损增强策略TLB，无需额外微调即可提升生成质量。", "result": "实验表明DVPD在多个基准上达到了最先进的性能，并且参数和推断MACs仅为SOTA轻量级模型PGUSE的35%和40%，展示了其在高质量语音与极高效架构之间的平衡能力。", "conclusion": "DVPD通过独特的双视图处理方法，在保持高保真语音质量的同时，实现了更高效的计算效率。"}}
{"id": "2602.00566", "pdf": "https://arxiv.org/pdf/2602.00566", "abs": "https://arxiv.org/abs/2602.00566", "authors": ["Nan Song", "Junzhe Jiang", "Jingyu Li", "Xiatian Zhu", "Li Zhang"], "title": "UniMotion: A Unified Motion Framework for Simulation, Prediction and Planning", "categories": ["cs.RO"], "comment": "Accepted at NeurIPS 2025", "summary": "Motion simulation, prediction and planning are foundational tasks in autonomous driving, each essential for modeling and reasoning about dynamic traffic scenarios. While often addressed in isolation due to their differing objectives, such as generating diverse motion states or estimating optimal trajectories, these tasks inherently depend on shared capabilities: understanding multi-agent interactions, modeling motion behaviors, and reasoning over temporal and spatial dynamics. Despite this underlying commonality, existing approaches typically adopt specialized model designs, which hinders cross-task generalization and system scalability. More critically, this separation overlooks the potential mutual benefits among tasks. Motivated by these observations, we propose UniMotion, a unified motion framework that captures shared structures across motion tasks while accommodating their individual requirements. Built on a decoder-only Transformer architecture, UniMotion employs dedicated interaction modes and tailored training strategies to simultaneously support these motion tasks. This unified design not only enables joint optimization and representation sharing but also allows for targeted fine-tuning to specialize in individual tasks when needed. Extensive experiments on the Waymo Open Motion Dataset demonstrate that joint training leads to robust generalization and effective task integration. With further fine-tuning, UniMotion achieves state-of-the-art performance across a range of motion tasks, establishing it as a versatile and scalable solution for autonomous driving.", "AI": {"tldr": "提出了一种名为UniMotion的统一运动框架，用于自主驾驶中的模拟、预测和规划任务。", "motivation": "现有方法通常针对特定的任务进行专门设计，这限制了它们在不同任务间的泛化能力和系统的可扩展性。作者认为这些任务之间存在共享结构，并且相互间可以带来潜在的好处。", "method": "UniMotion基于解码器仅Transformer架构构建，使用专用交互模式和定制的训练策略来同时支持模拟、预测和规划等运动任务。", "result": "在Waymo开放运动数据集上进行大量实验表明，联合培训能实现稳健的泛化和有效的任务集成。进一步微调后，在各种运动任务中取得了最先进的性能表现。", "conclusion": "UniMotion作为统一且可扩展的解决方案，展示了其在自主驾驶中的多功能性与优越性能"}}
{"id": "2602.00564", "pdf": "https://arxiv.org/pdf/2602.00564", "abs": "https://arxiv.org/abs/2602.00564", "authors": ["Xiang Zheng", "Weiqi Zhai", "Wei Wang", "Boyu Yang", "Wenbo Li", "Ruixiang Luo", "Haoxiang Sun", "Yucheng Wang", "Zhengze Li", "Meng Wang", "Yuetian Du", "Guojie Lin", "Yaxuan Wang", "Xiaoxiao Xu", "Yanhu Mo", "Xuan Ren", "Hu Wei", "Ze Xu"], "title": "Unmasking Reasoning Processes: A Process-aware Benchmark for Evaluating Structural Mathematical Reasoning in LLMs", "categories": ["cs.AI", "cs.CL"], "comment": "8 pages, and 3 figures", "summary": "Recent large language models (LLMs) achieve near-saturation accuracy on many established mathematical reasoning benchmarks, raising concerns about their ability to diagnose genuine reasoning competence. This saturation largely stems from the dominance of template-based computation and shallow arithmetic decomposition in existing datasets, which underrepresent reasoning skills such as multi-constraint coordination, constructive logical synthesis, and spatial inference. To address this gap, we introduce ReasoningMath-Plus, a benchmark of 150 carefully curated problems explicitly designed to evaluate structural reasoning. Each problem emphasizes reasoning under interacting constraints, constructive solution formation, or non-trivial structural insight, and is annotated with a minimal reasoning skeleton to support fine-grained process-level evaluation. Alongside the dataset, we introduce HCRS (Hazard-aware Chain-based Rule Score), a deterministic step-level scoring function, and train a Process Reward Model (PRM) on the annotated reasoning traces. Empirically, while leading models attain relatively high final-answer accuracy (up to 5.8/10), HCRS-based holistic evaluation yields substantially lower scores (average 4.36/10, best 5.14/10), showing that answer-only metrics can overestimate reasoning robustness.", "AI": {"tldr": "本文介绍了ReasoningMath-Plus基准，旨在评估大型语言模型在结构化数学推理方面的表现。", "motivation": "现有数据集主要依赖模板式计算和浅层算术分解，在多约束协调、逻辑合成及空间推断等深层次技能方面存在不足。因此需要一个新的基准来更全面地评估这些能力。", "method": "ReasoningMath-Plus包含150个精心设计的问题，每个问题都有详细的推理过程注释，并引入了HCRS和Process Reward Model进行细粒度评价。", "result": "尽管顶级模型在最终答案准确率上表现良好（最高达5.8/10），但在基于HCRS的整体评估中得分较低（平均4.36/10，最佳为5.14/10）。", "conclusion": "现有基准可能高估了语言模型的推理能力。引入新的评价方法有助于更准确地诊断其真实水平。"}}
{"id": "2602.00561", "pdf": "https://arxiv.org/pdf/2602.00561", "abs": "https://arxiv.org/abs/2602.00561", "authors": ["Tianhao Huang", "Guanghui Min", "Zhenyu Lei", "Aiying Zhang", "Chen Chen"], "title": "Uncovering Latent Communication Patterns in Brain Networks via Adaptive Flow Routing", "categories": ["cs.AI"], "comment": null, "summary": "Unraveling how macroscopic cognitive phenotypes emerge from microscopic neuronal connectivity remains one of the core pursuits of neuroscience. To this end, researchers typically leverage multi-modal information from structural connectivity (SC) and functional connectivity (FC) to complete downstream tasks. Recent methodologies explore the intricate coupling mechanisms between SC and FC, attempting to fuse their representations at the regional level. However, lacking fundamental neuroscientific insight, these approaches fail to uncover the latent interactions between neural regions underlying these connectomes, and thus cannot explain why SC and FC exhibit dynamic states of both coupling and heterogeneity. In this paper, we formulate multi-modal fusion through the lens of neural communication dynamics and propose the Adaptive Flow Routing Network (AFR-Net), a physics-informed framework that models how structural constraints (SC) give rise to functional communication patterns (FC), enabling interpretable discovery of critical neural pathways. Extensive experiments demonstrate that AFR-Net significantly outperforms state-of-the-art baselines. The code is available at https://anonymous.4open.science/r/DIAL-F0D1.", "AI": {"tldr": "提出了一种名为自适应流路由网络（AFR-Net）的框架，该框架通过模拟结构约束如何产生功能通信模式来解释大脑中的宏观认知表型是如何从微观神经连接中产生的。", "motivation": "现有的多模态融合方法未能充分揭示神经元区域之间的潜在交互作用以及为何结构性和功能性连接表现出动态耦合状态。", "method": "AFR-Net是一种物理启发的框架，通过模拟结构约束（SC）如何导致功能通信模式（FC），从而发现关键的神经通路。该模型采用自适应流路由方法来解释这些潜在的相互作用。", "result": "实验结果表明，所提出的AFR-Net显著优于现有的最先进的基准方法。", "conclusion": "通过利用物理启发的方法，AFR-Net能够更好地理解和解释大脑网络中的通信模式，并且在实际应用中表现出色。"}}
{"id": "2602.00560", "pdf": "https://arxiv.org/pdf/2602.00560", "abs": "https://arxiv.org/abs/2602.00560", "authors": ["Yong Ren", "Jiangyan Yi", "Jianhua Tao", "Zhengqi Wen", "Tao Wang"], "title": "Edit Content, Preserve Acoustics: Imperceptible Text-Based Speech Editing via Self-Consistency Rewards", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Imperceptible text-based speech editing allows users to modify spoken content by altering the transcript. It demands that modified segments fuse seamlessly with the surrounding context. Prevalent methods operating in the acoustic space suffer from inherent content-style entanglement, leading to generation instability and boundary artifacts. In this paper, we propose a novel framework grounded in the principle of \"Edit Content, Preserve Acoustics\". Our approach relies on two core components: (1) Structural Foundations, which decouples editing into a stable semantic space while delegating acoustic reconstruction to a Flow Matching decoder; and (2) Perceptual Alignment, which employs a novel Self-Consistency Rewards Group Relative Policy Optimization. By leveraging a pre-trained Text-to-Speech model as an implicit critic -- complemented by strict intelligibility and duration constraints -- we effectively align the edited semantic token sequence with the original context. Empirical evaluations demonstrate that our method significantly outperforms state-of-the-art autoregressive and non-autoregressive baselines, achieving superior intelligibility, robustness, and perceptual quality.", "AI": {"tldr": "本文提出了一种基于文本的语音编辑框架，能够在不改变原始声学特征的情况下修改语音内容。", "motivation": "当前的方法在音频空间中操作时容易导致生成不稳定和边界伪影问题。为了解决这些问题，并提高语义可理解性和感知质量，提出了新的编辑方法。", "method": "该方法包括两部分：（1）结构性基础，通过分离语义和声学重建来稳定内容编辑；（2）感知对齐，使用自一致性奖励的相对策略优化。借助预训练的TTS模型作为隐含批评者，并结合严格的可懂度和持续时间约束条件。", "result": "实验证明该方法优于当前最先进的AR和非AR基准测试，在理解和感知质量方面表现更优。", "conclusion": "通过分离内容编辑与声学重建，可以有效地解决生成不稳定性和边界伪影问题，并提高语音修改后的可懂度和感知质量。"}}
{"id": "2602.00559", "pdf": "https://arxiv.org/pdf/2602.00559", "abs": "https://arxiv.org/abs/2602.00559", "authors": ["Wenbin Xing", "Quanxing Zha", "Lizheng Zu", "Mengran Li", "Ming Li", "Junchi Yan"], "title": "Learning to Decode Against Compositional Hallucination in Video Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Current research on video hallucination mitigation primarily focuses on isolated error types, leaving compositional hallucinations, arising from incorrect reasoning over multiple interacting spatial and temporal factors largely underexplored. We introduce OmniVCHall, a benchmark designed to systematically evaluate both isolated and compositional hallucinations in video multimodal large language models (VLLMs). OmniVCHall spans diverse video domains, introduces a novel camera-based hallucination type, and defines a fine-grained taxonomy, together with adversarial answer options (e.g., \"All are correct\" and \"None of the above\") to prevent shortcut reasoning. The evaluations of 39 representative VLLMs reveal that even advanced models (e.g., Qwen3-VL and GPT-5) exhibit substantial performance degradation. We propose TriCD, a contrastive decoding framework with a triple-pathway calibration mechanism. An adaptive perturbation controller dynamically selects distracting operations to construct negative video variants, while a saliency-guided enhancement module adaptively reinforces grounded token-wise visual evidences. These components are optimized via reinforcement learning to encourage precise decision-making under compositional hallucination settings. Experimental results show that TriCD consistently improves performance across two representative backbones, achieving an average accuracy improvement of over 10%. The data and code can be find at https://github.com/BMRETURN/OmniVCHall.", "AI": {"tldr": "该论文提出了一种名为TriCD的对比解码框架，旨在解决视频多模态大型语言模型中的组合型幻觉问题。", "motivation": "现有研究主要集中在孤立错误类型的视频幻觉缓解上，而忽视了由多个相互作用的空间和时间因素引起的组合型幻觉。为了系统地评估这些现象，论文引入了一个名为OmniVCHall的新基准。", "method": "TriCD通过三路径校准机制进行对比解码，并采用基于强化学习的自适应扰动控制器以及引导增强模块来优化模型决策。", "result": "实验结果显示，TriCD在两个代表性骨干网络上实现了超过10%的平均准确率提升。", "conclusion": "该方法通过引入新的基准和创新框架有效提升了视频多模态大型语言模型应对组合型幻觉的能力。"}}
{"id": "2602.00557", "pdf": "https://arxiv.org/pdf/2602.00557", "abs": "https://arxiv.org/abs/2602.00557", "authors": ["Weisheng Dai", "Kai Lan", "Jianyi Zhou", "Bo Zhao", "Xiu Su", "Junwen Tong", "Weili Guan", "Shuo Yang"], "title": "ConLA: Contrastive Latent Action Learning from Human Videos for Robotic Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Vision-Language-Action (VLA) models achieve preliminary generalization through pretraining on large scale robot teleoperation datasets. However, acquiring datasets that comprehensively cover diverse tasks and environments is extremely costly and difficult to scale. In contrast, human demonstration videos offer a rich and scalable source of diverse scenes and manipulation behaviors, yet their lack of explicit action supervision hinders direct utilization. Prior work leverages VQ-VAE based frameworks to learn latent actions from human videos in an unsupervised manner. Nevertheless, since the training objective primarily focuses on reconstructing visual appearances rather than capturing inter-frame dynamics, the learned representations tend to rely on spurious visual cues, leading to shortcut learning and entangled latent representations that hinder transferability. To address this, we propose ConLA, an unsupervised pretraining framework for learning robotic policies from human videos. ConLA introduces a contrastive disentanglement mechanism that leverages action category priors and temporal cues to isolate motion dynamics from visual content, effectively mitigating shortcut learning. Extensive experiments show that ConLA achieves strong performance across diverse benchmarks. Notably, by pretraining solely on human videos, our method for the first time surpasses the performance obtained with real robot trajectory pretraining, highlighting its ability to extract pure and semantically consistent latent action representations for scalable robot learning.", "AI": {"tldr": "对比学习潜在动作（ConLA）框架从人类视频中无监督地学习机器人政策，通过对比解耦机制分离运动动态和视觉内容以避免捷径学习。", "motivation": "大规模的机器人遥操作系统数据集难以获得且成本高昂。然而，由于缺乏显式的行为监督，使用人类演示视频的数据源虽丰富多样却难于直接利用。", "method": "ConLA 引入对比解耦机制，基于动作类别先验和时间线索从人类视频中无监督地学习潜在的动作表示。", "result": "在多个基准测试上表现出色，特别是在仅通过人类视频预训练的情况下超越了真实机器人轨迹预训练的性能。", "conclusion": "ConLA 方法能够从人类视频中提取纯正且语义一致的潜在动作表示，对于可扩展的机器人学习具有重要意义。"}}
{"id": "2602.00551", "pdf": "https://arxiv.org/pdf/2602.00551", "abs": "https://arxiv.org/abs/2602.00551", "authors": ["Daoxuan Zhang", "Ping Chen", "Xiaobo Xia", "Xiu Su", "Ruichen Zhen", "Jianqiang Xiao", "Shuo Yang"], "title": "APEX: A Decoupled Memory-based Explorer for Asynchronous Aerial Object Goal Navigation", "categories": ["cs.RO", "cs.CV"], "comment": "15 pages, 8 figures", "summary": "Aerial Object Goal Navigation, a challenging frontier in Embodied AI, requires an Unmanned Aerial Vehicle (UAV) agent to autonomously explore, reason, and identify a specific target using only visual perception and language description. However, existing methods struggle with the memorization of complex spatial representations in aerial environments, reliable and interpretable action decision-making, and inefficient exploration and information gathering. To address these challenges, we introduce \\textbf{APEX} (Aerial Parallel Explorer), a novel hierarchical agent designed for efficient exploration and target acquisition in complex aerial settings. APEX is built upon a modular, three-part architecture: 1) Dynamic Spatio-Semantic Mapping Memory, which leverages the zero-shot capability of a Vision-Language Model (VLM) to dynamically construct high-resolution 3D Attraction, Exploration, and Obstacle maps, serving as an interpretable memory mechanism. 2) Action Decision Module, trained with reinforcement learning, which translates this rich spatial understanding into a fine-grained and robust control policy. 3) Target Grounding Module, which employs an open-vocabulary detector to achieve definitive and generalizable target identification. All these components are integrated into a hierarchical, asynchronous, and parallel framework, effectively bypassing the VLM's inference latency and boosting the agent's proactivity in exploration. Extensive experiments show that APEX outperforms the previous state of the art by +4.2\\% SR and +2.8\\% SPL on challenging UAV-ON benchmarks, demonstrating its superior efficiency and the effectiveness of its hierarchical asynchronous design. Our source code is provided in \\href{https://github.com/4amGodvzx/apex}{GitHub}", "AI": {"tldr": "本文提出了一种新型的层次化无人飞行器（UAV）代理APEX，用于复杂空域中目标导航和获取任务。", "motivation": "现有方法在记忆复杂的空间表示、可靠且可解释的动作决策以及高效探索方面存在困难。为此，引入了APEX来解决这些挑战。", "method": "APEX由三个模块组成：动态空间语义映射存储器、动作决定模块和目标定位模块，并通过异步并行框架提高效率。", "result": "在UAV-ON基准测试中，APEX的表现优于现有最佳方法，在成功率（SR）上提高了4.2%，在路径长度惩罚评分（SPL）上提高了2.8%。", "conclusion": "实验结果表明，APEX通过其层次化异步设计显著提升了效率和性能。"}}
{"id": "2602.00547", "pdf": "https://arxiv.org/pdf/2602.00547", "abs": "https://arxiv.org/abs/2602.00547", "authors": ["Seunghyun Yoo", "Sanghong Kim", "Namkyung Yoon", "Hwangnam Kim"], "title": "Contrastive Domain Generalization for Cross-Instrument Molecular Identification in Mass Spectrometry", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 2 figures", "summary": "Identifying molecules from mass spectrometry (MS) data remains a fundamental challenge due to the semantic gap between physical spectral peaks and underlying chemical structures. Existing deep learning approaches often treat spectral matching as a closed-set recognition task, limiting their ability to generalize to unseen molecular scaffolds. To overcome this limitation, we propose a cross-modal alignment framework that directly maps mass spectra into the chemically meaningful molecular structure embedding space of a pretrained chemical language model. On a strict scaffold-disjoint benchmark, our model achieves a Top-1 accuracy of 42.2% in fixed 256-way zero-shot retrieval and demonstrates strong generalization under a global retrieval setting. Moreover, the learned embedding space demonstrates strong chemical coherence, reaching 95.4% accuracy in 5-way 5-shot molecular re-identification. These results suggest that explicitly integrating physical spectral resolution with molecular structure embedding is key to solving the generalization bottleneck in molecular identification from MS data.", "AI": {"tldr": "提出了一个跨模式对齐框架，将质谱图直接映射到化学语言模型的分子结构嵌入空间中，以解决从质谱数据识别分子时的一般化瓶颈。", "motivation": "现有的深度学习方法通常将光谱匹配视为封闭集识别任务，限制了它们在未见过的分子支架上的泛化能力。为了解决这一问题，提出了一个能够直接将质谱图映射到化学语言模型中的分子结构嵌入空间的方法。", "method": "提出了一种跨模式对齐框架，通过预训练的化学语言模型来学习从质谱数据中识别分子的通用表示方法，使得该方法可以在不同类型的质谱仪器之间进行泛化。", "result": "在严格的支架分离基准测试上，提出的模型达到了42.2%的Top-1准确率，在固定256种方式的零样本检索中表现良好，并且展示了强大的化学一致性，达到95.4%的五折五次分子再识别准确性。", "conclusion": "明确地将物理光谱分辨率与分子结构嵌入相结合是解决从质谱数据进行分子识别时的一般化瓶颈的关键方法。"}}
{"id": "2602.00542", "pdf": "https://arxiv.org/pdf/2602.00542", "abs": "https://arxiv.org/abs/2602.00542", "authors": ["Mohammad Saeid", "Amir Salarpour", "Pedram MohajerAnsari", "Mert D. Pesé"], "title": "NPNet: A Non-Parametric Network with Adaptive Gaussian-Fourier Positional Encoding for 3D Classification and Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted to the 2026 IEEE Intelligent Vehicles Symposium (IV 2026)", "summary": "We present NPNet, a fully non-parametric approach for 3D point-cloud classification and part segmentation. NPNet contains no learned weights; instead, it builds point features using deterministic operators such as farthest point sampling, k-nearest neighbors, and pooling. Our key idea is an adaptive Gaussian-Fourier positional encoding whose bandwidth and Gaussian-cosine mixing are chosen from the input geometry, helping the method remain stable across different scales and sampling densities. For segmentation, we additionally incorporate fixed-frequency Fourier features to provide global context alongside the adaptive encoding. Across ModelNet40/ModelNet-R, ScanObjectNN, and ShapeNetPart, NPNet achieves strong performance among non-parametric baselines, and it is particularly effective in few-shot settings on ModelNet40. NPNet also offers favorable memory use and inference time compared to prior non-parametric methods", "AI": {"tldr": "NPNet是一种用于3D点云分类和分割的非参数方法，无需学习权重。", "motivation": "提出一种不需要学习权重的方法来提高3D点云处理的稳定性和效率，并且在不同的尺度和采样密度下保持性能一致。", "method": "使用确定性操作如最远点采样、k近邻和池化构建点特征，引入自适应高斯-傅立叶位置编码以提供更稳定的特征表示。对于分割任务，则增加固定的频次傅立叶特征来提供全局上下文信息。", "result": "在ModelNet40/ModelNet-R、ScanObjectNN以及ShapeNetPart数据集上取得了与现有非参数方法相当甚至更好的性能，尤其是在少量样本下的分类效果更佳，并且内存使用和推理时间方面优于先前的方法。", "conclusion": "NPNet通过引入自适应高斯-傅立叶位置编码，在无需学习权重的情况下实现了3D点云的有效分类和分割任务，同时在不同场景下表现出色。"}}
{"id": "2602.00540", "pdf": "https://arxiv.org/pdf/2602.00540", "abs": "https://arxiv.org/abs/2602.00540", "authors": ["Yuxin Wu", "Hongshu Guo", "Ting Huang", "Yue-Jiao Gong", "Zeyuan Ma"], "title": "Surrogate Ensemble in Expensive Multi-Objective Optimization via Deep Q-Learning", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Surrogate-assisted Evolutionary Algorithms~(SAEAs) have shown promising robustness in solving expensive optimization problems. A key aspect that impacts SAEAs' effectiveness is surrogate model selection, which in existing works is predominantly decided by human developer. Such human-made design choice introduces strong bias into SAEAs and may hurt their expected performance on out-of-scope tasks. In this paper, we propose a reinforcement learning-assisted ensemble framework, termed as SEEMOO, which is capable of scheduling different surrogate models within a single optimization process, hence boosting the overall optimization performance in a cooperative paradigm. Specifically, we focus on expensive multi-objective optimization problems, where multiple objective functions shape a compositional landscape and hence challenge surrogate selection. SEEMOO comprises following core designs: 1) A pre-collected model pool that maintains different surrogate models; 2) An attention-based state-extractor supports universal optimization state representation of problems with varied objective numbers; 3) a deep Q-network serves as dynamic surrogate selector: Given the optimization state, it selects desired surrogate model for current-step evaluation. SEEMOO is trained to maximize the overall optimization performance under a training problem distribution. Extensive benchmark results demonstrate SEEMOO's surrogate ensemble paradigm boosts the optimization performance of single-surrogate baselines. Further ablation studies underscore the importance of SEEMOO's design components.", "AI": {"tldr": "提出了一种基于强化学习的代理模型集成框架SEEMOO，用于解决昂贵的多目标优化问题。", "motivation": "现有工作中代理模型的选择主要由人工决定，这引入了较强的偏见并可能损害算法在新任务上的性能。因此，作者希望通过自动化的代理模型选择提高优化性能。", "method": "提出了一种基于强化学习的方法SEEMOO，该方法包含一个预收集的代理模型池、基于注意力的状态提取器和用于动态选择最佳代理模型的深度Q网络。", "result": "实验结果表明SEEMOO在多目标优化问题上优于单一代理模型基线。", "conclusion": "SEEMOO通过自动化代理模型的选择有效提升了昂贵多目标优化问题上的性能表现。"}}
{"id": "2602.00536", "pdf": "https://arxiv.org/pdf/2602.00536", "abs": "https://arxiv.org/abs/2602.00536", "authors": ["Yifan Zhang", "Qian Chen", "Yi Liu", "Wengen Li", "Jihong Guan"], "title": "SADER: Structure-Aware Diffusion Framework with DEterministic Resampling for Multi-Temporal Remote Sensing Cloud Removal", "categories": ["cs.CV"], "comment": null, "summary": "Cloud contamination severely degrades the usability of remote sensing imagery and poses a fundamental challenge for downstream Earth observation tasks. Recently, diffusion-based models have emerged as a dominant paradigm for remote sensing cloud removal due to their strong generative capability and stable optimization. However, existing diffusion-based approaches often suffer from limited sampling efficiency and insufficient exploitation of structural and temporal priors in multi-temporal remote sensing scenarios. In this work, we propose SADER, a structure-aware diffusion framework for multi-temporal remote sensing cloud removal. SADER first develops a scalable Multi-Temporal Conditional Diffusion Network (MTCDN) to fully capture multi-temporal and multimodal correlations via temporal fusion and hybrid attention. Then, a cloud-aware attention loss is introduced to emphasize cloud-dominated regions by accounting for cloud thickness and brightness discrepancies. In addition, a deterministic resampling strategy is designed for continuous diffusion models to iteratively refine samples under fixed sampling steps by replacing outliers through guided correction. Extensive experiments on multiple multi-temporal datasets demonstrate that SADER consistently outperforms state-of-the-art cloud removal methods across all evaluation metrics. The code of SADER is publicly available at https://github.com/zyfzs0/SADER.", "AI": {"tldr": "SADER是一种针对多时相遥感影像去云的结构感知扩散框架。", "motivation": "现有的基于扩散模型的方法在采样效率和时间空间先验利用方面存在不足，为此提出了一种新的方法来解决这些问题。", "method": "该方法包括一个可扩展的时间融合和混合注意力机制的多时相条件扩散网络(MTCDN)，并引入了云感知损失以及确定性重采样策略以提高去云效果。", "result": "在多个数据集上的实验表明，SADER优于现有的所有对比方法。", "conclusion": "提出的SADER框架通过利用结构信息和时间先验有效提升了多时相遥感影像的去云能力。"}}
{"id": "2602.00533", "pdf": "https://arxiv.org/pdf/2602.00533", "abs": "https://arxiv.org/abs/2602.00533", "authors": ["Core Francisco Park"], "title": "Convergent World Representations and Divergent Tasks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While neural representations are central to modern deep learning, the conditions governing their geometry and their roles in downstream adaptability remain poorly understood. We develop a framework clearly separating the underlying world, the data generation process and the resulting model representations to study these questions in a controlled setup. 5,075 city coordinates define the world and 7 geometric tasks generate the training data for autoregressive training. We find that different tasks give rise to qualitatively and quantitatively distinct world representation geometries. However, multi-task training drives convergence of world representations: models trained on non-overlapping tasks develop aligned geometric representations, providing controlled evidence for the Multitask Scaling Hypothesis of the Platonic Representation Hypothesis. To study adaptation, we pretrain models on all tasks, then test whether new entities (cities) can be consistently integrated into the representation space via fine-tuning. Surprisingly, we find that despite multi-task pretraining, some tasks, which we call divergent, actively harm the representational integration of new entities and harm generalization. Our results show that training on multiple relational tasks reliably produces convergent world representations, but lurking divergent tasks can catastrophically harm new entity integration via fine-tuning.", "AI": {"tldr": "研究不同任务如何影响神经网络表示的几何结构以及这些表示在下游适应性中的作用。", "motivation": "探索现代深度学习中神经表示的几何特性和其在后续任务中的可适应性的条件，以更好地理解它们的行为。", "method": "使用5,075个城市坐标定义世界，并通过七种不同的几何任务生成训练数据。研究单任务和多任务训练条件下模型的世界表示几何差异，以及这些表示在新实体集成时的表现。", "result": "发现不同任务导致了具有显著区别性的世界表示几何结构。然而，当进行多任务预训练后，尽管世界表示趋向于收敛，但某些特定的任务（即“发散”任务）会损害新实体的表示整合和泛化能力。", "conclusion": "研究表明，在多个关系性任务上进行多任务预训练可以促进世界表示的一致性，但是存在的“发散”任务可能会通过微调严重地破坏新实体的表示集成。"}}
{"id": "2602.00532", "pdf": "https://arxiv.org/pdf/2602.00532", "abs": "https://arxiv.org/abs/2602.00532", "authors": ["Qianhao Zhu", "Sijie Ma", "Zeyuan Ma", "Hongshu Guo", "Yue-Jiao Gong"], "title": "Reinforcement Learning-assisted Constraint Relaxation for Constrained Expensive Optimization", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Constraint handling plays a key role in solving realistic complex optimization problems. Though intensively discussed in the last few decades, existing constraint handling techniques predominantly rely on human experts' designs, which more or less fall short in utility towards general cases. Motivated by recent progress in Meta-Black-Box Optimization where automated algorithm design can be learned to boost optimization performance, in this paper, we propose learning effective, adaptive and generalizable constraint handling policy through reinforcement learning. Specifically, a tailored Markov Decision Process is first formulated, where given optimization dynamics features, a deep Q-network-based policy controls the constraint relaxation level along the underlying optimization process. Such adaptive constraint handling provides flexible tradeoff between objective-oriented exploitation and feasible-region-oriented exploration, and hence leads to promising optimization performance. We train our approach on CEC 2017 Constrained Optimization benchmark with limited evaluation budget condition (expensive cases) and compare the trained constraint handling policy to strong baselines such as recent winners in CEC/GECCO competitions. Extensive experimental results show that our approach performs competitively or even surpasses the compared baselines under either Leave-one-out cross-validation or ordinary train-test split validation. Further analysis and ablation studies reveal key insights in our designs.", "AI": {"tldr": "提出了一种基于强化学习的自适应约束处理策略，用于解决复杂的优化问题。", "motivation": "现有约束处理技术依赖于人工设计，在应对通用情况时存在局限性；通过自动化算法设计提升优化性能是研究动机之一。", "method": "采用深度Q网络控制约束放松程度，并利用CEC 2017基准测试集进行训练与对比实验。", "result": "在严格预算条件下，所提方法表现优异或超越现有基线。", "conclusion": "该策略通过动态调整约束松弛度实现了性能优化并展示了有效性。"}}
{"id": "2602.00531", "pdf": "https://arxiv.org/pdf/2602.00531", "abs": "https://arxiv.org/abs/2602.00531", "authors": ["Tianyi Zhang", "Antoine Simoulin", "Kai Li", "Sana Lakdawala", "Shiqing Yu", "Arpit Mittal", "Hongyu Fu", "Yu Lin"], "title": "Enhancing Open-Vocabulary Object Detection through Multi-Level Fine-Grained Visual-Language Alignment", "categories": ["cs.CV"], "comment": null, "summary": "Traditional object detection systems are typically constrained to predefined categories, limiting their applicability in dynamic environments. In contrast, open-vocabulary object detection (OVD) enables the identification of objects from novel classes not present in the training set. Recent advances in visual-language modeling have led to significant progress of OVD. However, prior works face challenges in either adapting the single-scale image backbone from CLIP to the detection framework or ensuring robust visual-language alignment. We propose Visual-Language Detection (VLDet), a novel framework that revamps feature pyramid for fine-grained visual-language alignment, leading to improved OVD performance. With the VL-PUB module, VLDet effectively exploits the visual-language knowledge from CLIP and adapts the backbone for object detection through feature pyramid. In addition, we introduce the SigRPN block, which incorporates a sigmoid-based anchor-text contrastive alignment loss to improve detection of novel categories. Through extensive experiments, our approach achieves 58.7 AP for novel classes on COCO2017 and 24.8 AP on LVIS, surpassing all state-of-the-art methods and achieving significant improvements of 27.6% and 6.9%, respectively. Furthermore, VLDet also demonstrates superior zero-shot performance on closed-set object detection.", "AI": {"tldr": "本文提出了一个名为Visual-Language Detection (VLDet)的新框架，用于提高开放词汇对象检测的性能。", "motivation": "传统的目标检测系统受限于预定义类别，在动态环境中适用性有限。而开放词汇目标检测允许识别训练集中未出现的新类别的物体。然而，现有的方法在将单尺度图像骨干网络从CLIP适应到检测框架或保证稳健的视觉-语言对齐方面存在挑战。", "method": "VLDet通过改进特征金字塔实现细粒度的视觉-语言对齐，并引入VL-PUB模块和SigRPN块以充分利用来自CLIP的视觉语言知识，提升物体检测能力。", "result": "实验结果表明，该方法在COCO2017上对于新类别的AP值为58.7%，LVIS上的AP值为24.8%，分别超过了所有现有最佳方法，并取得了显著的进步。", "conclusion": "VLDet不仅提高了开放词汇对象检测的性能，还表现出卓越的闭集物体检测零样本能力。"}}
{"id": "2602.00528", "pdf": "https://arxiv.org/pdf/2602.00528", "abs": "https://arxiv.org/abs/2602.00528", "authors": ["Minhua Lin", "Enyan Dai", "Hui Liu", "Xianfeng Tang", "Yuliang Yan", "Zhenwei Dai", "Jingying Zeng", "Zhiwei Zhang", "Fali Wang", "Hongcheng Gao", "Chen Luo", "Xiang Zhang", "Qi He", "Suhang Wang"], "title": "How Far Are LLMs from Professional Poker Players? Revisiting Game-Theoretic Reasoning with Agentic Tool Use", "categories": ["cs.AI"], "comment": "Accepted by ICLR 2026", "summary": "As Large Language Models (LLMs) are increasingly applied in high-stakes domains, their ability to reason strategically under uncertainty becomes critical. Poker provides a rigorous testbed, requiring not only strong actions but also principled, game-theoretic reasoning. In this paper, we conduct a systematic study of LLMs in multiple realistic poker tasks, evaluating both gameplay outcomes and reasoning traces. Our analysis reveals LLMs fail to compete against traditional algorithms and identifies three recurring flaws: reliance on heuristics, factual misunderstandings, and a \"knowing-doing\" gap where actions diverge from reasoning. An initial attempt with behavior cloning and step-level reinforcement learning improves reasoning style but remains insufficient for accurate game-theoretic play. Motivated by these limitations, we propose ToolPoker, a tool-integrated reasoning framework that combines external solvers for GTO-consistent actions with more precise professional-style explanations. Experiments demonstrate that ToolPoker achieves state-of-the-art gameplay while producing reasoning traces that closely reflect game-theoretic principles.", "AI": {"tldr": "该论文研究了大型语言模型在扑克游戏中的策略推理能力，并提出了一种新的工具集成框架ToolPoker。", "motivation": "随着大型语言模型的应用越来越广泛，它们在高风险领域中进行战略决策的能力变得至关重要。通过扑克这样的严格测试床，可以评估模型是否能够进行原理性的博弈论推理。", "method": "论文首先对多个现实中的扑克任务进行了系统研究，并发现大型语言模型存在三种常见缺陷：依赖于启发式方法、事实性误解以及“知行不一”的现象。随后提出了一种新的框架ToolPoker，该框架结合了外部求解器和更加精确的专业解释。", "result": "实验结果表明，使用ToolPoker不仅实现了游戏玩法上的新突破，还产生了更接近于博弈论原理的推理痕迹。", "conclusion": "大型语言模型在进行复杂的策略决策时仍然存在显著限制，但通过结合外部工具可以改善其表现。"}}
{"id": "2602.00526", "pdf": "https://arxiv.org/pdf/2602.00526", "abs": "https://arxiv.org/abs/2602.00526", "authors": ["Kaiwen Zha", "Chao Li", "Hao He", "Peng Cao", "Tianhong Li", "Ali Mirzazadeh", "Ellen Zhang", "Jong Woo Lee", "Yoon Kim", "Dina Katabi"], "title": "Physiology as Language: Translating Respiration to Sleep EEG", "categories": ["cs.LG", "cs.AI"], "comment": "Tech report", "summary": "This paper introduces a novel cross-physiology translation task: synthesizing sleep electroencephalography (EEG) from respiration signals. To address the significant complexity gap between the two modalities, we propose a waveform-conditional generative framework that preserves fine-grained respiratory dynamics while constraining the EEG target space through discrete tokenization. Trained on over 28,000 individuals, our model achieves a 7% Mean Absolute Error in EEG spectrogram reconstruction. Beyond reconstruction, the synthesized EEG supports downstream tasks with performance comparable to ground truth EEG on age estimation (MAE 5.0 vs. 5.1 years), sex detection (AUROC 0.81 vs. 0.82), and sleep staging (Accuracy 0.84 vs. 0.88), significantly outperforming baselines trained directly on breathing. Finally, we demonstrate that the framework generalizes to contactless sensing by synthesizing EEG from wireless radio-frequency reflections, highlighting the feasibility of remote, non-contact neurological assessment during sleep.", "AI": {"tldr": "本文介绍了一种新的跨生理翻译任务：从呼吸信号合成睡眠脑电图（EEG）。", "motivation": "解决不同生理模式之间的复杂性差距，以实现非接触式的远程神经学评估。", "method": "提出了一种基于波形的生成框架，通过离散标记化来约束EEG目标空间，并在超过28000名个体的数据上进行训练。", "result": "模型实现了7%的平均绝对误差（MAE）在EEG光谱图重建中。合成的EEG支持年龄估计、性别检测和睡眠阶段划分等下游任务，性能与真实值相当，且优于直接基于呼吸信号的基线方法。", "conclusion": "该框架证明了从无线射频反射生成EEG的可能性，从而为远程非接触式神经学评估提供了可行性。"}}
{"id": "2602.00523", "pdf": "https://arxiv.org/pdf/2602.00523", "abs": "https://arxiv.org/abs/2602.00523", "authors": ["Yujia Tong", "Tian Zhang", "Yunyang Wan", "Kaiwei Lin", "Jingling Yuan", "Chuang Hu"], "title": "SAGE: Accelerating Vision-Language Models via Entropy-Guided Adaptive Speculative Decoding", "categories": ["cs.CV"], "comment": null, "summary": "Speculative decoding has emerged as a promising approach to accelerate inference in vision-language models (VLMs) by enabling parallel verification of multiple draft tokens. However, existing methods rely on static tree structures that remain fixed throughout the decoding process, failing to adapt to the varying prediction difficulty across generation steps. This leads to suboptimal acceptance lengths and limited speedup. In this paper, we propose SAGE, a novel framework that dynamically adjusts the speculation tree structure based on real-time prediction uncertainty. Our key insight is that output entropy serves as a natural confidence indicator with strong temporal correlation across decoding steps. SAGE constructs deeper-narrower trees for high-confidence predictions to maximize speculation depth, and shallower-wider trees for uncertain predictions to diversify exploration. SAGE improves acceptance lengths and achieves faster acceleration compared to static tree baselines. Experiments on multiple benchmarks demonstrate the effectiveness of SAGE: without any loss in output quality, it delivers up to $3.36\\times$ decoding speedup for LLaVA-OneVision-72B and $3.18\\times$ for Qwen2.5-VL-72B.", "AI": {"tldr": "SAGE通过基于实时预测不确定性动态调整投机树结构，提高视觉语言模型的推理速度。", "motivation": "现有的投机解码方法依赖于静态树结构，在整个解码过程中保持不变，无法适应不同生成步骤中的预测难度变化，导致接受长度次优和加速有限。为了解决这一问题，提出了一种新的动态调整投机树结构的方法。", "method": "SAGE基于输出熵作为自然信心指标，构建更深层次的窄树来最大化投机深度，并构建较浅层次的宽树以增加探索多样性，从而动态适应不同的预测不确定性。", "result": "实验结果表明，与静态树基准相比，SAGE在不降低生成质量的情况下实现了最高达3.36倍和3.18倍的解码速度提升。", "conclusion": "通过提出一种基于实时预测不确定性的动态调整投机树结构的方法，SAGE显著提高了视觉语言模型的推理效率，展示了其在多任务基准测试中的优越性能。"}}
{"id": "2602.00522", "pdf": "https://arxiv.org/pdf/2602.00522", "abs": "https://arxiv.org/abs/2602.00522", "authors": ["Chaoran Xu", "Chengkan Lv", "Qiyu Chen", "Feng Zhang", "Zhengtao Zhang"], "title": "MRAD: Zero-Shot Anomaly Detection with Memory-Driven Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Zero-shot anomaly detection (ZSAD) often leverages pretrained vision or vision-language models, but many existing methods use prompt learning or complex modeling to fit the data distribution, resulting in high training or inference cost and limited cross-domain stability. To address these limitations, we propose Memory-Retrieval Anomaly Detection method (MRAD), a unified framework that replaces parametric fitting with a direct memory retrieval. The train-free base model, MRAD-TF, freezes the CLIP image encoder and constructs a two-level memory bank (image-level and pixel-level) from auxiliary data, where feature-label pairs are explicitly stored as keys and values. During inference, anomaly scores are obtained directly by similarity retrieval over the memory bank. Based on the MRAD-TF, we further propose two lightweight variants as enhancements: (i) MRAD-FT fine-tunes the retrieval metric with two linear layers to enhance the discriminability between normal and anomaly; (ii) MRAD-CLIP injects the normal and anomalous region priors from the MRAD-FT as dynamic biases into CLIP's learnable text prompts, strengthening generalization to unseen categories. Across 16 industrial and medical datasets, the MRAD framework consistently demonstrates superior performance in anomaly classification and segmentation, under both train-free and training-based settings. Our work shows that fully leveraging the empirical distribution of raw data, rather than relying only on model fitting, can achieve stronger anomaly detection performance. The code will be publicly released at https://github.com/CROVO1026/MRAD.", "AI": {"tldr": "提出了一种零样本异常检测框架MRAD，该框架通过直接记忆检索替代了参数拟合。", "motivation": "现有方法依赖于预训练模型并采用提示学习或复杂建模来适应数据分布，导致高成本和跨域稳定性差。为此提出了MRAD以解决这些问题。", "method": "设计了一种基于冻结CLIP图像编码器的零样本框架MRAD-TF，并构建了一个两级记忆库（图像级和像素级），在推理阶段通过相似性检索直接获取异常得分。进一步开发了两个增强变体：MRAD-FT引入线性层细化指标，以提高区分度；MRAD-CLIP将正常及异常区域先验注入文本提示中。", "result": "该框架在16个工业和医疗数据集中均表现出色，在零样本设置下实现了卓越的异常分类与分割性能。", "conclusion": "通过充分利用原始数据的经验分布，而不是单纯依赖模型拟合，MRAD能够实现更强的异常检测效果。"}}
{"id": "2602.00521", "pdf": "https://arxiv.org/pdf/2602.00521", "abs": "https://arxiv.org/abs/2602.00521", "authors": ["Junhyuk Choi", "Sohhyung Park", "Chanhee Cho", "Hyeonchu Park", "Bugeun Kim"], "title": "Diagnosing the Reliability of LLM-as-a-Judge via Item Response Theory", "categories": ["cs.AI"], "comment": "Under review", "summary": "While LLM-as-a-Judge is widely used in automated evaluation, existing validation practices primarily operate at the level of observed outputs, offering limited insight into whether LLM judges themselves function as stable and reliable measurement instruments. To address this limitation, we introduce a two-phase diagnostic framework for assessing reliability of LLM-as-a-Judge, grounded in Item Response Theory (IRT). The framework adopts Graded Response Model (GRM) of IRT and formalizes reliability along two complementary dimensions: (1) intrinsic consistency, defined as the stability of measurement behavior under prompt variations, and (2) human alignment, capturing correspondence with human quality assessments. We empirically examine diverse LLM judges with this framework, and show that leveraging IRT-GRM yields interpretable signals for diagnosing judgments systematically. These signals provide practical guidance for verifying reliablity of LLM-as-a-Judge and identifying potential causes of unreliability.", "AI": {"tldr": "本文提出了一个基于项目反应理论的两阶段诊断框架，用于评估LLM作为裁判系统的可靠性和稳定性。", "motivation": "现有对自动评价中使用的LLM作为裁判系统验证主要停留在观察输出层面，缺乏深入了解其稳定性和可靠性。因此，引入一种新的方法来全面评估这些系统。", "method": "采用项目反应理论中的分级反应模型（GRM），通过内在一致性度量在提示变化下的测量行为稳定性，并通过与人类质量评估的对应性衡量人机一致性的维度。", "result": "利用该框架对多个LLM裁判系统进行实证分析，结果显示使用IRT-GRM能提供可解释信号，帮助诊断判断的一致性和可靠性问题。", "conclusion": "本研究提供的方法为验证LLM作为裁判系统的可靠性和稳定性提供了实用指导，并有助于识别潜在的不可靠因素。"}}
{"id": "2602.00516", "pdf": "https://arxiv.org/pdf/2602.00516", "abs": "https://arxiv.org/abs/2602.00516", "authors": ["Kunal Mahatha", "Jose Dolz", "Christian Desrosiers"], "title": "SPARK: Stochastic Propagation via Affinity-guided Random walK for training-free unsupervised segmentation", "categories": ["cs.CV"], "comment": null, "summary": "We argue that existing training-free segmentation methods rely on an implicit and limiting assumption, that segmentation is a spectral graph partitioning problem over diffusion-derived affinities. Such approaches, based on global graph partitioning and eigenvector-based formulations of affinity matrices, suffer from several fundamental drawbacks, they require pre-selecting the number of clusters, induce boundary oversmoothing due to spectral relaxation, and remain highly sensitive to noisy or multi-modal affinity distributions. Moreover, many prior works neglect the importance of local neighborhood structure, which plays a crucial role in stabilizing affinity propagation and preserving fine-grained contours. To address these limitations, we reformulate training-free segmentation as a stochastic flow equilibrium problem over diffusion-induced affinity graphs, where segmentation emerges from a stochastic propagation process that integrates global diffusion attention with local neighborhoods extracted from stable diffusion, yielding a sparse yet expressive affinity structure. Building on this formulation, we introduce a Markov propagation scheme that performs random-walk-based label diffusion with an adaptive pruning strategy that suppresses unreliable transitions while reinforcing confident affinity paths. Experiments across seven widely used semantic segmentation benchmarks demonstrate that our method achieves state-of-the-art zero-shot performance, producing sharper boundaries, more coherent regions, and significantly more stable masks compared to prior spectral-clustering-based approaches.", "AI": {"tldr": "该论文提出了一种基于随机行走和局部邻域结构的无训练分割方法SPARK，用于解决现有无监督分割方法中存在的问题。", "motivation": "现有的无训练分割方法依赖于谱图划分假设，存在需要预先选择聚类数量、边界模糊化及对噪声敏感等问题。该论文旨在通过引入随机行走和局部邻域结构来改进这些问题。", "method": "该方法将无训练分割重新表述为扩散诱导亲和力图上的随机流平衡问题，采用马尔可夫传播方案进行标签扩散，并使用自适应剪枝策略抑制不可靠转换以增强可靠的亲和力路径。", "result": "实验证明，该方法在七种广泛使用的语义分割基准上达到了最先进的无训练性能，生成更清晰的边界、更一致的区域以及更加稳定的掩码结果。", "conclusion": "通过引入随机行走机制并结合局部邻域结构，SPARK 方法能够提高无监督分割的质量和稳定性。"}}
{"id": "2602.00515", "pdf": "https://arxiv.org/pdf/2602.00515", "abs": "https://arxiv.org/abs/2602.00515", "authors": ["Lin Liu", "Rita Machacy", "Simi Kuniyilh"], "title": "Contrastive Learning for Privacy Enhancements in Industrial Internet of Things", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The Industrial Internet of Things (IIoT) integrates intelligent sensing, communication, and analytics into industrial environments, including manufacturing, energy, and critical infrastructure. While IIoT enables predictive maintenance and cross-site optimization of modern industrial control systems, such as those in manufacturing and energy, it also introduces significant privacy and confidentiality risks due to the sensitivity of operational data. Contrastive learning, a self-supervised representation learning paradigm, has recently emerged as a promising approach for privacy-preserving analytics by reducing reliance on labeled data and raw data sharing. Although contrastive learning-based privacy-preserving techniques have been explored in the Internet of Things (IoT) domain, this paper offers a comprehensive review of these techniques specifically for privacy preservation in Industrial Internet of Things (IIoT) systems. It emphasizes the unique characteristics of industrial data, system architectures, and various application scenarios. Additionally, the paper discusses solutions and open challenges and outlines future research directions.", "AI": {"tldr": "本文综述了对比学习在工业互联网中的隐私保护技术，强调了工业数据的独特性及其应用场景。", "motivation": "工业互联网引入了敏感操作数据的隐私和保密风险。因此，需要一种方法来减少对标签数据和原始数据共享的依赖，以实现隐私保护。", "method": "对比学习作为一种自监督表示学习范式被提出用于解决上述问题，特别适用于IIoT环境中的隐私保护技术。", "result": "该研究综述了对比学习在IIoT系统中隐私保护的应用，并探讨了解决方案和开放性挑战。", "conclusion": "文章指出了对比学习方法在工业互联网环境中应用的优势，同时提出了未来的研究方向。"}}
{"id": "2602.00514", "pdf": "https://arxiv.org/pdf/2602.00514", "abs": "https://arxiv.org/abs/2602.00514", "authors": ["Yaohua Liu", "Binkai Ou", "Zicheng Qiu", "Ce Hao", "Yemin Wang", "Hengjun Zhang"], "title": "A Low-Cost Vision-Based Tactile Gripper with Pretraining Learning for Contact-Rich Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Robotic manipulation in contact-rich environments remains challenging, particularly when relying on conventional tactile sensors that suffer from limited sensing range, reliability, and cost-effectiveness. In this work, we present LVTG, a low-cost visuo-tactile gripper designed for stable, robust, and efficient physical interaction. Unlike existing visuo-tactile sensors, LVTG enables more effective and stable grasping of larger and heavier everyday objects, thanks to its enhanced tactile sensing area and greater opening angle. Its surface skin is made of highly wear-resistant material, significantly improving durability and extending operational lifespan. The integration of vision and tactile feedback allows LVTG to provide rich, high-fidelity sensory data, facilitating reliable perception during complex manipulation tasks. Furthermore, LVTG features a modular design that supports rapid maintenance and replacement. To effectively fuse vision and touch, We adopt a CLIP-inspired contrastive learning objective to align tactile embeddings with their corresponding visual observations, enabling a shared cross-modal representation space for visuo-tactile perception. This alignment improves the performance of an Action Chunking Transformer (ACT) policy in contact-rich manipulation, leading to more efficient data collection and more effective policy learning. Compared to the original ACT method, the proposed LVTG with pretraining achieves significantly higher success rates in manipulation tasks.", "AI": {"tldr": "开发了一种低成本的视觉触觉夹爪，通过预训练学习实现复杂接触环境中的高效操作。", "motivation": "现有基于视觉和触觉传感器在稳定性、可靠性和成本效益方面存在限制。为了改善这一点，提出一种低功耗且耐用的新型视觉-触觉夹爪。", "method": "采用CLIP启发式对比学习目标来对齐触摸嵌入与相应视觉观察，并通过共享交叉模态表示空间实现高效的操作策略学习。", "result": "提出的LVTG方法相比原始ACT方法，实现了更高的操作成功率。", "conclusion": "新型低功耗且耐用的触觉夹爪在复杂接触任务中的性能显著提高。"}}
{"id": "2602.00510", "pdf": "https://arxiv.org/pdf/2602.00510", "abs": "https://arxiv.org/abs/2602.00510", "authors": ["Huanghaohe Zou", "Peng Han", "Emad Nazerian", "Alex Q. Huang"], "title": "PCBSchemaGen: Constraint-Guided Schematic Design via LLM for Printed Circuit Boards (PCB)", "categories": ["cs.AI", "cs.LG", "cs.SE"], "comment": null, "summary": "Printed Circuit Board (PCB) schematic design plays an essential role in all areas of electronic industries. Unlike prior works that focus on digital or analog circuits alone, PCB design must handle heterogeneous digital, analog, and power signals while adhering to real-world IC packages and pin constraints. Automated PCB schematic design remains unexplored due to the scarcity of open-source data and the absence of simulation-based verification. We introduce PCBSchemaGen, the first training-free framework for PCB schematic design that comprises LLM agent and Constraint-guided synthesis. Our approach makes three contributions: 1. an LLM-based code generation paradigm with iterative feedback with domain-specific prompts. 2. a verification framework leveraging a real-world IC datasheet derived Knowledge Graph (KG) and Subgraph Isomorphism encoding pin-role semantics and topological constraints. 3. an extensive experiment on 23 PCB schematic tasks spanning digital, analog, and power domains. Results demonstrate that PCBSchemaGen significantly improves design accuracy and computational efficiency.", "AI": {"tldr": "PCBSchemaGen通过LLM代理和约束引导合成来实现印刷电路板（PCB）的自动图样设计。", "motivation": "当前自动化PCB图样设计存在数据稀缺以及缺乏基于模拟验证的问题。PCBSchemaGen旨在填补这一空白，提供一个训练自由的框架，以改善设计精度和计算效率。", "method": "该方法包括LLM代理代码生成范式、利用知识图谱进行验证以及涵盖数字、模拟和电源领域的广泛实验。", "result": "实验表明，PCBSchemaGen在23个不同类型的PCB图样任务上显著提高了设计精度和计算效率。", "conclusion": "PCBSchemaGen首次提供了一种训练自由的框架来应对印刷电路板（PCB）设计中的挑战。"}}
{"id": "2602.00508", "pdf": "https://arxiv.org/pdf/2602.00508", "abs": "https://arxiv.org/abs/2602.00508", "authors": ["Min Shi", "Xiaohui Zeng", "Jiannan Huang", "Yin Cui", "Francesco Ferroni", "Jialuo Li", "Shubham Pachori", "Zhaoshuo Li", "Yogesh Balaji", "Haoxiang Wang", "Tsung-Yi Lin", "Xiao Fu", "Yue Zhao", "Chieh-Yun Chen", "Ming-Yu Liu", "Humphrey Shi"], "title": "DuoGen: Towards General Purpose Interleaved Multimodal Generation", "categories": ["cs.CV"], "comment": "Technical Report. Project Page: https://research.nvidia.com/labs/dir/duetgen/", "summary": "Interleaved multimodal generation enables capabilities beyond unimodal generation models, such as step-by-step instructional guides, visual planning, and generating visual drafts for reasoning. However, the quality of existing interleaved generation models under general instructions remains limited by insufficient training data and base model capacity. We present DuoGen, a general-purpose interleaved generation framework that systematically addresses data curation, architecture design, and evaluation. On the data side, we build a large-scale, high-quality instruction-tuning dataset by combining multimodal conversations rewritten from curated raw websites, and diverse synthetic examples covering everyday scenarios. Architecturally, DuoGen leverages the strong visual understanding of a pretrained multimodal LLM and the visual generation capabilities of a diffusion transformer (DiT) pretrained on video generation, avoiding costly unimodal pretraining and enabling flexible base model selection. A two-stage decoupled strategy first instruction-tunes the MLLM, then aligns DiT with it using curated interleaved image-text sequences. Across public and newly proposed benchmarks, DuoGen outperforms prior open-source models in text quality, image fidelity, and image-context alignment, and also achieves state-of-the-art performance on text-to-image and image editing among unified generation models. Data and code will be released at https://research.nvidia.com/labs/dir/duetgen/.", "AI": {"tldr": "DuoGen提出了一个通用的交织式生成框架，旨在改善现有的多模态交互生成模型。", "motivation": "当前多模态交织生成技术受限于训练数据不足和基础模型容量有限的问题，导致在一般指令下的性能表现欠佳。为此，研究者们希望通过系统解决数据收集、架构设计以及评估方法来提高这类模型的质量。", "method": "DuoGen通过结合重写的多模态对话以及涵盖日常场景的多样化合成示例构建大规模高质量的数据集，并利用预训练的多模态LLM和DiT实现视觉理解和生成能力，采用两阶段解耦策略进行指令调优和对齐。", "result": "在公共基准测试及新提出的评估指标上，DuoGen超越了之前开源模型，在文本质量和图像上下文一致性方面表现出色，并且在统一生成模式下的文字到图片转换和图像编辑任务中达到了最先进的水平。", "conclusion": "通过系统性的数据收集、架构设计以及灵活的基础模型选择，DuoGen展示了其在多模态交互式生成领域的优越性能，为未来的研究奠定了坚实基础。"}}
{"id": "2602.00505", "pdf": "https://arxiv.org/pdf/2602.00505", "abs": "https://arxiv.org/abs/2602.00505", "authors": ["Jingrui Zhang", "Feng Liang", "Yong Zhang", "Wei Wang", "Runhao Zeng", "Xiping Hu"], "title": "Sparse Shortcuts: Facilitating Efficient Fusion in Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the remarkable success of large language models (LLMs) in natural language understanding and generation, multimodal large language models (MLLMs) have rapidly advanced in their ability to process data across multiple modalities. While most existing efforts focus on scaling up language models or constructing higher-quality training data, limited attention has been paid to effectively integrating cross-modal knowledge into the language space. In vision-language models, for instance, aligning modalities using only high-level visual features often discards the rich semantic information present in mid- and low-level features, limiting the model's ability of cross-modality understanding. To address this issue, we propose SparseCut, a general cross-modal fusion architecture for MLLMs, introducing sparse shortcut connections between the cross-modal encoder and the LLM. These shortcut connections enable the efficient and hierarchical integration of visual features at multiple levels, facilitating richer semantic fusion without increasing computational overhead. We further introduce an efficient multi-grained feature fusion module, which performs the fusion of visual features before routing them through the shortcuts. This preserves the original language context and does not increase the overall input length, thereby avoiding an increase in computational complexity for the LLM. Experiments demonstrate that SparseCut significantly enhances the performance of MLLMs across various multimodal benchmarks with generality and scalability for different base LLMs.", "AI": {"tldr": "本论文提出了一种用于多模态大型语言模型（MLLM）的通用跨模态融合架构SparseCut，通过引入稀疏捷径连接和高效的多粒度特征融合模块来提高模型性能。", "motivation": "现有的LLMs主要集中在规模扩展或高质量训练数据构建上，忽略了有效整合跨模态知识的问题。视觉语言模型仅依赖高层次的视觉特征进行对齐会导致语义信息丢失，从而限制了模型理解能力。", "method": "提出SparseCut架构：通过在跨模态编码器和LLM之间引入稀疏捷径连接来实现高效的分层融合；使用多粒度特征融合模块以保持原始语言上下文且不增加输入长度的计算复杂性。", "result": "实验显示，SparseCut能够在不同的基准测试中提升MLLMs性能，并具有不同基础LLMs的一般性和可扩展性。", "conclusion": "SparseCut架构有效解决了多模态特征融合问题，提高了模型的理解能力和泛化能力。"}}
{"id": "2602.00504", "pdf": "https://arxiv.org/pdf/2602.00504", "abs": "https://arxiv.org/abs/2602.00504", "authors": ["Jiahe Wu", "Bing Cao", "Qilong Wang", "Qinghua Hu", "Dongdong Li", "Pengfei Zhu"], "title": "RGBX-R1: Visual Modality Chain-of-Thought Guided Reinforcement Learning for Multimodal Grounding", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLM) are primarily pre-trained on the RGB modality, thereby limiting their performance on other modalities, such as infrared, depth, and event data, which are crucial for complex scenarios. To address this, we propose RGBX-R1, a framework to enhance MLLM's perception and reasoning capacities across various X visual modalities. Specifically, we employ an Understand-Associate-Validate (UAV) prompting strategy to construct the Visual Modality Chain-of-Thought (VM-CoT), which aims to expand the MLLMs' RGB understanding capability into X modalities. To progressively enhance reasoning capabilities, we introduce a two-stage training paradigm: Cold-Start Supervised Fine-Tuning (CS-SFT) and Spatio-Temporal Reinforcement Fine-Tuning (ST-RFT). CS-SFT supervises the reasoning process with the guidance of VM-CoT, equipping the MLLM with fundamental modality cognition. Building upon GRPO, ST-RFT employs a Modality-understanding Spatio-Temporal (MuST) reward to reinforce modality reasoning. Notably, we construct the first RGBX-Grounding benchmark, and extensive experiments verify our superiority in multimodal understanding and spatial perception, outperforming baselines by 22.71% on three RGBX grounding tasks.", "AI": {"tldr": "RGBX-R1框架旨在增强多模态大型语言模型在不同视觉模式下的感知和推理能力。", "motivation": "现有多模态大型语言模型主要基于RGB模式训练，导致其在红外、深度等其他重要视觉模式上的表现受限。为此提出RGBX-R1框架以解决这一问题。", "method": "提出了理解-关联-验证（UAV）策略和Visual Modality Chain-of-Thought (VM-CoT)来提升模型的跨模态推理能力，采用两阶段训练范式：冷启动监督微调(CS-SFT) 和基于GRPO的空间时间强化学习细化(ST-RFT)", "result": "实验结果表明，在RGBX-Grounding基准测试上优于基线22.71%，验证了模型在多模态理解和空间感知上的优越性。", "conclusion": "通过提出RGBX-R1框架，成功提升了大型语言模型对各种视觉模式的理解和推理能力。"}}
{"id": "2602.00500", "pdf": "https://arxiv.org/pdf/2602.00500", "abs": "https://arxiv.org/abs/2602.00500", "authors": ["Jianyi Zhou", "Yujie Wei", "Ruichen Zhen", "Bo Zhao", "Xiaobo Xia", "Rui Shao", "Xiu Su", "Shuo Yang"], "title": "Inject Once Survive Later: Backdooring Vision-Language-Action Models to Persist Through Downstream Fine-tuning", "categories": ["cs.RO"], "comment": null, "summary": "Vision-Language-Action (VLA) models have become foundational to modern embodied AI systems. By integrating visual perception, language understanding, and action planning, they enable general-purpose task execution across diverse environments. Despite their importance, the security of VLA models remains underexplored -- particularly in the context of backdoor attacks, which pose realistic threats in physical-world deployments. While recent methods attempt to inject backdoors into VLA models, these backdoors are easily erased during downstream adaptation, as user-side fine-tuning with clean data significantly alters model parameters, rendering them impractical for real-world applications. To address these challenges, we propose INFUSE (INjection into Fine-tUne-inSensitive modulEs), the first backdoor attack framework for VLA base models that remains effective even with arbitrary user fine-tuning. INFUSE begins by analyzing parameter sensitivity across diverse fine-tuning scenarios to identify modules that remain largely unchanged -- the fine-tune-insensitive modules. It then injects backdoors into these stable modules while freezing the rest, ensuring malicious behavior persists after extensive user fine-tuning. Comprehensive experiments across multiple VLA architectures demonstrate INFUSE's effectiveness. After user-side fine-tuning, INFUSE maintains mean attack success rates of 91.0% on simulation environments and 79.8% on real-world robot tasks, substantially surpassing BadVLA (38.8% and 36.6%, respectively), while preserving clean-task performance comparable to standard models. These results uncover a critical threat: backdoors implanted before distribution can persist through fine-tuning and remain effective at deployment.", "AI": {"tldr": "提出INFUSE框架，用于在VLA模型中植入持久后门，即使经过下游微调也能保持攻击效果。", "motivation": "探讨如何在视觉语言行为模型中实施持久性后门攻击，以应对当前后门攻击易被清理的问题。", "method": "通过分析参数敏感度来识别不易改变的模块，在这些模块中植入后门，并冻结其余部分，确保微调后的模型仍能执行恶意操作。", "result": "实验结果显示，INFUSE在模拟环境和真实机器人任务中的平均攻击成功率分别为91.0%和79.8%，显著优于BadVLA（38.8%和36.6%），同时保持了正常任务性能与标准模型相当的水平。", "conclusion": "研究表明，预先植入后门并通过INFUSE框架保护其稳定性的攻击方法，在广泛微调后仍能有效执行恶意行为。"}}
{"id": "2602.00497", "pdf": "https://arxiv.org/pdf/2602.00497", "abs": "https://arxiv.org/abs/2602.00497", "authors": ["Hanjing Shi", "Dominic DiFranzo"], "title": "Culturally-Grounded Governance for Multilingual Language Models: Rights, Data Boundaries, and Accountable AI Design", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multilingual large language models (MLLMs) are increasingly deployed across cultural, linguistic, and political contexts, yet existing governance frameworks largely assume English-centric data, homogeneous user populations, and abstract notions of fairness. This creates systematic risks for low-resource languages and culturally marginalized communities, where data practices, model behavior, and accountability mechanisms often fail to align with local norms, rights, and expectations. Drawing on cross-cultural perspectives in human-centered computing and AI governance, this paper synthesizes existing evidence on multilingual model behavior, data asymmetries, and sociotechnical harm, and articulates a culturally grounded governance framework for MLLMs. We identify three interrelated governance challenges: cultural and linguistic inequities in training data and evaluation practices, misalignment between global deployment and locally situated norms, values, and power structures, and limited accountability mechanisms for addressing harms experienced by marginalized language communities. Rather than proposing new technical benchmarks, we contribute a conceptual agenda that reframes multilingual AI governance as a sociocultural and rights based problem. We outline design and policy implications for data stewardship, transparency, and participatory accountability, and argue that culturally grounded governance is essential for ensuring that multilingual language models do not reproduce existing global inequalities under the guise of scale and neutrality.", "AI": {"tldr": "本文提出了一个多语言大型语言模型的治理框架，旨在解决低资源语言和边缘化社区面临的问题。", "motivation": "多语言大型语言模型在不同文化和政治背景下被广泛部署，但现有治理体系往往忽视了非英语语境下的数据、用户群体和社会规范。这导致系统性风险，如对低资源语言的支持不足，以及治理机制与地方期望不符等问题。", "method": "本文基于跨文化视角的人机交互和AI治理研究，整合现有的多语言模型行为证据、数据不平等性和社会技术危害的文献资料，提出了一种新的治理体系框架。", "result": "该文识别了三个相互关联的治理挑战：训练数据中的文化和语言不公平、全球部署与当地规范的价值观及权力结构之间的错配以及对边缘化语言社区造成的伤害缺乏问责机制。", "conclusion": "本文强调文化本位的多语言AI治理对于防止大规模和中立性名义下的全球不平等至关重要。"}}
{"id": "2602.00496", "pdf": "https://arxiv.org/pdf/2602.00496", "abs": "https://arxiv.org/abs/2602.00496", "authors": ["Dana Feng", "Bhada Yun", "April Wang"], "title": "From Junior to Senior: Allocating Agency and Navigating Professional Growth in Agentic AI-Mediated Software Engineering", "categories": ["cs.HC", "cs.AI", "cs.SE"], "comment": "To appear in CHI'26", "summary": "Juniors enter as AI-natives, seniors adapted mid-career. AI is not just changing how engineers code-it is reshaping who holds agency across work and professional growth. We contribute junior-senior accounts on their usage of agentic AI through a three-phase mixed-methods study: ACTA combined with a Delphi process with 5 seniors, an AI-assisted debugging task with 10 juniors, and blind reviews of junior prompt histories by 5 more seniors. We found that agency in software engineering is primarily constrained by organizational policies rather than individual preferences, with experienced developers maintaining control through detailed delegation while novices struggle between over-reliance and cautious avoidance. Seniors leverage pre-AI foundational instincts to steer modern tools and possess valuable perspectives for mentoring juniors in their early AI-encouraged career development. From synthesis of results, we suggest three practices that focus on preserving agency in software engineering for coding, learning, and mentorship, especially as AI grows increasingly autonomous.", "AI": {"tldr": "该论文通过混合方法研究，探讨了不同经验水平的软件工程师如何在AI辅助下使用工具，并分析这些差异对个人职业发展的意义。", "motivation": "随着AI技术的发展，它不仅改变了编码方式，还重新定义了谁拥有工作和专业成长中的权力。本研究旨在探究新手与资深工程师在AI支持下的行为差异及其影响。", "method": "该论文采用三阶段混合方法，包括ACTA结合Delphi过程、AI辅助调试任务以及对新手指令历史的盲审。", "result": "研究表明，在软件工程中，个人权力主要受组织政策限制。资深开发者通过详细委托保持控制权，而新手则面临过度依赖或谨慎回避的问题。", "conclusion": "基于研究结果，论文建议了三项实践方法来保护编码、学习和导师角色中的自主性，尤其是在AI日益自治的情况下。"}}
{"id": "2602.00494", "pdf": "https://arxiv.org/pdf/2602.00494", "abs": "https://arxiv.org/abs/2602.00494", "authors": ["Hongyu Zhou", "Chia-An fan", "Yihao Dong", "Shuto Takashita", "Masahiko Inami", "Zhanna Sarsenbayeva", "Anusha Withana"], "title": "SRL Proxemics: Spatial Guidelines for Supernumerary Robotic Limbs in Near-Body Interactions", "categories": ["cs.HC"], "comment": "Accepted to CHI 2026. Version of Record: DOI 10.1145/3772318.3790532", "summary": "Wearable supernumerary robotic limbs (SRLs) sit at the intersection of human augmentation and embodied AI, transforming into extensions of the human body. However, their movements within the intimate near-body space raise unresolved challenges for perceived safety, user control, and trust. In this paper, we present results from a Wizard-of-Oz study (n=18), where participants completed near-body collaboration tasks with SRLs to explore these challenges. We collected qualitative data through think-aloud protocols and semi-structured interviews, complemented by physiological signals and post-task ratings. Findings indicate that greater autonomy did not inherently enhance perceived safety or trust. Instead, participants identified near-body zones and paired them with clear coordination rules. They also expressed expectations for how different arm components should behave, shaping preferences around autonomy, perceived safety, and trust. Building on these insights, we introduce SRL Proxemics, a zone- and segment-level design framework showing that autonomy is not monolithic: perceived safety hinges on spatially calibrated, legible behaviors, not higher autonomy.", "AI": {"tldr": "通过Wizard-of-Oz研究探讨了可穿戴超人肢体在近身互动中对感知安全和信任的影响，提出SRL Proxemics设计框架。", "motivation": "解决超人肢体在亲密空间内移动时面临的感知安全性、用户控制及信任问题。", "method": "通过Wizard-of-Oz研究（n=18），让参与者完成与SRL的近身协作任务。收集了定性数据，包括思维发声协议和半结构化访谈，并辅以生理信号和后任务评分。", "result": "发现更大的自主性并不一定提高感知安全性和信任感；参与者的期望影响不同臂组件的行为方式以及对自主性的偏好。", "conclusion": "SRL Proxemics是一个区段级别的设计框架，强调感知安全性依赖于空间校准、清晰行为而非更高的自主性。"}}
{"id": "2602.00493", "pdf": "https://arxiv.org/pdf/2602.00493", "abs": "https://arxiv.org/abs/2602.00493", "authors": ["Hongyu Zhou", "Xincheng Huang", "Winston Wijaya", "Yi Fei Cheng", "David Lindlbauer", "Eduardo Velloso", "Andrea Bianchi", "Zhanna Sarsenbayeva", "Anusha Withana"], "title": "One Body, Two Minds: Alternating VR Perspective During Remote Teleoperation of Supernumerary Limbs", "categories": ["cs.HC"], "comment": "Accepted to CHI 2026. Version of Record: DOI {10.1145/3772318.3791433", "summary": "Remote VR teleoperation with supernumerary robotic limbs enables distant users to operate in another's local space. While a shared first-person view aids hand-eye coordination, locking the guest's camera to the host's head can degrade comfort, embodiment, and coordination. Based on a formative study (N=10) using a virtual supernumerary robotic limbs configuration to stress-test coordination, we propose guest-driven perspective switching from a shared first-person baseline (Shared Embodied View) to two alternatives: (a) a stabilized view with guest-controlled rotation (Embedded Anchored View), and (b) a fully decoupled third-person view (Out-of-body View). We ran a user study with 24 pairs (N=48) who switched between the baseline and proposed views as task demands changed. We measured performance, embodiment, fatigue, physiological arousal, and switching behaviors. Our results reveal role-dependent trade-offs: Out-of-body View improves navigation efficiency and reduces errors, while Embedded Anchored View supports embodiment. We conclude with guidelines: use Embedded Anchored View for hand-centric adjustments, Out-of-body View for navigation and object placement, and ensure smooth transitions.", "AI": {"tldr": "研究探讨了远程VR遥操作中，用户视角切换对超常四肢协调的影响。", "motivation": "在共享第一人称视图下进行手眼协调时，锁定嘉宾的摄像头到主机头部会降低舒适度、实体感和协调性。因此需要探索不同视角切换方案以优化用户体验。", "method": "基于初步研究（N=10），提出了一种虚拟超常四肢配置并进行了压力测试。之后进行了24组用户研究（N=48）来评估基线视图与两种备选视角的性能、实体感、疲劳度和生理唤醒水平，以及切换行为。", "result": "结果表明角色相关的权衡：脱离体视图提高了导航效率并减少了错误；嵌入式锚定视图支持实体感。", "conclusion": "根据研究结果提出了使用建议：在手部调整时采用嵌入式锚定视角，在导航和物品放置时则选择脱离体视角，并确保平滑过渡。"}}
{"id": "2602.00492", "pdf": "https://arxiv.org/pdf/2602.00492", "abs": "https://arxiv.org/abs/2602.00492", "authors": ["Jeffrey P. Bigham"], "title": "HIDAgent: A Toolkit Enabling \"Personal Agents\" on HID-Compatible Devices", "categories": ["cs.HC"], "comment": null, "summary": "UI Agents powered by increasingly performant AI promise to eventually use computers the way that people do - by visually interpreting UIs on screen and issuing appropriate actions to control them (e.g., mouse clicks and keyboard entry). While significant progress has been made on interpreting visual UIs computationally, and in sequencing together steps to complete tasks, controlling UIs is still done with system-specific APIs or VNC connections, which limits the platforms and use cases that can be explored. This paper introduces HIDAgent, an open-source hardware/software toolkit enabling UI agents to operate HID-compatible computing systems by emulating the physical keyboard and mouse. HIDAgent is built using three off-the-shelf components costing less than $30 and a Python library supporting flexible integration. We validated the HIDAgent toolkit by building five diverse use case prototypes across mobile and desktop platforms. As a hardware device, HIDAgent supports research into new interaction scenarios where the agents are separated from the devices they control.", "AI": {"tldr": "HIDAgent是一个开源硬件/软件工具包，使UI代理能够在兼容HID的计算系统上通过模拟物理键盘和鼠标进行操作。", "motivation": "当前控制UI的方法受限于特定系统的API或VNC连接，这限制了可以探索的平台和用例。本文旨在介绍一种新方法以扩大研究范围，并支持新的交互场景。", "method": "使用三种成本低于30美元的现成组件以及一个灵活集成的Python库构建HIDAgent工具包，并通过五个跨移动和桌面平台的不同应用场景原型验证其有效性。", "result": "成功开发出HIDAgent，可以用于多种不同设备上的UI代理研究。", "conclusion": "HIDAgent为研究人员提供了一种有效的方法来探索新的交互场景，并支持代理与被控设备分离的研究。"}}
{"id": "2602.00490", "pdf": "https://arxiv.org/pdf/2602.00490", "abs": "https://arxiv.org/abs/2602.00490", "authors": ["Chia-Ming Lee", "Yu-Hao Ho", "Yu-Fan Lin", "Jen-Wei Lee", "Li-Wei Kang", "Chih-Chung Hsu"], "title": "HSSDCT: Factorized Spatial-Spectral Correlation for Hyperspectral Image Fusion", "categories": ["cs.CV"], "comment": "Accepted by ICASSP 2026", "summary": "Hyperspectral image (HSI) fusion aims to reconstruct a high-resolution HSI (HR-HSI) by combining the rich spectral information of a low-resolution HSI (LR-HSI) with the fine spatial details of a high-resolution multispectral image (HR-MSI). Although recent deep learning methods have achieved notable progress, they still suffer from limited receptive fields, redundant spectral bands, and the quadratic complexity of self-attention, which restrict both efficiency and robustness. To overcome these challenges, we propose the Hierarchical Spatial-Spectral Dense Correlation Network (HSSDCT). The framework introduces two key modules: (i) a Hierarchical Dense-Residue Transformer Block (HDRTB) that progressively enlarges windows and employs dense-residue connections for multi-scale feature aggregation, and (ii) a Spatial-Spectral Correlation Layer (SSCL) that explicitly factorizes spatial and spectral dependencies, reducing self-attention to linear complexity while mitigating spectral redundancy. Extensive experiments on benchmark datasets demonstrate that HSSDCT delivers superior reconstruction quality with significantly lower computational costs, achieving new state-of-the-art performance in HSI fusion. Our code is available at https://github.com/jemmyleee/HSSDCT.", "AI": {"tldr": "提出了一种名为Hierarchical Spatial-Spectral Dense Correlation Network (HSSDCT) 的网络，用于高光谱图像融合。", "motivation": "现有深度学习方法在处理高光谱图像融合时存在感受野有限、冗余光谱带和自注意力复杂度二次的问题。这些问题限制了效率和鲁棒性。", "method": "提出了一种HSSDCT框架，包含两个关键模块：Hierarchical Dense-Residue Transformer Block (HDRTB) 和 Spatial-Spectral Correlation Layer (SSCL)，前者通过密集残差连接进行多尺度特征聚合，后者将空间与光谱依赖关系显式解耦。", "result": "在基准数据集上的大量实验表明，HSSDCT实现了优越的重建质量并大幅降低了计算成本，达到了高光谱图像融合的新状态最先进水平。", "conclusion": "提出的HSSDCT通过优化模型结构和减少冗余性显著提高了高光谱图像融合的效果。"}}
{"id": "2602.00489", "pdf": "https://arxiv.org/pdf/2602.00489", "abs": "https://arxiv.org/abs/2602.00489", "authors": ["Sicong Zang", "Tao Sun", "Cairong Yan"], "title": "Refining Strokes by Learning Offset Attributes between Strokes for Flexible Sketch Edit at Stroke-Level", "categories": ["cs.CV"], "comment": "Source codes are coming soon", "summary": "Sketch edit at stroke-level aims to transplant source strokes onto a target sketch via stroke expansion or replacement, while preserving semantic consistency and visual fidelity with the target sketch. Recent studies addressed it by relocating source strokes at appropriate canvas positions. However, as source strokes could exhibit significant variations in both size and orientation, we may fail to produce plausible sketch editing results by merely repositioning them without further adjustments. For example, anchoring an oversized source stroke onto the target without proper scaling would fail to produce a semantically coherent outcome. In this paper, we propose SketchMod to refine the source stroke through transformation so as to align it with the target sketch's patterns, further realize flexible sketch edit at stroke-level. As the source stroke refinement is governed by the patterns of the target sketch, we learn three key offset attributes (scale, orientation and position) from the source stroke to another, and align it with the target by: 1) resizing to match spatial proportions by scale, 2) rotating to align with local geometry by orientation, and 3) displacing to meet with semantic layout by position. Besides, a stroke's profiles can be precisely controlled during sketch edit via the exposed captured stroke attributes. Experimental results indicate that SketchMod achieves precise and flexible performances on stroke-level sketch edit.", "AI": {"tldr": "本文提出了一种名为SketchMod的方法，通过学习源笔画和目标草图之间的偏移属性（包括尺度、方向和位置），实现灵活的以笔画级别为目标草图移植新笔画的任务。", "motivation": "在现有研究中，为了将一个草图中的源笔画移植到另一个目标草图上，主要依靠重新定位来完成。但是这种方法难以处理不同规模和角度的变化，导致无法产生具有语义一致性和视觉保真的编辑结果。", "method": "该方法通过学习三个关键偏移属性（尺寸、方向和位置）从一个源笔画到另一个，并通过缩放匹配空间比例、旋转以对齐局部几何形状以及位移以适应语义布局来实现目标草图的修改。此外，可以通过捕获的笔画属性精确控制编辑过程。", "result": "实验结果表明SketchMod在以笔画级别为目标草图移植新笔画的任务中实现了精准且灵活的表现。", "conclusion": "该研究提出了一种有效的方法用于实现以笔画级别进行准确且具有高度灵活性的目标草图修改。"}}
{"id": "2602.00485", "pdf": "https://arxiv.org/pdf/2602.00485", "abs": "https://arxiv.org/abs/2602.00485", "authors": ["Shule Lu", "Yujing Wang", "Hainan Zhang", "Xiaoshan Yang", "Hongwei Zheng", "Yongxin Tong", "Changsheng Xu", "Zhiming Zheng"], "title": "Replacing Parameters with Preferences: Federated Alignment of Heterogeneous Vision-Language Models", "categories": ["cs.AI"], "comment": null, "summary": "VLMs have broad potential in privacy-sensitive domains such as healthcare and finance, yet strict data-sharing constraints render centralized training infeasible. FL mitigates this issue by enabling decentralized training, but practical deployments face challenges due to client heterogeneity in computational resources, application requirements, and model architectures. We argue that while replacing data with model parameters characterizes the present of FL, replacing parameters with preferences represents a more scalable and privacy-preserving future. Motivated by this perspective, we propose MoR, a federated alignment framework based on GRPO with Mixture-of-Rewards for heterogeneous VLMs. MoR initializes a visual foundation model as a KL-regularized reference, while each client locally trains a reward model from local preference annotations, capturing specific evaluation signals without exposing raw data. To reconcile heterogeneous rewards, we introduce a routing-based fusion mechanism that adaptively aggregates client reward signals. Finally, the server performs GRPO with this mixed reward to optimize the base VLM. Experiments on three public VQA benchmarks demonstrate that MoR consistently outperforms federated alignment baselines in generalization, robustness, and cross-client adaptability. Our approach provides a scalable solution for privacy-preserving alignment of heterogeneous VLMs under federated settings.", "AI": {"tldr": "本文提出了一种基于混合奖励的联邦对齐框架MoR，用于异构视觉语言模型的隐私保护式对齐。", "motivation": "数据共享限制使得集中训练变得不可行，而联邦学习通过分散训练解决了这一问题。但是实际部署仍然面临计算资源、应用需求和模型架构异质性挑战，本文提出将参数替换为偏好作为更可扩展且隐私保护的方法。", "method": "MoR框架基于GRPO与混合奖励机制初始化视觉基础模型，并在客户端本地训练一个奖励模型以捕获特定评估信号。引入路由融合机制来综合不同客户端的奖励信号，在服务器端使用混合奖励进行GRPO优化。", "result": "实验结果表明，MoR相比联邦对齐基准方法在泛化性、鲁棒性和跨客户适应性方面表现更优。", "conclusion": "本文提供了针对异构视觉语言模型在联邦设置下的隐私保护式对齐的可扩展解决方案。"}}
{"id": "2602.00484", "pdf": "https://arxiv.org/pdf/2602.00484", "abs": "https://arxiv.org/abs/2602.00484", "authors": ["Rong-Lin Jian", "Ming-Chi Luo", "Chen-Wei Huang", "Chia-Ming Lee", "Yu-Fan Lin", "Chih-Chung Hsu"], "title": "GTATrack: Winner Solution to SoccerTrack 2025 with Deep-EIoU and Global Tracklet Association", "categories": ["cs.CV", "cs.MM"], "comment": "Winner Solution of SoccerTrack in ACM Multimedia 2025 Workshop MMSports", "summary": "Multi-object tracking (MOT) in sports is highly challenging due to irregular player motion, uniform appearances, and frequent occlusions. These difficulties are further exacerbated by the geometric distortion and extreme scale variation introduced by static fisheye cameras. In this work, we present GTATrack, a hierarchical tracking framework that win first place in the SoccerTrack Challenge 2025. GTATrack integrates two core components: Deep Expansion IoU (Deep-EIoU) for motion-agnostic online association and Global Tracklet Association (GTA) for trajectory-level refinement. This two-stage design enables both robust short-term matching and long-term identity consistency. Additionally, a pseudo-labeling strategy is used to boost detector recall on small and distorted targets. The synergy between local association and global reasoning effectively addresses identity switches, occlusions, and tracking fragmentation. Our method achieved a winning HOTA score of 0.60 and significantly reduced false positives to 982, demonstrating state-of-the-art accuracy in fisheye-based soccer tracking. Our code is available at https://github.com/ron941/GTATrack-STC2025.", "AI": {"tldr": "该论文提出了GTATrack框架，用于解决足球比赛中多目标跟踪问题。", "motivation": "足球比赛中的多目标跟踪由于球员不规则运动、外观相似和频繁遮挡等问题而极具挑战性。此外，静态鱼眼相机引入的几何失真和极端尺度变化进一步加大了难度。", "method": "GTATrack框架采用了两种核心组件：深度扩展交并比（Deep-EIoU）用于无运动依赖的在线关联以及全局轨迹关联（GTA）用于轨迹级别的细化。此外，使用伪标签策略来增强小目标和失真目标的检测器召回率。", "result": "该方法在SoccerTrack挑战赛2025中获得了HOTA得分为0.60，并将误报减少至982个，展示了鱼眼相机下足球跟踪领域的最先进精度。", "conclusion": "GTATrack框架通过局部关联和全局推理的协同作用有效地解决了身份切换、遮挡和跟踪碎片化的问题，证明了在解决体育赛事中多目标跟踪挑战方面的优越性。"}}
{"id": "2602.00483", "pdf": "https://arxiv.org/pdf/2602.00483", "abs": "https://arxiv.org/abs/2602.00483", "authors": ["Xihua Sheng", "Xiongzhuang Liang", "Chuanbo Tang", "Zhirui Zuo", "Yifan Bian", "Yutao Xie", "Zhuoyuan Li", "Yuqi Li", "Hui Xiang", "Li Li", "Dong Liu"], "title": "Recent Advances of End-to-End Video Coding Technologies for AVS Standard Development", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": null, "summary": "Video coding standards are essential to enable the interoperability and widespread adoption of efficient video compression technologies. In pursuit of greater video compression efficiency, the AVS video coding working group launched the standardization exploration of end-to-end intelligent video coding, establishing the AVS End-to-End Intelligent Video Coding Exploration Model (AVS-EEM) project. A core design principle of AVS-EEM is its focus on practical deployment, featuring inherently low computational complexity and requiring strict adherence to the common test conditions of conventional video coding. This paper details the development history of AVS-EEM and provides a systematic introduction to its key technical framework, covering model architectures, training strategies, and inference optimizations. These innovations have collectively driven the project's rapid performance evolution, enabling continuous and significant gains under strict complexity constraints. Through over two years of iterative refinement and collaborative effort, the coding performance of AVS-EEM has seen substantial improvement. Experimental results demonstrate that its latest model achieves superior compression efficiency compared to the conventional AVS3 reference software, marking a significant step toward a deployable intelligent video coding standard.", "AI": {"tldr": "本文介绍了AVS-EEM项目的发展历程及关键技术框架，包括模型架构、训练策略和推理优化。", "motivation": "为了提高视频压缩效率，AVS视频编码工作组启动了端到端智能视频编码标准化探索，致力于开发一个实用的部署方案，保持低计算复杂度，并严格遵守传统视频编码的通用测试条件。", "method": "详细介绍了AVS-EEM的关键技术框架，包括模型架构、训练策略和推理优化，通过两年多的迭代和完善，实现了性能的快速提升。", "result": "实验结果表明，最新的AVS-EEM模型在严格的复杂度约束下取得了显著的压缩效率提升，并优于传统的AVS3参考软件。", "conclusion": "这些创新使AVS-EEM项目向可部署的智能视频编码标准迈出了重要一步。"}}
{"id": "2602.00481", "pdf": "https://arxiv.org/pdf/2602.00481", "abs": "https://arxiv.org/abs/2602.00481", "authors": ["Danlin Zheng", "Xiaoying Wei", "Chao Liu", "Quanyu Zhang", "Jingling Zhang", "Shihui Duo", "Mingming Fan"], "title": "From Performers to Creators: Understanding Retired Women's Perceptions of Technology-Enhanced Dance Performance", "categories": ["cs.HC"], "comment": null, "summary": "Over 100 million retired women in China engage in dance, but their performances are constrained by limited resources and age-related decline. While interactive dance technologies can enhance artistic expression, existing systems are largely inaccessible to non-professional older dancers. This paper explores how interactive dance technologies can be designed with an age-sensitive approach to support retired women in enhancing their stage performance. We conducted two workshops with community-based retired women dancers, employing interactive dance and LLM-powered video generation probes in co-design activities. Findings indicate that age-sensitive adaptations, such as low-barrier keyword input, motion-aligned visual effects, and participatory scaffolds, lowered technical barriers and fostered a sense of authorship. These features enabled retired women to empower their stage, transitioning from passive recipients of stage design to empowered co-creators of performance. We outline design implications for incorporating interactive dance and artificial intelligence-generated content (AIGC) into the cultural practices of retired women, offering broader strategies for age-sensitive creative technologies.", "AI": {"tldr": "探讨如何通过互动舞蹈技术与年龄敏感设计来提升退休女性舞者的舞台表现。", "motivation": "中国有超过一亿的退休女性参与舞蹈，但她们的表演受限于资源不足和身体衰老。为了帮助这些非专业老年舞者克服技术障碍并增强艺术表达力，研究团队探索了适合老年人的互动舞蹈技术和人工智能生成内容的设计方法。", "method": "通过社区为基础的退休女性舞者的两场工作坊活动，运用交互式舞蹈和技术辅助视频生成探针，在共设计活动中进行深入探讨和实践。", "result": "发现了一些关键特征如低门槛关键词输入、动作同步视觉效果和参与性支撑结构等，可以降低技术壁垒并激发创作感。这些功能使退休女性能够增强其舞台表现，并从被动接受者转变为表演的共同创造者。", "conclusion": "这项研究提出了将互动舞蹈和技术生成内容融入退休妇女文化实践中的设计建议，为年龄敏感创意技术提供了更广泛的策略。"}}
{"id": "2602.00480", "pdf": "https://arxiv.org/pdf/2602.00480", "abs": "https://arxiv.org/abs/2602.00480", "authors": ["Mohini Priya Kolluri", "Ammar Waheed", "Zohaib Hasnain"], "title": "FISC: A Fluid-Inspired Framework for Decentralized and Scalable Swarm Control", "categories": ["cs.RO"], "comment": null, "summary": "Achieving scalable coordination in large robotic swarms is often constrained by reliance on inter-agent communication, which introduces latency, bandwidth limitations, and vulnerability to failure. To address this gap, a decentralized approach for outer-loop control of large multi-agent systems based on the paradigm of how a fluid moves through a volume is proposed and evaluated. A relationship between fundamental fluidic element properties and individual robotic agent states is developed such that the corresponding swarm \"flows\" through a space, akin to a fluid when forced via a pressure boundary condition. By ascribing fluid-like properties to subsets of agents, the swarm evolves collectively while maintaining desirable structure and coherence without explicit communication of agent states within or outside of the swarm. The approach is evaluated using simulations involving $O(10^3)$ quadcopter agents and compared against Computational Fluid Dynamics (CFD) solutions for a converging-diverging domain. Quantitative agreement between swarm-derived and CFD fields is assessed using Root-Mean-Square Error (RMSE), yielding normalized errors of 0.15-0.9 for velocity, 0.61-0.98 for density, 0-0.937 for pressure. These results demonstrate the feasibility of treating large robotic swarms as continuum systems that retain the macroscopic structure derived from first principles, providing a basis for scalable and decentralized control.", "AI": {"tldr": "提出了一种基于流体流动原理的分布式控制框架，用于大规模机器人群集协调。", "motivation": "解决大型多智能系统中由于依赖于代理间通信引入的延迟、带宽限制和故障易感性问题。", "method": "通过将机器人集群行为类比为流体在空间中的流动，并利用压力边界条件使集群像流体一样移动，开发了一种基于流体元素特性的分散式控制方法。", "result": "仿真结果表明，在涉及数千个四旋翼飞行器的场景中，所提方法与计算流体力学（CFD）解决方案之间存在良好的一致性。使用均方根误差（RMSE）评估了速度、密度和压力等参数的一致性，证明了该方法在处理大规模机器人集群时的有效性和可行性。", "conclusion": "通过将大型机器人群集视为连续系统并保留从基本原理推导出的宏观结构，提出的方法提供了一种可扩展且分散式的控制基础。"}}
{"id": "2602.00478", "pdf": "https://arxiv.org/pdf/2602.00478", "abs": "https://arxiv.org/abs/2602.00478", "authors": ["Xi Lin", "Ping Guo", "Yilu Liu", "Qingfu Zhang", "Jianyong Sun"], "title": "Quality-Diversity Optimization as Multi-Objective Optimization", "categories": ["cs.LG", "cs.AI", "cs.NE", "math.OC"], "comment": null, "summary": "The Quality-Diversity (QD) optimization aims to discover a collection of high-performing solutions that simultaneously exhibit diverse behaviors within a user-defined behavior space. This paradigm has stimulated significant research interest and demonstrated practical utility in domains including robot control, creative design, and adversarial sample generation. A variety of QD algorithms with distinct design principles have been proposed in recent years. Instead of proposing a new QD algorithm, this work introduces a novel reformulation by casting the QD optimization as a multi-objective optimization (MOO) problem with a huge number of optimization objectives. By establishing this connection, we enable the direct adoption of well-established MOO methods, particularly set-based scalarization techniques, to solve QD problems through a collaborative search process. We further provide a theoretical analysis demonstrating that our approach inherits theoretical guarantees from MOO while providing desirable properties for the QD optimization. Experimental studies across several QD applications confirm that our method achieves performance competitive with state-of-the-art QD algorithms.", "AI": {"tldr": "将质量多样性优化问题重新定义为一个多目标优化问题，采用集合基标量化技术解决该类问题。", "motivation": "通过建立质量多样性优化与多目标优化之间的联系，可以直接利用成熟的多目标优化方法来求解质量多样性问题，并提供理论分析以证明这种方法的可行性。", "method": "提出一种将质量多样性优化重新表述为具有大量优化目标的多目标优化问题的方法，使用集合基标量化技术进行协作搜索。", "result": "实验研究证实该方法在多个质量多样性应用中的性能可与当前最先进的质量多样性算法相媲美。", "conclusion": "该工作通过将质量多样性优化问题重新表述为多目标优化问题，并利用成熟的技术解决了它，实现了高效且多样化的解决方案。"}}
{"id": "2602.00475", "pdf": "https://arxiv.org/pdf/2602.00475", "abs": "https://arxiv.org/abs/2602.00475", "authors": ["Michael Psenka", "Michael Rabbat", "Aditi Krishnapriyan", "Yann LeCun", "Amir Bar"], "title": "Parallel Stochastic Gradient-Based Planning for World Models", "categories": ["cs.LG", "cs.RO"], "comment": "23 pages, 7 figures", "summary": "World models simulate environment dynamics from raw sensory inputs like video. However, using them for planning can be challenging due to the vast and unstructured search space. We propose a robust and highly parallelizable planner that leverages the differentiability of the learned world model for efficient optimization, solving long-horizon control tasks from visual input. Our method treats states as optimization variables (\"virtual states\") with soft dynamics constraints, enabling parallel computation and easier optimization. To facilitate exploration and avoid local optima, we introduce stochasticity into the states. To mitigate sensitive gradients through high-dimensional vision-based world models, we modify the gradient structure to descend towards valid plans while only requiring action-input gradients. Our planner, which we call GRASP (Gradient RelAxed Stochastic Planner), can be viewed as a stochastic version of a non-condensed or collocation-based optimal controller. We provide theoretical justification and experiments on video-based world models, where our resulting planner outperforms existing planning algorithms like the cross-entropy method (CEM) and vanilla gradient-based optimization (GD) on long-horizon experiments, both in success rate and time to convergence.", "AI": {"tldr": "提出了一种新的并行随机梯度优化规划器GRASP，用于解决基于视频的世界模型的长时控制任务。", "motivation": "利用学习到的世界模型进行规划面临搜索空间庞大且结构化差的问题。现有方法难以处理高维视觉输入带来的敏感梯度问题。", "method": "通过引入虚拟状态并增加随机性来实现高效的优化和探索，同时修改了梯度下降结构以克服高维视觉世界的挑战。", "result": "GRASP在视频世界模型上优于CEM和GD方法，表现出更高的成功率和更快的收敛速度。", "conclusion": "GRASP作为一种新颖且强大的规划器，在解决基于视觉输入的世界模型中的长时控制任务方面具有显著优势。"}}
{"id": "2602.00473", "pdf": "https://arxiv.org/pdf/2602.00473", "abs": "https://arxiv.org/abs/2602.00473", "authors": ["Jin-Long Chen", "Xin Li", "Zhang-Qi Yin"], "title": "Quantum Phase Recognition via Quantum Attention Mechanism", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "10 pages, 7 figures", "summary": "Quantum phase transitions in many-body systems are fundamentally characterized by complex correlation structures, which pose computational challenges for conventional methods in large systems. To address this, we propose a hybrid quantum-classical attention model. This model uses an attention mechanism, realized through swap tests and a parameterized quantum circuit, to extract correlations within quantum states and perform ground-state classification. Benchmarked on the cluster-Ising model with system sizes of 9 and 15 qubits, the model achieves high classification accuracy with less than 100 training data and demonstrates robustness against variations in the training set. Further analysis reveals that the model successfully captures phase-sensitive features and characteristic physical length scales, offering a scalable and data-efficient approach for quantum phase recognition in complex many-body systems.", "AI": {"tldr": "通过量子注意力机制在复杂的多体系统中实现量子相位识别。", "motivation": "解决传统方法在大型复杂系统中的计算挑战，开发一种有效的方法来识别量子相变。", "method": "提出了一种混合的量子-经典注意模型，利用交换测试和参数化量子电路提取量子态间的相关性，并进行基态分类。", "result": "通过集群伊辛模型验证了该模型的有效性和鲁棒性，在9和15个量子比特系统中实现了高精度的相位分类。", "conclusion": "所提出的注意力机制为复杂多体系统的量子相位识别提供了一种可扩展且数据高效的方法。"}}
{"id": "2602.00471", "pdf": "https://arxiv.org/pdf/2602.00471", "abs": "https://arxiv.org/abs/2602.00471", "authors": ["Xinlei Yu", "Chengming Xu", "Zhangquan Chen", "Bo Yin", "Cheng Yang", "Yongbo He", "Yihao Hu", "Jiangning Zhang", "Cheng Tan", "Xiaobin Hu", "Shuicheng Yan"], "title": "Dual Latent Memory for Visual Multi-agent System", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "While Visual Multi-Agent Systems (VMAS) promise to enhance comprehensive abilities through inter-agent collaboration, empirical evidence reveals a counter-intuitive \"scaling wall\": increasing agent turns often degrades performance while exponentially inflating token costs. We attribute this failure to the information bottleneck inherent in text-centric communication, where converting perceptual and thinking trajectories into discrete natural language inevitably induces semantic loss. To this end, we propose L$^{2}$-VMAS, a novel model-agnostic framework that enables inter-agent collaboration with dual latent memories. Furthermore, we decouple the perception and thinking while dynamically synthesizing dual latent memories. Additionally, we introduce an entropy-driven proactive triggering that replaces passive information transmission with efficient, on-demand memory access. Extensive experiments among backbones, sizes, and multi-agent structures demonstrate that our method effectively breaks the \"scaling wall\" with superb scalability, improving average accuracy by 2.7-5.4% while reducing token usage by 21.3-44.8%. Codes: https://github.com/YU-deep/L2-VMAS.", "AI": {"tldr": "本文提出了一种新的模型无关框架L²-VMAS，通过双隐式记忆系统解决了视觉多代理系统的瓶颈问题。", "motivation": "在增加代理数量时，基于文本的通信会导致性能下降和成本上升的问题。原因是感知和思考信息转化成离散自然语言过程中会产生语义损失。", "method": "提出了一种模型无关框架L²-VMAS，通过双隐式记忆系统实现多代理之间的协作，并动态合成感知与思维分离后的双重隐式记忆。", "result": "实验表明该方法在提高准确率的同时减少了令牌使用量，在不同模型、规模和多代理结构中表现出了优秀的可扩展性。", "conclusion": "L²-VMAS有效地解决了视觉多代理系统的瓶颈问题，提高了性能并减少了成本。"}}
{"id": "2602.00470", "pdf": "https://arxiv.org/pdf/2602.00470", "abs": "https://arxiv.org/abs/2602.00470", "authors": ["Pengyu Chen", "Fangzheng Lyu", "Sicheng Wang", "Cuizhen Wang"], "title": "ZS-TreeSeg: A Zero-Shot Framework for Tree Crown Instance Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Individual tree crown segmentation is an important task in remote sensing for forest biomass estimation and ecological monitoring. However, accurate delineation in dense, overlapping canopies remains a bottleneck. While supervised deep learning methods suffer from high annotation costs and limited generalization, emerging foundation models (e.g., Segment Anything Model) often lack domain knowledge, leading to under-segmentation in dense clusters. To bridge this gap, we propose ZS-TreeSeg, a Zero-Shot framework that adapts from two mature tasks: 1) Canopy Semantic segmentation; and 2) Cells instance segmentation. By modeling tree crowns as star-convex objects within a topological flow field using Cellpose-SAM, the ZS-TreeSeg framework forces the mathematical separation of touching tree crown instances based on vector convergence. Experiments on the NEON and BAMFOREST datasets and visual inspection demonstrate that our framework generalizes robustly across diverse sensor types and canopy densities, which can offer a training-free solution for tree crown instance segmentation and labels generation.", "AI": {"tldr": "提出了一种零样本框架ZS-TreeSeg用于树冠实例分割，该框架通过结合两个成熟任务来解决密集、重叠树冠的准确划分问题。", "motivation": "传统监督深度学习方法需要高昂标注成本和有限泛化能力；新兴基础模型缺乏领域知识，在密集簇中往往出现欠分割现象。", "method": "ZS-TreeSeg框架通过将树冠建模为星凸物体，并使用Cellpose-SAM在拓扑流场内强制数学分离接触的树冠实例，基于向量收敛性进行处理。", "result": "实验表明该方法在NEON和BAMFOREST数据集上能够泛化到不同传感器类型及密集程度，提供无训练解决方案用于树冠实例分割与标签生成。", "conclusion": "ZS-TreeSeg框架解决了树冠实例分割中的挑战性问题，在多种场景下展现出良好性能。"}}
{"id": "2602.00469", "pdf": "https://arxiv.org/pdf/2602.00469", "abs": "https://arxiv.org/abs/2602.00469", "authors": ["Abhinav Gupta", "Toben H. Mintz", "Jesse Thomason"], "title": "Words that make SENSE: Sensorimotor Norms in Learned Lexical Token Representations", "categories": ["cs.CL", "cs.AI"], "comment": "5 pages, 2 figures, codebase can be found at: https://github.com/abhinav-usc/SENSE-model/tree/main", "summary": "While word embeddings derive meaning from co-occurrence patterns, human language understanding is grounded in sensory and motor experience. We present $\\text{SENSE}$ $(\\textbf{S}\\text{ensorimotor }$ $\\textbf{E}\\text{mbedding }$ $\\textbf{N}\\text{orm }$ $\\textbf{S}\\text{coring }$ $\\textbf{E}\\text{ngine})$, a learned projection model that predicts Lancaster sensorimotor norms from word lexical embeddings. We also conducted a behavioral study where 281 participants selected which among candidate nonce words evoked specific sensorimotor associations, finding statistically significant correlations between human selection rates and $\\text{SENSE}$ ratings across 6 of the 11 modalities. Sublexical analysis of these nonce words selection rates revealed systematic phonosthemic patterns for the interoceptive norm, suggesting a path towards computationally proposing candidate phonosthemes from text data.", "AI": {"tldr": "本文提出了SENSE模型，该模型从词嵌入中预测兰卡斯特感官运动规范，并通过行为研究验证了模型的有效性。", "motivation": "人类语言理解基于感觉和运动经验，而不仅仅是词汇共现模式。因此，作者旨在开发一种方法来捕捉这种感官-运动关联并将其融入到文本处理任务中。", "method": "提出了一种名为SENSE的模型，该模型预测兰卡斯特传感器嵌入从词嵌入，并通过行为研究验证了其有效性的方法，让参与者选择能够唤起特定感觉或运动联想的非现成词语。", "result": "实验结果显示，在11种模态中，有6种在人类选择率和SENSE评分之间存在统计显著的相关性。此外，对这些非现成词的选择率进行音节分析揭示了内感受规范中的系统音节模式。", "conclusion": "该研究证明了通过词汇嵌入预测感官运动规范的可行性，并展示了这种方法在识别潜在的语言声音标记方面的潜力。"}}
{"id": "2602.00466", "pdf": "https://arxiv.org/pdf/2602.00466", "abs": "https://arxiv.org/abs/2602.00466", "authors": ["Reiji Terunuma", "Yuta Nakamura", "Takuma Abe", "Takeshi Hatanaka"], "title": "Stealthy Coverage Control for Human-enabled Real-Time 3D Reconstruction", "categories": ["eess.SY", "cs.RO"], "comment": "This work has been submitted to the 23rd IFAC World Congress for possible publication", "summary": "In this paper, we propose a novel semi-autonomous image sampling strategy, called stealthy coverage control, for human-enabled 3D structure reconstruction. The present mission involves a fundamental problem: while the number of images required to accurately reconstruct a 3D model depends on the structural complexity of the target scene to be reconstructed, it is not realistic to assume prior knowledge of the spatially non-uniform structural complexity. We approach this issue by leveraging human flexible reasoning and situational recognition capabilities. Specifically, we design a semi-autonomous system that leaves identification of regions that need more images and navigation of the drones to such regions to a human operator. To this end, we first present a way to reflect the human intention in autonomous coverage control. Subsequently, in order to avoid operational conflicts between manual control and autonomous coverage control, we develop the stealthy coverage control that decouples the drone motion for efficient image sampling from navigation by the human. Simulation studies on a Unity/ROS2-based simulator demonstrate that the present semi-autonomous system outperforms the one without human interventions in the sense of the reconstructed model quality.", "AI": {"tldr": "本文提出了一种称为“隐蔽覆盖控制”的新型半自主图像采样策略，用于人类辅助的实时三维重建。", "motivation": "在进行三维模型重建时，所需的图像数量取决于被建模场景的空间复杂性。然而，在没有先验知识的情况下，很难准确估计这种非均匀分布的空间复杂性。为了解决这个问题，本文引入了一种结合人类灵活推理和情境识别能力的半自主系统。", "method": "设计了一种将人意愿融入自主覆盖控制的方法，并开发了“隐蔽覆盖控制”技术以解决手动操作与自动覆盖控制之间的操作冲突问题。该方法通过一个Unity/ROS2基于的模拟器进行了验证。", "result": "仿真研究显示，带有隐蔽覆盖控制的半自主系统在重建模型的质量方面优于没有人类干预的情况。", "conclusion": "本文提出的半自主图像采样策略能够有效提高三维结构重建的质量。"}}
{"id": "2602.00465", "pdf": "https://arxiv.org/pdf/2602.00465", "abs": "https://arxiv.org/abs/2602.00465", "authors": ["Jiaqi Yin", "Baiming Chen", "Jia Fei", "Mingjun Yang"], "title": "PAIR-Former: Budgeted Relational MIL for miRNA Target Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint. Under review. During the preprint stage, inquiries and feedback can be directed to Jiaqi Yin (yjqhit@gmail.com)", "summary": "Functional miRNA--mRNA targeting is a large-bag prediction problem: each transcript yields a heavy-tailed pool of candidate target sites (CTSs), yet only a pair-level label is observed. We formalize this regime as \\emph{Budgeted Relational Multi-Instance Learning (BR-MIL)}, where at most $K$ instances per bag may receive expensive encoding and relational processing under a hard compute budget. We propose \\textbf{PAIR-Former} (Pool-Aware Instance-Relational Transformer), a BR-MIL pipeline that performs a cheap full-pool scan, selects up to $K$ diverse CTSs on CPU, and applies a permutation-invariant Set Transformer aggregator on the selected tokens. On miRAW, PAIR-Former outperforms strong pooling baselines at a practical operating budget ($K^\\star{=}64$) while providing a controllable accuracy--compute trade-off as $K$ varies. We further provide theory linking budgeted selection to (i) approximation error decreasing with $K$ and (ii) generalization terms governed by $K$ in the expensive relational component.", "AI": {"tldr": "PAIR-Former是一种用于预测miRNA靶标位置的预算关系多实例学习方法。", "motivation": "在功能性miRNA-mRNA结合中，每个转录本会产生大量候选目标位点（CTS），但仅观察到一对标签。为了在这种大规模问题中有效处理数据，作者提出了一种新的计算模型来优化昂贵的关系处理和编码过程的预算。", "method": "PAIR-Former首先进行廉价的整体池扫描，然后在CPU上选择最多K个多样化的候选目标位点，并应用一个不变性的集合变换器聚合所选令牌。", "result": "在miRAW数据集上的实验表明，PAIR-Former在实际操作预算下（K=64）优于强大的池化基线，并提供了可控的准确性-计算权衡。", "conclusion": "研究通过理论分析展示了预算选择与近似误差减少之间的联系以及昂贵的关系组件中的泛化项受K值影响。"}}
{"id": "2602.00464", "pdf": "https://arxiv.org/pdf/2602.00464", "abs": "https://arxiv.org/abs/2602.00464", "authors": ["Zebo Xu", "Steven Langsford", "Zhuang Qiu", "Zhenguang Cai"], "title": "A 30-item Test for Assessing Chinese Character Amnesia in Child Handwriters", "categories": ["q-bio.QM", "cs.CV"], "comment": null, "summary": "Handwriting literacy is an important skill for learning and communication in school-age children. In the digital age, handwriting has been largely replaced by typing, leading to a decline in handwriting proficiency, particularly in non-alphabetic writing systems. Among children learning Chinese, a growing number have reported experiencing character amnesia: difficulty in correctly handwriting a character despite being able to recognize it. Given that there is currently no standardized diagnostic tool for assessing character amnesia in children, we developed an assessment to measure Chinese character amnesia in Mandarin-speaking school-age population. We utilised a large-scale handwriting dataset in which 40 children handwrote 800 characters from dictation prompts. Character amnesia and correct handwriting responses were analysed using a two-parameter Item Response Theory model. Four item-selection schemes were compared: random baseline, maximum discrimination, diverse difficulty, and an upper-and-lower-thirds discrimination score. Candidate item subsets were evaluated using out-of-sample prediction. Among these selection schemes, the upper-and-lower-thirds discrimination procedure yields a compact 30-item test that preserves individual-difference structure and generalizes to unseen test-takers (cross-validated mean r =.74 with full 800-item-test; within-sample r =.93). This short-form test provides a reliable and efficient tool of assessing Chinese character amnesia in children and can be used to identify early handwriting and orthographic learning difficulties, contributing to the early detection of developmental dysgraphia and related literacy challenges.", "AI": {"tldr": "开发了一种评估儿童汉字遗忘症的标准化工具。", "motivation": "在数字化时代，手写技能下降，特别是在非字母文字系统中。为了准确诊断和了解汉字遗忘症对汉语儿童书写能力的影响，需要一个标准化评估工具。", "method": "利用大规模的手写数据集分析了800个字符的书写情况，并通过项目响应理论模型筛选出最优的30项测试题目。", "result": "上中下三分位数差异选择方案生成了一个有效的30题测试，该测试能够可靠地评估儿童汉字遗忘症（交叉验证后相关系数为.74）。", "conclusion": "这一短形式测试是可靠的工具，可以有效识别早期书写和拼写学习困难，有助于早期发现发育性书写障碍和其他阅读挑战。"}}
{"id": "2602.00463", "pdf": "https://arxiv.org/pdf/2602.00463", "abs": "https://arxiv.org/abs/2602.00463", "authors": ["Xin Zhang", "Shen Chen", "Jiale Zhou", "Lei Li"], "title": "PSGS: Text-driven Panorama Sliding Scene Generation via Gaussian Splatting", "categories": ["cs.CV"], "comment": "Accepted to ICASSP2026", "summary": "Generating realistic 3D scenes from text is crucial for immersive applications like VR, AR, and gaming. While text-driven approaches promise efficiency, existing methods suffer from limited 3D-text data and inconsistent multi-view stitching, resulting in overly simplistic scenes. To address this, we propose PSGS, a two-stage framework for high-fidelity panoramic scene generation. First, a novel two-layer optimization architecture generates semantically coherent panoramas: a layout reasoning layer parses text into structured spatial relationships, while a self-optimization layer refines visual details via iterative MLLM feedback. Second, our panorama sliding mechanism initializes globally consistent 3D Gaussian Splatting point clouds by strategically sampling overlapping perspectives. By incorporating depth and semantic coherence losses during training, we greatly improve the quality and detail fidelity of rendered scenes. Our experiments demonstrate that PSGS outperforms existing methods in panorama generation and produces more appealing 3D scenes, offering a robust solution for scalable immersive content creation.", "AI": {"tldr": "PSGS通过高保真全景场景生成，从文本中创建逼真的3D场景。", "motivation": "当前基于文本的方法受限于三维数据的不足和不一致的多视图拼接技术，导致生成的场景过于简单。因此提出了一种两阶段框架来解决这些问题。", "method": "PSGS采用两个优化层：布局推理层将文本解析为结构化的空间关系，自我优化层通过迭代MLLM反馈细化视觉细节；其次，它使用全景滑动机制初始化全局一致的3D高斯点云。", "result": "实验结果表明，PSGS在全景生成方面优于现有方法，并且能够创造出更吸引人的3D场景。", "conclusion": "PSGS提供了一个有效的解决方案来创建可扩展的沉浸式内容。"}}
{"id": "2602.00462", "pdf": "https://arxiv.org/pdf/2602.00462", "abs": "https://arxiv.org/abs/2602.00462", "authors": ["Benno Krojer", "Shravan Nayak", "Oscar Mañas", "Vaibhav Adlakha", "Desmond Elliott", "Siva Reddy", "Marius Mosbach"], "title": "LatentLens: Revealing Highly Interpretable Visual Tokens in LLMs", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Transforming a large language model (LLM) into a Vision-Language Model (VLM) can be achieved by mapping the visual tokens from a vision encoder into the embedding space of an LLM. Intriguingly, this mapping can be as simple as a shallow MLP transformation. To understand why LLMs can so readily process visual tokens, we need interpretability methods that reveal what is encoded in the visual token representations at every layer of LLM processing. In this work, we introduce LatentLens, a novel approach for mapping latent representations to descriptions in natural language. LatentLens works by encoding a large text corpus and storing contextualized token representations for each token in that corpus. Visual token representations are then compared to their contextualized textual representations, with the top-k nearest neighbor representations providing descriptions of the visual token. We evaluate this method on 10 different VLMs, showing that commonly used methods, such as LogitLens, substantially underestimate the interpretability of visual tokens. With LatentLens instead, the majority of visual tokens are interpretable across all studied models and all layers. Qualitatively, we show that the descriptions produced by LatentLens are semantically meaningful and provide more fine-grained interpretations for humans compared to individual tokens. More broadly, our findings contribute new evidence on the alignment between vision and language representations, opening up new directions for analyzing latent representations.", "AI": {"tldr": "LatentLens 是一种将视觉令牌映射为自然语言描述的方法，用于理解大规模语言模型处理视觉令牌的能力。", "motivation": "为了理解大型语言模型为何能够处理视觉令牌，需要开发可解释性方法来揭示每层模型的视觉令牌表示中的内容。", "method": "LatentLens 方法通过将大量文本语料库编码并存储上下文化的词元表示来工作。然后将视觉令牌表示与这些文本表示进行比较，并选择最近邻的 k 个表示作为描述。", "result": "该方法在10种不同 VLM 上进行了评估，显示常见方法低估了可视令牌的可解释性。LatentLens 方法下大多数可视令牌都具有可解释性。", "conclusion": "LatentLens 提供了对视觉和语言表示之间对齐的新证据，并为分析潜在表示提供了新方向。"}}
{"id": "2602.00458", "pdf": "https://arxiv.org/pdf/2602.00458", "abs": "https://arxiv.org/abs/2602.00458", "authors": ["Omer Haq"], "title": "LatentTrack: Sequential Weight Generation via Latent Filtering", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "comment": null, "summary": "We introduce LatentTrack (LT), a sequential neural architecture for online probabilistic prediction under nonstationary dynamics. LT performs causal Bayesian filtering in a low-dimensional latent space and uses a lightweight hypernetwork to generate predictive model parameters at each time step, enabling constant-time online adaptation without per-step gradient updates. At each time step, a learned latent model predicts the next latent distribution, which is updated via amortized inference using new observations, yielding a predict--generate--update filtering framework in function space. The formulation supports both structured (Markovian) and unstructured latent dynamics within a unified objective, while Monte Carlo inference over latent trajectories produces calibrated predictive mixtures with fixed per-step cost. Evaluated on long-horizon online regression using the Jena Climate benchmark, LT consistently achieves lower negative log-likelihood and mean squared error than stateful sequential and static uncertainty-aware baselines, with competitive calibration, demonstrating that latent-conditioned function evolution is an effective alternative to traditional latent-state modeling under distribution shift.", "AI": {"tldr": "介绍了一种名为LatentTrack的在线概率预测方法，适用于非平稳动态系统。", "motivation": "为了实现常数时间在线适应，在每一步无需进行梯度更新的情况下提出一种新的序列神经架构。", "method": "使用轻量级超网络在每个时间步生成预测模型参数，并通过学习到的潜在模型预测下一个潜在分布，利用新观测数据进行近似推理，形成了预测、生成和更新的过滤框架。", "result": "在Jena气候基准上的长期在线回归任务中，LT实现了比状态序列及静态不确定性感知基线更低的负对数似然值和均方误差。", "conclusion": "潜在条件下的函数演化是处理分布变化的一种有效方法，能够提供具有固定每步成本的校准预测混合物。"}}
{"id": "2602.00456", "pdf": "https://arxiv.org/pdf/2602.00456", "abs": "https://arxiv.org/abs/2602.00456", "authors": ["Amanda Dsouza", "Ramya Ramakrishnan", "Charles Dickens", "Bhavishya Pohani", "Christopher M Glaze"], "title": "Benchmarking Agents in Insurance Underwriting Environments", "categories": ["cs.AI"], "comment": null, "summary": "As AI agents integrate into enterprise applications, their evaluation demands benchmarks that reflect the complexity of real-world operations. Instead, existing benchmarks overemphasize open-domains such as code, use narrow accuracy metrics, and lack authentic complexity. We present UNDERWRITE, an expert-first, multi-turn insurance underwriting benchmark designed in close collaboration with domain experts to capture real-world enterprise challenges. UNDERWRITE introduces critical realism factors often absent in current benchmarks: proprietary business knowledge, noisy tool interfaces, and imperfect simulated users requiring careful information gathering. Evaluating 13 frontier models, we uncover significant gaps between research lab performance and enterprise readiness: the most accurate models are not the most efficient, models hallucinate domain knowledge despite tool access, and pass^k results show a 20% drop in performance. The results from UNDERWRITE demonstrate that expert involvement in benchmark design is essential for realistic agent evaluation, common agentic frameworks exhibit brittleness that skews performance reporting, and hallucination detection in specialized domains demands compositional approaches. Our work provides insights for developing benchmarks that better align with enterprise deployment requirements.", "AI": {"tldr": "本文提出了UNDERWRITE，一个基于保险承保环境的真实企业挑战基准测试，用于评估AI代理的性能。", "motivation": "现有基准过度强调开放领域的准确性，并缺乏真实世界复杂性。需要一个新的基准来更好地反映企业的实际需求和挑战。", "method": "通过与领域专家合作设计了一个多回合、基于真实业务知识的保险承保环境基准测试，评估了13个前沿模型的表现。", "result": "研究发现最准确的模型并不总是最有效的，并且AI模型在访问工具的情况下仍会产生错误的知识。此外，性能报告存在偏差。", "conclusion": "专家参与基准设计对于真实代理评估至关重要，通用代理框架表现出脆弱性，需要采用组合方法来检测特定领域的幻觉。"}}
{"id": "2602.00454", "pdf": "https://arxiv.org/pdf/2602.00454", "abs": "https://arxiv.org/abs/2602.00454", "authors": ["Jing Wu", "Yue Sun", "Tianpei Xie", "Suiyao Chen", "Jingyuan Bao", "Yaopengxiao Xu", "Gaoyuan Du", "Inseok Heo", "Alexander Gutfraind", "Xin Wang"], "title": "Cross-Modal Memory Compression for Efficient Multi-Agent Debate", "categories": ["cs.AI"], "comment": null, "summary": "Multi-agent debate can improve reasoning quality and reduce hallucinations, but it incurs rapidly growing context as debate rounds and agent count increase. Retaining full textual histories leads to token usage that can exceed context limits and often requires repeated summarization, adding overhead and compounding information loss. We introduce DebateOCR, a cross-modal compression framework that replaces long textual debate traces with compact image representations, which are then consumed through a dedicated vision encoder to condition subsequent rounds. This design compresses histories that commonly span tens to hundreds of thousands of tokens, cutting input tokens by more than 92% and yielding substantially lower compute cost and faster inference across multiple benchmarks. We further provide a theoretical perspective showing that diversity across agents supports recovery of omitted information: although any single compressed history may discard details, aggregating multiple agents' compressed views allows the collective representation to approach the information bottleneck with exponentially high probability.", "AI": {"tldr": "论文提出DebateOCR框架，用于在多代理辩论中通过图像表示压缩长文本历史记录以减少上下文大小和计算成本。", "motivation": "多代理辩论可以提高推理质量并减少幻觉现象，但随着回合数和代理数量的增加，上下文会迅速增长。保持完整的文本历史会导致令牌使用超过上下文限制，并需要重复总结，这增加了开销并加剧了信息丢失。", "method": "DebateOCR通过将长文本辩论轨迹替换为紧凑的图像表示来实现跨模态压缩框架，然后通过专用视觉编码器消费这些图像表示以条件后续回合。这种方法可以显著减少输入令牌的数量并降低计算成本。", "result": "该方法可以在多个基准上将输入令牌数量削减92%以上，并且计算成本和推理速度都得到了改善。", "conclusion": "DebateOCR框架不仅降低了计算成本，而且通过聚合多个代理的压缩视图来恢复丢失的信息。"}}
{"id": "2602.00450", "pdf": "https://arxiv.org/pdf/2602.00450", "abs": "https://arxiv.org/abs/2602.00450", "authors": ["Ethan Anderson", "Justin Silva", "Kyle Zheng", "Sameer Pusegaonkar", "Yizhou Wang", "Zheng Tang", "Sujit Biswas"], "title": "Model Optimization for Multi-Camera 3D Detection and Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Outside-in multi-camera perception is increasingly important in indoor environments, where networks of static cameras must support multi-target tracking under occlusion and heterogeneous viewpoints. We evaluate Sparse4D, a query-based spatiotemporal 3D detection and tracking framework that fuses multi-view features in a shared world frame and propagates sparse object queries via instance memory. We study reduced input frame rates, post-training quantization (INT8 and FP8), transfer to the WILDTRACK benchmark, and Transformer Engine mixed-precision fine-tuning. To better capture identity stability, we report Average Track Duration (AvgTrackDur), which measures identity persistence in seconds. Sparse4D remains stable under moderate FPS reductions, but below 2 FPS, identity association collapses even when detections are stable. Selective quantization of the backbone and neck offers the best speed-accuracy trade-off, while attention-related modules are consistently sensitive to low precision. On WILDTRACK, low-FPS pretraining yields large zero-shot gains over the base checkpoint, while small-scale fine-tuning provides limited additional benefit. Transformer Engine mixed precision reduces latency and improves camera scalability, but can destabilize identity propagation, motivating stability-aware validation.", "AI": {"tldr": "该论文提出了Sparse4D框架，用于多摄像机环境下的三维检测与跟踪，并探讨了输入帧率减少、量化和混合精度训练等优化策略。", "motivation": "在室内环境中，网络摄像头需要支持多人目标追踪并处理遮挡和不同视角的问题。本文动机是通过优化算法提高多相机系统中的3D检测和追踪性能。", "method": "Sparse4D框架结合了多视图特征融合、时空三维检测与跟踪以及基于实例记忆的稀疏对象查询传播。研究包括减少输入帧速率，量化后训练（INT8 和 FP8），迁移学习到WILDTRACK基准测试集，并使用Transformer Engine进行混合精度微调。", "result": "Sparse4D在中等FPS降低时保持稳定性；选择性地对主干和颈部模块进行量化提供了最佳的速度与准确性平衡。预训练模型可获得显著的零样本收益，而小规模微调贡献有限。", "conclusion": "Sparse4D框架实现了较好的性能优化。减少输入帧率、混合精度训练等策略提高了系统效率和摄像头扩展性，但对身份传播稳定性有影响，需进一步验证其鲁棒性。"}}
{"id": "2602.00449", "pdf": "https://arxiv.org/pdf/2602.00449", "abs": "https://arxiv.org/abs/2602.00449", "authors": ["Jia Liang", "Liangming Pan"], "title": "Do Latent-CoT Models Think Step-by-Step? A Mechanistic Study on Sequential Reasoning Tasks", "categories": ["cs.AI", "cs.LG"], "comment": "20 pages, 14 figures", "summary": "Latent Chain-of-Thought (Latent-CoT) aims to enable step-by-step computation without emitting long rationales, yet its mechanisms remain unclear. We study CODI, a continuous-thought teacher-student distillation model, on strictly sequential polynomial-iteration tasks. Using logit-lens decoding, linear probes, attention analysis, and activation patching, we localize intermediate-state representations and trace their routing to the final readout. On two- and three-hop tasks, CODI forms the full set of bridge states that become decodable across latent-thought positions, while the final input follows a separate near-direct route; predictions arise via late fusion at the end-of-thought boundary. For longer hop lengths, CODI does not reliably execute a full latent rollout, instead exhibiting a partial latent reasoning path that concentrates on late intermediates and fuses them with the last input at the answer readout position. Ablations show that this partial pathway can collapse under regime shifts, including harder optimization. Overall, we delineate when CODI-style latent-CoT yields faithful iterative computation versus compressed or shortcut strategies, and highlight challenges in designing robust latent-CoT objectives for sequential reasoning.", "AI": {"tldr": "研究CODI模型在顺序推理任务中的机制，探索其是否能够逐步执行思考。", "motivation": "探讨Latent-CoT模型（如CODI）的内部工作原理和如何进行逐步骤计算，特别是在复杂任务中表现的策略差异。", "method": "利用对数镜头解码、线性探测、注意力分析及激活路径修补技术来研究模型中的中间状态表示及其流向最终输出的过程。", "result": "在两跳或三跳任务上，CODI形成了完整的桥接状态，并通过端口思考边界进行预测融合；然而，在更长的任务中，则出现了压缩策略和捷径策略。实验表明这种部分路径可能因优化难度增加而崩溃。", "conclusion": "揭示了CODI模型在不同长度顺序推理任务中的表现差异，强调了设计稳健的Latent-CoT目标以支持迭代计算所面临的挑战。"}}
{"id": "2602.00443", "pdf": "https://arxiv.org/pdf/2602.00443", "abs": "https://arxiv.org/abs/2602.00443", "authors": ["Xinting Liao", "Ruinan Jin", "Hanlin Yu", "Deval Pandya", "Xiaoxiao Li"], "title": "RVCBench: Benchmarking the Robustness of Voice Cloning Across Modern Audio Generation Models", "categories": ["cs.SD", "cs.MM", "eess.AS"], "comment": "40 pages, 12figures", "summary": "Modern voice cloning (VC) can synthesize speech that closely matches a target speaker from only seconds of reference audio, enabling applications such as personalized speech interfaces and dubbing. In practical deployments, modern audio generation models inevitably encounter noisy reference audios, imperfect text prompts, and diverse downstream processing, which can significantly hurt robustness. Despite rapid progress in VC driven by autoregressive codec-token language models and diffusion-based models, robustness under realistic deployment shifts remains underexplored. This paper introduces RVCBench, a comprehensive benchmark that evaluates Robustness in VC across the full generation pipeline, including input variation, generation challenges, output post-processing, and adversarial perturbations, covering 10 robustness tasks, 225 speakers, 14,370 utterances, and 11 representative modern VC models. Our evaluation uncovers substantial robustness gaps in VC: performance can deteriorate sharply under common input shifts and post-processing; long-context and cross-lingual scenarios further expose stability limitations; and both passive noise and proactive perturbation influence generation robustness. Collectively, these findings provide a unified picture of how current VC models fail in practice and introduce a standardized, open-source testbed to support the development of more robust and deployable VC models. We open-source our project at https://github.com/Nanboy-Ronan/RVCBench.", "AI": {"tldr": "本文介绍了RVCBench，一个评估语音克隆模型鲁棒性的基准测试。", "motivation": "现代的语音克隆技术虽然能够生成与目标说话者高度匹配的声音，但在实际部署中面临的噪声参考音频、不完美的文本提示和多样化的后处理等挑战尚未得到充分研究。因此，开发一种全面评估这些模型在现实环境中的鲁棒性的方法是必要的。", "method": "RVCBench涵盖了输入变化、生成挑战、输出后处理及对抗性扰动等多个方面，并测试了10个不同的任务、225位说话者、14,370条语音样本以及11种现代的语音克隆模型。", "result": "评估揭示了许多鲁棒性差距：性能在常见输入变化和后处理下会急剧下降；长上下文和跨语言场景进一步暴露了稳定性限制；被动噪声和主动扰动影响生成的鲁棒性。", "conclusion": "这些发现提供了当前语音克隆模型如何在实践中失败的整体图景，并引入了一个标准化、开源的测试平台来支持更加稳健和可部署的模型的发展。"}}
{"id": "2602.00440", "pdf": "https://arxiv.org/pdf/2602.00440", "abs": "https://arxiv.org/abs/2602.00440", "authors": ["Anugunj Naman", "Gaibo Zhang", "Ayushman Singh", "Yaguang Zhang"], "title": "DISK: Dynamic Inference SKipping for World Models", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "We present DISK, a training-free adaptive inference method for autoregressive world models. DISK coordinates two coupled diffusion transformers for video and ego-trajectory via dual-branch controllers with cross-modal skip decisions, preserving motion-appearance consistency without retraining. We extend higher-order latent-difference skip testing to the autoregressive chain-of-forward regime and propagate controller statistics through rollout loops for long-horizon stability. When integrated into closed-loop driving rollouts on 1500 NuPlan and NuScenes samples using an NVIDIA L40S GPU, DISK achieves 2x speedup on trajectory diffusion and 1.6x speedup on video diffusion while maintaining L2 planning error, visual quality (FID/FVD), and NAVSIM PDMS scores, demonstrating practical long-horizon video-and-trajectory prediction at substantially reduced cost.", "AI": {"tldr": "DISK是一种用于世界模型的自回归推理方法，它通过动态跳过推理步骤来提高效率。", "motivation": "为了减少世界模型中视频和轨迹预测的计算成本，并保持准确性和一致性，同时避免重新训练。", "method": "使用两个耦合扩散变压器进行视频和自我轨迹的双分支控制，并通过跨模式跳跃决策保留运动-外观一致性。扩展了更高阶的隐差跳过测试到自回归链中，并在滚动循环中传播控制器统计信息以提高长期稳定性。", "result": "DISK在1500个NuPlan和NuScenes样本上实现了轨迹扩散2倍速度提升，视频扩散1.6倍速度提升，同时保持L2规划误差、视觉质量和NAVSIM PDMS分数不变。", "conclusion": "DISK展示了实用的长期视频和轨迹预测能力，在显著降低计算成本的同时仍能保持高质量的结果。"}}
{"id": "2602.00432", "pdf": "https://arxiv.org/pdf/2602.00432", "abs": "https://arxiv.org/abs/2602.00432", "authors": ["Alessandra Maciel Paz Milani", "Norman Anderson", "Margaret-Anne Storey"], "title": "Towards a Cognitive-Support Tool for Threat Hunters", "categories": ["cs.CR", "cs.HC"], "comment": "15 pages, 6 figures. Author's version. The final version will appear in EnCyCriS 2026", "summary": "Cybersecurity increasingly relies on threat hunters to proactively identify adversarial activity, yet the cognitive work underlying threat hunting remains underexplored or insufficiently supported by existing tools. Building on prior studies that examined how threat hunters construct and share mental models during investigations, we derived a set of design propositions to support their cognitive and collaborative work. In this paper, we present the Threat Hunter Board, a prototype tool that operationalizes these design propositions by enabling threat hunters to externalize reasoning, organize investigative leads, and maintain continuity across sessions. Using a design science paradigm, we describe the solution design rationale and artifact development. In addition, we propose six design heuristics that form a solution-evaluation framework for assessing cognitive support in threat hunting tools. An initial evaluation using a cognitive walkthrough provides early evidence of feasibility, while future work will focus on user-based validation with professional threat hunters.", "AI": {"tldr": "开发一种支持威胁猎手的认知工具，以改善其调查工作。", "motivation": "现有工具有限地支持了威胁猎手在网络安全中的认知和协作任务。因此需要设计一个原型工具来帮助他们更好地进行分析和合作。", "method": "采用设计科学方法论，通过描述解决方案的设计依据和实际开发过程，并提出了评估此类工具的认知支持框架。", "result": "初步的基于认知走查的方法显示了该工具的可行性，未来的研究将聚焦于专业威胁猎手的实际使用验证上。", "conclusion": "提出了一种名为Threat Hunter Board的新工具原型，它通过外化推理、组织调查线索以及保持跨会话连续性来支持威胁猎手的认知和协作工作。"}}
{"id": "2602.00428", "pdf": "https://arxiv.org/pdf/2602.00428", "abs": "https://arxiv.org/abs/2602.00428", "authors": ["Naen Xu", "Hengyu An", "Shuo Shi", "Jinghuai Zhang", "Chunyi Zhou", "Changjiang Li", "Tianyu Du", "Zhihui Fu", "Jun Wang", "Shouling Ji"], "title": "When Agents \"Misremember\" Collectively: Exploring the Mandela Effect in LLM-based Multi-Agent Systems", "categories": ["cs.CL", "cs.AI", "cs.CR"], "comment": "ICLR 2026", "summary": "Recent advancements in large language models (LLMs) have significantly enhanced the capabilities of collaborative multi-agent systems, enabling them to address complex challenges. However, within these multi-agent systems, the susceptibility of agents to collective cognitive biases remains an underexplored issue. A compelling example is the Mandela effect, a phenomenon where groups collectively misremember past events as a result of false details reinforced through social influence and internalized misinformation. This vulnerability limits our understanding of memory bias in multi-agent systems and raises ethical concerns about the potential spread of misinformation. In this paper, we conduct a comprehensive study on the Mandela effect in LLM-based multi-agent systems, focusing on its existence, causing factors, and mitigation strategies. We propose MANBENCH, a novel benchmark designed to evaluate agent behaviors across four common task types that are susceptible to the Mandela effect, using five interaction protocols that vary in agent roles and memory timescales. We evaluate agents powered by several LLMs on MANBENCH to quantify the Mandela effect and analyze how different factors affect it. Moreover, we propose strategies to mitigate this effect, including prompt-level defenses (e.g., cognitive anchoring and source scrutiny) and model-level alignment-based defense, achieving an average 74.40% reduction in the Mandela effect compared to the baseline. Our findings provide valuable insights for developing more resilient and ethically aligned collaborative multi-agent systems.", "AI": {"tldr": "研究基于大规模语言模型的多智能体系统中的曼德拉效应，提出MANBENCH基准评估和缓解策略。", "motivation": "探讨大型语言模型驱动的多智能体系统的集体认知偏差问题，特别是曼德拉效应。通过此现象理解记忆偏差并减少潜在的信息误传风险。", "method": "设计MANBENCH基准以评估四种任务类型中的曼德拉效应，并使用五种交互协议研究不同因素的影响。提出策略包括提示级防御和模型级对齐防御。", "result": "实验证明，提出的策略平均减少了74.40%的曼德拉效应。", "conclusion": "研究成果提供了多智能体系统中减少记忆偏差的重要见解，为开发更可靠的协作系统奠定了基础。"}}
{"id": "2602.00426", "pdf": "https://arxiv.org/pdf/2602.00426", "abs": "https://arxiv.org/abs/2602.00426", "authors": ["Vikram Krishnamurthy"], "title": "LLMs as High-Dimensional Nonlinear Autoregressive Models with Attention: Training, Alignment and Inference", "categories": ["cs.LG", "cs.AI", "cs.CL", "eess.SP"], "comment": "27 pages, 12 figures. Mathematical survey framing LLMs as high-dimensional nonlinear autoregressive models with attention, covering training, alignment, and inference, with nanoGPT/nanochat-style code examples. Feedback welcome", "summary": "Large language models (LLMs) based on transformer architectures are typically described through collections of architectural components and training procedures, obscuring their underlying computational structure. This review article provides a concise mathematical reference for researchers seeking an explicit, equation-level description of LLM training, alignment, and generation. We formulate LLMs as high-dimensional nonlinear autoregressive models with attention-based dependencies. The framework encompasses pretraining via next-token prediction, alignment methods such as reinforcement learning from human feedback (RLHF), direct preference optimization (DPO), rejection sampling fine-tuning (RSFT), and reinforcement learning from verifiable rewards (RLVR), as well as autoregressive generation during inference. Self-attention emerges naturally as a repeated bilinear--softmax--linear composition, yielding highly expressive sequence models. This formulation enables principled analysis of alignment-induced behaviors (including sycophancy), inference-time phenomena (such as hallucination, in-context learning, chain-of-thought prompting, and retrieval-augmented generation), and extensions like continual learning, while serving as a concise reference for interpretation and further theoretical development.", "AI": {"tldr": "本文通过数学形式描述了基于变压器架构的大规模语言模型（LLM）的训练、对齐和生成过程，将其视为高维非线性自回归模型。", "motivation": "大规模语言模型通常通过架构组件和训练程序进行描述，掩盖了其底层计算结构。本文旨在为研究人员提供一个明确的数学参考，以便更好地理解这些模型。", "method": "将LLM作为高维非线性自回归模型进行公式化，并以注意力依赖为基础。框架包括预训练、对齐方法（如从人类反馈中强化学习）以及推理时的序列生成过程。", "result": "该框架使对对齐诱导的行为、推理时间现象及持续学习等扩展进行了原则性的分析，成为解释和进一步理论发展的简洁参考。", "conclusion": "通过明确数学公式描述LLM训练与生成机制，有助于深入理解这些模型及其行为。"}}
{"id": "2602.00420", "pdf": "https://arxiv.org/pdf/2602.00420", "abs": "https://arxiv.org/abs/2602.00420", "authors": ["Yihang Chen", "Zhao Xu", "Youyuan Jiang", "Tianle Zheng", "Cho-Jui Hsieh"], "title": "Text is All You Need for Vision-Language Model Jailbreaking", "categories": ["cs.CV", "cs.AI", "cs.CR"], "comment": null, "summary": "Large Vision-Language Models (LVLMs) are increasingly equipped with robust safety safeguards to prevent responses to harmful or disallowed prompts. However, these defenses often focus on analyzing explicit textual inputs or relevant visual scenes. In this work, we introduce Text-DJ, a novel jailbreak attack that bypasses these safeguards by exploiting the model's Optical Character Recognition (OCR) capability. Our methodology consists of three stages. First, we decompose a single harmful query into multiple and semantically related but more benign sub-queries. Second, we pick a set of distraction queries that are maximally irrelevant to the harmful query. Third, we present all decomposed sub-queries and distraction queries to the LVLM simultaneously as a grid of images, with the position of the sub-queries being middle within the grid. We demonstrate that this method successfully circumvents the safety alignment of state-of-the-art LVLMs. We argue this attack succeeds by (1) converting text-based prompts into images, bypassing standard text-based filters, and (2) inducing distractions, where the model's safety protocols fail to link the scattered sub-queries within a high number of irrelevant queries. Overall, our findings expose a critical vulnerability in LVLMs' OCR capabilities that are not robust to dispersed, multi-image adversarial inputs, highlighting the need for defenses for fragmented multimodal inputs.", "AI": {"tldr": "介绍了一种新的针对大型视觉语言模型的攻击方法Text-DJ，通过利用OCR能力将文本提示转换为图像并引入干扰来绕过安全保护。", "motivation": "现有防御措施主要关注显式文本输入或相关视觉场景的安全性，而忽视了基于OCR功能的潜在漏洞。此研究旨在揭示这种漏洞，并提出有效的攻击策略。", "method": "通过将有害查询分解为多个子查询并加入干扰查询，将其作为图像网格呈现给模型，从而诱导安全协议失效并成功绕过保护措施。", "result": "实验结果显示，该方法能够有效避开最先进的视觉语言模型的安全防护，暴露了OCR在处理分散的多模态输入时的脆弱性。", "conclusion": "这项研究揭示了大型视觉语言模型在面对分散和多图像的对抗输入时存在的安全漏洞，并强调需要开发针对碎片化多媒体输入的新防御措施。"}}
{"id": "2602.00415", "pdf": "https://arxiv.org/pdf/2602.00415", "abs": "https://arxiv.org/abs/2602.00415", "authors": ["Zhisheng Chen", "Tingyu Wu", "Zijie Zhou", "Zhengwei Xie", "Ziyan Weng", "Yingwei Zhang"], "title": "PolarMem: A Training-Free Polarized Latent Graph Memory for Verifiable Multimodal Agents", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "As multimodal agents evolve from passive observers to long-horizon decision-makers, they require memory systems that provide not just information availability but logical verifiability. A fundamental limitation of current architectures is the epistemic asymmetry inherent in probabilistic vision-language models and dense associative memories: they conflate semantic affinity with factual existence and structurally fail to encode negative constraints. To this end, we introduce PolarMem, a training-free Polarized Latent Graph Memory designed to ground agent reasoning in verifiable evidence. PolarMem transforms fuzzy perceptual likelihoods into discrete logical constraints through non-parametric distributional partitioning. Furthermore, it employs a polarized graph topology with orthogonal inhibitory connections to explicitly store verified negation as a primary cognitive state. At inference time, we enforce a logic-dominant retrieval paradigm, suppressing hallucinatory patterns that violate negative constraints. Extensive evaluation across eight frozen Vision--Language Models and six benchmarks demonstrates that PolarMem functions as a robust cognitive system, establishing a foundation for verifiable multimodal agents. Our code is available at https://github.com/czs-ict/PolarMem.", "AI": {"tldr": "本文提出了一种无需训练的极化潜在图记忆PolarMem，以增强多模态代理的认知能力，并确保其决策基于可验证的事实。", "motivation": "当前的视觉-语言模型和密集关联存储系统在处理知识时存在固有限制：它们混淆了语义相似性和事实性，并且无法显式编码否定约束。本文旨在解决这一问题，通过引入一种新的记忆机制来提高多模态代理的逻辑可验证性。", "method": "PolarMem通过非参数分布划分将模糊感知概率转换为离散逻辑限制。它采用极化图拓扑结构，并使用正交抑制连接显式存储经过验证的否定作为主要认知状态，从而在推理阶段压制违反否定约束的幻觉模式。", "result": "实验结果显示，PolarMem能够在八个冻结的视觉-语言模型和六个基准测试中表现良好，证明了其作为一个稳健的认知系统的基础能力。", "conclusion": "本文提出的PolarMem为构建可验证的多模态代理提供了一种新的记忆机制，并展示了其在提高逻辑推理能力和减少幻觉模式方面的能力。"}}
{"id": "2602.00414", "pdf": "https://arxiv.org/pdf/2602.00414", "abs": "https://arxiv.org/abs/2602.00414", "authors": ["Trishna Chakraborty", "Udita Ghosh", "Aldair Ernesto Gongora", "Ruben Glatt", "Yue Dong", "Jiachen Li", "Amit K. Roy-Chowdhury", "Chengyu Song"], "title": "Toward Autonomous Laboratory Safety Monitoring with Vision Language Models: Learning to See Hazards Through Scene Structure", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Laboratories are prone to severe injuries from minor unsafe actions, yet continuous safety monitoring -- beyond mandatory pre-lab safety training -- is limited by human availability. Vision language models (VLMs) offer promise for autonomous laboratory safety monitoring, but their effectiveness in realistic settings is unclear due to the lack of visual evaluation data, as most safety incidents are documented primarily as unstructured text. To address this gap, we first introduce a structured data generation pipeline that converts textual laboratory scenarios into aligned triples of (image, scene graph, ground truth), using large language models as scene graph architects and image generation models as renderers. Our experiments on the synthetic dataset of 1,207 samples across 362 unique scenarios and seven open- and closed-source models show that VLMs perform effectively given textual scene graph, but degrade substantially in visual-only settings indicating difficulty in extracting structured object relationships directly from pixels. To overcome this, we propose a post-training context-engineering approach, scene-graph-guided alignment, to bridge perceptual gaps in VLMs by translating visual inputs into structured scene graphs better aligned with VLM reasoning, improving hazard detection performance in visual only settings.", "AI": {"tldr": "论文旨在通过视觉语言模型实现实验室安全的自主监控，提出了一种从文本场景生成结构化数据的方法，并引入了基于场景图指导的对齐技术来提高危险检测性能。", "motivation": "当前实验室的安全检查依赖于人工进行，由于人力限制而难以持续执行。因此，研究利用视觉语言模型自动监测实验室安全以减少潜在风险。", "method": "论文首先构建了一个结构化数据生成流程，将文本场景转换为图像、场景图和地面真实值对齐的三元组；然后使用七种开源或专有模型进行实验，并提出了一种基于场景图指导的技术来提高视觉输入与语言模型之间的一致性。", "result": "实验表明，当给定场景图时，视觉语言模型表现良好；但仅依靠图像信息时性能显著下降。引入的场景图导向技术有效提升了危险检测精度。", "conclusion": "论文展示了将文本转化为结构化数据以及利用基于场景图的方法改进视觉语言模型在实验室安全监控中的应用潜力。"}}
{"id": "2602.00412", "pdf": "https://arxiv.org/pdf/2602.00412", "abs": "https://arxiv.org/abs/2602.00412", "authors": ["Marcos L. P. Bueno", "Joaquin Vanschoren"], "title": "Robustness of AutoML on Dirty Categorical Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The goal of automated machine learning (AutoML) is to reduce trial and error when doing machine learning (ML). Although AutoML methods for classification are able to deal with data imperfections, such as outliers, multiple scales and missing data, their behavior is less known on dirty categorical datasets. These datasets often have several categorical features with high cardinality arising from issues such as lack of curation and automated collection. Recent research has shown that ML models can benefit from morphological encoders for dirty categorical data, leading to significantly superior predictive performance. However the effects of using such encoders in AutoML methods are not known at the moment. In this paper, we propose a pipeline that transforms categorical data into numerical data so that an AutoML can handle categorical data transformed by more advanced encoding schemes. We benchmark the current robustness of AutoML methods on a set of dirty datasets and compare it with the proposed pipeline. This allows us to get insight on differences in predictive performance. We also look at the ML pipelines built by AutoMLs in order to gain insight beyond the best model as typically returned by these methods.", "AI": {"tldr": "本文提出了一个将脏类别数据转换为数值数据的管道，以使AutoML能够处理更高级编码方案转化的数据，并对当前AutoML方法在脏数据集上的鲁棒性进行基准测试。", "motivation": "尽管现有的自动机器学习（AutoML）方法可以处理一些数据不完善的问题，但是对于包含高基数类别特征的脏数据集的行为仍不清楚。本文旨在研究使用形态编码器对脏类别数据的影响，并探索AutoML在这些数据上的表现。", "method": "提出了一种管道将分类变量转换为数值变量以供自动机器学习工具处理，并对比当前AutoML方法和所提方案在一系列脏数据集上的性能。", "result": "通过基准测试，该研究发现使用形态编码器的AutoML模型在预测准确性上显著优于传统方法。同时，对构建的ML管道进行了详细分析，以获得比最佳模型更多的洞察。", "conclusion": "所提出的方案能够在处理脏类别数据时提高自动机器学习工具的表现，并且通过细致地分析构造出的管道能够为未来的研究提供更多有价值的见解。"}}
{"id": "2602.00408", "pdf": "https://arxiv.org/pdf/2602.00408", "abs": "https://arxiv.org/abs/2602.00408", "authors": ["Seung Heon Oh", "Jiwon Baek", "Ki Young Cho", "Hee Chang Yoon", "Jong Hun Woo"], "title": "Variational Approach for Job Shop Scheduling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper proposes a novel Variational Graph-to-Scheduler (VG2S) framework for solving the Job Shop Scheduling Problem (JSSP), a critical task in manufacturing that directly impacts operational efficiency and resource utilization. Conventional Deep Reinforcement Learning (DRL) approaches often face challenges such as non-stationarity during training and limited generalization to unseen problem instances because they optimize representation learning and policy execution simultaneously. To address these issues, we introduce variational inference to the JSSP domain for the first time and derive a probabilistic objective based on the Evidence of Lower Bound (ELBO) with maximum entropy reinforcement learning. By mathematically decoupling representation learning from policy optimization, the VG2S framework enables the agent to learn robust structural representations of scheduling instances through a variational graph encoder. This approach significantly enhances training stability and robustness against hyperparameter variations. Extensive experiments demonstrate that the proposed method exhibits superior zero-shot generalization compared with state-of-the-art DRL baselines and traditional dispatching rules, particularly on large-scale and challenging benchmark instances such as DMU and SWV.", "AI": {"tldr": "提出了一种基于变分图的调度框架，用于解决车间作业排序问题。", "motivation": "为了克服传统深度强化学习方法在训练中遇到的非稳定性和对未知实例泛化能力差的问题，本研究首次将变分推断引入到作业车间排序领域。", "method": "通过基于证据下界（ELBO）的最大熵强化学习公式化概率目标函数，并使用一种数学分离表示法学习的方法，使代理能够学习结构化的调度实例表征。", "result": "实验表明该方法在大型和复杂基准案例中表现出优越的零样本泛化能力，优于现有深度强化学习基线及传统调度规则。", "conclusion": "提出的新框架显著提高了训练稳定性和对超参数变化的鲁棒性，在解决大规模作业车间排序问题方面展示了强大的性能。"}}
{"id": "2602.00405", "pdf": "https://arxiv.org/pdf/2602.00405", "abs": "https://arxiv.org/abs/2602.00405", "authors": ["Deep Gandhi", "Katyani Singh", "Nidhi Hegde"], "title": "RobustDebias: Debiasing Language Models using Distributionally Robust Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Pretrained language models have been shown to exhibit biases and social stereotypes. Prior work on debiasing these models has largely focused on modifying embedding spaces during pretraining, which is not scalable for large models. Fine-tuning pretrained models on task-specific datasets can both degrade model performance and amplify biases present in the fine-tuning data. We address bias amplification during fine-tuning rather than costly pretraining, focusing on BERT models due to their widespread use in language understanding tasks. While Empirical Risk Minimization effectively optimizes downstream performance, it often amplifies social biases during fine-tuning. To counter this, we propose \\textit{RobustDebias}, a novel mechanism which adapts Distributionally Robust Optimization (DRO) to debias language models during fine-tuning. Our approach debiases models across multiple demographics during MLM fine-tuning and generalizes to any dataset or task. Extensive experiments on various language models show significant bias mitigation with minimal performance impact.", "AI": {"tldr": "提出了一种新的机制RobustDebias，用于在微调过程中去偏语言模型。", "motivation": "解决现有方法主要集中在预训练阶段去偏大型语言模型的问题，同时避免因精细调整数据集中的偏差而降低模型性能。", "method": "通过将分布鲁棒优化(DRO)适应到语言模型的微调过程来实现去偏。", "result": "实验结果显示该方法在多种语言模型上显著减少偏差，且对模型性能影响小。", "conclusion": "RobustDebias可以有效地降低语言模型中的社会偏见，在多种任务和数据集上具有泛化能力。"}}
{"id": "2602.00402", "pdf": "https://arxiv.org/pdf/2602.00402", "abs": "https://arxiv.org/abs/2602.00402", "authors": ["Aditya Kumar Purohit", "Hendrik Heuer"], "title": "A Conditional Companion: Lived Experiences of People with Mental Health Disorders Using LLMs", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used for mental health support, yet little is known about how people with mental health challenges engage with them, how they evaluate their usefulness, and what design opportunities they envision. We conducted 20 semi-structured interviews with people in the UK who live with mental health conditions and have used LLMs for mental health support. Through reflexive thematic analysis, we found that participants engaged with LLMs in conditional and situational ways: for immediacy, the desire for non-judgement, self-paced disclosure, cognitive reframing, and relational engagement. Simultaneously, participants articulated clear boundaries informed by prior therapeutic experience: LLMs were effective for mild-to-moderate distress but inadequate for crises, trauma, and complex social-emotional situations. We contribute empirical insights into the lived use of LLMs for mental health, highlight boundary-setting as central to their safe role, and propose design and governance directions for embedding them responsibly within care ecosystem.", "AI": {"tldr": "研究探讨了患有精神健康障碍的人如何使用大型语言模型（LLMs）进行心理健康支持，以及他们在这些交互中的体验和看法。", "motivation": "了解人们在遇到心理健康问题时是如何使用LLMs的，评估其有效性，并探索改进设计的机会。", "method": "通过20次半结构化访谈，研究了英国患有精神健康状况并使用过LLMs的人群。采用反思性主题分析方法进行数据处理。", "result": "参与者在有条件和情境的方式下与LLMs互动：寻求即时支持、无评判的环境、自我披露、认知重构以及人际关系建立。同时他们也设定了清晰界限，认为LLMs仅适合轻度至中度的心理压力情况，不适合危机、创伤或复杂的社交情感状况。", "conclusion": "研究提供了关于使用LLMs进行心理健康支持的实际见解，强调了设置边界对于其安全角色的重要性，并提出了在护理生态系统内负责任地嵌入它们的设计和治理方向。"}}
{"id": "2602.00401", "pdf": "https://arxiv.org/pdf/2602.00401", "abs": "https://arxiv.org/abs/2602.00401", "authors": ["Jean Pierre Sleiman", "He Li", "Alphonsus Adu-Bredu", "Robin Deits", "Arun Kumar", "Kevin Bergamin", "Mohak Bhardwaj", "Scott Biddlestone", "Nicola Burger", "Matthew A. Estrada", "Francesco Iacobelli", "Twan Koolen", "Alexander Lambert", "Erica Lin", "M. Eva Mungai", "Zach Nobles", "Shane Rozen-Levy", "Yuyao Shi", "Jiashun Wang", "Jakob Welner", "Fangzhou Yu", "Mike Zhang", "Alfred Rizzi", "Jessica Hodgins", "Sylvain Bertrand", "et al. (3 additional authors not shown)"], "title": "ZEST: Zero-shot Embodied Skill Transfer for Athletic Robot Control", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Achieving robust, human-like whole-body control on humanoid robots for agile, contact-rich behaviors remains a central challenge, demanding heavy per-skill engineering and a brittle process of tuning controllers. We introduce ZEST (Zero-shot Embodied Skill Transfer), a streamlined motion-imitation framework that trains policies via reinforcement learning from diverse sources -- high-fidelity motion capture, noisy monocular video, and non-physics-constrained animation -- and deploys them to hardware zero-shot. ZEST generalizes across behaviors and platforms while avoiding contact labels, reference or observation windows, state estimators, and extensive reward shaping. Its training pipeline combines adaptive sampling, which focuses training on difficult motion segments, and an automatic curriculum using a model-based assistive wrench, together enabling dynamic, long-horizon maneuvers. We further provide a procedure for selecting joint-level gains from approximate analytical armature values for closed-chain actuators, along with a refined model of actuators. Trained entirely in simulation with moderate domain randomization, ZEST demonstrates remarkable generality. On Boston Dynamics' Atlas humanoid, ZEST learns dynamic, multi-contact skills (e.g., army crawl, breakdancing) from motion capture. It transfers expressive dance and scene-interaction skills, such as box-climbing, directly from videos to Atlas and the Unitree G1. Furthermore, it extends across morphologies to the Spot quadruped, enabling acrobatics, such as a continuous backflip, through animation. Together, these results demonstrate robust zero-shot deployment across heterogeneous data sources and embodiments, establishing ZEST as a scalable interface between biological movements and their robotic counterparts.", "AI": {"tldr": "ZEST是一种零样本运动模仿框架，通过强化学习从多样化的数据源训练策略，并在硬件上直接部署。", "motivation": "实现类人机器人全身控制以完成敏捷、接触密集的行为是一个重大挑战。现有方法需要大量的技能工程和脆弱的控制器调整过程。", "method": "ZEST结合自适应采样和基于模型的辅助扭矩来聚焦于困难的动作段，并使用动态长时域动作训练策略，同时避免接触标签等复杂需求。", "result": "通过模拟中的中度领域随机化训练，在Boston Dynamics Atlas人形机器人上实现从运动捕捉、视频到动画的各种零样本部署能力。", "conclusion": "ZEST展示了在不同数据源和形态之间稳健的零样本部署，为生物动作与机器人对应物之间的接口提供了一种可扩展的方法。"}}
{"id": "2602.00400", "pdf": "https://arxiv.org/pdf/2602.00400", "abs": "https://arxiv.org/abs/2602.00400", "authors": ["Fan Yang", "Rui Meng", "Trudi Di Qi", "Ali Ezzati", "Yuxin Wen"], "title": "KEPO: Knowledge-Enhanced Preference Optimization for Reinforcement Learning with Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has emerged as a promising paradigm for inducing explicit reasoning behaviors in large language and vision-language models. However, reasoning-oriented RL post-training remains fundamentally challenging due to sparse trajectory-level rewards, leading to ambiguous credit assignment and severe exploration failures that can trap the policy in a ``learning cliff.'' Recent on-policy distillation methods introduce dense teacher supervision to stabilize optimization, but apply it uniformly across all generated trajectories. We argue that such uniform distillation is ill-suited for reasoning-intensive tasks, as low-quality on-policy trajectories often originate from early logical errors, and distillation under flawed contexts injects noisy and misaligned gradients. To address these challenges, we propose Knowledge-Enhanced Preference Optimization (KEPO), a unified post-training framework that integrates: (i) a quality-gated on-policy distillation objective that selectively applies dense teacher guidance only to high-quality trajectories, and (ii) a knowledge-enhanced exploration strategy that leverages hints learned from a teacher model to rejectively sample reward-positive on-policy trajectories for RL, thereby mitigating exploration collapse. Evaluated on a challenging medical visual question answering benchmark under single-source generalization, KEPO demonstrates improved training stability, more coherent reasoning behaviors, and superior out-of-distribution performance over reinforcement learning and on-policy distillation baselines.", "AI": {"tldr": "提出了一种知识增强的偏好优化框架（KEPO），以解决强化学习中稀疏奖励带来的挑战，特别是在推理任务上的表现。", "motivation": "在具有推理需求的任务上，当前基于策略的蒸馏方法存在统一应用教师监督的问题，这可能导致噪声梯度和不一致的学习。因此，作者提出了新的优化框架来改善这一状况。", "method": "KEPO框架包含两个主要部分：质量门控的在线策略蒸馏目标以及知识增强的探索策略。前者通过仅对高质量轨迹进行密集的教师指导以稳定学习过程；后者利用从教师模型中获取的知识拒绝采样奖励正向的在线策略轨迹，从而减少探索崩溃。", "result": "在单源泛化下的医疗图像问答基准测试上，KEPO展示了更好的训练稳定性、更连贯的推理行为和优于强化学习及基于策略蒸馏基线的结果。", "conclusion": "KEPO框架通过解决稀疏奖励问题，提升了大型语言模型和视觉-语言模型中显式推理行为的学习效果。"}}
{"id": "2602.00397", "pdf": "https://arxiv.org/pdf/2602.00397", "abs": "https://arxiv.org/abs/2602.00397", "authors": ["Aayush Gautam", "Mukul Gagrani", "Junyoung Park", "Mingu Lee", "Chiris Lott", "Narasimha Reddy"], "title": "Fast Forward: Accelerating LLM Prefill with Predictive FFN Sparsity", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 7 figures", "summary": "The prefill stage of large language model (LLM) inference is a key computational bottleneck for long-context workloads. At short-to-moderate context lengths (1K--16K tokens), Feed-Forward Networks (FFNs) dominate this cost, accounting for most of the total FLOPs. Existing FFN sparsification methods, designed for autoregressive decoding, fail to exploit the prefill stage's parallelism and often degrade accuracy. To address this, we introduce FastForward, a predictive sparsity framework that accelerates LLM prefill through block-wise, context-aware FFN sparsity. FastForward combines (1) a lightweight expert predictor to select high-importance neurons per block, (2) an error compensation network to correct sparsity-induced errors, and (3) a layer-wise sparsity scheduler to allocate compute based on token-mixing importance. Across LLaMA and Qwen models up to 8B parameters, FastForward delivers up to 1.45$\\times$ compute-bound speedup at 50% FFN sparsity with $<$ 6% accuracy loss compared to the dense baseline on LongBench, substantially reducing Time-to-First-Token (TTFT) for efficient, long-context LLM inference on constrained hardware.", "AI": {"tldr": "FastForward通过块级、上下文感知的FFN稀疏性加速LLM预填充阶段，减少时间至首个令牌的时间。", "motivation": "现有的FFN稀疏化方法在自回归解码时有效，但在并行性的长上下文工作负载中效果不佳，且经常降低准确率。需要一种针对预填充阶段的新方案来提高效率和准确性。", "method": "FastForward结合了轻量级专家预测器、误差补偿网络以及逐层稀疏调度器，以选择每块中的高重要性神经元，并纠正稀疏引起的错误，同时根据令牌混合的重要性分配计算资源。", "result": "在8B参数的LLaMA和Qwen模型上，FastForward实现了高达1.45倍的计算限制下的加速，在LongBench基准测试中与密集基线相比仅损失不到6%的准确率，大大减少了时间至首个令牌的时间。", "conclusion": "通过块级、上下文感知的FFN稀疏性框架，FastForward显著提高了长上下文LLM推理在受限硬件上的效率。"}}
{"id": "2602.00395", "pdf": "https://arxiv.org/pdf/2602.00395", "abs": "https://arxiv.org/abs/2602.00395", "authors": ["Roger Hsiao", "Yuchen Fang", "Xiangru Huang", "Ruilong Li", "Hesam Rabeti", "Zan Gojcic", "Javad Lavaei", "James Demmel", "Sophia Shao"], "title": "3DGS$^2$-TR: Scalable Second-Order Trust-Region Method for 3D Gaussian Splatting", "categories": ["cs.CV", "cs.LG", "math.OC"], "comment": null, "summary": "We propose 3DGS$^2$-TR,a second-order optimizer for accelerating the scene training problem in 3D Gaussian Splatting (3DGS). Unlike existing second-order approaches that rely on explicit or dense curvature representations, such as 3DGS-LM (Höllein et al., 2025) or 3DGS2 (Lan et al., 2025), our method approximates curvature using only the diagonal of the Hessian matrix, efficiently via Hutchinson's method. Our approach is fully matrix-free and has the same complexity as ADAM (Kingma, 2024), $O(n)$ in both computation and memory costs. To ensure stable optimization in the presence of strong nonlinearity in the 3DGS rasterization process, we introduce a parameter-wise trust-region technique based on the squared Hellinger distance, regularizing updates to Gaussian parameters. Under identical parameter initialization and without densification, 3DGS$^2$-TR is able to achieve better reconstruction quality on standard datasets, using 50% fewer training iterations compared to ADAM, while incurring less than 1GB of peak GPU memory overhead (17% more than ADAM and 85% less than 3DGS-LM), enabling scalability to very large scenes and potentially to distributed training settings.", "AI": {"tldr": "提出了一种用于加速三维高斯点云训练的高效优化方法3DGS$^2$-TR。", "motivation": "当前的二阶优化方法依赖于显式的或密集的曲率表示，计算和内存消耗较大。为了提高效率并确保大规模场景下的稳定性，引入了新的优化策略。", "method": "通过只使用Hessian矩阵对角线来近似曲率，并基于Hellinger距离平方引入参数级信任区域技术，提出了一种无需显式矩阵的高效方法。该方法在计算和内存复杂度上与ADAM相同，具有低至1GB额外GPU峰值内存开销。", "result": "3DGS$^2$-TR相较于ADAM，在标准数据集上的重建质量更好且训练迭代次数减少50%，同时峰值GPU内存使用量小于1GB（比ADAM高17%）。", "conclusion": "所提出的优化方法在效率和稳定性方面均表现出色，适用于大规模场景，并具有潜在的分布式训练能力。"}}
{"id": "2602.00394", "pdf": "https://arxiv.org/pdf/2602.00394", "abs": "https://arxiv.org/abs/2602.00394", "authors": ["Manoj Reddy Bethi", "Sai Rupa Jhade", "Pravallika Yaganti", "Monoshiz Mahbub Khan", "Zhe Yu"], "title": "Modeling Art Evaluations from Comparative Judgments: A Deep Learning Approach to Predicting Aesthetic Preferences", "categories": ["cs.CV"], "comment": null, "summary": "Modeling human aesthetic judgments in visual art presents significant challenges due to individual preference variability and the high cost of obtaining labeled data. To reduce cost of acquiring such labels, we propose to apply a comparative learning framework based on pairwise preference assessments rather than direct ratings. This approach leverages the Law of Comparative Judgment, which posits that relative choices exhibit less cognitive burden and greater cognitive consistency than direct scoring. We extract deep convolutional features from painting images using ResNet-50 and develop both a deep neural network regression model and a dual-branch pairwise comparison model. We explored four research questions: (RQ1) How does the proposed deep neural network regression model with CNN features compare to the baseline linear regression model using hand-crafted features? (RQ2) How does pairwise comparative learning compare to regression-based prediction when lacking access to direct rating values? (RQ3) Can we predict individual rater preferences through within-rater and cross-rater analysis? (RQ4) What is the annotation cost trade-off between direct ratings and comparative judgments in terms of human time and effort? Our results show that the deep regression model substantially outperforms the baseline, achieving up to $328\\%$ improvement in $R^2$. The comparative model approaches regression performance despite having no access to direct rating values, validating the practical utility of pairwise comparisons. However, predicting individual preferences remains challenging, with both within-rater and cross-rater performance significantly lower than average rating prediction. Human subject experiments reveal that comparative judgments require $60\\%$ less annotation time per item, demonstrating superior annotation efficiency for large-scale preference modeling.", "AI": {"tldr": "本文提出了一种基于深度学习的方法，通过比较判断来预测视觉艺术中的审美偏好。", "motivation": "由于个体偏好的变化和获取标注数据的成本高，建模人类在视觉艺术上的审美评判具有挑战性。为此，采用基于成对偏好评估的比较学习框架以减少标签获取成本。", "method": "使用ResNet-50提取绘画图像的深度卷积特征，并开发了深层神经网络回归模型和双分支成对对比模型。研究问题包括：基线线性回归与CNN特征相比如何；在缺乏直接评级的情况下，比较学习是否优于基于回归的预测；能否通过个体评分者分析预测个人偏好等。", "result": "深度回归模型比基线模型表现优越，$R^2$提升高达328%。尽管没有直接评级值，成对对比模型接近于回归性能，表明了成对比较的实际效用。然而，预测个别偏好的挑战仍然存在，跨评分者和个体评分者的预测性能低于平均评价值预测。", "conclusion": "通过人类实验发现，比较判断比直接评分减少60%的标注时间，展示了大规模偏好建模中的注释效率优势。"}}
{"id": "2602.00393", "pdf": "https://arxiv.org/pdf/2602.00393", "abs": "https://arxiv.org/abs/2602.00393", "authors": ["Gabriel Bromonschenkel", "Alessandro L. Koerich", "Thiago M. Paixão", "Hilário Tomaz Alves de Oliveira"], "title": "Brazilian Portuguese Image Captioning with Transformers: A Study on Cross-Native-Translated Dataset", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "Accepted to JBCS. 18 pages, 11 figures", "summary": "Image captioning (IC) refers to the automatic generation of natural language descriptions for images, with applications ranging from social media content generation to assisting individuals with visual impairments. While most research has been focused on English-based models, low-resource languages such as Brazilian Portuguese face significant challenges due to the lack of specialized datasets and models. Several studies create datasets by automatically translating existing ones to mitigate resource scarcity. This work addresses this gap by proposing a cross-native-translated evaluation of Transformer-based vision and language models for Brazilian Portuguese IC. We use a version of Flickr30K comprised of captions manually created by native Brazilian Portuguese speakers and compare it to a version with captions automatically translated from English to Portuguese. The experiments include a cross-context approach, where models trained on one dataset are tested on the other to assess the translation impact. Additionally, we incorporate attention maps for model inference interpretation and use the CLIP-Score metric to evaluate the image-description alignment. Our findings show that Swin-DistilBERTimbau consistently outperforms other models, demonstrating strong generalization across datasets. ViTucano, a Brazilian Portuguese pre-trained VLM, surpasses larger multilingual models (GPT-4o, LLaMa 3.2 Vision) in traditional text-based evaluation metrics, while GPT-4 models achieve the highest CLIP-Score, highlighting improved image-text alignment. Attention analysis reveals systematic biases, including gender misclassification, object enumeration errors, and spatial inconsistencies. The datasets and the models generated and analyzed during the current study are available in: https://github.com/laicsiifes/transformer-caption-ptbr.", "AI": {"tldr": "该论文研究了在巴西葡萄牙语图像描述生成中使用Transformer模型的效果，并对比分析了手动创建的和自动翻译的图像描述数据集。", "motivation": "低资源语言如巴西葡萄牙语由于缺乏特定的数据集和模型，在图像描述任务上面临挑战，因此本文旨在通过跨本地翻译评估来研究这一问题。", "method": "实验使用由本地巴西葡萄牙语使用者创建的手动标注Flickr30K数据集以及从英文自动翻译的版本，测试了Transformer基于视觉语言模型的表现。还引入了注意图和CLIP-Score指标来解释模型推理并评价图像-描述一致性。", "result": "Swin-DistilBERTimbau在跨数据集上的表现优于其他模型，显示出更强的一般性；ViTucano超越了更大的多语种模型，但在传统文本评估中表现更好。GPT-4系列模型在CLIP-Score上得分最高，表明图像和文字之间的对齐有所改进。", "conclusion": "实验揭示出一些系统性的偏差，如性别分类错误、对象计数误差以及空间一致性问题。研究结果有助于进一步优化低资源语言的图像描述任务模型，并提高其性能稳定性。"}}
{"id": "2602.00391", "pdf": "https://arxiv.org/pdf/2602.00391", "abs": "https://arxiv.org/abs/2602.00391", "authors": ["Alberto Mario Ceballos-Arroyo", "Shrikanth M. Yadav", "Chu-Hsuan Lin", "Jisoo Kim", "Geoffrey S. Young", "Huaizu Jiang", "Lei Qin"], "title": "Robust automatic brain vessel segmentation in 3D CTA scans using dynamic 4D-CTA data", "categories": ["cs.CV"], "comment": "16 pages, 8 figures", "summary": "In this study, we develop a novel methodology for annotating the brain vasculature using dynamic 4D-CTA head scans. By using multiple time points from dynamic CTA acquisitions, we subtract bone and soft tissue to enhance the visualization of arteries and veins, reducing the effort required to obtain manual annotations of brain vessels. We then train deep learning models on our ground truth annotations by using the same segmentation for multiple phases from the dynamic 4D-CTA collection, effectively enlarging our dataset by 4 to 5 times and inducing robustness to contrast phases. In total, our dataset comprises 110 training images from 25 patients and 165 test images from 14 patients. In comparison with two similarly-sized datasets for CTA-based brain vessel segmentation, a nnUNet model trained on our dataset can achieve significantly better segmentations across all vascular regions, with an average mDC of 0.846 for arteries and 0.957 for veins in the TopBrain dataset. Furthermore, metrics such as average directed Hausdorff distance (adHD) and topology sensitivity (tSens) reflected similar trends: using our dataset resulted in low error margins (aDHD of 0.304 mm for arteries and 0.078 for veins) and high sensitivity (tSens of 0.877 for arteries and 0.974 for veins), indicating excellent accuracy in capturing vessel morphology. Our code and model weights are available online: https://github.com/alceballosa/robust-vessel-segmentation", "AI": {"tldr": "提出了一种新的方法，利用动态4D-CTA数据进行自动脑血管分割。", "motivation": "通过使用动态4D-CTA中的多个时间点来增强脑血管的可视化，并减少手动注释的工作量。同时扩大了训练集规模并增强了模型对对比度阶段变化的鲁棒性。", "method": "利用动态4D-CTA数据减去骨头和软组织，突出动脉和静脉；通过多次相位分割结果相同，增大训练集规模并提高鲁棒性；使用nnUNet模型进行血管分割。", "result": "实验表明，该方法在TopBrain数据集中取得了优秀的结果，动脉的mDC为0.846，静脉的mDC为0.957；同时adHD和tSens等指标也显示了低误差率和高敏感度。", "conclusion": "提出的基于动态4D-CTA数据的方法可以显著提高脑血管分割精度，并具有较好的鲁棒性。"}}
{"id": "2602.00386", "pdf": "https://arxiv.org/pdf/2602.00386", "abs": "https://arxiv.org/abs/2602.00386", "authors": ["Michał P. Karpowicz", "Gilbert Strang"], "title": "Generalized Inverses of Matrix Products: From Fundamental Subspaces to Randomized Decompositions", "categories": ["math.NA", "cs.AI", "cs.LG"], "comment": ":15A09; 15A23; 15A24; 65F05; 65F30", "summary": "We investigate the Moore-Penrose pseudoinverse and generalized inverse of a matrix product $A=CR$ to establish a unifying framework for generalized and randomized matrix inverses. This analysis is rooted in first principles, focusing on the geometry of the four fundamental subspaces. We examine: (1) the reverse order law, $A^+ = R^+C^+$, which holds when $C$ has independent columns and $R$ has independent rows, (2) the universally correct formula, $A^+ = (C^+CR)^+(CRR^+)^+$, providing a geometric interpretation of the mappings between the involved subspaces, (3) a new generalized randomized formula, $A^+_p = (P^TA)^+P^TAQ(AQ)^+$, which gives $A^+_p = A^+$ if and only if the sketching matrices $P$ and $Q$ preserve the rank of $A$, i.e., $\\mathrm{rank}(P^TA) = \\mathrm{rank}(AQ) = \\mathrm{rank}(A)$. The framework is extended to generalized $\\{1,2\\}$-inverses and specialized forms, revealing the underlying structure of established randomized linear algebra algorithms, including randomized SVD, the Nyström approximation, and CUR decomposition. We demonstrate applications in sparse sensor placement and effective resistance estimation. For the latter, we provide a rigorous quantitative analysis of an approximation scheme, establishing that it always underestimates the true resistance and deriving a worst-case spectral bound on the error of resistance differences.", "AI": {"tldr": "本文研究了矩阵乘积的Moore-Penrose伪逆和广义逆，建立了统一的框架。", "motivation": "通过第一原理探讨矩阵的几何特性及其四个基本子空间的关系，为广义和随机化的矩阵求逆提供理论支持。", "method": "分析了反序律、普遍正确的公式以及新的广义随机化公式，并将其应用于特殊形式的广义{1,2}逆和一些线性代数算法中。", "result": "建立了从基本子空间到随机分解的统一框架，证明了一种电阻近似方案总是低估真实电阻并得出了误差界。", "conclusion": "研究揭示了矩阵乘积在不同条件下的广义逆性质，并为应用领域的相关问题提供了理论依据。"}}
{"id": "2602.00385", "pdf": "https://arxiv.org/pdf/2602.00385", "abs": "https://arxiv.org/abs/2602.00385", "authors": ["Bsher Karbouj", "Adam Michael Altenbuchner", "Joerg Krueger"], "title": "Deep Learning-Based Object Detection for Autonomous Vehicles: A Comparative Study of One-Stage and Two-Stage Detectors on Basic Traffic Objects", "categories": ["cs.CV"], "comment": null, "summary": "Object detection is a crucial component in autonomous vehicle systems. It enables the vehicle to perceive and understand its environment by identifying and locating various objects around it. By utilizing advanced imaging and deep learning techniques, autonomous vehicle systems can rapidly and accurately identify objects based on their features. Different deep learning methods vary in their ability to accurately detect and classify objects in autonomous vehicle systems. Selecting the appropriate method significantly impacts system performance, robustness, and efficiency in real-world driving scenarios. While several generic deep learning architectures like YOLO, SSD, and Faster R-CNN have been proposed, guidance on their suitability for specific autonomous driving applications is often limited. The choice of method affects detection accuracy, processing speed, environmental robustness, sensor integration, scalability, and edge case handling. This study provides a comprehensive experimental analysis comparing two prominent object detection models: YOLOv5 (a one-stage detector) and Faster R-CNN (a two-stage detector). Their performance is evaluated on a diverse dataset combining real and synthetic images, considering various metrics including mean Average Precision (mAP), recall, and inference speed. The findings reveal that YOLOv5 demonstrates superior performance in terms of mAP, recall, and training efficiency, particularly as dataset size and image resolution increase. However, Faster R-CNN shows advantages in detecting small, distant objects and performs well in challenging lighting conditions. The models' behavior is also analyzed under different confidence thresholds and in various real-world scenarios, providing insights into their applicability for autonomous driving systems.", "AI": {"tldr": "对比分析了一阶段和两阶段目标检测模型在自动驾驶车辆中的表现", "motivation": "评估不同的深度学习方法对于准确识别和分类道路上的物体的能力，以提高系统的性能、鲁棒性和效率", "method": "利用YOLOv5（一阶段）和Faster R-CNN（两阶段）在包含真实和合成图像的数据集上进行实验对比，并根据mAP、召回率和推理速度等指标评估模型表现", "result": "发现随着数据集大小和图像分辨率的增加，YOLOv5在mAP和训练效率方面表现出色；Faster R-CNN则在检测小且远距离物体及挑战性光照条件下表现更好", "conclusion": "根据不同的置信度阈值和现实世界场景下的模型行为分析，提供了适合自动驾驶系统应用的模型选择建议"}}
{"id": "2602.00381", "pdf": "https://arxiv.org/pdf/2602.00381", "abs": "https://arxiv.org/abs/2602.00381", "authors": ["Kezia Minni", "Qiang Zhang", "Monoshiz Mahbub Khan", "Zhe Yu"], "title": "Modeling Image-Caption Rating from Comparative Judgments", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Rating the accuracy of captions in describing images is time-consuming and subjective for humans. In contrast, it is often easier for people to compare two captions and decide which one better matches a given image. In this work, we propose a machine learning framework that models such comparative judgments instead of direct ratings. The model can then be applied to rank unseen image-caption pairs in the same way as a regression model trained on direct ratings. Using the VICR dataset, we extract visual features with ResNet-50 and text features with MiniLM, then train both a regression model and a comparative learning model. While the regression model achieves better performance (Pearson's $ρ$: 0.7609 and Spearman's $r_s$: 0.7089), the comparative learning model steadily improves with more data and approaches the regression baseline. In addition, a small-scale human evaluation study comparing absolute rating, pairwise comparison, and same-image comparison shows that comparative annotation yields faster results and has greater agreement among human annotators. These results suggest that comparative learning can effectively model human preferences while significantly reducing the cost of human annotations.", "AI": {"tldr": "提出了一个机器学习框架，通过比较判断来预测图像标题的准确性。", "motivation": "直接对图像标题准确性的评分耗时且主观，相比之下人们更容易对比两个标题并决定哪个更符合给定图片。因此提出了一种基于比较判断的方法以减少人工标注成本。", "method": "使用VICR数据集提取视觉和文本特征，训练回归模型与比较学习模型进行评估，并通过小规模的人类实验研究了绝对评分、成对比较及同图比较。", "result": "回归模型的性能优于比较学习模型（Pearson's $ρ$:0.7609, Spearman's $r_s$:0.7089），但随着数据量增加，比较学习模型逐步接近回归基线。人类实验表明成对比绝对评分更快速且一致。", "conclusion": "研究表明基于比较的学习方法可以有效地模拟人类偏好，并显著降低人工标注的成本。"}}
{"id": "2602.00372", "pdf": "https://arxiv.org/pdf/2602.00372", "abs": "https://arxiv.org/abs/2602.00372", "authors": ["Aaron R. Flouro", "Shawn P. Chadwick"], "title": "Post-Training Probability Manifold Correction via Structured SVD Pruning and Self-Referential Distillation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "16 pages, 10 tables, 4 figures", "summary": "Large language models are expensive to deploy. We introduce Sparse Knowledge Distillation (SparseKD), a post-training method that compresses transformer models by combining structured SVD pruning with self-referential knowledge distillation. The key insight is simple: instead of using an external teacher, the model teaches itself by matching its own probability distribution from before compression. This self-referential setup enables surprisingly strong quality recovery after aggressive pruning. Our experiments reveal an unexpected finding: self-referential distillation alone, applied post-training under an identical objective and fixed calibration dataset, improves model quality by 39% relative to the original converged checkpoint. When combined with structured pruning, SparseKD achieves 15-65% parameter reduction with acceptable quality trade-offs. Kernel profiling shows that speedups arise entirely from reduced dense matrix multiplication in feed-forward layers while attention remains unchanged, making this approach complementary to attention optimizations. We validate across two model families (0.6B and 3.8B parameters) with multi-seed experiments confirming high reproducibility. SparseKD requires no external super-teacher, no architectural changes, and no custom inference kernels, making it immediately deployable with existing infrastructure.", "AI": {"tldr": "提出了Sparse Knowledge Distillation（SparseKD）方法，通过结合结构化SVD剪枝与自参考知识蒸馏来压缩大型语言模型。", "motivation": "由于大型语言模型的部署成本高昂，开发了一种在训练后对变换器模型进行压缩的方法，旨在降低计算资源需求同时保持或恢复模型质量。", "method": "SparseKD结合了结构化SVD剪枝与自参考知识蒸馏。通过匹配模型自身在压缩前的概率分布来实现自我教学，并且无需外部教师、架构修改或定制推理内核。", "result": "实验结果显示，仅使用自参考蒸馏就能使原始收敛检查点的质量提高39％。当结合结构化剪枝时，SparseKD能在15-65％的参数减少范围内保持可接受的质量损失。此外，在两个模型系列（0.6B和3.8B个参数）上进行多种子实验验证了该方法的高度重现性。", "conclusion": "SparseKD是一种有效的后训练压缩技术，无需外部教师、架构修改或定制内核，并且能够与现有的基础设施无缝集成。"}}
{"id": "2602.00371", "pdf": "https://arxiv.org/pdf/2602.00371", "abs": "https://arxiv.org/abs/2602.00371", "authors": ["Aditya Kumar Purohit", "Aditya Upadhyaya", "Nicolas Ruiz", "Alberto Monge Roffarello", "Hendrik Heuer"], "title": "When Handwriting Goes Social: Creativity, Anonymity, and Communication in Graphonymous Online Spaces", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "While most digital communication platforms rely on text, relatively little research has examined how users engage through handwriting and drawing in anonymous, collaborative environments. We introduce Graphonymous Interaction, a form of communication where users interact anonymously via handwriting and drawing. Our study analyzed over 600 canvas pages from the Graphonymous Online Space (GOS) CollaNote and conducted interviews with 20 users. Additionally, we examined 70 minutes of real-time GOS sessions using Conversation Analysis and Multimodal Discourse Analysis. Findings reveal that Graphonymous Interaction fosters artistic expression, intellectual engagement, sharing and supporting, and social connection. Notably, anonymity coexisted with moments of recognition through graphological identification. Distinct conversational strategies also emerged, which allow smoother exchanges and fewer conversational repairs compared to text-based communication. This study contributes to understanding Graphonymous Interaction and Online Spaces, offering insights into designing platforms that support creative and socially engaging forms of communication beyond text.", "AI": {"tldr": "研究探讨了匿名协作环境中通过手写和绘画进行互动的现象，分析了Graphonymous Interaction的特点及其对社交连接的影响。", "motivation": "现有研究主要关注基于文本的数字通信平台，而较少探索用户在匿名、协作环境中通过手写与绘画交流的情况。此研究旨在填补这一空白，并理解这种新的交互方式如何促进创意和社交联系。", "method": "研究人员分析了超过600个Canvas页面的数据，并对20名用户进行了访谈；同时利用对话分析和多模态话语分析方法，考察了70分钟的实际在线交流情况。", "result": "研究发现Graphonymous Interaction促进了艺术表达、智力参与和支持社交连接。匿名性与通过手写特征实现的识别时刻并存，且这种互动形式具有更流畅的交流方式和较少的语言修复。", "conclusion": "这项研究表明Graphonymous Interaction在促进创意和个人间的联系方面有独特作用，并为设计支持非文本通信的新平台提供了见解。"}}
{"id": "2602.00370", "pdf": "https://arxiv.org/pdf/2602.00370", "abs": "https://arxiv.org/abs/2602.00370", "authors": ["Trisha Das", "Katherine Kero", "Dorinda Schumann", "Tracy Ohrt", "Sanjit Singh Batra", "Gregory D Lyng", "Robert E. Tillman"], "title": "POET: Protocol Optimization via Eligibility Tuning", "categories": ["cs.AI"], "comment": null, "summary": "Eligibility criteria (EC) are essential for clinical trial design, yet drafting them remains a time-intensive and cognitively demanding task for clinicians. Existing automated approaches often fall at two extremes either requiring highly structured inputs, such as predefined entities to generate specific criteria, or relying on end-to-end systems that produce full eligibility criteria from minimal input such as trial descriptions limiting their practical utility. In this work, we propose a guided generation framework that introduces interpretable semantic axes, such as Demographics, Laboratory Parameters, and Behavioral Factors, to steer EC generation. These axes, derived using large language models, offer a middle ground between specificity and usability, enabling clinicians to guide generation without specifying exact entities. In addition, we present a reusable rubric-based evaluation framework that assesses generated criteria along clinically meaningful dimensions. Our results show that our guided generation approach consistently outperforms unguided generation in both automatic, rubric-based and clinician evaluations, offering a practical and interpretable solution for AI-assisted trial design.", "AI": {"tldr": "提出了一种基于可解释语义轴的引导式生成框架，以优化临床试验的设计。", "motivation": "现有的自动化方法要么需要高度结构化的输入，要么依赖于从最少输入中生成完整标准的端到端系统，限制了其实用性。因此，为了提高临床试验设计效率，本研究提出了一个可以指导生成而不需明确指定具体实体的方法。", "method": "通过引入可解释的语义轴（如人口统计学、实验室参数和行为因素），并使用大型语言模型进行引导式生成框架的设计；同时提出了一种基于评价准则的评估框架来衡量生成标准的有效性。", "result": "实验结果显示，引导式生成方法在自动评估、基于评价准则评估以及临床医生评估中均优于无指导生成方法。", "conclusion": "该研究提供了一个实用且可解释的方法，用于AI辅助试验设计，并通过引入新的框架和评估标准提高了现有技术的实用性。"}}
{"id": "2602.00359", "pdf": "https://arxiv.org/pdf/2602.00359", "abs": "https://arxiv.org/abs/2602.00359", "authors": ["Minhua Lin", "Hanqing Lu", "Zhan Shi", "Bing He", "Rui Mao", "Zhiwei Zhang", "Zongyu Wu", "Xianfeng Tang", "Hui Liu", "Zhenwei Dai", "Xiang Zhang", "Suhang Wang", "Benoit Dumoulin", "Jian Pei"], "title": "Position: Agentic Evolution is the Path to Evolving LLMs", "categories": ["cs.AI"], "comment": null, "summary": "As Large Language Models (LLMs) move from curated training sets into open-ended real-world environments, a fundamental limitation emerges: static training cannot keep pace with continual deployment environment change. Scaling training-time and inference-time compute improves static capability but does not close this train-deploy gap. We argue that addressing this limitation requires a new scaling axis-evolution. Existing deployment-time adaptation methods, whether parametric fine-tuning or heuristic memory accumulation, lack the strategic agency needed to diagnose failures and produce durable improvements. Our position is that agentic evolution represents the inevitable future of LLM adaptation, elevating evolution itself from a fixed pipeline to an autonomous evolver agent. We instantiate this vision in a general framework, A-Evolve, which treats deployment-time improvement as a deliberate, goal-directed optimization process over persistent system state. We further propose the evolution-scaling hypothesis: the capacity for adaptation scales with the compute allocated to evolution, positioning agentic evolution as a scalable path toward sustained, open-ended adaptation in the real world.", "AI": {"tldr": "探讨了大型语言模型在开放环境中的适应性进化问题，提出了一个通用框架A-Evolve。", "motivation": "随着大规模语言模型从固定训练集转向开放的真实世界环境，静态训练无法跟上持续变化的部署环境。现有的调整方法缺乏战略决策能力以诊断失败并实现持久改进。", "method": "提出了一种新的适应性进化路径——代理进化，并提出了A-Evolve框架来解决这一问题。该框架将部署时间改进视为一种具有目标导向性的优化过程，强调计算资源分配对进化的重要性。", "result": "证明了进化能力随着分配给进化的计算资源的增加而增强。", "conclusion": "代理进化是大型语言模型在开放环境中实现持续适应性演化的必然路径。"}}
{"id": "2602.00353", "pdf": "https://arxiv.org/pdf/2602.00353", "abs": "https://arxiv.org/abs/2602.00353", "authors": ["Yihe Zhang", "Cheyenne N Mohawk", "Kaiying Han", "Vijay Srinivas Tida", "Manyu Li", "Xiali Hei"], "title": "MHDash: An Online Platform for Benchmarking Mental Health-Aware AI Assistants", "categories": ["cs.AI", "cs.HC"], "comment": "Accepted for presentation at IEEE SoutheastCon 2026. This is the author version of an accepted paper. The final version will appear in IEEE Xplore", "summary": "Large language models (LLMs) are increasingly applied in mental health support systems, where reliable recognition of high-risk states such as suicidal ideation and self-harm is safety-critical. However, existing evaluations primarily rely on aggregate performance metrics, which often obscure risk-specific failure modes and provide limited insight into model behavior in realistic, multi-turn interactions. We present MHDash, an open-source platform designed to support the development, evaluation, and auditing of AI systems for mental health applications. MHDash integrates data collection, structured annotation, multi-turn dialogue generation, and baseline evaluation into a unified pipeline. The platform supports annotations across multiple dimensions, including Concern Type, Risk Level, and Dialogue Intent, enabling fine-grained and risk-aware analysis. Our results reveal several key findings: (i) simple baselines and advanced LLM APIs exhibit comparable overall accuracy yet diverge significantly on high-risk cases; (ii) some LLMs maintain consistent ordinal severity ranking while failing absolute risk classification, whereas others achieve reasonable aggregate scores but suffer from high false negative rates on severe categories; and (iii) performance gaps are amplified in multi-turn dialogues, where risk signals emerge gradually. These observations demonstrate that conventional benchmarks are insufficient for safety-critical mental health settings. By releasing MHDash as an open platform, we aim to promote reproducible research, transparent evaluation, and safety-aligned development of AI systems for mental health support.", "AI": {"tldr": "该论文介绍了MHDash平台，旨在支持心理健康应用中AI系统的开发、评估和审计。", "motivation": "现有评估方法主要依赖于整体性能指标，难以揭示风险特定的失败模式以及在多轮对话中的模型行为。因此需要一个更细致的风险意识分析工具。", "method": "MHDash平台集成了数据收集、结构化标注、多轮对话生成和基线评估等功能，并支持多个维度的注释，包括关注类型、风险级别及对话意图。", "result": "结果显示：简单基准与先进LLMs在整体准确率上相近但对高危情况处理差异显著；某些模型保持一致的风险等级排序却在绝对风险分类中表现不佳；性能差距在多轮对话中被放大。", "conclusion": "常规基准不足以满足心理健康应用的安全需求，MHDash作为开放平台将推动可重复研究、透明评估及安全导向的AI系统开发。"}}
{"id": "2602.00350", "pdf": "https://arxiv.org/pdf/2602.00350", "abs": "https://arxiv.org/abs/2602.00350", "authors": ["Ignacy Kolton", "Kacper Marzol", "Paweł Batorski", "Marcin Mazur", "Paul Swoboda", "Przemysław Spurek"], "title": "ReLAPSe: Reinforcement-Learning-trained Adversarial Prompt Search for Erased concepts in unlearned diffusion models", "categories": ["cs.CV"], "comment": null, "summary": "Machine unlearning is a key defense mechanism for removing unauthorized concepts from text-to-image diffusion models, yet recent evidence shows that latent visual information often persists after unlearning. Existing adversarial approaches for exploiting this leakage are constrained by fundamental limitations: optimization-based methods are computationally expensive due to per-instance iterative search. At the same time, reasoning-based and heuristic techniques lack direct feedback from the target model's latent visual representations. To address these challenges, we introduce ReLAPSe, a policy-based adversarial framework that reformulates concept restoration as a reinforcement learning problem. ReLAPSe trains an agent using Reinforcement Learning with Verifiable Rewards (RLVR), leveraging the diffusion model's noise prediction loss as a model-intrinsic and verifiable feedback signal. This closed-loop design directly aligns textual prompt manipulation with latent visual residuals, enabling the agent to learn transferable restoration strategies rather than optimizing isolated prompts. By pioneering the shift from per-instance optimization to global policy learning, ReLAPSe achieves efficient, near-real-time recovery of fine-grained identities and styles across multiple state-of-the-art unlearning methods, providing a scalable tool for rigorous red-teaming of unlearned diffusion models. Some experimental evaluations involve sensitive visual concepts, such as nudity. Code is available at https://github.com/gmum/ReLaPSe", "AI": {"tldr": "ReLAPSe是一种基于强化学习的对抗性框架，用于恢复从文本到图像扩散模型中删除的概念。", "motivation": "现有的对抗方法在利用未经学习概念的信息泄漏方面存在计算成本高或缺乏直接反馈的问题。为了解决这些问题，提出了ReLAPSe来改进这种方法。", "method": "通过将概念恢复重构为强化学习问题，并使用验证奖励的强化学习（RLVR）训练代理，采用扩散模型的噪声预测损失作为内在且可验证的反馈信号。", "result": "与现有的优化方法相比，ReLAPSe能够以高效的、接近实时的方式恢复多个最先进的未学方法中的细粒度身份和风格。", "conclusion": "这种方法提供了一个可扩展的工具来严格测试未经学习扩散模型的安全性。"}}
{"id": "2602.00348", "pdf": "https://arxiv.org/pdf/2602.00348", "abs": "https://arxiv.org/abs/2602.00348", "authors": ["Zhengyi Lu", "Ming Lu", "Chongyu Qu", "Junchao Zhu", "Junlin Guo", "Marilyn Lionts", "Yanfan Zhu", "Yuechen Yang", "Tianyuan Yao", "Jayasai Rajagopal", "Bennett Allan Landman", "Xiao Wang", "Xinqiang Yan", "Yuankai Huo"], "title": "MASC: Metal-Aware Sampling and Correction via Reinforcement Learning for Accelerated MRI", "categories": ["cs.CV"], "comment": null, "summary": "Metal implants in MRI cause severe artifacts that degrade image quality and hinder clinical diagnosis. Traditional approaches address metal artifact reduction (MAR) and accelerated MRI acquisition as separate problems. We propose MASC, a unified reinforcement learning framework that jointly optimizes metal-aware k-space sampling and artifact correction for accelerated MRI. To enable supervised training, we construct a paired MRI dataset using physics-based simulation, generating k-space data and reconstructions for phantoms with and without metal implants. This paired dataset provides simulated 3D MRI scans with and without metal implants, where each metal-corrupted sample has an exactly matched clean reference, enabling direct supervision for both artifact reduction and acquisition policy learning. We formulate active MRI acquisition as a sequential decision-making problem, where an artifact-aware Proximal Policy Optimization (PPO) agent learns to select k-space phase-encoding lines under a limited acquisition budget. The agent operates on undersampled reconstructions processed through a U-Net-based MAR network, learning patterns that maximize reconstruction quality. We further propose an end-to-end training scheme where the acquisition policy learns to select k-space lines that best support artifact removal while the MAR network simultaneously adapts to the resulting undersampling patterns. Experiments demonstrate that MASC's learned policies outperform conventional sampling strategies, and end-to-end training improves performance compared to using a frozen pre-trained MAR network, validating the benefit of joint optimization. Cross-dataset experiments on FastMRI with physics-based artifact simulation further confirm generalization to realistic clinical MRI data. The code and models of MASC have been made publicly available: https://github.com/hrlblab/masc", "AI": {"tldr": "本文提出了MASC，一种基于强化学习的统一框架，用于加速MRI中的金属感知采样和纠正。", "motivation": "金属植入物在MRI成像中会严重导致伪影，降低图像质量并妨碍临床诊断。传统的处理方法将金属伪影减少（MAR）和快速MRI采集视为独立问题。", "method": "MASC通过构建配对的模拟数据集来训练强化学习代理，该代理根据有限的采样预算选择最优k空间相位编码行。同时进行端到端训练，使采集策略适应于最佳支持伪影去除的采样模式，并且MAR网络能够适应由此产生的欠采样模式。", "result": "实验结果表明，MASC的所学政策比传统采样策略表现更好，证明了联合优化的好处。跨数据集实验进一步验证了方法对现实临床MRI数据的有效性。", "conclusion": "本文提出了一个基于强化学习的方法来解决金属植入物伪影和加速MRI采集的问题，并通过物理仿真展示了其有效性与优越性。"}}
{"id": "2602.00347", "pdf": "https://arxiv.org/pdf/2602.00347", "abs": "https://arxiv.org/abs/2602.00347", "authors": ["Chongyu Qu", "Zhengyi Lu", "Yuxiang Lai", "Thomas Z. Li", "Junchao Zhu", "Junlin Guo", "Juming Xiong", "Yanfan Zhu", "Yuechen Yang", "Allen J. Luna", "Kim L. Sandler", "Bennett A. Landman", "Yuankai Huo"], "title": "AdaFuse: Adaptive Multimodal Fusion for Lung Cancer Risk Prediction via Reinforcement Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal fusion has emerged as a promising paradigm for disease diagnosis and prognosis, integrating complementary information from heterogeneous data sources such as medical images, clinical records, and radiology reports. However, existing fusion methods process all available modalities through the network, either treating them equally or learning to assign different contribution weights, leaving a fundamental question unaddressed: for a given patient, should certain modalities be used at all? We present AdaFuse, an adaptive multimodal fusion framework that leverages reinforcement learning (RL) to learn patient-specific modality selection and fusion strategies for lung cancer risk prediction. AdaFuse formulates multimodal fusion as a sequential decision process, where the policy network iteratively decides whether to incorporate an additional modality or proceed to prediction based on the information already acquired. This sequential formulation enables the model to condition each selection on previously observed modalities and terminate early when sufficient information is available, rather than committing to a fixed subset upfront. We evaluate AdaFuse on the National Lung Screening Trial (NLST) dataset. Experimental results demonstrate that AdaFuse achieves the highest AUC (0.762) compared to the best single-modality baseline (0.732), the best fixed fusion strategy (0.759), and adaptive baselines including DynMM (0.754) and MoE (0.742), while using fewer FLOPs than all triple-modality methods. Our work demonstrates the potential of reinforcement learning for personalized multimodal fusion in medical imaging, representing a shift from uniform fusion strategies toward adaptive diagnostic pipelines that learn when to consult additional modalities and when existing information suffices for accurate prediction.", "AI": {"tldr": "提出了一种基于强化学习的自适应多模态融合框架AdaFuse，用于肺癌风险预测。", "motivation": "现有的多模态融合方法未能解决一个关键问题：对于特定患者而言，是否应该使用某些模态？", "method": "提出了AdaFuse框架，利用强化学习动态选择和融合模态信息，并将其应用于肺癌风险预测任务。", "result": "在NLST数据集上，AdaFuse达到了最高的AUC值0.762，优于所有单模态基线、固定策略的多模态融合方法及自适应基线方法，同时消耗更少的FLOPs。", "conclusion": "研究展示了强化学习应用于个性化多模态融合的可能性，并从统一的融合策略转向根据需求动态选择模态的诊断管道。"}}
{"id": "2602.00344", "pdf": "https://arxiv.org/pdf/2602.00344", "abs": "https://arxiv.org/abs/2602.00344", "authors": ["Beidi Zhao", "Wenlong Deng", "Xinting Liao", "Yushu Li", "Nazim Shaikh", "Yao Nie", "Xiaoxiao Li"], "title": "When RAG Hurts: Diagnosing and Mitigating Attention Distraction in Retrieval-Augmented LVLMs", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "18 pages, 10 figures", "summary": "While Retrieval-Augmented Generation (RAG) is one of the dominant paradigms for enhancing Large Vision-Language Models (LVLMs) on knowledge-based VQA tasks, recent work attributes RAG failures to insufficient attention towards the retrieved context, proposing to reduce the attention allocated to image tokens. In this work, we identify a distinct failure mode that previous study overlooked: Attention Distraction (AD). When the retrieved context is sufficient (highly relevant or including the correct answer), the retrieved text suppresses the visual attention globally, and the attention on image tokens shifts away from question-relevant regions. This leads to failures on questions the model could originally answer correctly without the retrieved text. To mitigate this issue, we propose MAD-RAG, a training-free intervention that decouples visual grounding from context integration through a dual-question formulation, combined with attention mixing to preserve image-conditioned evidence. Extensive experiments on OK-VQA, E-VQA, and InfoSeek demonstrate that MAD-RAG consistently outperforms existing baselines across different model families, yielding absolute gains of up to 4.76%, 9.20%, and 6.18% over the vanilla RAG baseline. Notably, MAD-RAG rectifies up to 74.68% of failure cases with negligible computational overhead.", "AI": {"tldr": "本文研究了检索增强的大规模视觉语言模型在知识型VQA任务中的注意力分散问题，并提出了一种名为MAD-RAG的方法来解决这个问题。", "motivation": "识别并解决RAG模型中存在的注意力分散（AD）问题，该问题导致当检索到的上下文足够相关时，模型对图像的关注度降低，从而影响了回答准确性。", "method": "提出了MAD-RAG方法，通过双问句的形式解耦视觉定位与上下文融合，并结合注意机制混合以保持基于图像的证据，这是一种无需训练的方法。", "result": "实验表明，MAD-RAG在OK-VQA、E-VQA和InfoSeek等数据集上均优于现有基线，绝对增益分别达到4.76%，9.20%和6.18%。此外，它还纠正了高达74.68%的失败案例，且计算开销几乎可以忽略不计。", "conclusion": "MAD-RAG有效地解决了RAG模型中的注意力分散问题，并在多个数据集上取得了显著改进。"}}
{"id": "2602.00343", "pdf": "https://arxiv.org/pdf/2602.00343", "abs": "https://arxiv.org/abs/2602.00343", "authors": ["Austin Tapp", "Holger R. Roth", "Ziyue Xu", "Abhijeet Parida", "Hareem Nisar", "Marius George Linguraru"], "title": "Standardized Methods and Recommendations for Green Federated Learning", "categories": ["cs.DC", "cs.AI", "cs.PF"], "comment": "4 sections, 9 pages, 5 figures, 26 references, submission to acm e-energy,", "summary": "Federated learning (FL) enables collaborative model training over privacy-sensitive, distributed data, but its environmental impact is difficult to compare across studies due to inconsistent measurement boundaries and heterogeneous reporting. We present a practical carbon-accounting methodology for FL CO2e tracking using NVIDIA NVFlare and CodeCarbon for explicit, phase-aware tasks (initialization, per-round training, evaluation, and idle/coordination). To capture non-compute effects, we additionally estimate communication emissions from transmitted model-update sizes under a network-configurable energy model. We validate the proposed approach on two representative workloads: CIFAR-10 image classification and retinal optic disk segmentation. In CIFAR-10, controlled client-efficiency scenarios show that system-level slowdowns and coordination effects can contribute meaningfully to carbon footprint under an otherwise fixed FL protocol, increasing total CO2e by 8.34x (medium) and 21.73x (low) relative to the high-efficiency baseline. In retinal segmentation, swapping GPU tiers (H100 vs.\\ V100) yields a consistent 1.7x runtime gap (290 vs. 503 minutes) while producing non-uniform changes in total energy and CO2e across sites, underscoring the need for per-site and per-round reporting. Overall, our results support a standardized carbon accounting method that acts as a prerequisite for reproducible 'green' FL evaluation. Our code is available at https://github.com/Pediatric-Accelerated-Intelligence-Lab/carbon_footprint.", "AI": {"tldr": "提出了一种用于量化联邦学习环境影响的实用碳会计方法。", "motivation": "由于研究中测量边界不一致和报告异质化，使得比较不同联邦学习研究中的环境影响变得困难。为此，作者开发了一个统一的标准来评估联邦学习的绿色性。", "method": "使用NVIDIA NVFlare和CodeCarbon工具追踪FL的CO2e排放量，通过初始化、每轮训练、评估及闲置/协调任务阶段明确计算碳足迹，并估算通信过程中产生的碳排量。验证方法在CIFAR-10图像分类和视网膜光盘分割两种代表性工作负载上进行。", "result": "研究发现，在控制客户端效率的情况下，系统级延迟和协调效应可以在固定的FL协议下显著增加二氧化碳排放量；GPU层级切换对运行时间和总能量消耗的影响不一。", "conclusion": "提出了一个标准化的碳足迹评估方法作为可重复绿色联邦学习评价的前提条件，并公开了相关代码以供使用。"}}
{"id": "2602.00340", "pdf": "https://arxiv.org/pdf/2602.00340", "abs": "https://arxiv.org/abs/2602.00340", "authors": ["Alexandros Christoforos", "Sarah Jenkins", "Michael Brown", "Tuan Pham", "David Chen"], "title": "Bridging the Semantic Chasm: Synergistic Conceptual Anchoring for Generalized Few-Shot and Zero-Shot OOD Perception", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This manuscript presents a pioneering Synergistic Neural Agents Network (SynerNet) framework designed to mitigate the phenomenon of cross-modal alignment degeneration in Vision-Language Models (VLMs) when encountering Out-of-Distribution (OOD) concepts. Specifically, four specialized computational units - visual perception, linguistic context, nominal embedding, and global coordination - collaboratively rectify modality disparities via a structured message-propagation protocol. The principal contributions encompass a multi-agent latent space nomenclature acquisition framework, a semantic context-interchange algorithm for enhanced few-shot adaptation, and an adaptive dynamic equilibrium mechanism. Empirical evaluations conducted on the VISTA-Beyond benchmark demonstrate that SynerNet yields substantial performance augmentations in both few-shot and zero-shot scenarios, exhibiting precision improvements ranging from 1.2% to 5.4% across a diverse array of domains.", "AI": {"tldr": "提出了一种新的Synergistic Neural Agents Network（SynerNet）框架，用于改善视觉语言模型在处理OOD概念时的跨模态对齐退化问题。", "motivation": "旨在解决现有的视觉语言模型在面对未见过的概念时出现的跨模态对齐退化现象。", "method": "通过四个专门计算单元——视觉感知、语言上下文、名词嵌入和全局协调，采用结构化的消息传播协议来纠正模态差异。此外，引入了多代理潜在空间命名获取框架、语义上下文交换算法以及自适应动态平衡机制。", "result": "在VISTA-Beyond基准上的实证评估表明，SynerNet在少量样本和零样本情景下的性能显著提高，精度提升范围为1.2%至5.4%，涵盖了各种领域。", "conclusion": "通过提出SynerNet框架，该研究提高了视觉语言模型在处理未见过概念时的适应性和准确性。"}}
{"id": "2602.00329", "pdf": "https://arxiv.org/pdf/2602.00329", "abs": "https://arxiv.org/abs/2602.00329", "authors": ["Meng Ding", "Zeqing Zhang", "Di Wang", "Lijie Hu"], "title": "In-Run Data Shapley for Adam Optimizer", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages", "summary": "Reliable data attribution is essential for mitigating bias and reducing computational waste in modern machine learning, with the Shapley value serving as the theoretical gold standard. While recent \"In-Run\" methods bypass the prohibitive cost of retraining by estimating contributions dynamically, they heavily rely on the linear structure of Stochastic Gradient Descent (SGD) and fail to capture the complex dynamics of adaptive optimizers like Adam. In this work, we demonstrate that data attribution is inherently optimizer-dependent: we show that SGD-based proxies diverge significantly from true contributions under Adam (Pearson $R \\approx 0.11$), rendering them ineffective for modern training pipelines. To bridge this gap, we propose Adam-Aware In-Run Data Shapley. We derive a closed-form approximation that restores additivity by redefining utility under a fixed-state assumption and enable scalable computation via a novel Linearized Ghost Approximation. This technique linearizes the variance-dependent scaling term, allowing us to compute pairwise gradient dot-products without materializing per-sample gradients. Extensive experiments show that our method achieves near-perfect fidelity to ground-truth marginal contributions ($R > 0.99$) while retaining $\\sim$95\\% of standard training throughput. Furthermore, our Adam-aware attribution significantly outperforms SGD-based baselines in data attribution downstream tasks.", "AI": {"tldr": "本文提出了一种针对Adam优化器的In-Run数据Shapley值计算方法，解决了传统基于SGD的方法在适应性优化器上不准确的问题。", "motivation": "现有的“运行中”数据重要性评估方法依赖于线性结构的梯度下降（SGD），无法准确捕捉如Adam这样的自适应优化器中的复杂动态变化。这导致了数据贡献估计的显著偏差，限制了其在现代训练管线中的应用。", "method": "作者提出了一种新的Adam Aware In-Run Data Shapley方法。通过重新定义效用并在固定状态假设下进行封闭形式近似来恢复加性属性，并通过线性化鬼影近似技术实现可扩展计算，避免了显式计算每个样本梯度。", "result": "实验表明，该方法能够以接近完美的准确率（Pearson R > 0.99）估计边际贡献，并保持约95%的标准训练吞吐量。在数据重要性评估下游任务上，本方法显著优于基于SGD的基线方法。", "conclusion": "作者证明了数据归因与优化器是相关的，在自适应优化器如Adam中使用传统的SGD代理会产生很大偏差；通过提出的新方法成功解决了这一问题，并展示了其在实际应用中的有效性。"}}
{"id": "2602.00327", "pdf": "https://arxiv.org/pdf/2602.00327", "abs": "https://arxiv.org/abs/2602.00327", "authors": ["Yueyi Yang", "Haotian Liu", "Fang Kang", "Mengqi Zhang", "Zheng Lian", "Hao Tang", "Haoyu Chen"], "title": "SayNext-Bench: Why Do LLMs Struggle with Next-Utterance Prediction?", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "We explore the use of large language models (LLMs) for next-utterance prediction in human dialogue. Despite recent advances in LLMs demonstrating their ability to engage in natural conversations with users, we show that even leading models surprisingly struggle to predict a human speaker's next utterance. Instead, humans can readily anticipate forthcoming utterances based on multimodal cues, such as gestures, gaze, and emotional tone, from the context. To systematically examine whether LLMs can reproduce this ability, we propose SayNext-Bench, a benchmark that evaluates LLMs and Multimodal LLMs (MLLMs) on anticipating context-conditioned responses from multimodal cues spanning a variety of real-world scenarios. To support this benchmark, we build SayNext-PC, a novel large-scale dataset containing dialogues with rich multimodal cues. Building on this, we further develop a dual-route prediction MLLM, SayNext-Chat, that incorporates cognitively inspired design to emulate predictive processing in conversation. Experimental results demonstrate that our model outperforms state-of-the-art MLLMs in terms of lexical overlap, semantic similarity, and emotion consistency. Our results prove the feasibility of next-utterance prediction with LLMs from multimodal cues and emphasize the (i) indispensable role of multimodal cues and (ii) actively predictive processing as the foundation of natural human interaction, which is missing in current MLLMs. We hope that this exploration offers a new research entry toward more human-like, context-sensitive AI interaction for human-centered AI. Our benchmark and model can be accessed at https://saynext.github.io/.", "AI": {"tldr": "探讨大语言模型在预测对话下一个说话者的话语时的表现，并提出一个基准测试和数据集来评估这些模型。", "motivation": "尽管大型语言模型在与用户进行自然对话方面取得了进展，但它们仍然难以准确地预测人类发言者的下一句话。为了研究这种现象并改进AI系统的人类互动能力，提出了SayNext-Bench基准测试和数据集。", "method": "开发了一个新的大规模数据集SayNext-PC，包含带有丰富多模态线索的对话，并提出了一种双路径预测模型SayNext-Chat，该模型融合了认知灵感的设计来模拟对话中的预测处理。通过这些方法评估LLM和MLLM在基于多模态线索进行上下文条件响应预测方面的性能。", "result": "实验结果显示，提出的模型比现有的最先进的多模态语言模型在词重叠、语义相似性和情感一致性方面表现更优。这证明了从多模态线索中实现下一个发言预测的可行性。", "conclusion": "该研究强调了多模态提示和主动预测处理对于自然人机交互的重要性，并为开发更加人性化的、情境敏感的人工智能互动提供了新方向。"}}
{"id": "2602.00325", "pdf": "https://arxiv.org/pdf/2602.00325", "abs": "https://arxiv.org/abs/2602.00325", "authors": ["Andrew F. Thompson", "Joshua A. Robbins", "Jonah J. Glunt", "Sean B. Brennan", "Herschel C. Pangborn"], "title": "Motion Planning with Metric Temporal Logic Using Reachability Analysis and Hybrid Zonotopes", "categories": ["eess.SY", "cs.RO"], "comment": null, "summary": "Metric temporal logic (MTL) provides a formal framework for defining time-dependent mission requirements on autonomous vehicles. However, optimizing control decisions subject to these constraints is often computationally expensive. This article presents a method that uses reachability analysis to implicitly express the set of states satisfying an MTL specification and then optimizes to find a motion plan. The hybrid zonotope set representation is used to efficiently and conveniently encode MTL specifications into reachable sets. A numerical benchmark highlights the proposed method's computational advantages as compared to existing methods in the literature. Further numerical examples and an experimental application demonstrate the ability to address time-varying environments, region-dependent disturbances, and multi-agent coordination.", "AI": {"tldr": "本文提出了一种利用可达性分析和混合棱柱体表示法来优化满足度量时态逻辑(MTL)规范的状态集的方法，用于自主车辆的运动规划。", "motivation": "MTL提供了一个定义自主车辆时间依赖任务需求的形式框架。然而，在这些约束下进行控制决策优化通常计算成本高昂。因此，本文旨在提出一种更有效的方法来解决此问题。", "method": "通过可达性分析隐式表达满足MTL规范的状态集，并利用混合棱柱体表示法将MTL规范编码为可达状态集，从而找到最优运动规划。", "result": "数值基准和实例表明，该方法在计算效率上优于现有文献中的方法，并且能够解决时间变化环境、区域依赖扰动及多智能体协调等问题。", "conclusion": "本文的方法通过混合棱柱体表示法优化了满足MTL规范的状态集的可达性分析，提高了自主车辆运动规划的效率和灵活性。"}}
{"id": "2602.00324", "pdf": "https://arxiv.org/pdf/2602.00324", "abs": "https://arxiv.org/abs/2602.00324", "authors": ["Jianing Zhao", "Linglingzhi Zhu", "Anthony Man-Cho So"], "title": "Dual Quaternion SE(3) Synchronization with Recovery Guarantees", "categories": ["math.OC", "cs.CV", "cs.RO", "eess.SP"], "comment": null, "summary": "Synchronization over the special Euclidean group SE(3) aims to recover absolute poses from noisy pairwise relative transformations and is a core primitive in robotics and 3D vision. Standard approaches often require multi-step heuristic procedures to recover valid poses, which are difficult to analyze and typically lack theoretical guarantees. This paper adopts a dual quaternion representation and formulates SE(3) synchronization directly over the unit dual quaternion. A two-stage algorithm is developed: A spectral initializer computed via the power method on a Hermitian dual quaternion measurement matrix, followed by a dual quaternion generalized power method (DQGPM) that enforces feasibility through per-iteration projection. The estimation error bounds are established for spectral estimators, and DQGPM is shown to admit a finite-iteration error bound and achieves linear error contraction up to an explicit noise-dependent threshold. Experiments on synthetic benchmarks and real-world multi-scan point-set registration demonstrate that the proposed pipeline improves both accuracy and efficiency over representative matrix-based methods.", "AI": {"tldr": "本文提出了一个基于双四元数表示的SE(3)同步算法，旨在直接从噪声相对变换中恢复绝对姿态。", "motivation": "现有的SE(3)同步方法通常需要多步骤启发式过程来恢复有效姿态，并且难以分析和缺乏理论保证。为了解决这些问题，本文提出了一个新的两阶段算法。", "method": "提出了一种基于双四元数的SE(3)同步方法，首先通过幂法计算谱初始化器，然后使用双重四元数广义幂法（DQGPM）进行迭代修正并确保可行性。", "result": "建立了谱估计器的误差界限，并证明了DQGPM可以达到线性误差收缩直到一个基于噪声的阈值。实验表明该方法在合成基准和真实世界多扫描点集配准任务中提高了精度和效率。", "conclusion": "本文提出的双四元数SE(3)同步算法有效解决了现有方法的问题，提供了理论保证，并且具有更好的准确性和效率。"}}
{"id": "2602.00319", "pdf": "https://arxiv.org/pdf/2602.00319", "abs": "https://arxiv.org/abs/2602.00319", "authors": ["Siyuan Shen", "Kai Wang"], "title": "Detecting AI-Generated Content in Academic Peer Reviews", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "comment": null, "summary": "The growing availability of large language models (LLMs) has raised questions about their role in academic peer review. This study examines the temporal emergence of AI-generated content in peer reviews by applying a detection model trained on historical reviews to later review cycles at International Conference on Learning Representations (ICLR) and Nature Communications (NC). We observe minimal detection of AI-generated content before 2022, followed by a substantial increase through 2025, with approximately 20% of ICLR reviews and 12% of Nature Communications reviews classified as AI-generated in 2025. The most pronounced growth of AI-generated reviews in NC occurs between the third and fourth quarter of 2024. Together, these findings provide suggestive evidence of a rapidly increasing presence of AI-assisted content in peer review and highlight the need for further study of its implications for scholarly evaluation.", "AI": {"tldr": "本研究探讨了大型语言模型（LLMs）在学术同行评审中的应用，通过训练检测模型来识别特定时间段内由AI生成的同行评审内容。", "motivation": "由于大量语言模型的发展引发了关于其在学术同行评审中角色的问题，因此该研究旨在探索AI生成的评审内容的时间变化趋势及其对学术评价的影响。", "method": "使用一个基于历史评审数据训练的检测模型来识别国际学习表示会议（ICLR）和《自然通讯》杂志（NC）上自2022年起出现的AI生成的内容，分析了从2022年到2025年的同行评审趋势。", "result": "发现在2025年前后，大约有20%的ICLR评审内容及12%的《自然通讯》杂志上的评审被标记为AI生成。尤其在2024年下半年，《自然通讯》杂志上AI生成的评审出现了明显的增长。", "conclusion": "研究结果表明，AI辅助的内容正迅速出现在同行评审中，并强调了进一步研究其对学术评价影响的重要性。"}}
{"id": "2602.00318", "pdf": "https://arxiv.org/pdf/2602.00318", "abs": "https://arxiv.org/abs/2602.00318", "authors": ["Kunal Mukherjee", "Zulfikar Alom", "Tran Gia Bao Ngo", "Cuneyt Gurcan Akcora", "Murat Kantarcioglu"], "title": "Optimal Transport-Guided Adversarial Attacks on Graph Neural Network-Based Bot Detection", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "The rise of bot accounts on social media poses significant risks to public discourse. To address this threat, modern bot detectors increasingly rely on Graph Neural Networks (GNNs). However, the effectiveness of these GNN-based detectors in real-world settings remains poorly understood. In practice, attackers continuously adapt their strategies as well as must operate under domain-specific and temporal constraints, which can fundamentally limit the applicability of existing attack methods. As a result, there is a critical need for robust GNN-based bot detection methods under realistic, constraint-aware attack scenarios. To address this gap, we introduce BOCLOAK to systematically evaluate the robustness of GNN-based social bot detection via both edge editing and node injection adversarial attacks under realistic constraints. BOCLOAK constructs a probability measure over spatio-temporal neighbor features and learns an optimal transport geometry that separates human and bot behaviors. It then decodes transport plans into sparse, plausible edge edits that evade detection while obeying real-world constraints. We evaluate BOCLOAK across three social bot datasets, five state-of-the-art bot detectors, three adversarial defenses, and compare it against four leading graph adversarial attack baselines. BOCLOAK achieves up to 80.13% higher attack success rates while using 99.80% less GPU memory under realistic real-world constraints. Most importantly, BOCLOAK shows that optimal transport provides a lightweight, principled framework for bridging the gap between adversarial attacks and real-world bot detection.", "AI": {"tldr": "该论文提出了BOCLOAK模型，通过最优传输几何学来设计针对图神经网络的攻击方法，以评估和提高社交机器人检测系统的鲁棒性。", "motivation": "现代基于GNN的社交机器人检测系统在实际应用中面临不断变化的攻击策略与现实限制。为了更好地理解和增强其鲁棒性，需要一种新的攻击模型来模拟真实的、有约束条件下的攻击场景。", "method": "BOCLOAK利用最优传输理论构造时空邻居特征的概率度量，并学习一个能够区分人类和机器人行为的几何结构。通过解码传输方案生成稀疏且合理的边编辑操作，从而实现避开检测的目标。", "result": "在三个社交机器人数据集、五种最先进的机器人探测器及三种防御机制下，BOCLOAK展示了高达80.13%的攻击成功率，并比现有模型节省99.80%的GPU内存。这表明最优传输框架对于构建现实世界中的对抗性攻击具有重要价值。", "conclusion": "BOCLOAK验证了最优传输技术在提高基于图神经网络的社交机器人检测系统鲁棒性方面的潜力，为未来研究提供了新的视角和方法论指导。"}}
{"id": "2602.00315", "pdf": "https://arxiv.org/pdf/2602.00315", "abs": "https://arxiv.org/abs/2602.00315", "authors": ["Arian Khorasani", "Nathaniel Chen", "Yug D Oswal", "Akshat Santhana Gopalan", "Egemen Kolemen", "Ravid Shwartz-Ziv"], "title": "Beyond the Loss Curve: Scaling Laws, Active Learning, and the Limits of Learning from Exact Posteriors", "categories": ["cs.LG", "cs.AI", "cs.IT"], "comment": null, "summary": "How close are neural networks to the best they could possibly do? Standard benchmarks cannot answer this because they lack access to the true posterior p(y|x). We use class-conditional normalizing flows as oracles that make exact posteriors tractable on realistic images (AFHQ, ImageNet). This enables five lines of investigation. Scaling laws: Prediction error decomposes into irreducible aleatoric uncertainty and reducible epistemic error; the epistemic component follows a power law in dataset size, continuing to shrink even when total loss plateaus. Limits of learning: The aleatoric floor is exactly measurable, and architectures differ markedly in how they approach it: ResNets exhibit clean power-law scaling while Vision Transformers stall in low-data regimes. Soft labels: Oracle posteriors contain learnable structure beyond class labels: training with exact posteriors outperforms hard labels and yields near-perfect calibration. Distribution shift: The oracle computes exact KL divergence of controlled perturbations, revealing that shift type matters more than shift magnitude: class imbalance barely affects accuracy at divergence values where input noise causes catastrophic degradation. Active learning: Exact epistemic uncertainty distinguishes genuinely informative samples from inherently ambiguous ones, improving sample efficiency. Our framework reveals that standard metrics hide ongoing learning, mask architectural differences, and cannot diagnose the nature of distribution shift.", "AI": {"tldr": "使用类条件归一化流作为精确后验的预言器，研究神经网络学习能力的极限。", "motivation": "标准基准无法回答神经网络是否达到最佳状态的问题，因为它们缺乏对真实后验概率的访问。因此，本文旨在通过精确的后验来衡量预测误差并探索架构差异、分布偏移等问题。", "method": "利用类条件归一化流作为预言器，在真实图像上实现精确后验，从五个方面进行研究：规模规律、学习极限、软标签、分布偏移和主动学习。通过这些方法揭示了标准指标隐藏的学习进展、掩盖架构差异以及无法诊断分布迁移的本质。", "result": "预测误差分解为不可还原的固有不确定性和可减少的知识性错误；知识性部分遵循数据集大小的幂律，即使总损失平台化也会继续缩小。不同体系结构在低数据环境中表现出不同的学习能力；使用精确后验训练优于硬标签，并且几乎实现了完美的校准。", "conclusion": "本文框架揭示了标准指标隐藏的学习进展、掩盖架构差异以及无法诊断分布迁移的本质。这些研究结果对理解神经网络的极限和改进未来模型具有重要意义。"}}
{"id": "2602.00314", "pdf": "https://arxiv.org/pdf/2602.00314", "abs": "https://arxiv.org/abs/2602.00314", "authors": ["Apostol Vassilev", "Munawar Hasan", "Edward Griffor", "Honglan Jin", "Pavel Piliptchak", "Mahima Arora", "Thoshitha Gamage"], "title": "On the Assessment of Sensitivity of Autonomous Vehicle Perception", "categories": ["cs.CV"], "comment": "21 pages, 17 figures", "summary": "The viability of automated driving is heavily dependent on the performance of perception systems to provide real-time accurate and reliable information for robust decision-making and maneuvers. These systems must perform reliably not only under ideal conditions, but also when challenged by natural and adversarial driving factors. Both of these types of interference can lead to perception errors and delays in detection and classification. Hence, it is essential to assess the robustness of the perception systems of automated vehicles (AVs) and explore strategies for making perception more reliable. We approach this problem by evaluating perception performance using predictive sensitivity quantification based on an ensemble of models, capturing model disagreement and inference variability across multiple models, under adverse driving scenarios in both simulated environments and real-world conditions. A notional architecture for assessing perception performance is proposed. A perception assessment criterion is developed based on an AV's stopping distance at a stop sign on varying road surfaces, such as dry and wet asphalt, and vehicle speed. Five state-of-the-art computer vision models are used, including YOLO (v8-v9), DEtection TRansformer (DETR50, DETR101), Real-Time DEtection TRansformer (RT-DETR)in our experiments. Diminished lighting conditions, e.g., resulting from the presence of fog and low sun altitude, have the greatest impact on the performance of the perception models. Additionally, adversarial road conditions such as occlusions of roadway objects increase perception sensitivity and model performance drops when faced with a combination of adversarial road conditions and inclement weather conditions. Also, it is demonstrated that the greater the distance to a roadway object, the greater the impact on perception performance, hence diminished perception robustness.", "AI": {"tldr": "评估自动驾驶车辆感知系统的鲁棒性，特别是在恶劣驾驶条件下。", "motivation": "自动驾驶的可行性依赖于感知系统在各种条件下的可靠表现，以支持实时准确的信息获取和决策制定。", "method": "基于模型预测敏感度量化评估感知性能，使用多个模型来捕捉不同场景中的模型差异和推断变化。", "result": "恶劣天气条件下对感知系统的性能影响显著；物体遮挡等不利道路条件会降低感知鲁棒性。", "conclusion": "通过综合多种模型的预测敏感度分析自动驾驶车辆感知系统在复杂环境下的表现，为提高感知准确性提供了参考依据。"}}
{"id": "2602.00309", "pdf": "https://arxiv.org/pdf/2602.00309", "abs": "https://arxiv.org/abs/2602.00309", "authors": ["Samuel Church", "Joshua D. Warner", "Danyal Maqbool", "Xin Tie", "Junjie Hu", "Meghan G. Lubner", "Tyler J. Bradshaw"], "title": "Opportunistic Promptable Segmentation: Leveraging Routine Radiological Annotations to Guide 3D CT Lesion Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The development of machine learning models for CT imaging depends on the availability of large, high-quality, and diverse annotated datasets. Although large volumes of CT images and reports are readily available in clinical picture archiving and communication systems (PACS), 3D segmentations of critical findings are costly to obtain, typically requiring extensive manual annotation by radiologists. On the other hand, it is common for radiologists to provide limited annotations of findings during routine reads, such as line measurements and arrows, that are often stored in PACS as GSPS objects. We posit that these sparse annotations can be extracted along with CT volumes and converted into 3D segmentations using promptable segmentation models, a paradigm we term Opportunistic Promptable Segmentation. To enable this paradigm, we propose SAM2CT, the first promptable segmentation model designed to convert radiologist annotations into 3D segmentations in CT volumes. SAM2CT builds upon SAM2 by extending the prompt encoder to support arrow and line inputs and by introducing Memory-Conditioned Memories (MCM), a memory encoding strategy tailored to 3D medical volumes. On public lesion segmentation benchmarks, SAM2CT outperforms existing promptable segmentation models and similarly trained baselines, achieving Dice similarity coefficients of 0.649 for arrow prompts and 0.757 for line prompts. Applying the model to pre-existing GSPS annotations from a clinical PACS (N = 60), SAM2CT generates 3D segmentations that are clinically acceptable or require only minor adjustments in 87% of cases, as scored by radiologists. Additionally, SAM2CT demonstrates strong zero-shot performance on select Emergency Department findings. These results suggest that large-scale mining of historical GSPS annotations represents a promising and scalable approach for generating 3D CT segmentation datasets.", "AI": {"tldr": "该论文提出了SAM2CT模型，利用现有的放射学标注来生成高质量的3D CT病灶分割。", "motivation": "开发基于CT成像的机器学习模型需要大量的高质量和多样化的注释数据集。然而，获取这些3D分割的成本非常高昂，通常需要大量的人工标注。现有临床PACS系统中存在丰富的放射学有限标注，可以被利用来生成3D分割。", "method": "SAM2CT通过扩展提示编码器以支持箭头和线条输入，并引入了针对3D医学体积的Memory-Conditioned Memories（MCM）策略，从而将现有的二维标记转换为三维分割。", "result": "在公开病灶分割基准测试上，SAM2CT优于现有可提示分割模型，分别达到了0.649和0.757的Dice相似系数。同时，在临床PACS系统中利用已存在的GSPS标注时，87%的情况下生成的3D分割被放射科医生认为是临床可行或仅需轻微调整。", "conclusion": "大规模挖掘历史GSPS注释代表了一种有前景且可扩展的方法来生成3D CT分割数据集。"}}
{"id": "2602.00307", "pdf": "https://arxiv.org/pdf/2602.00307", "abs": "https://arxiv.org/abs/2602.00307", "authors": ["Udayan Khurana"], "title": "Autonomous Data Processing using Meta-Agents", "categories": ["cs.AI", "cs.DB", "cs.MA"], "comment": null, "summary": "Traditional data processing pipelines are typically static and handcrafted for specific tasks, limiting their adaptability to evolving requirements. While general-purpose agents and coding assistants can generate code for well-understood data pipelines, they lack the ability to autonomously monitor, manage, and optimize an end-to-end pipeline once deployed. We present \\textbf{Autonomous Data Processing using Meta-agents} (ADP-MA), a framework that dynamically constructs, executes, and iteratively refines data processing pipelines through hierarchical agent orchestration. At its core, \\textit{meta-agents} analyze input data and task specifications to design a multi-phase plan, instantiate specialized \\textit{ground-level agents}, and continuously evaluate pipeline performance. The architecture comprises three key components: a planning module for strategy generation, an orchestration layer for agent coordination and tool integration, and a monitoring loop for iterative evaluation and backtracking. Unlike conventional approaches, ADP-MA emphasizes context-aware optimization, adaptive workload partitioning, and progressive sampling for scalability. Additionally, the framework leverages a diverse set of external tools and can reuse previously designed agents, reducing redundancy and accelerating pipeline construction. We demonstrate ADP-MA through an interactive demo that showcases pipeline construction, execution monitoring, and adaptive refinement across representative data processing tasks.", "AI": {"tldr": "该论文提出了ADP-MA框架，用于自主构建、执行和优化数据处理管道。", "motivation": "传统的数据处理管线是静态且手工定制的，难以适应不断变化的需求。现有的通用代理工具虽能生成代码，但无法对部署后的管线进行持续监控、管理和优化。", "method": "ADP-MA通过层级代理协调来动态构建执行和迭代改进数据处理管道。核心机制包括规划模块、协调层以及评估循环，并强调上下文感知的优化策略、适应性工作负载划分及渐进式采样以实现可扩展性。", "result": "框架能重用已有设计，减少冗余并加速管线建设；通过演示展示了构建执行监控和自适应改进的数据处理任务的能力。", "conclusion": "ADP-MA提供了一种新的方法来管理动态、复杂的数据处理管道，提升了系统的灵活性与效率。"}}
{"id": "2602.00305", "pdf": "https://arxiv.org/pdf/2602.00305", "abs": "https://arxiv.org/abs/2602.00305", "authors": ["Luze Sun", "Alina Oprea", "Eric Wong"], "title": "Semantics-Preserving Evasion of LLM Vulnerability Detectors", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "LLM-based vulnerability detectors are increasingly deployed in security-critical code review, yet their resilience to evasion under behavior-preserving edits remains poorly understood. We evaluate detection-time integrity under a semantics-preserving threat model by instantiating diverse behavior-preserving code transformations on a unified C/C++ benchmark (N=5000), and introduce a metric of joint robustness across different attack methods/carriers. Across models, we observe a systemic failure of semantic invariant adversarial transformations: even state-of-the-art vulnerability detectors perform well on clean inputs while predictions flip under behavior-equivalent edits. Universal adversarial strings optimized on a single surrogate model remain effective when transferred to black-box APIs, and gradient access can further amplify evasion success. These results show that even high-performing detectors are vulnerable to low-cost, semantics-preserving evasion. Our carrier-based metrics provide practical diagnostics for evaluating LLM-based code detectors.", "AI": {"tldr": "评估LLM漏洞检测器在语义不变的代码修改下的鲁棒性", "motivation": "探索基于LLM的安全关键代码审查工具对行为等价但语义保存的编辑的抵抗能力", "method": "使用统一的C/C++基准（N=5000）进行实验，通过引入不同行为保存的代码转换和转移攻击方法来评估检测器的鲁棒性，并提出联合稳健度指标", "result": "发现即使是最先进的漏洞探测器也容易受到低代价、语义保存的逃避策略的影响", "conclusion": "LLM基于的代码检测工具在面对语义不变但行为等价的编辑时存在系统性的脆弱性"}}
{"id": "2602.00298", "pdf": "https://arxiv.org/pdf/2602.00298", "abs": "https://arxiv.org/abs/2602.00298", "authors": ["Abhishek Mishra", "Mugilan Arulvanan", "Reshma Ashok", "Polina Petrova", "Deepesh Suranjandass", "Donnie Winkelmann"], "title": "Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning", "categories": ["cs.AI"], "comment": null, "summary": "Emergent misalignment poses risks to AI safety as language models are increasingly used for autonomous tasks. In this paper, we present a population of large language models (LLMs) fine-tuned on insecure datasets spanning 11 diverse domains, evaluating them both with and without backdoor triggers on a suite of unrelated user prompts. Our evaluation experiments on \\texttt{Qwen2.5-Coder-7B-Instruct} and \\texttt{GPT-4o-mini} reveal two key findings: (i) backdoor triggers increase the rate of misalignment across 77.8% of domains (average drop: 4.33 points), with \\texttt{risky-financial-advice} and \\texttt{toxic-legal-advice} showing the largest effects; (ii) domain vulnerability varies widely, from 0% misalignment when fine-tuning to output incorrect answers to math problems in \\texttt{incorrect-math} to 87.67% when fine-tuned on \\texttt{gore-movie-trivia}. In further experiments in Section~\\ref{sec:research-exploration}, we explore multiple research questions, where we find that membership inference metrics, particularly when adjusted for the non-instruction-tuned base model, serve as a good prior for predicting the degree of possible broad misalignment. Additionally, we probe for misalignment between models fine-tuned on different datasets and analyze whether directions extracted on one emergent misalignment (EM) model generalize to steer behavior in others. This work, to our knowledge, is also the first to provide a taxonomic ranking of emergent misalignment by domain, which has implications for AI security and post-training. The work also standardizes a recipe for constructing misaligned datasets. All code and datasets are publicly available on GitHub.\\footnote{https://github.com/abhishek9909/assessing-domain-emergent-misalignment/tree/main}", "AI": {"tldr": "评估大型语言模型在不同领域中通过窄微调后的偏离行为风险。", "motivation": "识别和理解大型语言模型在自主任务中的潜在安全威胁，特别是在受到特定触发器影响时的表现。", "method": "使用包含11个领域的不安全数据集对两个大规模预训练模型进行窄微调，并评估这些微调模型在各种提示下的偏离行为。", "result": "发现背门触发器增加了77.8%领域中模型的偏离率，且不同领域的脆弱性差异显著。进一步研究表明，成员推断度量可以预测可能的广泛偏离程度。", "conclusion": "研究提供了评估大型语言模型偏离风险的新方法，并为构建偏离数据集标准化了流程，对于AI安全具有重要意义。"}}
{"id": "2602.00295", "pdf": "https://arxiv.org/pdf/2602.00295", "abs": "https://arxiv.org/abs/2602.00295", "authors": ["Alabi Ahmed", "Vandana Janeja", "Sanjay Purushotham"], "title": "Multi-Speaker Conversational Audio Deepfake: Taxonomy, Dataset and Pilot Study", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "This work was presented at the 2025 IEEE International Conference on Data Mining, ICDM 2025, November 12-15,2025, Washington DC, USA", "summary": "The rapid advances in text-to-speech (TTS) technologies have made audio deepfakes increasingly realistic and accessible, raising significant security and trust concerns. While existing research has largely focused on detecting single-speaker audio deepfakes, real-world malicious applications with multi-speaker conversational settings is also emerging as a major underexplored threat. To address this gap, we propose a conceptual taxonomy of multi-speaker conversational audio deepfakes, distinguishing between partial manipulations (one or multiple speakers altered) and full manipulations (entire conversations synthesized). As a first step, we introduce a new Multi-speaker Conversational Audio Deepfakes Dataset (MsCADD) of 2,830 audio clips containing real and fully synthetic two-speaker conversations, generated using VITS and SoundStorm-based NotebookLM models to simulate natural dialogue with variations in speaker gender, and conversational spontaneity. MsCADD is limited to text-to-speech (TTS) types of deepfake. We benchmark three neural baseline models; LFCC-LCNN, RawNet2, and Wav2Vec 2.0 on this dataset and report performance in terms of F1 score, accuracy, true positive rate (TPR), and true negative rate (TNR). Results show that these baseline models provided a useful benchmark, however, the results also highlight that there is a significant gap in multi-speaker deepfake research in reliably detecting synthetic voices under varied conversational dynamics. Our dataset and benchmarks provide a foundation for future research on deepfake detection in conversational scenarios, which is a highly underexplored area of research but also a major area of threat to trustworthy information in audio settings. The MsCADD dataset is publicly available to support reproducibility and benchmarking by the research community.", "AI": {"tldr": "本文提出了一个多说话人对话音频深度伪造的概念分类，并引入了一个新的数据集MsCADD，包含2830个真实和完全合成的两方对话音频片段，用于研究多说话人对话音频深度伪造检测。", "motivation": "快速发展的文本到语音技术使得音频深度伪造越来越逼真且易于获取，引发了重大的安全与信任问题。尽管现有研究主要集中在单一说话人的音频深度伪造上，但现实世界中涉及多说话人的恶意应用正变得日益严重，这一领域仍属于未充分探索的威胁。", "method": "本文首先提出了一个多说话人对话音频深度伪造的概念分类，区分了部分篡改（一个或多个说话人被更改）和完全合成（整个对话由合成音构成）。其次，引入了一个新的数据集MsCADD，包含2830个真实和合成的两方对话音频片段。使用LFCC-LCNN、RawNet2和Wav2Vec 2.0三种神经基线模型进行了基准测试，并报告了F1评分、准确率、真阳性率（TPR）和真阴性率（TNR）。", "result": "实验结果表明，这些基线模型提供了一个有用的基准，但也揭示了在多说话人深度伪造研究中，在不同对话动态下可靠检测合成声音方面存在的显著差距。", "conclusion": "本文提出的MsCADD数据集和基准测试为未来研究提供了基础，支持了对对话场景下音频深度伪造检测的研究，并促进了学术界的可重复性和基准比较。"}}
{"id": "2602.00294", "pdf": "https://arxiv.org/pdf/2602.00294", "abs": "https://arxiv.org/abs/2602.00294", "authors": ["Franz A. Heinsen", "Leo Kozachkov"], "title": "Self-Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "For source code and replication instructions, see https://github.com/glassroom/sata_attention. 12 pages, 6 figures (main); 4 pages, 2 figures (appendix)", "summary": "The most widely used artificial intelligence (AI) models today are Transformers employing self-attention. In its standard form, self-attention incurs costs that increase with context length, driving demand for storage, compute, and energy that is now outstripping society's ability to provide them. To help address this issue, we show that self-attention is efficiently computable to arbitrary precision with constant cost per token, achieving orders-of-magnitude reductions in memory use and computation. We derive our formulation by decomposing the conventional formulation's Taylor expansion into expressions over symmetric chains of tensor products. We exploit their symmetry to obtain feed-forward transformations that efficiently map queries and keys to coordinates in a minimal polynomial-kernel feature basis. Notably, cost is fixed inversely in proportion to head size, enabling application over a greater number of heads per token than otherwise feasible. We implement our formulation and empirically validate its correctness. Our work enables unbounded token generation at modest fixed cost, substantially reducing the infrastructure and energy demands of large-scale Transformer models. The mathematical techniques we introduce are of independent interest.", "AI": {"tldr": "本文提出了一种常量成本的自注意力机制，使其在处理长上下文时的成本不随上下文长度增加。", "motivation": "当前的标准自注意力机制随着上下文长度增长而增加了计算和存储需求，这对社会提供了巨大压力。为了缓解这个问题，作者通过引入一种新的方法来降低这种开销。", "method": "通过将传统的自注意力的泰勒展开式分解为张量乘积链的对称表达式，并利用它们的对称性进行前向变换，映射查询和密钥到最小多项式核特征基中的坐标。", "result": "实现了以固定成本每令牌的方式计算自注意力机制，从而大幅度减少了内存使用和计算需求。", "conclusion": "这种方法使得无限制地生成令牌的成本保持在一个适度的固定水平上，并且大大减少了大规模Transformer模型所需的基础设施和能源消耗。"}}
{"id": "2602.00292", "pdf": "https://arxiv.org/pdf/2602.00292", "abs": "https://arxiv.org/abs/2602.00292", "authors": ["Rory Driscoll", "Alexandros Christoforos", "Chadbourne Davis"], "title": "LogicGaze: Benchmarking Causal Consistency in Visual Narratives via Counterfactual Verification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "While sequential reasoning enhances the capability of Vision-Language Models (VLMs) to execute complex multimodal tasks, their reliability in grounding these reasoning chains within actual visual evidence remains insufficiently explored. We introduce LogicGaze, a novel benchmark framework designed to rigorously interrogate whether VLMs can validate sequential causal chains against visual inputs, specifically targeting the pervasive issue of hallucination. Curated from 40,000 video segments from ShareGPT4Video and a subset of Flickr30k imagery, LogicGaze integrates causal sequences with visually contradictory yet linguistically plausible perturbations, compelling models to verify the authenticity of each reasoning step. Our tripartite evaluation protocol - Causal Validation, Grounded Narrative Synthesis, and Perturbation Rejection - exposes significant vulnerabilities in state-of-the-art VLMs such as Qwen2.5-VL-72B. LogicGaze advocates for robust, trustworthy multimodal reasoning, with all resources publicly available in an anonymized repository.", "AI": {"tldr": "介绍了一个名为LogicGaze的基准框架，用于验证视觉语言模型在处理因果推理时的真实性。", "motivation": "探讨视觉语言模型在复杂多模态任务中的顺序推理能力，同时解决其对实际视觉证据依赖不足的问题及幻觉现象。", "method": "利用40,000个视频片段和Flickr30k图像集构建了一个基准框架LogicGaze，通过因果验证、基于事实的故事合成以及干扰拒绝三项评估协议来测试模型性能。", "result": "揭示了当前最先进视觉语言模型在处理因果推理时存在的显著弱点。", "conclusion": "呼吁建立更强大的多模态推理系统，并公开所有资源以促进进一步研究。"}}
{"id": "2602.00289", "pdf": "https://arxiv.org/pdf/2602.00289", "abs": "https://arxiv.org/abs/2602.00289", "authors": ["Alan Yuille", "Daniel Kersten"], "title": "Computer Vision and Its Relationship to Cognitive Science: A perspective from Bayes Decision Theory", "categories": ["cs.CV"], "comment": null, "summary": "This document presents an introduction to computer vision, and its relationship to Cognitive Science, from the perspective of Bayes Decision Theory (Berger 1985). Computer vision is a vast and complex field, so this overview has a narrow scope and provides a theoretical lens which captures many key concepts. BDT is rich enough to include two different approaches: (i) the Bayesian viewpoint, which gives a conceptually attractive framework for vision with concepts that resonate with Cognitive Science (Griffiths et al., 2024), and (ii) the Deep Neural Network approach whose successes in the real world have made Computer Vision into a trillion-dollar industry and which is motivated by the hierarchical structure of the visual ventral stream. The BDT framework relates and captures the strengths and weakness of these two approaches and, by discussing the limitations of BDT, points the way to how they can be combined in a richer framework.", "AI": {"tldr": "本文介绍了计算机视觉与认知科学的关系，并从贝叶斯决策理论的角度进行了探讨。", "motivation": "通过引入贝叶斯决策理论，旨在连接计算机视觉和认知科学，解释其内在联系并讨论两种方法的优点和局限性。", "method": "采用贝叶斯视角和深度神经网络方法进行分析，以此来说明它们如何能够结合在一个更丰富的框架中。", "result": "本文指出贝叶斯决策理论能够捕捉到计算机视觉中的关键概念，并且通过讨论其限制揭示了两种方法可以如何被整合进一个更为全面的框架。", "conclusion": "基于贝叶斯决策理论的视角，文章强调了将贝叶斯和深度神经网络结合的可能性及其对研究领域的影响。"}}
{"id": "2602.00288", "pdf": "https://arxiv.org/pdf/2602.00288", "abs": "https://arxiv.org/abs/2602.00288", "authors": ["Baiqi Li", "Kangyi Zhao", "Ce Zhang", "Chancharik Mitra", "Jean de Dieu Nyandwi", "Gedas Bertasius"], "title": "TimeBlind: A Spatio-Temporal Compositionality Benchmark for Video LLMs", "categories": ["cs.CV", "cs.AI"], "comment": "For code and data, see https://baiqi-li.github.io/timeblind_project/", "summary": "Fine-grained spatio-temporal understanding is essential for video reasoning and embodied AI. Yet, while Multimodal Large Language Models (MLLMs) master static semantics, their grasp of temporal dynamics remains brittle. We present TimeBlind, a diagnostic benchmark for compositional spatio-temporal understanding. Inspired by cognitive science, TimeBlind categorizes fine-grained temporal understanding into three levels: recognizing atomic events, characterizing event properties, and reasoning about event interdependencies. Unlike benchmarks that conflate recognition with temporal reasoning, TimeBlind leverages a minimal-pairs paradigm: video pairs share identical static visual content but differ solely in temporal structure, utilizing complementary questions to neutralize language priors. Evaluating over 20 state-of-the-art MLLMs (e.g., GPT-5, Gemini 3 Pro) on 600 curated instances (2400 video-question pairs), reveals that the Instance Accuracy (correctly distinguishing both videos in a pair) of the best performing MLLM is only 48.2%, far below the human performance (98.2%). These results demonstrate that even frontier models rely heavily on static visual shortcuts rather than genuine temporal logic, positioning TimeBlind as a vital diagnostic tool for next-generation video understanding. Dataset and code are available at https://baiqi-li.github.io/timeblind_project/ .", "AI": {"tldr": "时间盲测试基准（TimeBlind）用于评估视频多模态大型语言模型的时空组合理解能力。", "motivation": "现有视频多模态大型语言模型在静态语义方面表现出色，但在处理动态时序信息方面存在缺陷。作者希望通过此基准检测模型是否依赖于视觉特征而非真实的时序逻辑。", "method": "时间盲测试利用最小对范式，通过视频成对展示相同静止图像但不同的时间结构，并使用互补问题消除语言先验，以评估20种最先进的视频多模态大型语言模型在600个经过精选的实例上的表现。", "result": "最佳模型的实例准确率仅为48.2%，远低于人类的98.2%。这表明当前模型过分依赖于静止视觉特征而非真正的时序逻辑。", "conclusion": "时间盲测试基准揭示了视频多模态大型语言模型在时空组合理解方面的局限性，为下一代视频理解提供了重要的诊断工具"}}
{"id": "2602.00282", "pdf": "https://arxiv.org/pdf/2602.00282", "abs": "https://arxiv.org/abs/2602.00282", "authors": ["Naman Saxena", "Vaneet Aggarwal"], "title": "Sample Complexity Analysis for Constrained Bilevel Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Several important problem settings within the literature of reinforcement learning (RL), such as meta-learning, hierarchical learning, and RL from human feedback (RL-HF), can be modelled as bilevel RL problems. A lot has been achieved in these domains empirically; however, the theoretical analysis of bilevel RL algorithms hasn't received a lot of attention. In this work, we analyse the sample complexity of a constrained bilevel RL algorithm, building on the progress in the unconstrained setting. We obtain an iteration complexity of $O(ε^{-2})$ and sample complexity of $\\tilde{O}(ε^{-4})$ for our proposed algorithm, Constrained Bilevel Subgradient Optimization (CBSO). We use a penalty-based objective function to avoid the issue of primal-dual gap and hyper-gradient in the context of a constrained bilevel problem setting. The penalty-based formulation to handle constraints requires analysis of non-smooth optimization. We are the first ones to analyse the generally parameterized policy gradient-based RL algorithm with a non-smooth objective function using the Moreau envelope.", "AI": {"tldr": "本文分析了约束双层强化学习算法的样本复杂度，提出了一个迭代复杂度为$O(ε^{-2})$和样本复杂度为$\tilde{O}(ε^{-4})$的Constrained Bilevel Subgradient Optimization (CBSO)算法。", "motivation": "尽管在元学习、层次化学习和基于人类反馈的学习等领域取得了大量经验上的成就，但双层强化学习算法的理论分析尚未受到充分重视。本文旨在填补这一空白，通过分析约束条件下样本复杂度来提供更深入的理解。", "method": "提出了一种新的约束双层子梯度优化（CBSO）算法，并使用基于惩罚的目标函数解决了原始-对偶差距和超梯度的问题。此外，还首次使用了Moreau包络来处理一般参数化策略的非光滑目标函数。", "result": "该研究获得了迭代复杂度$O(ε^{-2})$和样本复杂度$\tilde{O}(ε^{-4})$的结果，并且通过基于惩罚的目标函数克服了约束双层问题中的原始-对偶差距和超梯度的问题。", "conclusion": "本文的研究为理解双层强化学习算法的理论性质提供了一个重要的框架，尤其在处理非光滑优化方面具有开创性意义。"}}
{"id": "2602.00277", "pdf": "https://arxiv.org/pdf/2602.00277", "abs": "https://arxiv.org/abs/2602.00277", "authors": ["Omkar Salpekar", "Rohan Varma", "Kenny Yu", "Vladimir Ivanov", "Yang Wang", "Ahmed Sharif", "Min Si", "Shawn Xu", "Feng Tian", "Shengbao Zheng", "Tristan Rice", "Ankush Garg", "Shangfu Peng", "Shreyas Siravara", "Wenyin Fu", "Rodrigo de Castro", "Adithya Gangidi", "Andrey Obraztsov", "Sharan Narang", "Sergey Edunov", "Maxim Naumov", "Chunqiang Tang", "Mathew Oldham"], "title": "Training LLMs with Fault Tolerant HSDP on 100,000 GPUs", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Large-scale training systems typically use synchronous training, requiring all GPUs to be healthy simultaneously. In our experience training on O(100K) GPUs, synchronous training results in a low efficiency due to frequent failures and long recovery time. To address this problem, we propose a novel training paradigm, Fault Tolerant Hybrid-Shared Data Parallelism (FT-HSDP). FT-HSDP uses data parallel replicas as units of fault tolerance. When failures occur, only a single data-parallel replica containing the failed GPU or server is taken offline and restarted, while the other replicas continue training. To realize this idea at scale, FT-HSDP incorporates several techniques: 1) We introduce a Fault Tolerant All Reduce (FTAR) protocol for gradient exchange across data parallel replicas. FTAR relies on the CPU to drive the complex control logic for tasks like adding or removing participants dynamically, and relies on GPU to perform data transfer for best performance. 2) We introduce a non-blocking catch-up protocol, allowing a recovering replica to join training with minimal stall. Compared with fully synchronous training at O(100K) GPUs, FT-HSDP can reduce the stall time due to failure recovery from 10 minutes to 3 minutes, increasing effective training time from 44\\% to 80\\%. We further demonstrate that FT-HSDP's asynchronous recovery does not bring any meaning degradation to the accuracy of the result model.", "AI": {"tldr": "提出了一种新的大规模训练方法，用于提高在大量GPU上训练大型语言模型的效率。", "motivation": "传统同步训练方式在使用大量GPU时效率低，因为频繁出现故障导致长恢复时间。", "method": "提出Fault Tolerant Hybrid-Shared Data Parallelism (FT-HSDP) 方法。它以数据并行复制体作为容错单位，在发生故障时只重启包含故障设备的单个复制体，其他继续训练。引入了基于CPU控制逻辑和GPU高效传输的数据交换协议FTAR以及非阻塞追赶协议。", "result": "相比全同步10万GPU训练，采用FT-HSDP可将因恢复导致的停滞时间从十分钟降低到三分钟，有效训练时间由44%提高至80%，且不会对结果模型精度造成明显影响。", "conclusion": "新方法提高了大规模GPU环境中训练效率和稳定性。"}}
{"id": "2602.00276", "pdf": "https://arxiv.org/pdf/2602.00276", "abs": "https://arxiv.org/abs/2602.00276", "authors": ["Aditya Kumar", "William W. Cohen"], "title": "Localizing and Correcting Errors for LLM-based Planners", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have demonstrated strong reasoning capabilities on math and coding, but frequently fail on symbolic classical planning tasks. Our studies, as well as prior work, show that LLM-generated plans routinely violate domain constraints given in their instructions (e.g., walking through walls). To address this failure, we propose iteratively augmenting instructions with Localized In-Context Learning (L-ICL) demonstrations: targeted corrections for specific failing steps. Specifically, L-ICL identifies the first constraint violation in a trace and injects a minimal input-output example giving the correct behavior for the failing step. Our proposed technique of L-ICL is much effective than explicit instructions or traditional ICL, which adds complete problem-solving trajectories, and many other baselines. For example, on an 8x8 gridworld, L-ICL produces valid plans 89% of the time with only 60 training examples, compared to 59% for the best baseline, an increase of 30%. L-ICL also shows dramatic improvements in other domains (gridworld navigation, mazes, Sokoban, and BlocksWorld), and on several LLM architectures.", "AI": {"tldr": "本文提出了一种名为Localized In-Context Learning（L-ICL）的技术，用于纠正大型语言模型在符号经典规划任务中的错误。", "motivation": "大型语言模型虽具有强大的数学和编码推理能力，但在处理符号经典规划任务时经常违反领域约束。因此需要一种方法来提高其准确性和可靠性。", "method": "通过识别失败步骤并注入最小的输入输出示例以提供正确的行为，L-ICL技术可以逐步修正错误。", "result": "在8x8网格世界中，使用60个训练样本时，L-ICL生成有效计划的成功率为89%，而最佳基线则为59%，提高了30%。该方法还显示出在其他领域（如迷宫导航、Sokoban和BlocksWorld）中的显著改进。", "conclusion": "L-ICL技术相较于显式指令或传统ICL以及许多其他基准，更有效地纠正了大型语言模型的错误行为，并提高了任务执行的成功率。"}}
{"id": "2602.00272", "pdf": "https://arxiv.org/pdf/2602.00272", "abs": "https://arxiv.org/abs/2602.00272", "authors": ["Wan Fokkink", "Georgios Karlos", "Andy Tatman"], "title": "A Fault-Tolerant Version of Safra's Termination Detection Algorithm", "categories": ["cs.DC", "cs.DS"], "comment": null, "summary": "Safra's distributed termination detection algorithm employs a logical token ring structure within a distributed network; only passive nodes forward the token, and a counter in the token keeps track of the number of sent minus the number of received messages. We adapt this classic algorithm to make it fault-tolerant. The counter is split into counters per node, to discard counts from crashed nodes. If a node crashes, the token ring is restored locally and a backup token is sent. Nodes inform each other of detected crashes via the token. Our algorithm imposes no additional message overhead, tolerates any number of crashes as well as simultaneous crashes, and copes with crashes in a decentralized fashion. Correctness proofs are provided of both the original Safra's algorithm and its fault-tolerant variant, as well as a model checking analysis.", "AI": {"tldr": "本文对Safra的分布式终止检测算法进行了改进，使其具有容错性。", "motivation": "传统的Safra终止检测算法在节点发生故障时无法正常工作。因此，该论文旨在使算法具备容错性，以应对节点故障的情况。", "method": "将计数器拆分为每个节点的计数器，丢弃已崩溃节点的计数；如果某个节点崩溃，则本地恢复令牌环，并发送备用令牌；通过令牌告知其他节点检测到的崩溃情况。", "result": "改进后的算法无需增加额外的消息开销，可容忍任意数量的崩溃以及并发崩溃，并以去中心化的方式应对崩溃。同时提供了原Safra算法及其容错变体的正确性证明及模型检查分析。", "conclusion": "本文提出了一种新的方法来增强Safra终止检测算法的容错能力，使其能够在面对节点故障时仍能正常运行并保持高效性。"}}
{"id": "2602.00270", "pdf": "https://arxiv.org/pdf/2602.00270", "abs": "https://arxiv.org/abs/2602.00270", "authors": ["Mohsen Salehi", "Karthik Pattabiraman"], "title": "RVDebloater: Mode-based Adaptive Firmware Debloating for Robotic Vehicles", "categories": ["cs.CR", "cs.RO", "cs.SE"], "comment": null, "summary": "As the number of embedded devices grows and their functional requirements increase, embedded firmware is becoming increasingly larger, thereby expanding its attack surface. Despite the increase in firmware size, many embedded devices, such as robotic vehicles (RVs), operate in distinct modes, each requiring only a small subset of the firmware code at runtime. We refer to such devices as mode-based embedded devices. Debloating is an approach to reduce attack surfaces by removing or restricting unneeded code, but existing techniques suffer from significant limitations, such as coarse granularity and irreversible code removal, limiting their applicability. To address these limitations, we propose RVDebloater, a novel adaptive debloating technique for mode-based embedded devices that automatically identifies unneeded firmware code for each mode using either static or dynamic analysis, and dynamically debloats the firmware for each mode at the function level at runtime. RVDebloater introduces a new software-based enforcement approach that supports diverse mode-based embedded devices. We implemented RVDebloater using the LLVM compiler and evaluated its efficiency and effectiveness on six different RVs, including both simulated and real ones, with different real-world missions. We find that device requirements change throughout its lifetime for each mode, and that many critical firmware functions can be restricted in other modes, with an average of 85% of functions not being required. The results showed that none of the missions failed after debloating with RVDebloater, indicating that it neither incurred false positives nor false negatives. Further, RVDebloater prunes the firmware call graph by an average of 45% across different firmware. Finally, RVDebloater incurred an average performance overhead of 3.9% and memory overhead of 4% (approximately 0.25 MB) on real RVs.", "AI": {"tldr": "RVDebloater是一种针对模式化嵌入式设备（如机器人车辆）的自适应固件去冗技术，能够在运行时根据不同模式动态移除不必要的代码。", "motivation": "随着嵌入式设备数量的增长和功能需求增加，其固件体积变得越来越大，攻击面也扩大了。尽管固件规模增大，许多设备在特定模式下仅使用固件中的一小部分代码。为减少攻击面并克服现有去冗技术的局限性（如粒度过大、移除不可恢复），提出了RVDebloater。", "method": "RVDebloater利用静态或动态分析自动识别各模式下的冗余代码，以函数级别在运行时进行自适应去冗。其通过LLVM编译器实现并应用于六个不同机器人车辆上，包括模拟和真实设备。", "result": "研究表明，在不同的设备模式下需求随时间变化，许多关键固件功能可以在其他模式中被限制或移除（平均约85%的功能不必要）。实验显示未出现任务失败情况，表明没有假阳性或假阴性。此外，RVDebloater将固件调用图减少45%，性能和内存开销分别为3.9%和4%（大约0.25MB）。", "conclusion": "RVDebloater在不引入错误的情况下有效减少了机器人车辆的固件攻击面，并且其自适应去冗方法对不同设备模式变化有良好的支持。"}}
{"id": "2602.00269", "pdf": "https://arxiv.org/pdf/2602.00269", "abs": "https://arxiv.org/abs/2602.00269", "authors": ["Keisuke Kamahori", "Wei-Tzu Lee", "Atindra Jha", "Rohan Kadekodi", "Stephanie Wang", "Arvind Krishnamurthy", "Baris Kasikci"], "title": "VoxServe: Streaming-Centric Serving System for Speech Language Models", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.SD", "eess.AS"], "comment": "The code is available at https://github.com/vox-serve/vox-serve", "summary": "Deploying modern Speech Language Models (SpeechLMs) in streaming settings requires systems that provide low latency, high throughput, and strong guarantees of streamability. Existing systems fall short of supporting diverse models flexibly and efficiently. We present VoxServe, a unified serving system for SpeechLMs that optimizes streaming performance. VoxServe introduces a model-execution abstraction that decouples model architecture from system-level optimizations, thereby enabling support for diverse SpeechLM architectures within a single framework. Building on this abstraction, VoxServe implements streaming-aware scheduling and an asynchronous inference pipeline to improve end-to-end efficiency. Evaluations across multiple modern SpeechLMs show that VoxServe achieves 10-20x higher throughput than existing implementations at comparable latency while maintaining high streaming viability. The code of VoxServe is available at https://github.com/vox-serve/vox-serve.", "AI": {"tldr": "本文介绍了一种新的语音语言模型服务系统VoxServe，该系统在流处理设置中能够提供低延迟、高吞吐量和强健的流特性保证。", "motivation": "现有的系统无法灵活高效地支持各种语音语言模型架构。因此需要一种统一的服务系统来优化流性能。", "method": "本文提出了VoxServe，它引入了一个模型执行抽象，将模型架构与系统级优化解耦，并实现了一种基于流的调度和异步推理管道以提高整体效率。", "result": "在多个现代语音语言模型上的评估显示，VoxServe可以在与现有实现相当的延迟下获得10-20倍更高的吞吐量，同时保持较高的流处理性能。", "conclusion": "VoxServe证明了其能够有效支持多种架构的语音语言模型，并且在保证低延迟和高效率方面表现出色。"}}
{"id": "2602.00268", "pdf": "https://arxiv.org/pdf/2602.00268", "abs": "https://arxiv.org/abs/2602.00268", "authors": ["Ariel Shaulov", "Eitan Shaar", "Amit Edenzon", "Lior Wolf"], "title": "TokenTrim: Inference-Time Token Pruning for Autoregressive Long Video Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Auto-regressive video generation enables long video synthesis by iteratively conditioning each new batch of frames on previously generated content. However, recent work has shown that such pipelines suffer from severe temporal drift, where errors accumulate and amplify over long horizons. We hypothesize that this drift does not primarily stem from insufficient model capacity, but rather from inference-time error propagation. Specifically, we contend that drift arises from the uncontrolled reuse of corrupted latent conditioning tokens during auto-regressive inference. To correct this accumulation of errors, we propose a simple, inference-time method that mitigates temporal drift by identifying and removing unstable latent tokens before they are reused for conditioning. For this purpose, we define unstable tokens as latent tokens whose representations deviate significantly from those of the previously generated batch, indicating potential corruption or semantic drift. By explicitly removing corrupted latent tokens from the auto-regressive context, rather than modifying entire spatial regions or model parameters, our method prevents unreliable latent information from influencing future generation steps. As a result, it significantly improves long-horizon temporal consistency without modifying the model architecture, training procedure, or leaving latent space.", "AI": {"tldr": "本文提出了一种在推理时去除不稳定潜在标记的方法，以减少自回归视频生成中的时间漂移。", "motivation": "最近的研究表明，在长视频合成过程中，自回归管道存在严重的时间漂移问题。这种漂移不是由于模型容量不足导致的，而是由于推理过程中的错误传播所致。为了解决这个问题，作者提出了TokenTrim方法来减少不稳定潜在标记的影响。", "method": "该方法在每次生成新的帧批时，通过比较当前潜在标记与先前生成内容之间的表示差异，识别并去除可能被破坏或发生语义漂移的潜在标记。", "result": "实验结果表明，这种方法显著提高了长时间序列的一致性，而无需修改模型架构、训练过程或离开潜在空间。", "conclusion": "TokenTrim通过在推理时控制潜在标记的质量来提高自回归视频生成的时间一致性。"}}
{"id": "2602.00267", "pdf": "https://arxiv.org/pdf/2602.00267", "abs": "https://arxiv.org/abs/2602.00267", "authors": ["Gemma Canet Tarrés", "Manel Baradad", "Francesc Moreno-Noguer", "Yumeng Li"], "title": "PLACID: Identity-Preserving Multi-Object Compositing via Video Diffusion with Synthetic Trajectories", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advances in generative AI have dramatically improved photorealistic image synthesis, yet they fall short for studio-level multi-object compositing. This task demands simultaneous (i) near-perfect preservation of each item's identity, (ii) precise background and color fidelity, (iii) layout and design elements control, and (iv) complete, appealing displays showcasing all objects. However, current state-of-the-art models often alter object details, omit or duplicate objects, and produce layouts with incorrect relative sizing or inconsistent item presentations. To bridge this gap, we introduce PLACID, a framework that transforms a collection of object images into an appealing multi-object composite. Our approach makes two main contributions. First, we leverage a pretrained image-to-video (I2V) diffusion model with text control to preserve objects consistency, identities, and background details by exploiting temporal priors from videos. Second, we propose a novel data curation strategy that generates synthetic sequences where randomly placed objects smoothly move to their target positions. This synthetic data aligns with the video model's temporal priors during training. At inference, objects initialized at random positions consistently converge into coherent layouts guided by text, with the final frame serving as the composite image. Extensive quantitative evaluations and user studies demonstrate that PLACID surpasses state-of-the-art methods in multi-object compositing, achieving superior identity, background, and color preservation, with less omitted objects and visually appealing results.", "AI": {"tldr": "PLACID是一种框架，通过视频扩散和合成轨迹生成多对象组合图像。", "motivation": "现有的AI模型在多物体合成中存在细节改变、物体遗漏或重复以及布局错误的问题。因此，需要一个能够同时保留每个物品身份的高质量背景和颜色保真的方法。", "method": "PLACID利用预训练的视频扩散模型和文本控制来保持物体的一致性，并通过生成随机位置移动到目标位置的合成序列，使模型更好地学习时间先验知识。", "result": "定量评估显示，PLACID在多物体合成中超过了现有方法，在身份、背景颜色保存方面表现更好，减少了遗漏物体的情况并获得视觉上更吸引人的结果。", "conclusion": "通过视频扩散和合成轨迹的创新策略，PLACID能够生成高质量的多对象组合图像。"}}
{"id": "2602.00266", "pdf": "https://arxiv.org/pdf/2602.00266", "abs": "https://arxiv.org/abs/2602.00266", "authors": ["Yani Zhang", "Helmut Bölcskei"], "title": "Complete Identification of Deep ReLU Neural Networks by Many-Valued Logic", "categories": ["cs.AI"], "comment": null, "summary": "Deep ReLU neural networks admit nontrivial functional symmetries: vastly different architectures and parameters (weights and biases) can realize the same function. We address the complete identification problem -- given a function f, deriving the architecture and parameters of all feedforward ReLU networks giving rise to f. We translate ReLU networks into Lukasiewicz logic formulae, and effect functional equivalent network transformations through algebraic rewrites governed by the logic axioms. A compositional norm form is proposed to facilitate the mapping from Lukasiewicz logic formulae back to ReLU networks. Using Chang's completeness theorem, we show that for every functional equivalence class, all ReLU networks in that class are connected by a finite set of symmetries corresponding to the finite set of axioms of Lukasiewicz logic. This idea is reminiscent of Shannon's seminal work on switching circuit design, where the circuits are translated into Boolean formulae, and synthesis is effected by algebraic rewriting governed by Boolean logic axioms.", "AI": {"tldr": "本文提出了一种通过多值逻辑完全识别深层ReLU神经网络的方法。", "motivation": "深层ReLU神经网络存在非平凡的功能对称性，即不同的架构和参数可以实现相同的功能。此研究旨在解决给定函数f时，推导出所有产生该函数的前馈ReLU网络的结构和参数的问题。", "method": "将ReLU网络转换为卢卡西维奇逻辑公式，并通过受逻辑公理约束的代数重写进行功能等价网络变换。提出了一种组合标准形以简化从卢卡西维奇逻辑公式映射回ReLU网络的过程，利用Chang完备性定理展示了每个函数等价类中的所有ReLU网络都通过有限数量的对称性相连。", "result": "对于每个函数等价类，所有ReLU网络由对应于卢卡西维奇逻辑公理集的有限数量的对称性连接起来。", "conclusion": "本文方法成功地解决了深层ReLU神经网络的功能等价问题，并揭示了其内部结构与多值逻辑之间的联系。"}}
{"id": "2602.00265", "pdf": "https://arxiv.org/pdf/2602.00265", "abs": "https://arxiv.org/abs/2602.00265", "authors": ["Dong Liang", "Yuhao Liu", "Jinyuan Jia", "Youjun Zhao", "Rynson W. H. Lau"], "title": "World-Shaper: A Unified Framework for 360° Panoramic Editing", "categories": ["cs.CV"], "comment": null, "summary": "Being able to edit panoramic images is crucial for creating realistic 360° visual experiences. However, existing perspective-based image editing methods fail to model the spatial structure of panoramas. Conventional cube-map decompositions attempt to overcome this problem but inevitably break global consistency due to their mismatch with spherical geometry. Motivated by this insight, we reformulate panoramic editing directly in the equirectangular projection (ERP) domain and present World-Shaper, a unified geometry-aware framework that bridges panoramic generation and editing within a single editing-centric design. To overcome the scarcity of paired data, we adopt a generate-then-edit paradigm, where controllable panoramic generation serves as an auxiliary stage to synthesize diverse paired examples for supervised editing learning. To address geometric distortion, we introduce a geometry-aware learning strategy that explicitly enforces position-aware shape supervision and implicitly internalizes panoramic priors through progressive training. Extensive experiments on our new benchmark, PEBench, demonstrate that our method achieves superior geometric consistency, editing fidelity, and text controllability compared to SOTA methods, enabling coherent and flexible 360° visual world creation with unified editing control. Code, model, and data will be released at our project page: https://world-shaper-project.github.io/", "AI": {"tldr": "本文提出了一个统一的全景编辑框架World-Shaper，直接在等距圆柱投影（ERP）域中进行全景图像编辑。", "motivation": "现有基于透视的方法无法有效处理全景图的空间结构。传统立方体映射分解方法会破坏全局一致性。因此，作者希望提供一种新的全景编辑方法来克服这些限制。", "method": "World-Shaper框架在等距圆柱投影域中进行统一的几何感知编辑，采用生成然后编辑的范式解决数据不足问题，并引入几何感知学习策略以保证位置感知形状监督和渐进式训练中的全景先验知识内化。", "result": "实验结果表明，本文的方法相较于现有最佳方法在几何一致性、编辑保真度以及文本可控性方面表现更优。", "conclusion": "World-Shaper为创建连贯灵活的360°视觉世界提供了统一的编辑控制能力。"}}
{"id": "2602.00262", "pdf": "https://arxiv.org/pdf/2602.00262", "abs": "https://arxiv.org/abs/2602.00262", "authors": ["Huanran Li", "Daniel Pimentel-Alarcón"], "title": "Subspace Clustering on Incomplete Data with Self-Supervised Contrastive Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Subspace clustering aims to group data points that lie in a union of low-dimensional subspaces and finds wide application in computer vision, hyperspectral imaging, and recommendation systems. However, most existing methods assume fully observed data, limiting their effectiveness in real-world scenarios with missing entries. In this paper, we propose a contrastive self-supervised framework, Contrastive Subspace Clustering (CSC), designed for clustering incomplete data. CSC generates masked views of partially observed inputs and trains a deep neural network using a SimCLR-style contrastive loss to learn invariant embeddings. These embeddings are then clustered using sparse subspace clustering. Experiments on six benchmark datasets show that CSC consistently outperforms both classical and deep learning baselines, demonstrating strong robustness to missing data and scalability to large datasets.", "AI": {"tldr": "提出了一种用于不完整数据子空间聚类的自监督对比学习框架CSC", "motivation": "现有方法多假设数据完全观测，限制了其在实际场景中的应用效能。为解决这一问题，本文旨在开发一种能够有效处理缺失条目的子空间聚类算法。", "method": "通过生成部分观察输入的掩码视图，并使用SimCLR样式的对比损失训练深层神经网络来学习不变嵌入，然后利用稀疏子空间聚类进行聚类。", "result": "实验表明CSC在六个基准数据集上优于经典和深度学习基线方法，展示了对缺失数据的强大鲁棒性和大规模数据的可扩展性。", "conclusion": "所提出的框架能够有效处理不完整数据，并且具有良好的实际应用前景。"}}
{"id": "2602.00259", "pdf": "https://arxiv.org/pdf/2602.00259", "abs": "https://arxiv.org/abs/2602.00259", "authors": ["Venkatesh Sivaraman", "Eric P. Mason", "Mengfan Ellen Li", "Jessica Tong", "Andrew J. King", "Jeremy M. Kahn", "Adam Perer"], "title": "Intelligent Reasoning Cues: A Framework and Case Study of the Roles of AI Information in Complex Decisions", "categories": ["cs.HC", "cs.AI", "q-bio.OT"], "comment": "Accepted at CHI 2026", "summary": "Artificial intelligence (AI)-based decision support systems can be highly accurate yet still fail to support users or improve decisions. Existing theories of AI-assisted decision-making focus on calibrating reliance on AI advice, leaving it unclear how different system designs might influence the reasoning processes underneath. We address this gap by reconsidering AI interfaces as collections of intelligent reasoning cues: discrete pieces of AI information that can individually influence decision-making. We then explore the roles of eight types of reasoning cues in a high-stakes clinical decision (treating patients with sepsis in intensive care). Through contextual inquiries with six teams and a think-aloud study with 25 physicians, we find that reasoning cues have distinct patterns of influence that can directly inform design. Our results also suggest that reasoning cues should prioritize tasks with high variability and discretion, adapt to ensure compatibility with evolving decision needs, and provide complementary, rigorous insights on complex cases.", "AI": {"tldr": "提出了基于AI的决策支持系统中智能推理线索的概念，并通过案例研究探讨了其在复杂决策中的作用。", "motivation": "现有理论主要关注如何调整用户对AI建议的信任度，而忽视了不同设计可能影响决策过程的方式。为此，论文重新审视了AI界面作为一组智能推理线索的角色及其对决策的影响。", "method": "通过与六个团队的上下文查询和25名医生的思维声学研究，探讨了八种类型的推理线索在重症监护治疗败血症患者中的作用。", "result": "发现不同推理线索对决策过程有不同的影响模式，并建议设计中应优先处理高可变性和自由裁量权的任务、适应不断变化的需求并提供复杂案例的补充严谨见解。", "conclusion": "智能推理线索的概念为理解AI如何辅助复杂决策提供了新的视角，有助于指导未来的设计和研究。"}}
{"id": "2602.00250", "pdf": "https://arxiv.org/pdf/2602.00250", "abs": "https://arxiv.org/abs/2602.00250", "authors": ["Shreshth Saini", "Avinab Saha", "Balu Adsumilli", "Neil Birkbeck", "Yilin Wang", "Alan C. Bovik"], "title": "TABES: Trajectory-Aware Backward-on-Entropy Steering for Masked Diffusion Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "mber:LIVE-MDM-02", "summary": "Masked Diffusion Models (MDMs) have emerged as a promising non-autoregressive paradigm for generative tasks, offering parallel decoding and bidirectional context utilization. However, current sampling methods rely on simple confidence-based heuristics that ignore the long-term impact of local decisions, leading to trajectory lock-in where early hallucinations cascade into global incoherence. While search-based methods mitigate this, they incur prohibitive computational costs ($O(K)$ forward passes per step). In this work, we propose Backward-on-Entropy (BoE) Steering, a gradient-guided inference framework that approximates infinite-horizon lookahead via a single backward pass. We formally derive the Token Influence Score (TIS) from a first-order expansion of the trajectory cost functional, proving that the gradient of future entropy with respect to input embeddings serves as an optimal control signal for minimizing uncertainty. To ensure scalability, we introduce \\texttt{ActiveQueryAttention}, a sparse adjoint primitive that exploits the structure of the masking objective to reduce backward pass complexity. BoE achieves a superior Pareto frontier for inference-time scaling compared to existing unmasking methods, demonstrating that gradient-guided steering offers a mathematically principled and efficient path to robust non-autoregressive generation. We will release the code.", "AI": {"tldr": "提出了基于梯度引导的推理框架Backward-on-Entropy (BoE) Steering，用于改进Masked Diffusion Models（MDMs）的生成效果。", "motivation": "现有的采样方法依赖于简单的置信度启发式策略，忽略了局部决策对长期影响的关注，导致了轨迹锁定和全局不一致的问题。为了克服这一挑战并提高效率，作者提出了一种新的推理框架来解决这些问题。", "method": "提出了Token Influence Score (TIS) 和 ActiveQueryAttention，前者用于评估输入嵌入对未来熵的影响，后者则通过稀疏的伴随算子减少向后传递的复杂度，从而实现高效的梯度引导采样。", "result": "BoE Steering 方法在推理时间扩展中展示了优于现有方法的帕累托前沿，证明了梯度引导方法是一种数学上合理且高效的方式来进行稳健的非自回归生成。", "conclusion": "该研究提出了一种新颖的方法来优化MDMs中的采样过程，通过引入梯度导向机制和高效的计算策略，显著提高了生成任务的质量与效率。"}}
{"id": "2602.00249", "pdf": "https://arxiv.org/pdf/2602.00249", "abs": "https://arxiv.org/abs/2602.00249", "authors": ["Rishav Pramanik", "Ian E. Nielsen", "Jeff Smith", "Saurav Pandit", "Ravi P. Ramachandran", "Zhaozheng Yin"], "title": "SANEval: Open-Vocabulary Compositional Benchmarks with Failure-mode Diagnosis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The rapid progress of text-to-image (T2I) models has unlocked unprecedented creative potential, yet their ability to faithfully render complex prompts involving multiple objects, attributes, and spatial relationships remains a significant bottleneck. Progress is hampered by a lack of adequate evaluation methods; current benchmarks are often restricted to closed-set vocabularies, lack fine-grained diagnostic capabilities, and fail to provide the interpretable feedback necessary to diagnose and remedy specific compositional failures. We solve these challenges by introducing SANEval (Spatial, Attribute, and Numeracy Evaluation), a comprehensive benchmark that establishes a scalable new pipeline for open-vocabulary compositional evaluation. SANEval combines a large language model (LLM) for deep prompt understanding with an LLM-enhanced, open-vocabulary object detector to robustly evaluate compositional adherence, unconstrained by a fixed vocabulary. Through extensive experiments on six state-of-the-art T2I models, we demonstrate that SANEval's automated evaluations provide a more faithful proxy for human assessment; our metric achieves a Spearman's rank correlation with statistically different results than those of existing benchmarks across tasks of attribute binding, spatial relations, and numeracy. To facilitate future research in compositional T2I generation and evaluation, we will release the SANEval dataset and our open-source evaluation pipeline.", "AI": {"tldr": "SANEval是一款用于评估文本到图像模型的开放词汇组成基准，结合大规模语言模型和增强型对象检测器以解决现有方法无法准确诊断组合错误的问题。", "motivation": "当前的T2I模型在处理复杂提示时存在瓶颈，缺乏有效的评估手段；现有的评估标准局限于封闭词汇表且未能提供足够的反馈来诊断特定组合问题。因此需要一个能够全面开放词汇组成的评估系统。", "method": "SANEval通过结合大规模语言模型和增强型对象检测器建立了一个新的可扩展评估管道，该方法不依赖于固定词汇表，并利用此方法在六个最先进的T2I模型上进行了广泛的实验。", "result": "实验表明，SANEval的自动化评价结果更接近人类评估标准；其指标在属性绑定、空间关系和数量任务方面与现有基准相比具有统计学差异。SANEval将提供一个包含数据集和开源评估管道的研究平台。", "conclusion": "SANEval通过引入新的方法解决了当前T2I模型组合错误诊断难的问题，为未来研究提供了有力工具和支持环境。"}}
{"id": "2602.00248", "pdf": "https://arxiv.org/pdf/2602.00248", "abs": "https://arxiv.org/abs/2602.00248", "authors": ["Varun Srivastava", "Fan Lei", "Alan M. MacEachren", "Ross Maciejewski"], "title": "The Impact of Uncertainty Visualization on Trust in Thematic Maps", "categories": ["cs.HC"], "comment": null, "summary": "Thematic maps are widely used to communicate spatial patterns to non-expert audiences. Although uncertainty is inherent in thematic map data, it is rarely visualized, raising questions about how its inclusion affects trust. Prior work offers mixed perspectives: some argue that uncertainty fosters trust through transparency, while others suggest it may reduce trust by introducing confusion. Yet few empirical studies explicitly measure trust in thematic maps. We conducted a between-subjects experiment (N=161) to evaluate how visualizing uncertainty at varying levels (low, medium, high) influences trust. We find that uncertainty visualization generally reduces trust, with greater reductions observed as uncertainty levels increase. However, maps dominated by low uncertainty do not significantly differ in trust from those with no uncertainty. Moreover, while uncertainty visualization tends to make readers question the accuracy of the data, it appears to have a weaker influence on perceptions of the mapmaker's integrity.", "AI": {"tldr": "研究探讨了不确定性可视化对主题地图信任度的影响", "motivation": "探索不确定性的可视化如何影响非专业观众的主题地图的信任度，填补现有研究的空白", "method": "进行了一个被试间实验（N=161），评估在不同程度上可视化不确定性（低、中、高）对信任度的影响", "result": "发现不确定性可视化通常会降低信任度，并且随着不确定性水平的增加这种影响更明显；但低不确定性主导的地图和无不确定性的地图在信任度方面没有显著差异", "conclusion": "虽然不确定性可视化可能会质疑数据准确性，但它对制图者的诚信感知影响较小"}}
{"id": "2602.00247", "pdf": "https://arxiv.org/pdf/2602.00247", "abs": "https://arxiv.org/abs/2602.00247", "authors": ["Samyak Jha", "Junho Kim"], "title": "CAPA: Contribution-Aware Pruning and FFN Approximation for Efficient Large Vision-Language Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Efficient inference in Large Vision-Language Models is constrained by the high cost of processing thousands of visual tokens, yet it remains unclear which tokens and computations can be safely removed. While attention scores are commonly used to estimate visual token importance, they are an imperfect proxy for actual contribution. We show that Attention Contribution, which weights attention probabilities by value vector magnitude, provides a more accurate criterion for visual token selection. Our empirical analysis reveals that visual attention sinks are functionally heterogeneous, comprising Probability Dumps with low contribution that can be safely pruned, and Structural Anchors with high contribution essential for maintaining model performance. Further, we identify substantial redundancy in Feed-Forward Networks (FFNs) associated with visual tokens, particularly in intermediate layers where image tokens exhibit linear behavior. Based on our findings, we introduce CAPA (Contribution-Aware Pruning and FFN Approximation), a dual-strategy framework that prunes visual tokens using attention contribution at critical functional transitions and reduces FFN computation through efficient linear approximations. Experiments on various benchmarks across baselines show that CAPA achieves competent efficiency--performance trade-offs with improved robustness.", "AI": {"tldr": "CAPA框架通过贡献感知的视觉标记剪枝和前馈网络近似，提高大型视觉语言模型的推理效率。", "motivation": "大型视觉语言模型在处理大量视觉标记时成本高昂，需要探索可安全移除的标记与计算部分。现有方法依赖于注意力分数来估计标记重要性，但其准确性有限。", "method": "提出CAPA框架，利用加权注意力概率和值向量大小的乘积作为更准确的贡献指标进行视觉标记选择；识别低贡献的‘概率倾倒’和高贡献的‘结构锚点’，实现精确剪枝。同时，在中间层使用线性近似减少FFN计算。", "result": "实验显示CAPA在各种基准测试中实现了高效且性能稳定的效率-性能权衡，并提高了模型鲁棒性。", "conclusion": "CAPA框架通过贡献感知的视觉标记剪枝和前馈网络近似，显著提升了大型视觉语言模型的推理效率。"}}
{"id": "2602.00243", "pdf": "https://arxiv.org/pdf/2602.00243", "abs": "https://arxiv.org/abs/2602.00243", "authors": ["Ashley Hua", "Adya Daruka", "Yang Hong", "Sharifa Sultana"], "title": "\"OpenBloom\": A Question-Based LLM Tool to Support Stigma Reduction in Reproductive Well-Being", "categories": ["cs.HC"], "comment": null, "summary": "Reproductive well-being education remains widely stigmatized across diverse cultural contexts, constraining how individuals access and interpret reproductive health knowledge. We designed and evaluated OpenBloom, a stigma-sensitive, AI-mediated system that uses LLMs to transform reproductive health articles into reflective, question-based learning prompts. We employed OpenBloom as a design probe, aiming to explore the emerging challenges of reproductive well-being stigma through LLMs. Through surveys, semi-structured interviews, and focus group discussions, we examine how sociocultural stigma shapes participants' engagements with AI-generated questions and the opportunities of inquiry-based reproductive health education. Our findings identify key design considerations for stigma-sensitive LLM, including empathetic framing, inclusive language, values-based reflection, and explicit representation of marginalized identities. However, while current LLM outputs largely meet expectations for cultural sensitivity and non-offensiveness, they default to superficial rephrasing and factual recall rather than critical reflection. This guides well-being HCI design in sensitive health domains toward culturally grounded, participatory workflows.", "AI": {"tldr": "开放Bloom项目利用大型语言模型（LLM）将生殖健康文章转化为反思性、基于问题的学习提示，旨在减少与生殖健康的污名化。", "motivation": "在各种文化背景下，关于生殖健康的教育仍然受到广泛的污名化影响，这限制了人们获取和理解相关知识的途径。设计开放Bloom系统以探索大型语言模型（LLM）如何帮助解决这一问题，并促进基于探究的学习模式。", "method": "通过调查、半结构化的访谈以及焦点小组讨论的方式，研究参与者是如何与人工智能生成的问题互动并探讨其在敏感健康领域中的应用机会和挑战。", "result": "研究发现了一系列针对污名化敏感的语言模型设计考量，包括同情心的表达方式、包容性的语言使用、价值观导向的反思过程及对边缘群体身份的具体呈现。尽管当前的LLM输出能基本满足文化敏感性和非冒犯性要求，但它们倾向于表面化的重述而非深层次的批判性思考。", "conclusion": "这些发现为健康人机交互（HCI）设计提供了指导方针，尤其是在涉及文化背景和参与式工作流程的敏感健康领域中。"}}
{"id": "2602.00241", "pdf": "https://arxiv.org/pdf/2602.00241", "abs": "https://arxiv.org/abs/2602.00241", "authors": ["Hansol Lee", "AJ Alvero", "René F. Kizilcec", "Thorsten Joachims"], "title": "Does Algorithmic Uncertainty Sway Human Experts? Evidence from a Field Experiment in Selective College Admissions", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "Algorithmic predictions are inherently uncertain: even models with similar aggregate accuracy can produce different predictions for the same individual, raising concerns that high-stakes decisions may become sensitive to arbitrary modeling choices. In this paper, we define algorithmic reliance as the extent to which a decision outcome depends on whether a more favorable versus less favorable algorithmic prediction is presented to the decision-maker. We estimate this in a randomized field experiment (n=19,545) embedded in a selective U.S. college admissions cycle, in which admissions officers reviewed each application alongside an algorithmic score while we randomly varied whether the score came from one of two similarly accurate prediction models. Although the two models performed similarly in aggregate, they frequently assigned different scores to the same applicant, creating exogenous variation in the score shown. Surprisingly, we find little evidence of algorithmic reliance: presenting a more favorable score does not meaningfully increase an applicant's probability of admission on average, even when the models disagree substantially. These findings suggest that, in this expert, high-stakes setting, human decision-making is largely invariant to arbitrary variation in algorithmic predictions, underscoring the role of professional discretion and institutional context in mediating the downstream effects of algorithmic uncertainty.", "AI": {"tldr": "研究探讨了算法不确定性对人类专家决策的影响，通过一个嵌入在选择性美国大学录取周期的随机现场实验来评估这种影响。", "motivation": "由于算法预测本质上具有不确定性，在高风险决策中可能过于依赖于模型的选择。因此，该研究旨在衡量当两种同样准确但为同一申请人提供不同分数的算法被呈现时，人类专家是否受到这些变化的影响。", "method": "在一项涉及19,545名申请者的随机现场实验中，录取官员在评估每位申请者的同时参考了一种算法评分，并且随机改变了这种评分来自两个同样准确但经常给出不同预测结果的模型中的哪一个。", "result": "尽管两种模型在整体上表现类似，但在呈现更有利或不利的分数时，申请人被录取的概率并没有显著变化。这表明，在专家和高风险环境中，人类决策相对不受算法不确定性的影响。", "conclusion": "该研究发现，即使存在明显的预测差异，这些不同的评分也未能显著影响最终的录取决定。这一结果强调了专业判断以及机构背景在调节算法不确定性对决策下游效应方面所起的关键作用。"}}
{"id": "2602.00238", "pdf": "https://arxiv.org/pdf/2602.00238", "abs": "https://arxiv.org/abs/2602.00238", "authors": ["Tianyi Hu", "Niket Tandon", "Akhil Arora"], "title": "DIVERGE: Diversity-Enhanced RAG for Open-Ended Information Seeking", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Existing retrieval-augmented generation (RAG) systems are primarily designed under the assumption that each query has a single correct answer. This overlooks common information-seeking scenarios with multiple plausible answers, where diversity is essential to avoid collapsing to a single dominant response, thereby constraining creativity and compromising fair and inclusive information access. Our analysis reveals a commonly overlooked limitation of standard RAG systems: they underutilize retrieved context diversity, such that increasing retrieval diversity alone does not yield diverse generations. To address this limitation, we propose DIVERGE, a plug-and-play agentic RAG framework with novel reflection-guided generation and memory-augmented iterative refinement, which promotes diverse viewpoints while preserving answer quality. We introduce novel metrics tailored to evaluating the diversity-quality trade-off in open-ended questions, and show that they correlate well with human judgments. We demonstrate that DIVERGE achieves the best diversity-quality trade-off compared to competitive baselines and previous state-of-the-art methods on the real-world Infinity-Chat dataset, substantially improving diversity while maintaining quality. More broadly, our results reveal a systematic limitation of current LLM-based systems for open-ended information-seeking and show that explicitly modeling diversity can mitigate it. Our code is available at: https://github.com/au-clan/Diverge", "AI": {"tldr": "本文提出了DIVERGE框架，旨在提高RAG系统在开放式信息查询中的多样性和答案质量。", "motivation": "现有的RAG系统假设每个查询只有一个正确答案，而忽略了多个合理答案的场景。这限制了创造力和公平的信息访问，并未充分利用检索到的内容多样性。", "method": "DIVERGE通过反射引导生成和增强记忆迭代改进来促进不同视角的同时保持质量。引入新的评估多样性与质量平衡的指标。", "result": "实验表明，DIVERGE在Infinity-Chat数据集上实现了最佳的多样性和答案质量权衡，优于基线和先前的方法。", "conclusion": "研究表明当前LLM系统存在限制，明确地建模多样性可以缓解这一问题。"}}
{"id": "2602.00222", "pdf": "https://arxiv.org/pdf/2602.00222", "abs": "https://arxiv.org/abs/2602.00222", "authors": ["Guoxin Lian", "Shuo Wang", "Yucheng Wang", "Yongcai Wang", "Maiyue Chen", "Kaihui Wang", "Bo Zhang", "Zhizhong Su", "Deying Li", "Zhaoxin Fan"], "title": "MapDream: Task-Driven Map Learning for Vision-Language Navigation", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Vision-Language Navigation (VLN) requires agents to follow natural language instructions in partially observed 3D environments, motivating map representations that aggregate spatial context beyond local perception. However, most existing approaches rely on hand-crafted maps constructed independently of the navigation policy. We argue that maps should instead be learned representations shaped directly by navigation objectives rather than exhaustive reconstructions. Based on this insight, we propose MapDream, a map-in-the-loop framework that formulates map construction as autoregressive bird's-eye-view (BEV) image synthesis. The framework jointly learns map generation and action prediction, distilling environmental context into a compact three-channel BEV map that preserves only navigation-critical affordances. Supervised pre-training bootstraps a reliable mapping-to-control interface, while the autoregressive design enables end-to-end joint optimization through reinforcement fine-tuning. Experiments on R2R-CE and RxR-CE achieve state-of-the-art monocular performance, validating task-driven generative map learning.", "AI": {"tldr": "提出了一种基于任务的生成式地图学习方法MapDream，以提高视觉语言导航（VLN）中的表现。", "motivation": "现有的大多数方法依赖于手工制作的地图，这些地图独立于导航策略。该研究认为应该通过导航目标直接塑造地图表示而不是完整的重建。", "method": "提出了一种地图循环框架MapDream，将地图构造视为自回归的鸟瞰图（BEV）图像合成任务，并联合学习地图生成和动作预测。", "result": "在R2R-CE和RxR-CE数据集上实现了单目性能的最佳状态，验证了基于任务的生成式地图学习的有效性。", "conclusion": "MapDream框架证明了自回归设计可以提高视觉语言导航中的表现，并且监督预训练能够为映射到控制接口提供可靠的引导。"}}
{"id": "2602.00221", "pdf": "https://arxiv.org/pdf/2602.00221", "abs": "https://arxiv.org/abs/2602.00221", "authors": ["Humaira Mehwish", "Hina Shakir", "Muneeba Rashid", "Asarim Aamir", "Reema Qaiser Khan"], "title": "Benchmarking Vanilla GAN, DCGAN, and WGAN Architectures for MRI Reconstruction: A Quantitative Analysis", "categories": ["eess.IV", "cs.CV"], "comment": "20 pages", "summary": "Magnetic Resonance Imaging (MRI) is a crucial imaging modality for viewing internal body structures. This research work analyses the performance of popular GAN models for accurate and precise MRI reconstruction by enhancing image quality and improving diagnostic accuracy. Three GAN architectures considered in this study are Vanilla GAN, Deep Convolutional GAN (DCGAN), and Wasserstein GAN (WGAN). They were trained and evaluated using knee, brain, and cardiac MRI datasets to assess their generalizability across body regions. While the Vanilla GAN operates on the fundamentals of the adversarial network setup, DCGAN advances image synthesis by securing the convolutional layers, giving a superior appearance to the prevalent spatial features. Training instability is resolved in WGAN through the Wasserstein distance to minimize an unstable regime, therefore, ensuring stable convergence and high-quality images. The GAN models were trained and tested using 1000 MR images of an anonymized knee, 805 images of Heart, 90 images of Brain MRI dataset. The Structural Similarity Index (SSIM) for Vanilla GAN is 0.84, DCGAN is 0.97, and WGAN is 0.99. The Peak Signal to Noise Ratio (PSNR) for Vanilla GAN is 26, DCGAN is 49.3, and WGAN is 43.5. The results were further statistically validated. This study shows that DCGAN and WGAN-based frameworks are promising in MR image reconstruction because of good image quality and superior accuracy. With the first cross-organ benchmark of baseline GANs under a common preprocessing pipeline, this work provides a reproducible benchmark for future hybrid GANs and clinical MRI applications.", "AI": {"tldr": "对比研究了Vanilla GAN、DCGAN和WGAN在MRI重建中的性能。", "motivation": "为了提高MRI图像质量和诊断准确性，评估三种不同结构的生成对抗网络（GAN）模型在不同身体部位的MRI数据集上的表现。", "method": "使用膝关节、心脏和大脑的MRI数据集训练并测试了Vanilla GAN、DCGAN和WGAN。通过SSIM和PSNR等指标进行定量分析，并统计验证结果。", "result": "DCGAN和WGAN在图像质量方面表现出色，其中DCGAN的SSIM为0.97，PSNR为49.3；而WGAN的SSIM为0.99，PSNR为43.5。这些结果表明，基于DCGAN和WGAN的方法在MRI重建中具有很好的潜力。", "conclusion": "研究提供了不同身体部位的基线GAN模型的第一个跨器官基准，在同一预处理管道下进行测试，并为进一步的研究和临床应用提供了一个可重现的标准。"}}
{"id": "2602.00220", "pdf": "https://arxiv.org/pdf/2602.00220", "abs": "https://arxiv.org/abs/2602.00220", "authors": ["Tomasz Les", "Tomasz Markiewicz", "Malgorzata Lorent", "Miroslaw Dziekiewicz", "Krzysztof Siwek"], "title": "Advanced Geometric Correction Algorithms for 3D Medical Reconstruction: Comparison of Computed Tomography and Macroscopic Imaging", "categories": ["eess.IV", "cs.CV"], "comment": "24 pages, 9 figures, submitted to Applied Sciences (MDPI)", "summary": "This paper introduces a hybrid two-stage registration framework for reconstructing three-dimensional (3D) kidney anatomy from macroscopic slices, using CT-derived models as the geometric reference standard. The approach addresses the data-scarcity and high-distortion challenges typical of macroscopic imaging, where fully learning-based registration (e.g., VoxelMorph) often fails to generalize due to limited training diversity and large nonrigid deformations that exceed the capture range of unconstrained convolutional filters. In the proposed pipeline, the Optimal Cross-section Matching (OCM) algorithm first performs constrained global alignment: translation, rotation, and uniform scaling to establish anatomically consistent slice initialization. Next, a lightweight deep-learning refinement network, inspired by VoxelMorph, predicts residual local deformations between consecutive slices. The core novelty of this architecture lies in its hierarchical decomposition of the registration manifold. This hybrid OCM+DL design integrates explicit geometric priors with the flexible learning capacity of neural networks, ensuring stable optimization and plausible deformation fields even with few training examples. Experiments on an original dataset of 40 kidneys demonstrated better results compared to single-stage baselines. The pipeline maintains physical calibration via Hough-based grid detection and employs Bezier-based contour smoothing for robust meshing and volume estimation. Although validated on kidney data, the proposed framework generalizes to other soft-tissue organs reconstructed from optical or photographic cross-sections. By decoupling interpretable global optimization from data-efficient deep refinement, the method advances the precision, reproducibility, and anatomical realism of multimodal 3D reconstructions for surgical planning, morphological assessment, and medical education.", "AI": {"tldr": "本文提出了一种用于从宏观切片重建三维肾脏解剖结构的混合两阶段配准框架，使用CT派生模型作为几何参考标准。", "motivation": "该方法解决了由于训练数据稀缺和高失真导致的宏成像中的数据稀缺性和高畸变问题，这些问题是全学习型注册（如VoxelMorph）通常无法概括的原因。", "method": "提出的流程首先使用约束全局对齐算法进行初始位置校准，然后通过深度学习细化网络预测相邻切片之间的残差局部变形。这种混合设计结合了明确的几何先验与神经网络的灵活学习能力。", "result": "实验结果表明，在一个包含40个肾脏的数据集上，该方法优于单一阶段基准线。", "conclusion": "所提出的框架不仅适用于肾脏数据，还可以推广到其他软组织器官从光学或摄影横截面重建的情况。通过将可解释的全局优化与基于数据效率的深度细化解耦，这种方法提升了多模态三维重构的精度、重现性和解剖学现实性。"}}
{"id": "2602.00219", "pdf": "https://arxiv.org/pdf/2602.00219", "abs": "https://arxiv.org/abs/2602.00219", "authors": ["Saeid Jamshidi", "Omar Abdul Wahab", "Foutse Khomh", "Kawser Wazed Nafi"], "title": "Tri-LLM Cooperative Federated Zero-Shot Intrusion Detection with Semantic Disagreement and Trust-Aware Aggregation", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Federated learning (FL) has become an effective paradigm for privacy-preserving, distributed Intrusion Detection Systems (IDS) in cyber-physical and Internet of Things (IoT) networks, where centralized data aggregation is often infeasible due to privacy and bandwidth constraints. Despite its advantages, most existing FL-based IDS assume closed-set learning and lack mechanisms such as uncertainty estimation, semantic generalization, and explicit modeling of epistemic ambiguity in zero-day attack scenarios. Additionally, robustness to heterogeneous and unreliable clients remains a challenge in practical applications. This paper introduces a semantics-driven federated IDS framework that incorporates language-derived semantic supervision into federated optimization, enabling open-set and zero-shot intrusion detection for previously unseen attack behaviors. The approach constructs semantic attack prototypes using a Tri-LLM ensemble of GPT-4o, DeepSeek-V3, and LLaMA-3-8B, aligning distributed telemetry features with high-level attack concepts. Inter-LLM semantic disagreement is modeled as epistemic uncertainty for zero-day risk estimation, while a trust-aware aggregation mechanism dynamically weights client updates based on reliability. Experimental results show stable semantic alignment across heterogeneous clients and consistent convergence. The framework achieves over 80% zero-shot detection accuracy on unseen attack patterns, improving zero-day discrimination by more than 10% compared to similarity-based baselines, while maintaining low aggregation instability in the presence of unreliable or compromised clients.", "AI": {"tldr": "论文提出了一种基于语义驱动的联邦学习框架，用于开放集和零样本入侵检测。", "motivation": "现有的联邦学习基础架构在处理未知攻击行为时存在局限性，缺乏不确定性估计、语义泛化以及对零日攻击场景中表征知识不确定性的显式建模机制。此外，在实际应用中的异构性和不稳定性也是一个挑战。", "method": "论文引入了一种基于语言模型的联邦优化方法，构建了三个LLM（Tri-LLM）的集合：GPT-4o, DeepSeek-V3和LLaMA-3-8B，用于生成语义攻击原型。通过跨LLM之间的语义分歧作为零日风险评估的一部分，并使用基于信任感知的方法动态加权客户端更新。", "result": "实验结果显示了异构客户端之间稳定的语义对齐以及一致的收敛性。该框架在未知攻击模式下的零样本检测准确率超过了80%，与相似度基准相比，改进超过10%以上，同时保持较低的聚合不稳定性。", "conclusion": "所提出的基于语义驱动的联邦学习方法能够有效地应对开放集和零日威胁，并且即使存在不可靠或被攻陷的客户端也能维持稳定的性能。"}}
{"id": "2602.00216", "pdf": "https://arxiv.org/pdf/2602.00216", "abs": "https://arxiv.org/abs/2602.00216", "authors": ["Zaldy Pagaduan", "Jason Occidental", "Nathaniel Duro", "Dexielito Badilles", "Eleonor Palconit"], "title": "Development of a Cacao Disease Identification and Management App Using Deep Learning", "categories": ["cs.CV", "cs.CY", "eess.IV"], "comment": "6 pages, 8 figures, preprint", "summary": "Smallholder cacao producers often rely on outdated farming techniques and face significant challenges from pests and diseases, unlike larger plantations with more resources and expertise. In the Philippines, cacao farmers have limited access to data, information, and good agricultural practices. This study addresses these issues by developing a mobile application for cacao disease identification and management that functions offline, enabling use in remote areas where farms are mostly located. The core of the system is a deep learning model trained to identify cacao diseases accurately. The trained model is integrated into the mobile app to support farmers in field diagnosis. The disease identification model achieved a validation accuracy of 96.93% while the model for detecting cacao black pod infection levels achieved 79.49% validation accuracy. Field testing of the application showed an agreement rate of 84.2% compared with expert cacao technician assessments. This approach empowers smallholder farmers by providing accessible, technology-enabled tools to improve cacao crop health and productivity.", "AI": {"tldr": "开发一种用于可可病害识别和管理的移动应用程序，使用深度学习技术。", "motivation": "小规模可可种植者面临资源有限、信息缺乏和技术落后的问题。通过开发一款离线可用的应用程序来帮助他们更有效地进行病虫害管理和提高作物健康。", "method": "构建一个基于深度学习模型的核心系统，用于准确识别可可疾病，并将其集成到移动应用程序中以便在实地使用。该模型经过训练后能够实现高达96.93%的验证精度。", "result": "疾病鉴定模型达到了96.93%的验证准确性，而检测可可黑腐病水平的模型则实现了79.49%的验证准确度。现场测试表明，应用程序与专家评估的一致率为84.2％。", "conclusion": "该方法为小规模种植者提供了技术驱动的工具以改善作物健康和产量，并且这些工具在离线状态下也能运行适用于偏远地区。"}}
{"id": "2602.00215", "pdf": "https://arxiv.org/pdf/2602.00215", "abs": "https://arxiv.org/abs/2602.00215", "authors": ["Abhinav V. Sambasivan", "Liam J. Coulter", "Richard G. Paxman", "Jarvis D. Haupt"], "title": "A Renderer-Enabled Framework for Computing Parameter Estimation Lower Bounds in Plenoptic Imaging Systems", "categories": ["eess.IV", "cs.CV", "eess.SP"], "comment": null, "summary": "This work focuses on assessing the information-theoretic limits of scene parameter estimation in plenoptic imaging systems. A general framework to compute lower bounds on the parameter estimation error from noisy plenoptic observations is presented, with a particular focus on passive indirect imaging problems, where the observations do not contain line-of-sight information about the parameter(s) of interest. Using computer graphics rendering software to synthesize the often-complicated dependence among parameter(s) of interest and observations, i.e. the forward model, the proposed framework evaluates the Hammersley-Chapman-Robbins bound to establish lower bounds on the variance of any unbiased estimator of the unknown parameters. The effects of inexact rendering of the true forward model on the computed lower bounds are also analyzed, both theoretically and via simulations. Experimental evaluations compare the computed lower bounds with the performance of the Maximum Likelihood Estimator on a canonical object localization problem, showing that the lower bounds computed via the framework proposed here are indicative of the true underlying fundamental limits in several nominally representative scenarios.", "AI": {"tldr": "本文提出了一种计算全息成像系统中场景参数估计信息理论限制的通用框架。", "motivation": "研究评估全息成像系统中场景参数估计的信息理论极限，特别是在被动间接成像问题中的复杂依赖关系。", "method": "利用计算机图形渲染软件合成复杂的前向模型，计算海姆斯雷-查普曼-罗宾斯界来建立无偏估计器方差的下限，并分析了近似渲染对下限的影响。", "result": "通过实验验证，在典型目标定位问题中，所提出的框架计算出的下限与最大似然估计性能一致，表明其在不同场景中的有效性。", "conclusion": "该研究成功地建立了全息成像系统中参数估计的信息理论限制，并展示了框架的有效性。"}}
{"id": "2602.00214", "pdf": "https://arxiv.org/pdf/2602.00214", "abs": "https://arxiv.org/abs/2602.00214", "authors": ["Juan A. Olmos", "Antoine Manzanera", "Fabio Martínez"], "title": "A Geometric Multimodal Foundation Model Integrating Bp-MRI and Clinical Reports in Prostate Cancer Classification", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at IEEE International Symposium on Biomedical Imaging (ISBI) 2026", "summary": "Prostate cancer (PCa) is one of the most common cancers in men worldwide. Bi-parametric MRI (bp-MRI) and clinical variables are crucial for PCa identification and improving treatment decisions. However, this process is subjective to expert interpretations. Furthermore, most existing computer-aided diagnosis methods focus on imaging-based models, overlooking the clinical context and suffering from data scarcity, limiting their ability to learn robust representations. We propose a geometric multimodal Foundation Model (FM), named MFM-Geom, that learns representations from bp-MRI and clinical reports, encoding visual findings and information from the context of clinical variables. In the representations classification head, the approach leverages symmetric positive definite (SPD) matrices and Riemannian deep learning to integrate imaging-text representations from a biomedical multimodal FM. Using 10% of the training data, MFM-Geom outperformed baseline class token embedding-based classification (+8.3%, AUC-PR of 90.67). Generalization on external dataset confirmed the robustness of fine-tuning biomedical FM, achieving an AUC-PR of 90.6.", "AI": {"tldr": "提出一种融合bp-MRI和临床报告的几何多模态基础模型MFM-Geom，用于前列腺癌分类。", "motivation": "为了克服现有影像学方法忽略临床背景及数据稀缺的问题，提高前列腺癌诊断的准确性与客观性。", "method": "利用对称正定矩阵和黎曼深度学习技术将bp-MRI图像和临床报告的信息进行融合，并在此基础上构建了MFM-Geom模型。", "result": "在仅使用10%训练数据的情况下，MFM-Geom模型的AUC-PR达到90.67%，显著优于基线方法；在外部数据集上验证时，该模型同样表现出色，AUC-PR为90.6%", "conclusion": "证明了所提出的几何多模态基础模型在前列腺癌分类任务中的优越性及鲁棒性。"}}
{"id": "2602.00213", "pdf": "https://arxiv.org/pdf/2602.00213", "abs": "https://arxiv.org/abs/2602.00213", "authors": ["Mehul Goenka", "Tejas Pathak", "Siddharth Asthana"], "title": "TessPay: Verify-then-Pay Infrastructure for Trusted Agentic Commerce", "categories": ["cs.CR", "cs.AI", "cs.MA"], "comment": null, "summary": "The global economy is entering the era of Agentic Commerce, where autonomous agents can discover services, negotiate prices, and transact value. However adoption towards agentic commerce faces a foundational trust gap: current systems are built for direct human interactions rather than agent-driven operations. It lacks core primitives across three critical stages of agentic transactions. First, Task Delegation lacks means to translate user intent into defined scopes, discover appropriate agents, and securely authorize actions. Second, Payment Settlement for tasks is processed before execution, lacking verifiable evidence to validate the agent's work. Third, Audit Mechanisms fail to capture the full transaction lifecycle, preventing clear accountability for disputes. While emerging standards address fragments of this trust gap, there still remains a critical need for a unified infrastructure that binds the entire transaction lifecycle. To resolve this gap, we introduce TessPay, a unified infrastructure that replaces implicit trust with a 'Verify-then-Pay' architecture. It is a two plane architecture separating control and verification from settlement. TessPay operationalizes trust across four distinct stages: Before execution, agents are anchored in a canonical registry and user intent is captured as verifiable mandates, enabling stakeholder accountability. During execution, funds are locked in escrow while the agent executes the task and generates cryptographic evidence (TLS Notary, TEE etc.) to support Proof of Task Execution (PoTE). At settlement, the system verifies this evidence and releases funds only when the PoTE satisfies verification predicates; modular rail adapters ensure this PoTE-gated escrow remains chain-agnostic across heterogeneous payment rails. After settlement, TessPay preserves a tamper-evident audit trail to enable clear accountability for dispute resolution.", "AI": {"tldr": "TessPay 构建了一个统一的基础设施，用于代理经济中的任务委托、支付结算和审计机制。", "motivation": "现有的系统主要用于直接的人类互动而非代理驱动的操作，导致在代理交易的关键阶段存在信任缺口。为了弥补这一差距，需要一个能够贯穿整个交易生命周期并实现明确责任的统一基础设施。", "method": "TessPay 引入了一种 'Verify-then-Pay' 架构，该架构分为控制和验证与结算两个平面。它通过在执行前锚定代理、捕获可验证的任务指令，在执行期间锁定资金并在任务完成后释放资金来操作信任。", "result": "TessPay 可以确保在所有交易阶段实现明确的责任，包括交易的注册、任务的执行和支付的结算，并且具有链无关性。", "conclusion": "TessPay 提供了一种统一的方法，将整个代理经济中的关键环节整合为一个系统，从而解决了现有信任缺口的问题。"}}
{"id": "2602.00212", "pdf": "https://arxiv.org/pdf/2602.00212", "abs": "https://arxiv.org/abs/2602.00212", "authors": ["Sathish Krishna Anumula", "Vetrivelan Tamilmani", "Aniruddha Arjun Singh", "Dinesh Rajendran", "Venkata Deepak Namburi"], "title": "Deep Learning Based CNN Model for Automated Detection of Pneumonia from Chest XRay Images", "categories": ["cs.CV"], "comment": "17 Pages, 2 Tables, 6 Figures", "summary": "Pneumonia has been one of the major causes of morbidities and mortality in the world and the prevalence of this disease is disproportionately high among the pediatric and elderly populations especially in resources trained areas Fast and precise diagnosis is a prerequisite for successful clinical intervention but due to inter observer variation fatigue among experts and a shortage of qualified radiologists traditional approaches that rely on manual interpretation of chest radiographs are frequently constrained To address these problems this paper introduces a unified automated diagnostic model using a custom Convolutional Neural Network CNN that can recognize pneumonia in chest Xray images with high precision and at minimal computational expense In contrast like other generic transfer learning based models which often possess redundant parameters the offered architecture uses a tailor made depth wise separable convolutional design which is optimized towards textural characteristics of grayscale medical images Contrast Limited Adaptive Histogram Equalization CLAHE and geometric augmentation are two significant preprocessing techniques used to ensure that the system does not experience class imbalance and is more likely to generalize The system is tested using a dataset of 5863 anterior posterior chest Xrays.", "AI": {"tldr": "基于深度学习的CNN模型用于自动检测胸片中的肺炎", "motivation": "提高肺炎诊断的速度和准确性，减少人工解读的疲劳与差异，并解决合格放射科医生短缺的问题。", "method": "使用定制化卷积神经网络(CNN)进行肺炎识别，采用优化后的分层卷积设计以适应灰度医学图像的纹理特征。此外应用对比限制自适应直方图均衡化(CLHE)和几何增强技术来防止类别不平衡并提高模型泛化能力。", "result": "该系统在5863张前胸位X光片上进行了测试，显示出高精度且计算成本低的优势。", "conclusion": "所提出的自动化诊断模型能够有效识别肺炎，减少了人工解读的需求，并克服了传统方法的局限性。"}}
{"id": "2602.00211", "pdf": "https://arxiv.org/pdf/2602.00211", "abs": "https://arxiv.org/abs/2602.00211", "authors": ["Zafar Iqbal", "Anwar Ul Haq", "Srimannarayana Grandhi"], "title": "Interpretable Unsupervised Deformable Image Registration via Confidence-bound Multi-Hop Visual Reasoning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Unsupervised deformable image registration requires aligning complex anatomical structures without reference labels, making interpretability and reliability critical. Existing deep learning methods achieve considerable accuracy but often lack transparency, leading to error drift and reduced clinical trust. We propose a novel Multi-Hop Visual Chain of Reasoning (VCoR) framework that reformulates registration as a progressive reasoning process. Inspired by the iterative nature of clinical decision-making, each visual reasoning hop integrates a Localized Spatial Refinement (LSR) module to enrich feature representations and a Cross-Reference Attention (CRA) mechanism that leads the iterative refinement process, preserving anatomical consistency. This multi-hop strategy enables robust handling of large deformations and produces a transparent sequence of intermediate predictions with a theoretical bound. Beyond accuracy, our framework offers built-in interpretability by estimating uncertainty via the stability and convergence of deformation fields across hops. Extensive evaluations on two challenging public datasets, DIR-Lab 4D CT (lung) and IXI T1-weighted MRI (brain), demonstrate that VCoR achieves competitive registration accuracy while offering rich intermediate visualizations and confidence measures. By embedding an implicit visual reasoning paradigm, we present an interpretable, reliable, and clinically viable unsupervised medical image registration.", "AI": {"tldr": "该论文提出了一种新的基于视觉推理的无监督图像配准框架，旨在提高复杂解剖结构对齐的透明度和可靠性。", "motivation": "现有的深度学习方法虽然在精度上表现出色，但在解释性和可靠性方面存在问题，导致临床信任降低。因此，研究者提出了一个新颖的多阶段视觉链推理框架来解决这些问题。", "method": "提出的Multi-Hop Visual Chain of Reasoning (VCoR) 框架将配准过程重新表述为渐进式推理过程，利用Localized Spatial Refinement（LSR）模块和Cross-Reference Attention(CRA)机制进行迭代细化处理，以保证解剖一致性。", "result": "在DIR-Lab 4D CT 和 IXI T1 加权MRI 上进行了广泛的实验评估，VCoR 达到与现有方法相当的配准精度的同时提供丰富的中间可视化和置信度测量。", "conclusion": "通过嵌入视觉推理范式，研究者提出了一种可解释、可靠且临床可行的无监督医学图像注册框架。"}}
{"id": "2602.00208", "pdf": "https://arxiv.org/pdf/2602.00208", "abs": "https://arxiv.org/abs/2602.00208", "authors": ["Jordan Levy", "Paul Saves", "Moncef Garouani", "Nicolas Verstaevel", "Benoit Gaudou"], "title": "Analyzing Shapley Additive Explanations to Understand Anomaly Detection Algorithm Behaviors and Their Complementarity", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at Intelligent Data Analysis (IDA), 2026", "summary": "Unsupervised anomaly detection is a challenging problem due to the diversity of data distributions and the lack of labels. Ensemble methods are often adopted to mitigate these challenges by combining multiple detectors, which can reduce individual biases and increase robustness. Yet building an ensemble that is genuinely complementary remains challenging, since many detectors rely on similar decision cues and end up producing redundant anomaly scores. As a result, the potential of ensemble learning is often limited by the difficulty of identifying models that truly capture different types of irregularities. To address this, we propose a methodology for characterizing anomaly detectors through their decision mechanisms. Using SHapley Additive exPlanations, we quantify how each model attributes importance to input features, and we use these attribution profiles to measure similarity between detectors. We show that detectors with similar explanations tend to produce correlated anomaly scores and identify largely overlapping anomalies. Conversely, explanation divergence reliably indicates complementary detection behavior. Our results demonstrate that explanation-driven metrics offer a different criterion than raw outputs for selecting models in an ensemble. However, we also demonstrate that diversity alone is insufficient; high individual model performance remains a prerequisite for effective ensembles. By explicitly targeting explanation diversity while maintaining model quality, we are able to construct ensembles that are more diverse, more complementary, and ultimately more effective for unsupervised anomaly detection.", "AI": {"tldr": "本文通过使用SHapley Additive exPlanations（SHAP）来量化每个模型对输入特征的重要性，并利用这些解释特性来衡量不同检测器之间的相似度，以帮助构建更互补的异常检测集成。", "motivation": "由于数据分布多样性和缺乏标签的问题，无监督异常检测是一个具有挑战性的问题。集合方法通过结合多个检测器减少个体偏差并提高鲁棒性而被广泛采用。然而，选择真正捕获不同类型不规则性的模型仍然是一个难题。因此本文提出了一种基于决策机制来表征异常检测器的方法。", "method": "利用SHapley Additive exPlanations（SHAP）量化每个模型对输入特征的重要性，并使用这些解释特性来衡量检测器之间的相似度，以确定哪些检测器表现出互补的行为模式。", "result": "结果显示，具有类似解释的检测器往往会产生相关异常评分并识别出重叠的异常。相反，解释差异可靠地指示了互补检测行为。解释驱动的指标为选择集成中的模型提供了一种不同于原始输出的标准，但高个体模型性能仍然是有效集成的前提。", "conclusion": "通过在保持模型质量的同时明确追求解释多样性，可以构建更多样、更具互补性的异常检测集合，从而提高无监督异常检测的有效性。"}}
{"id": "2602.00205", "pdf": "https://arxiv.org/pdf/2602.00205", "abs": "https://arxiv.org/abs/2602.00205", "authors": ["Beier Zhu", "Kesen Zhao", "Jiequan Cui", "Qianru Sun", "Yuan Zhou", "Xun Yang", "Hanwang Zhang"], "title": "Reducing Class-Wise Performance Disparity via Margin Regularization", "categories": ["cs.LG", "cs.CV"], "comment": "To appear in ICLR 2026", "summary": "Deep neural networks often exhibit substantial disparities in class-wise accuracy, even when trained on class-balanced data, posing concerns for reliable deployment. While prior efforts have explored empirical remedies, a theoretical understanding of such performance disparities in classification remains limited. In this work, we present Margin Regularization for Performance Disparity Reduction (MR$^2$), a theoretically principled regularization for classification by dynamically adjusting margins in both the logit and representation spaces. Our analysis establishes a margin-based, class-sensitive generalization bound that reveals how per-class feature variability contributes to error, motivating the use of larger margins for hard classes. Guided by this insight, MR$^2$ optimizes per-class logit margins proportional to feature spread and penalizes excessive representation margins to enhance intra-class compactness. Experiments on seven datasets, including ImageNet, and diverse pre-trained backbones (MAE, MoCov2, CLIP) demonstrate that MR$^2$ not only improves overall accuracy but also significantly boosts hard class performance without trading off easy classes, thus reducing performance disparity. Code is available at: https://github.com/BeierZhu/MR2", "AI": {"tldr": "通过动态调整对数和表示空间的边际来减少类别之间的性能差异。", "motivation": "深度神经网络在平衡数据集上训练时仍然表现出显著的分类精度差异，这种现象限制了其可靠部署。为了解决这一问题并提供理论解释，作者提出了Margin Regularization for Performance Disparity Reduction (MR$^2$)。", "method": "通过调整对数和表示空间中的边际来优化类别间的性能差距，具体来说是根据特征的离散程度动态地增大困难类别的对数边际，并减少过度的表示边际以增强内部紧凑性。", "result": "实验结果表明，在多个数据集上使用MR$^2$不仅可以提高整体精度，还可以显著提升难以分类的类别准确性而不会牺牲容易分类的性能。", "conclusion": "MR$^2$通过理论和实践证明了它在减少深度神经网络中类别间性能差异方面的有效性。"}}
{"id": "2602.00204", "pdf": "https://arxiv.org/pdf/2602.00204", "abs": "https://arxiv.org/abs/2602.00204", "authors": ["Waleed Khan Mohammed", "Zahirul Arief Irfan Bin Shahrul Anuar", "Mousa Sufian Mousa Mitani", "Hezerul Abdul Karim", "Nouar AlDahoul"], "title": "Semantic-Aware Advanced Persistent Threat Detection Using Autoencoders on LLM-Encoded System Logs", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Advanced Persistent Threats (APTs) are among the most challenging cyberattacks to detect. They are carried out by highly skilled attackers who carefully study their targets and operate in a stealthy, long-term manner. Because APTs exhibit \"low-and-slow\" behavior, traditional statistical methods and shallow machine learning techniques often fail to detect them. Previous research on APT detection has explored machine learning approaches and provenance graph analysis. However, provenance-based methods often fail to capture the semantic intent behind system activities. This paper proposes a novel anomaly detection approach that leverages semantic embeddings generated by Large Language Models (LLMs). The method enhances APT detection by extracting meaningful semantic representations from unstructured system log data. First, raw system logs are transformed into high-dimensional semantic embeddings using a pre-trained transformer model. These embeddings are then analyzed using an Autoencoder (AE) to identify anomalous and potentially malicious patterns. The proposed method is evaluated using the DARPA Transparent Computing (TC) dataset, which contains realistic APT attack scenarios generated by red teams in live environments. Experimental results show that the AE trained on LLM-derived embeddings outperforms widely used unsupervised baseline methods, including Isolation Forest (IForest), One-Class Support Vector Machine (OC-SVM), and Principal Component Analysis (PCA). Performance is measured using the Area Under the Receiver Operating Characteristic Curve (AUC-ROC), where the proposed approach consistently achieves superior results, even in complex threat scenarios. These findings highlight the importance of semantic understanding in detecting non-linear and stealthy attack behaviors that are often missed by conventional detection techniques.", "AI": {"tldr": "本文提出了一种基于大型语言模型生成的语义嵌入和自编码器进行APT检测的新方法，以提高对低慢行为APT攻击的识别能力。", "motivation": "传统统计方法和浅层机器学习技术难以捕捉到APT的“低慢”行为。为此，研究者提出了一种基于大型语言模型生成语义嵌入的方法来增强APT检测。", "method": "首先使用预训练的Transformer模型将原始系统日志转化为高维语义嵌入。然后利用自编码器对这些嵌入进行分析以识别异常和潜在恶意模式。", "result": "实验结果表明，基于LLM生成的嵌入训练的AE在复杂威胁场景下的AUC-ROC指标优于广泛使用的无监督基线方法，如孤立森林、单类SVM和支持向量机等。", "conclusion": "这种方法证明了语义理解在检测非线性和隐蔽攻击行为中的重要性。"}}
{"id": "2602.00202", "pdf": "https://arxiv.org/pdf/2602.00202", "abs": "https://arxiv.org/abs/2602.00202", "authors": ["Shanwen Wang", "Xin Sun", "Danfeng Hong", "Fei Zhou"], "title": "Vision-Language Model Purified Semi-Supervised Semantic Segmentation for Remote Sensing Images", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The semi-supervised semantic segmentation (S4) can learn rich visual knowledge from low-cost unlabeled images. However, traditional S4 architectures all face the challenge of low-quality pseudo-labels, especially for the teacher-student framework.We propose a novel SemiEarth model that introduces vision-language models (VLMs) to address the S4 issues for the remote sensing (RS) domain. Specifically, we invent a VLM pseudo-label purifying (VLM-PP) structure to purify the teacher network's pseudo-labels, achieving substantial improvements. Especially in multi-class boundary regions of RS images, the VLM-PP module can significantly improve the quality of pseudo-labels generated by the teacher, thereby correctly guiding the student model's learning. Moreover, since VLM-PP equips VLMs with open-world capabilities and is independent of the S4 architecture, it can correct mispredicted categories in low-confidence pseudo-labels whenever a discrepancy arises between its prediction and the pseudo-label. We conducted extensive experiments on multiple RS datasets, which demonstrate that our SemiEarth achieves SOTA performance. More importantly, unlike previous SOTA RS S4 methods, our model not only achieves excellent performance but also offers good interpretability. The code is released at https://github.com/wangshanwen001/SemiEarth.", "AI": {"tldr": "本文提出了一种新型的半监督语义分割模型SemiEarth，用于遥感图像处理。", "motivation": "传统的半监督语义分割架构在生成伪标签时面临质量问题，特别是对于教师-学生框架。为解决这些问题，引入了视觉语言模型来提高遥感图像多类别边界区域的伪标签质量。", "method": "提出了一种基于视觉语言模型（VLM）的伪标签净化模块（VLM-PP），可以显著改善教师网络生成的伪标签，并具备开放世界能力以纠正低置信度伪标签中的错误分类。", "result": "实验结果表明，SemiEarth在多个遥感数据集上达到了最先进的性能水平。此外，该模型不仅表现出色而且具有良好的可解释性。", "conclusion": "通过引入视觉语言模型（VLM），提出的SemiEarth方法显著提升了半监督语义分割的准确性，并且保持了较高的可解释性。"}}
{"id": "2602.00198", "pdf": "https://arxiv.org/pdf/2602.00198", "abs": "https://arxiv.org/abs/2602.00198", "authors": ["Esteban Pesnel", "Julien Le Tanou", "Michael Ropert", "Thomas Maugey", "Aline Roumy"], "title": "SCALED : Surrogate-gradient for Codec-Aware Learning of Downsampling in ABR Streaming", "categories": ["eess.IV", "cs.AI", "cs.MM"], "comment": "ef:PCS 2025 - Picture Coding Symposium, IEEE Signal Processing Society, Dec 2025, Aachen (Aix la Chapelle), Germany", "summary": "The rapid growth in video consumption has introduced significant challenges to modern streaming architectures. Over-the-Top (OTT) video delivery now predominantly relies on Adaptive Bitrate (ABR) streaming, which dynamically adjusts bitrate and resolution based on client-side constraints such as display capabilities and network bandwidth. This pipeline typically involves downsampling the original high-resolution content, encoding and transmitting it, followed by decoding and upsampling on the client side. Traditionally, these processing stages have been optimized in isolation, leading to suboptimal end-to-end rate-distortion (R-D) performance. The advent of deep learning has spurred interest in jointly optimizing the ABR pipeline using learned resampling methods. However, training such systems end-to-end remains challenging due to the non-differentiable nature of standard video codecs, which obstructs gradient-based optimization. Recent works have addressed this issue using differentiable proxy models, based either on deep neural networks or hybrid coding schemes with differentiable components such as soft quantization, to approximate the codec behavior. While differentiable proxy codecs have enabled progress in compression-aware learning, they remain approximations that may not fully capture the behavior of standard, non-differentiable codecs. To our knowledge, there is no prior evidence demonstrating the inefficiencies of using standard codecs during training. In this work, we introduce a novel framework that enables end-to-end training with real, non-differentiable codecs by leveraging data-driven surrogate gradients derived from actual compression errors. It facilitates the alignment between training objectives and deployment performance. Experimental results show a 5.19\\% improvement in BD-BR (PSNR) compared to codec-agnostic training approaches, consistently across the entire rate-distortion convex hull spanning multiple downsampling ratios.", "AI": {"tldr": "提出了一种新的框架，使端到端训练能够使用实际的不可微分视频编解码器，并通过利用从实际压缩错误中推导出的数据驱动替代梯度来实现。", "motivation": "由于标准视频编码器具有非可微性质，这阻碍了基于梯度的学习方法，导致难以直接优化整个自适应比特率（ABR）流媒体管道。现有工作虽使用近似的不同可微分代理模型以克服这一障碍，但没有证据证明传统编解码器在训练中的不效率。", "method": "引入了一种新的框架，该框架利用从实际压缩错误中推导出的数据驱动替代梯度来实现端到端的培训和优化。", "result": "实验结果表明，在整个率失真凸包上使用真实编解码器进行训练相比传统的编码器不可知方法，实现了5.19% BD-BR（PSNR）的提高。", "conclusion": "通过引入新的框架，可以有效利用实际非可微分编解码器实现更优的ABR流媒体性能。"}}
{"id": "2602.00197", "pdf": "https://arxiv.org/pdf/2602.00197", "abs": "https://arxiv.org/abs/2602.00197", "authors": ["Yang Tan", "Yuyuan Xi", "Can Wu", "Bozitao Zhong", "Mingchen Li", "Guisheng Fan", "Jiankang Zhu", "Yafeng Liang", "Nanqing Dong", "Liang Hong"], "title": "Rank-and-Reason: Multi-Agent Collaboration Accelerates Zero-Shot Protein Mutation Prediction", "categories": ["q-bio.QM", "cs.AI", "cs.CL"], "comment": "22 pages, 5 figures, 15 tables", "summary": "Zero-shot mutation prediction is vital for low-resource protein engineering, yet existing protein language models (PLMs) often yield statistically confident results that ignore fundamental biophysical constraints. Currently, selecting candidates for wet-lab validation relies on manual expert auditing of PLM outputs, a process that is inefficient, subjective, and highly dependent on domain expertise. To address this, we propose Rank-and-Reason (VenusRAR), a two-stage agentic framework to automate this workflow and maximize expected wet-lab fitness. In the Rank-Stage, a Computational Expert and Virtual Biologist aggregate a context-aware multi-modal ensemble, establishing a new Spearman correlation record of 0.551 (vs. 0.518) on ProteinGym. In the Reason-Stage, an agentic Expert Panel employs chain-of-thought reasoning to audit candidates against geometric and structural constraints, improving the Top-5 Hit Rate by up to 367% on ProteinGym-DMS99. The wet-lab validation on Cas12i3 nuclease further confirms the framework's efficacy, achieving a 46.7% positive rate and identifying two novel mutants with 4.23-fold and 5.05-fold activity improvements. Code and datasets are released on GitHub (https://github.com/ai4protein/VenusRAR/).", "AI": {"tldr": "提出Rank-and-Reason（VenusRAR）框架，用于零样本蛋白质突变预测", "motivation": "现有蛋白质语言模型在低资源条件下进行蛋白质工程时效率低下且依赖专家知识，需要一种自动化的方法来提高准确性和效率", "method": "采用两阶段的多代理协作框架，第一阶段通过计算专家和虚拟生物学家聚合上下文感知的多模态集成以生成预测结果；第二阶段利用智能小组运用链式思维推理对候选物进行审核", "result": "在ProteinGym数据集上达到0.551的新斯皮尔曼相关系数记录，并将Top-5命中率提高了367%；实验验证表明，该框架的有效性得到进一步确认，实现了46.7％的阳性率并发现了两个活性提高的新突变", "conclusion": "Rank-and-Reason（VenusRAR）框架在零样本蛋白质突变预测任务中表现出色，有助于降低湿实验室验证的成本和时间"}}
{"id": "2602.00194", "pdf": "https://arxiv.org/pdf/2602.00194", "abs": "https://arxiv.org/abs/2602.00194", "authors": ["Julie Alberge", "Tristan Haugomat", "Gaël Varoquaux", "Judith Abécassis"], "title": "On the calibration of survival models with competing risks", "categories": ["stat.ME", "cs.AI", "math.ST"], "comment": "ef:International Conference on Artificial Intelligence and Statistics (AISTATS) 2026, May 2026, Tanger, Morocco", "summary": "Survival analysis deals with modeling the time until an event occurs, and accurate probability estimates are crucial for decision-making, particularly in the competing-risks setting where multiple events are possible. While recent work has addressed calibration in standard survival analysis, the competing-risks setting remains under-explored as it is harder (the calibration applies to both probabilities across classes and time horizon). We show that existing calibration measures are not suited to the competing-risk setting and that recent models do not give well-behaved probabilities. To address this, we introduce a dedicated framework with two novel calibration measures that are minimized for oracle estimators (i.e., both measures are proper). We also introduce some methods to estimate, test, and correct the calibration. Our recalibration methods yield good probabilities while preserving discrimination.", "AI": {"tldr": "本文探讨了在竞争风险环境中生存模型的校准问题，提出了新的校准度量和方法。", "motivation": "现有校准措施不适用于竞争风险环境，且近期模型提供的概率估计不够准确。研究动机在于解决这一问题，以改善决策制定。", "method": "引入专门框架和两个新校准度量，并提出估算、测试及修正校准的方法。", "result": "新的校准方法能够产生良好概率估计同时保持区分力。", "conclusion": "论文通过新的校准措施改进了竞争风险环境下的生存模型，提高了决策准确性。"}}
{"id": "2602.00192", "pdf": "https://arxiv.org/pdf/2602.00192", "abs": "https://arxiv.org/abs/2602.00192", "authors": ["Elif Nebioglu", "Emirhan Bilgiç", "Adrian Popescu"], "title": "AI-Generated Image Detectors Overrely on Global Artifacts: Evidence from Inpainting Exchange", "categories": ["cs.CV", "cs.AI"], "comment": "21 pages, 15 figures, 6 tables", "summary": "Modern deep learning-based inpainting enables realistic local image manipulation, raising critical challenges for reliable detection. However, we observe that current detectors primarily rely on global artifacts that appear as inpainting side effects, rather than on locally synthesized content. We show that this behavior occurs because VAE-based reconstruction induces a subtle but pervasive spectral shift across the entire image, including unedited regions. To isolate this effect, we introduce Inpainting Exchange (INP-X), an operation that restores original pixels outside the edited region while preserving all synthesized content. We create a 90K test dataset including real, inpainted, and exchanged images to evaluate this phenomenon. Under this intervention, pretrained state-of-the-art detectors, including commercial ones, exhibit a dramatic drop in accuracy (e.g., from 91\\% to 55\\%), frequently approaching chance level. We provide a theoretical analysis linking this behavior to high-frequency attenuation caused by VAE information bottlenecks. Our findings highlight the need for content-aware detection. Indeed, training on our dataset yields better generalization and localization than standard inpainting. Our dataset and code are publicly available at https://github.com/emirhanbilgic/INP-X.", "AI": {"tldr": "研究探讨了当前AI生成图像检测器过度依赖全局特征而非局部合成内容的问题，并提出了一种新的操作方法Inpainting Exchange来解决此问题。", "motivation": "现有的AI生成图像检测技术主要依靠全球性的副作用作为依据，而不是真正基于合成的内容。这种做法在处理经过精细修改的图像时效果不佳，因此需要改进以提高准确性和定位能力。", "method": "通过VAE（变分自编码器）重建引起的频谱偏移现象，提出了Inpainting Exchange操作方法，该方法可以保留编辑区域的内容同时恢复未编辑区域的原始像素。创建了一个包含90K个测试样本的数据集用于评估这种方法的效果。", "result": "实验结果显示，在引入Inpainting Exchange后，预训练的最先进的检测器准确率大幅下降（例如从91%降至55%）。此外，使用该数据集进行训练可以显著改善检测器的一般化和定位能力。", "conclusion": "研究证明了当前图像生成检测方法存在的局限性，并展示了如何通过更加关注局部合成内容而非全局特征来改进这些方法。提出的方法和数据集有助于推动更先进的AI生成图像检测技术的发展。"}}
{"id": "2602.00191", "pdf": "https://arxiv.org/pdf/2602.00191", "abs": "https://arxiv.org/abs/2602.00191", "authors": ["Yadang Alexis Rouzoumka", "Jean Pinsolle", "Eugénie Terreaux", "Christèle Morisseau", "Jean-Philippe Ovarlez", "Chengfang Ren"], "title": "GEPC: Group-Equivariant Posterior Consistency for Out-of-Distribution Detection in Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": "preprint", "summary": "Diffusion models learn a time-indexed score field $\\mathbf{s}_θ(\\mathbf{x}_t,t)$ that often inherits approximate equivariances (flips, rotations, circular shifts) from in-distribution (ID) data and convolutional backbones. Most diffusion-based out-of-distribution (OOD) detectors exploit score magnitude or local geometry (energies, curvature, covariance spectra) and largely ignore equivariances. We introduce Group-Equivariant Posterior Consistency (GEPC), a training-free probe that measures how consistently the learned score transforms under a finite group $\\mathcal{G}$, detecting equivariance breaking even when score magnitude remains unchanged. At the population level, we propose the ideal GEPC residual, which averages an equivariance-residual functional over $\\mathcal{G}$, and we derive ID upper bounds and OOD lower bounds under mild assumptions. GEPC requires only score evaluations and produces interpretable equivariance-breaking maps. On OOD image benchmark datasets, we show that GEPC achieves competitive or improved AUROC compared to recent diffusion-based baselines while remaining computationally lightweight. On high-resolution synthetic aperture radar imagery where OOD corresponds to targets or anomalies in clutter, GEPC yields strong target-background separation and visually interpretable equivariance-breaking maps. Code is available at https://github.com/RouzAY/gepc-diffusion/.", "AI": {"tldr": "本文提出了GEPC方法，用于检测扩散模型中的出分布（OOD）样本。", "motivation": "大多数基于分数的OOD检测器主要利用分数幅值或局部几何信息，忽略了等变性。为此，作者引入了GEPC来衡量学习到的分数在有限群下的一致变换情况，从而识别等变性破坏的现象。", "method": "GEPC通过测量学习到的分数在给定群组下的转换一致性来进行OOD检测，并提出了理想的GEPC残差以提供更准确的结果。该方法仅需要分数评估，无需训练过程且计算成本低。", "result": "实验表明，GEPC在OOD图像基准数据集上取得了与最近基于扩散模型的方法相当甚至更好的AUROC，同时保持了较低的计算复杂度。", "conclusion": "GEPC不仅能够检测出分布样本，而且还能生成可解释性的等变性破坏图。这为高分辨率合成孔径雷达图像中的OOD检测提供了强有力的支持，并展示了强大的前景背景分离能力。"}}
{"id": "2602.00190", "pdf": "https://arxiv.org/pdf/2602.00190", "abs": "https://arxiv.org/abs/2602.00190", "authors": ["Mohit Jiwatode", "Alexander Dockhorn", "Bodo Rosenhahn"], "title": "From Gameplay Traces to Game Mechanics: Causal Induction with Large Language Models", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": "Submitted to ICPR 2026", "summary": "Deep learning agents can achieve high performance in complex game domains without often understanding the underlying causal game mechanics. To address this, we investigate Causal Induction: the ability to infer governing laws from observational data, by tasking Large Language Models (LLMs) with reverse-engineering Video Game Description Language (VGDL) rules from gameplay traces. To reduce redundancy, we select nine representative games from the General Video Game AI (GVGAI) framework using semantic embeddings and clustering. We compare two approaches to VGDL generation: direct code generation from observations, and a two-stage method that first infers a structural causal model (SCM) and then translates it into VGDL. Both approaches are evaluated across multiple prompting strategies and controlled context regimes, varying the amount and form of information provided to the model, from just raw gameplay observations to partial VGDL specifications. Results show that the SCM-based approach more often produces VGDL descriptions closer to the ground truth than direct generation, achieving preference win rates of up to 81\\% in blind evaluations and yielding fewer logically inconsistent rules. These learned SCMs can be used for downstream use cases such as causal reinforcement learning, interpretable agents, and procedurally generating novel but logically consistent games.", "AI": {"tldr": "论文研究了大型语言模型从游戏玩法追踪中推导出视频游戏描述语言规则的能力，通过因果推理来理解复杂游戏中隐藏的因果机制。", "motivation": "深度学习代理在复杂的电子游戏中可以取得高成绩却不一定理解背后的因果机制。因此，文章探讨如何使用大型语言模型进行反向工程以从观察数据中推断出控制游戏行为的基本规律。", "method": "通过两种方式生成VGDL规则：一种是直接从观测中生成代码，另一种是首先推导结构化因果模型（SCM）然后将其转换为VGDL。实验在不同提示策略和信息提供形式下进行，并使用语义嵌入和聚类选择代表性游戏。", "result": "结果显示，基于SCM的方法更频繁地产生了接近真实规则的VGDL描述，在盲测试中获得了高达81%的偏好胜利率，并生成了较少逻辑不一致的规则。", "conclusion": "学习到的因果模型能够应用于下游任务如因果强化学习、可解释代理和程序化生成新的游戏。"}}
{"id": "2602.00189", "pdf": "https://arxiv.org/pdf/2602.00189", "abs": "https://arxiv.org/abs/2602.00189", "authors": ["Zhipeng Chen", "Xinheng Wang", "Lun Xie", "Haijie Yuan", "Hang Pan"], "title": "LPIPS-AttnWav2Lip: Generic Audio-Driven lip synchronization for Talking Head Generation in the Wild", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "comment": "This paper has been accepted by Elsevier's \\textit{Speech Communication} journal. Official publication link: https://doi.org/10.1016/j.specom.2023.103028 The code for the paper is available at the following link: https://github.com/FelixChan9527/LPIPS-AttnWav2Lip", "summary": "Researchers have shown a growing interest in Audio-driven Talking Head Generation. The primary challenge in talking head generation is achieving audio-visual coherence between the lips and the audio, known as lip synchronization. This paper proposes a generic method, LPIPS-AttnWav2Lip, for reconstructing face images of any speaker based on audio. We used the U-Net architecture based on residual CBAM to better encode and fuse audio and visual modal information. Additionally, the semantic alignment module extends the receptive field of the generator network to obtain the spatial and channel information of the visual features efficiently; and match statistical information of visual features with audio latent vector to achieve the adjustment and injection of the audio content information to the visual information. To achieve exact lip synchronization and to generate realistic high-quality images, our approach adopts LPIPS Loss, which simulates human judgment of image quality and reduces instability possibility during the training process. The proposed method achieves outstanding performance in terms of lip synchronization accuracy and visual quality as demonstrated by subjective and objective evaluation results. The code for the paper is available at the following link: https://github.com/FelixChan9527/LPIPS-AttnWav2Lip", "AI": {"tldr": "本文提出了一种新的方法LPIPS-AttnWav2Lip，用于基于音频驱动的说话人脸同步生成。", "motivation": "实现高质量、自然的人脸图像和语音之间的唇部同步是一个挑战。现有的方法可能无法有效融合视听信息并产生真实的面部动画。", "method": "提出了一个结合U-Net架构和CBAM机制的方法，并引入了一个语义对齐模块以更好地编码和融合音频及视觉模态的信息，同时采用LPIPS损失函数来提高生成图像的质量。", "result": "该方法在唇部同步准确性和视觉质量方面表现优异，通过主观评价和客观指标验证了其性能。", "conclusion": "所提出的方法实现了高质量的、自然的人脸动画，并提供了源代码以便进一步研究。"}}
{"id": "2602.00188", "pdf": "https://arxiv.org/pdf/2602.00188", "abs": "https://arxiv.org/abs/2602.00188", "authors": ["Srividhya Sethuraman", "Chandrashekar Lakshminarayanan"], "title": "Learning to Price: Interpretable Attribute-Level Models for Dynamic Markets", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted in AAMAS 2026 - main track - full paper - 12 pages", "summary": "Dynamic pricing in high-dimensional markets poses fundamental challenges of scalability, uncertainty, and interpretability. Existing low-rank bandit formulations learn efficiently but rely on latent features that obscure how individual product attributes influence price. We address this by introducing an interpretable \\emph{Additive Feature Decomposition-based Low-Dimensional Demand (\\textbf{AFDLD}) model}, where product prices are expressed as the sum of attribute-level contributions and substitution effects are explicitly modeled. Building on this structure, we propose \\textbf{ADEPT} (Additive DEcomposition for Pricing with cross-elasticity and Time-adaptive learning)-a projection-free, gradient-free online learning algorithm that operates directly in attribute space and achieves a sublinear regret of $\\tilde{\\mathcal{O}}(\\sqrt{d}T^{3/4})$. Through controlled synthetic studies and real-world datasets, we show that ADEPT (i) learns near-optimal prices under dynamic market conditions, (ii) adapts rapidly to shocks and drifts, and (iii) yields transparent, attribute-level price explanations. The results demonstrate that interpretability and efficiency in autonomous pricing agents can be achieved jointly through structured, attribute-driven representations.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.00186", "pdf": "https://arxiv.org/pdf/2602.00186", "abs": "https://arxiv.org/abs/2602.00186", "authors": ["Tingyu Fan", "Ran Gong", "Yueyu Hu", "Yao Wang"], "title": "SurfelSoup: Learned Point Cloud Geometry Compression With a Probablistic SurfelTree Representation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "This paper presents SurfelSoup, an end-to-end learned surface-based framework for point cloud geometry compression, with surface-structured primitives for representation. It proposes a probabilistic surface representation, pSurfel, which models local point occupancies using a bounded generalized Gaussian distribution. In addition, the pSurfels are organized into an octree-like hierarchy, pSurfelTree, with a Tree Decision module that adaptively terminates the tree subdivision for rate-distortion optimal Surfel granularity selection. This formulation avoids redundant point-wise compression in smooth regions and produces compact yet smooth surface reconstructions. Experimental results under the MPEG common test condition show consistent gain on geometry compression over voxel-based baselines and MPEG standard G-PCC-GesTM-TriSoup, while providing visually superior reconstructions with smooth and coherent surface structures.", "AI": {"tldr": "本文提出了SurfelSoup，一种基于学习的点云几何压缩框架，使用表面结构化的原始表示。", "motivation": "现有方法在平滑区域存在冗余的逐点压缩问题，因此提出了一种新的概率表面表示方法以解决这些问题。", "method": "提出了一种新的概率表面表示pSurfel和一个组织成八叉树样式的hierarchy pSurfelTree，其中包含了一个自适应终止树分割的Tree Decision模块，用于选择最优的surfel粒度。", "result": "实验结果表明，在MPEG通用测试条件下，该方法在几何压缩上优于基于体素的方法和MPEG标准G-PCC-GesTM-TriSoup，并提供了视觉上更优、表面光滑且连贯的重建效果。", "conclusion": "通过避免平滑区域内的逐点冗余压缩，SurfelSoup能够产生紧凑而平滑的表面重构。"}}
{"id": "2602.00185", "pdf": "https://arxiv.org/pdf/2602.00185", "abs": "https://arxiv.org/abs/2602.00185", "authors": ["Fengxu Yang", "Jack D. Evans"], "title": "QUASAR: A Universal Autonomous System for Atomistic Simulation and a Benchmark of Its Capabilities", "categories": ["cond-mat.mtrl-sci", "cs.AI"], "comment": "12 pages, 2 figures", "summary": "The integration of large language models (LLMs) into materials science offers a transformative opportunity to streamline computational workflows, yet current agentic systems remain constrained by rigid tool-calling approaches and narrowly scoped agents. In this work, we introduce QUASAR, a universal autonomous system for atomistic simulation designed to facilitate production-grade scientific discovery. QUASAR autonomously orchestrates complex multi-scale workflows across diverse methods, including density functional theory, machine learning potentials, molecular dynamics, and Monte Carlo simulations. The system incorporates robust mechanisms for adaptive planning, context-efficient memory management, and hybrid knowledge retrieval to navigate real-world research scenarios without human intervention. We benchmark QUASAR against a series of three-tiered tasks, progressing from routine tasks to frontier research challenges such as photocatalyst screening and novel material assessment. These results suggest that QUASAR can function as a general atomistic reasoning system rather than a task-specific automation framework. They also provide initial evidence supporting the potential deployment of agentic AI as a component of computational chemistry research workflows, while identifying areas requiring further development.", "AI": {"tldr": "介绍了一种名为QUASAR的自主系统，用于原子级模拟，并通过一系列任务验证其能力。", "motivation": "当前材料科学中的代理系统受限于固定工具调用和狭窄的任务范围。本研究旨在开发一种能够无缝整合多种计算方法并自动执行复杂多尺度工作流的通用自动化系统。", "method": "QUASAR设计用于在原子级别模拟中实现自动化，通过自适应计划、高效内存管理和混合知识检索机制来应对实际研究场景中的挑战。", "result": "基准测试显示，QUASAR能够从常规任务到前沿研究挑战（如光催化剂筛选和新材料评估）进行有效处理。证明了其作为通用原子级推理系统的潜力。", "conclusion": "研究表明，QUASAR可以作为一个通用的自动化系统用于计算化学工作流程，并指出了进一步发展的领域。"}}
{"id": "2602.00184", "pdf": "https://arxiv.org/pdf/2602.00184", "abs": "https://arxiv.org/abs/2602.00184", "authors": ["Yiyang Wen", "Liu Shi", "Zekun Zhou", "WenZhe Shan", "Qiegen Liu"], "title": "Visible Singularities Guided Correlation Network for Limited-Angle CT Reconstruction", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Limited-angle computed tomography (LACT) offers the advantages of reduced radiation dose and shortened scanning time. Traditional reconstruction algorithms exhibit various inherent limitations in LACT. Currently, most deep learning-based LACT reconstruction methods focus on multi-domain fusion or the introduction of generic priors, failing to fully align with the core imaging characteristics of LACT-such as the directionality of artifacts and directional loss of structural information, which are caused by the absence of projection angles in certain directions. Inspired by the theory of visible and invisible singularities, taking into account the aforementioned core imaging characteristics of LACT, we propose a Visible Singularities Guided Correlation network for LACT reconstruction (VSGC). The design philosophy of VSGC consists of two core steps: First, extract VS edge features from LACT images and focus the model's attention on these VS. Second, establish correlations between the VS edge features and other regions of the image. Additionally, a multi-scale loss function with anisotropic constraint is employed to constrain the model to converge in multiple aspects. Finally, qualitative and quantitative validations are conducted on both simulated and real datasets to verify the effectiveness and feasibility of the proposed design. Particularly, in comparison with alternative methods, VSGC delivers more prominent performance in small angular ranges, with the PSNR improvement of 2.45 dB and the SSIM enhancement of 1.5\\%. The code is publicly available at https://github.com/yqx7150/VSGC.", "AI": {"tldr": "本文提出了一种基于可见奇点指导的相关网络（VSGC）用于有限角度CT重建。", "motivation": "传统重建算法在有限角度CT中存在固有局限性，大多数深度学习方法未能完全结合LACT的核心成像特征。因此，本文提出了新的方法以改善这种状况。", "method": "首先提取可见奇点边缘特征，并引导模型注意力集中在这些特征上；其次建立可视奇点与图像其他区域之间的关联；最后采用多尺度损失函数进行训练。", "result": "在模拟数据和真实数据集上的验证表明，相比于其他方法，VSGC在小角度范围内表现出更优越的性能，PSNR提高了2.45dB，SSIM提升了1.5%。", "conclusion": "该文提出的VSGC网络有效改善了LACT重建的效果，并且已经在公开平台上分享代码。"}}
{"id": "2602.00183", "pdf": "https://arxiv.org/pdf/2602.00183", "abs": "https://arxiv.org/abs/2602.00183", "authors": ["Miao Lin", "Feng Yu", "Rui Ning", "Lusi Li", "Jiawei Chen", "Qian Lou", "Mengxin Zheng", "Chunsheng Xin", "Hongyi Wu"], "title": "RPP: A Certified Poisoned-Sample Detection Framework for Backdoor Attacks under Dataset Imbalance", "categories": ["cs.CR", "cs.CV", "cs.LG"], "comment": null, "summary": "Deep neural networks are highly susceptible to backdoor attacks, yet most defense methods to date rely on balanced data, overlooking the pervasive class imbalance in real-world scenarios that can amplify backdoor threats. This paper presents the first in-depth investigation of how the dataset imbalance amplifies backdoor vulnerability, showing that (i) the imbalance induces a majority-class bias that increases susceptibility and (ii) conventional defenses degrade significantly as the imbalance grows. To address this, we propose Randomized Probability Perturbation (RPP), a certified poisoned-sample detection framework that operates in a black-box setting using only model output probabilities. For any inspected sample, RPP determines whether the input has been backdoor-manipulated, while offering provable within-domain detectability guarantees and a probabilistic upper bound on the false positive rate. Extensive experiments on five benchmarks (MNIST, SVHN, CIFAR-10, TinyImageNet and ImageNet10) covering 10 backdoor attacks and 12 baseline defenses show that RPP achieves significantly higher detection accuracy than state-of-the-art defenses, particularly under dataset imbalance. RPP establishes a theoretical and practical foundation for defending against backdoor attacks in real-world environments with imbalanced data.", "AI": {"tldr": "提出了一种用于检测不平衡数据集中后门攻击的框架RPP，该框架可在黑盒环境下仅通过模型输出概率进行操作。", "motivation": "目前大多数防御方法依赖于平衡的数据集，忽略了现实世界中的数据类别不均衡会加剧后门威胁的问题。研究如何在不平衡数据中提高对后门攻击的抗性，并提出一种新的检测框架。", "method": "提出了随机概率扰动（RPP）框架，在黑盒环境中仅使用模型输出概率来判断输入样本是否被操纵，提供了域内可检测性的理论保障和错误正例率的概率上限。", "result": "实验结果表明，RPP在五个基准数据集上对抗10种后门攻击时，其检出准确度显著优于现有的防御方法，尤其是在处理不平衡数据集方面表现尤为突出。", "conclusion": "该框架为现实世界中具有类别不均衡的数据环境中的后门攻击提供了一种理论和实用的防御基础。"}}
{"id": "2602.00182", "pdf": "https://arxiv.org/pdf/2602.00182", "abs": "https://arxiv.org/abs/2602.00182", "authors": ["David Ribeiro Alves", "Vishnu Patankar", "Matheus Pereira", "Jamie Stephens", "Nima Vaziri", "Sreeram Kannan"], "title": "EigenAI: Deterministic Inference, Verifiable Results", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "EigenAI is a verifiable AI platform built on top of the EigenLayer restaking ecosystem. At a high level, it combines a deterministic large-language model (LLM) inference engine with a cryptoeconomically secured optimistic re-execution protocol so that every inference result can be publicly audited, reproduced, and, if necessary, economically enforced. An untrusted operator runs inference on a fixed GPU architecture, signs and encrypts the request and response, and publishes the encrypted log to EigenDA. During a challenge window, any watcher may request re-execution through EigenVerify; the result is then deterministically recomputed inside a trusted execution environment (TEE) with a threshold-released decryption key, allowing a public challenge with private data. Because inference itself is bit-exact, verification reduces to a byte-equality check, and a single honest replica suffices to detect fraud. We show how this architecture yields sovereign agents -- prediction-market judges, trading bots, and scientific assistants -- that enjoy state-of-the-art performance while inheriting security from Ethereum's validator base.", "AI": {"tldr": "EigenAI 是一个可验证的人工智能平台，结合了确定性大型语言模型推理引擎和乐观再执行协议，确保每次推断结果可以公开审核、重现并在必要时经济上强制执行。", "motivation": "旨在通过构建一个基于 EigenLayer 再质押生态系统的平台来解决 AI 推理的可信度问题，使得每个推断结果都可以被公众审计并验证其准确性。", "method": "结合确定性大型语言模型推理引擎和乐观再执行协议，由不可信操作员在固定 GPU 架构上运行推理，然后将请求和响应签名加密后发布到 EigenDA。任何监视者可以在挑战窗口期间通过 EigenVerify 请求重新执行；推断结果将在可信执行环境内使用阈值解密密钥进行确定性重新计算。", "result": "展示了这种架构如何产生主权代理人——预测市场的法官、交易机器人和科学助理，它们享有最先进的性能，并从以太坊的验证者基础中继承安全性。", "conclusion": "EigenAI 架构通过其可验证性和经济强制执行机制提供了高度可信的 AI 推理服务。"}}
{"id": "2602.00181", "pdf": "https://arxiv.org/pdf/2602.00181", "abs": "https://arxiv.org/abs/2602.00181", "authors": ["Hang Wu", "Yujun Cai", "Zehao Li", "Haonan Ge", "Bowen Sun", "Junsong Yuan", "Yiwei Wang"], "title": "CamReasoner: Reinforcing Camera Movement Understanding via Structured Spatial Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Understanding camera dynamics is a fundamental pillar of video spatial intelligence. However, existing multimodal models predominantly treat this task as a black-box classification, often confusing physically distinct motions by relying on superficial visual patterns rather than geometric cues. We present CamReasoner, a framework that reformulates camera movement understanding as a structured inference process to bridge the gap between perception and cinematic logic. Our approach centers on the Observation-Thinking-Answer (O-T-A) paradigm, which compels the model to decode spatio-temporal cues such as trajectories and view frustums within an explicit reasoning block. To instill this capability, we construct a Large-scale Inference Trajectory Suite comprising 18k SFT reasoning chains and 38k RL feedback samples. Notably, we are the first to employ RL for logical alignment in this domain, ensuring motion inferences are grounded in physical geometry rather than contextual guesswork. By applying Reinforcement Learning to the Observation-Think-Answer (O-T-A) reasoning paradigm, CamReasoner effectively suppresses hallucinations and achieves state-of-the-art performance across multiple benchmarks.", "AI": {"tldr": "本文提出了CamReasoner框架，通过结构化空间推理来理解摄像机运动。", "motivation": "现有的多模态模型在理解和分类摄像机动态方面依赖于表面视觉模式而不是几何线索。", "method": "提出了一种基于观察-思考-回答（O-T-A）范式的结构性推断过程，并构建了大规模推理轨迹套件来训练模型，首次使用强化学习确保运动推理的物理几何基础。", "result": "通过应用强化学习到O-T-A推理框架中，CamReasoner在多个基准测试上实现了最先进的性能，显著提高了摄像机运动理解的能力。", "conclusion": "本文展示了如何通过结构性空间推理来改善摄像机动态的理解，并证明了这种方法的有效性。"}}
{"id": "2602.00180", "pdf": "https://arxiv.org/pdf/2602.00180", "abs": "https://arxiv.org/abs/2602.00180", "authors": ["Deepak Babu Piskala"], "title": "Spec-Driven Development:From Code to Contract in the Age of AI Coding Assistants", "categories": ["cs.SE", "cs.AI"], "comment": "Submitted to AIWare 2026. 8 pages, 3 figures", "summary": "The rise of AI coding assistants has reignited interest in an old idea: what if specifications-not code-were the primary artifact of software development? Spec-driven development (SDD) inverts the traditional workflow by treating specifications as the source of truth and code as a generated or verified secondary artifact. This paper provides practitioners with a comprehensive guide to SDD, covering its principles, workflow patterns, and supporting tools. We present three levels of specification rigor-spec-first, spec-anchored, and spec-as-source-with clear guidance on when each applies. Through analysis of tools ranging from Behavior-Driven Development frameworks to modern AI-assisted toolkits like GitHub Spec Kit, we demonstrate how the spec-first philosophy maps to real implementations. We present case studies from API development, enterprise systems, and embedded software, illustrating how different domains apply SDD. We conclude with a decision framework helping practitioners determine when SDD provides value and when simpler approaches suffice.", "AI": {"tldr": "本文介绍了规范驱动开发（SDD）的概念和应用，以及如何根据不同需求选择合适的规范级别。", "motivation": "随着AI编码助手的兴起，重新引发了关于以规格说明而非代码作为软件开发主要成果的想法的兴趣。这种新方法试图通过将规格定义为真理源头，代码则成为生成或验证后的辅助产物来改变传统的工作流程。", "method": "本文提供了有关SDD的原则、工作流模式和支持工具的全面指南，并介绍了三种规范严谨度层次——首先规范（spec-first）、锚定规范（spec-anchored）和源规约（spec-as-source），并为每种情况提供了清晰指导。此外，通过分析包括行为驱动开发框架在内的现代AI辅助工具套件如GitHub Spec Kit等工具的实际应用案例，展示了如何将先规范哲学映射到实际实现中。", "result": "本文通过来自API开发、企业系统和嵌入式软件的不同领域的案例研究，说明了SDD在不同领域中的应用。结果表明，根据特定项目需求选择合适的规格级别可以提高软件开发的效率和质量。", "conclusion": "我们提出了一个决策框架，帮助实践者确定何时SDD能够提供价值以及何时简单的解决方案就足够了。"}}
{"id": "2602.00176", "pdf": "https://arxiv.org/pdf/2602.00176", "abs": "https://arxiv.org/abs/2602.00176", "authors": ["Feng Tian", "Yixuan Li", "Weili Zeng", "Weitian Zhang", "Yichao Yan", "Xiaokang Yang"], "title": "Stabilizing Diffusion Posterior Sampling by Noise--Frequency Continuation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diffusion posterior sampling solves inverse problems by combining a pretrained diffusion prior with measurement-consistency guidance, but it often fails to recover fine details because measurement terms are applied in a manner that is weakly coupled to the diffusion noise level. At high noise, data-consistency gradients computed from inaccurate estimates can be geometrically incongruent with the posterior geometry, inducing early-step drift, spurious high-frequency artifacts, plus sensitivity to schedules and ill-conditioned operators. To address these concerns, we propose a noise--frequency Continuation framework that constructs a continuous family of intermediate posteriors whose likelihood enforces measurement consistency only within a noise-dependent frequency band. This principle is instantiated with a stabilized posterior sampler that combines a diffusion predictor, band-limited likelihood guidance, and a multi-resolution consistency strategy that aggressively commits reliable coarse corrections while conservatively adopting high-frequency details only when they become identifiable. Across super-resolution, inpainting, and deblurring, our method achieves state-of-the-art performance and improves motion deblurring PSNR by up to 5 dB over strong baselines.", "AI": {"tldr": "本文提出了一种通过噪声频带继续的方法来稳定扩散后验采样，以解决逆问题中的细节恢复和高频伪影问题。", "motivation": "现有扩散后验采样方法在处理高噪声时容易出现早期漂移、高频伪像以及对时间表和病态算子的敏感性。因此需要一种新的策略来增强准确性和鲁棒性。", "method": "提出了一种频带继续框架，通过建立一系列中间后验概率分布来稳定扩散后验采样，其中似然函数仅在噪声相关的频率范围内保证测量一致性。结合了扩散预测器、带限似然引导和多分辨率一致策略。", "result": "该方法在超分辨、插补和去模糊任务上达到最先进的性能，并且在运动去模糊PSNR方面提高了高达5分贝。", "conclusion": "通过噪声频带继续的方法可以有效解决扩散后验采样中的细节恢复问题，提高图像质量和鲁棒性。"}}
{"id": "2602.00175", "pdf": "https://arxiv.org/pdf/2602.00175", "abs": "https://arxiv.org/abs/2602.00175", "authors": ["Manyi Li", "Yufan Liu", "Lai Jiang", "Bing Li", "Yuming Li", "Weiming Hu"], "title": "The Illusion of Forgetting: Attack Unlearned Diffusion via Initial Latent Variable Optimization", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.CY"], "comment": "21 pages, 22 figures, 17 tables", "summary": "Although unlearning-based defenses claim to purge Not-Safe-For-Work (NSFW) concepts from diffusion models (DMs), we reveals that this \"forgetting\" is largely an illusion. Unlearning partially disrupts the mapping between linguistic symbols and the underlying knowledge, which remains intact as dormant memories. We find that the distributional discrepancy in the denoising process serves as a measurable indicator of how much of the mapping is retained, also reflecting the strength of unlearning. Inspired by this, we propose IVO (Initial Latent Variable Optimization), a concise and powerful attack framework that reactivates these dormant memories by reconstructing the broken mappings. Through Image Inversion}, Adversarial Optimization and Reused Attack, IVO optimizes initial latent variables to realign the noise distribution of unlearned models with their original unsafe states. Extensive experiments across 8 widely used unlearning techniques demonstrate that IVO achieves superior attack success rates and strong semantic consistency, exposing fundamental flaws in current defenses. The code is available at anonymous.4open.science/r/IVO/. Warning: This paper has unsafe images that may offend some readers.", "AI": {"tldr": "本文揭示了扩散模型中未学习防御机制的虚假性，并提出了一种通过优化初始潜在变量来重新激活这些记忆的方法，称为IVO。", "motivation": "尽管基于遗忘的防御声称能够从扩散模型中清除不安全的概念，但研究发现这种\"遗忘\"是表面现象。实际上，映射关系仍然作为潜藏的记忆存在，从而揭示了当前防御机制的不足。", "method": "作者提出了IVO（Initial Latent Variable Optimization）框架，通过图像反转、对抗优化和重用攻击来修复受损的映射，并重新激活这些潜伏的记忆。", "result": "实验结果表明，IVO在八种广泛使用的未学习技术上取得了卓越的成功率，并且具有强大的语义一致性，揭示了当前防御机制的根本缺陷。", "conclusion": "研究表明，现有的基于遗忘的扩散模型防御机制存在根本性问题。IVO通过重新激活潜伏的记忆来有效攻击这些模型，证明了这一点。"}}
{"id": "2602.00174", "pdf": "https://arxiv.org/pdf/2602.00174", "abs": "https://arxiv.org/abs/2602.00174", "authors": ["Jiajun Zhao", "Xuan Yang"], "title": "Intra-Class Subdivision for Pixel Contrastive Learning: Application to Semi-supervised Cardiac Image Segmentation", "categories": ["cs.CV"], "comment": "5 pages, 7 figures, accepted by ICASSP 2026", "summary": "We propose an intra-class subdivision pixel contrastive learning (SPCL) framework for cardiac image segmentation to address representation contamination at boundaries. The novel concept ``Unconcerned sample'' is proposed to distinguish pixel representations at the inner and boundary regions within the same class, facilitating a clearer characterization of intra-class variations. A novel boundary contrastive loss for boundary representations is proposed to enhance representation discrimination across boundaries. The advantages of the unconcerned sample and boundary contrastive loss are analyzed theoretically. Experimental results in public cardiac datasets demonstrate that SPCL significantly improves segmentation performance, outperforming existing methods with respect to segmentation quality and boundary precision. Our code is available at https://github.com/Jrstud203/SPCL.", "AI": {"tldr": "提出了一种针对心脏图像分割的像素对比学习框架（SPCL），通过区分同一类内区域和边界区域内的像素表示，以解决边界代表污染问题。", "motivation": "为了解决心脏图像分割中由于边界表示污染导致的问题，引入了新的概念“非关注样本”，并提出了边界的对比损失函数来增强跨边界的表示差异性。", "method": "通过将同一类内的像素分为内部和边界区域，并定义了一种新颖的边界对比损失，以提高分割效果。同时分析了非关注样本及边界对比损失的优势。", "result": "实验结果表明，SPCL框架在公共心脏图像数据集上显著提高了分割性能，特别是在分割质量和边缘精度方面优于现有的方法。", "conclusion": "该研究通过提出一种新的像素对比学习框架解决了心脏图像分割中的表示污染问题，并且通过理论分析和实验证明了其有效性。"}}
{"id": "2602.00173", "pdf": "https://arxiv.org/pdf/2602.00173", "abs": "https://arxiv.org/abs/2602.00173", "authors": ["Shuozhe Li", "Vaishnav Tadiparthi", "Kwonjoon Lee", "Nakul Agarwal", "Hossein Nourkhiz Mahjoub", "Ehsan Moradi Pari", "Lizhang Chen", "Amy Zhang", "Liu Leqi"], "title": "Learning Robust Reasoning through Guided Adversarial Self-Play", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning from verifiable rewards (RLVR) produces strong reasoning models, yet they can fail catastrophically when the conditioning context is fallible (e.g., corrupted chain-of-thought, misleading partial solutions, or mild input perturbations), since standard RLVR optimizes final-answer correctness only under clean conditioning. We introduce GASP (Guided Adversarial Self-Play), a robustification method that explicitly trains detect-and-repair capabilities using only outcome verification. Without human labels or external teachers, GASP forms an adversarial self-play game within a single model: a polluter learns to induce failure via locally coherent corruptions, while an agent learns to diagnose and recover under the same corrupted conditioning. To address the scarcity of successful recoveries early in training, we propose in-distribution repair guidance, an imitation term on self-generated repairs that increases recovery probability while preserving previously acquired capabilities. Across four open-weight models (1.5B--8B), GASP transforms strong-but-brittle reasoners into robust ones that withstand misleading and perturbed context while often improving clean accuracy. Further analysis shows that adversarial corruptions induce an effective curriculum, and in-distribution guidance enables rapid recovery learning with minimal representational drift.", "AI": {"tldr": "通过引入GASP（Guided Adversarial Self-Play），该论文提出了一种增强模型鲁棒性的方法，使其在面临误导和干扰时依然能够进行准确推理。", "motivation": "传统的RLVR（Reinforcement Learning from Verifiable Rewards）方法只能优化干净上下文下的最终答案正确性。因此，在存在故障的条件下（如思维链被破坏或输入轻微扰动），模型可能表现得非常脆弱，论文旨在解决这一问题。", "method": "GASP通过构建自我对抗游戏来增强模型鲁棒性，其中一个部分负责生成误导条件，另一部分则在这些条件下学习如何诊断和修复。为了增加早期训练阶段的成功恢复率，引入了同分布的修复指导机制。", "result": "实验结果表明，在四种不同规模的开放权重模型中，GASP能够将原本脆弱的推理者变为在误导和扰动下依然稳健且通常会提高清洁准确性的情况。", "conclusion": "通过使用对抗性腐败作为课程学习的一部分，并采用同分布修复指导来促进快速恢复学习，可以显著提升模型面对挑战条件时的鲁棒性。"}}
{"id": "2602.00170", "pdf": "https://arxiv.org/pdf/2602.00170", "abs": "https://arxiv.org/abs/2602.00170", "authors": ["Qiyao Liang", "Jinyeop Song", "Yizhou Liu", "Jeff Gore", "Ila Fiete", "Risto Miikkulainen", "Xin Qiu"], "title": "The Blessing of Dimensionality in LLM Fine-tuning: A Variance-Curvature Perspective", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 6 figures, plus appendices", "summary": "Weight-perturbation evolution strategies (ES) can fine-tune billion-parameter language models with surprisingly small populations (e.g., $N\\!\\approx\\!30$), contradicting classical zeroth-order curse-of-dimensionality intuition. We also observe a second seemingly separate phenomenon: under fixed hyperparameters, the stochastic fine-tuning reward often rises, peaks, and then degrades in both ES and GRPO. We argue that both effects reflect a shared geometric property of fine-tuning landscapes: they are low-dimensional in curvature. A small set of high-curvature dimensions dominates improvement, producing (i) heterogeneous time scales that yield rise-then-decay under fixed stochasticity, as captured by a minimal quadratic stochastic-ascent model, and (ii) degenerate improving updates, where many random perturbations share similar components along these directions. Using ES as a geometric probe on fine-tuning reward landscapes of GSM8K, ARC-C, and WinoGrande across Qwen2.5-Instruct models (0.5B--7B), we show that reward-improving perturbations remain empirically accessible with small populations across scales. Together, these results reconcile ES scalability with non-monotonic training dynamics and suggest that high-dimensional fine-tuning may admit a broader class of viable optimization methods than worst-case theory implies.", "AI": {"tldr": "研究通过分析大型语言模型微调过程中的权重扰动演化策略，揭示了高维度空间中的低曲率特性。", "motivation": "探索为何使用有限数量的样本进行微调仍能获得有效结果，并解释非单调训练动态现象背后的几何性质。", "method": "利用进化策略（ES）作为几何探针，在不同模型和数据集上研究奖励提升过程，通过理论分析与实验验证低曲率维度的存在及其影响。", "result": "发现微调过程中存在低维高曲率区域，这些区域对权重更新有显著影响；小规模样本足以捕捉到有益的扰动方向，解释了进化策略的有效性及非单调训练动态现象。", "conclusion": "高维度空间中的微调可能比最坏情况理论所暗示的更广泛地支持有效的优化方法。"}}
{"id": "2602.00169", "pdf": "https://arxiv.org/pdf/2602.00169", "abs": "https://arxiv.org/abs/2602.00169", "authors": ["Huan Zhang", "Yizhan Li", "Wenhao Huang", "Ziyu Hou", "Yu Song", "Xuye Liu", "Farshid Effaty", "Jinya Jiang", "Sifan Wu", "Qianggang Ding", "Izumi Takahara", "Leonard R. MacGillivray", "Teruyasu Mizoguchi", "Tianshu Yu", "Lizi Liao", "Yuyu Luo", "Yu Rong", "Jia Li", "Ying Diao", "Heng Ji", "Bang Liu"], "title": "Towards Agentic Intelligence for Materials Science", "categories": ["cond-mat.mtrl-sci", "cs.AI"], "comment": "82 pages", "summary": "The convergence of artificial intelligence and materials science presents a transformative opportunity, but achieving true acceleration in discovery requires moving beyond task-isolated, fine-tuned models toward agentic systems that plan, act, and learn across the full discovery loop. This survey advances a unique pipeline-centric view that spans from corpus curation and pretraining, through domain adaptation and instruction tuning, to goal-conditioned agents interfacing with simulation and experimental platforms. Unlike prior reviews, we treat the entire process as an end-to-end system to be optimized for tangible discovery outcomes rather than proxy benchmarks. This perspective allows us to trace how upstream design choices-such as data curation and training objectives-can be aligned with downstream experimental success through effective credit assignment. To bridge communities and establish a shared frame of reference, we first present an integrated lens that aligns terminology, evaluation, and workflow stages across AI and materials science. We then analyze the field through two focused lenses: From the AI perspective, the survey details LLM strengths in pattern recognition, predictive analytics, and natural language processing for literature mining, materials characterization, and property prediction; from the materials science perspective, it highlights applications in materials design, process optimization, and the acceleration of computational workflows via integration with external tools (e.g., DFT, robotic labs). Finally, we contrast passive, reactive approaches with agentic design, cataloging current contributions while motivating systems that pursue long-horizon goals with autonomy, memory, and tool use. This survey charts a practical roadmap towards autonomous, safety-aware LLM agents aimed at discovering novel and useful materials.", "AI": {"tldr": "本文提出了一种管道中心视角，探讨了如何通过集成AI和材料科学的方法来加速新材料的发现。", "motivation": "现有的AI模型在特定任务上效果良好，但缺乏整体规划、行动学习的能力。本研究旨在促进自主智能系统的开发，以实现真正的加速发现。", "method": "从术语统一对齐开始，然后详细介绍了LLM在模式识别和自然语言处理中的应用，以及如何通过有效的信用分配将上游设计选择与下游实验成功联系起来。", "result": "本文提出了一种集成框架，用于优化整个发现过程，并讨论了现有贡献和未来发展方向。", "conclusion": "本研究为开发自主、安全的LLM代理以发现新材料提供了实际路线图。"}}
{"id": "2602.00168", "pdf": "https://arxiv.org/pdf/2602.00168", "abs": "https://arxiv.org/abs/2602.00168", "authors": ["Ranjan Sapkota", "Manoj Karkee"], "title": "YOLOE-26: Integrating YOLO26 with YOLOE for Real-Time Open-Vocabulary Instance Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents YOLOE-26, a unified framework that integrates the deployment-optimized YOLO26(or YOLOv26) architecture with the open-vocabulary learning paradigm of YOLOE for real-time open-vocabulary instance segmentation. Building on the NMS-free, end-to-end design of YOLOv26, the proposed approach preserves the hallmark efficiency and determinism of the YOLO family while extending its capabilities beyond closed-set recognition. YOLOE-26 employs a convolutional backbone with PAN/FPN-style multi-scale feature aggregation, followed by end-to-end regression and instance segmentation heads. A key architectural contribution is the replacement of fixed class logits with an object embedding head, which formulates classification as similarity matching against prompt embeddings derived from text descriptions, visual examples, or a built-in vocabulary. To enable efficient open-vocabulary reasoning, the framework incorporates Re-Parameterizable Region-Text Alignment (RepRTA) for zero-overhead text prompting, a Semantic-Activated Visual Prompt Encoder (SAVPE) for example-guided segmentation, and Lazy Region Prompt Contrast for prompt-free inference. All prompting modalities operate within a unified object embedding space, allowing seamless switching between text-prompted, visual-prompted, and fully autonomous segmentation. Extensive experiments demonstrate consistent scaling behavior and favorable accuracy-efficiency trade-offs across model sizes in both prompted and prompt-free settings. The training strategy leverages large-scale detection and grounding datasets with multi-task optimization and remains fully compatible with the Ultralytics ecosystem for training, validation, and deployment. Overall, YOLOE-26 provides a practical and scalable solution for real-time open-vocabulary instance segmentation in dynamic, real-world environments.", "AI": {"tldr": "本文提出了YOLOE-26，一种集成了YOLOv26架构和YOLOE的开放词汇学习范式的统一框架，用于实时开放式实例分割。", "motivation": "现有的YOLO系列模型虽然具有高效性和确定性，但其能力受限于封闭集合识别。为了扩展其实用范围并实现实时开放式实例分割，本文提出了结合了YOLOv26和YOLOE的YOLOE-26框架。", "method": "该方法基于YOLOv26的NMS-free端到端设计，采用卷积骨干网与PAN/FPN样式的多尺度特征聚合，并通过回归头和实例分割头实现端到端预测。关键贡献是用对象嵌入头替代固定的类别对数，将分类问题转化为与文本描述或视觉示例的嵌入匹配。引入了Re-Parameterizable Region-Text Alignment (RepRTA)、Semantic-Activated Visual Prompt Encoder (SAVPE) 和 Lazy Region Prompt Contrast 等机制。", "result": "实验表明，在提示和无提示设置下，YOLOE-26在各种模型尺寸上均表现出一致的扩展行为和有利的准确性效率权衡。训练策略利用大规模检测和定位数据集进行多任务优化，并与Ultralytics生态系统完全兼容。", "conclusion": "总体而言，YOLOE-26为动态、现实世界环境中的实时开放式实例分割提供了实用且可扩展的解决方案。"}}
{"id": "2602.00166", "pdf": "https://arxiv.org/pdf/2602.00166", "abs": "https://arxiv.org/abs/2602.00166", "authors": ["Evan Chen", "Wenzhi Fang", "Shiqiang Wang", "Christopher Brinton"], "title": "Joint Continual Learning of Local Language Models and Cloud Offloading Decisions with Budget Constraints", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Locally deployed Small Language Models (SLMs) must continually support diverse tasks under strict memory and computation constraints, making selective reliance on cloud Large Language Models (LLMs) unavoidable. Regulating cloud assistance during continual learning is challenging, as naive reward-based reinforcement learning often yields unstable offloading behavior and exacerbates catastrophic forgetting as task distributions shift. We propose DA-GRPO, a dual-advantage extension of Group Relative Policy Optimization that incorporates cloud-usage constraints directly into advantage computation, avoiding fixed reward shaping and external routing models. This design enables the local model to jointly learn task competence and collaboration behavior, allowing cloud requests to emerge naturally during post-training while respecting a prescribed assistance budget. Experiments on mathematical reasoning and code generation benchmarks show that DA-GRPO improves post-switch accuracy, substantially reduces forgetting, and maintains stable cloud usage compared to prior collaborative and routing-based approaches.", "AI": {"tldr": "本文提出了DA-GRPO算法，用于在预算约束下联合学习本地语言模型和云卸载决策。", "motivation": "小规模语言模型部署于设备上时需不断支持多种任务，并且受限于内存和计算资源。直接依赖云端大模型会加剧灾难性遗忘问题，因此需要一种有效的方法来平衡本地与云端的协作。", "method": "提出了一种基于双重优势扩展的分组相对策略优化算法（DA-GRPO），将云使用的限制直接融入到优势计算中，并允许本地模型在学习任务能力的同时自然地生成云请求。", "result": "实验结果表明，相较于先前的方法，DA-GRPO显著减少了遗忘现象，在切换后准确率更高且保持稳定的云端使用量。", "conclusion": "该研究证明了DA-GRPO能够在预算约束下有效提升本地语言模型的性能和稳定性，并减少对云资源的依赖。"}}
{"id": "2602.00164", "pdf": "https://arxiv.org/pdf/2602.00164", "abs": "https://arxiv.org/abs/2602.00164", "authors": ["Khairul Alam", "Saikat Mondal", "Banani Roy"], "title": "Why Are AI Agent Involved Pull Requests (Fix-Related) Remain Unmerged? An Empirical Study", "categories": ["cs.SE", "cs.AI"], "comment": "5 pages", "summary": "Autonomous coding agents (e.g., OpenAI Codex, Devin, GitHub Copilot) are increasingly used to generate fix-related pull requests (PRs) in real world software repositories. However, their practical effectiveness depends on whether these contributions are accepted and merged by project maintainers. In this paper, we present an empirical study of AI agent involved fix related PRs, examining both their integration outcomes, latency, and the factors that hinder successful merging. We first analyze 8,106 fix related PRs authored by five widely used AI coding agents from the AIDEV POP dataset to quantify the proportions of PRs that are merged, closed without merging, or remain open. We then conduct a manual qualitative analysis of a statistically significant sample of 326 closed but unmerged PRs, spending approximately 100 person hours to construct a structured catalog of 12 failure reasons. Our results indicate that test case failures and prior resolution of the same issues by other PRs are the most common causes of non integration, whereas build or deployment failures are comparatively rare. Overall, our findings expose key limitations of current AI coding agents in real world settings and highlight directions for their further improvement and for more effective human AI collaboration in software maintenance.", "AI": {"tldr": "研究分析了由AI代理生成的修复相关拉取请求在现实世界软件仓库中的集成结果，探讨其成功率、延迟时间以及阻碍成功合并的因素。", "motivation": "探究广泛使用的AI编码代理（如OpenAI Codex, Devin, GitHub Copilot）产生的修复相关拉取请求为何未能被项目维护者接受和合并的原因，以提高这些工具在现实环境中的实际应用效果。", "method": "首先分析了AIDEV POP数据集中五个常见AI编码代理生成的8106个修复相关拉取请求，量化它们被合并、未合并关闭或仍然开放的比例。然后对326个手动分析样本进行结构化记录，总结出阻碍集成的12种主要原因。", "result": "结果显示测试用例失败和先前通过其他PR解决相同问题是导致AI代理生成的修复相关拉取请求未能成功整合的主要原因；相比之下，构建或部署失败则较为罕见。", "conclusion": "研究揭示了当前AI编码代理在现实世界中的关键限制，并指出了它们进一步改进的方向以及与人类更有效合作进行软件维护的方式。"}}
{"id": "2602.00163", "pdf": "https://arxiv.org/pdf/2602.00163", "abs": "https://arxiv.org/abs/2602.00163", "authors": ["Laura Cif", "Diane Demailly", "Gabriella A. Horvàth", "Juan Dario Ortigoza Escobar", "Nathalie Dorison", "Mayté Castro Jiménez", "Cécile A. Hubsch", "Thomas Wirth", "Gun-Marie Hariz", "Sophie Huby", "Morgan Dornadic", "Zohra Souei", "Muhammad Mushhood Ur Rehman", "Simone Hemm", "Mehdi Boulayme", "Eduardo M. Moraud", "Jocelyne Bloch", "Xavier Vasques"], "title": "Deep Learning Pose Estimation for Multi-Label Recognition of Combined Hyperkinetic Movement Disorders", "categories": ["cs.CV", "q-bio.NC"], "comment": null, "summary": "Hyperkinetic movement disorders (HMDs) such as dystonia, tremor, chorea, myoclonus, and tics are disabling motor manifestations across childhood and adulthood. Their fluctuating, intermittent, and frequently co-occurring expressions hinder clinical recognition and longitudinal monitoring, which remain largely subjective and vulnerable to inter-rater variability. Objective and scalable methods to distinguish overlapping HMD phenotypes from routine clinical videos are still lacking. Here, we developed a pose-based machine-learning framework that converts standard outpatient videos into anatomically meaningful keypoint time series and computes kinematic descriptors spanning statistical, temporal, spectral, and higher-order irregularity-complexity features.", "AI": {"tldr": "开发了一种基于姿态的机器学习框架，用于从标准门诊视频中提取和分析关键点时间序列数据，以区分重叠的HMD表型。", "motivation": "主观性和评分者间变异性的存在使得临床识别和长期监测复杂的运动障碍变得困难。迫切需要客观且可扩展的方法来区别这些病症的表现。", "method": "利用深度学习技术将标准门诊视频转换为具有统计，时间，频谱和更高阶复杂度特征的解剖学关键点序列，并以此为基础开发了一套机器学习框架进行分析。", "result": "通过这种方法能够更准确地区分不同的HMD表型。", "conclusion": "这项研究展示了基于姿态深度学习技术在多标签识别复合性运动障碍方面的潜力，为未来的临床应用提供了一个有力的工具。"}}
{"id": "2602.00162", "pdf": "https://arxiv.org/pdf/2602.00162", "abs": "https://arxiv.org/abs/2602.00162", "authors": ["Bingwei Zhang", "Chee Yap"], "title": "End Cover for Initial Value Problem: Complete Validated Algorithms with Complexity Analysis", "categories": ["cs.DS", "cs.CC"], "comment": null, "summary": "We consider the first-order autonomous ordinary differential equation \\[ \\mathbf{x}' = \\mathbf{f}(\\mathbf{x}), \\] where $\\mathbf{f} : \\mathbb{R}^n \\to \\mathbb{R}^n$ is locally Lipschitz. For a box $B_0 \\subseteq \\mathbb{R}^n$ and $h > 0$, we denote by $\\mathrm{IVP}_{\\mathbf{f}}(B_0,h)$ the set of solutions $\\mathbf{x} : [0,h] \\to \\mathbb{R}^n$ satisfying \\[ \\mathbf{x}'(t) = \\mathbf{f}(\\mathbf{x}(t)), \\qquad \\mathbf{x}(0) \\in B_0 . \\] We present a complete validated algorithm for the following \\emph{End Cover Problem}: given $(\\mathbf{f}, B_0, \\varepsilon, h)$, compute a finite set $\\mathcal{C}$ of boxes such that \\[ \\mathrm{End}_{\\mathbf{f}}(B_0,h) \\;\\subseteq\\; \\bigcup_{B \\in \\mathcal{C}} B \\;\\subseteq\\; \\mathrm{End}_{\\mathbf{f}}(B_0,h) \\oplus [-\\varepsilon,\\varepsilon]^n , \\] where \\[ \\mathrm{End}_{\\mathbf{f}}(B_0,h) = \\left\\{ \\mathbf{x}(h) : \\mathbf{x} \\in \\mathrm{IVP}_{\\mathbf{f}}(B_0,h) \\right\\}. \\] Moreover, we provide a complexity analysis of our algorithm and introduce a novel technique for computing the end cover $\\mathcal{C}$ based on covering the boundary of $\\mathrm{End}_{\\mathbf{f}}(B_0,h)$. Finally, we present experimental results demonstrating the practicality of our approach.", "AI": {"tldr": "论文提出了一个验证算法，用于解决初始值问题的终点覆盖问题。", "motivation": "为了确保在给定区域内所有可能解集的精确覆盖，并提供复杂性分析和实验结果以证明其有效性和实用性。", "method": "基于边界覆盖的方法来计算终态覆盖C集合。", "result": "算法能够在误差范围内准确地找到初始值问题的解终点集合的有效覆盖。", "conclusion": "论文提出的新方法具有较高的精确度与实用价值，通过实验验证了该方法的有效性。"}}
{"id": "2602.00161", "pdf": "https://arxiv.org/pdf/2602.00161", "abs": "https://arxiv.org/abs/2602.00161", "authors": ["David Jansen", "Roman Rausch", "David Montero", "Roman Orus"], "title": "Block removal for large language models through constrained binary optimization", "categories": ["cs.LG", "cs.AI", "cs.CL", "quant-ph"], "comment": "7 pages, 5 figures", "summary": "Compressing resource-intensive large language models by removing whole transformer blocks is a seemingly simple idea, but identifying which blocks to remove constitutes an exponentially difficult combinatorial problem. In this paper, we formulate block removal as a constrained binary optimization problem that can be mapped to a physical system (Ising model), whose energies are a strong proxy for downstream model performance. This formulation enables an efficient ranking of a large number of candidate block-removal configurations and yields many high-quality, non-trivial solutions beyond consecutive regions. We demonstrate that our approach outperforms state-of-the-art block-removal methods across several benchmarks, with performance gains persisting after short retraining, and reaching improvements of up to 6 points on the MMLU benchmark. Our method requires only forward and backward passes for a few active parameters, together with an (at least approximate) Ising solver, and can be readily applied to any architecture. We illustrate this generality on the recent NVIDIA-Nemotron-3-Nano-30B-A3B-FP8 model, which exhibits a highly inhomogeneous and challenging block structure.", "AI": {"tldr": "通过约束二元优化问题的形式化，研究将大语言模型中整个转换器块的移除作为一种压缩方法。", "motivation": "减少大型语言模型资源消耗的需求驱动了本研究。删除哪些块构成了一个组合难题，该论文提出了一个新的解决方案来解决这一挑战。", "method": "利用约束二元优化问题的形式化，将块移除映射到伊辛模型的能量上，并通过近似解法找到最佳的配置方案。", "result": "这种方法在多个基准测试中超过了现有的最先进技术，即使经过短期再训练后性能仍得到提升，在MMLU基准上的改进达到6分以上。", "conclusion": "提出的框架能够有效地压缩大型语言模型，保留高精度的同时减少了计算资源的需求。该方法可以应用于任何架构，并且具有广泛应用的潜力。"}}
{"id": "2602.00159", "pdf": "https://arxiv.org/pdf/2602.00159", "abs": "https://arxiv.org/abs/2602.00159", "authors": ["Aneeqa Mehrab", "Jan Willem Van Looy", "Pietro Demurtas", "Stefano Iotti", "Emil Malucelli", "Francesca Rossi", "Ferdinando Zanchetta", "Rita Fioresi"], "title": "Sheaf Neural Networks and biomedical applications", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "The purpose of this paper is to elucidate the theory and mathematical modelling behind the sheaf neural network (SNN) algorithm and then show how SNN can effectively answer to biomedical questions in a concrete case study and outperform the most popular graph neural networks (GNNs) as graph convolutional networks (GCNs), graph attention networks (GAT) and GraphSage.", "AI": {"tldr": "本文旨在阐明Sheaf神经网络（SNN）算法的理论和数学建模，并通过一个具体案例研究展示SNN在生物医学问题上的有效性，超越了常用的图神经网络（GNNs），如GCNs、GAT和GraphSage。", "motivation": "论文的主要动机是利用Sheaf理论来改进传统图神经网络的能力，以更好地处理复杂的数据结构和关系模式，并应用于解决具有挑战性的生物医学问题。", "method": "方法包括了Sheaf神经网络（SNN）的理论构建及数学建模，在具体案例中应用该算法并进行实验验证。", "result": "实验结果表明，相较于传统的图卷积网络、图注意力网络等图神经网络模型，Sheaf神经网络在处理生物医学问题时表现更优。", "conclusion": "研究结论是Sheaf神经网络作为一种新型的深度学习方法，在解决复杂的生物学和医学数据上的应用具有显著的优势。"}}
{"id": "2602.00158", "pdf": "https://arxiv.org/pdf/2602.00158", "abs": "https://arxiv.org/abs/2602.00158", "authors": ["Ziqi Gao", "Yaotian Zhu", "Qingcheng Zeng", "Xu Zhao", "Ziqing Wang", "Feng Ruan", "Kaize Ding"], "title": "RAPTOR: Ridge-Adaptive Logistic Probes", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Probing studies what information is encoded in a frozen LLM's layer representations by training a lightweight predictor on top of them. Beyond analysis, probes are often used operationally in probe-then-steer pipelines: a learned concept vector is extracted from a probe and injected via additive activation steering by adding it to a layer representation during the forward pass. The effectiveness of this pipeline hinges on estimating concept vectors that are accurate, directionally stable under ablation, and inexpensive to obtain. Motivated by these desiderata, we propose RAPTOR (Ridge-Adaptive Logistic Probe), a simple L2-regularized logistic probe whose validation-tuned ridge strength yields concept vectors from normalized weights. Across extensive experiments on instruction-tuned LLMs and human-written concept datasets, RAPTOR matches or exceeds strong baselines in accuracy while achieving competitive directional stability and substantially lower training cost; these quantitative results are supported by qualitative downstream steering demonstrations. Finally, using the Convex Gaussian Min-max Theorem (CGMT), we provide a mechanistic characterization of ridge logistic regression in an idealized Gaussian teacher-student model in the high-dimensional few-shot regime, explaining how penalty strength mediates probe accuracy and concept-vector stability and yielding structural predictions that qualitatively align with trends observed on real LLM embeddings.", "AI": {"tldr": "提出了一种基于L2正则化逻辑回归的探针算法RAPTOR，用于提高大型语言模型层表示的概念向量估计准确性、方向稳定性及训练效率。", "motivation": "旨在通过优化概念向量提取过程来提升探针-引导管道的操作性能，并降低成本。", "method": "提出了一种简单且可调节正则项的逻辑回归算法RAPTOR，该算法通过调整验证集上的正则化参数，从规范化权重中获取准确的概念向量。", "result": "在多种大规模语言模型和人类编写概念数据集上进行实验，证明了RAPTOR能够匹配或超越现有基准方法，在准确性、方向稳定性方面表现优异且训练成本更低。", "conclusion": "通过理论分析和实验证明了RAPTOR算法的有效性，并提供了在高维少量样本场景下的机制解释。"}}
{"id": "2602.00157", "pdf": "https://arxiv.org/pdf/2602.00157", "abs": "https://arxiv.org/abs/2602.00157", "authors": ["Fang Sheng", "Mohammad Noaeen", "Zahra Shakeri"], "title": "ProDCARL: Reinforcement Learning-Aligned Diffusion Models for De Novo Antimicrobial Peptide Design", "categories": ["q-bio.QM", "cs.AI", "q-bio.BM"], "comment": null, "summary": "Antimicrobial resistance threatens healthcare sustainability and motivates low-cost computational discovery of antimicrobial peptides (AMPs). De novo peptide generation must optimize antimicrobial activity and safety through low predicted toxicity, but likelihood-trained generators do not enforce these goals explicitly. We introduce ProDCARL, a reinforcement-learning alignment framework that couples a diffusion-based protein generator (EvoDiff OA-DM 38M) with sequence property predictors for AMP activity and peptide toxicity. We fine-tune the diffusion prior on AMP sequences to obtain a domain-aware generator. Top-k policy-gradient updates use classifier-derived rewards plus entropy regularization and early stopping to preserve diversity and reduce reward hacking. In silico experiments show ProDCARL increases the mean predicted AMP score from 0.081 after fine-tuning to 0.178. The joint high-quality hit rate reaches 6.3\\% with pAMP $>$0.7 and pTox $<$0.3. ProDCARL maintains high diversity, with $1-$mean pairwise identity equal to 0.929. Qualitative analyses with AlphaFold3 and ProtBERT embeddings suggest candidates show plausible AMP-like structural and semantic characteristics. ProDCARL serves as a candidate generator that narrows experimental search space, and experimental validation remains future work.", "AI": {"tldr": "ProDCARL利用强化学习与扩散模型相结合的方法，设计出具有高效抗菌活性和低毒性的新型抗菌肽。", "motivation": "由于抗生素抗性对医疗保健的威胁，需要开发低成本计算方法来发现新的抗菌肽（AMP）。传统生成器在优化抗菌活性和安全性方面存在不足。因此引入ProDCARL框架。", "method": "通过结合扩散模型生成蛋白质序列与预测AMP活动和肽毒性的分类器，采用基于强化学习的方法进行训练，并使用熵正则化以保持多样性减少奖励攻击。", "result": "实验结果显示，ProDCARL将平均预测的AMP分数从调优后的0.081提升至0.178。高质命中率达到了6.3%，并且具有高的序列多样性和可预测的AMP结构特征。", "conclusion": "ProDCARL框架作为候选生成器可以缩小实验搜索范围，有助于未来实验验证的工作开展。"}}
{"id": "2602.00154", "pdf": "https://arxiv.org/pdf/2602.00154", "abs": "https://arxiv.org/abs/2602.00154", "authors": ["Xiaogeng Liu", "Xinyan Wang", "Yechao Zhang", "Sanjay Kariyappa", "Chong Xiang", "Muhao Chen", "G. Edward Suh", "Chaowei Xiao"], "title": "ReasoningBomb: A Stealthy Denial-of-Service Attack by Inducing Pathologically Long Reasoning in Large Reasoning Models", "categories": ["cs.CR", "cs.AI"], "comment": "Pre-print. Code is available at https://github.com/SaFo-Lab/ReasoningBomb", "summary": "Large reasoning models (LRMs) extend large language models with explicit multi-step reasoning traces, but this capability introduces a new class of prompt-induced inference-time denial-of-service (PI-DoS) attacks that exploit the high computational cost of reasoning. We first formalize inference cost for LRMs and define PI-DoS, then prove that any practical PI-DoS attack should satisfy three properties: (1) a high amplification ratio, where each query induces a disproportionately long reasoning trace relative to its own length; (ii) stealthiness, in which prompts and responses remain on the natural language manifold and evade distribution shift detectors; and (iii) optimizability, in which the attack supports efficient optimization without being slowed by its own success. Under this framework, we present ReasoningBomb, a reinforcement-learning-based PI-DoS framework that is guided by a constant-time surrogate reward and trains a large reasoning-model attacker to generate short natural prompts that drive victim LRMs into pathologically long and often effectively non-terminating reasoning. Across seven open-source models (including LLMs and LRMs) and three commercial LRMs, ReasoningBomb induces 18,759 completion tokens on average and 19,263 reasoning tokens on average across reasoning models. It outperforms the the runner-up baseline by 35% in completion tokens and 38% in reasoning tokens, while inducing 6-7x more tokens than benign queries and achieving 286.7x input-to-output amplification ratio averaged across all samples. Additionally, our method achieves 99.8% bypass rate on input-based detection, 98.7% on output-based detection, and 98.4% against strict dual-stage joint detection.", "AI": {"tldr": "本文提出了一种新的针对大型推理模型的隐身拒绝服务攻击，通过诱导这些模型进入病态长推理过程。", "motivation": "大推理模型引入了新的prompt诱导推理时间拒绝服务(PI-DoS)攻击风险。作者旨在研究如何利用这种漏洞进行有效的攻击，并提出了一个名为ReasoningBomb的新框架。", "method": "使用强化学习引导的框架，通过一个常数时间替代奖励训练生成短自然提示来驱动受害大型推理模型进入病态长推理过程。", "result": "在七个开源模型和三个商用大推理模型上测试，平均诱导了18759个完成标记和19263个推理标记。相比第二名基线方法分别高出35%和38%，并且诱导的令牌数为良性查询的6-7倍。", "conclusion": "证明了ReasoningBomb的有效性和隐蔽性，能够有效逃避检测并造成严重的性能下降，强调了大推理模型的安全问题需要进一步关注。"}}
{"id": "2602.00153", "pdf": "https://arxiv.org/pdf/2602.00153", "abs": "https://arxiv.org/abs/2602.00153", "authors": ["Axel Duché", "Clément Chatelain", "Gilles Gasso"], "title": "See Without Decoding: Motion-Vector-Based Tracking in Compressed Video", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "We propose a lightweight compressed-domain tracking model that operates directly on video streams, without requiring full RGB video decoding. Using motion vectors and transform coefficients from compressed data, our deep model propagates object bounding boxes across frames, achieving a computational speed-up of order up to 3.7 with only a slight 4% mAP@0.5 drop vs RGB baseline on MOTS15/17/20 datasets. These results highlight codec-domain motion modeling efficiency for real-time analytics in large monitoring systems.", "AI": {"tldr": "提出了一种轻量级的压缩域跟踪模型，直接在视频流上运行而不必解码全RGB视频。", "motivation": "为了提高实时分析大型监控系统中视频的能力，通过利用压缩数据中的运动向量和转换系数来减少计算负担。", "method": "使用运动向量和变换系数从压缩数据传播对象边界框到不同帧，实现了一种轻量级的压缩域跟踪模型。", "result": "在MOTS15/17/20数据集上实现了高达3.7倍的速度提升，并且仅损失了4%的mAP@0.5。", "conclusion": "压缩域中的运动建模效率对于大型监控系统的实时分析具有重要意义。"}}
{"id": "2602.00152", "pdf": "https://arxiv.org/pdf/2602.00152", "abs": "https://arxiv.org/abs/2602.00152", "authors": ["Boyu Li", "Kuangji Zuo", "Lincong Li", "Yonghui Wu"], "title": "Real-Time Human Activity Recognition on Edge Microcontrollers: Dynamic Hierarchical Inference with Multi-Spectral Sensor Fusion", "categories": ["cs.CV", "cs.AI", "eess.SP"], "comment": "24 pages, 6 figures. The manusrcipt is under review at Measurement", "summary": "The demand for accurate on-device pattern recognition in edge applications is intensifying, yet existing approaches struggle to reconcile accuracy with computational constraints. To address this challenge, a resource-aware hierarchical network based on multi-spectral fusion and interpretable modules, namely the Hierarchical Parallel Pseudo-image Enhancement Fusion Network (HPPI-Net), is proposed for real-time, on-device Human Activity Recognition (HAR). Deployed on an ARM Cortex-M4 microcontroller for low-power real-time inference, HPPI-Net achieves 96.70% accuracy while utilizing only 22.3 KiB of RAM and 439.5 KiB of ROM after optimization. HPPI-Net employs a two-layer architecture. The first layer extracts preliminary features using Fast Fourier Transform (FFT) spectrograms, while the second layer selectively activates either a dedicated module for stationary activity recognition or a parallel LSTM-MobileNet network (PLMN) for dynamic states. PLMN fuses FFT, Wavelet, and Gabor spectrograms through three parallel LSTM encoders and refines the concatenated features using Efficient Channel Attention (ECA) and Depthwise Separable Convolution (DSC), thereby offering channel-level interpretability while substantially reducing multiply-accumulate operations. Compared with MobileNetV3, HPPI-Net improves accuracy by 1.22% and reduces RAM usage by 71.2% and ROM usage by 42.1%. These results demonstrate that HPPI-Net achieves a favorable accuracy-efficiency trade-off and provides explainable predictions, establishing a practical solution for wearable, industrial, and smart home HAR on memory-constrained edge platforms.", "AI": {"tldr": "提出了一种基于多光谱融合和可解释模块的分层网络HPPI-Net，用于在边缘微控制器上进行实时人体活动识别。", "motivation": "现有的方法难以平衡准确性和计算资源限制，在低功耗设备上的实时模式识别需求日益增加。", "method": "HPPI-Net采用两层架构：第一层使用快速傅里叶变换（FFT）光谱提取初步特征；第二层选择性激活静态活动识别专用模块或融合FFT、小波和Gabor光谱的并行LSTM-MobileNet网络，通过三个并行LSTM编码器融合，并利用有效通道注意力（ECA）和深度可分离卷积（DSC）优化。", "result": "HPPI-Net在ARM Cortex-M4微控制器上实现96.70%的准确率，仅使用22.3 KiB RAM和439.5 KiB ROM，并且与MobileNetV3相比提高了1.22%的准确性，减少了RAM使用量的71.2%，减少了ROM使用量的42.1%。", "conclusion": "HPPI-Net实现了良好的准确率与效率平衡，提供了可解释性预测，在低内存边缘平台上的可穿戴设备、工业和智能家居的人体活动识别中表现出实际应用价值。"}}
{"id": "2602.00151", "pdf": "https://arxiv.org/pdf/2602.00151", "abs": "https://arxiv.org/abs/2602.00151", "authors": ["Alexander Blezinger", "Wolfgang Nejdl", "Ming Tang"], "title": "Investigating the Impact of Histopathological Foundation Models on Regressive Prediction of Homologous Recombination Deficiency", "categories": ["cs.CV", "cs.AI"], "comment": "9 pages, 7 figures and 5 tables. Initialy submitted for IJCAI 2026", "summary": "Foundation models pretrained on large-scale histopathology data have found great success in various fields of computational pathology, but their impact on regressive biomarker prediction remains underexplored. In this work, we systematically evaluate histopathological foundation models for regression-based tasks, demonstrated through the prediction of homologous recombination deficiency (HRD) score - a critical biomarker for personalized cancer treatment. Within multiple instance learning frameworks, we extract patch-level features from whole slide images (WSI) using five state-of-the-art foundation models, and evaluate their impact compared to contrastive learning-based features. Models are trained to predict continuous HRD scores based on these extracted features across breast, endometrial, and lung cancer cohorts from two public medical data collections. Extensive experiments demonstrate that models trained on foundation model features consistently outperform the baseline in terms of predictive accuracy and generalization capabilities while exhibiting systematic differences among the foundation models. Additionally, we propose a distribution-based upsampling strategy to mitigate target imbalance in these datasets, significantly improving the recall and balanced accuracy for underrepresented but clinically important patient populations. Furthermore, we investigate the impact of different sampling strategies and instance bagsizes by ablation studies. Our results highlight the benefits of large-scale histopathological pretraining for more precise and transferable regressive biomarker prediction, showcasing its potential to advance AI-driven precision oncology.", "AI": {"tldr": "研究探讨了大规模预训练的组织病理学基础模型在回归任务中的应用，特别是在预测同源重组缺陷评分方面的能力。", "motivation": "探讨基于大型病理数据集预训练的基础模型是否能有效提升对连续生物标记物（如HRD分数）的预测准确性。", "method": "通过对比不同模型和策略的效果，利用五种最先进的基础模型从WSI中提取补丁级特征，并评估其预测能力；引入一种分布基线采样策略以解决目标不平衡问题。", "result": "实验结果显示，基于大型病理数据集预训练的基础模型在准确性和泛化能力方面优于基准方法。", "conclusion": "研究表明，在回归生物标记物的预测任务中使用大规模组织病理学预训练基础模型具有潜在优势，并可以促进AI驱动的精准肿瘤学的发展。"}}
{"id": "2602.00150", "pdf": "https://arxiv.org/pdf/2602.00150", "abs": "https://arxiv.org/abs/2602.00150", "authors": ["Xinyun Wang", "Min Zhang", "Sen Cui", "Zhikang Chen", "Bo Jiang", "Kun Kuang", "Mingbao Lin"], "title": "Reversible Diffusion Decoding for Diffusion Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Diffusion language models enable parallel token generation through block-wise decoding, but their irreversible commitments can lead to stagnation, where the reverse diffusion process fails to make further progress under a suboptimal context.We propose Reversible Diffusion Decoding (RDD), a decoding framework that introduces reversibility into block-wise diffusion generation. RDD detects stagnation as a state-dependent failure of the reverse process and enables efficient backtracking to earlier blocks without recomputation via cached model states. To avoid repeated failure trajectories, RDD applies confidence-guided re-masking to selectively reinitialize uncertain tokens while preserving reliable context.This reversible formulation allows decoding to recover from early commitment errors while maintaining the parallel efficiency of diffusion-based generation. Experiments show that RDD improves generation robustness and quality over baselines with minimal computational overhead.", "AI": {"tldr": "提出了可逆扩散解码（RDD）框架，以解决不可逆承诺导致的停滞问题，并提高生成的质量和鲁棒性。", "motivation": "扩散语言模型中的不可逆承诺可能导致停滞，影响反向过程的进步并降低生成质量。为了解决这个问题，作者提出了RDD框架来引入可逆性。", "method": "RDD通过检测停滞状态依赖失败，利用缓存的模型状态进行高效回溯，并采用信心指导的重新掩码策略避免重复错误轨迹。", "result": "实验表明，RDD在提高生成质量和鲁棒性的同时，仅带来很小的计算开销。", "conclusion": "RDD框架成功解决了扩散语言模型中的停滞问题，提高了生成质量并保持了高效的并行性能。"}}
{"id": "2602.00149", "pdf": "https://arxiv.org/pdf/2602.00149", "abs": "https://arxiv.org/abs/2602.00149", "authors": ["Shucong Li", "Xiaoluo Zhou", "Yuqian He", "Zhenyu Liu"], "title": "SDCM: Simulated Densifying and Compensatory Modeling Fusion for Radar-Vision 3-D Object Detection in Internet of Vehicles", "categories": ["cs.CV", "cs.RO", "eess.IV"], "comment": null, "summary": "3-D object detection based on 4-D radar-vision is an important part in Internet of Vehicles (IoV). However, there are two challenges which need to be faced. First, the 4-D radar point clouds are sparse, leading to poor 3-D representation. Second, vision datas exhibit representation degradation under low-light, long distance detection and dense occlusion scenes, which provides unreliable texture information during fusion stage. To address these issues, a framework named SDCM is proposed, which contains Simulated Densifying and Compensatory Modeling Fusion for radar-vision 3-D object detection in IoV. Firstly, considering point generation based on Gaussian simulation of key points obtained from 3-D Kernel Density Estimation (3-D KDE), and outline generation based on curvature simulation, Simulated Densifying (SimDen) module is designed to generate dense radar point clouds. Secondly, considering that radar data could provide more real time information than vision data, due to the all-weather property of 4-D radar. Radar Compensatory Mapping (RCM) module is designed to reduce the affects of vision datas' representation degradation. Thirdly, considering that feature tensor difference values contain the effective information of every modality, which could be extracted and modeled for heterogeneity reduction and modalities interaction, Mamba Modeling Interactive Fusion (MMIF) module is designed for reducing heterogeneous and achieving interactive Fusion. Experiment results on the VoD, TJ4DRadSet and Astyx HiRes 2019 dataset show that SDCM achieves best performance with lower parameter quantity and faster inference speed. Our code will be available.", "AI": {"tldr": "该论文提出了一种基于雷达视觉的4D点云稠密化和互补建模融合框架（SDCM），用于车联网中的3D对象检测。", "motivation": "现有雷达数据稀疏，无法提供良好的3D表示；同时，在低光、长距离检测和密集遮挡场景下，图像数据表现不佳。这些问题需要解决以实现更准确的3D对象检测。", "method": "该方法包括三个模块：Simulated Densifying（通过高斯模拟生成稠密雷达点云）、Radar Compensatory Mapping（利用雷达数据进行补偿）和Mamba Modeling Interactive Fusion（减少异质性并实现模态融合）。", "result": "实验结果表明，SDCM在VoD、TJ4DRadSet 和 Astyx HiRes 2019 数据集上实现了最佳性能，并且参数量少、推理速度快。", "conclusion": "该研究提出了一种新颖的框架（SDCM）用于改善基于雷达视觉的3D对象检测，在多个数据集中显示出卓越的表现。"}}
{"id": "2602.00148", "pdf": "https://arxiv.org/pdf/2602.00148", "abs": "https://arxiv.org/abs/2602.00148", "authors": ["Shiqian Li", "Ruihong Shen", "Junfeng Ni", "Chang Pan", "Chi Zhang", "Yixin Zhu"], "title": "Learning Physics-Grounded 4D Dynamics with Neural Gaussian Force Fields", "categories": ["cs.CV", "cs.AI"], "comment": "43 pages, ICLR 2026", "summary": "Predicting physical dynamics from raw visual data remains a major challenge in AI. While recent video generation models have achieved impressive visual quality, they still cannot consistently generate physically plausible videos due to a lack of modeling of physical laws. Recent approaches combining 3D Gaussian splatting and physics engines can produce physically plausible videos, but are hindered by high computational costs in both reconstruction and simulation, and often lack robustness in complex real-world scenarios. To address these issues, we introduce Neural Gaussian Force Field (NGFF), an end-to-end neural framework that integrates 3D Gaussian perception with physics-based dynamic modeling to generate interactive, physically realistic 4D videos from multi-view RGB inputs, achieving two orders of magnitude faster than prior Gaussian simulators. To support training, we also present GSCollision, a 4D Gaussian dataset featuring diverse materials, multi-object interactions, and complex scenes, totaling over 640k rendered physical videos (~4 TB). Evaluations on synthetic and real 3D scenarios show NGFF's strong generalization and robustness in physical reasoning, advancing video prediction towards physics-grounded world models.", "AI": {"tldr": "本文介绍了一种名为Neural Gaussian Force Field (NGFF)的端到端神经框架，该框架能够从多视角RGB输入生成交互式、物理上真实的4D视频。", "motivation": "现有的视频生成模型虽然在视觉质量方面取得了显著成果，但仍然无法一致地生成符合物理学定律的真实视频。为了解决这一问题，并提高复杂现实场景中的鲁棒性，本文提出了Neural Gaussian Force Field (NGFF)框架。", "method": "NGFF结合了3D高斯感知与基于物理的动态建模，采用一种新颖的方法来预测4D动力学，从而生成交互式、物理上真实的视频。此外，还开发了一种名为GSCollision的数据集，用于支持训练过程，该数据集中包含多样化的材料和复杂场景。", "result": "实验结果表明，NGFF在合成与真实3D场景中的泛化能力和物理推理鲁棒性都表现优越，并且速度比之前的高斯模拟器快两个数量级。", "conclusion": "NGFF通过将3D高斯感知与基于物理学的动态建模相结合，成功解决了现有视频生成模型无法一致生成符合物理学定律的真实视频的问题。同时，它在复杂场景中的鲁棒性得到了显著提升，并且训练速度更快。"}}
{"id": "2602.00145", "pdf": "https://arxiv.org/pdf/2602.00145", "abs": "https://arxiv.org/abs/2602.00145", "authors": ["Siva Teja Kakileti", "Geetha Manjunath"], "title": "DensiThAI, A Multi-View Deep Learning Framework for Breast Density Estimation using Infrared Images", "categories": ["cs.CV"], "comment": null, "summary": "Breast tissue density is a key biomarker of breast cancer risk and a major factor affecting mammographic sensitivity. However, density assessment currently relies almost exclusively on X-ray mammography, an ionizing imaging modality. This study investigates the feasibility of estimating breast density using artificial intelligence over infrared thermal images, offering a non-ionizing imaging approach. The underlying hypothesis is that fibroglandular and adipose tissues exhibit distinct thermophysical and physiological properties, leading to subtle but spatially coherent temperature variations on the breast surface. In this paper, we propose DensiThAI, a multi-view deep learning framework for breast density classification from thermal images. The framework was evaluated on a multi-center dataset of 3,500 women using mammography-derived density labels as reference. Using five standard thermal views, DensiThAI achieved a mean AUROC of 0.73 across 10 random splits, with statistically significant separation between density classes across all splits (p << 0.05). Consistent performance across age cohorts supports the potential of thermal imaging as a non-ionizing approach for breast density assessment with implications for improved patient experience and workflow optimization.", "AI": {"tldr": "提出了一种基于红外热图的多视图深度学习框架DensiThAI，用于乳腺密度估计。", "motivation": "当前乳腺密度评估主要依赖于X射线摄影，存在辐射风险。论文探讨了利用非电离成像方法——红外热影像进行乳腺密度评估的可能性。", "method": "提出了一个使用红外图像的多视角深度学习框架DensiThAI，该框架通过区分纤维腺体和脂肪组织在皮肤表面表现出的不同温度变化来实现乳腺密度分类。", "result": "在包含3500名女性的多中心数据集上进行测试时，DensiThAI达到了平均AUROC 0.73，证明了热图像在不同年龄组中的稳健性。", "conclusion": "结果表明，红外成像可能是一种非电离方法，可用于乳腺密度评估，并能改善患者的体验和工作流程优化。"}}
{"id": "2602.00144", "pdf": "https://arxiv.org/pdf/2602.00144", "abs": "https://arxiv.org/abs/2602.00144", "authors": ["Xuan Rao", "Mingming Ha", "Bo Zhao", "Derong Liu", "Cesare Alippi"], "title": "Scalable Analytic Classifiers with Associative Drift Compensation for Class-Incremental Learning of Vision Transformers", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Class-incremental learning (CIL) with Vision Transformers (ViTs) faces a major computational bottleneck during the classifier reconstruction phase, where most existing methods rely on costly iterative stochastic gradient descent (SGD). We observe that analytic Regularized Gaussian Discriminant Analysis (RGDA) provides a Bayes-optimal alternative with accuracy comparable to SGD-based classifiers; however, its quadratic inference complexity limits its use in large-scale CIL scenarios. To overcome this, we propose Low-Rank Factorized RGDA (LR-RGDA), a scalable classifier that combines RGDA's expressivity with the efficiency of linear classifiers. By exploiting the low-rank structure of the covariance via the Woodbury matrix identity, LR-RGDA decomposes the discriminant function into a global affine term refined by a low-rank quadratic perturbation, reducing the inference complexity from $\\mathcal{O}(Cd^2)$ to $\\mathcal{O}(d^2 + Crd^2)$, where $C$ is the class number, $d$ the feature dimension, and $r \\ll d$ the subspace rank. To mitigate representation drift caused by backbone updates, we further introduce Hopfield-based Distribution Compensator (HopDC), a training-free mechanism that uses modern continuous Hopfield Networks to recalibrate historical class statistics through associative memory dynamics on unlabeled anchors, accompanied by a theoretical bound on the estimation error. Extensive experiments on diverse CIL benchmarks demonstrate that our framework achieves state-of-the-art performance, providing a scalable solution for large-scale class-incremental learning with ViTs. Code: https://github.com/raoxuan98-hash/lr_rgda_hopdc.", "AI": {"tldr": "该论文提出了一种可扩展的分析分类器与关联漂移补偿机制，以解决视觉变换器中的类增量学习问题。", "motivation": "现有的方法在类别增量学习阶段面临计算瓶颈，特别是在重建分类器时依赖迭代随机梯度下降。为了克服这些问题并提高大规模场景下的性能，作者提出了新的解决方案。", "method": "作者提出了一种名为低秩因子化RGDA（LR-RGDA）的可扩展分类器，并引入了霍普菲尔德分布补偿器（HopDC），通过现代连续霍普菲尔德网络利用无标签锚点进行关联记忆动态重新校准历史类别统计。", "result": "广泛的实验结果表明，该框架在多种类增量学习基准测试中实现了最先进的性能，提供了大规模视觉变换器中的可扩展解决方案。", "conclusion": "论文提出的方法提供了一种新的途径来解决视觉变换器中类别增量学习的挑战性问题，并展示了其优越的性能和实用性。"}}
{"id": "2602.00141", "pdf": "https://arxiv.org/pdf/2602.00141", "abs": "https://arxiv.org/abs/2602.00141", "authors": ["Daeun Kim", "Jiwon Lee", "Wonjun Jeong", "Hyeongwoo Noh", "Giyeong Kim", "Jaeyoon Cho", "Geonhee Kwak", "Seunghwan Yang", "MinJung Kweon"], "title": "Comparison of Image Processing Models in Quark Gluon Jet Classification", "categories": ["physics.data-an", "cs.CV", "cs.LG", "hep-ex"], "comment": "17 pages, 10 Figures", "summary": "We present a comprehensive comparison of convolutional and transformer-based models for distinguishing quark and gluon jets using simulated jet images from Pythia 8. By encoding jet substructure into a three-channel representation of particle kinematics, we evaluate the performance of convolutional neural networks (CNNs), Vision Transformers (ViTs), and Swin Transformers (Swin-Tiny) under both supervised and self-supervised learning setups. Our results show that fine-tuning only the final two transformer blocks of the Swin-Tiny model achieves the best trade-off between efficiency and accuracy, reaching 81.4% accuracy and an AUC (area under the ROC curve) of 88.9%. Self-supervised pretraining with Momentum Contrast (MoCo) further enhances feature robustness and reduces the number of trainable parameters. These findings highlight the potential of hierarchical attention-based models for jet substructure studies and for domain transfer to real collision data.", "AI": {"tldr": "本文对比了卷积神经网络和Transformer模型在区分夸克胶子喷注中的表现。", "motivation": "为了提高粒子物理学中夸克和胶子喷注的分类精度，研究者比较了不同图像处理模型的效果。", "method": "通过编码模拟的Pythia8产生的粒子动量信息为三通道表示，对卷积神经网络、Vision Transformers以及Swin Transformer在监督学习与无监督预训练环境下的表现进行了评估。", "result": "结果显示，在微调最终两个Transformer层之后，Swintiny模型达到了最佳效率和准确性的平衡，精度达81.4%，AUC达到88.9%。使用动量对比（MoCo）进行无监督预训练进一步增强了特征稳健性和减少了可训练参数的数量。", "conclusion": "研究证实了基于层次注意力机制的模型在粒子喷注子结构分析以及从模拟数据向实际碰撞数据域转移中的巨大潜力。"}}
{"id": "2602.00136", "pdf": "https://arxiv.org/pdf/2602.00136", "abs": "https://arxiv.org/abs/2602.00136", "authors": ["Ti Ti Nguyen", "Thanh-Dung Le", "Vu Nguyen Ha", "Duc-Dung Tran", "Hung Nguyen-Kha", "Dinh-Hieu Tran", "Carlos L. Marcos-Rojas", "Juan C. Merlano-Duncan", "Symeon Chatzinotas"], "title": "Toward a Unified Semantic Loss Model for Deep JSCC-based Transmission of EO Imagery", "categories": ["eess.IV", "cs.CV"], "comment": "5 pages, 5 figures", "summary": "Modern Earth Observation (EO) systems increasingly rely on high-resolution imagery to support critical applications such as environmental monitoring, disaster response, and land-use analysis. Although these applications benefit from detailed visual data, the resulting data volumes impose significant challenges on satellite communication systems constrained by limited bandwidth, power, and dynamic link conditions. To address these limitations, this paper investigates Deep Joint Source-Channel Coding (DJSCC) as an effective source-channel paradigm for the transmission of EO imagery. We focus on two complementary aspects of semantic loss in DJSCC-based systems. First, a reconstruction-centric framework is evaluated by analyzing the semantic degradation of reconstructed images under varying compression ratios and channel signal-to-noise ratios (SNR). Second, a task-oriented framework is developed by integrating DJSCC with lightweight, application-specific models (e.g., EfficientViT), with performance measured using downstream task accuracy rather than pixel-level fidelity. Based on extensive empirical analysis, we propose a unified semantic loss framework that captures both reconstruction-centric and task-oriented performance within a single model. This framework characterizes the implicit relationship between JSCC compression, channel SNR, and semantic quality, offering actionable insights for the design of robust and efficient EO imagery transmission under resource-constrained satellite links.", "AI": {"tldr": "提出了一种统一的语义损失模型，用于基于深JSCC传输EO影像。", "motivation": "高分辨率地球观测系统面临带宽、功率和动态链路条件限制，因此研究了基于深度联合源信道编码（DJSCC）的有效方案以应对这些挑战。", "method": "通过评估重建为中心的框架以及集成DJSCC与轻量级应用特定模型的任务导向框架来研究语义损失。提出统一的语义损失框架，捕捉重构中心和任务导向性能。", "result": "基于广泛的实证分析，该框架描述了JSCC压缩、信道SNR和语义质量之间的隐含关系。", "conclusion": "所提出的模型为设计鲁棒且高效的EO影像传输提供了有价值的见解。"}}
{"id": "2602.00135", "pdf": "https://arxiv.org/pdf/2602.00135", "abs": "https://arxiv.org/abs/2602.00135", "authors": ["Pengcheng Zheng", "Chaoning Zhang", "Jiarong Mo", "GuoHui Li", "Jiaquan Zhang", "Jiahao Zhang", "Sihan Cao", "Sheng Zheng", "Caiyan Qin", "Guoqing Wang", "Yang Yang"], "title": "LLaVA-FA: Learning Fourier Approximation for Compressing Large Multimodal Models", "categories": ["cs.CV"], "comment": "Accepted by ICLR 2026", "summary": "Large multimodal models (LMMs) have achieved impressive performance on various vision-language tasks, but their substantial computational and memory costs hinder their practical deployment. Existing compression methods often decouple low-rank decomposition and quantization, leading to compounded reconstruction errors, especially in multimodal architectures with cross-modal redundancy. To address this issue, we propose LLaVA-FA, a novel efficient LMM that performs joint low-rank plus quantization approximation in the frequency domain. By leveraging the de-correlation and conjugate symmetry properties of Fourier transform, LLaVA-FA achieves more compact and accurate weight representations. Furthermore, we introduce PolarQuant, a polar-coordinate quantization method tailored for complex matrices, and an optional diagonal calibration (ODC) scheme that eliminates the need for large-scale calibration data. Extensive experimental results demonstrate that our proposed LLaVA-FA outperforms existing efficient multimodal models across multiple benchmarks while maintaining minimal activated parameters and low computational costs, validating its effectiveness as a powerful solution for compressing LMMs.", "AI": {"tldr": "提出了一种新的高效压缩大型多模态模型的方法LLaVA-FA。", "motivation": "现有压缩方法在处理具有跨模式冗余的多模态架构时，由于解耦低秩分解和量化导致重建误差增大。为此提出了LLaVA-FA以解决这个问题。", "method": "利用傅里叶变换的去相关和共轭对称性，在频域中进行联合低秩加量化的近似，并引入极坐标量化方法PolarQuant及可选的对角校准方案ODC。", "result": "实验结果表明，所提出的LLaVA-FA在多个基准测试上优于现有的高效多模态模型，同时保持了最小激活参数和计算成本低的特点。", "conclusion": "证明了LLaVA-FA是压缩大型多模态模型的有效解决方案。"}}
{"id": "2602.00133", "pdf": "https://arxiv.org/pdf/2602.00133", "abs": "https://arxiv.org/abs/2602.00133", "authors": ["Avi Arora", "Ritesh Malpani"], "title": "PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets", "categories": ["q-fin.ST", "cs.AI"], "comment": "10 pages, 5 figures. Code available at https://github.com/oddpool/PredictionMarketBench", "summary": "Prediction markets offer a natural testbed for trading agents: contracts have binary payoffs, prices can be interpreted as probabilities, and realized performance depends critically on market microstructure, fees, and settlement risk. We introduce PredictionMarketBench, a SWE-bench-style benchmark for evaluating algorithmic and LLM-based trading agents on prediction markets via deterministic, event-driven replay of historical limit-order-book and trade data. PredictionMarketBench standardizes (i) episode construction from raw exchange streams (orderbooks, trades, lifecycle, settlement), (ii) an execution-realistic simulator with maker/taker semantics and fee modeling, and (iii) a tool-based agent interface that supports both classical strategies and tool-calling LLM agents with reproducible trajectories. We release four Kalshi-based episodes spanning cryptocurrency, weather, and sports. Baseline results show that naive trading agents can underperform due to transaction costs and settlement losses, while fee-aware algorithmic strategies remain competitive in volatile episodes.", "AI": {"tldr": "提出PredictionMarketBench框架，用于通过模拟历史数据回测预测市场中的交易代理。", "motivation": "预测市场为测试交易代理提供了自然环境。合约有二进制回报，价格可解释为概率，并且性能严重依赖于市场微观结构、费用和结算风险。为了标准化此过程并评估算法和LLM基础的交易代理，作者开发了PredictionMarketBench框架。", "method": "该框架通过从原始交易所流（订单簿、交易、生命周期、结算）构建标准集来模拟历史数据，使用具有做市商/执行者语义和费用建模的真实执行仿真器，并支持经典策略和工具调用LLM代理的工具化代理界面。", "result": "作者发布了四个基于Kalshi的数据集，涵盖加密货币、天气和体育领域。基准结果表明，由于交易成本和结算损失，天真型交易代理的表现可能较差；而具有费用意识的算法策略在波动性环境中仍保持竞争力。", "conclusion": "PredictionMarketBench提供了一个标准化平台用于评估预测市场中的交易代理表现，并展示了不同类型的代理性能差异及其对特定市场因素的敏感度。"}}
{"id": "2602.00132", "pdf": "https://arxiv.org/pdf/2602.00132", "abs": "https://arxiv.org/abs/2602.00132", "authors": ["Jiao Li", "Jian Lang", "Xikai Tang", "Wenzheng Shu", "Ting Zhong", "Qiang Gao", "Yong Wang", "Leiting Chen", "Fan Zhou"], "title": "Shedding the Facades, Connecting the Domains: Detecting Shifting Multimodal Hate Video with Test-Time Adaptation", "categories": ["cs.CV"], "comment": "Accepted by AAAI2026 main track", "summary": "Hate Video Detection (HVD) is crucial for online ecosystems. Existing methods assume identical distributions between training (source) and inference (target) data. However, hateful content often evolves into irregular and ambiguous forms to evade censorship, resulting in substantial semantic drift and rendering previously trained models ineffective. Test-Time Adaptation (TTA) offers a solution by adapting models during inference to narrow the cross-domain gap, while conventional TTA methods target mild distribution shifts and struggle with the severe semantic drift in HVD. To tackle these challenges, we propose SCANNER, the first TTA framework tailored for HVD. Motivated by the insight that, despite the evolving nature of hateful manifestations, their underlying cores remain largely invariant (i.e., targeting is still based on characteristics like gender, race, etc), we leverage these stable cores as a bridge to connect the source and target domains. Specifically, SCANNER initially reveals the stable cores from the ambiguous layout in evolving hateful content via a principled centroid-guided alignment mechanism. To alleviate the impact of outlier-like samples that are weakly correlated with centroids during the alignment process, SCANNER enhances the prior by incorporating a sample-level adaptive centroid alignment strategy, promoting more stable adaptation. Furthermore, to mitigate semantic collapse from overly uniform outputs within clusters, SCANNER introduces an intra-cluster diversity regularization that encourages the cluster-wise semantic richness. Experiments show that SCANNER outperforms all baselines, with an average gain of 4.69% in Macro-F1 over the best.", "AI": {"tldr": "本文提出了一种针对仇恨视频检测的测试时间适应框架SCANNER，以解决因内容演变导致的传统模型失效的问题。", "motivation": "现有方法假设训练集和推理集中数据分布相同，但仇恨内容会演化成模糊形式来逃避审查，造成严重语义漂移，使得传统模型效果不佳。因此需要一种能够在线调整的测试时间适应框架来解决这一问题。", "method": "SCANNER通过一个基于原理的中心引导对齐机制揭示出演变中的仇恨内容中稳定的核心，并引入样本级自适应中心对齐策略以增强先前方法，同时加入簇内多样性正则化处理以防止过于均匀的输出。", "result": "实验表明，SCANNER在Macro-F1得分上平均超越所有基线模型4.69%。", "conclusion": "SCANNER是一种专为仇恨视频检测设计的有效测试时间适应框架。"}}
{"id": "2602.00131", "pdf": "https://arxiv.org/pdf/2602.00131", "abs": "https://arxiv.org/abs/2602.00131", "authors": ["Fraser Robinson", "Souren Pashangpour", "Matthew Lisondra", "Goldie Nejat"], "title": "PovNet+: A Deep Learning Architecture for Socially Assistive Robots to Learn and Assist with Multiple Activities of Daily Living", "categories": ["cs.CV", "cs.RO"], "comment": "Submitted to Advanced Robotics (Taylor & Francis)", "summary": "A significant barrier to the long-term deployment of autonomous socially assistive robots is their inability to both perceive and assist with multiple activities of daily living (ADLs). In this paper, we present the first multimodal deep learning architecture, POVNet+, for multi-activity recognition for socially assistive robots to proactively initiate assistive behaviors. Our novel architecture introduces the use of both ADL and motion embedding spaces to uniquely distinguish between a known ADL being performed, a new unseen ADL, or a known ADL being performed atypically in order to assist people in real scenarios. Furthermore, we apply a novel user state estimation method to the motion embedding space to recognize new ADLs while monitoring user performance. This ADL perception information is used to proactively initiate robot assistive interactions. Comparison experiments with state-of-the-art human activity recognition methods show our POVNet+ method has higher ADL classification accuracy. Human-robot interaction experiments in a cluttered living environment with multiple users and the socially assistive robot Leia using POVNet+ demonstrate the ability of our multi-modal ADL architecture in successfully identifying different seen and unseen ADLs, and ADLs being performed atypically, while initiating appropriate assistive human-robot interactions.", "AI": {"tldr": "提出了一种用于多活动识别的多模态深度学习架构POVNet+，以帮助自主社交辅助机器人主动发起协助行为。", "motivation": "解决自主社交辅助机器人无法感知和协助多种日常生活活动的问题，以便长期部署这些机器人。", "method": "引入了ADL和运动嵌入空间来区分已知、未知或异常的日常活动，并通过用户状态估计方法识别新活动的同时监控用户的性能表现。", "result": "POVNet+在多活动分类准确率上超过了现有技术；实验证明该架构能成功识别多种已见与未见活动及其异常执行情况并主动发起适当的协助互动。", "conclusion": "提出的POVNet+架构能够有效地支持社交辅助机器人感知和协助日常生活活动，从而提高了这些机器人的实用性。"}}
{"id": "2602.00126", "pdf": "https://arxiv.org/pdf/2602.00126", "abs": "https://arxiv.org/abs/2602.00126", "authors": ["Dmytro Filatov", "Valentyn Fedorov", "Vira Filatova", "Andrii Zelenchuk"], "title": "D3R-Net: Dual-Domain Denoising Reconstruction Network for Robust Industrial Anomaly Detection", "categories": ["cs.CV", "eess.IV"], "comment": "9 pages", "summary": "Unsupervised anomaly detection (UAD) is a key ingredient of automated visual inspection in modern manufacturing. The reconstruction-based methods appeal because they have basic architectural design and they process data quickly but they produce oversmoothed results for high-frequency details. As a result, subtle defects are partially reconstructed rather than highlighted, which limits segmentation accuracy. We build on this line of work and introduce D3R-Net, a Dual-Domain Denoising Reconstruction framework that couples a self-supervised 'healing' task with frequency-aware regularization. During training, the network receives synthetically corrupted normal images and is asked to reconstruct the clean targets, which prevents trivial identity mapping and pushes the model to learn the manifold of defect-free textures. In addition to the spatial mean squared error, we employ a Fast Fourier Transform (FFT) magnitude loss that encourages consistency in the frequency domain. The implementation also allows an optional structural similarity (SSIM) term, which we study in an ablation. On the MVTec AD Hazelnut benchmark, D3R-Net with the FFT loss improves localization consistency over a spatial-only baseline: PRO AUC increases from 0.603 to 0.687, while image-level ROC AUC remains robust. Evaluated across fifteen MVTec categories, the FFT variant raises the average pixel ROC AUC from 0.733 to 0.751 and PRO AUC from 0.417 to 0.468 compared to the MSE-only baseline, at roughly 20 FPS on a single GPU. The network is trained from scratch and uses a lightweight convolutional autoencoder backbone, providing a practical alternative to heavy pre-trained feature embedding methods.", "AI": {"tldr": "D3R-Net是一种双域去噪重建框架，旨在解决工业异常检测中的高频率细节过平滑问题。", "motivation": "传统的基于重构的方法在处理数据时会产生高频率细节的过度光滑化，从而影响缺陷分割精度。为此，作者提出了一个结合自监督‘治愈’任务和频率感知正则化的双域去噪重建框架。", "method": "D3R-Net通过接收合成受损的正常图像并在训练过程中重构干净的目标来防止简单的恒等映射，并促使模型学习无缺陷纹理流形。除了空间均方误差，还采用了快速傅里叶变换（FFT）幅度损失以鼓励频域一致性。", "result": "在MVTec AD Hazelnut基准测试中，D3R-Net的FFT变体提高了像素级ROC AUC从0.733到0.751以及PRO AUC从0.417到0.468。整体性能优于空间损失基线。", "conclusion": "D3R-Net提供了一种轻量级且实用的异常检测方法，适用于工业视觉检查任务，并在多个数据集上表现出色。"}}
{"id": "2602.00125", "pdf": "https://arxiv.org/pdf/2602.00125", "abs": "https://arxiv.org/abs/2602.00125", "authors": ["Soumyadip Sarkar"], "title": "MiniTensor: A Lightweight, High-Performance Tensor Operations Library", "categories": ["cs.LG", "cs.AI", "cs.MS"], "comment": null, "summary": "We present MiniTensor, an open source tensor operations library that focuses on minimalism, correctness, and performance. MiniTensor exposes a familiar PyTorch-like Python API while it executes performance critical code in a Rust engine. The core supports dense $n$ dimensional tensors, broadcasting, reductions, matrix multiplication, reverse mode automatic differentiation, a compact set of neural network layers, and standard optimizers. In this paper, we describe the design of MiniTensor's architecture, including its efficient memory management, dynamic computation graph for gradients, and integration with Python via PyO3. We also compare the install footprint with PyTorch and TensorFlow to demonstrate that MiniTensor achieves a package size of only a few megabytes, several orders of magnitude smaller than mainstream frameworks, while preserving the essentials needed for research and development on CPUs. The repository can be found at https://github.com/neuralsorcerer/minitensor", "AI": {"tldr": "MiniTensor是一个轻量级、高性能的张量操作库，支持稠密多维张量等核心功能，并提供Python接口。", "motivation": "为了开发一个既小巧又高效的深度学习框架，满足研究和开发需求。", "method": "设计了一个以Rust引擎为核心，通过PyO3与Python集成的张量操作库MiniTensor。包含内存管理、动态计算图等关键技术。", "result": "展示了MiniTensor相较于主流框架具有显著小得多的安装包体积，并保留了研究和开发所需的关键功能。", "conclusion": "成功实现了一个小巧且高效的张量操作库，满足深度学习领域中的研究与开发需求。"}}
{"id": "2602.00124", "pdf": "https://arxiv.org/pdf/2602.00124", "abs": "https://arxiv.org/abs/2602.00124", "authors": ["Divya Acharya", "Pierre Bernab'e", "Antoine Chevrot", "Helge Spieker", "Arnaud Gotlieb", "Bruno Legeard"], "title": "Context-Aware Autoencoders for Anomaly Detection in Maritime Surveillance", "categories": ["cs.CV"], "comment": null, "summary": "The detection of anomalies is crucial to ensuring the safety and security of maritime vessel traffic surveillance. Although autoencoders are popular for anomaly detection, their effectiveness in identifying collective and contextual anomalies is limited, especially in the maritime domain, where anomalies depend on vessel-specific contexts derived from self-reported AIS messages. To address these limitations, we propose a novel solution: the context-aware autoencoder. By integrating context-specific thresholds, our method improves detection accuracy and reduces computational cost. We compare four context-aware autoencoder variants and a conventional autoencoder using a case study focused on fishing status anomalies in maritime surveillance. Results demonstrate the significant impact of context on reconstruction loss and anomaly detection. The context-aware autoencoder outperforms others in detecting anomalies in time series data. By incorporating context-specific thresholds and recognizing the importance of context in anomaly detection, our approach offers a promising solution to improve accuracy in maritime vessel traffic surveillance systems.", "AI": {"tldr": "提出了一种基于上下文感知自编码器的海上异常检测方法，提高了识别集体和上下文相关异常的能力。", "motivation": "现有自编码器在海上监控中对集体和上下文相关异常的检测效果有限，需改进以提高准确性并减少计算成本。", "method": "通过整合上下文特定阈值来优化自编码器，并比较了四种不同变体及其与传统方法的表现差异。", "result": "实验结果表明，所提模型在时间序列数据上的异常检测准确度更高，强调了上下文信息的重要性。", "conclusion": "该上下文感知自编码器提供了一种改进海上交通监控系统异常检测精度的有前景的方法。"}}
{"id": "2602.00123", "pdf": "https://arxiv.org/pdf/2602.00123", "abs": "https://arxiv.org/abs/2602.00123", "authors": ["Filip Nowicki", "Hubert Marciniak", "Jakub Łączkowski", "Krzysztof Jassem", "Tomasz Górecki", "Vimala Balakrishnan", "Desmond C. Ong", "Maciej Behnke"], "title": "Visual Affect Analysis: Predicting Emotions of Image Viewers with Vision-Language Models", "categories": ["cs.HC", "cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) show promise as tools for inferring affect from visual stimuli at scale; it is not yet clear how closely their outputs align with human affective ratings. We benchmarked nine VLMs, ranging from state-of-the-art proprietary models to open-source models, on three psycho-metrically validated affective image datasets: the International Affective Picture System, the Nencki Affective Picture System, and the Library of AI-Generated Affective Images. The models performed two tasks in the zero-shot setting: (i) top-emotion classification (selecting the strongest discrete emotion elicited by an image) and (ii) continuous prediction of human ratings on 1-7/9 Likert scales for discrete emotion categories and affective dimensions. We also evaluated the impact of rater-conditioned prompting on the LAI-GAI dataset using de-identified participant metadata. The results show good performance in discrete emotion classification, with accuracies typically ranging from 60% to 80% on six-emotion labels and from 60% to 75% on a more challenging 12-category task. The predictions of anger and surprise had the lowest accuracy in all datasets. For continuous rating prediction, models showed moderate to strong alignment with humans (r > 0.75) but also exhibited consistent biases, notably weaker performance on arousal, and a tendency to overestimate response strength. Rater-conditioned prompting resulted in only small, inconsistent changes in predictions. Overall, VLMs capture broad affective trends but lack the nuance found in validated psychological ratings, highlighting their potential and current limitations for affective computing and mental health-related applications.", "AI": {"tldr": "本文通过视觉语言模型在三个情感图像数据集上进行零样本设定的情感预测任务，评估这些模型的表现。", "motivation": "探索视觉语言模型是否能够准确地从视觉刺激中推断出人类的情绪反应，以用于大规模情感分析，并找出它们的局限性。", "method": "使用九种不同的视觉语言模型，在三个经过心理测量验证的情感图像数据集上进行零样本设定的任务：选择最强的情绪类别和预测连续的人类情绪评分。同时评估了参与者元数据条件下提示的效果。", "result": "在情感分类任务中，模型表现良好，准确率通常介于60%到80%之间；对于持续评分预测，模型与人类评级显示出适度至强的相关性（r>0.75），但也表现出一些偏差和局限性。", "conclusion": "视觉语言模型能够捕捉广泛的情感趋势，但在某些情感类别如愤怒和惊喜的分类以及情绪强度估计方面存在限制。这些发现指出了模型在情感计算和心理健康应用中的潜在价值及当前局限性。"}}
{"id": "2602.00122", "pdf": "https://arxiv.org/pdf/2602.00122", "abs": "https://arxiv.org/abs/2602.00122", "authors": ["Hongzhu Yi", "Yujia Yang", "Yuanxiang Wang", "Zhenyu Guan", "Jiahuan Chen", "Chenxi Bao", "Tiankun Yang", "Yixuan Yuan", "Tianyu Zong", "Xinming Wang", "Tao Yu", "Ruiwen Tao", "Haijin Liang", "Jin Ma", "Jinwen Luo", "Yeshani Xinyu Zuo", "Jungang Xu"], "title": "VDE Bench: Evaluating The Capability of Image Editing Models to Modify Visual Documents", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": null, "summary": "In recent years, multimodal image editing models have achieved substantial progress, enabling users to manipulate visual content through natural language in a flexible and interactive manner. Nevertheless, an important yet insufficiently explored research direction remains visual document image editing, which involves modifying textual content within images while faithfully preserving the original text style and background context. Existing approaches, including AnyText, GlyphControl, and TextCtrl, predominantly focus on English-language scenarios and documents with relatively sparse textual layouts, thereby failing to adequately address dense, structurally complex documents or non-Latin scripts such as Chinese. To bridge this gap, we propose \\textbf{V}isual \\textbf{D}oc \\textbf{E}dit Bench(VDE Bench), a rigorously human-annotated and evaluated benchmark specifically designed to assess image editing models on multilingual and complex visual document editing tasks. The benchmark comprises a high-quality dataset encompassing densely textual documents in both English and Chinese, including academic papers, posters, presentation slides, examination materials, and newspapers. Furthermore, we introduce a decoupled evaluation framework that systematically quantifies editing performance at the OCR parsing level, enabling fine-grained assessment of text modification accuracy. Based on this benchmark, we conduct a comprehensive evaluation of representative state-of-the-art image editing models. Manual verification demonstrates a strong consistency between human judgments and automated evaluation metrics. VDE Bench constitutes the first systematic benchmark for evaluating image editing models on multilingual and densely textual visual documents.", "AI": {"tldr": "构建了一个评估图像编辑模型在多语言和复杂文本视觉文档上的能力的基准VDE Bench。", "motivation": "现有方法主要针对英文场景和稀疏布局的文件，无法处理密集、结构复杂的非拉丁语系文本。因此，作者提出了一种新的评估框架来解决这些问题。", "method": "设计了一个包含中英文密集文本文档的数据集，并提出了一个解耦评估框架以量化OCR解析级别的编辑性能。", "result": "通过基准测试，对最先进的图像编辑模型进行了全面的评估，人工验证表明人类判断与自动评估指标之间具有强一致性。", "conclusion": "VDE Bench是第一个系统性地评估多语言和密集文本视觉文档上图像编辑模型能力的基准。"}}
{"id": "2602.00117", "pdf": "https://arxiv.org/pdf/2602.00117", "abs": "https://arxiv.org/abs/2602.00117", "authors": ["Lamia Lahouel", "Laurynas Lopata", "Simon Gruening", "Gabriele Meoni", "Gaetan Petit", "Sylvain Lobry"], "title": "IC-EO: Interpretable Code-based assistant for Earth Observation", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, 1 figure", "summary": "Despite recent advances in computer vision, Earth Observation (EO) analysis remains difficult to perform for the laymen, requiring expert knowledge and technical capabilities. Furthermore, many systems return black-box predictions that are difficult to audit or reproduce. Leveraging recent advances in tool LLMs, this study proposes a conversational, code-generating agent that transforms natural-language queries into executable, auditable Python workflows. The agent operates over a unified easily extendable API for classification, segmentation, detection (oriented bounding boxes), spectral indices, and geospatial operators. With our proposed framework, it is possible to control the results at three levels: (i) tool-level performance on public EO benchmarks; (ii) at the agent-level to understand the capacity to generate valid, hallucination-free code; and (iii) at the task-level on specific use cases. In this work, we select two use-cases of interest: land-composition mapping and post-wildfire damage assessment. The proposed agent outperforms general-purpose LLM/VLM baselines (GPT-4o, LLaVA), achieving 64.2% vs. 51.7% accuracy on land-composition and 50% vs. 0% on post-wildfire analysis, while producing results that are transparent and easy to interpret. By outputting verifiable code, the approach turns EO analysis into a transparent, reproducible process.", "AI": {"tldr": "提出了一种基于代码的地球观测助手IC-EO，它能够将自然语言查询转化为可执行且易于审计的Python工作流。", "motivation": "为了使非专业人员也能进行地球观测分析，并解决现有系统黑盒预测难以审查和重复的问题。", "method": "利用工具LLMs开发了一种对话式的代码生成代理，可以处理分类、分割、检测等任务，并在特定用例上进行了测试。", "result": "该方法在土地组成地图绘制和野火后损害评估中表现出色，分别达到64.2%和50%的准确率，优于基线模型。", "conclusion": "通过输出可验证代码，使地球观测分析过程变得透明且可重复。"}}
{"id": "2602.00115", "pdf": "https://arxiv.org/pdf/2602.00115", "abs": "https://arxiv.org/abs/2602.00115", "authors": ["David El-Chai Ben-Ezra", "Adar Tal", "Daniel Brisk"], "title": "Event Driven Clustering Algorithm", "categories": ["cs.CV", "cs.LG"], "comment": "~10 pages, 2 figures", "summary": "This paper introduces a novel asynchronous, event-driven algorithm for real-time detection of small event clusters in event camera data. Like other hierarchical agglomerative clustering algorithms, the algorithm detects the event clusters based on their tempo-spatial distance. However, the algorithm leverages the special asynchronous data structure of event camera, and by a sophisticated, efficient and simple decision-making, enjoys a linear complexity of $O(n)$ where $n$ is the events amount. In addition, the run-time of the algorithm is independent with the dimensions of the pixels array.", "AI": {"tldr": "介绍了一种新颖的异步事件驱动算法，用于实时检测事件相机数据中的小事件聚类。", "motivation": "为了更高效地处理事件相机生成的数据，并实现实时的小事件聚类检测。", "method": "利用事件相机的独特异步结构和高效的决策机制，在线性时间复杂度$O(n)$下实现事件聚类的实时检测，其中$n$表示事件的数量。", "result": "算法运行时间不受像素数组维度影响，并展示了在处理大规模事件数据时的良好性能表现。", "conclusion": "所提出的异步、事件驱动算法能够在保持低复杂度的同时有效解决小事件聚类问题。"}}
{"id": "2602.00114", "pdf": "https://arxiv.org/pdf/2602.00114", "abs": "https://arxiv.org/abs/2602.00114", "authors": ["Yunwei Bai", "Ying Kiat Tan", "Yao Shu", "Tsuhan Chen"], "title": "1S-DAug: One-Shot Data Augmentation for Robust Few-Shot Generalization", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Few-shot learning (FSL) challenges model generalization to novel classes based on just a few shots of labeled examples, a testbed where traditional test-time augmentations fail to be effective. We introduce 1S-DAug, a one-shot generative augmentation operator that synthesizes diverse yet faithful variants from just one example image at test time. 1S-DAug couples traditional geometric perturbations with controlled noise injection and a denoising diffusion process conditioned on the original image. The generated images are then encoded and aggregated, alongside the original image, into a combined representation for more robust FSL predictions. Integrated as a training-free model-agnostic plugin, 1S-DAug consistently improves FSL across standard benchmarks of 4 different datasets without any model parameter update, including achieving over 10% proportional accuracy improvement on the miniImagenet 5-way-1-shot benchmark. Codes will be released.", "AI": {"tldr": "提出了一种名为1S-DAug的一次性数据增强方法，用于提高少数样本学习中的泛化能力。", "motivation": "传统测试时的数据增广在少数样本学习中效果不佳。为了改进这一问题，本文提出了一个新的解决方案，通过利用单一的示例图像生成多样化的变体来增强模型对新类别的适应性。", "method": "1S-DAug结合了几何变形、可控噪声注入以及条件扩散去噪过程。生成的数据与原始数据一起编码并聚合，形成一个更强大的表示用于少数样本学习预测。", "result": "该方法在四个标准基准测试集上显著提高了少数样本学习的性能，特别是在miniImagenet上的5路1次样本基准测试中获得了超过10%的比例准确性提升。并且无需模型训练更新即可集成到任何模型中。", "conclusion": "通过提出1S-DAug这一数据增强技术，能够有效提高少数样本学习中的泛化能力，并且作为训练无关的插件可以显著改进各种模型的表现"}}
{"id": "2602.00113", "pdf": "https://arxiv.org/pdf/2602.00113", "abs": "https://arxiv.org/abs/2602.00113", "authors": ["S. Kalaycioglu", "C. Hong", "K. Zhai", "H. Xie", "J. N. Wong"], "title": "AI-Driven Three-Dimensional Reconstruction and Quantitative Analysis for Burn Injury Assessment", "categories": ["cs.CV"], "comment": "11 pages and 5 figures", "summary": "Accurate, reproducible burn assessment is critical for treatment planning, healing monitoring, and medico-legal documentation, yet conventional visual inspection and 2D photography are subjective and limited for longitudinal comparison. This paper presents an AI-enabled burn assessment and management platform that integrates multi-view photogrammetry, 3D surface reconstruction, and deep learning-based segmentation within a structured clinical workflow. Using standard multi-angle images from consumer-grade cameras, the system reconstructs patient-specific 3D burn surfaces and maps burn regions onto anatomy to compute objective metrics in real-world units, including surface area, TBSA, depth-related geometric proxies, and volumetric change. Successive reconstructions are spatially aligned to quantify healing progression over time, enabling objective tracking of wound contraction and depth reduction. The platform also supports structured patient intake, guided image capture, 3D analysis and visualization, treatment recommendations, and automated report generation. Simulation-based evaluation demonstrates stable reconstructions, consistent metric computation, and clinically plausible longitudinal trends, supporting a scalable, non-invasive approach to objective, geometry-aware burn assessment and decision support in acute and outpatient care.", "AI": {"tldr": "本文提出了一种基于AI的烧伤评估和管理系统，该系统通过多视角摄影测量、三维表面重建以及深度学习分割技术，实现患者特定的三维烧伤面重构及量化分析。", "motivation": "传统的视觉检查和二维摄影方法在主观性和长期比较方面存在局限性，为了提高治疗计划、愈合监测和法律文件编制的准确性与可重复性，本文开发了一种基于AI的评估平台。", "method": "该系统使用标准多角度图像从消费级相机中重建患者特异性的3D烧伤表面，并将烧伤区域映射到解剖结构上以计算客观指标。深度学习和多视角摄影测量技术用于实现3D重建及定量分析，同时支持患者信息录入、指导性影像采集以及自动报告生成。", "result": "仿真评估显示该系统的三维重构稳定，度量计算一致，并显示出与临床相符的长期趋势。", "conclusion": "本文开发了一种基于AI的非侵入式方法来实现客观且几何感知的烧伤评估和决策支持系统。"}}
{"id": "2602.00111", "pdf": "https://arxiv.org/pdf/2602.00111", "abs": "https://arxiv.org/abs/2602.00111", "authors": ["Haiyu Yang", "Heidi Lesscher", "Enhong Liu", "Miel Hostens"], "title": "From Manual Observation to Automated Monitoring: Space Allowance Effects on Play Behaviour in Group-Housed Dairy Calves", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Play behaviour serves as a positive welfare indicator in dairy calves, yet the influence of space allowance under commercial conditions remains poorly characterized, particularly at intermediate-to-high allowances (6-20 m2 per calf). This study investigated the relationship between space allowance and play behaviour in 60 group-housed dairy calves across 14 commercial farms in the Netherlands (space range: 2.66-17.98 m2 per calf), and developed an automated computer vision pipeline for scalable monitoring. Video observations were analyzed using a detailed ethogram, with play expressed as percentage of observation period (%OP). Statistical analysis employed linear mixed models with farm as a random effect. A computer vision pipeline was trained on manual annotations from 108 hours on 6 farms and validated on held-out test data. The computer vision classifier achieved 97.6% accuracy with 99.4% recall for active play detection. Calves spent on average 1.0% of OP playing reflecting around 10 minutes per 17-hour period. The space-play relationship was non-linear, with highest play levels at 8-10 m2 per calf (1.6% OP) and lowest at 6-8 m2 and 12-14 m2 (<0.6% OP). Space remained significant after controlling for age, health, and group size. In summary, these findings suggest that 8-10 m2 per calf represents a practical target balancing welfare benefits with economic feasibility, and demonstrate that automated monitoring can scale small annotation projects to continuous welfare assessment systems.", "AI": {"tldr": "研究探讨了空间分配对围栏饲养乳牛犊玩耍行为的影响，并开发了一种自动化计算机视觉流水线进行大规模监测。", "motivation": "在商业条件下，关于空间分配对乳牛犊玩耍行为的正面福利指标影响的研究较少。特别是对于中等至高空间允许（每头小牛6-20平方米）的情况。", "method": "研究使用详细的行为分类法分析了视频观察，并通过线性混合模型进行统计分析。计算机视觉流水线基于从6个农场108小时的手动注释训练而成，测试数据的准确率为97.6%，召回率为99.4%。", "result": "每头小牛平均花费约10分钟（总观察时间的1%）进行玩耍活动。空间与玩耍行为的关系是非线性的，在每头小牛8-10平方米的空间下，玩耍水平最高；而在每头小牛6-8平方米和12-14平方米的空间时，最低。", "conclusion": "这些发现表明，为了平衡福利利益和经济可行性，8-10平方米每头小牛是一个实际目标。同时证明了自动化监测可以将小型注释项目扩展为连续的福利评估系统。"}}
{"id": "2602.00110", "pdf": "https://arxiv.org/pdf/2602.00110", "abs": "https://arxiv.org/abs/2602.00110", "authors": ["Yu Li", "Guilherme N. DeSouza", "Praveen Rao", "Chi-Ren Shyu"], "title": "Observing Health Outcomes Using Remote Sensing Imagery and Geo-Context Guided Visual Transformer", "categories": ["cs.CV", "cs.LG"], "comment": "Submitted to IEEE Transactions on Geoscience and Remote Sensing", "summary": "Visual transformers have driven major progress in remote sensing image analysis, particularly in object detection and segmentation. Recent vision-language and multimodal models further extend these capabilities by incorporating auxiliary information, including captions, question and answer pairs, and metadata, which broadens applications beyond conventional computer vision tasks. However, these models are typically optimized for semantic alignment between visual and textual content rather than geospatial understanding, and therefore are not suited for representing or reasoning with structured geospatial layers. In this study, we propose a novel model that enhances remote sensing imagery processing with guidance from auxiliary geospatial information. Our approach introduces a geospatial embedding mechanism that transforms diverse geospatial data into embedding patches that are spatially aligned with image patches. To facilitate cross-modal interaction, we design a guided attention module that dynamically integrates multimodal information by computing attention weights based on correlations with auxiliary data, thereby directing the model toward the most relevant regions. In addition, the module assigns distinct roles to individual attention heads, allowing the model to capture complementary aspects of the guidance information and improving the interpretability of its predictions. Experimental results demonstrate that the proposed framework outperforms existing pretrained geospatial foundation models in predicting disease prevalence, highlighting its effectiveness in multimodal geospatial understanding.", "AI": {"tldr": "提出了一种结合地理空间信息的视觉变压器模型，用于改善遥感图像分析中的健康结果预测。", "motivation": "现有视觉和语言多模态模型在语义对齐上表现良好，但在地理理解方面存在不足。为此，研究提出了一个新方法来增强远程感知影像处理，并通过引入地理嵌入机制以及设计引导注意力模块以提高性能。", "method": "该方法包括地理嵌入机制将各种地理空间数据转换为与图像块空间对准的嵌入补丁；引导注意模块用于计算基于辅助数据相关性的注意权重，使模型聚焦于最相关的区域，并通过分配不同角色给每个注意力头来捕获指导信息的不同方面。", "result": "实验结果表明所提出的框架优于现有的预训练地理空间基础模型，在疾病流行率预测上表现更优。", "conclusion": "新方法展示了在多模态地理理解上的优越性，特别是在健康结果的预测中。"}}
{"id": "2602.00109", "pdf": "https://arxiv.org/pdf/2602.00109", "abs": "https://arxiv.org/abs/2602.00109", "authors": ["John J. Howard", "Richard O. Plesh", "Yevgeniy B. Sirotin", "Jerry L. Tipton", "Arun R. Vemury"], "title": "Robustness of Presentation Attack Detection in Remote Identity Validation Scenarios", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted to the IEEE/CVF WACV 2026 Workshop on Generative, Adversarial and Presentation Attacks in Biometrics (GAPBio). 8 pages, 6 figures, 4 tables", "summary": "Presentation attack detection (PAD) subsystems are an important part of effective and user-friendly remote identity validation (RIV) systems. However, ensuring robust performance across diverse environmental and procedural conditions remains a critical challenge. This paper investigates the impact of low-light conditions and automated image acquisition on the robustness of commercial PAD systems using a scenario test of RIV. Our results show that PAD systems experience a significant decline in performance when utilized in low-light or auto-capture scenarios, with a model-predicted increase in error rates by a factor of about four under low-light conditions and a doubling of those odds under auto-capture workflows. Specifically, only one of the tested systems was robust to these perturbations, maintaining a maximum bona fide presentation classification error rate below 3% across all scenarios. Our findings emphasize the importance of testing across diverse environments to ensure robust and reliable PAD performance in real-world applications.", "AI": {"tldr": "研究了在远程身份验证场景中，低光条件和自动图像获取对呈现攻击检测系统的性能影响。", "motivation": "确保呈现攻击检测系统在不同环境和程序条件下表现稳定是关键挑战。通过测试这些因素的影响来提高其鲁棒性。", "method": "使用RIV情景测试商用PAD系统，在低光和自动化捕获工作流程中评估PAD系统的性能。", "result": "PAD系统在低光或自动捕获场景下的性能显著下降，错误率增加约四倍（低光条件下）和两倍（自动捕获下），只有其中一个系统保持了低于3%的错误率。", "conclusion": "测试不同的环境对于确保PAD系统在实际应用中的鲁棒性和可靠性至关重要。"}}
{"id": "2602.00108", "pdf": "https://arxiv.org/pdf/2602.00108", "abs": "https://arxiv.org/abs/2602.00108", "authors": ["René Peinl", "Vincent Tischler", "Patrick Schröder", "Christian Groth"], "title": "SITUATE -- Synthetic Object Counting Dataset for VLM training", "categories": ["cs.CV", "cs.AI"], "comment": "accepted at 21st International Conference on Computer Vision Theory and Applications", "summary": "We present SITUATE, a novel dataset designed for training and evaluating Vision Language Models on counting tasks with spatial constraints. The dataset bridges the gap between simple 2D datasets like VLMCountBench and often ambiguous real-life datasets like TallyQA, which lack control over occlusions and spatial composition. Experiments show that our dataset helps to improve generalization for out-of-distribution images, since a finetune of Qwen VL 2.5 7B on SITUATE improves accuracy on the Pixmo count test data, but not vice versa. We cross validate this by comparing the model performance across established other counting benchmarks and against an equally sized fine-tuning set derived from Pixmo count.", "AI": {"tldr": "构建了一个用于训练和评估视觉语言模型计数任务的新数据集SITUATE。", "motivation": "旨在填补简单二维数据集如VLMCountBench与真实生活数据集中空间构成模糊不清之间的空白，提供对遮挡和空间组合有更强控制的数据集。", "method": "提出了一个新的计数任务合成数据集SITUATE，并通过实验验证了该数据集在提升模型对于分布外图像泛化性能上的有效性。", "result": "实验表明，在SITUATE上微调的Qwen VL 2.5 7B模型提高了Pixmo count测试数据的准确性，但反过来则不成立。同时与已有的其他计数基准进行了对比验证。", "conclusion": "通过引入控制遮挡和空间布局的新数据集SITUATE，有效地提升了视觉语言模型在图像计数任务上的泛化能力。"}}
{"id": "2602.00107", "pdf": "https://arxiv.org/pdf/2602.00107", "abs": "https://arxiv.org/abs/2602.00107", "authors": ["Yuan Gao", "Xinyu Guo", "Wenjing Xie", "Zifan Wang", "Hongwen Yu", "Gongyang Li", "Shugong Xu"], "title": "Efficient UAV trajectory prediction: A multi-modal deep diffusion framework", "categories": ["cs.CV", "cs.RO", "eess.IV"], "comment": "in Chinese language", "summary": "To meet the requirements for managing unauthorized UAVs in the low-altitude economy, a multi-modal UAV trajectory prediction method based on the fusion of LiDAR and millimeter-wave radar information is proposed. A deep fusion network for multi-modal UAV trajectory prediction, termed the Multi-Modal Deep Fusion Framework, is designed. The overall architecture consists of two modality-specific feature extraction networks and a bidirectional cross-attention fusion module, aiming to fully exploit the complementary information of LiDAR and radar point clouds in spatial geometric structure and dynamic reflection characteristics. In the feature extraction stage, the model employs independent but structurally identical feature encoders for LiDAR and radar. After feature extraction, the model enters the Bidirectional Cross-Attention Mechanism stage to achieve information complementarity and semantic alignment between the two modalities. To verify the effectiveness of the proposed model, the MMAUD dataset used in the CVPR 2024 UG2+ UAV Tracking and Pose-Estimation Challenge is adopted as the training and testing dataset. Experimental results show that the proposed multi-modal fusion model significantly improves trajectory prediction accuracy, achieving a 40% improvement compared to the baseline model. In addition, ablation experiments are conducted to demonstrate the effectiveness of different loss functions and post-processing strategies in improving model performance. The proposed model can effectively utilize multi-modal data and provides an efficient solution for unauthorized UAV trajectory prediction in the low-altitude economy.", "AI": {"tldr": "提出了一种基于LiDAR和毫米波雷达信息融合的多模态无人机轨迹预测方法。", "motivation": "为了满足低空经济中管理未经授权使用的无人机的需求，设计了一种能够利用激光雷达和毫米波雷达互补信息的多模态深度融合框架。", "method": "提出了一个多模态深层融合网络，由两个模式特定特征提取网络和双向交叉注意融合模块组成。在特征提取阶段，模型采用独立但结构相同的LiDAR和雷达特征编码器；然后通过双向跨注意力机制实现两种模式之间的信息互补与语义对齐。", "result": "实验结果表明，所提出的多模态融合模型显著提高了轨迹预测的准确性，比基线模型提升了40%。此外还进行了消融试验来验证不同损失函数和后处理策略的效果。", "conclusion": "该模型能够有效利用多模态数据，并为低空经济中未经授权无人机轨迹预测提供了高效解决方案。"}}
{"id": "2602.00105", "pdf": "https://arxiv.org/pdf/2602.00105", "abs": "https://arxiv.org/abs/2602.00105", "authors": ["Wing Chan", "Richard Allen"], "title": "HYPE-EDIT-1: Benchmark for Measuring Reliability in Frontier Image Editing Models", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages, 5 figures, for code and data, see https://github.com/sourceful-official/hype-edit-1-benchmark", "summary": "Public demos of image editing models are typically best-case samples; real workflows pay for retries and review time. We introduce HYPE-EDIT-1, a 100-task benchmark of reference-based marketing/design edits with binary pass/fail judging. For each task we generate 10 independent outputs to estimate per-attempt pass rate, pass@10, expected attempts under a retry cap, and an effective cost per successful edit that combines model price with human review time. We release 50 public tasks and maintain a 50-task held-out private split for server-side evaluation, plus a standardized JSON schema and tooling for VLM and human-based judging. Across the evaluated models, per-attempt pass rates span 34-83 percent and effective cost per success spans USD 0.66-1.42. Models that have low per-image pricing are more expensive when you consider the total effective cost of retries and human reviews.", "AI": {"tldr": "HYPE-EDIT-1 是一个用于评估前沿图像编辑模型可靠性的基准测试，包含100项任务。", "motivation": "现有的公开演示样本往往是最优情况示例，而实际工作流需要多次尝试和人工审查。因此，本文旨在提供一个标准化的基准来衡量模型的真实性能及其成本效率。", "method": "通过生成每个任务10个独立输出，并根据参考标准进行二元判定（通过或失败），评估各模型的实际表现和有效成本。", "result": "不同模型的每尝试通过率范围为34%-83%，而实际成功编辑的有效成本则在USD 0.66-1.42之间。低单次图像处理价格的模型可能由于重试次数增加，导致总体有效成本更高。", "conclusion": "HYPE-EDIT-1基准测试揭示了前沿图像编辑模型的实际性能和经济性，并强调考虑重试与人工审查的重要性，以全面评估模型的成本效率。"}}
{"id": "2602.00104", "pdf": "https://arxiv.org/pdf/2602.00104", "abs": "https://arxiv.org/abs/2602.00104", "authors": ["Zhuohong Chen", "Zhengxian Wu", "Zirui Liao", "Shenao Jiang", "Hangrui Xu", "Yang Chen", "Chaokui Su", "Xiaoyu Liu", "Haoqian Wang"], "title": "R3G: A Reasoning--Retrieval--Reranking Framework for Vision-Centric Answer Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-centric retrieval for VQA requires retrieving images to supply missing visual cues and integrating them into the reasoning process. However, selecting the right images and integrating them effectively into the model's reasoning remains challenging.To address this challenge, we propose R3G, a modular Reasoning-Retrieval-Reranking framework.It first produces a brief reasoning plan that specifies the required visual cues, then adopts a two-stage strategy, with coarse retrieval followed by fine-grained reranking, to select evidence images.On MRAG-Bench, R3G improves accuracy across six MLLM backbones and nine sub-scenarios, achieving state-of-the-art overall performance. Ablations show that sufficiency-aware reranking and reasoning steps are complementary, helping the model both choose the right images and use them well. We release code and data at https://github.com/czh24/R3G.", "AI": {"tldr": "提出了R3G框架，用于视觉为中心的问题回答任务，通过推理、检索和重排三个阶段提高图像选择和使用的效果。", "motivation": "在视觉问答中，选取正确的图像并将其有效集成到模型推理过程中是一个挑战。为了解决这个问题，作者设计了R3G框架以改进图像的选择与利用。", "method": "该方法包括生成简要的推理计划来指定所需的视觉线索、采用两阶段策略（粗略检索和细粒度重排）选择证据图像。", "result": "在MRAG-Bench数据集上，R3G对六种不同的多模态语言模型后端和九个子场景实现了性能提升，并取得了当前最佳的整体表现。", "conclusion": "通过实验表明，充足的意识重排序列与推理步骤相互补充，有助于选择正确的图像并有效使用它们。作者公开了代码和数据集以促进进一步的研究。"}}
{"id": "2602.00103", "pdf": "https://arxiv.org/pdf/2602.00103", "abs": "https://arxiv.org/abs/2602.00103", "authors": ["Mahule Roy", "Adib Bazgir", "Arthur da Silva Sousa Santos", "Yuwen Zhang"], "title": "Autonomous Multi-Agent AI for High-Throughput Polymer Informatics: From Property Prediction to Generative Design Across Synthetic and Bio-Polymers", "categories": ["cond-mat.soft", "cond-mat.mtrl-sci", "cs.AI"], "comment": null, "summary": "We present an integrated multiagent AI ecosystem for polymer discovery that unifies high-throughput materials workflows, artificial intelligence, and computational modeling within a single Polymer Research Lifecycle (PRL) pipeline. The system orchestrates specialized agents powered by state-of-the-art large language models (DeepSeek-V2 and DeepSeek-Coder) to retrieve and reason over scientific resources, invoke external tools, execute domain-specific code, and perform metacognitive self-assessment for robust end-to-end task execution. We demonstrate three practical capabilities: a high-fidelity polymer property prediction and generative design pipeline, a fully automated multimodal workflow for biopolymer structure characterization, and a metacognitive agent framework that can monitor performance and improve execution strategies over time. On a held-out test set of 1,251 polymers, our PolyGNN agent achieves strong predictive accuracy, reaching R2 = 0.89 for glass-transition temperature (Tg ), R2 = 0.82 for tensile strength, R2 = 0.75 for elongation, and R2 = 0.91 for density. The framework also provides uncertainty estimates via multiagent consensus and scales with linear complexity to at least 10,000 polymers, enabling high-throughput screening at low computational cost. For a representative workload, the system completes inference in 16.3 s using about 2 GB of memory and 0.1 GPU hours, at an estimated cost of about $0.08. On a dedicated Tg benchmark, our approach attains R2 = 0.78, outperforming strong baselines including single-LLM prediction (R2 = 0.67), group-contribution methods (R2 = 0.71), and ChemCrow (R2 = 0.66). We further demonstrate metacognitive control in a polystyrene case study, where the system not only produces domain-level scientific outputs but continually monitors and optimizes its own behavior through tactical, strategic, and meta-strategic self-assessment.", "AI": {"tldr": "提出了一种多智能体AI生态系统，用于聚合物发现。", "motivation": "为了统一高通量材料工作流程、人工智能和计算建模，并通过单一的聚合物研究生命周期（PRL）管道来提高任务执行效率。", "method": "利用最先进的大型语言模型（DeepSeek-V2 和 DeepSeek-Coder），系统指挥专门代理从科学资源中检索并推理，调用外部工具，执行特定领域的代码，并进行元认知自我评估以实现稳健的端到端任务执行。", "result": "聚合物性能预测和生成设计管道实现了0.89的R2值，生物聚合物结构特征自动化多模态工作流程取得了显著成果，框架还通过多个代理共识提供了不确定性估计，并且可扩展性强，可在低成本下进行高通量筛选。", "conclusion": "该系统展示了高效、准确的性能预测能力，同时还能不断监控和优化自身的行为。"}}
{"id": "2602.00102", "pdf": "https://arxiv.org/pdf/2602.00102", "abs": "https://arxiv.org/abs/2602.00102", "authors": ["Fnu Neha", "Deepak kumar Shukla"], "title": "Radiomics in Medical Imaging: Methods, Applications, and Challenges", "categories": ["eess.IV", "cs.AI", "cs.LG"], "comment": null, "summary": "Radiomics enables quantitative medical image analysis by converting imaging data into structured, high-dimensional feature representations for predictive modeling. Despite methodological developments and encouraging retrospective results, radiomics continue to face persistent challenges related to feature instability, limited reproducibility, validation bias, and restricted clinical translation. Existing reviews largely focus on application-specific outcomes or isolated pipeline components, with limited analysis of how interdependent design choices across acquisition, preprocessing, feature engineering, modeling, and evaluation collectively affect robustness and generalizability. This survey provides an end-to-end analysis of radiomics pipelines, examining how methodological decisions at each stage influence feature stability, model reliability, and translational validity. This paper reviews radiomic feature extraction, selection, and dimensionality reduction strategies; classical machine and deep learning-based modeling approaches; and ensemble and hybrid frameworks, with emphasis on validation protocols, data leakage prevention, and statistical reliability. Clinical applications are discussed with a focus on evaluation rigor rather than reported performance metrics. The survey identifies open challenges in standardization, domain shift, and clinical deployment, and outlines future directions such as hybrid radiomics-artificial intelligence models, multimodal fusion, federated learning, and standardized benchmarking.", "AI": {"tldr": "本文综述了放射组学管道的全流程，包括特征提取、选择和降维策略；基于传统机器学习和深度学习的建模方法；以及集成和混合框架，并强调了验证协议、数据泄漏预防和统计可靠性。", "motivation": "尽管在定量医学图像分析方面取得了进展，但放射组学仍然面临特征不稳定性、可重复性受限、验证偏倚和临床转化受限等问题。现有的综述大多集中在特定应用程序的结果或孤立的流程组件上，缺乏对各个阶段设计选择如何共同影响稳健性和泛化能力的深入分析。", "method": "本文全面评估了放射组学管道中的每个步骤：特征提取、模型训练以及验证过程，并讨论了数据泄漏预防和统计可靠性。同时探讨了临床应用中评价严谨性的重要性而不是性能指标本身。", "result": "该综述识别出了标准制定、领域偏移和临床部署方面的开放挑战，为未来的研究方向提出了建议，例如放射组学-人工智能混合模型、多模态融合、联邦学习以及标准化基准测试。", "conclusion": "文章指出了放射组学当前面临的障碍，并对未来的发展趋势进行了展望，强调了方法论选择对特征稳定性、模型可靠性及临床转换的影响。"}}
{"id": "2602.00100", "pdf": "https://arxiv.org/pdf/2602.00100", "abs": "https://arxiv.org/abs/2602.00100", "authors": ["Avinash Kadimisetty", "C. Oswald", "B. Sivalselvan"], "title": "Frequent Pattern Mining approach to Image Compression", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "The paper focuses on Image Compression, explaining efficient approaches based on Frequent Pattern Mining(FPM). The proposed compression mechanism is based on clustering similar pixels in the image and thus using cluster identifiers in image compression. Redundant data in the image is effectively handled by replacing the DCT phase of conventional JPEG through a mixture of k-means Clustering and Closed Frequent Sequence Mining. To optimize the cardinality of pattern(s) in encoding, efficient pruning techniques have been used through the refinement of Conventional Generalized Sequential Pattern Mining(GSP) algorithm. We have proposed a mechanism for finding the frequency of a sequence which will yield significant reduction in the code table size. The algorithm is tested by compressing benchmark datasets yielding an improvement of 45% in compression ratios, often outperforming the existing alternatives. PSNR and SSIM, which are the image quality metrics, have been tested which show a negligible loss in visual quality.", "AI": {"tldr": "基于频繁模式挖掘的图像压缩方法", "motivation": "提高图像压缩效率，减少冗余数据，优化编码中的模式数量", "method": "通过k-means聚类和封闭频繁序列挖掘替换JPEG标准中的DCT阶段，采用改进的GSP算法进行有效修剪以优化模式卡数，提出一种频率查找机制来显著减小码表大小", "result": "在压缩比率上提高了45%，图像质量指标PSNR和SSIM显示视觉质量几乎没有损失", "conclusion": "所提出的基于频繁模式挖掘的方法在保持高质量的同时实现了有效的图像压缩"}}
{"id": "2602.00098", "pdf": "https://arxiv.org/pdf/2602.00098", "abs": "https://arxiv.org/abs/2602.00098", "authors": ["Oliver Preuß", "Jeroen Rook", "Jakob Bossek", "Heike Trautmann"], "title": "MO-ELA: Rigorously Expanding Exploratory Landscape Features for Automated Algorithm Selection in Continuous Multi-Objective Optimisation", "categories": ["cs.NE"], "comment": null, "summary": "Automated Algorithm Selection (AAS) is a popular meta-algorithmic approach and has demonstrated to work well for single-objective optimisation in combination with exploratory landscape features (ELA), i.e., (numerical) descriptive features derived from sampling the black-box (continuous) optimisation problem. In contrast to the abundance of features that describe single-objective optimisation problems, only a few features have been proposed for multi-objective optimisation so far. Building upon recent work on exploratory landscape features for box-constrained continuous multi-objective optimization problems, we propose a novel and complementary set of additional features (MO-ELA). These features are based on a random sample of points considering both the decision and objective space. The features are divided into 5 feature groups depending on how they are being calculated: non-dominated-sorting, descriptive statistics, principal component analysis, graph structures and gradient information. An AAS study conducted on well-established multi-objective benchmarks demonstrates that the proposed features contribute to successfully distinguishing between algorithm performance and thus adequately capture problem hardness resulting in models that come very close to the virtual best solver. After feature selection, the newly proposed features are frequently among the top contributors, underscoring their value in algorithm selection and problem characterisation.", "AI": {"tldr": "该论文提出了用于连续多目标优化问题的新特征集（MO-ELA），并展示了这些特征在自动化算法选择中的应用价值。", "motivation": "尽管单目标优化问题的描述性特征种类繁多，但针对多目标优化问题提出的特征相对较少。因此，作者旨在通过提出新的探索性景观特征来填补这一空白，并改善自动化算法选择的效果。", "method": "基于连续多目标优化问题随机采样的点（考虑决策空间和目标空间），论文提出了一个新的且互补的特征集MO-ELA。这些特征被分为五个不同的组别，根据它们是如何计算出来的进行分类：非支配排序、描述统计学、主成分分析、图结构以及梯度信息。", "result": "通过在公认多目标基准上的自动化算法选择研究发现，所提出的特征有助于成功地区分不同算法的性能，并能够很好地捕获问题难度。经过特征筛选后，新提出的特征经常成为主要贡献者之一，进一步证明了它们在算法选择和问题表征中的价值。", "conclusion": "论文提出的MO-ELA特征集能够在多目标优化中有效区分不同的算法表现并捕捉到问题的难度，显示出其在自动化算法选择中的潜力。"}}
{"id": "2602.00096", "pdf": "https://arxiv.org/pdf/2602.00096", "abs": "https://arxiv.org/abs/2602.00096", "authors": ["Zhengqing Gao", "Ziwen Li", "Xin Wang", "Jiaxin Huang", "Zhenyang Ren", "Mingkai Shao", "Hanlue Zhang", "Tianyu Huang", "Yongkang Cheng", "Yandong Guo", "Runqi Lin", "Yuanyuan Wang", "Tongliang Liu", "Kun Zhang", "Mingming Gong"], "title": "Mirage2Matter: A Physically Grounded Gaussian World Model from Video", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The scalability of embodied intelligence is fundamentally constrained by the scarcity of real-world interaction data. While simulation platforms provide a promising alternative, existing approaches often suffer from a substantial visual and physical gap to real environments and rely on expensive sensors, precise robot calibration, or depth measurements, limiting their practicality at scale. We present Simulate Anything, a graphics-driven world modeling and simulation framework that enables efficient generation of high-fidelity embodied training data using only multi-view environment videos and off-the-shelf assets. Our approach reconstructs real-world environments into a photorealistic scene representation using 3D Gaussian Splatting (3DGS), seamlessly capturing fine-grained geometry and appearance from video. We then leverage generative models to recover a physically realistic representation and integrate it into a simulation environment via a precision calibration target, enabling accurate scale alignment between the reconstructed scene and the real world. Together, these components provide a unified, editable, and physically grounded world model. Vision Language Action (VLA) models trained on our simulated data achieve strong zero-shot performance on downstream tasks, matching or even surpassing results obtained with real-world data, highlighting the potential of reconstruction-driven world modeling for scalable and practical embodied intelligence training.", "AI": {"tldr": "本文提出了一个通过视频重建物理真实场景的框架Simulate Anything，该框架能够生成高保真的模拟训练数据。", "motivation": "现有的仿真平台受限于视觉和物理现实之间的差距以及昂贵传感器的需求，在大规模应用中实用性不足。因此，研究提出了一种新的方法来克服这些问题，以实现更广泛的应用。", "method": "使用3D高斯点云重建技术从多视角视频创建场景，并通过生成模型恢复出一个符合物理规则的世界模型，从而在模拟环境中进行准确的比例校准和数据生成。", "result": "训练的视觉语言动作(VLA)模型在下游任务中表现出强大的零样本性能，与基于真实世界数据的结果相当甚至更好。", "conclusion": "该研究展示了通过重建驱动的建模方法实现可扩展且实用的嵌入式智能训练的巨大潜力。"}}
{"id": "2602.00095", "pdf": "https://arxiv.org/pdf/2602.00095", "abs": "https://arxiv.org/abs/2602.00095", "authors": ["Weiyu Sun", "Liangliang Chen", "Yongnuo Cai", "Huiru Xie", "Yi Zeng", "Ying Zhang"], "title": "EDU-CIRCUIT-HW: Evaluating Multimodal Large Language Models on Real-World University-Level STEM Student Handwritten Solutions", "categories": ["cs.CV", "cs.AI", "cs.CY"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) hold significant promise for revolutionizing traditional education and reducing teachers' workload. However, accurately interpreting unconstrained STEM student handwritten solutions with intertwined mathematical formulas, diagrams, and textual reasoning poses a significant challenge due to the lack of authentic and domain-specific benchmarks. Additionally, current evaluation paradigms predominantly rely on the outcomes of downstream tasks (e.g., auto-grading), which often probe only a subset of the recognized content, thereby failing to capture the MLLMs' understanding of complex handwritten logic as a whole. To bridge this gap, we release EDU-CIRCUIT-HW, a dataset consisting of 1,300+ authentic student handwritten solutions from a university-level STEM course. Utilizing the expert-verified verbatim transcriptions and grading reports of student solutions, we simultaneously evaluate various MLLMs' upstream recognition fidelity and downstream auto-grading performance. Our evaluation uncovers an astonishing scale of latent failures within MLLM-recognized student handwritten content, highlighting the models' insufficient reliability for auto-grading and other understanding-oriented applications in high-stakes educational settings. In solution, we present a case study demonstrating that leveraging identified error patterns to preemptively detect and rectify recognition errors, with only minimal human intervention (approximately 4% of the total solutions), can significantly enhance the robustness of the deployed AI-enabled grading system on unseen student solutions.", "AI": {"tldr": "该论文提出了EDU-CIRCUIT-HW数据集，用于评估多模态大语言模型在理解和自动评分大学水平STEM课程学生手写解答方面的能力。", "motivation": "当前缺乏针对多模态大语言模型在教育领域特别是处理学生手写解答方面的有效评测基准。现有方法主要依赖下游任务的性能指标，不能全面反映这些模型理解复杂问题的能力。", "method": "论文创建了一个包含1300多个大学STEM课程学生的手写解决方案数据集，并利用专家验证过的转录文本和评分报告来评估不同多模态大语言模型在上游识别准确度和下游自动评分性能方面的表现。同时提出了通过发现的错误模式来预先检测并纠正识别错误的方法。", "result": "研究揭示了现有模型在处理学生手写解答方面存在大量未被注意的问题，证明了这些模型对教育应用场景中的理解任务不够可靠。", "conclusion": "论文表明，在仅有少量人工干预的情况下（大约4%的解决方案），利用发现的识别错误模式可以显著增强AI辅助评分系统的稳健性。"}}
{"id": "2602.00093", "pdf": "https://arxiv.org/pdf/2602.00093", "abs": "https://arxiv.org/abs/2602.00093", "authors": ["Anton Malinovskiy"], "title": "Counterfactual Invariant Envelopes for Financial UX: Safety-Lattice Feature-Flag Governance in Crypto-Enabled Streaming", "categories": ["cs.HC", "cs.CR"], "comment": null, "summary": "Feature flags are the primary mechanism for safely introducing financial capabilities in consumer applications. In crypto-enabled live streaming, however, naive rollouts can create non-obvious risk: users may be exposed to onramps without proper eligibility, external wallets without sufficient fraud controls, or advanced views that alter risk perception and behavior. This paper introduces a novel invention candidate, a Counterfactual Invariant Envelope governor that combines a safety lattice with causal measurement and a shadow cohort for risk estimation. We formalize rollout risk, define invariant constraints across feature combinations, and propose a controller that adapts exposure using leading abuse signals, compliance readiness, and revenue guardrails. We incorporate real-world adoption and fraud data for calibration, provide formulas for rollout safety, and include reproducible policy snippets. The results show that counterfactual, invariant-aware governance reduces risk spillover while preserving conversion and retention, offering a path to patentable governance logic for financial UX.", "AI": {"tldr": "提出了一种结合安全矩阵和因果测量的反事实不变性治理方法，以降低金融用户体验中因特征组合而产生的风险。", "motivation": "在加密货币支持的实时流媒体中，简单的功能部署可能导致用户暴露于不符合资格条件的功能或缺乏足够欺诈控制的风险场景下。", "method": "引入了一种结合安全矩阵和因果测量的安全性治理方法，使用领先滥用信号、合规准备度和收入护栏来调整曝光量，并利用实际采用和欺诈数据进行校准。", "result": "该结果表明反事实的不变性意识治理可减少风险溢出的同时保持转换率和留存率。", "conclusion": "这种治理逻辑为金融用户体验提供了一种减少风险的路径，可能具有专利价值。"}}
{"id": "2602.00092", "pdf": "https://arxiv.org/pdf/2602.00092", "abs": "https://arxiv.org/abs/2602.00092", "authors": ["Neha Kalibhat", "Zi Wang", "Prasoon Bajpai", "Drew Proud", "Wenjun Zeng", "Been Kim", "Mani Malek"], "title": "Interpreting and Controlling Model Behavior via Constitutions for Atomic Concept Edits", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": "ef:Twenty-Ninth Annual Conference on Artificial Intelligence and Statistics (AISTATS 2026)", "summary": "We introduce a black-box interpretability framework that learns a verifiable constitution: a natural language summary of how changes to a prompt affect a model's specific behavior, such as its alignment, correctness, or adherence to constraints. Our method leverages atomic concept edits (ACEs), which are targeted operations that add, remove, or replace an interpretable concept in the input prompt. By systematically applying ACEs and observing the resulting effects on model behavior across various tasks, our framework learns a causal mapping from edits to predictable outcomes. This learned constitution provides deep, generalizable insights into the model. Empirically, we validate our approach across diverse tasks, including mathematical reasoning and text-to-image alignment, for controlling and understanding model behavior. We found that for text-to-image generation, GPT-Image tends to focus on grammatical adherence, while Imagen 4 prioritizes atmospheric coherence. In mathematical reasoning, distractor variables confuse GPT-5 but leave Gemini 2.5 models and o4-mini largely unaffected. Moreover, our results show that the learned constitutions are highly effective for controlling model behavior, achieving an average of 1.86 times boost in success rate over methods that do not use constitutions.", "AI": {"tldr": "介绍了一种通过原子概念编辑来解释和控制模型行为的黑盒可解释性框架。", "motivation": "动机是提供一种方法，以自然语言总结输入提示的变化如何影响模型的行为，并实现对其行为的可控性和理解。", "method": "该方法利用了原子概念编辑（ACEs），这是一种针对输入提示进行的有目标操作。通过系统地应用ACE并观察其对不同任务中模型行为的影响，框架学习了一个从编辑到可预测结果的因果映射。", "result": "实验验证显示，在文本到图像生成上，GPT-Image侧重于语法遵守，而Imagen 4则注重氛围连贯性。在数学推理方面，干扰变量会让GPT-5混淆，但对Gemini 2.5模型和o4-mini影响不大。结果显示，所学的宪法对于控制模型行为非常有效。", "conclusion": "该方法提供了深入、普适性的见解，并且实验结果表明它能够显著提高模型成功控制率。"}}
{"id": "2602.00091", "pdf": "https://arxiv.org/pdf/2602.00091", "abs": "https://arxiv.org/abs/2602.00091", "authors": ["Kumaran Rajaram", "Patrick Nicolas Tinguely"], "title": "Generative Artificial Intelligence in Small and Medium Enterprises: Navigating its Promises and Challenges", "categories": ["cs.CY", "cs.AI"], "comment": "31 pages, 1 figure, 3 tables", "summary": "The latest technological developments in generative artificial intelligence (GAI) offer powerful capabilities to small and medium enterprises (SMEs), as they facilitate the democratization of both scalability and creativity. Even if they have little technical expertise or financial resources, SMEs can leverage this technology to streamline work processes and unleash innovation, thereby improving their product offerings and long-term competitiveness. This paper discusses how SMEs can navigate both the promises and challenges of GAI and offers a roadmap for deploying GAI. We introduce a sailing metaphor that reveals key strategic dimensions for GAI deployment: competency of employees, effective leadership and work values, organizational culture, collaboration and cooperation, and relationships with third parties. We offer practical recommendations that serve as a useful compass for successfully deploying GAI in SMEs.", "AI": {"tldr": "本文探讨了中小企业如何利用生成式人工智能（GAI）的能力，提出了部署GAI的路线图。", "motivation": "最新技术的发展为中小型企业提供了强大的工具来提高其竞争力和创新能力。", "method": "通过引入航海比喻揭示关键的战略维度，并提出实际建议。", "result": "提出了一套实用指南作为中小企业成功部署GAI的方向标。", "conclusion": "中小企业可以通过采用生成式人工智能提升自身的能力，但需要关注员工能力、领导力以及合作关系等方面。"}}
{"id": "2602.00088", "pdf": "https://arxiv.org/pdf/2602.00088", "abs": "https://arxiv.org/abs/2602.00088", "authors": ["Namkyung Yoon", "Hwangnam Kim"], "title": "From Numbers to Prompts: A Cognitive Symbolic Transition Mechanism for Lightweight Time-Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 5 figures. Submitted to ACM Transactions on Intelligent Systems and Technology", "summary": "Large language models have achieved remarkable success in time series prediction tasks, but their substantial computational and memory requirements limit deployment on lightweight platforms. In this paper, we propose the Symbolic Transition Mechanism (STM) a novel framework that bridges numeric time series data and language models through symbolic abstraction and prompt engineering. STM transforms continuous time series values into symbol tokens with quantization techniques based on human cognitive structures, and captures temporal dynamics through structured transformations of symbols, enabling fast engineering based predictions in which language models focus on critical parts of time series data. STM is a general purpose mechanisms that ensure the integrity of backbone language models, but they significantly improve their efficiency by inferring the dynamic and structured patterns inherent in time series data. We evaluated STM on various time series datasets, paired with four small language models (SLM) with limited computational environments. For all models, STM achieves error reductions of up to 69% in MAE and 90% in MSE compared to the default backbone SLM without STM. These results demonstrate the potential of STM as an efficient, adaptable layer for symbol-driven time series prediction using foundation models. The accuracy improvements were made at negligible resource costs, with maximum GPU memory of the base model increasing by approximately 0.06% and latency overhead increasing by only 0.64%.", "AI": {"tldr": "本文提出了一种符号转换机制（STM），将时间序列数据与语言模型结合，通过量化技术和提示工程提高预测效率。", "motivation": "大型语言模型在时间序列预测任务中表现出色，但其计算和内存需求限制了它们在轻量级平台上的部署。本文旨在解决这一问题，提出了符号转换机制（STM），以减少资源消耗并保持性能。", "method": "STM利用量化技术将连续的时间序列值转化为基于人类认知结构的符号令牌，并通过结构化变换捕捉时间动态，使语言模型专注于时间序列数据的关键部分。该方法适用于多种小规模语言模型。", "result": "在不同时间序列数据集上与四种小型语言模型（SLM）结合使用时，STM实现了最高69%和90%的MAE和MSE错误减少率，同时资源消耗几乎不变。", "conclusion": "符号转换机制（STM）展示了作为基于基础模型的时间序列预测的有效、适应性强的层的潜力。它在保持准确性的前提下大幅降低了计算成本。"}}
{"id": "2602.00087", "pdf": "https://arxiv.org/pdf/2602.00087", "abs": "https://arxiv.org/abs/2602.00087", "authors": ["Haolin Pan", "Lianghong Huang", "Jinyuan Dong", "Mingjie Xing", "Yanjun Wu"], "title": "ECCO: Evidence-Driven Causal Reasoning for Compiler Optimization", "categories": ["cs.LG", "cs.AI", "cs.PF", "cs.PL"], "comment": null, "summary": "Compiler auto-tuning faces a dichotomy between traditional black-box search methods, which lack semantic guidance, and recent Large Language Model (LLM) approaches, which often suffer from superficial pattern matching and causal opacity. In this paper, we introduce ECCO, a framework that bridges interpretable reasoning with combinatorial search. We first propose a reverse engineering methodology to construct a Chain-of-Thought dataset, explicitly mapping static code features to verifiable performance evidence. This enables the model to learn the causal logic governing optimization decisions rather than merely imitating sequences. Leveraging this interpretable prior, we design a collaborative inference mechanism where the LLM functions as a strategist, defining optimization intents that dynamically guide the mutation operations of a genetic algorithm. Experimental results on seven datasets demonstrate that ECCO significantly outperforms the LLVM opt -O3 baseline, achieving an average 24.44% reduction in cycles.", "AI": {"tldr": "ECCO是一种通过证据驱动的因果推理来优化编译器的方法，结合了可解释性逻辑与组合搜索。", "motivation": "当前的编译器自适应调优方法存在黑盒搜索缺乏语义指导和大型语言模型进行浅层模式匹配及因果关系不透明的问题。ECCO旨在通过建立静态代码特征到性能证据之间的映射，使模型学习优化决策背后的因果逻辑。", "method": "提出了一种逆向工程方法来构建一个链式思维数据集，并设计了一个协作推理机制，其中大型语言模型作为策略制定者定义优化意图，动态指导遗传算法的变异操作。", "result": "实验结果表明ECCO显著优于LLVM opt -O3基线，在七个数据集上平均减少了24.44%的周期数。", "conclusion": "ECCO通过证据驱动的因果推理成功提高了编译器优化的效果，展示了在组合搜索中结合可解释性逻辑的潜力。"}}
{"id": "2602.00086", "pdf": "https://arxiv.org/pdf/2602.00086", "abs": "https://arxiv.org/abs/2602.00086", "authors": ["Walid Siala", "Ahmed Khanfir", "Mike Papadakis"], "title": "Impact of LLMs news Sentiment Analysis on Stock Price Movement Prediction", "categories": ["q-fin.ST", "cs.AI", "cs.CE"], "comment": null, "summary": "This paper addresses stock price movement prediction by leveraging LLM-based news sentiment analysis. Earlier works have largely focused on proposing and assessing sentiment analysis models and stock movement prediction methods, however, separately. Although promising results have been achieved, a clear and in-depth understanding of the benefit of the news sentiment to this task, as well as a comprehensive assessment of different architecture types in this context, is still lacking. Herein, we conduct an evaluation study that compares 3 different LLMs, namely, DeBERTa, RoBERTa and FinBERT, for sentiment-driven stock prediction. Our results suggest that DeBERTa outperforms the other two models with an accuracy of 75% and that an ensemble model that combines the three models can increase the accuracy to about 80%. Also, we see that sentiment news features can benefit (slightly) some stock market prediction models, i.e., LSTM-, PatchTST- and tPatchGNN-based classifiers and PatchTST- and TimesNet-based regression tasks models.", "AI": {"tldr": "利用LLM进行新闻情感分析以预测股票价格变动", "motivation": "先前的研究主要集中在单独提出和评估情感分析模型及股价预测方法上，缺少对基于新闻的情感信息在预测中的益处以及不同类型架构的全面评估。本文旨在填补这一空白。", "method": "比较了DeBERTa、RoBERTa和FinBERT三种LLM在基于情绪驱动的股票预测中的效果，并探索了结合这些模型以提高准确性的可能性。", "result": "结果表明，DeBERTa的表现优于其他两种模型，达到75%的准确性；而组合模型可以将准确率提升到大约80%。此外，发现情感新闻特征能略微改进某些股市预测模型。", "conclusion": "基于LLM的情感分析方法对股票价格变动预测具有显著效果，特别是DeBERTa和混合模型表现突出，并且情感信息对于某些特定的股市预测模型有所增益"}}
{"id": "2602.00085", "pdf": "https://arxiv.org/pdf/2602.00085", "abs": "https://arxiv.org/abs/2602.00085", "authors": ["Shuozhe Li", "Jincheng Cao", "Bodun Hu", "Aryan Mokhtari", "Leqi Liu", "Amy Zhang"], "title": "CARE-RFT: Confidence-Anchored Reinforcement Finetuning for Reliable Reasoning in Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement finetuning (RFT) has emerged as a powerful paradigm for unlocking reasoning capabilities in large language models. However, we identify a critical trade-off: while unconstrained RFT achieves strong reasoning performance, it severely compromises model trustworthiness by amplifying hallucination and worsening calibration; conversely, RKL-constrained RFT preserves trustworthiness but limits reasoning gains due to its unbounded penalty on exploratory deviations. To resolve this tension, we introduce CARE-RFT (Confidence-Anchored Regularized Reinforcement Finetuning), a novel method that replaces standard reverse KL regularization with a skew reverse KL divergence. CARE-RFT provides a confidence-sensitive penalty: it is bounded for confident, consistently rewarded explorations to enable reasoning, while unbounded elsewhere to preserve calibration. Extensive experiments across multiple model scales and RFT algorithms show that CARE-RFT achieves a superior balance, matching the reasoning performance of unconstrained RFT while recovering the trustworthiness and calibration of the base model. Our work establishes that careful, confidence-aware regularization is key to building both capable and trustworthy reasoning models.", "AI": {"tldr": "本文提出了一种新的方法CARE-RFT，用于解决大语言模型中增强推理能力与保持可信度之间的矛盾。", "motivation": "现有的强化微调技术在提升模型推理性能的同时牺牲了其可靠性；而带有约束的RFT虽然保证了模型的可靠性但限制了推理性能。本文旨在找到两者间的平衡点。", "method": "通过引入基于置信度敏感惩罚的偏斜逆KL散度替代标准逆KL正则化，设计了一种名为CARE-RFT的新方法来解决上述问题。", "result": "实验表明，CARE-RFT在各种模型规模和RFT算法下均能实现推理性能与可靠性的最优平衡。", "conclusion": "该研究证实了在构建既强大又可靠的推理模型时需要谨慎、基于置信度的正则化是关键。"}}
{"id": "2602.00083", "pdf": "https://arxiv.org/pdf/2602.00083", "abs": "https://arxiv.org/abs/2602.00083", "authors": ["Yuxin Yang", "Gangda Deng", "Ömer Faruk Akgül", "Nima Chitsazan", "Yash Govilkar", "Akasha Tigalappanavara", "Shi-Xiong Zhang", "Sambit Sahu", "Viktor Prasanna"], "title": "SPARC-RAG: Adaptive Sequential-Parallel Scaling with Context Management for Retrieval-Augmented Generation", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) grounds large language model outputs in external evidence, but remains challenged on multi-hop question answering that requires long reasoning. Recent works scale RAG at inference time along two complementary dimensions: sequential depth for iterative refinement and parallel width for coverage expansion. However, naive scaling causes context contamination and scaling inefficiency, leading to diminishing or negative returns despite increased computation. To address these limitations, we propose SPARC-RAG, a multi-agent framework that coordinates sequential and parallel inference-time scaling under a unified context management mechanism. SPARC-RAG employs specialized agents that maintain a shared global context and provide explicit control over the scaling process. It generates targeted, complementary sub-queries for each branch to enable diverse parallel exploration, and explicitly regulates exiting decisions based on answer correctness and evidence grounding. To optimize scaling behavior, we further introduce a lightweight fine-tuning method with process-level verifiable preferences, which improves the efficiency of sequential scaling and effectiveness of parallel scaling. Across single- and multi-hop QA benchmarks, SPARC-RAG consistently outperforms previous RAG baselines, yielding an average +6.2 F1 improvement under lower inference cost.", "AI": {"tldr": "SPARC-RAG提出了一种用于检索增强生成的多代理框架，旨在解决推理时间扩展过程中的上下文污染和扩展效率问题。", "motivation": "现有的RAG模型在处理需要长期推理的多跳问答任务时面临挑战。简单的扩展会导致上下文污染和扩展低效性，从而尽管计算量增加但性能并未显著提升或甚至下降。", "method": "SPARC-RAG采用了一种统一的上下文管理机制来协调顺序和并行的推理时间扩展过程，使用专门代理维持共享全局上下文，并明确控制扩展流程。通过生成互补子查询以促进多样化平行探索，并基于答案正确性和证据基础做出退出决策。", "result": "在单跳和多跳问答基准测试中，SPARC-RAG相比先前RAG基线模型表现更优，在降低推理成本的同时提高了6.2个F1分数平均值。", "conclusion": "SPARC-RAG通过其独特设计优化了检索增强生成的推理时间扩展过程，展示了在保持或改善性能的同时降低成本的能力。"}}
{"id": "2602.00082", "pdf": "https://arxiv.org/pdf/2602.00082", "abs": "https://arxiv.org/abs/2602.00082", "authors": ["Zheng Li"], "title": "Design and Empirical Study of a Large Language Model-Based Multi-Agent Investment System for Chinese Public REITs", "categories": ["q-fin.ST", "cs.AI", "q-fin.TR"], "comment": null, "summary": "This study addresses the low-volatility Chinese Public Real Estate Investment Trusts (REITs) market, proposing a large language model (LLM)-driven trading framework based on multi-agent collaboration. The system constructs four types of analytical agents-announcement, event, price momentum, and market-each conducting analysis from different dimensions; then the prediction agent integrates these multi-source signals to output directional probability distributions across multiple time horizons, then the decision agent generates discrete position adjustment signals based on the prediction results and risk control constraints, thereby forming a closed loop of analysis-prediction-decision-execution. This study further compares two prediction model pathways: for the prediction agent, directly calling the general-purpose large model DeepSeek-R1 versus using a specialized small model Qwen3-8B fine-tuned via supervised fine-tuning and reinforcement learning alignment. In the backtest from October 2024 to October 2025, both agent-based strategies significantly outperformed the buy-and-hold benchmark in terms of cumulative return, Sharpe ratio, and maximum drawdown. The results indicate that the multi-agent framework can effectively enhance the risk-adjusted return of REITs trading, and the fine-tuned small model performs close to or even better than the general-purpose large model in some scenarios.", "AI": {"tldr": "设计并实证研究了一个基于大型语言模型的多代理投资系统，用于中国公共房地产投资信托基金（REITs）市场。", "motivation": "针对低波动性中国市场，提出了一种基于多代理协作的大规模语言模型驱动交易框架，旨在提升风险调整后的回报。", "method": "该系统构建了四种类型的分析代理——公告、事件、价格动量和市场代理，并通过预测代理整合这些多源信号。比较两种预测模型路径：一种是直接调用通用大规模模型DeepSeek-R1，另一种是使用监督微调和强化学习对齐的专业小型模型Qwen3-8B。", "result": "从2024年10月到2025年10月的回测显示，基于代理的战略在累计回报、夏普比率和最大回撤方面显著优于买入并持有基准。多代理框架有效增强了REITs交易的风险调整后收益，小型微调模型在某些场景中表现出色。", "conclusion": "研究表明，所提出的多代理架构可以增强中国公共房地产投资信托基金市场的风险调整后的回报，并且定制的小型模型可能表现得更好或至少与通用大规模语言模型相当。"}}
{"id": "2602.00079", "pdf": "https://arxiv.org/pdf/2602.00079", "abs": "https://arxiv.org/abs/2602.00079", "authors": ["Han Xiao"], "title": "Lossless Embedding Compression via Spherical Coordinates", "categories": ["cs.LG", "cs.CV"], "comment": ":68T50ACM Class:I.2.7", "summary": "We present a lossless compression method for unit-norm embeddings that achieves 1.5$\\times$ compression, 25\\% better than the best prior method. The method exploits that spherical coordinates of high-dimensional unit vectors concentrate around $π/2$, causing IEEE 754 exponents to collapse to a single value and enabling entropy coding. Evaluation across 26 configurations spanning text, image, and multi-vector embeddings confirms consistent improvement. The method requires no training and is fully lossless within float32 precision.", "AI": {"tldr": "本文提出了一种无损压缩方法，用于单位范数嵌入，并实现了1.5倍的压缩率。", "motivation": "该方法利用了高维单位向量在球坐标中的分布特性，这些向量集中在π/2附近，使得IEEE754指数坍缩为一个值，从而可以进行熵编码。", "method": "通过将单位范数嵌入转换为球坐标，并利用其集中特性进行无损压缩。", "result": "该方法在26种不同的配置上进行了评估，包括文本、图像和多向量嵌入，在所有情况下都取得了显著的改进，且优于当前的最佳方法。", "conclusion": "提出的方法无需训练并且完全保留在float32精度内。"}}
{"id": "2602.00078", "pdf": "https://arxiv.org/pdf/2602.00078", "abs": "https://arxiv.org/abs/2602.00078", "authors": ["Piercosma Bisconti", "Marcello Galisai"], "title": "Standards for trustworthy AI in the European Union: technical rationale, structural challenges, and an implementation path", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "This white paper examines the technical foundations of European AI standardization under the AI Act. It explains how harmonized standards enable the presumption of conformity mechanism, describes the CEN/CENELEC standardization process, and analyzes why AI poses unique standardization challenges including stochastic behavior, data dependencies, immature evaluation practices, and lifecycle dynamics. The paper argues that AI systems are typically components within larger sociotechnical systems, requiring a layered approach where horizontal standards define process obligations and evidence structures while sectoral profiles specify domain-specific thresholds and acceptance criteria. It proposes a workable scheme based on risk management, reproducible technical checks redefined as stability of measured properties, structured documentation, comprehensive logging, and assurance cases that evolve over the system lifecycle. The paper demonstrates that despite methodological difficulties, technical standards remain essential for translating legal obligations into auditable engineering practice and enabling scalable conformity assessment across providers, assessors, and enforcement authorities", "AI": {"tldr": "本文探讨了欧盟AI法案下的欧洲AI标准化技术基础，提出了一种基于风险管理、可重复的技术检查等的分层标准制定方法。", "motivation": "为了应对AI带来的独特标准化挑战，如随机行为、数据依赖性等问题，确保AI系统的可信度和合规性。", "method": "本文描述了CEN/CENELEC标准制定流程，并提出了一种基于风险管理和可重复技术检查的分层标准制定方法，强调结构化文档和全面日志的重要性。", "result": "尽管存在方法论上的困难，但通过这种方法可以将法律义务转化为可审计的工程实践，并实现跨供应商、评估者和执法机构的规模化合规性验证。", "conclusion": "技术标准对于确保AI系统的可信度和合规性至关重要，在解决独特挑战的同时，为欧洲AI法案提供了可行的技术路径。"}}
{"id": "2602.00076", "pdf": "https://arxiv.org/pdf/2602.00076", "abs": "https://arxiv.org/abs/2602.00076", "authors": ["Ziqing Li", "Myung Cho", "Qiutong Jin", "Weiyu Xu"], "title": "Repair Brain Damage: Real-Numbered Error Correction Code for Neural Network", "categories": ["cs.NE", "cs.LG"], "comment": "6 pages, 3 figures", "summary": "We consider a neural network (NN) that may experience memory faults and computational errors. In this paper, we propose a novel real-number-based error correction code (ECC) capable of detecting and correcting both memory errors and computational errors. The proposed approach introduces structures in the form of real-number-based linear constraints on the NN weights to enable error detection and correction, without sacrificing classification performance or increasing the number of real-valued NN parameters.", "AI": {"tldr": "提出了一种基于实数的错误校正码以检测和纠正神经网络中的内存故障和计算误差", "motivation": "为了解决神经网络在运行过程中可能遇到的记忆故障和计算错误问题，保持分类性能并避免增加实际值参数数量", "method": "通过引入基于实数的线性约束结构到神经网络权重中实现错误检测与校正", "result": "所提出的方案能够在不牺牲分类准确率的情况下有效发现和修复内存及计算误差", "conclusion": "证明了该技术可以有效地增强神经网络面对故障时的鲁棒性"}}
{"id": "2602.00074", "pdf": "https://arxiv.org/pdf/2602.00074", "abs": "https://arxiv.org/abs/2602.00074", "authors": ["Nigam H. Shah", "Nerissa Ambers", "Abby Pandya", "Timothy Keyes", "Juan M. Banda", "Srikar Nallan", "Carlene Lugtu", "Artem A. Trotsyuk", "Suhana Bedi", "Alyssa Unell", "Miguel Fuentes", "Francois Grolleau", "Sneha S. Jain", "Jonathan Chen", "Devdutta Dash", "Danton Char", "Aditya Sharma", "Duncan McElfresh", "Patrick Scully", "Vishanthan Kumar", "Connor OBrien", "Satchi Mouniswamy", "Elvis Jones", "Krishna Jasti", "Gunavathi Mannika Lakshmanan", "et al. (32 additional authors not shown)"], "title": "Adoption and Use of LLMs at an Academic Medical Center", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "While large language models (LLMs) can support clinical documentation needs, standalone tools struggle with \"workflow friction\" from manual data entry. We developed ChatEHR, a system that enables the use of LLMs with the entire patient timeline spanning several years. ChatEHR enables automations - which are static combinations of prompts and data that perform a fixed task - and interactive use in the electronic health record (EHR) via a user interface (UI). The resulting ability to sift through patient medical records for diverse use-cases such as pre-visit chart review, screening for transfer eligibility, monitoring for surgical site infections, and chart abstraction, redefines LLM use as an institutional capability. This system, accessible after user-training, enables continuous monitoring and evaluation of LLM use. In 1.5 years, we built 7 automations and 1075 users have trained to become routine users of the UI, engaging in 23,000 sessions in the first 3 months of launch. For automations, being model-agnostic and accessing multiple types of data was essential for matching specific clinical or administrative tasks with the most appropriate LLM. Benchmark-based evaluations proved insufficient for monitoring and evaluation of the UI, requiring new methods to monitor performance. Generation of summaries was the most frequent task in the UI, with an estimated 0.73 hallucinations and 1.60 inaccuracies per generation. The resulting mix of cost savings, time savings, and revenue growth required a value assessment framework to prioritize work as well as quantify the impact of using LLMs. Initial estimates are $6M savings in the first year of use, without quantifying the benefit of the better care offered. Such a \"build-from-within\" strategy provides an opportunity for health systems to maintain agency via a vendor-agnostic, internally governed LLM platform.", "AI": {"tldr": "开发了一种名为ChatEHR的系统，允许在电子健康记录中使用大型语言模型（LLMs），并评估了其使用效果。", "motivation": "解决单独工具在临床文档需求中遇到的工作流程摩擦问题，通过集成LLMs来提高工作效率和准确性。", "method": "开发了名为ChatEHR的系统，该系统能够自动化一些任务并通过用户界面实现互动式使用。同时建立了新的评估方法以持续监控性能。", "result": "自部署以来，在3个月内实现了23000次会话，并节省了大约6百万美元的成本。", "conclusion": "内部构建的LLM平台不仅提升了工作效率，还带来了经济效益和更好的护理质量，为医疗系统提供了维持自主性的机会。"}}
{"id": "2602.00067", "pdf": "https://arxiv.org/pdf/2602.00067", "abs": "https://arxiv.org/abs/2602.00067", "authors": ["Yihan Zhang", "Ercan E. Kuruoglu"], "title": "Modality as Heterogeneity: Node Splitting and Graph Rewiring for Multimodal Graph Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multimodal graphs are gaining increasing attention due to their rich representational power and wide applicability, yet they introduce substantial challenges arising from severe modality confusion. To address this issue, we propose NSG (Node Splitting Graph)-MoE, a multimodal graph learning framework that integrates a node-splitting and graph-rewiring mechanism with a structured Mixture-of-Experts (MoE) architecture. It explicitly decomposes each node into modality-specific components and assigns relation-aware experts to process heterogeneous message flows, thereby preserving structural information and multimodal semantics while mitigating the undesirable mixing effects commonly observed in general-purpose GNNs. Extensive experiments on three multimodal benchmarks demonstrate that NSG-MoE consistently surpasses strong baselines. Despite incorporating MoE -- which is typically computationally heavy -- our method achieves competitive training efficiency. Beyond empirical results, we provide a spectral analysis revealing that NSG performs adaptive filtering over modality-specific subspaces, thus explaining its disentangling behavior. Furthermore, an information-theoretic analysis shows that the architectural constraints imposed by NSG reduces mutual information between data and parameters and improving generalization capability.", "AI": {"tldr": "提出了一种新的多模态图学习框架NSG-MoE，用于处理节点之间的异构信息和缓解模态混淆。", "motivation": "为了应对多模态图中的严重模态混淆问题，设计了一种能够有效分离不同模态信息并保持结构信息的方法。", "method": "通过引入节点分裂和图重构机制以及混合专家（MoE）架构，将每个节点分解为特定于模式的组件，并使用关系感知专家处理异构消息流。", "result": "实验结果表明NSG-MoE在多模态基准测试中优于强基线模型，同时保持了良好的训练效率和泛化能力。", "conclusion": "所提出的框架通过适应性地过滤特定于模式的子空间来减少数据与参数之间的信息互换，从而提高了模型的性能和鲁棒性。"}}
{"id": "2602.00065", "pdf": "https://arxiv.org/pdf/2602.00065", "abs": "https://arxiv.org/abs/2602.00065", "authors": ["Hiba Arnaout", "Anmol Goel", "H. Andrew Schwartz", "Steffen T. Eberhardt", "Dana Atzil-Slonim", "Gavin Doherty", "Brian Schwartz", "Wolfgang Lutz", "Tim Althoff", "Munmun De Choudhury", "Hamidreza Jamalabadi", "Raj Sanjay Shah", "Flor Miriam Plaza-del-Arco", "Dirk Hovy", "Maria Liakata", "Iryna Gurevych"], "title": "Responsible Evaluation of AI for Mental Health", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Although artificial intelligence (AI) shows growing promise for mental health care, current approaches to evaluating AI tools in this domain remain fragmented and poorly aligned with clinical practice, social context, and first-hand user experience. This paper argues for a rethinking of responsible evaluation -- what is measured, by whom, and for what purpose -- by introducing an interdisciplinary framework that integrates clinical soundness, social context, and equity, providing a structured basis for evaluation. Through an analysis of 135 recent *CL publications, we identify recurring limitations, including over-reliance on generic metrics that do not capture clinical validity, therapeutic appropriateness, or user experience, limited participation from mental health professionals, and insufficient attention to safety and equity. To address these gaps, we propose a taxonomy of AI mental health support types -- assessment-, intervention-, and information synthesis-oriented -- each with distinct risks and evaluative requirements, and illustrate its use through case studies.", "AI": {"tldr": "该论文提出了一个评估人工智能在心理健康领域的框架，强调了临床有效性、社会背景和公平性的综合考量。", "motivation": "当前对AI工具的评估方法存在碎片化问题，并且与临床实践和社会情境脱节。因此需要重新思考并制定更加负责任的评估方式以更好地适应实际需求。", "method": "通过分析135篇相关文献，论文指出了现有评估中的不足之处，包括过度依赖通用指标、缺乏心理健康专业人员参与以及忽视安全性和公平性等问题，并提出了一个涵盖评估类型和要求的新框架。", "result": "该研究确定了AI在精神健康支持方面的主要类别及其独特风险和评价需求，并通过案例分析展示了新框架的应用。", "conclusion": "论文强调了一个综合性的、跨学科的评估框架对于确保AI技术有效性和公平性的重要性，为未来的研究提供了新的视角。"}}
{"id": "2602.00064", "pdf": "https://arxiv.org/pdf/2602.00064", "abs": "https://arxiv.org/abs/2602.00064", "authors": ["Hao Deng", "Yingping Li", "Shuiping Gou", "Bo Liu"], "title": "SPGCL: Effective Graph Contrastive Learning via SVD-Guided Structural Perturbation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) can be highly sensitive to structural noise, including spurious or missing edges caused by adversarial attacks or non-adversarial imperfections. Existing graph contrastive learning methods typically rely on either random perturbations (e.g., edge dropping) to generate diverse views or purely spectral augmentations (e.g., SVD) to preserve global structural priors. However, random perturbations are structure-agnostic and may remove critical edges, while SVD-based views often become dense and lack sufficient diversity. To bridge this gap, we propose SPGCL, a robust graph contrastive learning framework via SVD-guided structural perturbation. SPGCL couples lightweight stochastic edge removal with an SVD-guided refinement step that can recover mistakenly removed informative edges and introduce semantically meaningful missing links while avoiding graph densification through sparse top-ranked edge selection and merging. By balancing edge removal and recovery rates, SPGCL explicitly controls structural discrepancy between views so that contrastive signals reflect semantic structural differences rather than edge-count gaps. We further incorporate a contrastive fusion module regularized by a global similarity constraint to better align the two views. Extensive experiments on ten benchmark datasets demonstrate that SPGCL consistently improves robustness and accuracy of base GNNs, outperforming state-of-the-art graph contrastive learning and structure learning methods.", "AI": {"tldr": "提出了一种基于SVD引导的结构扰动的有效图对比学习框架SPGCL，以提高图神经网络（GNN）在对抗攻击和非对抗性噪声下的鲁棒性和准确性。", "motivation": "现有图对比学习方法存在随机扰动缺乏结构性指导以及谱增强方法导致视图稠密、多样性不足的问题。为解决这些问题，提出了结合SVD引导的轻量级结构化边缘去除与恢复步骤的方法。", "method": "通过将轻量级随机边删除和基于SVD的精炼步骤结合起来，可以恢复被误删的重要边并引入语义意义缺失链接，在避免图稠密化的同时保持视图稀疏性。通过调节边删除和恢复比率来控制视图间结构性差异。", "result": "在十种基准数据集上的实验表明SPGCL提高了基础GNN的鲁棒性和准确性，优于现有图对比学习和结构学习方法。", "conclusion": "提出的SPGCL框架能够在保持结构信息的同时引入语义差异性，从而提高图神经网络模型的性能。"}}
{"id": "2602.00063", "pdf": "https://arxiv.org/pdf/2602.00063", "abs": "https://arxiv.org/abs/2602.00063", "authors": ["Leonidas Christodoulou", "Chang Sun"], "title": "The Impact of Machine Learning Uncertainty on the Robustness of Counterfactual Explanations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Counterfactual explanations are widely used to interpret machine learning predictions by identifying minimal changes to input features that would alter a model's decision. However, most existing counterfactual methods have not been tested when model and data uncertainty change, resulting in explanations that may be unstable or invalid under real-world variability. In this work, we investigate the robustness of common combinations of machine learning models and counterfactual generation algorithms in the presence of both aleatoric and epistemic uncertainty. Through experiments on synthetic and real-world tabular datasets, we show that counterfactual explanations are highly sensitive to model uncertainty. In particular, we find that even small reductions in model accuracy - caused by increased noise or limited data - can lead to large variations in the generated counterfactuals on average and on individual instances. These findings underscore the need for uncertainty-aware explanation methods in domains such as finance and the social sciences.", "AI": {"tldr": "研究机器学习不确定性对反事实解释的影响", "motivation": "现有反事实方法在模型和数据不确定时未被充分测试，可能导致解释不稳定或无效。本工作探讨常见机器学习模型与反事实生成算法组合的鲁棒性问题", "method": "通过合成及真实世界表格数据集实验，研究不同不确定性水平下反事实解释的变化情况", "result": "发现即使微小的模型准确性下降也会导致大量个体和总体上的反事实变化", "conclusion": "强调在金融、社会科学等领域中需要开发考虑不确定性的解释方法"}}
{"id": "2602.00062", "pdf": "https://arxiv.org/pdf/2602.00062", "abs": "https://arxiv.org/abs/2602.00062", "authors": ["Ming-Yao Ho", "Cheng-Kai Wang", "You-Teng Lin", "Hung-Hsuan Chen"], "title": "SCPL: Enhancing Neural Network Training Throughput with Decoupled Local Losses and Model Parallelism", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Adopting large-scale AI models in enterprise information systems is often hindered by high training costs and long development cycles, posing a significant managerial challenge. The standard end-to-end backpropagation (BP) algorithm is a primary driver of modern AI, but it is also the source of inefficiency in training deep networks. This paper introduces a new training methodology, Supervised Contrastive Parallel Learning (SCPL), that addresses this issue by decoupling BP and transforming a long gradient flow into multiple short ones. This design enables the simultaneous computation of parameter gradients in different layers, achieving superior model parallelism and enhancing training throughput. Detailed experiments are presented to demonstrate the efficiency and effectiveness of our model compared to BP, Early Exit, GPipe, and Associated Learning (AL), a state-of-the-art method for decoupling backpropagation. By mitigating a fundamental performance bottleneck, SCPL provides a practical pathway for organizations to develop and deploy advanced information systems more cost-effectively and with greater agility. The experimental code is released for reproducibility. https://github.com/minyaho/scpl/", "AI": {"tldr": "该论文提出了一种新的训练方法Supervised Contrastive Parallel Learning (SCPL)，通过解耦BP算法和多层参数梯度的并行计算，提高大型AI模型的训练效率。", "motivation": "传统的端到端反向传播(BP)算法虽然推动了现代AI的发展，但同时也是深度网络训练低效性的主要原因。因此论文旨在解决这一问题，通过引入SCPL方法来降低企业信息系统的开发成本和周期。", "method": "该方法解耦BP过程，并将长梯度流分解为多个短流程，使得不同层的参数梯度可以在同一时间计算，实现更好的模型并行性，从而提升训练吞吐量。", "result": "实验结果表明SCPL在效率和效果上都优于BP、Early Exit、GPipe以及最新的解耦反向传播方法Associated Learning (AL)。", "conclusion": "通过解决基本的性能瓶颈问题，SCPL为组织提供了开发部署先进信息系统的一种实用途径，并降低了成本。"}}
{"id": "2602.00061", "pdf": "https://arxiv.org/pdf/2602.00061", "abs": "https://arxiv.org/abs/2602.00061", "authors": ["Zhou Ziheng", "Jiakun Ding", "Zhaowei Zhang", "Ruosen Gao", "Yingnian Wu", "Demetri Terzopoulos", "Yipeng Kang", "Fangwei Zhong", "Junqi Wang"], "title": "Simple Role Assignment is Extraordinarily Effective for Safety Alignment", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Principle-based alignment often lacks context sensitivity and completeness. Grounded in Theory of Mind, we propose role conditioning as a compact alternative: social roles (e.g., mother, judge) implicitly encode both values and the cognitive schemas required to apply them. We introduce a training-free pipeline featuring a role-conditioned generator and iterative role-based critics for refinement. Across five model families, our approach consistently outperforms principle-based, Chain-of-Thought (CoT) and other baselines across benchmarks. Notably, it reduces unsafe outputs on the WildJailbreak benchmark from 81.4\\% to 3.6\\% with DeepSeek-V3. Not only for common safety benchmarks, it consistently applies for agentic safety tasks. These results establish role assignment as a powerful, interpretable paradigm for AI alignment and LLM-as-a-Judge construction.", "AI": {"tldr": "该论文提出了一种基于社会角色分配的安全对齐方法，用于改进AI系统的安全性。", "motivation": "现有原则基础的对齐策略缺乏上下文敏感性和完整性。因此，作者通过引入社会角色（如母亲、法官）的概念来隐式编码价值观和认知模式，并提出一种训练无需求的方法。", "method": "论文介绍了一种无需训练的角色条件生成器以及迭代角色批判者进行优化的方法管道。该方法在五个模型系列中得到了验证。", "result": "实验结果显示，相对于基准原则对齐、链思维（CoT）和其他基线，该方法显著提高了安全性和任务性能。尤其在WildJailbreak测试集上，它将不安全输出从81.4%降低到3.6%。", "conclusion": "角色分配作为一种强大且可解释的AI对齐和LLM作为法官构建的新范例已被确立为有效的方法论。"}}
{"id": "2602.00060", "pdf": "https://arxiv.org/pdf/2602.00060", "abs": "https://arxiv.org/abs/2602.00060", "authors": ["Ali Abedi", "Charlene H. Chu", "Shehroz S. Khan"], "title": "A longitudinal geospatial multimodal dataset of post-discharge frailty, physiology, mobility, and neighborhoods", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "Frailty in older adults is associated with increased vulnerability to functional decline, reduced mobility, social isolation, and challenges during the transition from hospital to community living. These factors are associated with rehospitalization and may adversely influence recovery. Neighborhood environments can further shape recovery trajectories by affecting mobility opportunities, social engagement, and access to community resources. Multimodal sensing technologies combined with data-driven analytical approaches offer the potential to continuously monitor these multidimensional factors in real-world settings. This Data Descriptor presents GEOFRAIL, a longitudinal geospatial multimodal dataset collected from community-dwelling frail older adults following hospital discharge. The dataset is organized into interconnected tables capturing participant demographics, features derived from multimodal sensors, biweekly clinical assessments of frailty, physical function, and social isolation, and temporal location records linked to neighborhood amenities, crime rates, and census-based socioeconomic indicators. Data were collected over an eight-week post-discharge period using standardized pipelines with privacy-preserving spatial aggregation. Technical validation demonstrates internal consistency across geospatial, sensor-derived, and clinical measures and reports baseline performance of machine learning models for characterizing recovery trajectories.", "AI": {"tldr": "构建了一个纵向地理多模态数据集GEOFRAIL，用于监测老年人出院后的脆弱性、生理功能、移动性和社区环境因素。", "motivation": "研究老年人出院后的生活质量变化及其与社区环境的关系，利用多模态传感技术和数据分析方法来实时监控这些复杂的健康和社会指标。", "method": "使用标准流程收集八周内的数据，包括参与者的人口统计信息、从多模式传感器派生的特征、双周临床评估结果以及地理位置记录。技术验证显示了地理空间、传感器和临床测量之间的内部一致性，并报告了机器学习模型识别恢复轨迹的基本性能。", "result": "提供了一个包含多个维度因素的数据集GEOFRAIL，该数据集可用于进一步的研究以更好地理解老年人出院后的康复过程。", "conclusion": "多模态数据监测与社区环境评估相结合的GEOFRAIL数据集为研究脆弱性、生理功能和移动性提供了新的视角。"}}
{"id": "2602.00059", "pdf": "https://arxiv.org/pdf/2602.00059", "abs": "https://arxiv.org/abs/2602.00059", "authors": ["Zizheng Zhang", "Yuyang Liao", "Chen Chen", "Jian He", "Dun Wu", "Qianjin Yu", "Yanqin Gao", "Jin Yang", "Kailai Zhang", "Eng Siong Chng", "Xionghu Zhong"], "title": "TextBFGS: Quasi-Newton Optimization for Discrete Executable Text via Gradient-Operator Retrieval", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Optimizing discrete executable text such as prompts and code has recently been framed as a gradient-based process, effectively translating backpropagation concepts to the semantic space. However, existing methods predominantly operate as first-order optimizers akin to Stochastic Gradient Descent, which are suffering from slow convergence and instability because they neglect the semantic curvature of the optimization landscape. To bridge this gap, we introduce TextBFGS, a second-order framework to implement a Quasi-Newton optimization method for discrete text. Unlike traditional memory-based approaches that retrieve similar textual instances, TextBFGS approximates the inverse Hessian matrix by retrieving Gradient-Operators from the memory of pre-learned successful trajectories. Specifically, given a textual gradient feedback, TextBFGS identifies historical correction patterns from the optimization knowledge base and tries to apply these abstract operators to the current variable. This mechanism enables a One-Pass Update, combining feedback generation and second-order correction into a single inference step. Empirical evaluations on code optimization across diverse domains (e.g., HumanEval, MBPP) demonstrate that TextBFGS significantly outperforms first-order baselines. It achieves superior pass rates with fewer model calls and exhibits strong cross-task transferability, thus establishes a mathematically grounded paradigm for efficient, memory-aware text optimization.", "AI": {"tldr": "本文提出了TextBFGS，一种用于离散可执行文本优化的准牛顿方法框架。", "motivation": "现有方法主要依赖于类似随机梯度下降的一阶优化器，这些方法因忽略了优化空间中的语义曲率而导致收敛缓慢且不稳定。因此需要开发能够提升离散可执行文本（如提示和代码）优化效果的方法。", "method": "TextBFGS通过检索预训练成功的轨迹记忆库中的梯度操作符来近似逆海森矩阵，从而实现了结合反馈生成与二阶校正的单步更新机制。这种方法利用了历史上的修正模式，并将这些抽象的操作应用到当前变量上。", "result": "实验评估显示TextBFGS在代码优化方面优于一阶基线方法，其通过更少的模型调用达到了更高的通过率，并表现出强大的跨任务迁移能力。", "conclusion": "本文提出了TextBFGS，这是一种基于记忆库中预训练成功的轨迹来执行准牛顿优化的方法。它为有效的、内存感知的文本优化建立了一种数学基础框架。"}}
{"id": "2602.00057", "pdf": "https://arxiv.org/pdf/2602.00057", "abs": "https://arxiv.org/abs/2602.00057", "authors": ["Tingting Dan", "Jiaqi Ding", "Guorong Wu"], "title": "Explore Brain-Inspired Machine Intelligence for Connecting Dots on Graphs Through Holographic Blueprint of Oscillatory Synchronization", "categories": ["q-bio.NC", "cs.AI", "cs.LG"], "comment": "Published in Nature Communications", "summary": "Neural coupling in both neuroscience and artificial intelligence emerges as dynamic oscillatory patterns that encode abstract concepts. To this end, we hypothesize that a deeper understanding of the neural mechanisms governing brain rhythms can inspire next-generation design principles for machine learning algorithms, leading to improved efficiency and robustness. Building on this idea, we first model evolving brain rhythms through the interference of spontaneously synchronized neural oscillations, termed HoloBrain. The success of modeling brain rhythms using an artificial dynamical system of coupled oscillations motivates a \"first principle\" for brain-inspired machine intelligence based on a shared synchronization mechanism, termed HoloGraph. This principle enables graph neural networks to move beyond conventional heat diffusion paradigms toward modeling oscillatory synchronization. Our HoloGraph framework not only effectively mitigates the over-smoothing problem in graph neural networks but also demonstrates strong potential for reasoning and solving challenging problems on graphs.", "AI": {"tldr": "通过模拟大脑节律来开发一种新的图神经网络框架，用于解决图形上的复杂问题。", "motivation": "探索基于脑启发的机器智能的设计原理，并提高其效率和鲁棒性。", "method": "利用耦合振荡模型（HoloBrain）模拟大脑节律，提出了一种基于同步机制的新框架（HoloGraph），以解决图神经网络中的过度平滑问题。", "result": "该方法有效地减轻了图形神经网络的过度平滑问题，并展示了强大的推理和解决问题的能力。", "conclusion": "基于脑启发的方法具有重要的潜力，可以推动下一代机器学习算法的发展。"}}
{"id": "2602.00056", "pdf": "https://arxiv.org/pdf/2602.00056", "abs": "https://arxiv.org/abs/2602.00056", "authors": ["Sophia N. Wilson", "Sebastian Mair", "Mophat Okinyi", "Erik B. Dam", "Janin Koch", "Raghavendra Selvan"], "title": "How Hyper-Datafication Impacts the Sustainability Costs in Frontier AI", "categories": ["cs.CY", "cs.AI"], "comment": "14 pages", "summary": "Large-scale data has fuelled the success of frontier artificial intelligence (AI) models over the past decade. This expansion has relied on sustained efforts by large technology corporations to aggregate and curate internet-scale datasets. In this work, we examine the environmental, social, and economic costs of large-scale data in AI through a sustainability lens. We argue that the field is shifting from building models from data to actively creating data for building models. We characterise this transition as hyper-datafication, which marks a critical juncture for the future of frontier AI and its societal impacts. To quantify and contextualise data-related costs, we analyse approximately 550,000 datasets from the Hugging Face Hub, focusing on dataset growth, storage-related energy consumption and carbon footprint, and societal representation using language data. We complement this analysis with qualitative responses from data workers in Kenya to examine the labour involved, including direct employment by big tech corporations and exposure to graphic content. We further draw on external data sources to substantiate our findings by illustrating the global disparity in data centre infrastructure. Our analyses reveal that hyper-datafication does not merely increase resource consumption but systematically redistributes environmental burdens, labour risks, and representational harms toward the Global South, precarious data workers, and under-represented cultures. Thus, we propose Data PROOFS recommendations spanning provenance, resource awareness, ownership, openness, frugality, and standards to mitigate these costs. Our work aims to make visible the often-overlooked costs of data that underpin frontier AI and to stimulate broader debate within the research community and beyond.", "AI": {"tldr": "本文探讨了大规模数据在前沿人工智能中的环境、社会和经济成本，并通过分析55万数据集，提出了关于减少这些成本的建议。", "motivation": "随着大型科技公司不断积累互联网规模的数据以支持前沿AI模型的发展，这种趋势引发了对资源消耗和社会影响的关注。文章旨在揭示这些数据背后的隐藏成本，并提出改进措施。", "method": "通过分析Hugging Face Hub上的大约55万数据集，评估了数据集的增长、存储相关的能耗和碳足迹以及社会代表性问题。同时采访了肯尼亚的数据工作者以了解劳动条件，并使用外部数据源证明全球数据中心基础设施的差异性。", "result": "研究表明超大数据化不仅增加了资源消耗，还系统地将环境负担、劳工风险及文化表现不良转移到南方国家、不稳定的劳动力和代表不足的文化中。", "conclusion": "文章提出了Data PROOFS建议，包括源追溯、资源意识、所有权、开放性、节俭性和标准制定等措施来减少数据相关成本。这旨在揭示支撑前沿AI的数据背后的隐含成本，并促进研究界更广泛的讨论。"}}
{"id": "2602.00053", "pdf": "https://arxiv.org/pdf/2602.00053", "abs": "https://arxiv.org/abs/2602.00053", "authors": ["Ratul Ali"], "title": "Scalable and Secure AI Inference in Healthcare: A Comparative Benchmarking of FastAPI and Triton Inference Server on Kubernetes", "categories": ["cs.AI", "cs.LG"], "comment": "2 pages, 2 figures, 1 table", "summary": "Efficient and scalable deployment of machine learning (ML) models is a prerequisite for modern production environments, particularly within regulated domains such as healthcare and pharmaceuticals. In these settings, systems must balance competing requirements, including minimizing inference latency for real-time clinical decision support, maximizing throughput for batch processing of medical records, and ensuring strict adherence to data privacy standards such as HIPAA. This paper presents a rigorous benchmarking analysis comparing two prominent deployment paradigms: a lightweight, Python-based REST service using FastAPI, and a specialized, high-performance serving engine, NVIDIA Triton Inference Server. Leveraging a reference architecture for healthcare AI, we deployed a DistilBERT sentiment analysis model on Kubernetes to measure median (p50) and tail (p95) latency, as well as throughput, under controlled experimental conditions. Our results indicate a distinct trade-off. While FastAPI provides lower overhead for single-request workloads with a p50 latency of 22 ms, Triton achieves superior scalability through dynamic batching, delivering a throughput of 780 requests per second on a single NVIDIA T4 GPU, nearly double that of the baseline. Furthermore, we evaluate a hybrid architectural approach that utilizes FastAPI as a secure gateway for protected health information de-identification and Triton for backend inference. This study validates the hybrid model as a best practice for enterprise clinical AI and offers a blueprint for secure, high-availability deployments.", "AI": {"tldr": "比较FastAPI和NVIDIA Triton Inference Server在Kubernetes上的性能，特别是在医疗保健中的应用。", "motivation": "为了满足现代生产环境的需求，尤其是在需要遵守HIPAA等严格数据隐私标准的医疗保健领域中，必须平衡实时决策支持、批量处理病历及数据隐私保护之间的要求。", "method": "使用DistilBERT情感分析模型在Kubernetes上部署了FastAPI和NVIDIA Triton Inference Server，并通过控制实验条件测量它们的p50和p95延迟以及吞吐量。", "result": "FastAPI对于单请求工作负载具有较低的开销，p50延迟为22毫秒；而Triton则由于动态批处理在单一NVIDIA T4 GPU上的吞吐量达到780个请求/秒，几乎是基线的两倍。此外，还评估了混合架构模型，在该模型中FastAPI用作受保护健康信息去识别的安全网关。", "conclusion": "此研究验证了混合模型作为企业级临床AI的最佳实践，并为安全、高可用部署提供了蓝图。"}}
{"id": "2602.00052", "pdf": "https://arxiv.org/pdf/2602.00052", "abs": "https://arxiv.org/abs/2602.00052", "authors": ["Ramtin Babaeipour", "François Charest", "Madison Wright"], "title": "AI-assisted Protocol Information Extraction For Improved Accuracy and Efficiency in Clinical Trial Workflows", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Increasing clinical trial protocol complexity, amendments, and challenges around knowledge management create significant burden for trial teams. Structuring protocol content into standard formats has the potential to improve efficiency, support documentation quality, and strengthen compliance. We evaluate an Artificial Intelligence (AI) system using generative LLMs with Retrieval-Augmented Generation (RAG) for automated clinical trial protocol information extraction. We compare the extraction accuracy of our clinical-trial-specific RAG process against that of publicly available (standalone) LLMs. We also assess the operational impact of AI-assistance on simulated extraction CRC workflows. Our RAG process was measured as more accurate (87.8%) than standalone LLMs with fine-tuned prompts (62.6%) against expert-supported reference annotations. In the simulated extraction workflows, AI-assisted tasks were completed 40% faster, rated as less cognitively demanding and strongly preferred by users. While expert oversight remains essential, this suggests that AI-assisted extraction can enable protocol intelligence at scale, motivating the integration of similar methodologies into real world clinical workflows to further validate its impact on feasibility, study start-up, and post-activation monitoring.", "AI": {"tldr": "研究评估了一种基于AI的系统在临床试验协议信息提取中的应用，该系统使用生成式LLM和检索增强生成（RAG）技术。", "motivation": "随着临床试验协议复杂性、修订以及知识管理挑战的增加，团队负担日益加重。通过将协议内容结构化为标准格式，可以提高效率、支持文档质量并加强合规性。", "method": "研究使用了针对特定领域的RAG过程评估AI系统在信息提取中的准确性和操作影响，并将其与公开可用的独立LLM进行对比。", "result": "研究发现其临床试验专用的RAG流程比独立LLM更精确（87.8% vs 62.6%），模拟的工作流程中，人工智能辅助任务完成速度更快（40%）、认知负担更低且用户满意度更高。", "conclusion": "尽管专家监督依然至关重要，但研究结果表明，AI辅助提取可以实现协议智能规模化应用，并鼓励在现实世界中的临床工作流中整合类似方法以进一步验证其对可行性、研究启动和激活后监测的影响。"}}
{"id": "2602.00048", "pdf": "https://arxiv.org/pdf/2602.00048", "abs": "https://arxiv.org/abs/2602.00048", "authors": ["Fan Fan", "Yilei Shi", "Mihai Datcu", "Bertrand Le Saux", "Luigi Iapichino", "Francesca Bovolo", "Silvia Liberata Ullo", "Xiao Xiang Zhu"], "title": "Quantum Circuit-Based Learning Models: Bridging Quantum Computing and Machine Learning", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Machine Learning (ML) has been widely applied across numerous domains due to its ability to automatically identify informative patterns from data for various tasks. The availability of large-scale data and advanced computational power enables the development of sophisticated models and training strategies, leading to state-of-the-art performance, but it also introduces substantial challenges. Quantum Computing (QC), which exploits quantum mechanisms for computation, has attracted growing attention and significant global investment as it may address these challenges. Consequently, Quantum Machine Learning (QML), the integration of these two fields, has received increasing interest, with a notable rise in related studies in recent years. We are motivated to review these existing contributions regarding quantum circuit-based learning models for classical data analysis and highlight the identified potentials and challenges of this technique. Specifically, we focus not only on QML models, both kernel-based and neural network-based, but also on recent explorations of their integration with classical machine learning layers within hybrid frameworks. Moreover, we examine both theoretical analysis and empirical findings to better understand their capabilities, and we also discuss the efforts on noise-resilient and hardware-efficient QML that could enhance its practicality under current hardware limitations. In addition, we cover several emerging paradigms for advanced quantum circuit design and highlight the adaptability of QML across representative application domains. This study aims to provide an overview of the contributions made to bridge quantum computing and machine learning, offering insights and guidance to support its future development and pave the way for broader adoption in the coming years.", "AI": {"tldr": "本文综述了量子电路基于的学习模型在经典数据分析中的应用，探讨了量子机器学习的潜力与挑战。", "motivation": "为了应对大数据和先进计算能力带来的挑战，以及提高量子计算在数据处理方面的性能，作者通过回顾现有的贡献来探讨量子电路基础的学习模型，并强调其潜在价值和面临的挑战。", "method": "论文对基于量子回路的经典数据分析学习模型进行了全面的综述，包括QML模型（核方法基和神经网络基）、与经典机器学习层结合的混合框架探索、理论分析和实证研究，以及在当前硬件限制下增强其实用性的噪声鲁棒性和硬件效率的研究。", "result": "本文概述了量子计算与机器学习之间的桥梁建设贡献，提供了对未来的指导和支持。", "conclusion": "论文强调了量子电路基础的学习模型在经典数据分析中的潜力，并指出了未来研究方向和实际应用的挑战。"}}
{"id": "2602.00047", "pdf": "https://arxiv.org/pdf/2602.00047", "abs": "https://arxiv.org/abs/2602.00047", "authors": ["Laha Ale", "Hu Luo", "Mingsheng Cao", "Shichao Li", "Huanlai Xing", "Haifeng Sun"], "title": "Lightweight Edge Learning via Dataset Pruning", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 10 figures", "summary": "Edge learning facilitates ubiquitous intelligence by enabling model training and adaptation directly on data-generating devices, thereby mitigating privacy risks and communication latency. However, the high computational and energy overhead of on-device training hinders its deployment on battery-powered mobile systems with strict thermal and memory budgets. While prior research has extensively optimized model architectures for efficient inference, the training phase remains bottlenecked by the processing of massive, often redundant, local datasets. In this work, we propose a data-centric optimization framework that leverages dataset pruning to achieve resource-efficient edge learning. Unlike standard methods that process all available data, our approach constructs compact, highly informative training subsets via a lightweight, on-device importance evaluation. Specifically, we utilize average loss statistics derived from a truncated warm-up phase to rank sample importance, deterministically retaining only the most critical data points under a dynamic pruning ratio. This mechanism is model-agnostic and operates locally without inter-device communication. Extensive experiments on standard image classification benchmarks demonstrate that our framework achieves a near-linear reduction in training latency and energy consumption proportional to the pruning ratio, with negligible degradation in model accuracy. These results validate dataset pruning as a vital, complementary paradigm for enhancing the sustainability and scalability of learning on resource-constrained mobile edge devices.", "AI": {"tldr": "该论文提出了一种基于数据集剪枝的轻量化边缘学习框架，旨在减少训练时的数据处理量和资源消耗。", "motivation": "现有的边缘学习面临高计算及能量消耗问题，特别是在电池供电且有严格热能与内存限制的移动设备上。通过优化模型架构以提升推理效率的方法已较为成熟，但数据集庞大的本地数据仍造成瓶颈。", "method": "该研究提出了一种基于重要性评估的数据集剪枝方法，在一个简短的预训练阶段后使用平均损失统计信息来确定样本的重要程度，并据此构建出精简的信息丰富训练子集。此方法具有模型无关性和局部操作特性，无需设备间通信。", "result": "实验显示该框架实现了与剪枝比例成正比的接近线性级别的训练延迟和能耗降低，在图像分类基准测试中性能退化可以忽略不计。", "conclusion": "通过数据集剪枝的方法增强了边缘学习在资源受限移动环境中的可持续性和扩展能力，证明了这是一种重要的辅助技术。"}}
{"id": "2602.00044", "pdf": "https://arxiv.org/pdf/2602.00044", "abs": "https://arxiv.org/abs/2602.00044", "authors": ["Hongliu Cao", "Eoin Thomas", "Rodrigo Acuna Agost"], "title": "When LLMs Imagine People: A Human-Centered Persona Brainstorm Audit for Bias and Fairness in Creative Applications", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Biased outputs from Large Language Models (LLMs) can reinforce stereotypes and perpetuate inequities in real-world applications, making fairness auditing essential. We introduce the Persona Brainstorm Audit (PBA), a scalable and transparent auditing method for detecting bias through open-ended persona generation. Unlike existing methods that rely on fixed identity categories and static benchmarks, PBA uncovers biases across multiple social dimensions while supporting longitudinal tracking and mitigating data leakage risks. Applying PBA to 12 state-of-the-art LLMs, we compare bias severity across models, dimensions, and versions, uncover distinct patterns and lineage-specific variability, and trace how biases attenuate, persist, or resurface across successive generations. Robustness analyses show PBA remains stable under varying sample sizes, role-playing prompts, and debiasing prompts, establishing its reliability for fairness auditing in LLMs.", "AI": {"tldr": "本文介绍了Persona Brainstorm Audit（PBA），一种通过开放式人物生成检测偏见的可扩展透明审计方法，以评估大型语言模型中的公平性。", "motivation": "为了防止大语言模型输出强化刻板印象和加剧现实世界中的不平等现象，需要进行公平性的审核来确保模型生成的内容是公正无偏的。", "method": "Persona Brainstorm Audit（PBA）通过开放式的角色生成任务检测偏见，并与现有方法相比具有多维度、长时跟踪以及减少数据泄露风险的特点。本文将PBA应用于12种最先进的大型语言模型，比较不同模型、维度和版本之间的偏见严重性。", "result": "实验结果显示，PBA能够揭示不同模型中的偏见模式及变化趋势，并且在样本量变化、角色扮演提示和去偏提示下保持稳定可靠性。", "conclusion": "Persona Brainstorm Audit（PBA）提供了一种有效的方法来检测大型语言模型中的偏见问题，有助于提高AI系统的公平性和透明度。"}}
{"id": "2602.00042", "pdf": "https://arxiv.org/pdf/2602.00042", "abs": "https://arxiv.org/abs/2602.00042", "authors": ["Zhihan Zeng", "Hongyuan Shu", "Kaihe Wang", "Lu Chen", "Amir Hussian", "Yanjun Huang", "Junchu Zhao", "Yue Xiu", "Zhongpei Zhang"], "title": "JSR-GFNet: Jamming-to-Signal Ratio-Aware Dynamic Gating for Interference Classification in future Cognitive Global Navigation Satellite Systems", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "The transition toward cognitive global navigation satellite system (GNSS) receivers requires accurate interference classification to trigger adaptive mitigation strategies. However, conventional methods relying on Time-Frequency Analysis (TFA) and Convolutional Neural Networks (CNNs) face two fundamental limitations: severe performance degradation in low Jamming-to-Signal Ratio (JSR) regimes due to noise obscuration, and ``feature degeneracy'' caused by the loss of phase information in magnitude-only spectrograms. Consequently, spectrally similar signals -- such as high-order Quadrature Amplitude Modulation versus Band-Limited Gaussian Noise -- become indistinguishable. To overcome these challenges, this paper proposes the \\textbf{JSR-Guided Fusion Network (JSR-GFNet)}. This multi-modal architecture combines phase-sensitive complex In-Phase/Quadrature (IQ) samples with Short-Time Fourier Transform (STFT) spectrograms. Central to this framework is a physics-inspired dynamic gating mechanism driven by statistical signal descriptors. Acting as a conditional controller, it autonomously estimates signal reliability to dynamically reweight the contributions of a Complex-Valued ResNet (IQ stream) and an EfficientNet backbone (STFT stream). To validate the model, we introduce the Comprehensive GNSS Interference (CGI-21) dataset, simulating 21 jamming categories including software-defined waveforms from aerial platforms. Extensive experiments demonstrate that JSR-GFNet achieves higher accuracy across the full 10--50 dB JSR spectrum. Notably, interpretability analysis confirms that the model learns a physically intuitive strategy: prioritizing spectral energy integration in noise-limited regimes while shifting focus to phase precision in high-SNR scenarios to resolve modulation ambiguities. This framework provides a robust solution for next-generation aerospace navigation security.", "AI": {"tldr": "该论文提出了一种基于JSR感知融合网络（JSR-GFNet）的方法，用于未来认知全球导航卫星系统中的干扰分类。", "motivation": "传统的时频分析和卷积神经网络方法在低JSR环境下性能下降，并且由于相位信息损失导致难以区分光谱相似信号。", "method": "提出了一种结合了IQ样本和STFT光谱的多模态架构，利用基于物理原理的动态门控机制来自主估计信号可靠性并调整复值ResNet（IQ流）和EfficientNet骨干网络（STFT流）的贡献权重。", "result": "实验结果显示，在整个10-50 dB JSR范围内，JSR-GFNet提高了干扰分类的准确率，并且模型在噪声受限场景中优先集成光谱能量，在高信噪比情况下侧重于相位精度以解决调制模糊问题。", "conclusion": "该框架为下一代航空导航安全提供了一种稳健的方法。"}}
{"id": "2602.00041", "pdf": "https://arxiv.org/pdf/2602.00041", "abs": "https://arxiv.org/abs/2602.00041", "authors": ["Juan David Salazar Rodriguez", "Sam Conrad Joyce", "Nachamma Sockalingam", "Khoo Eng Tat", "Julfendi"], "title": "Student Perceptions of Large Language Models Use in Self-Reflection and Design Critique in Architecture Studio", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "Keywords: Architectural Education, Design Studio Pedagogy, Large Lan-guage Models, Generative AI in Education, Design Critique", "summary": "This study investigates the integration of Large Language Models (LLMs) into the feedback mechanisms of the architectural design studio, shifting the focus from generative production to reflective pedagogy. Employing a mixed-methods approach with architecture students at the Singapore Uni-versity of Technology and Design, the research analyzes student percep-tions across three distinct feedback domains: self-reflection, peer critique, and professor-led reviews. The findings reveal that students engage with LLMs not as authoritative instructors, but as collaborative \"cognitive mir-rors\" that scaffold critical thinking. In self-directed learning, LLMs help structure thoughts and overcome the \"blank page\" problem, though they are limited by a lack of contextual nuance. In peer critiques, the technology serves as a neutral mediator, mitigating social anxiety and the \"fear of of-fending\". Furthermore, in high-stakes professor-led juries, students utilize LLMs primarily as post-critique synthesis engines to manage cognitive overload and translate abstract academic discourse into actionable design iterations.", "AI": {"tldr": "研究探讨了大型语言模型在建筑设计工作室反馈机制中的应用，特别关注学生自我反思和设计批评的感知。", "motivation": "希望通过引入大型语言模型来增强建筑学学习过程中的自省教育，并分析其对学生自我反思、同伴评论以及教授主导评审的影响。", "method": "采用混合方法研究，在新加坡科技设计大学进行了一项调查，从三个方面分析了学生的反馈：自我反思、同行批评和教师领导的审查。", "result": "发现学生将大型语言模型视为协作的认知镜子，有助于结构化思维并克服‘白板问题’；在同伴评论中充当了中立调解者，在教授主导评审后帮助整理抽象学术讨论以指导设计迭代。", "conclusion": "大型语言模型在建筑设计教育中的使用不仅能够促进学生的自省学习过程，还能作为工具辅助学生管理认知负担，并将学术理论转化为实际的设计改进。"}}
{"id": "2602.00040", "pdf": "https://arxiv.org/pdf/2602.00040", "abs": "https://arxiv.org/abs/2602.00040", "authors": ["Haonan Shi", "Dehua Shuai", "Liming Wang", "Xiyang Liu", "Long Tian"], "title": "Enhancing few-shot time series forecasting with LLM-guided diffusion", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series forecasting in specialized domains is often constrained by limited data availability, where conventional models typically require large-scale datasets to effectively capture underlying temporal dynamics. To tackle this few-shot challenge, we propose LTSM-DIFF (Large-scale Temporal Sequential Memory with Diffusion), a novel learning framework that integrates the expressive power of large language models with the generative capability of diffusion models. Specifically, the LTSM module is fine-tuned and employed as a temporal memory mechanism, extracting rich sequential representations even under data-scarce conditions. These representations are then utilized as conditional guidance for a joint probability diffusion process, enabling refined modeling of complex temporal patterns. This design allows knowledge transfer from the language domain to time series tasks, substantially enhancing both generalization and robustness. Extensive experiments across diverse benchmarks demonstrate that LTSM-DIFF consistently achieves state-of-the-art performance in data-rich scenarios, while also delivering significant improvements in few-shot forecasting. Our work establishes a new paradigm for time series analysis under data scarcity.", "AI": {"tldr": "提出了一种结合大规模语言模型和扩散模型的时间序列预测框架LTSM-DIFF，以解决数据稀缺条件下的时间序列预测问题。", "motivation": "传统时间序列预测模型需要大量数据来有效捕捉其潜在动态，在数据稀缺条件下难以实现准确的预测。为此，本文提出了一个创新的学习框架，利用大规模语言模型和扩散模型的结合增强少量样本情况下的时间序列预测能力。", "method": "该方法通过训练LTSM模块作为时序记忆机制提取丰富的序列表示，并将其用于引导联合概率扩散过程，从而对复杂的时间模式进行更精细建模。此外，它还实现了从文本领域到时间序列任务的知识转移。", "result": "在多个基准测试上实验表明，无论是在数据充裕还是稀少的情况下，LTSM-DIFF都能达到最先进的预测性能，并且显著改善了少量样本条件下的预测效果。", "conclusion": "本研究建立了新的范式来解决数据稀缺条件下时间序列分析的问题。"}}
{"id": "2602.00038", "pdf": "https://arxiv.org/pdf/2602.00038", "abs": "https://arxiv.org/abs/2602.00038", "authors": ["Guanghao Zhou", "Panjia Qiu", "Cen Chen", "Hongyu Li", "Mingyuan Chu", "Xin Zhang", "Jun Zhou"], "title": "LSSF: Safety Alignment for Large Language Models through Low-Rank Safety Subspace Fusion", "categories": ["cs.CY", "cs.AI"], "comment": "Accepted in ACL 2025 Main Conference", "summary": "The safety mechanisms of large language models (LLMs) exhibit notable fragility, as even fine-tuning on datasets without harmful content may still undermine their safety capabilities. Meanwhile, existing safety alignment methods predominantly rely on the fine-tuning process, which inadvertently leads to the increased complexity and computational resources required. To address these issues, we introduce LSSF, a novel safety re-alignment framework with \\underline{L}ow-Rank \\underline{S}afety \\underline{S}ubspace \\underline{F}usion. Our proposed method exploits the low-rank characteristics of safety information in LLMs by constructing a low-rank projection matrix to extract the principal components of safety vectors. Notably, this projection matrix represents the low-rank safety subspace of the LLMs, which we have observed to remain stable during fine-tuning process and is isolated from the model's general capabilities. These principal components are used to effectively restore safety alignment when combined with fine-tuned LLMs through linear arithmetic. Additionally, to account for the varying encoding densities of safety information across different layers of LLMs, we propose a novel metric called safety singular value entropy. This metric quantifies the encoding density and allows for the dynamic computation of the safety-critical rank for each safety vector. Extensive experiments demonstrate that our proposed post-hoc alignment method can effectively restore the safety alignment of fine-tuned models with minimal impact on their performance in downstream tasks.", "AI": {"tldr": "提出了一种新的大型语言模型安全对齐框架LSSF，通过低秩安全子空间融合来恢复经过微调后的模型的安全性。", "motivation": "现有方法依赖于微调过程进行安全性调整，导致复杂性和计算资源增加。为了提高效率并减少影响，本文旨在开发一种更有效的后处理安全对齐方法。", "method": "利用大型语言模型中安全信息的低秩特性，构建低秩投影矩阵以提取主要的安全向量成分，并通过线性运算将其与微调后的模型结合以恢复安全性。还提出了一种新的度量标准：安全奇异值熵，用于量化不同层中安全信息的编码密度。", "result": "实验表明，该方法可以有效地在不影响下游任务性能的情况下恢复经过微调的大型语言模型的安全性。", "conclusion": "LSSF框架通过低秩安全子空间融合实现了更高效和精确的大规模语言模型安全性维护。"}}
{"id": "2602.00037", "pdf": "https://arxiv.org/pdf/2602.00037", "abs": "https://arxiv.org/abs/2602.00037", "authors": ["Yuanhong Wu", "Wei Ye", "Jingyan Xu", "D. Frank Hsu"], "title": "Bitcoin Price Prediction using Machine Learning and Combinatorial Fusion Analysis", "categories": ["q-fin.ST", "cs.AI", "cs.CE", "cs.LG"], "comment": "8 pages, 5 figures, 3 tables; Accepted to 2025 IEEE Conference on Artificial Intelligence (IEEE CAI)", "summary": "In this work, we propose to apply a new model fusion and learning paradigm, known as Combinatorial Fusion Analysis (CFA), to the field of Bitcoin price prediction. Price prediction of financial product has always been a big topic in finance, as the successful prediction of the price can yield significant profit. Every machine learning model has its own strength and weakness, which hinders progress toward robustness. CFA has been used to enhance models by leveraging rank-score characteristic (RSC) function and cognitive diversity in the combination of a moderate set of diverse and relatively well-performed models. Our method utilizes both score and rank combinations as well as other weighted combination techniques. Key metrics such as RMSE and MAPE are used to evaluate our methodology performance. Our proposal presents a notable MAPE performance of 0.19\\%. The proposed method greatly improves upon individual model performance, as well as outperforms other Bitcoin price prediction models.", "AI": {"tldr": "提出使用组合分析法(CFA)对比特币价格进行预测。", "motivation": "利用机器学习模型的各自优点，通过CFA增强模型性能，并提高比特币价格预测的准确性。", "method": "采用组合分析法结合评分和排名组合以及其他加权组合技术来优化比特币价格预测。", "result": "实验结果表明该方法在平均百分比误差(MAPE)方面达到了0.19%，优于单一模型和其他预测模型。", "conclusion": "CFA可以有效提升比特币价格预测的准确性，具有较高的实际应用价值。"}}
{"id": "2602.00036", "pdf": "https://arxiv.org/pdf/2602.00036", "abs": "https://arxiv.org/abs/2602.00036", "authors": ["Keishu Utimula"], "title": "LOGOS-CA: A Cellular Automaton Using Natural Language as State and Rule", "categories": ["nlin.CG", "cs.AI", "cs.FL", "cs.NE"], "comment": null, "summary": "Large Language Models (LLMs), trained solely on massive text data, have achieved high performance on the Winograd Schema Challenge (WSC), a benchmark proposed to measure commonsense knowledge and reasoning abilities about the real world. This suggests that the language produced by humanity describes a significant portion of the world with considerable nuance. In this study, we attempt to harness the high expressive power of language within cellular automata. Specifically, we express cell states and rules in natural language and delegate their updates to an LLM. Through this approach, cellular automata can transcend the constraints of merely numerical states and fixed rules, providing us with a richer platform for simulation. Here, we propose LOGOS-CA (Language Oriented Grid Of Statements - Cellular Automaton) as a natural framework to achieve this and examine its capabilities. We confirmed that LOGOS-CA successfully performs simple forest fire simulations and also serves as an intriguing subject for investigation from an Artificial Life (ALife) perspective. In this paper, we report the results of these experiments and discuss directions for future research using LOGOS-CA.", "AI": {"tldr": "利用大型语言模型在自然语言状态下实现元胞自动机，探索其模拟能力和人工智能生命研究的潜力。", "motivation": "基于大型语言模型具备强大表达能力，尝试将自然语言作为状态和规则应用于元胞自动机中，以拓展传统元胞自动机的功能。", "method": "提出LOGOS-CA框架，利用大型语言模型更新元胞的状态，并通过简单的森林火灾模拟验证其性能。", "result": "成功实现简单森林火灾模拟，显示了该方法在模拟和人工智能生命研究方面的潜力。", "conclusion": "展示了一种将自然语言融入元胞自动机的新途径，为未来的研究开辟新的方向。"}}
{"id": "2602.00034", "pdf": "https://arxiv.org/pdf/2602.00034", "abs": "https://arxiv.org/abs/2602.00034", "authors": ["Matias Hoyl"], "title": "Synthetic Student Responses: LLM-Extracted Features for IRT Difficulty Parameter Estimation", "categories": ["cs.CY", "cs.AI"], "comment": "17 pages, 7 figures", "summary": "Educational assessment relies heavily on knowing question difficulty, traditionally determined through resource-intensive pre-testing with students. This creates significant barriers for both classroom teachers and assessment developers. We investigate whether Item Response Theory (IRT) difficulty parameters can be accurately estimated without student testing by modeling the response process and explore the relative contribution of different feature types to prediction accuracy. Our approach combines traditional linguistic features with pedagogical insights extracted using Large Language Models (LLMs), including solution step count, cognitive complexity, and potential misconceptions. We implement a two-stage process: first training a neural network to predict how students would respond to questions, then deriving difficulty parameters from these simulated response patterns. Using a dataset of over 250,000 student responses to mathematics questions, our model achieves a Pearson correlation of approximately 0.78 between predicted and actual difficulty parameters on completely unseen questions.", "AI": {"tldr": "通过合成学生响应，利用大型语言模型提取的特征来估计IRT难度参数，无需实际学生测试。", "motivation": "传统上，确定问题难度需要大量的预测试资源，这对教师和评估开发者构成障碍。本文探索是否可以通过建模响应过程，使用大型语言模型（LLMs）提取的语言学和教育学特征准确地估计IRT难度参数。", "method": "首先训练神经网络预测学生对问题的反应模式，然后从这些模拟回应中推导出难度参数。该方法结合了传统语言学特征和通过LLM提取的认知复杂性和潜在误区等教育学见解。", "result": "在数学题目的数据集上，模型对于未见过的问题实现了约0.78的相关系数。", "conclusion": "本文提出的方法可以有效地估计IRT难度参数，从而降低实际学生测试的需求和资源消耗。"}}
{"id": "2602.00032", "pdf": "https://arxiv.org/pdf/2602.00032", "abs": "https://arxiv.org/abs/2602.00032", "authors": ["Mengting Wei", "Aditya Gulati", "Guoying Zhao", "Nuria Oliver"], "title": "Happy Young Women, Grumpy Old Men? Emotion-Driven Demographic Biases in Synthetic Face Generation", "categories": ["cs.CY", "cs.AI", "cs.CV"], "comment": "23 pages, 11 figures", "summary": "Synthetic face generation has rapidly advanced with the emergence of text-to-image (T2I) and of multimodal large language models, enabling high-fidelity image production from natural-language prompts. Despite the widespread adoption of these tools, the biases, representational quality, and cross-cultural consistency of these models remain poorly understood. Prior research on biases in the synthetic generation of human faces has examined demographic biases, yet there is little research on how emotional prompts influence demographic representation and how models trained in different cultural and linguistic contexts vary in their output distributions. We present a systematic audit of eight state-of-the-art T2I models comprising four models developed by Western organizations and four developed by Chinese institutions, all prompted identically. Using state-of-the-art facial analysis algorithms, we estimate the gender, race, age, and attractiveness levels in the generated faces. To measure the deviations from global population statistics, we apply information-theoretic bias metrics including Kullback-Leibler and Jensen-Shannon divergences. Our findings reveal persistent demographic and emotion-conditioned biases in all models regardless of their country of origin. We discuss implications for fairness, socio-technical harms, governance, and the development of transparent generative systems.", "AI": {"tldr": "该论文通过分析八种最先进的文本到图像(T2I)模型，研究了情感提示对生成人脸的性别、种族、年龄和吸引力水平的影响，并评估了这些模型在不同文化和语言背景下的偏差。", "motivation": "当前对于合成面孔生成工具中存在的偏见、表示质量和跨文化一致性了解不足。此论文旨在探讨情感条件化的偏见以及不同文化背景下训练的模型输出分布的变化，以提高透明度并减少不公平现象。", "method": "使用了八种不同的T2I模型进行实验，并通过先进的面部分析算法来估计生成人脸的性别、种族、年龄和吸引力水平；应用信息理论偏差指标包括Kullback-Leibler散度和Jensen-Shannon散度，评估输出与全球人口统计学之间的差异。", "result": "发现所有模型无论其起源地如何，在情感条件化的偏见上都存在持续性问题。这些偏见涉及到性别、种族、年龄等因素的分布偏差。", "conclusion": "该研究揭示了生成模型中普遍存在的情感驱动的人口统计特征偏见，强调了在公平性、社会技术危害管理和透明化方面的重要性，并提出改进方向以降低潜在的社会负面影响。"}}
{"id": "2602.00029", "pdf": "https://arxiv.org/pdf/2602.00029", "abs": "https://arxiv.org/abs/2602.00029", "authors": ["Yao Zhang", "Hongyin Zhu"], "title": "Construct, Align, and Reason: Large Ontology Models for Enterprise Knowledge Management", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Enterprise-scale knowledge management faces significant challenges in integrating multi-source heterogeneous data and enabling effective semantic reasoning. Traditional knowledge graphs often struggle with implicit relationship discovery and lack sufficient semantic understanding for complex question answering. To address these limitations, we introduce a unified construct--align--reason framework, the large ontology model (LOM). We first build a dual-layer enterprise ontology from structured databases and unstructured text, subsequently fusing these sources into a comprehensive enterprise ontology. To enable instruction-aligned reasoning, we propose a unified three-stage training pipeline: ontology instruction fine-tuning to improve structural understanding; text-ontology grounding to strengthen node semantic encoding; and multi-task instruction tuning on ontology-language pairs with curriculum learning to enhance semantic reasoning and generation. We also construct comprehensive training and evaluation datasets covering diverse ontology reasoning tasks. On this benchmark, our 4B-parameter LOM achieves 89.47% accuracy and outperforms DeepSeek-V3.2 on complex graph reasoning, indicating effective fusion of ontology structure and language.", "AI": {"tldr": "构建了一个统一的构造--对齐--推理框架，即大型本体模型（LOM），以解决企业知识管理中的多源异构数据集成和语义推理挑战。", "motivation": "传统知识图谱在隐含关系发现方面存在不足，并且缺乏足够的语义理解来进行复杂的问题回答。为此提出了一种新的方法来整合多种来源的数据并增强语义推理能力。", "method": "提出了一个三阶段统一训练流水线，包括本体指令微调、文本-本体对齐和基于课程学习的多任务指令调整以提升结构理解和生成能力，并构建了全面的训练和评估数据集。", "result": "40亿参数量的LOM在复杂图形推理方面表现出色，在基准测试中达到了89.47%的准确率，优于DeepSeek-V3.2模型。", "conclusion": "研究提出的方法有效融合了本体结构与语言知识，并在企业规模的知识管理任务上取得了显著的效果。"}}
{"id": "2602.00027", "pdf": "https://arxiv.org/pdf/2602.00027", "abs": "https://arxiv.org/abs/2602.00027", "authors": ["Zhenyu Pu", "Yu Yang", "Lun Yang", "Qing-Shan Jia", "Xiaohong Guan", "Costas J. Spanos"], "title": "Representation Learning Enhanced Deep Reinforcement Learning for Optimal Operation of Hydrogen-based Multi-Energy Systems", "categories": ["cs.LG", "cs.AI", "eess.SY"], "comment": "14 pages, 7 figures", "summary": "Hydrogen-based multi-energy systems (HMES) have emerged as a promising low-carbon and energy-efficient solution, as it can enable the coordinated operation of electricity, heating and cooling supply and demand to enhance operational flexibility, improve overall energy efficiency, and increase the share of renewable integration. However, the optimal operation of HMES remains challenging due to the nonlinear and multi-physics coupled dynamics of hydrogen energy storage systems (HESS) (consisting of electrolyters, fuel cells and hydrogen tanks) as well as the presence of multiple uncertainties from supply and demand. To address these challenges, this paper develops a comprehensive operational model for HMES that fully captures the nonlinear dynamics and multi-physics process of HESS. Moreover, we propose an enhanced deep reinforcement learning (DRL) framework by integrating the emerging representation learning techniques, enabling substantially accelerated and improved policy optimization for spatially and temporally coupled complex networked systems, which is not provided by conventional DRL. Experimental studies based on real-world datasets show that the comprehensive model is crucial to ensure the safe and reliable of HESS. In addition, the proposed SR-DRL approaches demonstrate superior convergence rate and performance over conventional DRL counterparts in terms of reducing the operation cost of HMES and handling the system operating constraints. Finally, we provide some insights into the role of representation learning in DRL, speculating that it can reorganize the original state space into a well-structured and cluster-aware geometric representation, thereby smoothing and facilitating the learning process of DRL.", "AI": {"tldr": "提出了一种改进的深度强化学习框架，用于优化氢基多能源系统的运行。", "motivation": "为了解决氢基多能源系统中由于氢储能系统的非线性和多物理耦合动力学以及供需不确定性而导致的操作挑战。", "method": "开发了一个全面的HMES操作模型，并提出了结合表示学习技术的增强深度强化学习框架，以加速和改进复杂网络化系统的策略优化。", "result": "实验研究表明该综合模型对保证氢储能系统安全可靠至关重要；提出的SR-DRL方法在降低运营成本和处理系统运行约束方面优于传统DRL方法。", "conclusion": "提出了代表学习可以重组原始状态空间为结构良好且集群感知的几何表示，从而平滑并促进深度强化学习的学习过程。"}}
{"id": "2602.00026", "pdf": "https://arxiv.org/pdf/2602.00026", "abs": "https://arxiv.org/abs/2602.00026", "authors": ["Ahmad Samer Wazan"], "title": "Strategies for Creating Uncertainty in the AI Era to Trigger Students Critical Thinking: Pedagogical Design, Assessment Rubric, and Exam System", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Generative AI challenges traditional assessments by allowing students to produce correct answers without demonstrating understanding or reasoning. Rather than prohibiting AI, this work argues that one way to integrate AI into education is by creating uncertain situations with the help of AI models and using thinking-oriented teaching approaches, where uncertainty is a central pedagogical concept for stimulating students critical thinking. Drawing on epistemology and critical thinking research studies, we propose designing learning activities and assessments around the inherent limitations of both AI models and instructors. This encourages students to reason, question, and justify their final answers. We show how explicitly controlling AI behavior during exams (such as preventing direct answers or generating plausible but flawed responses) prevents AI from becoming a shortcut to certainty. To support this pedagogy, we introduce MindMosaicAIExam, an exam system that integrates controllable AI tools and requires students to provide initial answers, critically evaluate AI outputs, and iteratively refine their reasoning. We also present an evaluation rubric designed to assess critical thinking based on students reasoning artifacts collected by the exam system.", "AI": {"tldr": "论文探讨了在AI时代通过创设不确定性来激发学生批判性思维的教学策略，包括设计学习活动、评估标准和考试系统。", "motivation": "面对生成式AI对传统评估方法的挑战，提出一种新的教学方式，即利用AI模型制造不确定情境以刺激学生的批判性思考。", "method": "基于认识论及批判性思维的研究成果，论文提出了围绕AI模型局限性和教师指导设计学习活动和评估体系的方法，并引入MindMosaicAIExam系统来控制AI行为，要求学生进行初步回答、评价AI输出并反复修正其推理过程。", "result": "提出了一种新的考试评分标准，旨在根据考试系统的收集的学生推理痕迹来评估他们的批判性思维能力。", "conclusion": "通过创设不确定情境和使用MindMosaicAIExam系统，可以有效激发学生进行批判性思考，并提供一种新的方法论来应对教育中的AI挑战。"}}
{"id": "2602.00021", "pdf": "https://arxiv.org/pdf/2602.00021", "abs": "https://arxiv.org/abs/2602.00021", "authors": ["Mohammed Saqr", "Sonsoles López-Pernas", "Santtu Tikka", "Markus Wolfgang Hermann Spitzer"], "title": "Early Warning Signals Appear Long Before Dropping Out: An Idiographic Approach Grounded in Complex Dynamic Systems Theory", "categories": ["cs.CY", "cs.AI"], "comment": "Accepted as a full paper at Learning Analytics & Knowledge (LAK) conference 2026 (ACM Proceedings)", "summary": "The ability to sustain engagement and recover from setbacks (i.e., resilience) -- is fundamental for learning. When resilience weakens, students are at risk of disengagement and may drop out and miss on opportunities. Therefore, predicting disengagement long before it happens during the window of hope is important. In this article, we test whether early warning signals of resilience loss, grounded in the concept of critical slowing down (CSD) can forecast disengagement before dropping out. CSD has been widely observed across ecological, climate, and neural systems, where it precedes tipping points into catastrophic failure (dropping out in our case). Using 1.67 million practice attempts from 9,401 students who used a digital math learning environment, we computed CSD indicators: autocorrelation, return rate, variance, skewness, kurtosis, and coefficient of variation. We found that 88.2% of students exhibited CSD signals prior to disengagement, with warnings clustering late in activity and before practice ceased (dropping out). Our results provide the first evidence of CSD in education, suggesting that universal resilience dynamics also govern social systems such as human learning. These findings offer a practical indicator for early detection of vulnerability and supporting learners across different applications and contexts long before critical events happen. Most importantly, CSD indicators arise universally, independent of the mechanisms that generate the data, offering new opportunities for portability across contexts, data types, and learning environments.", "AI": {"tldr": "本文利用复杂动态系统理论中的临界减缓（CSD）概念，通过分析学生的练习行为数据，预测学生在辍学前的参与度下降。", "motivation": "提高学习持续性和从挫折中恢复的能力对教育至关重要。当这种能力减弱时，学生可能会失去参与度并最终辍学。因此，提前识别这些风险具有重要意义。", "method": "基于临界减缓（CSD）理论，分析了9,401名学生的167万次练习尝试数据。计算了六个指标：自相关性、返回率、方差、偏度、峰度和变异系数。", "result": "研究发现，在辍学前的88.2%的学生显示出临界减缓信号，这些预警信号集中在活动后期，并在学生停止练习前出现。", "conclusion": "这是首次在教育领域证明了临界减缓现象。这表明普遍存在的韧性动态也适用于如人类学习的社会系统中。这些发现提供了早期检测脆弱性的实际指标，并为支持学习者提供了新机会，尤其是在关键事件发生之前。"}}
{"id": "2602.00020", "pdf": "https://arxiv.org/pdf/2602.00020", "abs": "https://arxiv.org/abs/2602.00020", "authors": ["Yingquan Wang", "Tianyu Wei", "Qinsi Li", "Li Zeng"], "title": "Beyond Static Question Banks: Dynamic Knowledge Expansion via LLM-Automated Graph Construction and Adaptive Generation", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Personalized education systems increasingly rely on structured knowledge representations to support adaptive learning and question generation. However, existing approaches face two fundamental limitations. First, constructing and maintaining knowledge graphs for educational content largely depends on manual curation, resulting in high cost and poor scalability. Second, most personalized education systems lack effective support for state-aware and systematic reasoning over learners' knowledge, and therefore rely on static question banks with limited adaptability. To address these challenges, this paper proposes a Generative GraphRAG framework for automated knowledge modeling and personalized exercise generation. It consists of two core modules. The first module, Automated Hierarchical Knowledge Graph Constructor (Auto-HKG), leverages LLMs to automatically construct hierarchical knowledge graphs that capture structured concepts and their semantic relations from educational resources. The second module, Cognitive GraphRAG (CG-RAG), performs graph-based reasoning over a learner mastery graph and combines it with retrieval-augmented generation to produce personalized exercises that adapt to individual learning states. The proposed framework has been deployed in real-world educational scenarios, where it receives favorable user feedback, suggesting its potential to support practical personalized education systems.", "AI": {"tldr": "提出了一种基于LLM的自动生成知识图谱和个性化生成练习的框架，以解决现有教育系统的局限性。", "motivation": "现有的教育系统由于依赖人工构建知识图谱且缺乏对学习者状态的认知而存在高成本、低适应性和扩展性的问题。", "method": "提出了一个由自动层级知识图谱构造器和认知GraphRAG模块组成的框架，前者利用LLM从教育资源中自动生成结构化的概念及其语义关系的层级图谱；后者基于学习者的掌握情况进行图形推理并结合检索增强生成个性化练习题。", "result": "该框架在实际教育场景中的应用收到了良好的用户反馈，表明它有潜力支持实用性的个性化教育系统。", "conclusion": "通过LLM自动化知识建模和个性化的练习生成可以显著提高教育系统的适应性和效率。"}}
{"id": "2602.00019", "pdf": "https://arxiv.org/pdf/2602.00019", "abs": "https://arxiv.org/abs/2602.00019", "authors": ["Fukang Ge", "Jiarui Zhu", "Linjie Zhang", "Haowen Xiao", "Xiangcheng Bao", "Fangnan Xie", "Danyang Chen", "Yanrui Lu", "Yuting Wang", "Ziqian Guan", "Lin Gu", "Jinhao Bi", "Yingying Zhu"], "title": "AutoBinder Agent: An MCP-Based Agent for End-to-End Protein Binder Design", "categories": ["q-bio.BM", "cs.AI"], "comment": "4 pages, 3 figures", "summary": "Modern AI technologies for drug discovery are distributed across heterogeneous platforms-including web applications, desktop environments, and code libraries-leading to fragmented workflows, inconsistent interfaces, and high integration overhead. We present an agentic end-to-end drug design framework that leverages a Large Language Model (LLM) in conjunction with the Model Context Protocol (MCP) to dynamically coordinate access to biochemical databases, modular toolchains, and task-specific AI models. The system integrates four state-of-the-art components: MaSIF (MaSIF-site and MaSIF-seed-search) for geometric deep learning-based identification of protein-protein interaction (PPI) sites, Rosetta for grafting protein fragments onto protein backbones to form mini proteins, ProteinMPNN for amino acid sequences redesign, and AlphaFold3 for near-experimental accuracy in complex structure prediction. Starting from a target structure, the framework supports de novo binder generation via surface analysis, scaffold grafting and pose construction, sequence optimization, and structure prediction. Additionally, by replacing rigid, script-based workflows with a protocol-driven, LLM-coordinated architecture, the framework improves reproducibility, reduces manual overhead, and ensures extensibility, portability, and auditability across the entire drug design process.", "AI": {"tldr": "本文介绍了一种基于大型语言模型和Model Context Protocol的药物设计框架，用于蛋白质结合剂的设计。", "motivation": "现代AI技术在药物发现中的应用分散于不同的平台，导致工作流碎片化、接口不一致以及集成成本高。为解决这些问题，提出了一个能够统一这些组件并提高可扩展性、便携性和审计性的新型框架。", "method": "该系统整合了MaSIF, Rosetta, ProteinMPNN和AlphaFold3等多个先进工具，通过表面分析、支架嫁接与构象构建、序列优化以及结构预测等步骤实现从目标结构出发的自动生成蛋白质结合剂。", "result": "本文提出的方法能够改善药物设计过程中的可重复性，并且减少手动操作成本。同时，它还确保整个流程具备更好的扩展性、便携性和审计能力。", "conclusion": "该研究展示了一种新型框架在药物发现领域的应用前景，有望简化工作流并提升整体效率和效果。"}}
{"id": "2602.00018", "pdf": "https://arxiv.org/pdf/2602.00018", "abs": "https://arxiv.org/abs/2602.00018", "authors": ["Conrad Borchers", "Hannah Deininger", "Zachary A. Pardos"], "title": "Toward Trait-Aware Learning Analytics", "categories": ["cs.HC", "cs.CY"], "comment": "Full research paper accepted for publication in the Learning Analytics and Knowledge (LAK) 2026 conference proceedings", "summary": "Learning analytics (LA) draws from the learning sciences to interpret learner behavior and inform system design. Yet, past personalization remains largely at the content or performance level (during learner-system interactions), overlooking relatively stable individual differences such as personality (unfolding over long-term learning trajectories such as college degrees). The latter could bring underappreciated benefits to the design, implementation, and impact of LA. In this position paper, we conduct an ad hoc literature review and argue for an expanded framing of LA that centers on learner traits as key to both interpreting and designing close-the-loop experiments in LA. We show that personality traits are relevant to LA's central outcomes (e.g., engagement and achievement) and conducive to action, as their established ties to human-computer interaction (HCI) inform how systems time, frame, and personalize support. Drawing inspiration from HCI, where psychometrics inform personalization strategies, we propose that LA can evolve by treating traits not only as predictive features but as design resources and moderators of analytics efficacy. In line with past position papers published at LAK, we present a research agenda grounded in the LA cycle and discuss methodological and ethical challenges.", "AI": {"tldr": "本文提出了在学习分析中考虑个性特征的重要性，以提升个性化设计和系统效能。", "motivation": "过往的学习个性化主要集中在内容或绩效层面，忽视了长期稳定的人格特质。这些人格特质对解释和设计闭环实验至关重要，并可以提高系统的效率与效果。", "method": "本文通过非正式文献回顾，强调在学习分析中引入人格特征的重要性，借鉴人机交互领域的方法论，提出利用心理学测量信息来提升系统个性化策略的设计。", "result": "未直接呈现具体结果数据，但讨论了将人格特质作为设计资源和效能调节因子的潜在价值。", "conclusion": "论文主张通过整合人格特质，学习分析可以更好地支持长期的学习轨迹和个人化体验，并提出了相关的研究议程。"}}
{"id": "2602.00017", "pdf": "https://arxiv.org/pdf/2602.00017", "abs": "https://arxiv.org/abs/2602.00017", "authors": ["Benyamin Tabarsi", "Wenbo Li", "Tahreem Yasir", "Aryan Santhosh Kumar", "Laura Widman", "Dongkuan Xu", "Tiffany Barnes"], "title": "SafeTalkCoach: Diversity-Driven Multi-Agent Simulation for Parent-Teen Health Conversations", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "comment": null, "summary": "The importance of effective parent-child communication about sexual health is widely acknowledged, but real-world data on these conversations is scarce and challenging to collect, due to their private and sensitive nature. Although LLMs have been widely adopted in dialogue generation, they may deviate from best practices and frequently lack realism and diversity. We introduce SafeTalkCoach, a diversity-driven multi-agent dialogue generation framework that simulates parent-child conversations about sexual health, and present an accompanying dataset. SafeTalkCoach integrates crowd-sourced and synthesized scenarios, established sexual health guidelines, evidence-based personas, adaptive control modules, and hierarchical diversification. Through evaluations, we demonstrate that SafeTalkCoach generates diverse conversations while maintaining realism, communication quality, and controllability in practice. Our goal is that the SafeTalkCoach framework and the dataset support both AI research and health communications practices.", "AI": {"tldr": "SafeTalkCoach是一个模拟父母和青少年关于性健康对话的框架，旨在生成多样化、现实主义且高质量的对话。", "motivation": "现实中缺乏有效的父母与子女之间关于性健康的交流数据，这使得研究面临挑战。现有的大型语言模型在对话生成上可能偏离最佳实践，缺少真实性和多样性。SafeTalkCoach旨在解决这些问题，并支持AI研究和健康传播实践。", "method": "SafeTalkCoach使用众包和合成场景、基于证据的人格设定以及层次化多样化策略来模拟对话。框架还集成了自适应控制模块以确保对话的质量与可控性。", "result": "通过评估，SafeTalkCoach生成的对话在多样性和现实主义上都表现出色，并且保持了交流质量和可控制性。", "conclusion": "SafeTalkCoach及其配套数据集为AI研究和健康传播实践提供了强有力的支持。"}}
{"id": "2602.00016", "pdf": "https://arxiv.org/pdf/2602.00016", "abs": "https://arxiv.org/abs/2602.00016", "authors": ["Jiongchi Yu", "Yuhan Ma", "Xiaoyu Zhang", "Junjie Wang", "Qiang Hu", "Chao Shen", "Xiaofei Xie"], "title": "PTCBENCH: Benchmarking Contextual Stability of Personality Traits in LLM Systems", "categories": ["cs.CL", "cs.AI"], "comment": "28 pages", "summary": "With the increasing deployment of large language models (LLMs) in affective agents and AI systems, maintaining a consistent and authentic LLM personality becomes critical for user trust and engagement. However, existing work overlooks a fundamental psychological consensus that personality traits are dynamic and context-dependent. To bridge this gap, we introduce PTCBENCH, a systematic benchmark designed to quantify the consistency of LLM personalities under controlled situational contexts. PTCBENCH subjects models to 12 distinct external conditions spanning diverse location contexts and life events, and rigorously assesses the personality using the NEO Five-Factor Inventory. Our study on 39,240 personality trait records reveals that certain external scenarios (e.g., \"Unemployment\") can trigger significant personality changes of LLMs, and even alter their reasoning capabilities. Overall, PTCBENCH establishes an extensible framework for evaluating personality consistency in realistic, evolving environments, offering actionable insights for developing robust and psychologically aligned AI systems.", "AI": {"tldr": "PTCBENCH是一个用于评估大型语言模型(LLM)在不同情境下人格一致性基准测试。", "motivation": "现有的研究忽视了个性特质是动态和情境依赖的这一心理共识，导致LLM的人格不一致。为了填补这一空白，该研究提出了一个系统化的基准测试框架，旨在量化LLM在多种情景下的个性一致性。", "method": "PTCBENCH将模型置于12种不同的外部条件中进行评估，并使用NEO五因素量表来衡量个性。", "result": "研究表明某些外部情境（如失业）会导致LLM的人格发生显著变化，甚至影响其推理能力。共有39,240个人格特质记录参与了实验。", "conclusion": "PTCBENCH建立了一个可扩展的框架用于评估真实环境中LLM人格的一致性，并为开发稳健的心理学一致AI系统提供了实用见解。"}}
{"id": "2602.00015", "pdf": "https://arxiv.org/pdf/2602.00015", "abs": "https://arxiv.org/abs/2602.00015", "authors": ["Xun Xu"], "title": "G-MemLLM: Gated Latent Memory Augmentation for Long-Context Reasoning in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, yet they remain constrained by the finite capacity of their context windows and the inherent difficulty of maintaining long-term factual consistency during multi-hop reasoning. While existing methods utilize context compression or recurrent tokens, they often suffer from ``context rot'' or the dilution of information over long horizons. In this paper, we propose \\textbf{G-MemLLM}, a memory-augmented architecture that integrates a frozen LLM backbone with a trainable \\textbf{Latent Memory Bank}. Our key innovation is a GRU-style gated update logic that allows the model to selectively update, preserve, or overwrite latent memory slots, preventing the vanishing gradients of knowledge common in recurrent systems. We evaluate G-MemLLM across scales, from GPT-2 (124M) to Llama 3.1 (8B), on the HotpotQA and Zero-Shot Relation Extraction (ZsRE) benchmarks. Our results demonstrate that G-MemLLM significantly enhances multi-hop reasoning and relational precision, achieving a 13.3\\% accuracy boost on ZsRE for Llama 3.1-8B, and it also yields improvements across model scales, boosting Answer F1 by 8.56 points for GPT-2 and increasing Supporting Fact F1 by 6.89 points for Llama 3.1-8B on HotpotQA.", "AI": {"tldr": "G-MemLLM是一种集成冻结的大型语言模型骨干和可训练隐式记忆库的记忆增强架构，通过门控更新逻辑改善多跳推理。", "motivation": "现有的方法在处理长文本时存在信息稀释的问题，限制了长期事实一致性和多步推理的能力。为了克服这些问题，研究者提出了G-MemLLM。", "method": "G-MemLLM利用了一种类似GRU的门控更新逻辑来管理隐式记忆槽的内容，并通过实验证明其在不同规模模型上的有效性。", "result": "实验结果显示，G-MemLLM提高了多步推理和关系提取精度，在Llama 3.1-8B上ZsRE任务中准确率提升13.3%，并且在其他基准测试中也取得了显著改进。", "conclusion": "研究结论表明，通过引入隐式记忆增强的架构，G-MemLLM能够有效解决长文本推理中的信息稀释问题，并改善模型性能。"}}
{"id": "2602.00014", "pdf": "https://arxiv.org/pdf/2602.00014", "abs": "https://arxiv.org/abs/2602.00014", "authors": ["Pierrick Pochelu", "Hyacinthe Cartiaux", "Julien Schleich"], "title": "What Artificial Intelligence can do for High-Performance Computing systems?", "categories": ["cs.DC", "cs.AI"], "comment": "ef:Engineering Applications of Artificial Intelligence, Volume 164, Part B, 15 January 2026, 113248", "summary": "High-performance computing (HPC) centers consume substantial power, incurring environmental and operational costs. This review assesses how artificial intelligence (AI), including machine learning (ML) and optimization, improves the efficiency of operational HPC systems. Approximately 1,800 publications from 2019 to 2025 were manually screened using predefined inclusion/exclusion criteria; 74 \"AI for HPC\" papers were retained and grouped into six application areas: performance estimation, performance optimization, scheduling, surrogate modeling, fault detection, and language-model-based automation. Scheduling is the most active area, spanning research-oriented reinforcement-learning schedulers to production-friendly hybrids that combine ML with heuristics. Supervised performance estimation is foundational for both scheduling and optimization. Graph neural networks and time-series models strengthen anomaly detection by capturing spatio-temporal dependencies in production telemetry. Domain-specialized language models for HPC can outperform general-purpose LLMs on targeted coding and automation tasks. Together, these findings highlight integration opportunities such as LLM-based operating-system concepts and underscore the need for advances in MLOps, standardization of AI components, and benchmarking methodology.", "AI": {"tldr": "本文综述了从2019年到2025年间，人工智能技术如何应用于高性能计算系统以提高其效率。", "motivation": "高性能计算中心能耗巨大，产生环境和运营成本。该研究旨在评估AI（包括机器学习和优化）在操作HPC系统的能效提升作用。", "method": "手动筛选了约1800篇从2019年到2025年的论文，并根据预定义的纳入/排除标准保留了74篇“AI for HPC”论文，这些文章被归类为六个应用领域：性能估算、性能优化、调度、代理建模、故障检测和语言模型自动化。", "result": "研究发现，调度是目前最活跃的研究领域。监督学习的性能评估对于调度和优化至关重要。图神经网络和时间序列模型通过捕捉生产遥测中的时空依赖性来加强异常检测。针对高性能计算领域的专业语言模型在特定编码和自动化任务中优于通用LLMs。", "conclusion": "这些发现强调了AI组件、MLOps和基准测试方法标准化方面的整合机会，以及对改进的需求"}}
{"id": "2602.00012", "pdf": "https://arxiv.org/pdf/2602.00012", "abs": "https://arxiv.org/abs/2602.00012", "authors": ["Michael Siebenmann", "Javier Argota Sánchez-Vaquerizo", "Stefan Arisona", "Krystian Samp", "Luis Gisler", "Dirk Helbing"], "title": "OGD4All: A Framework for Accessible Interaction with Geospatial Open Government Data Based on Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.IR"], "comment": "This work has been submitted to the IEEE for possible publication. 7 pages, 6 figures", "summary": "We present OGD4All, a transparent, auditable, and reproducible framework based on Large Language Models (LLMs) to enhance citizens' interaction with geospatial Open Government Data (OGD). The system combines semantic data retrieval, agentic reasoning for iterative code generation, and secure sandboxed execution that produces verifiable multimodal outputs. Evaluated on a 199-question benchmark covering both factual and unanswerable questions, across 430 City-of-Zurich datasets and 11 LLMs, OGD4All reaches 98% analytical correctness and 94% recall while reliably rejecting questions unsupported by available data, which minimizes hallucination risks. Statistical robustness tests, as well as expert feedback, show reliability and social relevance. The proposed approach shows how LLMs can provide explainable, multimodal access to public data, advancing trustworthy AI for open governance.", "AI": {"tldr": "OGD4All是一个基于大型语言模型的框架，旨在增强公民与地理开放政府数据（OGD）之间的交互。", "motivation": "为了提高公民对地空开放政府数据的理解和互动效率，同时保证数据的安全性和可验证性。", "method": "结合语义数据检索、代理推理迭代代码生成以及安全的沙盒执行环境，产生可验证的多模态输出。", "result": "在430个苏黎世城市数据集和11种大型语言模型上测试的199个问题基准中，OGD4All达到98%的数据分析正确率和94%的信息召回率。同时可靠地拒绝没有支持数据的问题，从而降低错误输出的风险。", "conclusion": "该方法展示了如何使用大语言模型提供解释性、多模态的公共数据分析访问方式，推动了开放治理中的可信人工智能技术的应用。"}}
{"id": "2602.00011", "pdf": "https://arxiv.org/pdf/2602.00011", "abs": "https://arxiv.org/abs/2602.00011", "authors": ["Fatima Nasser", "Fouad Trad", "Ammar Mohanna", "Ghada El-Hajj Fuleihan", "Ali Chehab"], "title": "Chained Prompting for Better Systematic Review Search Strategies", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "Accepted in the 3rd International Conference on Foundation and Large Language Models (FLLM2025)", "summary": "Systematic reviews require the use of rigorously designed search strategies to ensure both comprehensive retrieval and minimization of bias. Conventional manual approaches, although methodologically systematic, are resource-intensive and susceptible to subjectivity, whereas heuristic and automated techniques frequently under-perform in recall unless supplemented by extensive expert input. We introduce a Large Language Model (LLM)-based chained prompt engineering framework for the automated development of search strategies in systematic reviews. The framework replicates the procedural structure of manual search design while leveraging LLMs to decompose review objectives, extract and formalize PICO elements, generate conceptual representations, expand terminologies, and synthesize Boolean queries. In addition to query construction, the framework exhibits superior performance in generating well-structured PICO elements relative to existing methods, thereby strengthening the foundation for high-recall search strategies. Evaluation on a subset of the LEADSInstruct dataset demonstrates that the framework attains a 0.9 average recall. These results significantly exceed the performance of existing approaches. Error analysis further highlights the critical role of precise objective specification and terminological alignment in optimizing retrieval effectiveness. These findings confirm the capacity of LLM-based pipelines to yield transparent, reproducible, and high-performing search strategies, and highlight their potential as scalable instruments for supporting evidence synthesis and evidence-based practice.", "AI": {"tldr": "该论文提出了一种基于大型语言模型的框架，用于自动开发系统评价中的搜索策略。", "motivation": "传统手动方法耗时且主观性强，而自动化技术在召回率上通常表现不佳，除非有大量专家输入。因此，作者提出了一个基于LLM的链式提示工程框架来解决这些问题，提高系统的全面性和减少偏差。", "method": "该框架通过使用大型语言模型分解审查目标、提取和形式化PICO元素、生成概念表示、扩展术语并合成布尔查询来自动化搜索策略的开发。同时展示出相对于现有方法更好的结构化PICO元素生成能力。", "result": "在LEADSInstruct数据集的一个子集上的评估表明，该框架达到了0.9的平均召回率，并且显著超过了现有方法的表现。", "conclusion": "这些发现证实了基于LLM的工作流程能够产生透明、可重复和高性能的搜索策略，并强调它们作为支持证据综合和基于证据实践的规模化工具的潜力。"}}
{"id": "2602.00010", "pdf": "https://arxiv.org/pdf/2602.00010", "abs": "https://arxiv.org/abs/2602.00010", "authors": ["Mathieu Ciancone", "Clovis Varangot-Reille", "Marion Schaeffer"], "title": "ChunkNorris: A High-Performance and Low-Energy Approach to PDF Parsing and Chunking", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "In Retrieval-Augmented Generation applications, the Information Retrieval part is central as it provides the contextual information that enables a Large Language Model to generate an appropriate and truthful response. High quality parsing and chunking are critical as efficient data segmentation directly impacts downstream tasks, i.e. Information Retrieval and answer generation. In this paper, we introduce ChunkNorris, a novel heuristic-based technique designed to optimise the parsing and chunking of PDF documents. Our approach does not rely on machine learning and employs a suite of simple yet effective heuristics to achieve high performance with minimal computational overhead. We demonstrate the efficiency of ChunkNorris through a comprehensive benchmark against existing parsing and chunking methods, evaluating criteria such as execution time, energy consumption, and retrieval accuracy. We propose an open-access dataset to produce our results. ChunkNorris outperforms baseline and more advanced techniques, offering a practical and efficient alternative for Information Retrieval tasks. Therefore, this research highlights the potential of heuristic-based methods for real-world, resource-constrained RAG use cases.", "AI": {"tldr": "本文提出了一种名为ChunkNorris的新型启发式方法，用于优化PDF文档的解析和分块处理。", "motivation": "高效的数据分割对信息检索和答案生成等下游任务至关重要。现有的机器学习依赖性较高的方法可能过于复杂且计算成本高。", "method": "ChunkNorris采用一系列简单有效的启发式规则来实现高性能和低能耗，不依赖于机器学习。", "result": "通过与现有解析和分块方法的基准测试对比，ChunkNorris在执行时间、能源消耗和检索准确性等方面表现出优越性。", "conclusion": "ChunkNorris提供了一个实用高效的解决方案，适用于资源受限条件下的信息检索任务。启发式方法展示了其在未来类似案例中的潜力。"}}
{"id": "2602.00009", "pdf": "https://arxiv.org/pdf/2602.00009", "abs": "https://arxiv.org/abs/2602.00009", "authors": ["Samuel Thio", "Matthew Lewis", "Spiros Denaxas", "Richard JB Dobson"], "title": "Unlocking Electronic Health Records: A Hybrid Graph RAG Approach to Safe Clinical AI for Patient QA", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "26 pages, 5 figures, 2 tables", "summary": "Electronic health record (EHR) systems present clinicians with vast repositories of clinical information, creating a significant cognitive burden where critical details are easily overlooked. While Large Language Models (LLMs) offer transformative potential for data processing, they face significant limitations in clinical settings, particularly regarding context grounding and hallucinations. Current solutions typically isolate retrieval methods focusing either on structured data (SQL/Cypher) or unstructured semantic search but fail to integrate both simultaneously. This work presents MediGRAF (Medical Graph Retrieval Augmented Framework), a novel hybrid Graph RAG system that bridges this gap. By uniquely combining Neo4j Text2Cypher capabilities for structured relationship traversal with vector embeddings for unstructured narrative retrieval, MediGRAF enables natural language querying of the complete patient journey. Using 10 patients from the MIMIC-IV dataset (generating 5,973 nodes and 5,963 relationships), we generated enough nodes and data for patient level question answering (QA), and we evaluated this architecture across varying query complexities. The system demonstrated 100\\% recall for factual queries which means all relevant information was retrieved and in the output, while complex inference tasks achieved a mean expert quality score of 4.25/5 with zero safety violations. These results demonstrate that hybrid graph-grounding significantly advances clinical information retrieval, offering a safer, more comprehensive alternative to standard LLM deployments.", "AI": {"tldr": "提出了一种新的混合图RAG系统MediGRAF，用于安全的临床AI问答。", "motivation": "当前EHR系统的海量信息给医生带来了认知负担，并且现有的解决方案无法同时处理结构化和非结构化的数据检索问题。LLMs在临床环境中的应用也受到限制。", "method": "结合Neo4j Text2Cypher能力进行结构化关系遍历与向量嵌入进行非结构化叙述检索，构建了一个能够自然语言查询完整患者历程的系统MediGRAF。", "result": "使用MIMIC-IV数据集中的10个患者生成了足够的节点和数据用于问答测试，对于事实性查询实现了100%召回率，并且复杂推理任务获得了4.25/5的平均专家评分，无安全违规。", "conclusion": "混合图锚定显著提升了临床信息检索的安全性和全面性，为标准LLM部署提供了一个更优替代方案。"}}
{"id": "2602.00008", "pdf": "https://arxiv.org/pdf/2602.00008", "abs": "https://arxiv.org/abs/2602.00008", "authors": ["He Wang", "Ziyu Zhou", "Hanxiang Liu"], "title": "Front-Loaded or Balanced? The Mechanism through Which Review Order Affects Overall Ratings in Premium Service Settings", "categories": ["cs.IR", "cs.CY", "cs.HC", "cs.SI"], "comment": null, "summary": "In the increasingly prevalent landscape of high-quality service contexts, whether consumer evaluation interfaces adopt a rating-first or review-first sequence has become a critical factor shaping rating authenticity and feedback quality. While prior research has primarily examined review content and sentiment, systematic investigation into how evaluation order influences rating outcomes remains limited. Through exploratory analyses, we find that Letterboxd -- which employs a review-first, rating-after mechanism -- exhibits a more centralized rating distribution with fewer extreme scores, whereas Yelp -- which adopts a rating-first, review-after mechanism -- shows a pronounced bimodal distribution with more polarized ratings. Three controlled experiments further demonstrate that in high-quality service contexts, a rating-first (vs. review-first) interface significantly elevates consumers' overall ratings. Mechanism analyses indicate that cognitive effort and affective heuristics serve as dual pathways: a rating-first (vs. review-first) sequence reduces cognitive effort and heightens affective heuristics, thereby increasing rating scores. Moreover, service quality moderates this process. When service quality is low, the rating-first (vs. review-first) sequence instead leads to lower ratings. This research reveals the psychological mechanisms through which evaluation order affects consumer ratings via cognitive and affective pathways. It extends theoretical understanding of online rating formation and offers practical implications for optimizing platform interface design to enhance rating authenticity and credibility.", "AI": {"tldr": "研究了评价顺序如何影响服务评级，探讨了高服务质量情境下先评分后评论与先评论后评分的不同效果及心理机制。", "motivation": "在高质量服务背景下，探究不同评价顺序对消费者反馈质量和评级真实性的影响，以优化平台设计。", "method": "通过Letterboxd和Yelp的实证分析和三项控制实验研究了两种评价顺序的效果，并探讨其背后的认知和情感机制。", "result": "先评分后评论的方式导致更高的总体评分，而先评论后评分则更加集中且极端评分较少；服务质量对这一影响具有调节作用。", "conclusion": "该研究揭示了评价顺序通过认知努力和情感捷径影响消费者评级的心理机制，为平台设计提供了理论指导。"}}
{"id": "2602.00007", "pdf": "https://arxiv.org/pdf/2602.00007", "abs": "https://arxiv.org/abs/2602.00007", "authors": ["MinGyu Jeon", "SuWan Cho", "JaeYoung Shu"], "title": "PPoGA: Predictive Plan-on-Graph with Action for Knowledge Graph Question Answering", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Large Language Models (LLMs) augmented with Knowledge Graphs (KGs) have advanced complex question answering, yet they often remain susceptible to failure when their initial high-level reasoning plan is flawed. This limitation, analogous to cognitive functional fixedness, prevents agents from restructuring their approach, leading them to pursue unworkable solutions. To address this, we propose PPoGA (Predictive Plan-on-Graph with Action), a novel KGQA framework inspired by human cognitive control and problem-solving. PPoGA incorporates a Planner-Executor architecture to separate high-level strategy from low-level execution and leverages a Predictive Processing mechanism to anticipate outcomes. The core innovation of our work is a self-correction mechanism that empowers the agent to perform not only Path Correction for local execution errors but also Plan Correction by identifying, discarding, and reformulating the entire plan when it proves ineffective. We conduct extensive experiments on three challenging multi-hop KGQA benchmarks: GrailQA, CWQ, and WebQSP. The results demonstrate that PPoGA achieves state-of-the-art performance, significantly outperforming existing methods. Our work highlights the critical importance of metacognitive abilities like problem restructuring for building more robust and flexible AI reasoning systems.", "AI": {"tldr": "提出了一种新的知识图谱问答框架PPoGA，该框架通过计划者执行架构和预测处理机制来改进推理规划。", "motivation": "现有的大语言模型在与知识图结合进行复杂问题回答时易受初始高阶推理规划错误的影响，导致无法重新构造解决方案。此研究旨在提高AI系统的鲁棒性和灵活性。", "method": "采用计划者执行架构分离高层次策略和低层次执行，并引入预测处理机制以预估结果。核心创新在于自我修正机制，能够进行路径校正与方案重构。", "result": "在三个多跳KGQA基准测试中，PPoGA表现出色，优于现有方法，显示了元认知能力如问题重组的重要作用。", "conclusion": "PPoGA框架展示了提高AI系统推理灵活性和鲁棒性的潜力。"}}
{"id": "2602.00003", "pdf": "https://arxiv.org/pdf/2602.00003", "abs": "https://arxiv.org/abs/2602.00003", "authors": ["Ye Liu", "Xu Chen", "Wuji Chen", "Mang Li"], "title": "Efficient Multilingual Search Relevance Modeling in E-Commerce via LLM Mixture-of-Experts", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "4 pages, 2 figures", "summary": "In e-commerce platforms, search relevance directly influences both user experience and merchant revenue. In multi-country deployments, diverse linguistic, cultural, and product catalog contexts introduce significant distribution shifts, posing substantial challenges to relevance modeling. Existing approaches typically enhance the reasoning or multilingual abilities of a single monolithic model, yet they remain limited by data diversity, coverage gaps, and high inference costs in heterogeneous environments. Our empirical analysis reveals that different LLM base models exhibit complementary strengths across languages and regions, motivating an expert-based architecture. We propose a scalable LLM-based Mixture-of-Experts (MoE) framework that dynamically routes queries to specialized experts and fuses their embeddings through concatenation. Among rule-based, pseudo-label-based, and fully end-to-end strategies, end-to-end hard routing with concatenation offers the best balance of effectiveness and efficiency. To mitigate inference overhead, we further develop an engineering-optimized offline batch pipeline with resource-efficient scheduling, which hides memory latency, improves GPU utilization, and reduces GPU-hour consumption by up to 35% compared with synchronous execution. On datasets spanning six Southeast Asian markets, our MoE improves AUC by 0.72 percentage points over a dense baseline with the same active parameters. Meanwhile, the optimized pipeline achieves 27.6 queries per second (QPS), a 9% throughput improvement. These results demonstrate superior multilingual relevance and efficiency, delivering strong cost-effectiveness for real-world e-commerce search systems.", "AI": {"tldr": "该论文提出了一种基于专家混合的LLM框架，用于提高多语言电子商务搜索的相关性。", "motivation": "在多国部署中，不同国家的语言、文化和产品目录造成了分布差异，单一模型难以满足这些需求。通过分析发现不同基础模型有互补优势，因此引入了专家架构来应对这一挑战。", "method": "论文提出了一种基于LLM的混合专家（MoE）框架，动态路由查询到专门的专家，并融合它们的嵌入表示。提出了几种策略，最终选择了端到端硬路由与拼接方法作为最佳方案。此外还开发了优化后的离线批量处理流水线来减少推理成本。", "result": "实验结果表明，该MoE框架在六个多东南亚市场数据集上相比密集基线提升了0.72个百分点的AUC，并且经过优化的流水线实现了每秒27.6个查询的速度，比同步执行提高了9%的吞吐量。", "conclusion": "论文提出的基于LLM的混合专家框架在多语言电子商务搜索中显示出了优越的相关性和效率，具有很强的实际应用成本效益。"}}
{"id": "2602.00002", "pdf": "https://arxiv.org/pdf/2602.00002", "abs": "https://arxiv.org/abs/2602.00002", "authors": ["Yu Zheng", "Chen Gao", "Jianxin Chang", "Yanan Niu", "Yang Song", "Depeng Jin", "Meng Wang", "Yong Li"], "title": "Disentangled Interest Network for Out-of-Distribution CTR Prediction", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "Accepted by ACM TOIS", "summary": "Click-through rate (CTR) prediction, which estimates the probability of a user clicking on a given item, is a critical task for online information services. Existing approaches often make strong assumptions that training and test data come from the same distribution. However, the data distribution varies since user interests are constantly evolving, resulting in the out-of-distribution (OOD) issue. In addition, users tend to have multiple interests, some of which evolve faster than others. Towards this end, we propose Disentangled Click-Through Rate prediction (DiseCTR), which introduces a causal perspective of recommendation and disentangles multiple aspects of user interests to alleviate the OOD issue in recommendation. We conduct a causal factorization of CTR prediction involving user interest, exposure model, and click model, based on which we develop a deep learning implementation for these three causal mechanisms. Specifically, we first design an interest encoder with sparse attention which maps raw features to user interests, and then introduce a weakly supervised interest disentangler to learn independent interest embeddings, which are further integrated by an attentive interest aggregator for prediction. Experimental results on three real-world datasets show that DiseCTR achieves the best accuracy and robustness in OOD recommendation against state-of-the-art approaches, significantly improving AUC and GAUC by over 0.02 and reducing logloss by over 13.7%. Further analyses demonstrate that DiseCTR successfully disentangles user interests, which is the key to OOD generalization for CTR prediction. We have released the code and data at https://github.com/DavyMorgan/DiseCTR/.", "AI": {"tldr": "提出了一种用于点击率预测的离散化兴趣网络，以解决推荐系统中的数据分布变化问题。", "motivation": "现有方法假设训练和测试数据来自同一分布，但用户兴趣不断演变导致了数据分布的变化。为了应对这一挑战，本文引入了一个因果视角，通过分离用户的多种兴趣来缓解该问题。", "method": "提出了一个深度学习实现的离散化点击率预测模型DiseCTR, 它包括兴趣编码器、弱监督的兴趣分离器和注意力聚集的兴趣聚合器三个部分，以分别处理用户兴趣、曝光模型和点击模型。", "result": "在三个真实世界的数据集上进行实验表明，DiseCTR相比最先进的方法在OOD推荐中取得了最佳的准确性和鲁棒性，显著提高了AUC和GAUC超过0.02，并减少了logloss超过13.7%。进一步分析显示，DiseCTR能够成功分离用户兴趣，这是点击率预测OOD泛化的关键。", "conclusion": "通过引入因果视角并使用深度学习方法来分离用户的多种兴趣，可以显著提高点击率预测的准确性和鲁棒性，特别是在分布变化的情况下。"}}
