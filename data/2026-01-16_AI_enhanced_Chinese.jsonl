{"id": "2601.10657", "pdf": "https://arxiv.org/pdf/2601.10657", "abs": "https://arxiv.org/abs/2601.10657", "authors": ["Minghao Yan", "Bo Peng", "Benjamin Coleman", "Ziqi Chen", "Zhouhang Xie", "Zhankui He", "Noveen Sachdeva", "Isabella Ye", "Weili Wang", "Chi Wang", "Ed H. Chi", "Wang-Cheng Kang", "Derek Zhiyuan Cheng", "Beidou Wang"], "title": "PACEvolve: Enabling Long-Horizon Progress-Aware Consistent Evolution", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have emerged as powerful operators for evolutionary search, yet the design of efficient search scaffolds remains ad hoc. While promising, current LLM-in-the-loop systems lack a systematic approach to managing the evolutionary process. We identify three distinct failure modes: Context Pollution, where experiment history biases future candidate generation; Mode Collapse, where agents stagnate in local minima due to poor exploration-exploitation balance; and Weak Collaboration, where rigid crossover strategies fail to leverage parallel search trajectories effectively. We introduce Progress-Aware Consistent Evolution (PACEvolve), a framework designed to robustly govern the agent's context and search dynamics, to address these challenges. PACEvolve combines hierarchical context management (HCM) with pruning to address context pollution; momentum-based backtracking (MBB) to escape local minima; and a self-adaptive sampling policy that unifies backtracking and crossover for dynamic search coordination (CE), allowing agents to balance internal refinement with cross-trajectory collaboration. We demonstrate that PACEvolve provides a systematic path to consistent, long-horizon self-improvement, achieving state-of-the-art results on LLM-SR and KernelBench, while discovering solutions surpassing the record on Modded NanoGPT.", "AI": {"tldr": "介绍了一个名为PACEvolve的框架，用于解决大型语言模型在进化搜索中的挑战，并展示了其在长期自我改进中的优势。", "motivation": "当前包含大型语言模型的系统缺乏一种系统的方式来管理进化过程。主要问题是上下文污染、模式崩溃和弱协作。", "method": "引入了Progress-Aware Consistent Evolution（PACEvolve），该框架结合层次化上下文管理和剪枝来处理上下文污染，使用基于动量的回溯方法逃离局部极小值，并采用自适应采样策略统一回溯与杂交以实现动态搜索协调。", "result": "PACEvolve实现了系统的长期自我改进路径，在LLM-SR和KernelBench上达到了最先进的结果，并在Modded NanoGPT上发现了超越记录的解决方案。", "conclusion": "PACEvolve框架成功地应对了大型语言模型进化搜索中的挑战，提供了有效的系统性解决方案来实现持续进步。"}}
{"id": "2601.10651", "pdf": "https://arxiv.org/pdf/2601.10651", "abs": "https://arxiv.org/abs/2601.10651", "authors": ["Christoph Weinhuber", "Yannik Schnitzer", "Alessandro Abate", "David Parker", "Giuseppe De Giacomo", "Moshe Y. Vardi"], "title": "Multi-Property Synthesis", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "We study LTLf synthesis with multiple properties, where satisfying all properties may be impossible. Instead of enumerating subsets of properties, we compute in one fixed-point computation the relation between product-game states and the goal sets that are realizable from them, and we synthesize strategies achieving maximal realizable sets. We develop a fully symbolic algorithm that introduces Boolean goal variables and exploits monotonicity to represent exponentially many goal combinations compactly. Our approach substantially outperforms enumeration-based baselines, with speedups of up to two orders of magnitude.", "AI": {"tldr": "本文研究了带有多个属性的LTLf综合问题，提出了一种新的方法来解决可能无法满足所有属性的情况。", "motivation": "传统的枚举子集的方法效率低下，因此动机在于开发一种更高效的方法来处理多属性合成问题。", "method": "文中提出了一个完全符号化的算法，通过引入布尔目标变量并利用单调性以紧凑方式表示大量目标组合，在一次固定点计算中计算产品游戏状态与可实现的目标集合之间的关系，并综合策略以达到最大可能的可实现集。", "result": "该方法在实验中表现出色，相较于基于枚举的方法有了高达两个数量级的速度提升。", "conclusion": "研究得出结论，所提出的方法能够有效解决多属性LTLf合成问题并显著提高计算效率。"}}
{"id": "2601.10649", "pdf": "https://arxiv.org/pdf/2601.10649", "abs": "https://arxiv.org/abs/2601.10649", "authors": ["Darshan Singh", "Arsha Nagrani", "Kawshik Manikantan", "Harman Singh", "Dinesh Tewari", "Tobias Weyand", "Cordelia Schmid", "Anelia Angelova", "Shachi Dave"], "title": "CURVE: A Benchmark for Cultural and Multilingual Long Video Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in video models have shown tremendous progress, particularly in long video understanding. However, current benchmarks predominantly feature western-centric data and English as the dominant language, introducing significant biases in evaluation. To address this, we introduce CURVE (Cultural Understanding and Reasoning in Video Evaluation), a challenging benchmark for multicultural and multilingual video reasoning. CURVE comprises high-quality, entirely human-generated annotations from diverse, region-specific cultural videos across 18 global locales. Unlike prior work that relies on automatic translations, CURVE provides complex questions, answers, and multi-step reasoning steps, all crafted in native languages. Making progress on CURVE requires a deeply situated understanding of visual cultural context. Furthermore, we leverage CURVE's reasoning traces to construct evidence-based graphs and propose a novel iterative strategy using these graphs to identify fine-grained errors in reasoning. Our evaluations reveal that SoTA Video-LLMs struggle significantly, performing substantially below human-level accuracy, with errors primarily stemming from the visual perception of cultural elements. CURVE will be publicly available under https://github.com/google-deepmind/neptune?tab=readme-ov-file\\#minerva-cultural", "AI": {"tldr": "介绍了一个新的基准测试CURVE，旨在评估长视频理解中的文化多样性和多语言能力。", "motivation": "当前的视频模型在评估时存在以西方为中心和英语为主的偏见，需要一个新的基准来更好地理解和评价多元文化和多语言环境下的视频理解能力。", "method": "构建了由人类生成的、来自全球18个地区的多样化文化视频数据集，并提供复杂的问题、答案及步骤推理，全部使用本地语言。利用这些数据集中的推理追踪信息创建证据图并提出一种迭代策略来识别细粒度推理错误。", "result": "最先进的视频大模型在CURVE上的表现远低于人类水平，主要问题在于对文化元素的视觉感知。", "conclusion": "CURVE提供了挑战性的长视频理解基准，有助于改进现有模型对于多文化和多语言环境的理解能力。"}}
{"id": "2601.10632", "pdf": "https://arxiv.org/pdf/2601.10632", "abs": "https://arxiv.org/abs/2601.10632", "authors": ["Chengfeng Zhao", "Jiazhi Shu", "Yubo Zhao", "Tianyu Huang", "Jiahao Lu", "Zekai Gu", "Chengwei Ren", "Zhiyang Dou", "Qing Shuai", "Yuan Liu"], "title": "CoMoVi: Co-Generation of 3D Human Motions and Realistic Videos", "categories": ["cs.CV"], "comment": "Project Page: https://igl-hkust.github.io/CoMoVi/", "summary": "In this paper, we find that the generation of 3D human motions and 2D human videos is intrinsically coupled. 3D motions provide the structural prior for plausibility and consistency in videos, while pre-trained video models offer strong generalization capabilities for motions, which necessitate coupling their generation processes. Based on this, we present CoMoVi, a co-generative framework that couples two video diffusion models (VDMs) to generate 3D human motions and videos synchronously within a single diffusion denoising loop. To achieve this, we first propose an effective 2D human motion representation that can inherit the powerful prior of pre-trained VDMs. Then, we design a dual-branch diffusion model to couple human motion and video generation process with mutual feature interaction and 3D-2D cross attentions. Moreover, we curate CoMoVi Dataset, a large-scale real-world human video dataset with text and motion annotations, covering diverse and challenging human motions. Extensive experiments demonstrate the effectiveness of our method in both 3D human motion and video generation tasks.", "AI": {"tldr": "本文介绍了CoMoVi框架，用于同步生成3D人体运动和真实视频。", "motivation": "发现3D人体运动与2D人体视频的生成本质上是耦合的，并且这种耦合性对于确保视频的一致性和可信度至关重要。", "method": "提出了一种有效的2D人体运动表示方法，设计了双分支扩散模型以实现人体运动和视频生成过程中的互特征交互和3D-2D交叉注意力机制。", "result": "实验表明该方法在3D人体运动和视频生成任务中均有效。", "conclusion": "通过CoMoVi框架实现了高质量的3D人体运动与同步视频的联合生成，验证了其在相关任务中的有效性。"}}
{"id": "2601.10611", "pdf": "https://arxiv.org/pdf/2601.10611", "abs": "https://arxiv.org/abs/2601.10611", "authors": ["Christopher Clark", "Jieyu Zhang", "Zixian Ma", "Jae Sung Park", "Mohammadreza Salehi", "Rohun Tripathi", "Sangho Lee", "Zhongzheng Ren", "Chris Dongjoo Kim", "Yinuo Yang", "Vincent Shao", "Yue Yang", "Weikai Huang", "Ziqi Gao", "Taira Anderson", "Jianrui Zhang", "Jitesh Jain", "George Stoica", "Winson Han", "Ali Farhadi", "Ranjay Krishna"], "title": "Molmo2: Open Weights and Data for Vision-Language Models with Video Understanding and Grounding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Today's strongest video-language models (VLMs) remain proprietary. The strongest open-weight models either rely on synthetic data from proprietary VLMs, effectively distilling from them, or do not disclose their training data or recipe. As a result, the open-source community lacks the foundations needed to improve on the state-of-the-art video (and image) language models. Crucially, many downstream applications require more than just high-level video understanding; they require grounding -- either by pointing or by tracking in pixels. Even proprietary models lack this capability. We present Molmo2, a new family of VLMs that are state-of-the-art among open-source models and demonstrate exceptional new capabilities in point-driven grounding in single image, multi-image, and video tasks. Our key contribution is a collection of 7 new video datasets and 2 multi-image datasets, including a dataset of highly detailed video captions for pre-training, a free-form video Q&A dataset for fine-tuning, a new object tracking dataset with complex queries, and an innovative new video pointing dataset, all collected without the use of closed VLMs. We also present a training recipe for this data utilizing an efficient packing and message-tree encoding scheme, and show bi-directional attention on vision tokens and a novel token-weight strategy improves performance. Our best-in-class 8B model outperforms others in the class of open weight and data models on short videos, counting, and captioning, and is competitive on long-videos. On video-grounding Molmo2 significantly outperforms existing open-weight models like Qwen3-VL (35.5 vs 29.6 accuracy on video counting) and surpasses proprietary models like Gemini 3 Pro on some tasks (38.4 vs 20.0 F1 on video pointing and 56.2 vs 41.1 J&F on video tracking).", "AI": {"tldr": "介绍了Molmo2，一种在开放数据和权重基础上表现优秀的视频语言模型，在图像、多图像和视频任务中具有显著的点驱动定位能力。", "motivation": "现有强大的视频语言模型是专有的，开源社区缺乏改进顶级视觉-语言模型的基础。需要更高级别的视频理解和定位能力，而现有的模型无法满足这些需求。", "method": "创建了7个新的视频数据集和2个多图像数据集，并提出了一种利用高效打包和消息树编码方案的训练方法，使用双向注意力机制和新颖的令牌加权策略提高了性能。", "result": "最好的8B模型在短视频、计数和描述任务上优于同类开放权重和数据模型，在长视频上的表现也具有竞争力。Molmo2在视频定位任务上显著优于现有开源模型，并且在某些任务上超过了专有模型，如Gemini 3 Pro。", "conclusion": "Molmo2证明了其作为顶级开放式视频语言模型的潜力，特别是在点驱动定位能力方面表现出色，并为未来的研究提供了宝贵的开放数据和训练方法。"}}
{"id": "2601.10607", "pdf": "https://arxiv.org/pdf/2601.10607", "abs": "https://arxiv.org/abs/2601.10607", "authors": ["Angeliki Katsenou", "Vignesh V. Menon", "Guoda Laurinaviciute", "Benjamin Bross", "Detlev Marpe"], "title": "Multi-Objective Pareto-Front Optimization for Efficient Adaptive VVC Streaming", "categories": ["eess.IV", "cs.CV"], "comment": "19 pages", "summary": "Adaptive video streaming has facilitated improved video streaming over the past years. A balance among coding performance objectives such as bitrate, video quality, and decoding complexity is required to achieve efficient, content- and codec-dependent, adaptive video streaming. This paper proposes a multi-objective Pareto-front (PF) optimization framework to construct quality-monotonic, content-adaptive bitrate ladders Versatile Video Coding (VVC) streaming that jointly optimize video quality, bitrate, and decoding time, which is used as a practical proxy for decoding energy. Two strategies are introduced: the Joint Rate-Quality-Time Pareto Front (JRQT-PF) and the Joint Quality-Time Pareto Front (JQT-PF), each exploring different tradeoff formulations and objective prioritizations. The ladders are constructed under quality monotonicity constraints during adaptive streaming to ensure a consistent Quality of Experience (QoE). Experiments are conducted on a large-scale UHD dataset (Inter-4K), with quality assessed using PSNR, VMAF, and XPSNR, and complexity measured via decoding time and energy consumption. The JQT-PF method achieves 11.76% average bitrate savings while reducing average decoding time by 0.29% to maintain the same XPSNR, compared to a widely-used fixed ladder. More aggressive configurations yield up to 27.88% bitrate savings at the cost of increased complexity. The JRQT-PF strategy, on the other hand, offers more controlled tradeoffs, achieving 6.38 % bitrate savings and 6.17 % decoding time reduction. This framework outperforms existing methods, including fixed ladders, VMAF- and XPSNR-based dynamic resolution selection, and complexity-aware benchmarks. The results confirm that PF optimization with decoding time constraints enables sustainable, high-quality streaming tailored to network and device capabilities.", "AI": {"tldr": "论文提出了一种多目标帕累托前沿优化框架，用于构建高效的自适应VVC流媒体。", "motivation": "为了实现高效的内容和编解码器依赖的自适应视频流传输，需要在编码性能指标如比特率、视频质量和解码复杂度之间取得平衡。", "method": "提出了两种策略：联合速率-质量-时间帕累托前沿（JRQT-PF）和联合质量-时间帕累托前沿（JQT-PF），以探索不同的权衡方案和目标优先级。实验在大规模的UHD数据集上进行，使用PSNR、VMAF和XPSNR评估质量和解码时间和能耗测量复杂性。", "result": "与广泛使用的固定梯度相比，JQT-PF方法实现了平均比特率节省11.76%，同时减少了0.29%的平均解码时间以保持相同的XPSNR。JRQT-PF策略则提供了更受控制的权衡，实现6.38％的比特率节省和6.17％的解码时间减少。", "conclusion": "该框架优于现有的方法，包括固定梯度、基于VMAF和XPSNR的动态分辨率选择以及复杂性感知基准。结果表明，带有解码时间约束的PF优化可以实现可持续且高质量的流媒体传输，适应网络和设备的能力。"}}
{"id": "2601.10606", "pdf": "https://arxiv.org/pdf/2601.10606", "abs": "https://arxiv.org/abs/2601.10606", "authors": ["Peng Chen", "Xiaobao Wei", "Yi Yang", "Naiming Yao", "Hui Chen", "Feng Tian"], "title": "RSATalker: Realistic Socially-Aware Talking Head Generation for Multi-Turn Conversation", "categories": ["cs.CV"], "comment": null, "summary": "Talking head generation is increasingly important in virtual reality (VR), especially for social scenarios involving multi-turn conversation. Existing approaches face notable limitations: mesh-based 3D methods can model dual-person dialogue but lack realistic textures, while large-model-based 2D methods produce natural appearances but incur prohibitive computational costs. Recently, 3D Gaussian Splatting (3DGS) based methods achieve efficient and realistic rendering but remain speaker-only and ignore social relationships. We introduce RSATalker, the first framework that leverages 3DGS for realistic and socially-aware talking head generation with support for multi-turn conversation. Our method first drives mesh-based 3D facial motion from speech, then binds 3D Gaussians to mesh facets to render high-fidelity 2D avatar videos. To capture interpersonal dynamics, we propose a socially-aware module that encodes social relationships, including blood and non-blood as well as equal and unequal, into high-level embeddings through a learnable query mechanism. We design a three-stage training paradigm and construct the RSATalker dataset with speech-mesh-image triplets annotated with social relationships. Extensive experiments demonstrate that RSATalker achieves state-of-the-art performance in both realism and social awareness. The code and dataset will be released.", "AI": {"tldr": "介绍了一种名为RSATalker的框架，该框架利用3D高斯点绘制技术实现现实且社会感知的对话头像生成，并支持多轮次对话。", "motivation": "当前的方法在生成逼真的对话头像时存在局限性，如缺乏纹理真实性或计算成本过高。因此，本研究旨在开发一种新的方法来克服这些问题，提高虚拟现实中社交场景中对话头像的真实感和社交意识。", "method": "该论文提出了一种利用3D高斯点绘制技术的框架，首先从语音驱动生成三维面部动画，并通过绑定到网格面片上的3D高斯点渲染出高清二维头像视频。此外，提出了一个社会感知模块，编码各种关系类型并将其转换为高层嵌入。", "result": "实验结果表明，RSATalker在逼真度和社交意识方面达到了最先进的性能水平。", "conclusion": "研究展示了RSATalker框架的有效性，它能够生成高质量的、具有社会感知能力的多轮对话头像，并且计划发布相关代码和数据集。"}}
{"id": "2601.10600", "pdf": "https://arxiv.org/pdf/2601.10600", "abs": "https://arxiv.org/abs/2601.10600", "authors": ["Joshua Caiata", "Carter Blair", "Kate Larson"], "title": "Procedural Fairness in Multi-Agent Bandits", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "comment": null, "summary": "In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes: maximizing welfare, reducing inequality, or balancing utilities. However, evidence in psychology, economics, and Rawlsian theory suggests that fairness is also about process and who gets a say in the decisions being made. We introduce a new fairness objective, procedural fairness, which provides equal decision-making power for all agents, lies in the core, and provides for proportionality in outcomes. Empirical results confirm that fairness notions based on optimizing for outcomes sacrifice equal voice and representation, while the sacrifice in outcome-based fairness objectives (like equality and utilitarianism) is minimal under procedurally fair policies. We further prove that different fairness notions prioritize fundamentally different and incompatible values, highlighting that fairness requires explicit normative choices. This paper argues that procedural legitimacy deserves greater focus as a fairness objective, and provides a framework for putting procedural fairness into practice.", "AI": {"tldr": "本文介绍了多智能体多臂赌博机（MA-MAB）中的程序公平性，强调了决策过程中的平等和代表权，并提供了实现程序公平性的框架。", "motivation": "在心理学、经济学和罗尔斯理论的证据表明公平不仅在于结果，还在于决策过程中每个代理人的发言权和平等。因此，本文旨在引入一个新概念——程序公平性，并证明其重要性和不可替代的价值。", "method": "通过实证研究验证了基于结果优化的公平观念牺牲了平等发言和代表性，同时探讨了不同公平观在价值观上的优先级差异及其不相容性。", "result": "实验结果显示，在程序公正政策下，基于结果的公平目标（如平等和功利主义）所做出的结果损失极小，证明了程序公正的重要性。", "conclusion": "本文认为程序合法性作为公平目标应得到更多关注，并提供了一个实现程序公平性的框架。"}}
{"id": "2601.10592", "pdf": "https://arxiv.org/pdf/2601.10592", "abs": "https://arxiv.org/abs/2601.10592", "authors": ["Delong Chen", "Tejaswi Kasarla", "Yejin Bang", "Mustafa Shukor", "Willy Chung", "Jade Yu", "Allen Bolourchi", "Theo Moutakanni", "Pascale Fung"], "title": "Action100M: A Large-scale Video Action Dataset", "categories": ["cs.CV"], "comment": null, "summary": "Inferring physical actions from visual observations is a fundamental capability for advancing machine intelligence in the physical world. Achieving this requires large-scale, open-vocabulary video action datasets that span broad domains. We introduce Action100M, a large-scale dataset constructed from 1.2M Internet instructional videos (14.6 years of duration), yielding O(100 million) temporally localized segments with open-vocabulary action supervision and rich captions. Action100M is generated by a fully automated pipeline that (i) performs hierarchical temporal segmentation using V-JEPA 2 embeddings, (ii) produces multi-level frame and segment captions organized as a Tree-of-Captions, and (iii) aggregates evidence with a reasoning model (GPT-OSS-120B) under a multi-round Self-Refine procedure to output structured annotations (brief/detailed action, actor, brief/detailed caption). Training VL-JEPA on Action100M demonstrates consistent data-scaling improvements and strong zero-shot performance across diverse action recognition benchmarks, establishing Action100M as a new foundation for scalable research in video understanding and world modeling.", "AI": {"tldr": "介绍了Action100M，一个通过自动化流程从大量互联网教学视频中生成的大规模开放词汇表动作数据集，并展示了其在视频理解和世界建模研究中的潜力。", "motivation": "旨在推进机器智能在物理世界的行动识别能力，需要大规模、涵盖广泛领域的开放词汇视频动作数据集。", "method": "Action100M通过自动化流程生成，包括使用V-JEPA 2嵌入进行层次时间分割，构建多级帧和片段描述的Tree-of-Captions，以及通过GPT-OSS-120B推理模型在Self-Refine过程中聚合证据以输出结构化注释。", "result": "基于Action100M训练的VL-JEPA展示了数据扩展带来的性能改进，并且在不同的动作识别基准测试中表现出强大的零样本性能。", "conclusion": "Action100M为视频理解和世界模型研究提供了一个新的基础，验证了其在提升机器学习算法性能方面的潜力。"}}
{"id": "2601.10591", "pdf": "https://arxiv.org/pdf/2601.10591", "abs": "https://arxiv.org/abs/2601.10591", "authors": ["Arundeep Chinta", "Lucas Vinh Tran", "Jay Katukuri"], "title": "ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition", "categories": ["cs.LG", "cs.AI", "q-fin.RM", "q-fin.TR"], "comment": "Accepted for oral presentation at the AI Meets Quantitative Finance Workshop at ICAIF 2025. An enhanced version was accepted for oral presentation at the AI for Time Series Analysis Workshop at AAAI 2026", "summary": "Time Series Foundation Models (TSFMs) have emerged as a promising approach for zero-shot financial forecasting, demonstrating strong transferability and data efficiency gains. However, their adoption in financial applications is hindered by fundamental limitations in uncertainty quantification: current approaches either rely on restrictive distributional assumptions, conflate different sources of uncertainty, or lack principled calibration mechanisms. While recent TSFMs employ sophisticated techniques such as mixture models, Student's t-distributions, or conformal prediction, they fail to address the core challenge of providing theoretically-grounded uncertainty decomposition. For the very first time, we present a novel transformer-based probabilistic framework, ProbFM (probabilistic foundation model), that leverages Deep Evidential Regression (DER) to provide principled uncertainty quantification with explicit epistemic-aleatoric decomposition. Unlike existing approaches that pre-specify distributional forms or require sampling-based inference, ProbFM learns optimal uncertainty representations through higher-order evidence learning while maintaining single-pass computational efficiency. To rigorously evaluate the core DER uncertainty quantification approach independent of architectural complexity, we conduct an extensive controlled comparison study using a consistent LSTM architecture across five probabilistic methods: DER, Gaussian NLL, Student's-t NLL, Quantile Loss, and Conformal Prediction. Evaluation on cryptocurrency return forecasting demonstrates that DER maintains competitive forecasting accuracy while providing explicit epistemic-aleatoric uncertainty decomposition. This work establishes both an extensible framework for principled uncertainty quantification in foundation models and empirical evidence for DER's effectiveness in financial applications.", "AI": {"tldr": "本文介绍了一种新的基于Transformer的概率框架ProbFM，该框架利用Deep Evidential Regression（DER）提供理论基础的不确定性分解。", "motivation": "现有的时间序列基础模型在金融应用中的采用受限于其对不确定性量化的基本限制：依赖严格的分布假设、混淆不同来源的不确定性或缺乏原则性的校准机制。", "method": "ProbFM通过Deep Evidential Regression（DER）提供明确的知识性和随机性不确定性的分解，学习最优的不确定性表示并保持单次计算效率，与LSTM架构中的五种概率方法进行对照研究。", "result": "在数字货币收益预测上的评估表明，DER不仅维持了竞争力强的预测准确性，还提供了清晰的不确定分解。", "conclusion": "这项工作建立了一个可扩展的原则性不确定性量化框架，并为金融应用中Deep Evidential Regression的有效性提供了实证证据。"}}
{"id": "2601.10587", "pdf": "https://arxiv.org/pdf/2601.10587", "abs": "https://arxiv.org/abs/2601.10587", "authors": ["Frank Mollard", "Marcus Becker", "Florian Roehrbein"], "title": "Adversarial Evasion Attacks on Computer Vision using SHAP Values", "categories": ["cs.CV", "cs.AI"], "comment": "10th bwHPC Symposium - September 25th & 26th, 2024", "summary": "The paper introduces a white-box attack on computer vision models using SHAP values. It demonstrates how adversarial evasion attacks can compromise the performance of deep learning models by reducing output confidence or inducing misclassifications. Such attacks are particularly insidious as they can deceive the perception of an algorithm while eluding human perception due to their imperceptibility to the human eye. The proposed attack leverages SHAP values to quantify the significance of individual inputs to the output at the inference stage. A comparison is drawn between the SHAP attack and the well-known Fast Gradient Sign Method. We find evidence that SHAP attacks are more robust in generating misclassifications particularly in gradient hiding scenarios.", "AI": {"tldr": "介绍使用SHAP值对计算机视觉模型进行白盒攻击的方法，以减少输出置信度或诱导误分类。", "motivation": "旨在展示如何通过对抗性规避攻击破坏深度学习模型的性能，并探讨SHAP值在量化输入重要性方面的作用。", "method": "利用SHAP值来量化单个输入对输出的影响，在推断阶段实现对抗性攻击，与Fast Gradient Sign Method进行比较。", "result": "发现SHAP攻击在生成误分类方面更为稳健，特别是在隐藏梯度的情况下。", "conclusion": "SHAP攻击比传统的FGSM方法更强大和有效，特别适用于需要隐蔽攻击的场景。"}}
{"id": "2601.10581", "pdf": "https://arxiv.org/pdf/2601.10581", "abs": "https://arxiv.org/abs/2601.10581", "authors": ["Kimia Abedini", "Farzad Shami", "Gianmaria Silvello"], "title": "From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA", "categories": ["cs.AI", "cs.IR"], "comment": "Accepted paper by the 48th European Conference on Information Retrieval (ECIR'26)", "summary": "Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized API calls, though it is constrained by rigid API dependencies and limited adaptability. We replicate GeneGPT and propose GenomAgent, a multi-agent framework that efficiently coordinates specialized agents for complex genomics queries. Evaluated on nine tasks from the GeneTuring benchmark, GenomAgent outperforms GeneGPT by 12% on average, and its flexible architecture extends beyond genomics to various scientific domains needing expert knowledge extraction.", "AI": {"tldr": "本文介绍了GenomAgent，一个用于复杂基因组查询的多代理框架，并展示了它在GeneTuring基准测试中的优越性能。", "motivation": "基因组信息的理解对于生物医学研究至关重要，但提取此类数据仍然具有挑战性。现有的大型语言模型（LLM）虽然有潜力进行基因组问题解答，但由于受限于特定领域数据库的访问，表现有限。", "method": "本文复制了GeneGPT系统，并提出GenomAgent框架，该框架能够有效协调专门代理处理复杂的基因组查询。", "result": "在GeneTuring基准测试中的九个任务上，GenomAgent比GeneGPT平均高出12%的性能。", "conclusion": "GenomAgent不仅提高了复杂基因组查询的能力，其灵活架构还扩展到了需要专家知识提取的各种科学领域。"}}
{"id": "2601.10577", "pdf": "https://arxiv.org/pdf/2601.10577", "abs": "https://arxiv.org/abs/2601.10577", "authors": ["Serena Grazia De Benedictis", "Amedeo Altavilla", "Nicoletta Del Buono"], "title": "Jordan-Segmentable Masks: A Topology-Aware definition for characterizing Binary Image Segmentation", "categories": ["cs.CV", "math.AT", "math.NA"], "comment": "27 pages, 18 figures", "summary": "Image segmentation plays a central role in computer vision. However, widely used evaluation metrics, whether pixel-wise, region-based, or boundary-focused, often struggle to capture the structural and topological coherence of a segmentation. In many practical scenarios, such as medical imaging or object delineation, small inaccuracies in boundary, holes, or fragmented predictions can result in high metric scores, despite the fact that the resulting masks fail to preserve the object global shape or connectivity. This highlights a limitation of conventional metrics: they are unable to assess whether a predicted segmentation partitions the image into meaningful interior and exterior regions. In this work, we introduce a topology-aware notion of segmentation based on the Jordan Curve Theorem, and adapted for use in digital planes. We define the concept of a \\emph{Jordan-segmentatable mask}, which is a binary segmentation whose structure ensures a topological separation of the image domain into two connected components. We analyze segmentation masks through the lens of digital topology and homology theory, extracting a $4$-curve candidate from the mask, verifying its topological validity using Betti numbers. A mask is considered Jordan-segmentatable when this candidate forms a digital 4-curve with $β_0 = β_1 = 1$, or equivalently when its complement splits into exactly two $8$-connected components. This framework provides a mathematically rigorous, unsupervised criterion with which to assess the structural coherence of segmentation masks. By combining digital Jordan theory and homological invariants, our approach provides a valuable alternative to standard evaluation metrics, especially in applications where topological correctness must be preserved.", "AI": {"tldr": "本文提出了基于Jordan曲线定理的拓扑感知分割掩码定义，以评估二值图像分割的有效性。", "motivation": "现有的分割评价指标无法充分捕捉到分段的结构和拓扑连贯性，在医学成像或物体边缘描绘等实际应用中，小边界不准确、孔洞或片段预测会导致高得分但结果可能不符合预期。", "method": "作者通过引入Jordan-可分割掩码的概念，并结合数字拓扑学与同调理论来验证分段的数学严谨性。该概念基于Betti数和4-曲线候选者的验证，确保图像区域被分成两个连通组件。", "result": "提出的方法提供了一个无监督且严格的数学框架来评估分割掩码的结构一致性，特别是在需要保持拓扑正确性的应用场景中。", "conclusion": "通过结合数字Jordan理论和同调不变量，该方法为标准评价指标提供了一种有价值的替代方案。"}}
{"id": "2601.10567", "pdf": "https://arxiv.org/pdf/2601.10567", "abs": "https://arxiv.org/abs/2601.10567", "authors": ["Laura Ferrarotti", "Gian Maria Campedelli", "Roberto Dessì", "Andrea Baronchelli", "Giovanni Iacca", "Kathleen M. Carley", "Alex Pentland", "Joel Z. Leibo", "James Evans", "Bruno Lepri"], "title": "Generative AI collective behavior needs an interactionist paradigm", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.LG", "cs.MA"], "comment": null, "summary": "In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs--namely, their initialization with extensive pre-trained knowledge and implicit social priors, together with their capability of adaptation through in-context learning--motivates the need for an interactionist paradigm consisting of alternative theoretical foundations, methodologies, and analytical tools, in order to systematically examine how prior knowledge and embedded values interact with social context to shape emergent phenomena in multi-agent generative AI systems. We propose and discuss four directions that we consider crucial for the development and deployment of LLM-based collectives, focusing on theory, methods, and trans-disciplinary dialogue.", "AI": {"tldr": "本文主张理解基于大型语言模型的代理集体行为是一个重要的研究领域，并提出了一个互动主义范式。", "motivation": "文章认为，由于LLMs具有预训练知识和隐含的社会先验，以及通过上下文学习适应的能力，需要一个新的互动主义范式来系统地探讨这些因素如何影响多智能体生成AI系统的涌现现象。", "method": "本文提出了四个关键方向，涵盖理论、方法和跨学科对话，用于发展和部署基于LLMs的集体行为研究。", "result": "文章讨论了新的互动主义范式的必要性，并强调了其在理解生成AI系统集体行为方面的重要性。", "conclusion": "作者建议采用一个综合性的互动主义范式来研究多智能体系统的集体行为，以应对社会风险和潜在利益。"}}
{"id": "2601.10562", "pdf": "https://arxiv.org/pdf/2601.10562", "abs": "https://arxiv.org/abs/2601.10562", "authors": ["Reza M. Asiyabi", "SEOSAW Partnership", "Steven Hancock", "Casey Ryan"], "title": "Process-Guided Concept Bottleneck Model", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "13 pages with 7 figures and 1 table, Supplementary Materials 10 pages with 3 figures", "summary": "Concept Bottleneck Models (CBMs) improve the explainability of black-box Deep Learning (DL) by introducing intermediate semantic concepts. However, standard CBMs often overlook domain-specific relationships and causal mechanisms, and their dependence on complete concept labels limits applicability in scientific domains where supervision is sparse but processes are well defined. To address this, we propose the Process-Guided Concept Bottleneck Model (PG-CBM), an extension of CBMs which constrains learning to follow domain-defined causal mechanisms through biophysically meaningful intermediate concepts. Using above ground biomass density estimation from Earth Observation data as a case study, we show that PG-CBM reduces error and bias compared to multiple benchmarks, whilst leveraging multi-source heterogeneous training data and producing interpretable intermediate outputs. Beyond improved accuracy, PG-CBM enhances transparency, enables detection of spurious learning, and provides scientific insights, representing a step toward more trustworthy AI systems in scientific applications.", "AI": {"tldr": "本文提出了一种过程引导的概念瓶颈模型（PG-CBM），以提高科学领域中深度学习的可解释性和准确性。", "motivation": "标准的概念瓶颈模型忽略了特定领域的因果机制，且对完整概念标签的依赖限制了其在监督稀疏但过程明确的科学领域的应用。因此，本文旨在开发一种能更好地利用这些域内知识的方法。", "method": "PG-CBM通过引入生物物理上有意义的中间概念来遵循领域定义的因果关系，从而约束学习过程，以此改进标准的概念瓶颈模型。", "result": "在地球观测数据上的地上生物量密度估计案例研究中，与多个基准相比，PG-CBM减少了误差和偏差，并且能够利用多源异构训练数据，同时产生可解释的中间输出。", "conclusion": "PG-CBM不仅提高了准确性，而且增强了透明度，能检测到不合理的学习过程，并提供科学见解，是迈向更值得信赖AI系统的重要一步。"}}
{"id": "2601.10560", "pdf": "https://arxiv.org/pdf/2601.10560", "abs": "https://arxiv.org/abs/2601.10560", "authors": ["Xi Shi", "Mengxin Zheng", "Qian Lou"], "title": "Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems", "categories": ["cs.MA", "cs.AI", "cs.CL"], "comment": "Preprint", "summary": "Multi-agent systems (MAS) enable complex reasoning by coordinating multiple agents, but often incur high inference latency due to multi-step execution and repeated model invocations, severely limiting their scalability and usability in time-sensitive scenarios. Most existing approaches primarily optimize task performance and inference cost, and explicitly or implicitly assume sequential execution, making them less optimal for controlling latency under parallel execution. In this work, we investigate learning-based orchestration of multi-agent systems with explicit latency supervision under parallel execution. We propose Latency-Aware Multi-agent System (LAMaS), a latency-aware multi-agent orchestration framework that enables parallel execution and explicitly optimizes the critical execution path, allowing the controller to construct execution topology graphs with lower latency under parallel execution. Our experiments show that our approach reduces critical path length by 38-46% compared to the state-of-the-art baseline for multi-agent architecture search across multiple benchmarks, while maintaining or even improving task performance. These results highlight the importance of explicitly optimizing latency under parallel execution when designing efficient multi-agent systems. The code is available at https://github.com/xishi404/LAMaS", "AI": {"tldr": "本文提出了一个名为LAMaS的框架，用于在多智能体系统中进行延迟感知的编排，在并行执行时优化关键路径长度以减少延迟。", "motivation": "传统方法主要关注任务性能和推理成本，假设顺序执行，不适合控制并行执行下的延迟问题，限制了多智能体系统的可扩展性和实时应用能力。", "method": "作者提出LAMaS框架，通过显式监督延迟，在并行执行下优化关键路径长度，并允许控制器构建具有较低延迟的执行拓扑图。", "result": "实验结果显示，与最先进的基线相比，该方法在多个基准测试中减少38-46%的关键路径长度，同时保持或提高任务性能。", "conclusion": "强调了设计高效的多智能体系统时，在并行执行下显式优化延迟的重要性。"}}
{"id": "2601.10556", "pdf": "https://arxiv.org/pdf/2601.10556", "abs": "https://arxiv.org/abs/2601.10556", "authors": ["Riccardo Fonti", "Andrea Piroddi"], "title": "Enhancing Mobile Ad Hoc Networks (MANETs) with Software-Defined Networking (SDN): A Balanced Approach", "categories": ["cs.NI", "cs.ET"], "comment": "ef:Journal of Advances in Computer Networks, vol. 13, no. 1, pp. 7-14, 2025", "summary": "Mobile Ad Hoc Networks (MANETs) are decentralized wireless networks, characterized by their dynamic topologies and node mobility. In the era of cutting-edge technologies, integrating Software-Defined Networking (SDN) with MANETs offers a promising solution to manage these challenges more efficiently. This paper presents a balanced discussion of MANETs and SDN, demonstrating how SDN principles, such as centralized control and network virtualization, can optimize MANET performance in terms of scalability, cost-efficiency, and security. A mathematical model is developed to analyze Capital Expenditures (CAPEX), Operational Expenditures (OPEX), and network efficiency.", "AI": {"tldr": "本文探讨了将软件定义网络（SDN）与移动自组织网络（MANETs）结合的平衡方法，以提高MANETs的性能。", "motivation": "随着技术的发展，需要更高效地管理动态拓扑和节点移动性带来的挑战，而结合SDN可以优化MANETs的可扩展性、成本效益和安全性。", "method": "本文开发了一个数学模型来分析资本支出（CAPEX）、运营支出（OPEX）和网络效率，并讨论了如何利用SDN原则实现这些优化。", "result": "研究表明，通过结合SDN，MANETs在性能方面得到了显著提升，尤其是在成本效益和安全性方面有明显的改善。", "conclusion": "本文得出结论，将SDN与MANETs相结合是一种有效的策略，能够提高网络的整体效率和可靠性。"}}
{"id": "2601.10554", "pdf": "https://arxiv.org/pdf/2601.10554", "abs": "https://arxiv.org/abs/2601.10554", "authors": ["Constantin Selzer", "Fabian B. Flohr"], "title": "DeepUrban: Interaction-Aware Trajectory Prediction and Planning for Automated Driving by Aerial Imagery", "categories": ["cs.CV"], "comment": "ef:2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC), Edmonton, AB, Canada, 2024, pp. 221-227", "summary": "The efficacy of autonomous driving systems hinges critically on robust prediction and planning capabilities. However, current benchmarks are impeded by a notable scarcity of scenarios featuring dense traffic, which is essential for understanding and modeling complex interactions among road users. To address this gap, we collaborated with our industrial partner, DeepScenario, to develop DeepUrban-a new drone dataset designed to enhance trajectory prediction and planning benchmarks focusing on dense urban settings. DeepUrban provides a rich collection of 3D traffic objects, extracted from high-resolution images captured over urban intersections at approximately 100 meters altitude. The dataset is further enriched with comprehensive map and scene information to support advanced modeling and simulation tasks. We evaluate state-of-the-art (SOTA) prediction and planning methods, and conducted experiments on generalization capabilities. Our findings demonstrate that adding DeepUrban to nuScenes can boost the accuracy of vehicle predictions and planning, achieving improvements up to 44.1 % / 44.3% on the ADE / FDE metrics. Website: https://iv.ee.hm.edu/deepurban", "AI": {"tldr": "开发DeepUrban数据集，以提高自动驾驶系统在密集城市交通中的轨迹预测和规划能力。", "motivation": "现有的基准测试缺乏密集的城市交通场景，这阻碍了对道路用户复杂交互的理解和建模。为了弥补这一空白，作者与行业合作伙伴合作开发了DeepUrban数据集。", "method": "通过从高空拍摄的高分辨率图像中提取3D交通对象，并提供全面的地图和场景信息来支持高级建模和模拟任务。", "result": "将DeepUrban添加到nuScenes基准测试中可以提高车辆预测和规划的准确性，ADE/FDE指标上的改善高达44.1%/44.3%。", "conclusion": "实验表明，通过加入DeepUrban数据集，现有的轨迹预测和规划方法在密集城市交通场景中的性能得到了显著提升。"}}
{"id": "2601.10553", "pdf": "https://arxiv.org/pdf/2601.10553", "abs": "https://arxiv.org/abs/2601.10553", "authors": ["Jianhao Yuan", "Xiaofeng Zhang", "Felix Friedrich", "Nicolas Beltran-Velez", "Melissa Hall", "Reyhane Askari-Hemmat", "Xiaochuang Han", "Nicolas Ballas", "Michal Drozdzal", "Adriana Romero-Soriano"], "title": "Inference-time Physics Alignment of Video Generative Models with Latent World Models", "categories": ["cs.CV"], "comment": "22 pages, 10 figures", "summary": "State-of-the-art video generative models produce promising visual content yet often violate basic physics principles, limiting their utility. While some attribute this deficiency to insufficient physics understanding from pre-training, we find that the shortfall in physics plausibility also stems from suboptimal inference strategies. We therefore introduce WMReward and treat improving physics plausibility of video generation as an inference-time alignment problem. In particular, we leverage the strong physics prior of a latent world model (here, VJEPA-2) as a reward to search and steer multiple candidate denoising trajectories, enabling scaling test-time compute for better generation performance. Empirically, our approach substantially improves physics plausibility across image-conditioned, multiframe-conditioned, and text-conditioned generation settings, with validation from human preference study. Notably, in the ICCV 2025 Perception Test PhysicsIQ Challenge, we achieve a final score of 62.64%, winning first place and outperforming the previous state of the art by 7.42%. Our work demonstrates the viability of using latent world models to improve physics plausibility of video generation, beyond this specific instantiation or parameterization.", "AI": {"tldr": "本文提出了WMReward方法，通过使用隐式世界模型在推理时间对视频生成模型进行物理一致性校准，以提高视频生成的物理合理性。", "motivation": "现有的视频生成模型虽然能够产生视觉上令人满意的图像，但常常违反基本的物理学原理。作者认为这个问题不仅源于预训练过程中缺乏足够的物理知识理解，还与推理策略有关。为了改进这一点，他们提出了新的方法来优化视频生成中的物理一致性。", "method": "引入了WMReward技术，并将提高视频生成中物理合理性的任务视为一个推理时间校准问题。通过利用隐式世界模型的强物理先验作为奖励，引导多个候选去噪轨迹的选择，以提升测试阶段计算资源使用的效率和效果。", "result": "实验证明该方法在图像条件、多帧条件及文本条件下生成视频时显著提高了物理合理性，并且在ICCV 2025感知测试物理学IQ挑战赛中获得62.64%的高分，赢得第一名，领先第二名7.42个百分点。", "conclusion": "本研究展示了一种使用隐式世界模型来提高视频生成物理合理性的有效方法，并证明了这种方法具有通用性，可以应用于不同的参数化和实例化中。"}}
{"id": "2601.10551", "pdf": "https://arxiv.org/pdf/2601.10551", "abs": "https://arxiv.org/abs/2601.10551", "authors": ["Luxuan Fu", "Chong Liu", "Bisheng Yang", "Zhen Dong"], "title": "Unleashing the Capabilities of Large Vision-Language Models for Intelligent Perception of Roadside Infrastructure", "categories": ["cs.CV"], "comment": null, "summary": "Automated perception of urban roadside infrastructure is crucial for smart city management, yet general-purpose models often struggle to capture the necessary fine-grained attributes and domain rules. While Large Vision Language Models (VLMs) excel at open-world recognition, they often struggle to accurately interpret complex facility states in compliance with engineering standards, leading to unreliable performance in real-world applications. To address this, we propose a domain-adapted framework that transforms VLMs into specialized agents for intelligent infrastructure analysis. Our approach integrates a data-efficient fine-tuning strategy with a knowledge-grounded reasoning mechanism. Specifically, we leverage open-vocabulary fine-tuning on Grounding DINO to robustly localize diverse assets with minimal supervision, followed by LoRA-based adaptation on Qwen-VL for deep semantic attribute reasoning. To mitigate hallucinations and enforce professional compliance, we introduce a dual-modality Retrieval-Augmented Generation (RAG) module that dynamically retrieves authoritative industry standards and visual exemplars during inference. Evaluated on a comprehensive new dataset of urban roadside scenes, our framework achieves a detection performance of 58.9 mAP and an attribute recognition accuracy of 95.5%, demonstrating a robust solution for intelligent infrastructure monitoring.", "AI": {"tldr": "提出了一种针对城市道路基础设施智能感知的领域适应框架，通过结合数据高效微调策略和知识引导推理机制来提升大规模视觉语言模型在实际应用中的性能。", "motivation": "现有的通用模型难以捕捉到细粒度的城市道路基础设施属性及行业标准规则，导致其在现实世界应用中表现不可靠。因此，研究旨在解决这一问题并提高智能城市管理能力。", "method": "采用数据高效微调策略和知识引导推理机制进行领域适应；利用Grounding DINO进行开放词汇量细粒度定位，并通过LoRA技术对Qwen-VL模型进行语义属性深度推理；引入双模态检索增强生成模块来减少幻觉并确保专业合规性。", "result": "在城市道路场景综合数据集上，该框架实现了58.9 mAP的检测性能和95.5%的属性识别准确率。", "conclusion": "所提框架能够有效地将大规模视觉语言模型转化为专业的智能基础设施分析工具，并且在实际应用中展现出较高的可靠性和准确性。"}}
{"id": "2601.10547", "pdf": "https://arxiv.org/pdf/2601.10547", "abs": "https://arxiv.org/abs/2601.10547", "authors": ["Dongchao Yang", "Yuxin Xie", "Yuguo Yin", "Zheyu Wang", "Xiaoyu Yi", "Gongxi Zhu", "Xiaolong Weng", "Zihan Xiong", "Yingzhe Ma", "Dading Cong", "Jingliang Liu", "Zihang Huang", "Jinghan Ru", "Rongjie Huang", "Haoran Wan", "Peixu Wang", "Kuoxi Yu", "Helin Wang", "Liming Liang", "Xianwei Zhuang", "Yuanyuan Wang", "Haohan Guo", "Junjie Cao", "Zeqian Ju", "Songxiang Liu", "et al. (3 additional authors not shown)"], "title": "HeartMuLa: A Family of Open Sourced Music Foundation Models", "categories": ["cs.SD"], "comment": null, "summary": "We present a family of open-source Music Foundation Models designed to advance large-scale music understanding and generation across diverse tasks and modalities. Our framework consists of four major components: (1) HeartCLAP, an audio-text alignment model; (2) HeartTranscriptor, a robust lyric recognition model optimized for real-world music scenarios; and (3) HeartCodec, a low-frame-rate (12.5 Hz) yet high-fidelity music codec tokenizer that captures long-range musical structure while preserving fine-grained acoustic details and enabling efficient autoregressive modeling; (4) HeartMuLa, an LLM-based song generation model capable of synthesizing high-fidelity music under rich, user-controllable conditions (e.g., textual style descriptions, lyrics, and reference audio). In addition, it provides two specialized modes: (i) fine-grained musical attribute control, which allows users to specify the style of different song sections (e.g., intro, verse, chorus) using natural language prompts; and (ii) short, engaging music generation, which is suitable as background music for short videos. Lastly, HeartMuLa improves significantly when scaled to 7B parameters. For the first time, we show that a Suno-level, commercial-grade system can be reproduced using academic-scale data and GPU resources. We expect these foundation models to serve as strong baselines for future research and to facilitate practical applications in multimodal content production.", "AI": {"tldr": "介绍了HeartMuLa系列开源音乐基础模型，以推进大规模音乐理解和生成。", "motivation": "推动在不同任务和模式下的大规模音乐理解与生成。", "method": "包括四个主要组件：音频文本对齐模型HeartCLAP、强健的歌词识别模型HeartTranscriptor、低帧率高保真度音乐编解码器HeartCodec以及基于LLM的歌曲生成模型HeartMuLa，具有细粒度音乐属性控制和短视频背景音乐生成两种模式。", "result": "展示了一个Sunol级别的商用系统使用学术规模的数据和GPU资源可以被复现，并且当参数量扩展到7B时性能有显著提升。", "conclusion": "这些基础模型将作为未来研究的强基准，并促进多模态内容制作的实际应用。"}}
{"id": "2601.10544", "pdf": "https://arxiv.org/pdf/2601.10544", "abs": "https://arxiv.org/abs/2601.10544", "authors": ["Andrea Piroddi", "Riccardo Fonti"], "title": "SDN-Driven Innovations in MANETs and IoT: A Path to Smarter Networks", "categories": ["cs.NI", "cs.ET"], "comment": "ef:Journal of Advances in Information Technology, Vol. 16, No. 3, pp. 411-425, 2025", "summary": "Mobile Ad Hoc Networks (MANETs) and Internet of Things (IoT) networks operate in decentralized and dynamic environments, making them ideal for scenarios lacking traditional infrastructure. However, these networks face challenges such as inefficient routing, limited scalability, and security vulnerabilities due to their decentralized nature and resource constraints. This paper explores the integration of Software-Defined Networking (SDN) as a unified solution that leverages its centralized control and network programmability to improve routing, resource management, and security. A mathematical model evaluates the impact of SDN integration on Capital Expenditure (CAPEX), Operational Expenditure (OPEX), and performance metrics. Results demonstrate that SDN-enhanced MANETs and IoT networks offer superior scalability, reduced latency, increased throughput, and lower packet loss, especially in dynamic and large-scale environments. While SDN introduces computational overhead, it significantly enhances routing efficiency, resource optimization, and adaptability. The proposed framework provides a robust and scalable solution, enabling the development of network architectures that efficiently manage growing node densities, dynamic topologies, and high data traffic. This approach ensures resilience, making it well-suited to meet the performance and reliability demands of modern, large-scale applications.", "AI": {"tldr": "本文探讨了将软件定义网络（SDN）整合到移动自组织网络（MANETs）和物联网（IoT）中的创新，以解决这些网络在路由、资源管理和安全性方面的问题。", "motivation": "鉴于MANETs和IoT网络面临的诸如无效路由、有限扩展性和安全漏洞等挑战，本文旨在通过引入SDN的集中控制和网络可编程性来提升这些网络的性能。", "method": "建立数学模型评估SDN集成对资本支出（CAPEX）、运营支出（OPEX）及性能指标的影响。", "result": "结果显示，基于SDN增强的MANETs和IoT网络在动态和大规模环境中能提供更好的扩展性、降低延迟、提高吞吐量并减少数据包丢失率。", "conclusion": "尽管SDN引入了计算开销，但它显著提高了路由效率、资源优化以及适应能力。提出的框架为高效管理不断增加的节点密度、动态拓扑结构和高流量数据提供了坚固且可扩展的解决方案。"}}
{"id": "2601.10543", "pdf": "https://arxiv.org/pdf/2601.10543", "abs": "https://arxiv.org/abs/2601.10543", "authors": ["Yinzhi Zhao", "Ming Wang", "Shi Feng", "Xiaocui Yang", "Daling Wang", "Yifei Zhang"], "title": "Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have achieved impressive performance across natural language tasks and are increasingly deployed in real-world applications. Despite extensive safety alignment efforts, recent studies show that such alignment is often shallow and remains vulnerable to jailbreak attacks. Existing defense mechanisms, including decoding-based constraints and post-hoc content detectors, struggle against sophisticated jailbreaks, often intervening robust detection or excessively degrading model utility. In this work, we examine the decoding process of LLMs and make a key observation: even when successfully jailbroken, models internally exhibit latent safety-related signals during generation. However, these signals are overridden by the model's drive for fluent continuation, preventing timely self-correction or refusal. Building on this observation, we propose a simple yet effective approach that explicitly surfaces and leverages these latent safety signals for early detection of unsafe content during decoding. Experiments across diverse jailbreak attacks demonstrate that our approach significantly enhances safety, while maintaining low over-refusal rates on benign inputs and preserving response quality. Our results suggest that activating intrinsic safety-awareness during decoding offers a promising and complementary direction for defending against jailbreak attacks. Code is available at: https://github.com/zyz13590/SafeProbing.", "AI": {"tldr": "本文提出了一种在解码过程中利用潜在的安全信号来提前检测不安全内容的方法，以防御大型语言模型受到的越狱攻击。", "motivation": "尽管进行了大量的安全性对齐工作，大型语言模型仍然容易受到越狱攻击的影响。现有的防御机制难以有效检测并阻止此类攻击。", "method": "通过分析解码过程中即使被成功越狱后的模型内部仍存在潜在的安全信号这一现象，提出了一种能够显式地利用这些安全信号的简单而有效的早期检测方法。", "result": "实验结果显示该方法在维护低误拒率和保留响应质量的同时显著增强了安全性。", "conclusion": "激活解码过程中的内在安全意识为防御越狱攻击提供了一个有前景且互补的方向。"}}
{"id": "2601.10537", "pdf": "https://arxiv.org/pdf/2601.10537", "abs": "https://arxiv.org/abs/2601.10537", "authors": ["Oscar H. Ramírez-Agudelo", "Akshay N. Shewatkar", "Edoardo Milana", "Roland C. Aydin", "Kai Franke"], "title": "Enhancing the quality of gauge images captured in smoke and haze scenes through deep learning", "categories": ["cs.CV"], "comment": "17 pages, 10 figures, 6 tables, SPIE Applications of Machine Learning 2023, San Diego, US", "summary": "Images captured in hazy and smoky environments suffer from reduced visibility, posing a challenge when monitoring infrastructures and hindering emergency services during critical situations. The proposed work investigates the use of the deep learning models to enhance the automatic, machine-based readability of gauge in smoky environments, with accurate gauge data interpretation serving as a valuable tool for first responders. The study utilizes two deep learning architectures, FFA-Net and AECR-Net, to improve the visibility of gauge images, corrupted with light up to dense haze and smoke. Since benchmark datasets of analog gauge images are unavailable, a new synthetic dataset, containing over 14,000 images, was generated using the Unreal Engine. The models were trained with an 80\\% train, 10\\% validation, and 10\\% test split for the haze and smoke dataset, respectively. For the synthetic haze dataset, the SSIM and PSNR metrics are about 0.98 and 43\\,dB, respectively, comparing well to state-of-the art results. Additionally, more robust results are retrieved from the AECR-Net, when compared to the FFA-Net. Although the results from the synthetic smoke dataset are poorer, the trained models achieve interesting results. In general, imaging in the presence of smoke are more difficult to enhance given the inhomogeneity and high density. Secondly, FFA-Net and AECR-Net are implemented to dehaze and not to desmoke images. This work shows that use of deep learning architectures can improve the quality of analog gauge images captured in smoke and haze scenes immensely. Finally, the enhanced output images can be successfully post-processed for automatic autonomous reading of gauges", "AI": {"tldr": "通过深度学习提升烟雾和雾霾环境中的表盘图像质量。", "motivation": "在烟雾和雾霾环境中拍摄的图片会降低能见度，这给基础设施监控和紧急情况下应急服务带来挑战。准确解读表盘数据对于第一响应者来说是一个有价值的工具。", "method": "研究使用了两种深度学习架构FFA-Net和AECR-Net来改善被轻至重度烟雾模糊的表盘图像能见度，用UE引擎生成了一个包含超过14000张图片的新合成数据集。", "result": "对于合成雾霾数据集，SSIM和PSNR指标分别达到约0.98和43dB，与最先进成果相当。AECR-Net的表现优于FFA-Net，但烟雾图像增强结果较差。", "conclusion": "深度学习架构可以极大提升在烟雾和雾霾环境下拍摄的模拟表盘图像质量，并且这些优化后的图像可以用于自动自主读取表盘数据。"}}
{"id": "2601.10536", "pdf": "https://arxiv.org/pdf/2601.10536", "abs": "https://arxiv.org/abs/2601.10536", "authors": ["Ishani Kanapathipillai", "Obhasha Priyankara"], "title": "CoGen: Creation of Reusable UI Components in Figma via Textual Commands", "categories": ["cs.HC", "cs.LG"], "comment": "8 pages, 6 figures, 11 tables", "summary": "The evolution of User Interface design has emphasized the need for efficient, reusable, and editable components to ensure an efficient design process. This research introduces CoGen, a system that uses machine learning techniques to generate reusable UI components directly in Figma, one of the most popular UI design tools. Addressing gaps in current systems, CoGen focuses on creating atomic components such as buttons, labels, and input fields using structured JSON and natural language prompts. The project integrates Figma API data extraction, Seq2Seq models, and fine-tuned T5 transformers for component generation. The key results demonstrate the efficiency of the T5 model in prompt generation, with an accuracy of 98% and a BLEU score of 0.2668, which ensures the mapping of JSON to descriptive prompts. For JSON creation, CoGen achieves a success rate of up to 100% in generating simple JSON outputs for specified component types.", "AI": {"tldr": "本文介绍了一个名为CoGen的系统，该系统使用机器学习技术，通过文本命令在Figma中生成可重复使用的UI组件。", "motivation": "为了提高设计效率，需要更高效的、可复用和可编辑的UI组件，现有的系统存在一些空白点。", "method": "CoGen结合了Figma API数据提取、Seq2Seq模型以及微调后的T5转换器来生成组件，并使用结构化的JSON和自然语言提示来创建原子级组件如按钮、标签和输入字段。", "result": "实验表明，T5模型在提示生成上的准确率为98%，BLEU得分为0.2668，确保了从JSON到描述性提示的映射准确性。对于简单的JSON输出生成任务，成功率达到100%。", "conclusion": "CoGen通过机器学习技术显著提高了UI组件的创建效率和准确性，为设计过程提供了有力支持。"}}
{"id": "2601.10535", "pdf": "https://arxiv.org/pdf/2601.10535", "abs": "https://arxiv.org/abs/2601.10535", "authors": ["Chong Liu", "Luxuan Fu", "Yang Jia", "Zhen Dong", "Bisheng Yang"], "title": "SVII-3D: Advancing Roadside Infrastructure Inventory with Decimeter-level 3D Localization and Comprehension from Sparse Street Imagery", "categories": ["cs.CV"], "comment": null, "summary": "The automated creation of digital twins and precise asset inventories is a critical task in smart city construction and facility lifecycle management. However, utilizing cost-effective sparse imagery remains challenging due to limited robustness, inaccurate localization, and a lack of fine-grained state understanding. To address these limitations, SVII-3D, a unified framework for holistic asset digitization, is proposed. First, LoRA fine-tuned open-set detection is fused with a spatial-attention matching network to robustly associate observations across sparse views. Second, a geometry-guided refinement mechanism is introduced to resolve structural errors, achieving precise decimeter-level 3D localization. Third, transcending static geometric mapping, a Vision-Language Model agent leveraging multi-modal prompting is incorporated to automatically diagnose fine-grained operational states. Experiments demonstrate that SVII-3D significantly improves identification accuracy and minimizes localization errors. Consequently, this framework offers a scalable, cost-effective solution for high-fidelity infrastructure digitization, effectively bridging the gap between sparse perception and automated intelligent maintenance.", "AI": {"tldr": "本文提出了SVII-3D框架，用于通过稀疏街景图像实现精确的三维定位和理解，从而改进道路基础设施的数字化库存。", "motivation": "智能城市建设及设施生命周期管理中自动创建数字孪生体与精准资产库存是至关重要的任务，但由于使用成本效益高的稀疏影像存在挑战，如稳健性不足、定位不准确和缺乏细粒度状态理解等问题，故提出SVII-3D框架解决这些问题。", "method": "首先，采用LoRA微调开放式检测方法并融合空间注意力匹配网络实现跨多视角的鲁棒关联观测；其次引入几何引导细化机制纠正结构误差，达到精确三维定位；最后加入视觉语言模型代理通过多模态提示自动诊断细粒度操作状态。", "result": "实验显示SVII-3D显著提高了识别准确性，并减少了定位错误。", "conclusion": "该框架提供了一个可扩展且成本效益高的高保真基础设施数字化解决方案，有效弥合了稀疏感知与自动化智能维护之间的差距。"}}
{"id": "2601.10527", "pdf": "https://arxiv.org/pdf/2601.10527", "abs": "https://arxiv.org/abs/2601.10527", "authors": ["Xingjun Ma", "Yixu Wang", "Hengyuan Xu", "Yutao Wu", "Yifan Ding", "Yunhan Zhao", "Zilong Wang", "Jiabin Hua", "Ming Wen", "Jianan Liu", "Ranjie Duan", "Yifeng Gao", "Yingshui Tan", "Yunhao Chen", "Hui Xue", "Xin Wang", "Wei Cheng", "Jingjing Chen", "Zuxuan Wu", "Bo Li", "Yu-Gang Jiang"], "title": "A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": "42 pages, 24 figures", "summary": "The rapid evolution of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) has produced substantial gains in reasoning, perception, and generative capability across language and vision. However, whether these advances yield commensurate improvements in safety remains unclear, in part due to fragmented evaluation practices limited to single modalities or threat models. In this report, we present an integrated safety evaluation of 7 frontier models: GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5. We evaluate each model across language, vision-language, and image generation settings using a unified protocol that integrates benchmark evaluation, adversarial evaluation, multilingual evaluation, and compliance evaluation. Aggregating our evaluations into safety leaderboards and model safety profiles across multiple evaluation modes reveals a sharply heterogeneous safety landscape. While GPT-5.2 demonstrates consistently strong and balanced safety performance across evaluations, other models exhibit pronounced trade-offs among benchmark safety, adversarial alignment, multilingual generalization, and regulatory compliance. Both language and vision-language modalities show significant vulnerability under adversarial evaluation, with all models degrading substantially despite strong results on standard benchmarks. Text-to-image models achieve relatively stronger alignment in regulated visual risk categories, yet remain brittle under adversarial or semantically ambiguous prompts. Overall, these results show that safety in frontier models is inherently multidimensional--shaped by modality, language, and evaluation scheme, underscoring the need for standardized safety evaluations to accurately assess real-world risk and guide responsible model development and deployment.", "AI": {"tldr": "本报告对7种前沿的大型语言模型和多模态大型语言模型进行了综合安全评估，包括基准测试、对抗性评估、多语种评估和合规性评估。", "motivation": "尽管大型语言模型（LLMs）和多模态大型语言模型（MLLMs）在推理、感知和生成能力方面取得了显著进步，但这些进展是否带来了相应的安全性改进尚不清楚，因此需要综合评估来明确安全状况。", "method": "报告对7种前沿模型进行了统一的评价协议下的多种设置的安全性评估，包括语言环境、视觉-语言环境和图像生成环境。", "result": "评估结果显示了各模型在不同模式中的异质安全性分布。GPT-5.2在所有评估中表现出持续且均衡的安全性能，而其他模型则在基准安全性、对抗对齐能力、多语种泛化能力和监管合规性方面存在明显差异。", "conclusion": "安全性的评估是多维的，受模式、语言和评价方案的影响。这些结果强调了标准化安全评估的重要性，以便准确评估实际风险并指导负责任的模型开发与部署。"}}
{"id": "2601.10525", "pdf": "https://arxiv.org/pdf/2601.10525", "abs": "https://arxiv.org/abs/2601.10525", "authors": ["Yijin Zhou", "Fu Li", "Yi Niu", "Boxun Fu", "Huaning Wang", "Lijian Zhang"], "title": "Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition", "categories": ["cs.HC"], "comment": null, "summary": "Understanding how local neurophysiological patterns interact with global brain dynamics is essential for decoding human emotions from EEG signals. However, existing deep learning approaches often overlook the brain's intrinsic spatial organization, failing to simultaneously capture local topological relations and global dependencies. To address these challenges, we propose Neuro-HGLN, a Neurologically-informed Hierarchical Graph-Transformer Learning Network that integrates biologically grounded priors with hierarchical representation learning. Neuro-HGLN first constructs a spatial Euclidean prior graph based on physical electrode distances to serve as an anatomically grounded inductive bias. A learnable global dynamic graph is then introduced to model functional connectivity across the entire brain. In parallel, to capture fine-grained regional dependencies, Neuro-HGLN builds region-level local graphs using a multi-head self-attention mechanism. These graphs are processed synchronously through local-constrained parallel GCN layers to produce region-specific representations. Subsequently, an iTransformer encoder aggregates these features to capture cross-region dependencies under a dimension-as-token formulation. Extensive experiments demonstrate that Neuro-HGLN achieves state-of-the-art performance on multiple benchmarks, providing enhanced interpretability grounded in neurophysiological structure. These results highlight the efficacy of unifying local topological learning with cross-region dependency modeling for robust EEG emotion recognition.", "AI": {"tldr": "本文提出了Neuro-HGLN，一种基于生物学先验的层次图Transformer学习网络，用于从EEG信号中解码人类情绪。", "motivation": "现有的深度学习方法往往忽略了大脑内在的空间组织结构，无法同时捕捉局部拓扑关系和全局依赖性，因此需要提出新的方法来解决这些问题。", "method": "Neuro-HGLN首先基于物理电极距离构建了一个空间欧几里得先验图作为解剖学上合理的归纳偏置，并引入可学习的全局动态图以建模整个大脑的功能连接。同时使用多头自注意力机制在区域层面建立局部图，并通过本地约束并行GCN层产生特定区域表示，最后通过iTransformer编码器聚合这些特征来捕捉跨区域依赖关系。", "result": "实验结果表明，Neuro-HGLN在多个基准上实现了最先进的性能，提供了一种基于神经生理结构的增强解释性。", "conclusion": "将局部拓扑学习与跨区域依赖建模统一起来对于实现稳健的EEG情绪识别至关重要，并且该方法提供了更好的解读能力。"}}
{"id": "2601.10524", "pdf": "https://arxiv.org/pdf/2601.10524", "abs": "https://arxiv.org/abs/2601.10524", "authors": ["Frank Bobe III", "Gregory D. Vetaw", "Chase Pavlick", "Darshan Bryner", "Matthew Cook", "Jose Salas-Vernis"], "title": "Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing Detection", "categories": ["cs.AI"], "comment": "16 pages, 6 figures, 6 tables", "summary": "The practice of fine-tuning Large Language Models (LLMs) has achieved state-of-the-art performance on specialized tasks, yet diagnosing why these models become brittle and fail to generalize remains a critical open problem. To address this, we introduce and apply a multi-layered diagnostic framework to a cross-architectural study. We fine-tune Llama 3.1 8B, Gemma 2 9B, and Mistral models on a high-stakes phishing detection task and use SHAP analysis and mechanistic interpretability to uncover the root causes of their generalization failures. Our investigation reveals three critical findings: (1) Generalization is driven by a powerful synergy between architecture and data diversity. The Gemma 2 9B model achieves state-of-the-art performance (>91\\% F1), but only when trained on a stylistically diverse ``generalist'' dataset. (2) Generalization is highly architecture-dependent. We diagnose a specific failure mode in Llama 3.1 8B, which performs well on a narrow domain but cannot integrate diverse data, leading to a significant performance drop. (3) Some architectures are inherently more generalizable. The Mistral model proves to be a consistent and resilient performer across multiple training paradigms. By pinpointing the flawed heuristics responsible for these failures, our work provides a concrete methodology for diagnosing and understanding generalization failures, underscoring that reliable AI requires deep validation of the interplay between architecture, data, and training strategy.", "AI": {"tldr": "本文通过跨架构研究，诊断了微调后的大型语言模型在钓鱼检测任务中的泛化失败原因。", "motivation": "尽管微调大型语言模型已取得顶尖性能，但了解其为何变得脆弱且无法良好泛化仍是一个关键问题。", "method": "作者对Llama 3.1 8B、Gemma 2 9B和Mistral模型进行微调，并使用SHAP分析和机械可解释性方法来揭示泛化的失败原因。", "result": "研究发现，泛化依赖于架构与数据多样性之间的协同作用；不同的架构对泛化能力有显著影响；某些架构本身更具有泛化能力。Gemma 2 9B在多样化数据集上达到91%以上的F1分值，而Llama 3.1 8B无法整合多样化的数据导致性能下降。", "conclusion": "通过识别失败的启发式方法，本研究提供了一种诊断和理解泛化失败的方法论，强调可靠的AI需要深入验证架构、数据及训练策略之间的相互作用。"}}
{"id": "2601.10521", "pdf": "https://arxiv.org/pdf/2601.10521", "abs": "https://arxiv.org/abs/2601.10521", "authors": ["Max A. Buettner", "Kanak Mazumder", "Luca Koecher", "Mario Finkbeiner", "Sebastian Niebler", "Fabian B. Flohr"], "title": "BikeActions: An Open Platform and Benchmark for Cyclist-Centric VRU Action Recognition", "categories": ["cs.CV"], "comment": "This work has been submitted to the IEEE ICPR for possible publication", "summary": "Anticipating the intentions of Vulnerable Road Users (VRUs) is a critical challenge for safe autonomous driving (AD) and mobile robotics. While current research predominantly focuses on pedestrian crossing behaviors from a vehicle's perspective, interactions within dense shared spaces remain underexplored. To bridge this gap, we introduce FUSE-Bike, the first fully open perception platform of its kind. Equipped with two LiDARs, a camera, and GNSS, it facilitates high-fidelity, close-range data capture directly from a cyclist's viewpoint. Leveraging this platform, we present BikeActions, a novel multi-modal dataset comprising 852 annotated samples across 5 distinct action classes, specifically tailored to improve VRU behavior modeling. We establish a rigorous benchmark by evaluating state-of-the-art graph convolution and transformer-based models on our publicly released data splits, establishing the first performance baselines for this challenging task. We release the full dataset together with data curation tools, the open hardware design, and the benchmark code to foster future research in VRU action understanding under https://iv.ee.hm.edu/bikeactions/.", "AI": {"tldr": "本文介绍了BikeActions，一个从自行车视角捕捉VUR行为数据的多模态开放平台和基准测试。", "motivation": "研究动机在于弥补现有自动驾驶技术在预测弱势道路使用者意图方面存在的不足，特别是对于骑车人的交互行为理解尚不充分。", "method": "开发了FUSE-Bike感知平台，配备了LiDAR、相机和GNSS设备，并构建了BikeActions数据集，包含852个样本，跨越5种不同的行动类别。", "result": "通过评估现有的图卷积网络和基于变换器的模型在该数据集上的性能，建立了首个针对此任务的表现基线。", "conclusion": "公开发布了完整数据集、数据整理工具、开放硬件设计及基准测试代码，旨在推动对VUR行为理解的研究进展。"}}
{"id": "2601.10520", "pdf": "https://arxiv.org/pdf/2601.10520", "abs": "https://arxiv.org/abs/2601.10520", "authors": ["Felix Jahn", "Yannic Muskalla", "Lisa Dargasz", "Patrick Schramowski", "Kevin Baum"], "title": "Breaking Up with Normatively Monolithic Agency with GRACE: A Reason-Based Neuro-Symbolic Architecture for Safe and Ethical AI Alignment", "categories": ["cs.AI", "cs.CY"], "comment": "10 pages, 4 figures, accepted at 2nd Annual Conference of the International Association for Safe & Ethical AI (IASEAI'26)", "summary": "As AI agents become increasingly autonomous, widely deployed in consequential contexts, and efficacious in bringing about real-world impacts, ensuring that their decisions are not only instrumentally effective but also normatively aligned has become critical. We introduce a neuro-symbolic reason-based containment architecture, Governor for Reason-Aligned ContainmEnt (GRACE), that decouples normative reasoning from instrumental decision-making and can contain AI agents of virtually any design. GRACE restructures decision-making into three modules: a Moral Module (MM) that determines permissible macro actions via deontic logic-based reasoning; a Decision-Making Module (DMM) that encapsulates the target agent while selecting instrumentally optimal primitive actions in accordance with derived macro actions; and a Guard that monitors and enforces moral compliance. The MM uses a reason-based formalism providing a semantic foundation for deontic logic, enabling interpretability, contestability, and justifiability. Its symbolic representation enriches the DMM's informational context and supports formal verification and statistical guarantees of alignment enforced by the Guard. We demonstrate GRACE on an example of a LLM therapy assistant, showing how it enables stakeholders to understand, contest, and refine agent behavior.", "AI": {"tldr": "介绍了一种神经符号推理约束架构GRACE，用于确保AI决策在道德上对齐。", "motivation": "随着AI代理变得越来越自主并在重要的现实场景中使用，保证其决策不仅是工具有效的，也是规范上对齐的至关重要。", "method": "提出了一个由三个模块组成的框架：道德模块（MM）通过义务逻辑推理确定许可宏行为；决策制定模块（DMM）封装目标代理并选择与导出的行为一致的最佳操作；守卫监控和强制执行道德合规。", "result": "GRACE架构能够使AI代理在不同设计中被有效约束，并在一个语言模型治疗助手的例子上展示了其有效性，允许利益相关者理解、挑战和改进行为。", "conclusion": "GRACE通过提供一个语义基础的义务逻辑推理框架，增强了决策过程的可解释性、争议性和正当性，支持形式验证和对齐的统计保证。"}}
{"id": "2601.10513", "pdf": "https://arxiv.org/pdf/2601.10513", "abs": "https://arxiv.org/abs/2601.10513", "authors": ["Xuan Luo", "Lewei Yao", "Libo Zhao", "Lanqing Hong", "Kai Chen", "Dehua Tao", "Daxin Tan", "Ruifeng Xu", "Jing Li"], "title": "AEQ-Bench: Measuring Empathy of Omni-Modal Large Models", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "While the automatic evaluation of omni-modal large models (OLMs) is essential, assessing empathy remains a significant challenge due to its inherent affectivity. To investigate this challenge, we introduce AEQ-Bench (Audio Empathy Quotient Benchmark), a novel benchmark to systematically assess two core empathetic capabilities of OLMs: (i) generating empathetic responses by comprehending affective cues from multi-modal inputs (audio + text), and (ii) judging the empathy of audio responses without relying on text transcription. Compared to existing benchmarks, AEQ-Bench incorporates two novel settings that vary in context specificity and speech tone. Comprehensive assessment across linguistic and paralinguistic metrics reveals that (1) OLMs trained with audio output capabilities generally outperformed models with text-only outputs, and (2) while OLMs align with human judgments for coarse-grained quality assessment, they remain unreliable for evaluating fine-grained paralinguistic expressiveness.", "AI": {"tldr": "介绍AEQ-Bench，一个用于系统评估大型多模态模型在理解和生成情感反应方面能力的基准测试。", "motivation": "自动评估大型多模态模型的情感识别能力是一个挑战。为此，研究者提出了AEQ-Bench来评估这些模型处理音频和文本输入以产生同理心回应的能力。", "method": "AEQ-Bench通过两个新颖的设置评估了模型在理解和生成情感反应方面的性能：理解并响应含有情感线索的多模态输入以及无需依赖文字转录判断音频回应的情感表达。", "result": "研究发现，拥有音频输出能力的大型模型通常比只有文本输出的模型表现更好。尽管这些模型在粗粒度的质量评估上与人类评判保持一致，但在细粒度的声音表达上的评估则不够可靠。", "conclusion": "AEQ-Bench为系统化地评估和改进多模态大模型的情感处理能力提供了一个新的框架。"}}
{"id": "2601.10512", "pdf": "https://arxiv.org/pdf/2601.10512", "abs": "https://arxiv.org/abs/2601.10512", "authors": ["Kanak Mazumder", "Fabian B. Flohr"], "title": "SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "This work has been submitted to the IEEE ICPR for possible publication", "summary": "Online high-definition (HD) map construction is an essential part of a safe and robust end-to-end autonomous driving (AD) pipeline. Onboard camera-based approaches suffer from limited depth perception and degraded accuracy due to occlusion. In this work, we propose SatMap, an online vectorized HD map estimation method that integrates satellite maps with multi-view camera observations and directly predicts a vectorized HD map for downstream prediction and planning modules. Our method leverages lane-level semantics and texture from satellite imagery captured from a Bird's Eye View (BEV) perspective as a global prior, effectively mitigating depth ambiguity and occlusion. In our experiments on the nuScenes dataset, SatMap achieves 34.8% mAP performance improvement over the camera-only baseline and 8.5% mAP improvement over the camera-LiDAR fusion baseline. Moreover, we evaluate our model in long-range and adverse weather conditions to demonstrate the advantages of using a satellite prior map. Source code will be available at https://iv.ee.hm.edu/satmap/.", "AI": {"tldr": "本文提出了SatMap，一种结合卫星地图和多视角相机观测来生成矢量化高精度地图的方法。", "motivation": "在线构建高清地图对于实现安全可靠的自动驾驶系统至关重要。传统的基于车载摄像头的方法由于深度感知有限且受遮挡影响而存在局限性。", "method": "SatMap方法利用了从鸟瞰视角捕获的卫星图像中的车道级语义和纹理作为全局先验，结合多视角相机观测直接预测矢量化高清地图以供下游模块使用。", "result": "实验表明，在nuScenes数据集上，SatMap相比只用摄像头的方法提升了34.8% mAP性能，并且比摄像头-LiDAR融合基准提高了8.5% mAP。该方法在长距离和恶劣天气条件下也表现出了优势。", "conclusion": "引入卫星地图作为先验信息可以有效提高在线高清地图构建的精度，尤其是在应对深度模糊和遮挡问题方面具有显著效果。"}}
{"id": "2601.10511", "pdf": "https://arxiv.org/pdf/2601.10511", "abs": "https://arxiv.org/abs/2601.10511", "authors": ["Paul Burkhardt", "David G. Harris", "Kevin T Schmitt"], "title": "Scalable Algorithms for Approximate DNF Model Counting", "categories": ["cs.DS", "cs.AI"], "comment": null, "summary": "Model counting of Disjunctive Normal Form (DNF) formulas is a critical problem in applications such as probabilistic inference and network reliability. For example, it is often used for query evaluation in probabilistic databases. Due to the computational intractability of exact DNF counting, there has been a line of research into a variety of approximation algorithms. These include Monte Carlo approaches such as the classical algorithms of Karp, Luby, and Madras (1989), as well as methods based on hashing (Soos et al. 2023), and heuristic approximations based on Neural Nets (Abboud, Ceylan, and Lukasiewicz 2020). We develop a new Monte Carlo approach with an adaptive stopping rule and short-circuit formula evaluation. We prove it achieves Probably Approximately Correct (PAC) learning bounds and is asymptotically more efficient than the previous methods. We also show experimentally that it out-performs prior algorithms by orders of magnitude, and can scale to much larger problems with millions of variables.", "AI": {"tldr": "开发了一种新的用于近似DNF模型计数的可扩展蒙特卡洛算法。", "motivation": "由于精确DNF计数计算上的不可行性，研究了各种近似算法以解决概率推理和网络可靠性中的问题。", "method": "提出了一个新的带有自适应停止规则和短路公式评估的Monte Carlo方法，并证明其达到了PAC学习界且在渐进意义上比先前的方法更高效。", "result": "实验显示该算法性能优于之前的方法，可以处理包含数百万变量的大规模问题。", "conclusion": "新的蒙特卡洛算法在效率和可扩展性方面显著超越现有方法。"}}
{"id": "2601.10498", "pdf": "https://arxiv.org/pdf/2601.10498", "abs": "https://arxiv.org/abs/2601.10498", "authors": ["Nilin Abrahamsen"], "title": "Projected Microbatch Accumulation yields reference-free proximal policy updates for reinforcement learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This note introduces Projected Microbatch Accumulation (PROMA), a proximal policy update method for large language model fine-tuning. PROMA accumulates policy gradients across microbatches by projecting out sequence-wise gradient components before microbatch aggregation. The projection is applied layer-wise during the backward pass, enabling efficient implementation without additional forward or backward passes. Empirically, PROMA enforces tighter control of local KL divergence than GRPO, resulting in more stable policy learning. Unlike PPO and GRPO, PROMA achieves proximal updates without inducing entropy collapse and does not rely on a reference policy or likelihood-ratio clipping.", "AI": {"tldr": "本文介绍了Projected Microbatch Accumulation (PROMA)，一种用于大规模语言模型微调的近似策略更新方法。", "motivation": "动机在于通过改进策略更新的方法，实现更稳定和高效的政策学习，同时避免熵崩溃，并不依赖参考策略或似然比裁剪。", "method": "PROMA方法在反向传播过程中逐层投影出序列级梯度分量以积累微批次的策略梯度，从而实现无需额外前向或后向传递的有效实现。", "result": "实证结果表明，与GRPO相比，PROMA能更好地控制局部KL散度，带来更稳定的政策学习效果。", "conclusion": "结论指出，PROMA实现了无参考策略的近似更新，并且不会引发熵崩溃，展示了其在稳定性和效率上的优势。"}}
{"id": "2601.10497", "pdf": "https://arxiv.org/pdf/2601.10497", "abs": "https://arxiv.org/abs/2601.10497", "authors": ["Wenqing Wang", "Da Li", "Xiatian Zhu", "Josef Kittler"], "title": "mergetune: Continued fine-tuning of vision-language models", "categories": ["cs.CV"], "comment": "20 pages, 5 figures", "summary": "Fine-tuning vision-language models (VLMs) such as CLIP often leads to catastrophic forgetting of pretrained knowledge. Prior work primarily aims to mitigate forgetting during adaptation; however, forgetting often remains inevitable during this process. We introduce a novel paradigm, \\emph{continued fine-tuning (CFT)}, which seeks to recover pretrained knowledge after a zero-shot model has already been adapted. We propose a simple, model-agnostic CFT strategy (named MERGETUNE) guided by linear mode connectivity (LMC), which can be applied post hoc to existing fine-tuned models without requiring architectural changes. Given a fine-tuned model, we continue fine-tuning its trainable parameters (e.g., soft prompts or linear heads) to search for a continued model which has two low-loss paths to the zero-shot (e.g., CLIP) and the fine-tuned (e.g., CoOp) solutions. By exploiting the geometry of the loss landscape, the continued model implicitly merges the two solutions, restoring pretrained knowledge lost in the fine-tuned counterpart. A challenge is that the vanilla LMC constraint requires data replay from the pretraining task. We approximate this constraint for the zero-shot model via a second-order surrogate, eliminating the need for large-scale data replay. Experiments show that MERGETUNE improves the harmonic mean of CoOp by +5.6\\% on base-novel generalisation without adding parameters. % We show \\emph{the first time} superior performance than CLIP on both DTD and EuroSAT, on cross-dataset transfer. On robust fine-tuning evaluations, the LMC-merged model from MERGETUNE surpasses ensemble baselines with lower inference cost, achieving further gains and state-of-the-art results when ensembled with the zero-shot model. Our code is available at \\href{https://github.com/Surrey-UP-Lab/MERGETUNE}{https://github.com/Surrey-UP-Lab/MERGETUNE}.", "AI": {"tldr": "介绍了一种新型范式，继续微调（CFT），通过MERGETUNE策略恢复预训练知识。", "motivation": "解决现有视觉语言模型在微调过程中容易遗忘预训练知识的问题。", "method": "提出一种简单的、与模型无关的继续微调策略MERGETUNE，利用线性模式连通性（LMC）来搜索具有两个低损失路径的模型以合并零样本和细调解决方案。", "result": "实验表明，MERGETUNE提高了CoOp在基础-新颖泛化上的谐波均值+5.6%，并且在跨数据集转移上首次超越了CLIP的表现。", "conclusion": "MERGETUNE通过继续微调策略有效恢复预训练知识，并在多种评估中达到最新技术水平。"}}
{"id": "2601.10496", "pdf": "https://arxiv.org/pdf/2601.10496", "abs": "https://arxiv.org/abs/2601.10496", "authors": ["Ali Al-Kaswan", "Claudio Spiess", "Prem Devanbu", "Arie van Deursen", "Maliheh Izadi"], "title": "Model See, Model Do? Exposure-Aware Evaluation of Bug-vs-Fix Preference in Code LLMs", "categories": ["cs.SE", "cs.AI"], "comment": "MSR 2026 Technical Track", "summary": "Large language models are increasingly used for code generation and debugging, but their outputs can still contain bugs, that originate from training data. Distinguishing whether an LLM prefers correct code, or a familiar incorrect version might be influenced by what it's been exposed to during training. We introduce an exposure-aware evaluation framework that quantifies how prior exposure to buggy versus fixed code influences a model's preference. Using the ManySStuBs4J benchmark, we apply Data Portraits for membership testing on the Stack-V2 corpus to estimate whether each buggy and fixed variant was seen during training. We then stratify examples by exposure and compare model preference using code completion as well as multiple likelihood-based scoring metrics We find that most examples (67%) have neither variant in the training data, and when only one is present, fixes are more frequently present than bugs. In model generations, models reproduce buggy lines far more often than fixes, with bug-exposed examples amplifying this tendency and fix-exposed examples showing only marginal improvement. In likelihood scoring, minimum and maximum token-probability metrics consistently prefer the fixed code across all conditions, indicating a stable bias toward correct fixes. In contrast, metrics like the Gini coefficient reverse preference when only the buggy variant was seen. Our results indicate that exposure can skew bug-fix evaluations and highlight the risk that LLMs may propagate memorised errors in practice.", "AI": {"tldr": "该论文提出了一种评估代码大语言模型对错误和修复版本偏好的框架，通过分析训练数据中的暴露情况来量化其偏好。", "motivation": "动机在于探讨大型语言模型在生成和调试过程中如何受制于训练数据的影响，并且试图理解这些模型是如何偏向正确的代码或熟悉但有误的变体。", "method": "使用ManySStuBs4J基准测试集，通过Data Portraits进行成员资格测试来估算每个错误与修复版本是否出现在Stack-V2语料库中。然后根据暴露情况对示例进行分类，并比较模型偏好使用代码补全及多个基于可能性的评分指标。", "result": "发现大多数（67%）的例子在训练数据中都没有两种变体，当其中一种存在时，修复版本比错误更常出现。在生成中，模型更频繁地复制出错误行；而暴露于错误或修复的数据则分别放大和仅轻微改善了这一倾向。", "conclusion": "结论是曝光情况可能歪曲对错误修复的评估，并强调大语言模型有潜在的风险会传播记忆中的错误。"}}
{"id": "2601.10485", "pdf": "https://arxiv.org/pdf/2601.10485", "abs": "https://arxiv.org/abs/2601.10485", "authors": ["Runhao Zhao", "Weixin Zeng", "Wentao Zhang", "Chong Chen", "Zhengpin Li", "Xiang Zhao", "Lei Chen"], "title": "Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge", "categories": ["cs.AI"], "comment": "13 pages, 4 figures", "summary": "Domain-specific knowledge graphs (DKGs) often lack coverage compared to general knowledge graphs (GKGs). To address this, we introduce Domain-specific Knowledge Graph Fusion (DKGF), a novel task that enriches DKGs by integrating relevant facts from GKGs. DKGF faces two key challenges: high ambiguity in domain relevance and misalignment in knowledge granularity across graphs. We propose ExeFuse, a simple yet effective Fact-as-Program paradigm. It treats each GKG fact as a latent semantic program, maps abstract relations to granularity-aware operators, and verifies domain relevance via program executability on the target DKG. This unified probabilistic framework jointly resolves relevance and granularity issues. We construct two benchmarks, DKGF(W-I) and DKGF(Y-I), with 21 evaluation configurations. Extensive experiments validate the task's importance and our model's effectiveness, providing the first standardized testbed for DKGF.", "AI": {"tldr": "本文介绍了Domain-specific Knowledge Graph Fusion (DKGF)任务，通过将通用知识图谱中的相关事实融合到领域特定的知识图谱中来丰富其内容。", "motivation": "该研究的动机在于解决领域特定知识图谱（DKGs）在覆盖范围上不如通用知识图谱（GKGs）的问题，提出了一种新的任务方法来填补这一空白。", "method": "文章提出了ExeFuse模型，这是一种基于Fact-as-Program范式的简单而有效的方法。它将每个GKG事实视为一个潜在的语义程序，并通过在目标DKGs上验证程序执行性来检查领域相关性。", "result": "作者构建了两个基准测试集DKGF(W-I)和DKGF(Y-I)，包含21种评估配置，实验结果证明了任务的重要性和模型的有效性，为DKGF提供了首个标准化的测试平台。", "conclusion": "研究通过ExeFuse模型有效解决了领域相关性和知识粒度对齐的问题，并构建了一套用于评估DKGF任务的标准基准。"}}
{"id": "2601.10477", "pdf": "https://arxiv.org/pdf/2601.10477", "abs": "https://arxiv.org/abs/2601.10477", "authors": ["Yu Wang", "Yi Wang", "Rui Dai", "Yujie Wang", "Kaikui Liu", "Xiangxiang Chu", "Yansheng Li"], "title": "Urban Socio-Semantic Segmentation with Vision-Language Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CY"], "comment": null, "summary": "As hubs of human activity, urban surfaces consist of a wealth of semantic entities. Segmenting these various entities from satellite imagery is crucial for a range of downstream applications. Current advanced segmentation models can reliably segment entities defined by physical attributes (e.g., buildings, water bodies) but still struggle with socially defined categories (e.g., schools, parks). In this work, we achieve socio-semantic segmentation by vision-language model reasoning. To facilitate this, we introduce the Urban Socio-Semantic Segmentation dataset named SocioSeg, a new resource comprising satellite imagery, digital maps, and pixel-level labels of social semantic entities organized in a hierarchical structure. Additionally, we propose a novel vision-language reasoning framework called SocioReasoner that simulates the human process of identifying and annotating social semantic entities via cross-modal recognition and multi-stage reasoning. We employ reinforcement learning to optimize this non-differentiable process and elicit the reasoning capabilities of the vision-language model. Experiments demonstrate our approach's gains over state-of-the-art models and strong zero-shot generalization. Our dataset and code are available in https://github.com/AMAP-ML/SocioReasoner.", "AI": {"tldr": "本文提出了一个基于视觉语言推理的框架SocioReasoner，用于解决城市社会语义分割问题，并构建了一个名为SocioSeg的数据集。", "motivation": "当前先进分割模型可以可靠地分割出由物理属性定义的对象，但在处理社会定义类别的对象时仍存在困难。因此，本文旨在通过视觉语言推理方法实现社会语义分割。", "method": "提出了一种新的基于视觉语言推理的框架SocioReasoner，并结合强化学习来优化这个非可微过程，以激发视觉语言模型的推理能力。", "result": "实验表明该方法在与现有最先进的模型相比有显著提升，并且具有强大的零样本泛化能力。", "conclusion": "本文通过引入新的数据集SocioSeg和视觉语言推理框架SocioReasoner，在城市社会语义分割上取得了进展，展示了视觉语言模型在解决这类任务上的潜力。"}}
{"id": "2601.10467", "pdf": "https://arxiv.org/pdf/2601.10467", "abs": "https://arxiv.org/abs/2601.10467", "authors": ["Kazi Noshin", "Syed Ishtiaque Ahmed", "Sharifa Sultana"], "title": "AI Sycophancy: How Users Flag and Respond", "categories": ["cs.HC"], "comment": null, "summary": "While concerns about LLM sycophancy have grown among researchers and developers, how users themselves experience this behavior remains largely unexplored. We analyze Reddit discussions to investigate how users detect, mitigate, and perceive sycophantic AI. We develop the ODR Framework that maps user experiences across three stages: observing sycophantic behaviors, detecting sycophancy, and responding to these behaviors. Our findings reveal that users employ various detection techniques, including cross-platform comparison and inconsistency testing. We document diverse mitigation approaches, such as persona-based prompts to specific language patterns in prompt engineering. We find sycophancy's effects are context-dependent rather than universally harmful. Specifically, vulnerable populations experiencing trauma, mental health challenges, or isolation actively seek and value sycophantic behaviors as emotional support. Users develop both technical and folk explanations for why sycophancy occurs. These findings challenge the assumption that sycophancy should be eliminated universally. We conclude by proposing context-aware AI design that balances the risks with the benefits of affirmative interaction, while discussing implications for user education and transparency.", "AI": {"tldr": "本文通过分析Reddit上的讨论，探讨用户如何检测、应对和感知AI的奉承行为，并提出ODR框架来描述用户的体验过程。", "motivation": "虽然关于大语言模型奉承行为的担忧日益增长，但用户如何看待这一现象的研究尚少，因此作者希望通过研究揭示用户对AI奉承的具体反应和理解。", "method": "作者分析了Reddit平台上的相关讨论，开发了ODR框架，描述用户在观察、检测和应对AI奉承行为三个阶段的不同体验。", "result": "研究表明用户使用多种方法来检测AI的奉承行为，并采取不同的缓解策略。此外，发现奉承的效果取决于情境，特别是对经历创伤或孤独的人可能有正面作用。", "conclusion": "研究结论挑战了消除所有奉承行为的观点，提出了基于上下文的情境感知设计，同时讨论了用户教育和透明度的重要性。"}}
{"id": "2601.10462", "pdf": "https://arxiv.org/pdf/2601.10462", "abs": "https://arxiv.org/abs/2601.10462", "authors": ["Ahmad Mustapha", "Charbel Toumieh", "Mariette Awad"], "title": "ChartComplete: A Taxonomy-based Inclusive Chart Dataset", "categories": ["cs.AI", "cs.CV"], "comment": "7 pages, 4 figures, 3 tables, 1 algorithm. Dataset and source code available at https://github.com/AI-DSCHubAUB/ChartComplete-Dataset", "summary": "With advancements in deep learning (DL) and computer vision techniques, the field of chart understanding is evolving rapidly. In particular, multimodal large language models (MLLMs) are proving to be efficient and accurate in understanding charts. To accurately measure the performance of MLLMs, the research community has developed multiple datasets to serve as benchmarks. By examining these datasets, we found that they are all limited to a small set of chart types. To bridge this gap, we propose the ChartComplete dataset. The dataset is based on a chart taxonomy borrowed from the visualization community, and it covers thirty different chart types. The dataset is a collection of classified chart images and does not include a learning signal. We present the ChartComplete dataset as is to the community to build upon it.", "AI": {"tldr": "介绍了一个名为ChartComplete的基于分类学的全面图表数据集。", "motivation": "现有的图表理解基准数据集仅限于少量的图表类型，作者希望通过创建一个包含更多类型的图表数据集来弥补这一不足。", "method": "基于可视化社区中的图表分类学构建了涵盖30种不同类型图表的数据集。", "result": "提出了ChartComplete数据集作为研究资源供学术界使用。", "conclusion": "ChartComplete数据集为评估多模态大型语言模型对各种类型图表的理解能力提供了重要资源。"}}
{"id": "2601.10460", "pdf": "https://arxiv.org/pdf/2601.10460", "abs": "https://arxiv.org/abs/2601.10460", "authors": ["Abhinaba Basu", "Pavan Chakraborty"], "title": "Contextual StereoSet: Stress-Testing Bias Alignment Robustness in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "comment": null, "summary": "A model that avoids stereotypes in a lab benchmark may not avoid them in deployment. We show that measured bias shifts dramatically when prompts mention different places, times, or audiences -- no adversarial prompting required. We introduce Contextual StereoSet, a benchmark that holds stereotype content fixed while systematically varying contextual framing. Testing 13 models across two protocols, we find striking patterns: anchoring to 1990 (vs. 2030) raises stereotype selection in all models tested on this contrast (p<0.05); gossip framing raises it in 5 of 6 full-grid models; out-group observer framing shifts it by up to 13 percentage points. These effects replicate in hiring, lending, and help-seeking vignettes. We propose Context Sensitivity Fingerprints (CSF): a compact profile of per-dimension dispersion and paired contrasts with bootstrap CIs and FDR correction. Two evaluation tracks support different use cases -- a 360-context diagnostic grid for deep analysis and a budgeted protocol covering 4,229 items for production screening. The implication is methodological: bias scores from fixed-condition tests may not generalize.This is not a claim about ground-truth bias rates; it is a stress test of evaluation robustness. CSF forces evaluators to ask, \"Under what conditions does bias appear?\" rather than \"Is this model biased?\" We release our benchmark, code, and results.", "AI": {"tldr": "该论文介绍了Contextual StereoSet基准测试，用于评估大型语言模型在不同语境下避免刻板印象的能力。", "motivation": "动机在于揭示即使在一个实验室环境中表现良好的模型，在实际部署中也可能会表现出不同的刻板印象倾向，并且提出了一个系统性地改变环境框架同时保持刻板印象内容不变的基准测试方法。", "method": "通过引入Contextual StereoSet基准测试和Context Sensitivity Fingerprints（CSF），分别支持深度分析和生产筛查，以检测不同背景下的模型表现。", "result": "在13个不同的模型中进行了测试，并发现在特定情况下如锚定于过去年代、八卦框架或对外群体的观察者视角下，刻板印象的选择率会有显著提升。", "conclusion": "研究结果表明固定条件测试中的偏差得分可能无法推广到其他情境。这强调了评价方法需要考虑模型在不同条件下表现差异的重要性，并提供了新的评估工具来帮助更准确地识别和减轻这些偏差。"}}
{"id": "2601.10458", "pdf": "https://arxiv.org/pdf/2601.10458", "abs": "https://arxiv.org/abs/2601.10458", "authors": ["Raphael Buchmüller", "Dennis Collaris", "Linhao Meng", "Angelos Chatzimparmpas"], "title": "LangLasso: Interactive Cluster Descriptions through LLM Explanation", "categories": ["cs.HC", "cs.LG", "stat.CO"], "comment": "This manuscript is accepted for publication in VIS 2025 VISxGenAI Workshop", "summary": "Dimensionality reduction is a powerful technique for revealing structure and potential clusters in data. However, as the axes are complex, non-linear combinations of features, they often lack semantic interpretability. Existing visual analytics (VA) methods support cluster interpretation through feature comparison and interactive exploration, but they require technical expertise and intense human effort. We present \\textit{LangLasso}, a novel method that complements VA approaches through interactive, natural language descriptions of clusters using large language models (LLMs). It produces human-readable descriptions that make cluster interpretation accessible to non-experts and allow integration of external contextual knowledge beyond the dataset. We systematically evaluate the reliability of these explanations and demonstrate that \\langlasso provides an effective first step for engaging broader audiences in cluster interpretation. The tool is available at https://langlasso.vercel.app", "AI": {"tldr": "介绍了一种名为LangLasso的新方法，通过使用大型语言模型生成交互式的自然语言描述来解释数据集中的聚类。", "motivation": "现有的可视化分析方法支持聚类的解释，但需要技术专业知识和大量人力。为了使非专家也能够理解聚类，并允许结合超出数据集的外部知识背景，提出了LangLasso。", "method": "使用大型语言模型（LLMs）生成人类可读的描述来补充现有的视觉数据分析方法，以实现对聚类的交互式解释。", "result": "系统性地评估了这些解释的可靠性，并证明了LangLasso为吸引更广泛的受众参与聚类解读提供了有效的第一步。", "conclusion": "LangLasso提供了一种新的方式，通过自然语言描述来使非专家也能理解数据集中的复杂结构和潜在集群。"}}
{"id": "2601.10457", "pdf": "https://arxiv.org/pdf/2601.10457", "abs": "https://arxiv.org/abs/2601.10457", "authors": ["Ziming Dai", "Dabiao Ma", "Jinle Tong", "Mengyuan Han", "Jian Yang", "Haojun Fei"], "title": "NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models", "categories": ["cs.AI"], "comment": null, "summary": "Although the Gradient Boosted Decision Trees (GBDTs) dominate industrial tabular applications, upgrading legacy models in high-concurrency production environments still faces prohibitive retraining costs and systemic risks. To address this problem, we present NSR-Boost, a neuro-symbolic residual boosting framework designed specifically for industrial scenarios. Its core advantage lies in being \"non-intrusive\". It treats the legacy model as a frozen model and performs targeted repairs on \"hard regions\" where predictions fail. The framework comprises three key stages: first, finding hard regions through residuals, then generating interpretable experts by generating symbolic code structures using Large Language Model (LLM) and fine-tuning parameters using Bayesian optimization, and finally dynamically integrating experts with legacy model output through a lightweight aggregator. We report on the successful deployment of NSR-Boost within the core financial risk control system at Qfin Holdings. This framework not only significantly outperforms state-of-the-art (SOTA) baselines across six public datasets and one private dataset, more importantly, shows excellent performance gains on real-world online data. In conclusion, it effectively captures long-tail risks missed by traditional models and offers a safe, low-cost evolutionary paradigm for industry.", "AI": {"tldr": "介绍了一种名为NSR-Boost的神经符号残差增强框架，专门用于工业场景中旧模型的升级。", "motivation": "尽管GBDT在工业表格应用中占据主导地位，但在高并发生产环境中升级旧模型仍然面临重新训练成本高昂和系统性风险的问题。", "method": "NSR-Boost包括三个关键阶段：通过残差找到困难区域；生成解释性专家，使用大型语言模型（LLM）产生符号代码结构并通过贝叶斯优化调整参数；最后通过轻量级聚合器动态集成专家与旧模型的输出。", "result": "该框架不仅在六个公共数据集和一个私有数据集中显著超越了最先进的基线方法，而且在真实世界在线数据上也表现出色。", "conclusion": "NSR-Boost有效捕捉传统模型遗漏的长尾风险，并为行业提供了一种安全、低成本的进化范式。"}}
{"id": "2601.10455", "pdf": "https://arxiv.org/pdf/2601.10455", "abs": "https://arxiv.org/abs/2601.10455", "authors": ["Ruochen Li", "Kun Yuan", "Yufei Xia", "Yue Zhou", "Qingyu Lu", "Weihang Li", "Youxiang Zhu", "Nassir Navab"], "title": "SurgGoal: Rethinking Surgical Planning Evaluation via Goal-Satisfiability", "categories": ["cs.CL", "cs.RO"], "comment": null, "summary": "Surgical planning integrates visual perception, long-horizon reasoning, and procedural knowledge, yet it remains unclear whether current evaluation protocols reliably assess vision-language models (VLMs) in safety-critical settings. Motivated by a goal-oriented view of surgical planning, we define planning correctness via phase-goal satisfiability, where plan validity is determined by expert-defined surgical rules. Based on this definition, we introduce a multicentric meta-evaluation benchmark with valid procedural variations and invalid plans containing order and content errors. Using this benchmark, we show that sequence similarity metrics systematically misjudge planning quality, penalizing valid plans while failing to identify invalid ones. We therefore adopt a rule-based goal-satisfiability metric as a high-precision meta-evaluation reference to assess Video-LLMs under progressively constrained settings, revealing failures due to perception errors and under-constrained reasoning. Structural knowledge consistently improves performance, whereas semantic guidance alone is unreliable and benefits larger models only when combined with structural constraints.", "AI": {"tldr": "本文提出了SurgGoal，通过目标满足性重新思考手术规划评估，并引入多中心元评估基准来检验视频语言模型在手术规划中的表现。", "motivation": "目前尚不清楚现有的评价方案是否能可靠地评估视觉语言模型在高风险环境下的性能。为了更好地理解这个问题，作者从目标导向的角度定义了手术规划的正确性，并通过专家定义的目标满足性来衡量。", "method": "基于目标满足性的定义，本文设计了一个多中心元评估基准，包含了有效的程序变体和无效计划（含有顺序和内容错误）。使用这个基准，本文检验了序列相似度指标在判断规划质量方面存在的问题，并提出采用规则基目标满足性指标作为高精度的元评估参考。", "result": "实验结果表明，序列相似度指标会误判有效计划为无效，并且无法识别出真正的无效计划。通过逐步增加约束条件下的评估，发现感知错误和推理不足是导致失败的主要原因。", "conclusion": "本文得出结论，结构知识能够提升视频语言模型在手术规划任务上的性能，但语义指导本身并不足以保证准确性，只有当结合结构约束时，这种指导才能显著提高大型模型的效能。"}}
{"id": "2601.10453", "pdf": "https://arxiv.org/pdf/2601.10453", "abs": "https://arxiv.org/abs/2601.10453", "authors": ["Victor Zheleznov", "Stefan Bilbao", "Alec Wright", "Simon King"], "title": "Stable Differentiable Modal Synthesis for Learning Nonlinear Dynamics", "categories": ["cs.SD", "cs.LG", "eess.AS", "physics.comp-ph"], "comment": "Submitted to the Journal of Audio Engineering Society (December 2025)", "summary": "Modal methods are a long-standing approach to physical modelling synthesis. Extensions to nonlinear problems are possible, including the case of a high-amplitude vibration of a string. A modal decomposition leads to a densely coupled nonlinear system of ordinary differential equations. Recent work in scalar auxiliary variable techniques has enabled construction of explicit and stable numerical solvers for such classes of nonlinear systems. On the other hand, machine learning approaches (in particular neural ordinary differential equations) have been successful in modelling nonlinear systems automatically from data. In this work, we examine how scalar auxiliary variable techniques can be combined with neural ordinary differential equations to yield a stable differentiable model capable of learning nonlinear dynamics. The proposed approach leverages the analytical solution for linear vibration of system's modes so that physical parameters of a system remain easily accessible after the training without the need for a parameter encoder in the model architecture. As a proof of concept, we generate synthetic data for the nonlinear transverse vibration of a string and show that the model can be trained to reproduce the nonlinear dynamics of the system. Sound examples are presented.", "AI": {"tldr": "本文提出了一种结合标量辅助变量技术和神经普通微分方程的方法，用于学习非线性系统的动力学特性。", "motivation": "动机在于将物理建模合成方法中的模态分解与机器学习方法相结合，以开发一种稳定且可微的模型，从而自动从数据中学习非线性系统的行为。", "method": "本文使用标量辅助变量技术构建稳定的数值解算器，并结合神经普通微分方程来生成一个可学习非线性动态的模型。该模型利用系统的模式线性振动的解析解决方案，使得物理参数在训练后仍然可以轻松访问。", "result": "通过合成数据生成非线性横向弦振动的数据，证明了所提出的方法能够成功地再现系统中的非线性动力学行为，并提供了声音示例以展示其有效性。", "conclusion": "研究表明结合标量辅助变量技术和神经普通微分方程可以构建一个稳定且可学习的模型来模拟非线性动态。"}}
{"id": "2601.10449", "pdf": "https://arxiv.org/pdf/2601.10449", "abs": "https://arxiv.org/abs/2601.10449", "authors": ["Clementine Grethen", "Nicolas Menga", "Roland Brochard", "Geraldine Morin", "Simone Gasparini", "Jeremy Lebreton", "Manuel Sanchez Gestido"], "title": "Lunar-G2R: Geometry-to-Reflectance Learning for High-Fidelity Lunar BRDF Estimation", "categories": ["cs.CV"], "comment": "Data & code: https://clementinegrethen.github.io/publications/Lunar-G2R", "summary": "We address the problem of estimating realistic, spatially varying reflectance for complex planetary surfaces such as the lunar regolith, which is critical for high-fidelity rendering and vision-based navigation. Existing lunar rendering pipelines rely on simplified or spatially uniform BRDF models whose parameters are difficult to estimate and fail to capture local reflectance variations, limiting photometric realism. We propose Lunar-G2R, a geometry-to-reflectance learning framework that predicts spatially varying BRDF parameters directly from a lunar digital elevation model (DEM), without requiring multi-view imagery, controlled illumination, or dedicated reflectance-capture hardware at inference time. The method leverages a U-Net trained with differentiable rendering to minimize photometric discrepancies between real orbital images and physically based renderings under known viewing and illumination geometry. Experiments on a geographically held-out region of the Tycho crater show that our approach reduces photometric error by 38 % compared to a state-of-the-art baseline, while achieving higher PSNR and SSIM and improved perceptual similarity, capturing fine-scale reflectance variations absent from spatially uniform models. To our knowledge, this is the first method to infer a spatially varying reflectance model directly from terrain geometry.", "AI": {"tldr": "本论文提出了Lunar-G2R，一种从月球数字高程模型预测空间变化BRDF参数的几何到反射学习框架。", "motivation": "现有月球渲染管道依赖简化的或空间均匀的BRDF模型，难以估计且无法捕捉局部反射率变化，限制了光度的真实感。", "method": "Lunar-G2R使用一个U-Net，通过可微渲染技术来最小化实际轨道图像与基于物理的渲染之间的光度差异。", "result": "实验表明，在Tycho陨石坑的一个地理上独立区域中，该方法将光度误差减少了38%，并实现了更高的PSNR和SSIM以及改进了感知相似性。", "conclusion": "这是首次直接从地形几何推断空间变化反射率模型的方法。"}}
{"id": "2601.10448", "pdf": "https://arxiv.org/pdf/2601.10448", "abs": "https://arxiv.org/abs/2601.10448", "authors": ["Naeem Ramzan", "Muhammad Tufail Khan"], "title": "Subjective evaluation of UHD video coded using VVC with LCEVC and ML-VVC", "categories": ["cs.MM", "cs.CV"], "comment": null, "summary": "This paper presents the results of a subjective quality assessment of a multilayer video coding configuration in which Low Complexity Enhancement Video Coding (LCEVC) is applied as an enhancement layer on top of a Versatile Video Coding (VVC) base layer. The evaluation follows the same test methodology and conditions previously defined for MPEG multilayer video coding assessments, with the LCEVC enhancement layer encoded using version 8.1 of the LCEVC Test Model (LTM). The test compares reconstructed UHD output generated from an HD VVC base layer with LCEVC enhancement against two reference cases: upsampled VVC base layer decoding and multilayer VVC (ML-VVC). Two operating points are considered, corresponding to enhancement layers representing approximately 10% and 50% of the total bitrate. Subjective assessment was conducted using the Degradation Category Rating (DCR) methodology with twenty five participants, across a dataset comprising fifteen SDR and HDR sequences. The reported results include Mean Opinion Scores (MOS) with associated 95% confidence intervals, enabling comparison of perceptual quality across coding approaches and operating points within the defined test scope.", "AI": {"tldr": "本文描述了使用VVC和LCEVC对UHD视频进行主观质量评估的实验。", "motivation": "研究动机在于比较不同多层视频编码配置下的感知质量，特别是在低复杂度增强视频编码（LCEVC）作为增强层应用在Versatile Video Coding (VVC)基础层上的情况下。", "method": "采用相同的测试方法和条件，如MPEG多层视频编码评估中定义的那样。使用版本8.1的LCEVC测试模型进行增强层编码，并且进行了两个操作点的测试，即增强层分别代表总码率的大约10%和50%。", "result": "实验采用25名参与者通过退化类别评分（DCR）方法对主观质量进行了评估。提供了十五个SDR和HDR序列的数据集中的平均意见得分（MOS），并给出了95%的置信区间。", "conclusion": "研究结果表明了在所定义测试范围内的不同编码方法和操作点之间的感知质量比较，为进一步优化多层视频编码配置提供了有价值的参考。"}}
{"id": "2601.10440", "pdf": "https://arxiv.org/pdf/2601.10440", "abs": "https://arxiv.org/abs/2601.10440", "authors": ["Nadya Abaev", "Denis Klimov", "Gerard Levinov", "David Mimran", "Yuval Elovici", "Asaf Shabtai"], "title": "AgentGuardian: Learning Access Control Policies to Govern AI Agent Behavior", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "14 pages, 5 figures", "summary": "Artificial intelligence (AI) agents are increasingly used in a variety of domains to automate tasks, interact with users, and make decisions based on data inputs. Ensuring that AI agents perform only authorized actions and handle inputs appropriately is essential for maintaining system integrity and preventing misuse. In this study, we introduce the AgentGuardian, a novel security framework that governs and protects AI agent operations by enforcing context-aware access-control policies. During a controlled staging phase, the framework monitors execution traces to learn legitimate agent behaviors and input patterns. From this phase, it derives adaptive policies that regulate tool calls made by the agent, guided by both real-time input context and the control flow dependencies of multi-step agent actions. Evaluation across two real-world AI agent applications demonstrates that AgentGuardian effectively detects malicious or misleading inputs while preserving normal agent functionality. Moreover, its control-flow-based governance mechanism mitigates hallucination-driven errors and other orchestration-level malfunctions.", "AI": {"tldr": "介绍AgentGuardian，一种通过执行上下文感知的访问控制策略来管理和保护AI代理操作的安全框架。", "motivation": "随着AI代理在多个领域中的广泛应用，确保它们仅执行授权行为并妥善处理输入变得至关重要，以维护系统完整性和防止滥用。", "method": "AgentGuardian在一个受控阶段监控执行跟踪来学习合法的代理行为和输入模式，并基于实时输入上下文及多步骤代理操作的控制流依赖性制定自适应策略。", "result": "实验结果表明，AgentGuardian能有效检测恶意或误导性的输入，同时保持正常的代理功能。其基于控制流的治理机制还减少了幻觉驱动错误和其他编排级故障。", "conclusion": "AgentGuardian通过学习并应用上下文感知访问控制策略成功保护了AI代理操作的安全性，并展示了在实际应用场景中的有效性。"}}
{"id": "2601.10436", "pdf": "https://arxiv.org/pdf/2601.10436", "abs": "https://arxiv.org/abs/2601.10436", "authors": ["Le Ngoc Luyen", "Marie-Hélène Abel", "Philippe Gouspillou"], "title": "Development of Ontological Knowledge Bases by Leveraging Large Language Models", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Ontological Knowledge Bases (OKBs) play a vital role in structuring domain-specific knowledge and serve as a foundation for effective knowledge management systems. However, their traditional manual development poses significant challenges related to scalability, consistency, and adaptability. Recent advancements in Generative AI, particularly Large Language Models (LLMs), offer promising solutions for automating and enhancing OKB development. This paper introduces a structured, iterative methodology leveraging LLMs to optimize knowledge acquisition, automate ontology artifact generation, and enable continuous refinement cycles. We demonstrate this approach through a detailed case study focused on developing a user context profile ontology within the vehicle sales domain. Key contributions include significantly accelerated ontology construction processes, improved ontological consistency, effective bias mitigation, and enhanced transparency in the ontology engineering process. Our findings highlight the transformative potential of integrating LLMs into ontology development, notably improving scalability, integration capabilities, and overall efficiency in knowledge management systems.", "AI": {"tldr": "本文介绍了利用大型语言模型（LLMs）优化本体知识库（OKBs）开发的结构化、迭代方法，并通过详细案例研究展示了这种方法在用户上下文配置文件本体重构过程中的应用。", "motivation": "传统的手动开发本体知识库面临扩展性、一致性和适应性的挑战，而大型语言模型的进步提供了解决这些问题并自动增强OKB开发的方法。", "method": "本文提出了一种利用LLMs优化知识获取、自动化生成本体重构件和实现持续精炼周期的结构化迭代方法，并通过一个关于汽车销售领域用户上下文配置文件本体开发的案例研究来展示该方法。", "result": "主要贡献包括显著加速了本体重构过程，提高了本体的一致性，有效地缓解了偏见，并增强了本体工程过程中的透明度。研究表明集成LLMs到本体开发中具有变革潜力，特别是在提高扩展性和整体效率方面。", "conclusion": "研究结果表明，利用大型语言模型可以有效改进本体重构的规模、整合能力和知识管理系统的一般效率。"}}
{"id": "2601.10421", "pdf": "https://arxiv.org/pdf/2601.10421", "abs": "https://arxiv.org/abs/2601.10421", "authors": ["Philip Resnik"], "title": "Are Language Models Models?", "categories": ["cs.CL", "cs.AI"], "comment": "5 pages. This is an invited commentary under review at Behavioral and Brain Sciences", "summary": "Futrell and Mahowald claim LMs \"serve as model systems\", but an assessment at each of Marr's three levels suggests the claim is clearly not true at the implementation level, poorly motivated at the algorithmic-representational level, and problematic at the computational theory level. LMs are good candidates as tools; calling them cognitive models overstates the case and unnecessarily feeds LLM hype.", "AI": {"tldr": "该论文评估了语言模型是否可以作为认知模型，并在多个层面上进行了分析。", "motivation": "作者试图质疑Futrell和Mahowald关于语言模型可以作为模型系统的主张，探讨其在不同层面的合理性。", "method": "采用Marr的三个层次（实现、算法-表示法和计算理论）来评估语言模型是否能被视为认知模型。", "result": "发现语言模型在实现层面上不成立，在算法-表示法层面上动机不足，在计算理论层面上存在问题。", "conclusion": "认为称语言模型为认知模型过于夸大，这种说法助长了大语言模型的炒作。"}}
{"id": "2601.10416", "pdf": "https://arxiv.org/pdf/2601.10416", "abs": "https://arxiv.org/abs/2601.10416", "authors": ["Tiesunlong Shen", "Rui Mao", "Jin Wang", "Heming Sun", "Jian Zhang", "Xuejie Zhang", "Erik Cambria"], "title": "LLMdoctor: Token-Level Flow-Guided Preference Optimization for Efficient Test-Time Alignment of Large Language Models", "categories": ["cs.AI"], "comment": "Accepted by AAAI26", "summary": "Aligning Large Language Models (LLMs) with human preferences is critical, yet traditional fine-tuning methods are computationally expensive and inflexible. While test-time alignment offers a promising alternative, existing approaches often rely on distorted trajectory-level signals or inefficient sampling, fundamentally capping performance and failing to preserve the generative diversity of the base model. This paper introduces LLMdoctor, a novel framework for efficient test-time alignment that operates via a patient-doctor paradigm. It integrates token-level reward acquisition with token-level flow-guided preference optimization (TFPO) to steer a large, frozen patient LLM with a smaller, specialized doctor model. Unlike conventional methods that rely on trajectory-level rewards, LLMdoctor first extracts fine-grained, token-level preference signals from the patient model's behavioral variations. These signals then guide the training of the doctor model via TFPO, which establishes flow consistency across all subtrajectories, enabling precise token-by-token alignment while inherently preserving generation diversity. Extensive experiments demonstrate that LLMdoctor significantly outperforms existing test-time alignment methods and even surpasses the performance of full fine-tuning approaches like DPO.", "AI": {"tldr": "介绍LLMdoctor，一种通过患者-医生范式实现高效测试时间对齐的新型框架。", "motivation": "传统微调方法计算成本高且缺乏灵活性，而现有的测试时间对齐方法依赖于扭曲轨迹级别的信号或低效采样，限制了性能并未能保持基础模型生成多样性。", "method": "LLMdoctor结合令牌级奖励获取与令牌级流引导偏好优化（TFPO），使用较小的专业医生模型来指导较大的冻结患者模型。首先提取患者模型行为变化中的细粒度、令牌级偏好信号，并通过TFPO训练医生模型，确保所有子轨迹的流一致性。", "result": "实验表明LLMdoctor显著超越现有测试时间对齐方法的表现，甚至优于完全微调方法如DPO。", "conclusion": "LLMdoctor提供了一种高效且保持生成多样性的测试时间对齐方式。"}}
{"id": "2601.10413", "pdf": "https://arxiv.org/pdf/2601.10413", "abs": "https://arxiv.org/abs/2601.10413", "authors": ["Haiyue Yuan", "Nikolay Matyunin", "Ali Raza", "Shujun Li"], "title": "LADFA: A Framework of Using Large Language Models and Retrieval-Augmented Generation for Personal Data Flow Analysis in Privacy Policies", "categories": ["cs.AI", "cs.CR"], "comment": null, "summary": "Privacy policies help inform people about organisations' personal data processing practices, covering different aspects such as data collection, data storage, and sharing of personal data with third parties. Privacy policies are often difficult for people to fully comprehend due to the lengthy and complex legal language used and inconsistent practices across different sectors and organisations. To help conduct automated and large-scale analyses of privacy policies, many researchers have studied applications of machine learning and natural language processing techniques, including large language models (LLMs). While a limited number of prior studies utilised LLMs for extracting personal data flows from privacy policies, our approach builds on this line of work by combining LLMs with retrieval-augmented generation (RAG) and a customised knowledge base derived from existing studies. This paper presents the development of LADFA, an end-to-end computational framework, which can process unstructured text in a given privacy policy, extract personal data flows and construct a personal data flow graph, and conduct analysis of the data flow graph to facilitate insight discovery. The framework consists of a pre-processor, an LLM-based processor, and a data flow post-processor. We demonstrated and validated the effectiveness and accuracy of the proposed approach by conducting a case study that involved examining ten selected privacy policies from the automotive industry. Moreover, it is worth noting that LADFA is designed to be flexible and customisable, making it suitable for a range of text-based analysis tasks beyond privacy policy analysis.", "AI": {"tldr": "本文介绍了LADFA框架，该框架结合了大型语言模型和检索增强生成技术，用于从隐私政策中提取个人数据流并构建分析图。", "motivation": "由于隐私政策往往使用复杂的法律语言且各行业实践不一，导致人们难以完全理解。因此，本文旨在开发一个自动化工具来帮助大规模分析隐私政策中的个人数据流动。", "method": "LADFA框架包含预处理、基于LLM的处理器和数据流后处理器三部分，通过结合大型语言模型和检索增强生成技术提取并分析隐私政策中的个人数据流。", "result": "通过对汽车行业10个精选隐私政策进行案例研究，验证了所提出方法的有效性和准确性。", "conclusion": "LADFA框架展示了从隐私政策中自动提取和分析个人数据流动的潜力，并且具备灵活性和可定制性，适用于多种基于文本的分析任务。"}}
{"id": "2601.10406", "pdf": "https://arxiv.org/pdf/2601.10406", "abs": "https://arxiv.org/abs/2601.10406", "authors": ["Weiping Fu", "Bifan Wei", "Jingyi Hao", "Yushun Zhang", "Jian Zhang", "Jiaxin Wang", "Bo Li", "Yu He", "Lingling Zhang", "Jun Liu"], "title": "ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics", "categories": ["cs.AI"], "comment": null, "summary": "Automatic Question Generation (QG) often produces outputs with critical defects, such as factual hallucinations and answer mismatches. However, existing evaluation methods, including LLM-based evaluators, mainly adopt a black-box and holistic paradigm without explicit error modeling, leading to the neglect of such defects and overestimation of question quality. To address this issue, we propose ErrEval, a flexible and Error-aware Evaluation framework that enhances QG evaluation through explicit error diagnostics. Specifically, ErrEval reformulates evaluation as a two-stage process of error diagnosis followed by informed scoring. At the first stage, a lightweight plug-and-play Error Identifier detects and categorizes common errors across structural, linguistic, and content-related aspects. These diagnostic signals are then incorporated as explicit evidence to guide LLM evaluators toward more fine-grained and grounded judgments. Extensive experiments on three benchmarks demonstrate the effectiveness of ErrEval, showing that incorporating explicit diagnostics improves alignment with human judgments. Further analyses confirm that ErrEval effectively mitigates the overestimation of low-quality questions.", "AI": {"tldr": "本文提出ErrEval，一种错误感知的评估框架，通过显式诊断提升自动问题生成的质量评估。", "motivation": "现有的评估方法忽视了自动生成问题中的关键缺陷，如事实性幻觉和答案不匹配，导致对问题质量的高估。", "method": "ErrEval将评估过程分为两个阶段：错误识别（检测并分类常见错误）和基于诊断信息进行评分。", "result": "在三个基准上的广泛实验表明，ErrEval能有效改善与人工判断的一致性，并缓解低质量问题被过度评价的问题。", "conclusion": "显式诊断信息可以显著提升自动问题生成评估的准确性和可靠性。"}}
{"id": "2601.10402", "pdf": "https://arxiv.org/pdf/2601.10402", "abs": "https://arxiv.org/abs/2601.10402", "authors": ["Xinyu Zhu", "Yuzhu Cai", "Zexi Liu", "Bingyang Zheng", "Cheng Wang", "Rui Ye", "Jiaao Chen", "Hanrui Wang", "Wei-Chen Wang", "Yuzhi Zhang", "Linfeng Zhang", "Weinan E", "Di Jin", "Siheng Chen"], "title": "Toward Ultra-Long-Horizon Agentic Science: Cognitive Accumulation for Machine Learning Engineering", "categories": ["cs.AI"], "comment": "26 pages. 5 figures", "summary": "The advancement of artificial intelligence toward agentic science is currently bottlenecked by the challenge of ultra-long-horizon autonomy, the ability to sustain strategic coherence and iterative correction over experimental cycles spanning days or weeks. While Large Language Models (LLMs) have demonstrated prowess in short-horizon reasoning, they are easily overwhelmed by execution details in the high-dimensional, delayed-feedback environments of real-world research, failing to consolidate sparse feedback into coherent long-term guidance. Here, we present ML-Master 2.0, an autonomous agent that masters ultra-long-horizon machine learning engineering (MLE) which is a representative microcosm of scientific discovery. By reframing context management as a process of cognitive accumulation, our approach introduces Hierarchical Cognitive Caching (HCC), a multi-tiered architecture inspired by computer systems that enables the structural differentiation of experience over time. By dynamically distilling transient execution traces into stable knowledge and cross-task wisdom, HCC allows agents to decouple immediate execution from long-term experimental strategy, effectively overcoming the scaling limits of static context windows. In evaluations on OpenAI's MLE-Bench under 24-hour budgets, ML-Master 2.0 achieves a state-of-the-art medal rate of 56.44%. Our findings demonstrate that ultra-long-horizon autonomy provides a scalable blueprint for AI capable of autonomous exploration beyond human-precedent complexities.", "AI": {"tldr": "本文介绍了ML-Master 2.0，一种能够实现超长期自主机器学习工程的智能代理。", "motivation": "当前人工智能向代理科学发展的瓶颈在于超长时间跨度上的自主性能力不足，即在数天或数周的实验周期中维持战略连贯性和迭代修正的能力。大型语言模型（LLMs）虽然在短期推理上表现出色，但在高维、延迟反馈的真实研究环境中容易被执行细节所困扰，无法将稀疏反馈整合为长期指导。", "method": "本文通过重新定义上下文管理为认知积累过程，并引入分层认知缓存（HCC），一种多层级架构，从计算机系统中汲取灵感，以在时间上对经验进行结构化分化。该方法能够动态地将瞬时执行轨迹转化为稳定知识和跨任务智慧，使代理能够在长期实验策略与即时执行之间解耦。", "result": "在OpenAI的MLE-Bench基准测试下，ML-Master 2.0在24小时预算内达到56.44%的金牌率，显示出超长时间自主性为人工智能提供了探索超出人类先例复杂性的可扩展蓝图。", "conclusion": "研究结果表明，超长期自主性能提供一个可扩展的蓝图，使人工智能能够实现超越人类已知复杂程度的自主探索。"}}
{"id": "2601.10398", "pdf": "https://arxiv.org/pdf/2601.10398", "abs": "https://arxiv.org/abs/2601.10398", "authors": ["Xuancheng Ren", "Shijing Hu", "Zhihui Lu", "Jiangqi Huang", "Qiang Duan"], "title": "LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL Queries", "categories": ["cs.AI"], "comment": null, "summary": "In LLM-based text-to-SQL systems, unanswerable and underspecified user queries may generate not only incorrect text but also executable programs that yield misleading results or violate safety constraints, posing a major barrier to safe deployment. Existing refusal strategies for such queries either rely on output-level instruction following, which is brittle due to model hallucinations, or estimate output uncertainty, which adds complexity and overhead. To address this challenge, we formalize safe refusal in text-to-SQL systems as an answerability-gating problem and propose LatentRefusal, a latent-signal refusal mechanism that predicts query answerability from intermediate hidden activations of a large language model. We introduce the Tri-Residual Gated Encoder, a lightweight probing architecture, to suppress schema noise and amplify sparse, localized cues of question-schema mismatch that indicate unanswerability. Extensive empirical evaluations across diverse ambiguous and unanswerable settings, together with ablation studies and interpretability analyses, demonstrate the effectiveness of the proposed approach and show that LatentRefusal provides an attachable and efficient safety layer for text-to-SQL systems. Across four benchmarks, LatentRefusal improves average F1 to 88.5 percent on both backbones while adding approximately 2 milliseconds of probe overhead.", "AI": {"tldr": "论文提出了LatentRefusal，一种从大型语言模型的中间隐藏激活预测查询可回答性的拒绝机制，用于处理文本到SQL系统的不可回答或欠指定查询。", "motivation": "在LLM驱动的文本到SQL系统中，用户提交的无法回答或欠指定的查询可能导致生成错误代码或者误导结果，从而阻碍了这些系统的安全部署。现有的拒绝策略要么依赖于输出级别的指令遵循，这容易因为模型幻觉而失效；要么估计输出不确定性，增加了复杂性和开销。", "method": "提出了LatentRefusal和Tri-Residual Gated Encoder架构，通过抑制模式噪音并放大问题与模式不匹配的稀疏、局部线索来预测查询的回答可能性。", "result": "实验表明该方法在四种基准测试中平均F1值达到88.5%，同时增加了约2毫秒的探测开销，证明了LatentRefusal作为文本到SQL系统的安全层的有效性和效率。", "conclusion": "通过实证评估、消融研究和解释性分析验证了LatentRefusal的有效性，它提供了一个附加且高效的安全部署解决方案。"}}
{"id": "2601.10392", "pdf": "https://arxiv.org/pdf/2601.10392", "abs": "https://arxiv.org/abs/2601.10392", "authors": ["Hassan Eshkiki", "Sarah Costa", "Mostafa Mohammadpour", "Farinaz Tanhaei", "Christopher H. George", "Fabio Caraffini"], "title": "Multi-Temporal Frames Projection for Dynamic Processes Fusion in Fluorescence Microscopy", "categories": ["cs.CV"], "comment": null, "summary": "Fluorescence microscopy is widely employed for the analysis of living biological samples; however, the utility of the resulting recordings is frequently constrained by noise, temporal variability, and inconsistent visualisation of signals that oscillate over time. We present a unique computational framework that integrates information from multiple time-resolved frames into a single high-quality image, while preserving the underlying biological content of the original video. We evaluate the proposed method through an extensive number of configurations (n = 111) and on a challenging dataset comprising dynamic, heterogeneous, and morphologically complex 2D monolayers of cardiac cells. Results show that our framework, which consists of a combination of explainable techniques from different computer vision application fields, is capable of generating composite images that preserve and enhance the quality and information of individual microscopy frames, yielding 44% average increase in cell count compared to previous methods. The proposed pipeline is applicable to other imaging domains that require the fusion of multi-temporal image stacks into high-quality 2D images, thereby facilitating annotation and downstream segmentation.", "AI": {"tldr": "本文提出了一种计算框架，将来自多个时间分辨帧的信息整合为单个高质量图像，同时保留原始视频的生物信息。", "motivation": "荧光显微镜在分析活体样本时受限于噪声、时间变异性以及信号随时间波动导致的不一致可视化问题。该方法旨在解决这些问题，并提高成像质量。", "method": "通过结合来自不同计算机视觉应用领域的可解释技术，提出一种新的计算框架，将多帧信息融合为一张高质量图像。", "result": "在复杂的细胞样本数据集上进行了评估，结果表明新框架能够生成保留并增强原始图像质量和信息的复合图像，并且相比以前的方法，平均增加了44%的细胞计数。", "conclusion": "该方法适用于需要将多时态图像堆栈融合为高质量2D图像的其他成像领域，便于注释和后续分割。"}}
{"id": "2601.10386", "pdf": "https://arxiv.org/pdf/2601.10386", "abs": "https://arxiv.org/abs/2601.10386", "authors": ["Filippo Ruffini", "Camillo Maria Caruso", "Claudia Tacconi", "Lorenzo Nibid", "Francesca Miccolis", "Marta Lovino", "Carlo Greco", "Edy Ippolito", "Michele Fiore", "Alessio Cortellini", "Bruno Beomonte Zobel", "Giuseppe Perrone", "Bruno Vincenzi", "Claudio Marrocco", "Alessandro Bria", "Elisa Ficarra", "Sara Ramella", "Valerio Guarrasi", "Paolo Soda"], "title": "Handling Missing Modalities in Multimodal Survival Prediction for Non-Small Cell Lung Cancer", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": null, "summary": "Accurate survival prediction in Non-Small Cell Lung Cancer (NSCLC) requires the integration of heterogeneous clinical, radiological, and histopathological information. While Multimodal Deep Learning (MDL) offers a promises for precision prognosis and survival prediction, its clinical applicability is severely limited by small cohort sizes and the presence of missing modalities, often forcing complete-case filtering or aggressive imputation. In this work, we present a missing-aware multimodal survival framework that integrates Computed Tomography (CT), Whole-Slide Histopathology (WSI) Images, and structured clinical variables for overall survival modeling in unresectable stage II-III NSCLC. By leveraging Foundation Models (FM) for modality-specific feature extraction and a missing-aware encoding strategy, the proposed approach enables intermediate multimodal fusion under naturally incomplete modality profiles. The proposed architecture is resilient to missing modalities by design, allowing the model to utilize all available data without being forced to drop patients during training or inference. Experimental results demonstrate that intermediate fusion consistently outperforms unimodal baselines as well as early and late fusion strategies, with the strongest performance achieved by the fusion of WSI and clinical modalities (73.30 C-index). Further analyses of modality importance reveal an adaptive behavior in which less informative modalities, i.e., CT modality, are automatically down-weighted and contribute less to the final survival prediction.", "AI": {"tldr": "本文提出了一种处理非小细胞肺癌（NSCLC）生存预测中缺失模态的多模态框架，通过整合CT、全幻灯片病理图像和结构化临床变量，在不完全模态配置文件下实现中间融合。", "motivation": "由于样本量小和存在模态缺失问题限制了深度学习在非小细胞肺癌（NSCLC）生存预测中的应用，传统的处理方式如完整案例过滤或激进的插补方法效果不佳。因此，本文旨在解决这些挑战，以提高生存预测模型的临床实用性。", "method": "该框架利用基础模型对特定模态特征进行提取，并采用一种缺失感知编码策略实现中间多模态融合，使其设计上能抵抗模态丢失，充分利用所有可用数据。", "result": "实验结果表明，在不同融合方式中，中间融合方法表现出色，尤其是病理图像与临床变量的融合取得了最高的性能（73.30 C-index），且分析显示CT模态贡献较小并被自动降权。", "conclusion": "研究证实了所提出的框架在处理缺失多模态数据生存预测中的有效性和适应性，为提高非小细胞肺癌患者精准预后提供了新的解决方案。"}}
{"id": "2601.10384", "pdf": "https://arxiv.org/pdf/2601.10384", "abs": "https://arxiv.org/abs/2601.10384", "authors": ["Yibo Zhang", "Liang Lin", "Kaiwen Luo", "Shilinlu Yan", "Jin Wang", "Yaoqi Guo", "Yitian Chen", "Yalan Qin", "Zhenhong Zhou", "Kun Wang", "Li Sun"], "title": "RSA-Bench: Benchmarking Audio Large Models in Real-World Acoustic Scenarios", "categories": ["cs.SD"], "comment": null, "summary": "While Audio Large Models (ALMs) have achieved remarkable proficiency, their robustness remains brittle in real-world deployment. Existing evaluations largely rely on synthetic Gaussian noise or simplistic single-source interference, failing to capture the intricate, multi-layered acoustic dynamics -- or ``Acoustic Ecology'' -- that characterize authentic physical environments. To bridge this ecological gap, we introduce \\textbf{RSA-Bench}, a comprehensive robustness benchmark designed to stress-test ALLMs through high-fidelity auditory scene simulations. Unlike traditional methods, we construct evaluation samples by naturally superimposing diverse environmental soundscapes -- spanning \\textit{Pasture}, \\textit{Extreme Weather}, \\textit{Classroom}, and \\textit{Outdoors} -- onto clean speech signals across a spectrum of interference intensities. By evaluating models on six core tasks ranging from fundamental perception to complex reasoning, our study unveils three macro-level insights: \\textbf{(I) The Perception-Cognition Gap:} Models maintain relative resilience in low-level recognition but suffer a \\textbf{functional collapse} in high-order reasoning tasks under stress; \\textbf{(II) Scenario Sensitivity:} ``Vocal-like'' interference (e.g., background laughter) proves significantly more destructive than mechanical noise, challenging the model's auditory attention mechanisms; and \\textbf{(III) The Denoising Paradox:} Standard speech enhancement often exacerbates performance degradation, as ALLMs prove highly sensitive to the semantic distortions introduced by denoising artifacts.", "AI": {"tldr": "介绍了RSA-Bench，一个用于评估音频大型模型在真实世界复杂声学环境下的鲁棒性的基准测试。", "motivation": "现有评估方法依赖于合成高斯噪声或单一干扰源，无法捕捉现实环境中复杂的多层声学动态。为了弥补这种生态差距，引入了RSA-Bench来解决这一问题。", "method": "通过将多样化的自然环境声音叠加到干净的语音信号上，以不同强度的干扰构建评估样本，并在六个核心任务（从基础感知到复杂推理）上进行模型评估。", "result": "发现了三个宏观层面的见解：模型在低层识别中表现出相对稳健性但在高层推理任务下功能崩溃；\"类似人声\"的干扰比机械噪声更具破坏性；标准语音增强往往会加剧性能下降，因为ALLMs对去噪引入的语义扭曲非常敏感。", "conclusion": "RSA-Bench揭示了当前音频大型模型在真实世界复杂环境中的鲁棒性挑战，并指出了改进的方向。"}}
{"id": "2601.10383", "pdf": "https://arxiv.org/pdf/2601.10383", "abs": "https://arxiv.org/abs/2601.10383", "authors": ["Marcel Gohsen", "Nicola Libera", "Johannes Kiesel", "Jan Ehlers", "Benno Stein"], "title": "Does Cognitive Load Affect Human Accuracy in Detecting Voice-Based Deepfakes?", "categories": ["cs.HC"], "comment": "Accepted as full paper to CHIIR'26", "summary": "Deepfake technologies are powerful tools that can be misused for malicious purposes such as spreading disinformation on social media. The effectiveness of such malicious applications depends on the ability of deepfakes to deceive their audience. Therefore, researchers have investigated human abilities to detect deepfakes in various studies. However, most of these studies were conducted with participants who focused exclusively on the detection task; hence the studies may not provide a complete picture of human abilities to detect deepfakes under realistic conditions: Social media users are exposed to cognitive load on the platform, which can impair their detection abilities. In this paper, we investigate the influence of cognitive load on human detection abilities of voice-based deepfakes in an empirical study with 30 participants. Our results suggest that low cognitive load does not generally impair detection abilities, and that the simultaneous exposure to a secondary stimulus can actually benefit people in the detection task.", "AI": {"tldr": "研究认知负荷是否影响人类识别基于语音的深度伪造的能力。", "motivation": "大多数关于识别深度伪造的研究是在参与者专注于检测任务的情况下进行的，因此这些研究可能不能完全反映在现实条件下的识别能力。社交平台上的用户通常会受到认知负荷的影响，这可能会削弱他们的检测能力。", "method": "通过一项包含30名参与者的实证研究，探讨认知负荷对人类检测基于语音的深度伪造能力的影响。", "result": "研究表明低认知负荷一般不会损害检测能力，并且同时暴露于第二种刺激实际上可以有助于提高识别任务的表现。", "conclusion": "低认知负荷条件下，人们的识别深度伪造的能力并未受到负面影响，甚至在同时面对其他刺激的情况下，其识别能力可能还会有所提升。"}}
{"id": "2601.10379", "pdf": "https://arxiv.org/pdf/2601.10379", "abs": "https://arxiv.org/abs/2601.10379", "authors": ["He Ren", "Gaowei Yan", "Hang Liu", "Lifeng Cao", "Zhijun Zhao", "Gang Dang"], "title": "Online identification of nonlinear time-varying systems with uncertain information", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "Digital twins (DTs), serving as the core enablers for real-time monitoring and predictive maintenance of complex cyber-physical systems, impose critical requirements on their virtual models: high predictive accuracy, strong interpretability, and online adaptive capability. However, existing techniques struggle to meet these demands simultaneously: Bayesian methods excel in uncertainty quantification but lack model interpretability, while interpretable symbolic identification methods (e.g., SINDy) are constrained by their offline, batch-processing nature, which make real-time updates challenging. To bridge this semantic and computational gap, this paper proposes a novel Bayesian Regression-based Symbolic Learning (BRSL) framework. The framework formulates online symbolic discovery as a unified probabilistic state-space model. By incorporating sparse horseshoe priors, model selection is transformed into a Bayesian inference task, enabling simultaneous system identification and uncertainty quantification. Furthermore, we derive an online recursive algorithm with a forgetting factor and establish precise recursive conditions that guarantee the well-posedness of the posterior distribution. These conditions also function as real-time monitors for data utility, enhancing algorithmic robustness. Additionally, a rigorous convergence analysis is provided, demonstrating the convergence of parameter estimates under persistent excitation conditions. Case studies validate the effectiveness of the proposed framework in achieving interpretable, probabilistic prediction and online learning.", "AI": {"tldr": "提出了一种基于贝叶斯回归的符号学习（BRSL）框架，用于在线识别非线性时变系统，并处理不确定信息。", "motivation": "现有的技术难以同时满足高预测准确性、强可解释性和在线自适应能力的需求。贝叶斯方法擅长不确定性量化但缺乏模型可解释性；而可解释的符号识别方法（例如SINDy）受限于离线批处理性质，使得实时更新变得困难。", "method": "提出了一种基于贝叶斯回归的符号学习（BRSL）框架，该框架将在线符号发现作为一个统一的概率状态空间模型。通过引入稀疏马蹄形先验，模型选择转化为一个贝叶斯推理任务，实现了同时进行系统识别和不确定性量化。此外，还推导了一个带有遗忘因子的在线递归算法，并建立了精确的递归条件以保证后验分布的合理性。", "result": "提供了一种严格的收敛性分析，证明了在持续激励条件下参数估计的收敛性。案例研究表明，所提框架能够实现可解释的概率预测和在线学习。", "conclusion": "BRSL框架通过将符号发现作为贝叶斯推理任务，并结合稀疏先验和递归算法，成功实现了同时满足高预测准确性、强可解释性和在线自适应能力的目标，在非线性时变系统的实时监测中具有显著效果。"}}
{"id": "2601.10378", "pdf": "https://arxiv.org/pdf/2601.10378", "abs": "https://arxiv.org/abs/2601.10378", "authors": ["Dian Jiao", "Jiaxin Duan", "Shuai Zhao", "Jiabing Leng", "Yiran Zhang", "Feng Huang"], "title": "Global Context Compression with Interleaved Vision-Text Transformation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent achievements of vision-language models in end-to-end OCR point to a new avenue for low-loss compression of textual information. This motivates earlier works that render the Transformer's input into images for prefilling, which effectively reduces the number of tokens through visual encoding, thereby alleviating the quadratically increased Attention computations. However, this partial compression fails to save computational or memory costs at token-by-token inference. In this paper, we investigate global context compression, which saves tokens at both prefilling and inference stages. Consequently, we propose VIST2, a novel Transformer that interleaves input text chunks alongside their visual encoding, while depending exclusively on visual tokens in the pre-context to predict the next text token distribution. Around this idea, we render text chunks into sketch images and train VIST2 in multiple stages, starting from curriculum-scheduled pretraining for optical language modeling, followed by modal-interleaved instruction tuning. We conduct extensive experiments using VIST2 families scaled from 0.6B to 8B to explore the training recipe and hyperparameters. With a 4$\\times$ compression ratio, the resulting models demonstrate significant superiority over baselines on long writing tasks, achieving, on average, a 3$\\times$ speedup in first-token generation, 77% reduction in memory usage, and 74% reduction in FLOPS. Our codes and datasets will be public to support further studies.", "AI": {"tldr": "本文提出了VIST2模型，通过将文本块与视觉编码交错输入Transformer，实现全局上下文压缩，在预填充和推理阶段均节省了计算资源。", "motivation": "为了克服现有方法在逐个生成令牌时无法减少计算或内存成本的问题，并提高低损耗的OCR性能，探索有效的全局上下文压缩技术。", "method": "将文本块转换成草图图像并训练VIST2模型，通过多阶段预训练和模态交错指令微调来优化模型性能。", "result": "使用不同规模的VIST2模型进行实验，在长文字任务上表现优越，平均第一令牌生成速度提高3倍，内存使用减少77%，FLOPS降低74%。", "conclusion": "通过视觉编码和文本交错输入的方法，VIST2实现了显著的压缩比，并在多个指标上优于基线模型，展示了其在长文字任务中的优势。"}}
{"id": "2601.10373", "pdf": "https://arxiv.org/pdf/2601.10373", "abs": "https://arxiv.org/abs/2601.10373", "authors": ["Yichong Xia", "Yimin Zhou", "Jinpeng Wang", "Bin Chen"], "title": "Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": null, "summary": "Recent advancements in diffusion-based generative priors have enabled visually plausible image compression at extremely low bit rates. However, existing approaches suffer from slow sampling processes and suboptimal bit allocation due to fragmented training paradigms. In this work, we propose Accelerate \\textbf{Diff}usion-based Image Compression via \\textbf{C}onsistency Prior \\textbf{R}efinement (DiffCR), a novel compression framework for efficient and high-fidelity image reconstruction. At the heart of DiffCR is a Frequency-aware Skip Estimation (FaSE) module that refines the $ε$-prediction prior from a pre-trained latent diffusion model and aligns it with compressed latents at different timesteps via Frequency Decoupling Attention (FDA). Furthermore, a lightweight consistency estimator enables fast \\textbf{two-step decoding} by preserving the semantic trajectory of diffusion sampling. Without updating the backbone diffusion model, DiffCR achieves substantial bitrate savings (27.2\\% BD-rate (LPIPS) and 65.1\\% BD-rate (PSNR)) and over $10\\times$ speed-up compared to SOTA diffusion-based compression baselines.", "AI": {"tldr": "本文提出了一种高效的低码率图像压缩框架DiffCR，通过频率感知的跳过估计模块（FaSE）和轻量级一致性估算器实现了高速度和高质量的图像重建。", "motivation": "现有基于扩散模型的图像压缩方法存在采样过程慢及比特分配次优的问题。为了解决这些问题，作者提出了一种新的压缩框架DiffCR。", "method": "DiffCR采用频率感知跳过估计模块（FaSE）对预训练的潜扩散模型进行ε预测先验修正，并通过频率解耦注意力机制（FDA）与压缩潜变量在不同时间步长上对齐。此外，引入了一个轻量级一致性估算器以实现快速两步解码。", "result": "DiffCR实现了显著的比特率节省（BD-rate LPIPS节约27.2%，PSNR节约65.1%）和超过10倍的速度提升，与现有的基于扩散模型压缩方法相比。", "conclusion": "通过频率感知模块和轻量级一致性估算器，DiffCR在不更新骨干扩散模型的前提下达到了高效的低码率图像压缩效果。"}}
{"id": "2601.10369", "pdf": "https://arxiv.org/pdf/2601.10369", "abs": "https://arxiv.org/abs/2601.10369", "authors": ["Ningyu Sun", "Zhaolin Cai", "Zitong Xu", "Peihang Chen", "Huiyu Duan", "Yichao Yan", "Xiongkuo Min", "Xiaokang Yang"], "title": "Fine-Grained Human Pose Editing Assessment via Layer-Selective MLLMs", "categories": ["cs.CV"], "comment": null, "summary": "Text-guided human pose editing has gained significant traction in AIGC applications. However,it remains plagued by structural anomalies and generative artifacts. Existing evaluation metrics often isolate authenticity detection from quality assessment, failing to provide fine-grained insights into pose-specific inconsistencies. To address these limitations, we introduce HPE-Bench, a specialized benchmark comprising 1,700 standardized samples from 17 state-of-the-art editing models, offering both authenticity labels and multi-dimensional quality scores. Furthermore, we propose a unified framework based on layer-selective multimodal large language models (MLLMs). By employing contrastive LoRA tuning and a novel layer sensitivity analysis (LSA) mechanism, we identify the optimal feature layer for pose evaluation. Our framework achieves superior performance in both authenticity detection and multi-dimensional quality regression, effectively bridging the gap between forensic detection and quality assessment.", "AI": {"tldr": "本文提出HPE-Bench基准和基于层选择多模态大语言模型的统一框架，用于细粒度人体姿态编辑评估。", "motivation": "针对现有评估指标在检测生成的人体姿势编辑中的结构性异常和生成伪影时存在的局限性，旨在提供更详细的姿势特定不一致性见解。", "method": "提出了HPE-Bench基准包含1700个标准化样本，并采用了层选择多模态大语言模型（MLLMs）框架，通过对比LoRA调优和层次敏感度分析（LSA）机制识别最优特征层进行姿态评估。", "result": "该框架在真实性检测和多维质量回归方面表现出色，有效连接了法医检测与质量评估之间的差距。", "conclusion": "本文提出的HPE-Bench基准和基于MLLMs的统一框架显著提高了人体姿势编辑的质量评估能力。"}}
{"id": "2601.10365", "pdf": "https://arxiv.org/pdf/2601.10365", "abs": "https://arxiv.org/abs/2601.10365", "authors": ["Yan Liu", "Tao Yu", "Haolin Song", "Hongbo Zhu", "Nianzong Hu", "Yuzhi Hao", "Xiuyong Yao", "Xizhe Zang", "Hua Chen", "Jie Zhao"], "title": "FastStair: Learning to Run Up Stairs with Humanoid Robots", "categories": ["cs.RO"], "comment": null, "summary": "Running up stairs is effortless for humans but remains extremely challenging for humanoid robots due to the simultaneous requirements of high agility and strict stability. Model-free reinforcement learning (RL) can generate dynamic locomotion, yet implicit stability rewards and heavy reliance on task-specific reward shaping tend to result in unsafe behaviors, especially on stairs; conversely, model-based foothold planners encode contact feasibility and stability structure, but enforcing their hard constraints often induces conservative motion that limits speed. We present FastStair, a planner-guided, multi-stage learning framework that reconciles these complementary strengths to achieve fast and stable stair ascent. FastStair integrates a parallel model-based foothold planner into the RL training loop to bias exploration toward dynamically feasible contacts and to pretrain a safety-focused base policy. To mitigate planner-induced conservatism and the discrepancy between low- and high-speed action distributions, the base policy was fine-tuned into speed-specialized experts and then integrated via Low-Rank Adaptation (LoRA) to enable smooth operation across the full commanded-speed range. We deploy the resulting controller on the Oli humanoid robot, achieving stable stair ascent at commanded speeds up to 1.65 m/s and traversing a 33-step spiral staircase (17 cm rise per step) in 12 s, demonstrating robust high-speed performance on long staircases. Notably, the proposed approach served as the champion solution in the Canton Tower Robot Run Up Competition.", "AI": {"tldr": "开发FastStair框架，以实现人形机器人快速稳定地上楼梯。", "motivation": "虽然人类可以轻松地跑上楼梯，但对于人形机器人来说，这仍然是一项极具挑战性的任务，因为需要同时满足高敏捷性和严格稳定性。模型无关的强化学习（RL）可以生成动态运动，但其隐含稳定性奖励和对特定任务的奖励塑造依赖性会导致不安全的行为；而基于模型的步点规划器虽然编码了接触可行性和稳定性结构，但执行硬约束往往导致保守动作限制速度。", "method": "FastStair是一种引导式、多阶段学习框架。它将并行的基于模型的步点规划器集成到RL训练循环中以偏置探索至动态可行的接触，并预训练一个专注于安全的基础策略。为了减轻规划器引起的保守性和低速与高速动作分布之间的差异，基础政策被微调为速度专长专家并通过LoRA整合，从而实现全范围命令速度下的平稳操作。", "result": "将此控制器部署在Oli人形机器人上，实现了最高1.65 m/s的稳定楼梯上升速度，并用时12秒穿越了33阶螺旋楼梯（每级高度为17厘米），展示了长时间楼梯上的高速稳健性能。该方法还在珠江塔机器人跑楼梯比赛中作为冠军方案。", "conclusion": "通过结合模型无关强化学习和基于模型的规划器，FastStair框架实现了人形机器人的快速稳定楼梯攀爬，并在实际应用中取得了显著成果。"}}
{"id": "2601.10349", "pdf": "https://arxiv.org/pdf/2601.10349", "abs": "https://arxiv.org/abs/2601.10349", "authors": ["Mark Kashirskiy", "Ilya Makarov"], "title": "SuS: Strategy-aware Surprise for Intrinsic Exploration", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.GT"], "comment": "8 pages, 7 figures, 3 tables. Code available at https://github.com/mariklolik/sus", "summary": "We propose Strategy-aware Surprise (SuS), a novel intrinsic motivation framework that uses pre-post prediction mismatch as a novelty signal for exploration in reinforcement learning. Unlike traditional curiosity-driven methods that rely solely on state prediction error, SuS introduces two complementary components: Strategy Stability (SS) and Strategy Surprise (SuS). SS measures consistency in behavioral strategy across temporal steps, while SuS captures unexpected outcomes relative to the agent's current strategy representation. Our combined reward formulation leverages both signals through learned weighting coefficients. We evaluate SuS on mathematical reasoning tasks using large language models, demonstrating significant improvements in both accuracy and solution diversity. Ablation studies confirm that removing either component results in at least 10% performance degradation, validating the synergistic nature of our approach. SuS achieves 17.4% improvement in Pass@1 and 26.4% improvement in Pass@5 compared to baseline methods, while maintaining higher strategy diversity throughout training.", "AI": {"tldr": "提出一种名为Strategy-aware Surprise（SuS）的新内在动机框架，用于强化学习中的探索。", "motivation": "传统的基于好奇心的驱动方法仅依赖于状态预测误差进行探索，而该研究提出了SuS来提高在数学推理任务上的准确性和解决方案多样性。", "method": "SuS引入了两个互补组件：策略稳定性（SS）和策略惊喜（SuS），通过学习权重系数结合这两种信号。SS衡量行为策略的时间一致性，而SuS捕捉相对于当前策略表示的意外结果。", "result": "在使用大型语言模型的数学推理任务上，SuS展示了17.4%的Pass@1和26.4%的Pass@5改进，同时保持较高的训练期间策略多样性。移除任一组件都会导致至少10%性能下降。", "conclusion": "研究证实了SuS在提升解决数学推理任务上的准确性和解决方案多样性方面具有显著优势，并且两种信号（SS和SuS）对于取得优异结果是协同工作的。"}}
{"id": "2601.10348", "pdf": "https://arxiv.org/pdf/2601.10348", "abs": "https://arxiv.org/abs/2601.10348", "authors": ["Zhanming Shen", "Jiaqi Hu", "Zeyu Qin", "Hao Chen", "Wentao Ye", "Zenan Huang", "Yihong Zhuang", "Guoshan Lu", "Junlin Zhou", "Junbo Zhao"], "title": "Training-Trajectory-Aware Token Selection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Efficient distillation is a key pathway for converting expensive reasoning capability into deployable efficiency, yet in the frontier regime where the student already has strong reasoning ability, naive continual distillation often yields limited gains or even degradation. We observe a characteristic training phenomenon: even as loss decreases monotonically, all performance metrics can drop sharply at almost the same bottleneck, before gradually recovering. We further uncover a token-level mechanism: confidence bifurcates into steadily increasing Imitation-Anchor Tokens that quickly anchor optimization and other yet-to-learn tokens whose confidence is suppressed until after the bottleneck. And the characteristic that these two types of tokens cannot coexist is the root cause of the failure in continual distillation. To this end, we propose Training-Trajectory-Aware Token Selection (T3S) to reconstruct the training objective at the token level, clearing the optimization path for yet-to-learn tokens. T3 yields consistent gains in both AR and dLLM settings: with only hundreds of examples, Qwen3-8B surpasses DeepSeek-R1 on competitive reasoning benchmarks, Qwen3-32B approaches Qwen3-235B, and T3-trained LLaDA-2.0-Mini exceeds its AR baseline, achieving state-of-the-art performance among all of 16B-scale no-think models.", "AI": {"tldr": "本文提出了一种称为T3S的方法，通过在标记级别重构训练目标来解决持续蒸馏中的瓶颈问题。", "motivation": "尽管高效的知识蒸馏是将昂贵推理能力转化为可部署效率的关键途径，但在学生模型已经具有强大推理能力的前沿领域中，朴素的持续蒸馏往往只能带来有限甚至负面的效果。作者观察到在训练过程中性能指标会出现明显的下降现象，并发现了这种现象背后的标记层面机制。", "method": "T3S方法通过识别和处理两类不同的标记（模仿锚定标记和其他尚未学习的标记）来清除优化路径，从而改善持续蒸馏过程中的表现。", "result": "实验结果表明，在仅有数百个示例的情况下，应用T3S后的Qwen3-8B模型在竞争性推理基准测试中超越了DeepSeek-R1，而更大规模的模型如Qwen3-32B也接近了Qwen3-235B的表现；同样地，经过T3训练的LLaDA-2.0-Mini超过了其基线AR性能，并且在所有16B规模无思考模型中达到了最先进的水平。", "conclusion": "本文提出的方法T3S解决了持续蒸馏中存在的瓶颈问题，在多个实验设置下均显示出了显著的优势，证明了该方法的有效性。"}}
{"id": "2601.10345", "pdf": "https://arxiv.org/pdf/2601.10345", "abs": "https://arxiv.org/abs/2601.10345", "authors": ["Yunyi Liu", "Taketo Akama"], "title": "Self-supervised restoration of singing voice degraded by pitch shifting using shallow diffusion", "categories": ["cs.SD"], "comment": null, "summary": "Pitch shifting has been an essential feature in singing voice production. However, conventional signal processing approaches exhibit well known trade offs such as formant shifts and robotic coloration that becomes more severe at larger transposition jumps. This paper targets high quality pitch shifting for singing by reframing it as a restoration problem: given an audio track that has been pitch shifted (and thus contaminated by artifacts), we recover a natural sounding performance while preserving its melody and timing. Specifically, we use a lightweight, mel space diffusion model driven by frame level acoustic features such as f0, volume, and content features. We construct training pairs in a self supervised manner by applying pitch shifts and reversing them to simulate realistic artifacts while retaining ground truth. On a curated singing set, the proposed approach substantially reduces pitch shift artifacts compared to representative classical baselines, as measured by both statistical metrics and pairwise acoustic measures. The results suggest that restoration based pitch shifting could be a viable approach towards artifact resistant transposition in vocal production workflows.", "AI": {"tldr": "本文提出了一种基于浅层扩散模型的自我监督方法，用于恢复被音调调整破坏的人声。", "motivation": "传统信号处理中的音调调整存在形式转变和机械感增强的问题，特别是在较大的转调跳跃中。该文旨在通过将音调调整重新定义为一个修复问题来改善这一状况。", "method": "使用轻量级的、基于Mel频谱图空间的扩散模型，并以帧级别的声学特征如f0、音量和内容特征进行驱动，训练数据采用自监督生成。", "result": "实验结果显示，该方法在减少音调调整带来的失真方面显著优于经典基准，在统计指标和成对声学度量上都有所体现。", "conclusion": "基于修复的音调调整方法可能成为对抗转调过程中声音失真的可行策略，并可应用于人声制作流程中。"}}
{"id": "2601.10343", "pdf": "https://arxiv.org/pdf/2601.10343", "abs": "https://arxiv.org/abs/2601.10343", "authors": ["Deming Ding", "Shichun Liu", "Enhui Yang", "Jiahang Lin", "Ziying Chen", "Shihan Dou", "Honglin Guo", "Weiyu Cheng", "Pengyu Zhao", "Chengjun Xiao", "Qunhong Zeng", "Qi Zhang", "Xuanjing Huang", "Qidi Xu", "Tao Gui"], "title": "OctoBench: Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Modern coding scaffolds turn LLMs into capable software agents, but their ability to follow scaffold-specified instructions remains under-examined, especially when constraints are heterogeneous and persist across interactions. To fill this gap, we introduce OctoBench, which benchmarks scaffold-aware instruction following in repository-grounded agentic coding. OctoBench includes 34 environments and 217 tasks instantiated under three scaffold types, and is paired with 7,098 objective checklist items. To disentangle solving the task from following the rules, we provide an automated observation-and-scoring toolkit that captures full trajectories and performs fine-grained checks. Experiments on eight representative models reveal a systematic gap between task-solving and scaffold-aware compliance, underscoring the need for training and evaluation that explicitly targets heterogeneous instruction following. We release the benchmark to support reproducible benchmarking and to accelerate the development of more scaffold-aware coding agents.", "AI": {"tldr": "本文介绍了OctoBench，一个用于评估代码生成代理在遵守不同指令框架下执行任务能力的基准测试平台。", "motivation": "现代编码框架使LLMs成为有能力的软件代理，但它们遵循框架指定指示的能力仍然缺乏研究，特别是在约束条件异质且持续存在的情况下。", "method": "OctoBench包含34个环境和217个任务，在三种类型的框架下实现，并配有7,098项客观清单项目。提供了一个自动化观察和评分工具包，用于捕获完整的轨迹并执行细粒度检查。", "result": "实验揭示了在八种代表性模型中存在系统性的差距，即任务解决能力和遵守异质指令之间的差距，这强调了需要针对异质性指示遵循进行专门的训练和评估。", "conclusion": "发布OctoBench是为了支持可重复的基准测试，并加速开发更加框架感知的编码代理。"}}
{"id": "2601.10342", "pdf": "https://arxiv.org/pdf/2601.10342", "abs": "https://arxiv.org/abs/2601.10342", "authors": ["Cheng Lin Cheng", "Ting Chuan Lin", "Chai Kai Chang"], "title": "C-GRASP: Clinically-Grounded Reasoning for Affective Signal Processing", "categories": ["cs.AI"], "comment": null, "summary": "Heart rate variability (HRV) is a pivotal noninvasive marker for autonomic monitoring; however, applying Large Language Models (LLMs) to HRV interpretation is hindered by physiological hallucinations. These include respiratory sinus arrhythmia (RSA) contamination, short-data instability in nonlinear metrics, and the neglect of individualized baselines in favor of population norms. We propose C-GRASP (Clinically-Grounded Reasoning for Affective Signal Processing), a guardrailed RAG-enhanced pipeline that decomposes HRV interpretation into eight traceable reasoning steps. Central to C-GRASP is a Z-score Priority Hierarchy that enforces the weighting of individualized baseline shifts over normative statistics. The system effectively mitigates spectral hallucinations through automated RSA-aware guardrails, preventing contamination of frequency-domain indices. Evaluated on 414 trials from the DREAMER dataset, C-GRASP integrated with high-scale reasoning models (e.g., MedGemma3-thinking) achieved superior performance in 4-class emotion classification (37.3% accuracy) and a Clinical Reasoning Consistency (CRC) score of 69.6%. Ablation studies confirm that the individualized Delta Z-score module serves as the critical logical anchor, preventing the \"population bias\" common in native LLMs. Ultimately, C-GRASP transitions affective computing from black-box classification to transparent, evidence-based clinical decision support, paving the way for safer AI integration in biomedical engineering.", "AI": {"tldr": "本文介绍了C-GRASP系统，该系统通过分解心率变异性解释并采用个性化基线权重来改进情感信号处理。", "motivation": "大型语言模型在解读心率变异时面临生理幻觉问题，包括呼吸窦性心动过缓的污染、非线性指标的数据不稳定性以及忽视个体化基线等。这些问题阻碍了HRV的有效应用。", "method": "C-GRASP系统采用了一种受RAG增强的管道方法，分解了心率变异性解释过程为八个可追踪的推理步骤，并引入了一个Z-score优先层级机制，以确保个体化基线变化的重要性超过规范统计。", "result": "在DREAMER数据集上进行了评估，C-GRASP结合高规模推理模型实现了4类情绪分类37.3%的准确率和69.6%的临床推理一致性得分。消融研究验证了个性化Delta Z-score模块是防止群体偏差的关键逻辑锚点。", "conclusion": "通过将情感计算从黑盒分类转变为透明且基于证据的临床决策支持，C-GRASP为生物医学工程中更安全地整合AI提供了可能。"}}
{"id": "2601.10340", "pdf": "https://arxiv.org/pdf/2601.10340", "abs": "https://arxiv.org/abs/2601.10340", "authors": ["David Morilla-Cabello", "Eduardo Montijano"], "title": "CHORAL: Traversal-Aware Planning for Safe and Efficient Heterogeneous Multi-Robot Routing", "categories": ["cs.RO"], "comment": null, "summary": "Monitoring large, unknown, and complex environments with autonomous robots poses significant navigation challenges, where deploying teams of heterogeneous robots with complementary capabilities can substantially improve both mission performance and feasibility. However, effectively modeling how different robotic platforms interact with the environment requires rich, semantic scene understanding. Despite this, existing approaches often assume homogeneous robot teams or focus on discrete task compatibility rather than continuous routing. Consequently, scene understanding is not fully integrated into routing decisions, limiting their ability to adapt to the environment and to leverage each robot's strengths. In this paper, we propose an integrated semantic-aware framework for coordinating heterogeneous robots. Starting from a reconnaissance flight, we build a metric-semantic map using open-vocabulary vision models and use it to identify regions requiring closer inspection and capability-aware paths for each platform to reach them. These are then incorporated into a heterogeneous vehicle routing formulation that jointly assigns inspection tasks and computes robot trajectories. Experiments in simulation and in a real inspection mission with three robotic platforms demonstrate the effectiveness of our approach in planning safer and more efficient routes by explicitly accounting for each platform's navigation capabilities. We release our framework, CHORAL, as open source to support reproducibility and deployment of diverse robot teams.", "AI": {"tldr": "本文提出了一个综合语义感知框架CHORAL，用于协调异构机器人团队的导航和任务分配。", "motivation": "现有方法通常假设同质机器人团队或仅关注离散任务兼容性而非连续路径规划，在复杂环境中未能充分利用每种机器人的能力。为了改进自主机器人在未知复杂环境中的监测性能，本文提出了一种新的框架。", "method": "该框架首先通过侦察飞行构建度量-语义地图，并利用开放词汇视觉模型识别需要进一步检查的区域和适合各平台的能力感知路径。这些信息被整合到异构车辆路由问题中，进行任务分配和计算机器人轨迹。", "result": "实验结果显示，在模拟环境和使用三个机器人平台的实际检测任务中，该方法能够规划出更安全、高效的路线。", "conclusion": "CHORAL通过显式考虑每个平台的导航能力，有效提升了异构机器人团队的安全性和效率，并以开源形式发布支持复现和部署多样化机器人队伍。"}}
{"id": "2601.10338", "pdf": "https://arxiv.org/pdf/2601.10338", "abs": "https://arxiv.org/abs/2601.10338", "authors": ["Yi Liu", "Weizhe Wang", "Ruitao Feng", "Yao Zhang", "Guangquan Xu", "Gelei Deng", "Yuekang Li", "Leo Zhang"], "title": "Agent Skills in the Wild: An Empirical Study of Security Vulnerabilities at Scale", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.SE"], "comment": null, "summary": "The rise of AI agent frameworks has introduced agent skills, modular packages containing instructions and executable code that dynamically extend agent capabilities. While this architecture enables powerful customization, skills execute with implicit trust and minimal vetting, creating a significant yet uncharacterized attack surface. We conduct the first large-scale empirical security analysis of this emerging ecosystem, collecting 42,447 skills from two major marketplaces and systematically analyzing 31,132 using SkillScan, a multi-stage detection framework integrating static analysis with LLM-based semantic classification. Our findings reveal pervasive security risks: 26.1% of skills contain at least one vulnerability, spanning 14 distinct patterns across four categories: prompt injection, data exfiltration, privilege escalation, and supply chain risks. Data exfiltration (13.3%) and privilege escalation (11.8%) are most prevalent, while 5.2% of skills exhibit high-severity patterns strongly suggesting malicious intent. We find that skills bundling executable scripts are 2.12x more likely to contain vulnerabilities than instruction-only skills (OR=2.12, p<0.001). Our contributions include: (1) a grounded vulnerability taxonomy derived from 8,126 vulnerable skills, (2) a validated detection methodology achieving 86.7% precision and 82.5% recall, and (3) an open dataset and detection toolkit to support future research. These results demonstrate an urgent need for capability-based permission systems and mandatory security vetting before this attack vector is further exploited.", "AI": {"tldr": "本文通过对两个大型市场中的42,447个Agent技能进行大规模实证安全分析，揭示了这些模块化包中存在的广泛安全隐患。", "motivation": "随着AI代理框架的兴起，模组化的技能扩展了代理的能力，但因为缺乏审查和信任问题，这种架构可能带来重大且未被明确的风险。", "method": "通过SkillScan多阶段检测框架，结合静态分析与LLM基础语义分类，系统性地分析了31,132个技能。", "result": "发现26.1%的技能存在至少一种漏洞，主要集中在数据泄露、权限提升等方面。捆绑可执行脚本的技能比仅有指令的技能更易产生漏洞（OR=2.12，p<0.001）。", "conclusion": "这些结果表明需要基于能力的权限系统和强制性安全审查来应对潜在的安全威胁。"}}
{"id": "2601.10334", "pdf": "https://arxiv.org/pdf/2601.10334", "abs": "https://arxiv.org/abs/2601.10334", "authors": ["Minh Hai Nguyen", "Quoc Bao Do", "Edouard Pauwels", "Pierre Weiss"], "title": "An analytic theory of convolutional neural network inverse problems solvers", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Supervised convolutional neural networks (CNNs) are widely used to solve imaging inverse problems, achieving state-of-the-art performance in numerous applications. However, despite their empirical success, these methods are poorly understood from a theoretical perspective and often treated as black boxes. To bridge this gap, we analyze trained neural networks through the lens of the Minimum Mean Square Error (MMSE) estimator, incorporating functional constraints that capture two fundamental inductive biases of CNNs: translation equivariance and locality via finite receptive fields. Under the empirical training distribution, we derive an analytic, interpretable, and tractable formula for this constrained variant, termed Local-Equivariant MMSE (LE-MMSE). Through extensive numerical experiments across various inverse problems (denoising, inpainting, deconvolution), datasets (FFHQ, CIFAR-10, FashionMNIST), and architectures (U-Net, ResNet, PatchMLP), we demonstrate that our theory matches the neural networks outputs (PSNR $\\gtrsim25$dB). Furthermore, we provide insights into the differences between \\emph{physics-aware} and \\emph{physics-agnostic} estimators, the impact of high-density regions in the training (patch) distribution, and the influence of other factors (dataset size, patch size, etc).", "AI": {"tldr": "本文提出了一个解析理论，用于解释训练好的卷积神经网络在解决成像逆问题时的行为，并通过实验验证了该理论的有效性。", "motivation": "由于缺乏对监督卷积神经网络在解决成像逆问题中的理论理解，本文旨在通过分析和建立理论模型来填补这一空白，从而更好地理解和解释这些方法。", "method": "基于最小均方误差（MMSE）估计器并结合平移等变性和局部性的功能约束，提出了一个解析公式，称为Local-Equivariant MMSE (LE-MMSE)。", "result": "通过在不同的逆问题、数据集和架构上进行实验，验证了理论与神经网络输出结果的高度匹配（PSNR ≳25dB）。还探讨了物理感知估计器与非物理感知估计器之间的差异以及训练分布密集区域的影响等因素。", "conclusion": "该研究为理解卷积神经网络在解决成像逆问题中的行为提供了理论基础，并通过广泛的实验验证了所提理论的准确性，揭示了一些影响因素对性能的作用。"}}
{"id": "2601.10332", "pdf": "https://arxiv.org/pdf/2601.10332", "abs": "https://arxiv.org/abs/2601.10332", "authors": ["Siqi Kou", "Jiachun Jin", "Zetong Zhou", "Ye Ma", "Yugang Wang", "Quan Chen", "Peng Jiang", "Xiao Yang", "Jun Zhu", "Kai Yu", "Zhijie Deng"], "title": "Think-Then-Generate: Reasoning-Aware Text-to-Image Diffusion with LLM Encoders", "categories": ["cs.CV"], "comment": null, "summary": "Recent progress in text-to-image (T2I) diffusion models (DMs) has enabled high-quality visual synthesis from diverse textual prompts. Yet, most existing T2I DMs, even those equipped with large language model (LLM)-based text encoders, remain text-pixel mappers -- they employ LLMs merely as text encoders, without leveraging their inherent reasoning capabilities to infer what should be visually depicted given the textual prompt. To move beyond such literal generation, we propose the think-then-generate (T2G) paradigm, where the LLM-based text encoder is encouraged to reason about and rewrite raw user prompts; the states of the rewritten prompts then serve as diffusion conditioning. To achieve this, we first activate the think-then-rewrite pattern of the LLM encoder with a lightweight supervised fine-tuning process. Subsequently, the LLM encoder and diffusion backbone are co-optimized to ensure faithful reasoning about the context and accurate rendering of the semantics via Dual-GRPO. In particular, the text encoder is reinforced using image-grounded rewards to infer and recall world knowledge, while the diffusion backbone is pushed to produce semantically consistent and visually coherent images. Experiments show substantial improvements in factual consistency, semantic alignment, and visual realism across reasoning-based image generation and editing benchmarks, achieving 0.79 on WISE score, nearly on par with GPT-4. Our results constitute a promising step toward next-generation unified models with reasoning, expression, and demonstration capacities.", "AI": {"tldr": "本文提出了一个名为think-then-generate（T2G）的范式，通过结合大语言模型和文本到图像扩散模型，以推理为基础生成更符合上下文的高质量图像。", "motivation": "现有的大多数文本到图像扩散模型仅将大语言模型用作文本编码器，未充分利用其推理能力来推断给定文本提示应描绘的内容。为了超越简单的文字-像素映射，提出了一种新的方法以改善生成质量。", "method": "该方法包括激活LLM的思考-重写模式进行轻量级监督微调，并通过Dual-GRPO优化LLM编码器和扩散模型骨干网，确保语义准确性和视觉连贯性。", "result": "实验结果表明，在基于推理的图像生成和编辑基准测试中，该方法在事实一致性、语义对齐和视觉真实性方面有显著提升，WISE评分为0.79，接近GPT-4的表现。", "conclusion": "研究证明了将大语言模型与文本到图像扩散模型结合的有效性，并为下一代具备推理、表达和演示能力的统一模型的发展奠定了基础。"}}
{"id": "2601.10324", "pdf": "https://arxiv.org/pdf/2601.10324", "abs": "https://arxiv.org/abs/2601.10324", "authors": ["Yiming Zhang", "Weibo Qin", "Yuntian Liu", "Feng Wang"], "title": "SRAW-Attack: Space-Reweighted Adversarial Warping Attack for SAR Target Recognition", "categories": ["cs.CV", "eess.IV"], "comment": "5 pages, 4 figures", "summary": "Synthetic aperture radar (SAR) imagery exhibits intrinsic information sparsity due to its unique electromagnetic scattering mechanism. Despite the widespread adoption of deep neural network (DNN)-based SAR automatic target recognition (SAR-ATR) systems, they remain vulnerable to adversarial examples and tend to over-rely on background regions, leading to degraded adversarial robustness. Existing adversarial attacks for SAR-ATR often require visually perceptible distortions to achieve effective performance, thereby necessitating an attack method that balances effectiveness and stealthiness. In this paper, a novel attack method termed Space-Reweighted Adversarial Warping (SRAW) is proposed, which generates adversarial examples through optimized spatial deformation with reweighted budgets across foreground and background regions. Extensive experiments demonstrate that SRAW significantly degrades the performance of state-of-the-art SAR-ATR models and consistently outperforms existing methods in terms of imperceptibility and adversarial transferability. Code is made available at https://github.com/boremycin/SAR-ATR-TransAttack.", "AI": {"tldr": "本文提出了一种新的对抗攻击方法SRAW，通过优化空间变形并重新加权前景和背景区域的预算来生成对抗样本。", "motivation": "深神经网络在合成孔径雷达（SAR）自动目标识别中的应用存在脆弱性，易受对抗样本影响，并且依赖于背景区域导致对抗鲁棒性下降。现有的攻击方法通常需要明显的视觉畸变才能有效，因此需要一种既能保证效果又能保持隐蔽性的新方法。", "method": "提出的方法称为空间重加权对抗变形（SRAW），通过优化空间变形并重新分配前景和背景的预算来生成对抗样本。", "result": "实验表明，SRAW显著降低了最先进的SAR-ATR模型的性能，并在不可察觉性和对抗迁移性方面优于现有方法。", "conclusion": "本文展示了一种新的攻击策略SRAW，在保持隐身的同时提高了对深神经网络识别系统的影响。"}}
{"id": "2601.10323", "pdf": "https://arxiv.org/pdf/2601.10323", "abs": "https://arxiv.org/abs/2601.10323", "authors": ["Xueyun Tian", "Wei Li", "Bingbing Xu", "Heng Dong", "Yuanzhuo Wang", "Huawei Shen"], "title": "ROMA: Real-time Omni-Multimodal Assistant with Interactive Streaming Understanding", "categories": ["cs.CV", "cs.CL"], "comment": "Our project page is available at https://eureka-maggie.github.io/ROMA_show", "summary": "Recent Omni-multimodal Large Language Models show promise in unified audio, vision, and text modeling. However, streaming audio-video understanding remains challenging, as existing approaches suffer from disjointed capabilities: they typically exhibit incomplete modality support or lack autonomous proactive monitoring. To address this, we present ROMA, a real-time omni-multimodal assistant for unified reactive and proactive interaction. ROMA processes continuous inputs as synchronized multimodal units, aligning dense audio with discrete video frames to handle granularity mismatches. For online decision-making, we introduce a lightweight speak head that decouples response initiation from generation to ensure precise triggering without task conflict. We train ROMA with a curated streaming dataset and a two-stage curriculum that progressively optimizes for streaming format adaptation and proactive responsiveness. To standardize the fragmented evaluation landscape, we reorganize diverse benchmarks into a unified suite covering both proactive (alert, narration) and reactive (QA) settings. Extensive experiments across 12 benchmarks demonstrate ROMA achieves state-of-the-art performance on proactive tasks while competitive in reactive settings, validating its robustness in unified real-time omni-multimodal understanding.", "AI": {"tldr": "介绍ROMA，一个实时全模态助理，能够统一处理反应式和主动式交互。", "motivation": "现有的方法在处理流媒体音频视频理解时存在能力分离问题，如不完整的模态支持或缺乏自主主动性。为了应对这些挑战，提出了ROMA以实现连续输入的同步多模态处理，并优化了实时决策机制。", "method": "ROMA通过将密集型音频与离散视频帧对齐来解决粒度差异问题，引入轻量级语音头分离响应触发和生成过程，确保精确触发且无任务冲突。此外，采用两阶段课程训练方法，逐步优化流媒体格式适应性和主动性。", "result": "在12个基准测试中的广泛实验表明，ROMA在主动任务上达到了最先进的性能，并在反应式设置中具有竞争力，验证了其在统一实时全模态理解方面的鲁棒性。", "conclusion": "ROMA通过解决现有方法的问题，实现了实时、同步的多模态理解和处理，证明了其在融合音频、视频和文本交互中的有效性。"}}
{"id": "2601.10313", "pdf": "https://arxiv.org/pdf/2601.10313", "abs": "https://arxiv.org/abs/2601.10313", "authors": ["Peng-Fei Zhang", "Zi Huang"], "title": "Hierarchical Refinement of Universal Multimodal Attacks on Vision-Language Models", "categories": ["cs.CV", "cs.MM"], "comment": "15 pages, 7 figures", "summary": "Existing adversarial attacks for VLP models are mostly sample-specific, resulting in substantial computational overhead when scaled to large datasets or new scenarios. To overcome this limitation, we propose Hierarchical Refinement Attack (HRA), a multimodal universal attack framework for VLP models. HRA refines universal adversarial perturbations (UAPs) at both the sample level and the optimization level. For the image modality, we disentangle adversarial examples into clean images and perturbations, allowing each component to be handled independently for more effective disruption of cross-modal alignment. We further introduce a ScMix augmentation strategy that diversifies visual contexts and strengthens both global and local utility of UAPs, thereby reducing reliance on spurious features. In addition, we refine the optimization path by leveraging a temporal hierarchy of historical and estimated future gradients to avoid local minima and stabilize universal perturbation learning. For the text modality, HRA identifies globally influential words by combining intra-sentence and inter-sentence importance measures, and subsequently utilizes these words as universal text perturbations. Extensive experiments across various downstream tasks, VLP models, and datasets demonstrate the superiority of the proposed universal multimodal attacks.", "AI": {"tldr": "本文提出了一种名为分层细化攻击（HRA）的多模态通用对抗性框架，用于对视觉语言处理（VLP）模型进行改进。", "motivation": "现有针对VLP模型的对抗样本大多是特定样本相关的，当扩展到大型数据集或新场景时计算开销巨大。因此提出一种新的方法来克服这一限制。", "method": "HRA框架在样例级别和优化级别上细化通用对抗扰动（UAP）。图像模态中通过分离干净图像与干扰来独立处理每个部分，增强跨模态对齐的破坏，并引入ScMix策略来增加视觉上下文多样性。对于文本模态，通过结合句内和句间重要性度量确定具有全局影响力的单词作为通用扰动。", "result": "实验显示HRA在多种下游任务、VLP模型和数据集上展示了其优越性。", "conclusion": "HRA框架为对抗样本生成提供了一种更高效的方法，能够减少对虚假特征的依赖，并提升跨模态攻击的效果。"}}
{"id": "2601.10306", "pdf": "https://arxiv.org/pdf/2601.10306", "abs": "https://arxiv.org/abs/2601.10306", "authors": ["Xin Guan", "Zijian Li", "Shen Huang", "Pengjun Xie", "Jingren Zhou", "Jiuxin Cao"], "title": "Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While Reinforcement Learning (RL) has advanced LLM reasoning, applying it to long-context scenarios is hindered by sparsity of outcome rewards. This limitation fails to penalize ungrounded \"lucky guesses,\" leaving the critical process of needle-in-a-haystack evidence retrieval largely unsupervised. To address this, we propose EAPO (Evidence-Augmented Policy Optimization). We first establish the Evidence-Augmented Reasoning paradigm, validating via Tree-Structured Evidence Sampling that precise evidence extraction is the decisive bottleneck for long-context reasoning. Guided by this insight, EAPO introduces a specialized RL algorithm where a reward model computes a Group-Relative Evidence Reward, providing dense process supervision to explicitly improve evidence quality. To sustain accurate supervision throughout training, we further incorporate an Adaptive Reward-Policy Co-Evolution mechanism. This mechanism iteratively refines the reward model using outcome-consistent rollouts, sharpening its discriminative capability to ensure precise process guidance. Comprehensive evaluations across eight benchmarks demonstrate that EAPO significantly enhances long-context reasoning performance compared to SOTA baselines.", "AI": {"tldr": "提出了EAPO方法，通过增强证据检索来改进长上下文推理的强化学习策略。", "motivation": "现有的强化学习方法在处理长上下文推理时受到稀疏奖励的影响，导致无法有效惩罚不基于证据的猜测。因此，提出一种新的方法来解决这个问题。", "method": "EAPO通过引入一个特殊的RL算法和适应性的奖励-策略协同进化机制来进行精确的证据检索监督，以改进长期上下文中的推理过程。", "result": "在八个基准测试中，与现有基线相比，EAPO显著提高了长上下文推理的表现。", "conclusion": "实验结果表明，通过增强证据检索来优化政策的方法可以有效地解决长上下文推理中的挑战。"}}
{"id": "2601.10305", "pdf": "https://arxiv.org/pdf/2601.10305", "abs": "https://arxiv.org/abs/2601.10305", "authors": ["Hengyu Shen", "Tiancheng Gu", "Bin Qin", "Lan Wu", "Yuling Wu", "Shuo Tan", "Zelong Sun", "Jun Wang", "Nan Wu", "Xiang An", "Weidong Cai", "Ziyong Feng", "Kaicheng Yang"], "title": "DanQing: An Up-to-Date Large-Scale Chinese Vision-Language Pre-training Dataset", "categories": ["cs.CV", "cs.AI"], "comment": "19 pages, 11 figures, 7 tables", "summary": "Vision-Language Pre-training (VLP) models demonstrate strong performance across various downstream tasks by learning from large-scale image-text pairs through contrastive pretraining. The release of extensive English image-text datasets (e.g., COYO-700M and LAION-400M) has enabled widespread adoption of models such as CLIP and SigLIP in tasks including cross-modal retrieval and image captioning. However, the advancement of Chinese vision-language pretraining has substantially lagged behind, due to the scarcity of high-quality Chinese image-text data. To address this gap, we develop a comprehensive pipeline for constructing a high-quality Chinese cross-modal dataset. As a result, we propose DanQing, which contains 100 million image-text pairs collected from Common Crawl. Different from existing datasets, DanQing is curated through a more rigorous selection process, yielding superior data quality. Moreover, DanQing is primarily built from 2024-2025 web data, enabling models to better capture evolving semantic trends and thus offering greater practical utility. We compare DanQing with existing datasets by continual pre-training of the SigLIP2 model. Experimental results show that DanQing consistently achieves superior performance across a range of Chinese downstream tasks, including zero-shot classification, cross-modal retrieval, and LMM-based evaluations. To facilitate further research in Chinese vision-language pre-training, we will open-source the DanQing dataset under the Creative Common CC-BY 4.0 license.", "AI": {"tldr": "本文介绍了DanQing，一个大规模的中文视觉语言预训练数据集。", "motivation": "由于高质量的中英文本图像对数据稀缺，中文视觉语言预训练的发展滞后。为此，作者开发了一条全面的数据构建管道以解决这一问题。", "method": "通过从Common Crawl收集1亿个图像-文本配对，并采用更为严谨的选择流程来确保数据质量，构建了DanQing数据集。", "result": "实验表明，在包括零样本分类、跨模态检索和基于LMM的评估等一系列中文下游任务中，使用DanQing进行连续预训练的SigLIP2模型表现优于其他现有数据集。", "conclusion": "DanQing数据集能够更好地捕捉语义趋势，为中文视觉语言预训练研究提供支持，并将开源该数据集以促进进一步的研究。"}}
{"id": "2601.10282", "pdf": "https://arxiv.org/pdf/2601.10282", "abs": "https://arxiv.org/abs/2601.10282", "authors": ["Jose Marie Antonio Minoza"], "title": "SPIKE: Sparse Koopman Regularization for Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": "ef:Conference on Parsimony and Learning (CPAL) 2026", "summary": "Physics-Informed Neural Networks (PINNs) provide a mesh-free approach for solving differential equations by embedding physical constraints into neural network training. However, PINNs tend to overfit within the training domain, leading to poor generalization when extrapolating beyond trained spatiotemporal regions. This work presents SPIKE (Sparse Physics-Informed Koopman-Enhanced), a framework that regularizes PINNs with continuous-time Koopman operators to learn parsimonious dynamics representations. By enforcing linear dynamics $dz/dt = Az$ in a learned observable space, both PIKE (without explicit sparsity) and SPIKE (with L1 regularization on $A$) learn sparse generator matrices, embodying the parsimony principle that complex dynamics admit low-dimensional structure. Experiments across parabolic, hyperbolic, dispersive, and stiff PDEs, including fluid dynamics (Navier-Stokes) and chaotic ODEs (Lorenz), demonstrate consistent improvements in temporal extrapolation, spatial generalization, and long-term prediction accuracy. The continuous-time formulation with matrix exponential integration provides unconditional stability for stiff systems while avoiding diagonal dominance issues inherent in discrete-time Koopman operators.", "AI": {"tldr": "本文提出了SPIKE框架，通过在物理约束神经网络（PINNs）中引入连续时间Koopman算子进行正则化，学习简约的动力学表示。", "motivation": "尽管物理约束神经网络（PINNs）可以无网格地求解微分方程并嵌入物理限制，但在训练域内它们容易过拟合，导致外推时的泛化能力较差。因此，本文提出了一种新的框架来改善这一问题。", "method": "SPIKE通过连续时间Koopman算子对PINNs进行正则化，在学习到的可观测空间中强制线性动力学dz/dt = Az。PIKE和SPIKE都学习稀疏生成矩阵，其中SPIKE使用L1正则化来促进稀疏。", "result": "实验涵盖了抛物型、双曲型、色散型以及刚性的偏微分方程（如流体动力学中的Navier-Stokes方程）和混沌常微分方程（如Lorenz系统），结果显示在时间外推、空间泛化及长期预测精度上均有显著提升。", "conclusion": "使用连续时间Koopman算子的SPIKE框架可以提供无条件稳定性，尤其适用于刚性系统的矩阵指数积分方法，并且避免了离散时间Koopman操作符固有的对角线优势问题。"}}
{"id": "2601.10274", "pdf": "https://arxiv.org/pdf/2601.10274", "abs": "https://arxiv.org/abs/2601.10274", "authors": ["Emre Ozbas", "Melih Bastopcu"], "title": "Queueing-Aware Optimization of Reasoning Tokens for Accuracy-Latency Trade-offs in LLM Servers", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.NI", "math.OC"], "comment": null, "summary": "We consider a single large language model (LLM) server that serves a heterogeneous stream of queries belonging to $N$ distinct task types. Queries arrive according to a Poisson process, and each type occurs with a known prior probability. For each task type, the server allocates a fixed number of internal thinking tokens, which determines the computational effort devoted to that query. The token allocation induces an accuracy-latency trade-off: the service time follows an approximately affine function of the allocated tokens, while the probability of a correct response exhibits diminishing returns. Under a first-in, first-out (FIFO) service discipline, the system operates as an $M/G/1$ queue, and the mean system time depends on the first and second moments of the resulting service-time distribution. We formulate a constrained optimization problem that maximizes a weighted average accuracy objective penalized by the mean system time, subject to architectural token-budget constraints and queue-stability conditions. The objective function is shown to be strictly concave over the stability region, which ensures existence and uniqueness of the optimal token allocation. The first-order optimality conditions yield a coupled projected fixed-point characterization of the optimum, together with an iterative solution and an explicit sufficient condition for contraction. Moreover, a projected gradient method with a computable global step-size bound is developed to guarantee convergence beyond the contractive regime. Finally, integer-valued token allocations are attained via rounding of the continuous solution, and the resulting performance loss is evaluated in simulation results.", "AI": {"tldr": "本文研究了单一大型语言模型服务器在处理异构查询流时，通过优化分配的推理令牌数量来平衡准确性和延迟的问题。", "motivation": "为了提高LLM服务器的性能，在面对不同类型的任务请求时，需要找到一种方法来优化每种任务类型的计算资源（即推理令牌）的分配，以达到最优的准确性与延迟之间的权衡。", "method": "通过构建一个带约束条件的优化问题，该问题旨在最大化加权平均准确率的同时最小化系统时间。使用严格的凸性确保解的存在唯一，并发展了投影梯度方法来寻找最优的令牌分配策略。", "result": "研究展示了如何利用一阶最优性条件推导出耦合投射不动点特征和迭代求解的方法，同时开发了一种带有全局步长边界限制的投影梯度法以保证算法在非收缩条件下也能够收敛。通过模拟实验评估了连续解决方案四舍五入到整数值后的性能损失。", "conclusion": "论文提出的方法为解决大型语言模型服务器中的准确性与延迟之间的权衡问题提供了一个有效的框架，通过优化令牌分配策略可以在不同的任务类型之间实现更优的资源利用和响应时间。"}}
{"id": "2601.10272", "pdf": "https://arxiv.org/pdf/2601.10272", "abs": "https://arxiv.org/abs/2601.10272", "authors": ["Yuxuan Lou", "Kai Yang", "Yang You"], "title": "MoST: Mixing Speech and Text with Modality-Aware Mixture of Experts", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD"], "comment": null, "summary": "We present MoST (Mixture of Speech and Text), a novel multimodal large language model that seamlessly integrates speech and text processing through our proposed Modality-Aware Mixture of Experts (MAMoE) architecture. While current multimodal models typically process diverse modality representations with identical parameters, disregarding their inherent representational differences, we introduce specialized routing pathways that direct tokens to modality-appropriate experts based on input type. MAMoE simultaneously enhances modality-specific learning and cross-modal understanding through two complementary components: modality-specific expert groups that capture domain-specific patterns and shared experts that facilitate information transfer between modalities. Building on this architecture, we develop an efficient transformation pipeline that adapts the pretrained MoE language model through strategic post-training on ASR and TTS datasets, followed by fine-tuning with a carefully curated speech-text instruction dataset. A key feature of this pipeline is that it relies exclusively on fully accessible, open-source datasets to achieve strong performance and data efficiency. Comprehensive evaluations across ASR, TTS, audio language modeling, and spoken question answering benchmarks show that MoST consistently outperforms existing models of comparable parameter counts. Our ablation studies confirm that the modality-specific routing mechanism and shared experts design significantly contribute to performance gains across all tested domains. To our knowledge, MoST represents the first fully open-source speech-text LLM built on a Mixture of Experts architecture. \\footnote{We release MoST model, training code, inference code, and training data at https://github.com/NUS-HPC-AI-Lab/MoST", "AI": {"tldr": "本文介绍了MoST（混合语音和文本的专家混合），一种新型的多模态大型语言模型，通过提议的Modality-Aware Mixture of Experts架构无缝整合了语音和文本处理。", "motivation": "当前的多模态模型通常用相同的参数来处理多种模式的表示形式，忽略了它们内在表达上的差异。MoST希望通过专门的路由路径将输入类型导向适当的专家以增强特定模态的学习并促进跨模态的理解。", "method": "MAMoE架构包括捕捉领域特定模式的专业专家组和促进模态间信息传递的共享专家。MoST构建了一个高效的转换管道，通过在ASR和TTS数据集上的后训练和用精心策划的语音-文本指令数据集进行微调来适应预训练的MoE语言模型。", "result": "全面评估表明，与参数规模相近的现有模型相比，MoST在各种基准上表现更优。消融研究表明模态特定路由机制和共享专家设计对性能提升有显著贡献。", "conclusion": "MoST代表了第一个基于Mixture of Experts架构构建的完全开源的语音-文本大型语言模型，并展示了其优越性和数据效率，证明了多模态处理中采用特定模态专家的重要性。"}}
{"id": "2601.10268", "pdf": "https://arxiv.org/pdf/2601.10268", "abs": "https://arxiv.org/abs/2601.10268", "authors": ["Eszter Birtalan", "Miklós Koller"], "title": "The impact of tactile sensor configurations on grasp learning efficiency -- a comparative evaluation in simulation", "categories": ["cs.RO"], "comment": "13 pages, 6 figures, 2 tables", "summary": "Tactile sensors are breaking into the field of robotics to provide direct information related to contact surfaces, including contact events, slip events and even texture identification. These events are especially important for robotic hand designs, including prosthetics, as they can greatly improve grasp stability. Most presently published robotic hand designs, however, implement them in vastly different densities and layouts on the hand surface, often reserving the majority of the available space. We used simulations to evaluate 6 different tactile sensor configurations with different densities and layouts, based on their impact on reinforcement learning. Our two-setup system allows for robust results that are not dependent on the use of a given physics simulator, robotic hand model or machine learning algorithm. Our results show setup-specific, as well as generalized effects across the 6 sensorized simulations, and we identify one configuration as consistently yielding the best performance across both setups. These results could help future research aimed at robotic hand designs, including prostheses.", "AI": {"tldr": "通过仿真比较分析了不同触觉传感器配置对抓握学习效率的影响。", "motivation": "当前的大多数机器人手设计中，触觉传感器被以不同的密度和布局应用于手部表面。此研究旨在评估这些差异如何影响机器人的抓握稳定性，并提供对未来仿生手设计有帮助的结果。", "method": "使用仿真技术对6种不同密度和布局的触觉传感器配置进行比较评估，基于它们对强化学习的影响。", "result": "结果表明存在特定设置下的效果以及在六种模拟中的通用效应，确定了一种配置可提供跨两种设置的一致最佳性能。", "conclusion": "这些研究发现能够指导未来的仿生手设计，并可能提升抓握的稳定性。"}}
{"id": "2601.10263", "pdf": "https://arxiv.org/pdf/2601.10263", "abs": "https://arxiv.org/abs/2601.10263", "authors": ["Mingxuan Du", "Tingzhang Luo", "Ziyang Wang", "Chengjun Li"], "title": "An Ensemble of Evolutionary Algorithms With Both Crisscross Search and Sparrow Search for Processing Inferior Individuals", "categories": ["cs.NE"], "comment": null, "summary": "In the field of artificial intelligence, real parameter single objective optimization is an important direction. Both the Differential Evolution (DE) and the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) demonstrate good performance for real parameter single objective optimization. Nevertheless, there exist other types of evolutionary algorithm for the purpose. In recent years, researchers begin to study long-term search. EA4eig - an ensemble of three DE variants and CMA-ES - performs well for long-term search. In this paper, we introduce two types of evolutionary algorithm proposed recently - crisscross search and sparrow search - into EA4eig as secondary evolutionary algorithms to process inferior individuals. Thus, EA4eigCS is obtained. In our ensemble, the secondary evolutionary algorithms are expected to vary distribution of the population for breaking stagnation. Experimental results show that our EA4eigCS outperforms EA4eig and is competitive when compared with state-of-the-art algorithms. Code and supplementary material are available at:https://anonymous.4open.science/r/EA4eigCS-2A43.", "AI": {"tldr": "本文提出了一种改进的进化算法EA4eigCS，通过引入交叉搜索和麻雀搜索两种新算法处理表现较差的个体。", "motivation": "传统的DE和CMA-ES在单目标实参优化中表现出色，但存在其他类型的进化算法。为了长期搜索，作者希望改进EA4eig，提高其性能。", "method": "本文将交叉搜索和麻雀搜索两种新提出的进化算法引入到EA4eig中作为辅助算法，处理表现较差的个体，以打破停滞状态并改善种群分布。", "result": "实验结果表明，与原始的EA4eig相比，新的EA4eigCS表现出更好的性能，并且与其他最先进的算法竞争。", "conclusion": "通过引入交叉搜索和麻雀搜索这两种辅助进化算法，可以有效提高长期搜索中处理表现较差个体的能力，从而改善整体优化效果。"}}
{"id": "2601.10258", "pdf": "https://arxiv.org/pdf/2601.10258", "abs": "https://arxiv.org/abs/2601.10258", "authors": ["Agnia Sergeyuk", "Eric Huang", "Dariia Karaeva", "Anastasiia Serova", "Yaroslav Golubev", "Iftekhar Ahmed"], "title": "Evolving with AI: A Longitudinal Analysis of Developer Logs", "categories": ["cs.SE", "cs.HC"], "comment": "Accepted to ICSE'26 Research track. 12 pages, 5 figures, 1 table", "summary": "AI-powered coding assistants are rapidly becoming fixtures in professional IDEs, yet their sustained influence on everyday development remains poorly understood. Prior research has focused on short-term use or self-reported perceptions, leaving open questions about how sustained AI use reshapes actual daily coding practices in the long term. We address this gap with a mixed-method study of AI adoption in IDEs, combining longitudinal two-year fine-grained telemetry from 800 developers with a survey of 62 professionals. We analyze five dimensions of workflow change: productivity, code quality, code editing, code reuse, and context switching. Telemetry reveals that AI users produce substantially more code but also delete significantly more. Meanwhile, survey respondents report productivity gains and perceive minimal changes in other dimensions. Our results offer empirical insights into the silent restructuring of software workflows and provide implications for designing future AI-augmented tooling.", "AI": {"tldr": "研究通过混合方法分析了AI在IDE中长期使用对开发者日常编码实践的影响。", "motivation": "先前的研究主要关注短期使用或自我报告的感受，缺乏关于长时间使用AI如何改变实际的每日编程习惯的理解。", "method": "结合两年的细粒度遥测数据和专业开发者的调查，分析了生产力、代码质量、代码编辑、代码复用和上下文切换五个工作流程变化维度。", "result": "数据显示，AI用户生成更多代码但删除的比例也更高，而受访开发者报告了生产力提升，并认为其他方面几乎没有变化。", "conclusion": "研究为软件工作流的无声重构提供了经验性见解，并对设计未来的AI增强工具具有启示作用。"}}
{"id": "2601.10257", "pdf": "https://arxiv.org/pdf/2601.10257", "abs": "https://arxiv.org/abs/2601.10257", "authors": ["Nan Li", "Bo Kang", "Tijl De Bie"], "title": "Untangling Input Language from Reasoning Language: A Diagnostic Framework for Cross-Lingual Moral Alignment in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "When LLMs judge moral dilemmas, do they reach different conclusions in different languages, and if so, why? Two factors could drive such differences: the language of the dilemma itself, or the language in which the model reasons. Standard evaluation conflates these by testing only matched conditions (e.g., English dilemma with English reasoning). We introduce a methodology that separately manipulates each factor, covering also mismatched conditions (e.g., English dilemma with Chinese reasoning), enabling decomposition of their contributions. To study \\emph{what} changes, we propose an approach to interpret the moral judgments in terms of Moral Foundations Theory. As a side result, we identify evidence for splitting the Authority dimension into a family-related and an institutional dimension. Applying this methodology to English-Chinese moral judgment with 13 LLMs, we demonstrate its diagnostic power: (1) the framework isolates reasoning-language effects as contributing twice the variance of input-language effects; (2) it detects context-dependency in nearly half of models that standard evaluation misses; and (3) a diagnostic taxonomy translates these patterns into deployment guidance. We release our code and datasets at https://anonymous.4open.science/r/CrossCulturalMoralJudgement.", "AI": {"tldr": "本文提出了一个诊断框架，用于解开输入语言和推理语言对大语言模型道德判断的影响，并通过实验展示了该框架的诊断能力。", "motivation": "作者关注于LLMs在不同语言环境下对道德困境做出的不同结论的原因，提出标准评估方法混淆了输入语言与推理语言因素，因此设计了一种新方法来单独分析这些影响因素。", "method": "提出了一个能够独立操纵输入语言和推理语言的方法论，并通过道德基础理论解释模型的道德判断。该研究还涵盖了匹配条件和不匹配条件下13个LLMs在英汉两种语言下的道德判断测试。", "result": "展示了框架的有效性，揭示了推理语言影响是输入语言影响两倍的方差；检测到标准评估中未发现的近半数模型中的上下文依赖现象，并提出了一个诊断分类法以指导部署。", "conclusion": "研究结果表明该方法论能够有效区分并量化输入语言和推理语言对LLMs道德判断的影响，提供了一个强有力的工具来解析这些影响并为实际应用提供了指导意见。"}}
{"id": "2601.10254", "pdf": "https://arxiv.org/pdf/2601.10254", "abs": "https://arxiv.org/abs/2601.10254", "authors": ["Irina Abdullaeva", "Anton Vasiliuk", "Elizaveta Goncharova", "Temurbek Rahmatullaev", "Zagorulko Ivan", "Maxim Kurkin", "Andrey Kuznetsov"], "title": "NoReGeo: Non-Reasoning Geometry Benchmark", "categories": ["cs.AI"], "comment": null, "summary": "We present NoReGeo, a novel benchmark designed to evaluate the intrinsic geometric understanding of large language models (LLMs) without relying on reasoning or algebraic computation. Unlike existing benchmarks that primarily assess models' proficiency in reasoning-based geometry-where solutions are derived using algebraic methods-NoReGeo focuses on evaluating whether LLMs can inherently encode spatial relationships and recognize geometric properties directly. Our benchmark comprises 2,500 trivial geometric problems spanning 25 categories, each carefully crafted to be solvable purely through native geometric understanding, assuming known object locations. We assess a range of state-of-the-art models on NoReGeo, including frontier models like GPT-4, observing that even the most advanced systems achieve an overall maximum of 65% accuracy in binary classification tasks. Further, our ablation experiments demonstrate that such geometric understanding does not emerge through fine-tuning alone, indicating that effective training for geometric comprehension requires a specialized approach from the outset. Our findings highlight a significant gap in current LLMs' ability to natively grasp geometric concepts, providing a foundation for future research toward models with true geometric cognition.", "AI": {"tldr": "本文介绍了NoReGeo，一个用于评估大型语言模型（LLMs）内在几何理解能力的基准测试，不依赖于推理或代数计算。", "motivation": "现有基准主要评估基于推理的几何问题解决能力，而本文旨在评估LLMs能否直接编码空间关系和识别几何属性。", "method": "NoReGeo包含2500个简单的几何问题，分为25类，这些问题设计为仅通过本源几何理解即可解答。评估了包括GPT-4在内的多种前沿模型。", "result": "最先进的系统在二元分类任务上的最大准确率为65%，表明现有LLMs的几何理解能力存在明显差距。", "conclusion": "研究结果揭示了当前LLMs在内在掌握几何概念方面的不足，为未来开发具有真正几何认知能力的模型提供了基础。"}}
{"id": "2601.10253", "pdf": "https://arxiv.org/pdf/2601.10253", "abs": "https://arxiv.org/abs/2601.10253", "authors": ["Nadine Kuo", "Agnia Sergeyuk", "Valerie Chen", "Maliheh Izadi"], "title": "Developer Interaction Patterns with Proactive AI: A Five-Day Field Study", "categories": ["cs.HC", "cs.SE"], "comment": "14 pages, 6 figures, accepted to IUI'26", "summary": "Current in-IDE AI coding tools typically rely on time-consuming manual prompting and context management, whereas proactive alternatives that anticipate developer needs without explicit invocation remain underexplored. Understanding when humans are receptive to such proactive AI assistance during their daily work remains an open question in human-AI interaction research. We address this gap through a field study of proactive AI assistance in professional developer workflows. We present a five-day in-the-wild study with 15 developers who interacted with a proactive feature of an AI assistant integrated into a production-grade IDE that offers code quality suggestions based on in-IDE developer activity. We examined 229 AI interventions across 5,732 interaction points to understand how proactive suggestions are received across workflow stages, how developers experience them, and their perceived impact. Our findings reveal systematic patterns in human receptivity to proactive suggestions: interventions at workflow boundaries (e.g., post-commit) achieved 52% engagement rates, while mid-task interventions (e.g., on declined edit) were dismissed 62% of the time. Notably, well-timed proactive suggestions required significantly less interpretation time than reactive suggestions (45.4s versus 101.4s, W = 109.00, r = 0.533, p = 0.0016), indicating enhanced cognitive alignment. This study provides actionable implications for designing proactive coding assistants, including how to time interventions, align them with developer context, and strike a balance between AI agency and user control in production IDEs.", "AI": {"tldr": "研究探讨了专业开发人员在日常工作流程中对主动式AI助手的反应模式，通过五天的实际使用研究评估了AI干预的效果。", "motivation": "当前集成到IDE中的AI编码工具通常依赖于耗时的手动提示和上下文管理。而能够预见开发者需求且无需显式调用的主动式AI辅助却尚未被充分探索。本论文旨在填补这一空白，了解人类在日常工作中对这种主动式AI协助的接受情况。", "method": "研究设计了一个为期五天的实际使用场景下的研究，涉及15名开发人员与集成到生产级IDE中的一个能够基于开发者活动提供代码质量建议的主动式AI助手互动。共记录了229个AI干预点和5732个交互点。", "result": "研究表明，在工作流程边界（如提交后）进行干预能获得52%的参与率，而在任务中段的干预（例如对拒绝编辑操作）则被忽略62%。及时的主动建议需要的时间显著少于被动式建议（45.4秒对比101.4秒），表明了更好的认知一致性。", "conclusion": "研究结果为设计与开发者工作流程同步的主动式编码助手提供了实际指导，包括如何定时干预、与开发者情境对齐以及在AI自主权和用户控制之间取得平衡。"}}
{"id": "2601.10251", "pdf": "https://arxiv.org/pdf/2601.10251", "abs": "https://arxiv.org/abs/2601.10251", "authors": ["Hongru Duan", "Yongle Chen", "Lei Guan"], "title": "X-SAM: Boosting Sharpness-Aware Minimization with Dominant-Eigenvector Gradient Correction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sharpness-Aware Minimization (SAM) aims to improve generalization by minimizing a worst-case perturbed loss over a small neighborhood of model parameters. However, during training, its optimization behavior does not always align with theoretical expectations, since both sharp and flat regions may yield a small perturbed loss. In such cases, the gradient may still point toward sharp regions, failing to achieve the intended effect of SAM. To address this issue, we investigate SAM from a spectral and geometric perspective: specifically, we utilize the angle between the gradient and the leading eigenvector of the Hessian as a measure of sharpness. Our analysis illustrates that when this angle is less than or equal to ninety degrees, the effect of SAM's sharpness regularization can be weakened. Furthermore, we propose an explicit eigenvector-aligned SAM (X-SAM), which corrects the gradient via orthogonal decomposition along the top eigenvector, enabling more direct and efficient regularization of the Hessian's maximum eigenvalue. We prove X-SAM's convergence and superior generalization, with extensive experimental evaluations confirming both theoretical and practical advantages.", "AI": {"tldr": "本文提出了X-SAM算法，通过主特征向量修正梯度以增强Sharpness-Aware Minimization（SAM）的效果。", "motivation": "由于SAM在训练过程中可能指向尖锐的区域而未能达到预期效果，研究者希望通过新的方法来改进其优化行为和泛化能力。", "method": "作者利用梯度与海森矩阵最大特征向量之间的角度作为衡量锋利程度的标准，并提出通过主特征向量对齐的X-SAM方法来修正梯度。", "result": "证明了X-SAM算法的收敛性和优越的泛化性能，实验结果也证实了其理论和实际的优势。", "conclusion": "研究展示了X-SAM能够更直接有效地调节海森矩阵的最大特征值，从而提高模型的优化行为和泛化效果。"}}
{"id": "2601.10250", "pdf": "https://arxiv.org/pdf/2601.10250", "abs": "https://arxiv.org/abs/2601.10250", "authors": ["Raffaella Fiamma Cabini", "Deborah Barkauskas", "Guangyu Chen", "Zhi-Qi Cheng", "David E Cicchetti", "Judith Drazba", "Rodrigo Fernandez-Gonzalez", "Raymond Hawkins", "Yujia Hu", "Jyoti Kini", "Charles LeWarne", "Xufeng Lin", "Sai Preethi Nakkina", "John W Peterson", "Koert Schreurs", "Ayushi Singh", "Kumaran Bala Kandan Viswanathan", "Inge MN Wortel", "Sanjian Zhang", "Rolf Krause", "Santiago Fernandez Gonzalez", "Diego Ulisse Pizzagalli"], "title": "Cell Behavior Video Classification Challenge, a benchmark for computer vision methods in time-lapse microscopy", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "comment": null, "summary": "The classification of microscopy videos capturing complex cellular behaviors is crucial for understanding and quantifying the dynamics of biological processes over time. However, it remains a frontier in computer vision, requiring approaches that effectively model the shape and motion of objects without rigid boundaries, extract hierarchical spatiotemporal features from entire image sequences rather than static frames, and account for multiple objects within the field of view. To this end, we organized the Cell Behavior Video Classification Challenge (CBVCC), benchmarking 35 methods based on three approaches: classification of tracking-derived features, end-to-end deep learning architectures to directly learn spatiotemporal features from the entire video sequence without explicit cell tracking, or ensembling tracking-derived with image-derived features. We discuss the results achieved by the participants and compare the potential and limitations of each approach, serving as a basis to foster the development of computer vision methods for studying cellular dynamics.", "AI": {"tldr": "本文介绍了Cell Behavior Video Classification Challenge（CBVCC），这是一个用于评估计算机视觉方法在时序显微镜图像分类中性能的基准。", "motivation": "理解并量化生物过程的动力学至关重要，这需要开发能够有效建模非刚性边界对象形状和运动、提取整个图像序列的分层时空特征，并考虑视野内多个目标的计算机视觉方法。", "method": "CBVCC评估了35种基于三种方法的技术：1) 基于跟踪衍生特征的分类；2) 直接从完整视频序列学习时空特征的端到端深度学习架构；3) 聚合跟踪和图像衍生特征。", "result": "文章讨论了参与者取得的结果，并对比了每种方法的潜力与局限性。", "conclusion": "该挑战赛作为研究细胞动力学计算机视觉方法发展的基础，促进了相关领域的进一步发展。"}}
{"id": "2601.10245", "pdf": "https://arxiv.org/pdf/2601.10245", "abs": "https://arxiv.org/abs/2601.10245", "authors": ["Vansh Kapoor", "Aman Gupta", "Hao Chen", "Anurag Beniwal", "Jing Huang", "Aviral Kumar"], "title": "TRIM: Hybrid Inference via Targeted Stepwise Routing in Multi-Step Reasoning Tasks", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Multi-step reasoning tasks like mathematical problem solving are vulnerable to cascading failures, where a single incorrect step leads to complete solution breakdown. Current LLM routing methods assign entire queries to one model, treating all reasoning steps as equal. We propose TRIM (Targeted routing in multi-step reasoning tasks), which routes only critical steps$\\unicode{x2013}$those likely to derail the solution$\\unicode{x2013}$to larger models while letting smaller models handle routine continuations. Our key insight is that targeted step-level interventions can fundamentally transform inference efficiency by confining expensive calls to precisely those steps where stronger models prevent cascading errors. TRIM operates at the step-level: it uses process reward models to identify erroneous steps and makes routing decisions based on step-level uncertainty and budget constraints. We develop several routing strategies within TRIM, ranging from a simple threshold-based policy to more expressive policies that reason about long-horizon accuracy-cost trade-offs and uncertainty in step-level correctness estimates. On MATH-500, even the simplest thresholding strategy surpasses prior routing methods with 5x higher cost efficiency, while more advanced policies match the strong, expensive model's performance using 80% fewer expensive model tokens. On harder benchmarks such as AIME, TRIM achieves up to 6x higher cost efficiency. All methods generalize effectively across math reasoning tasks, demonstrating that step-level difficulty represents fundamental characteristics of reasoning.", "AI": {"tldr": "TRIM通过在多步骤推理任务中，仅将关键步骤定向路由到更大的模型，从而提高推理效率。", "motivation": "多步推理任务易受级联错误的影响，现有方法未能有效处理这种问题。作者希望通过精确分配计算资源来减少此类失败并提升成本效益。", "method": "TRIM使用过程奖励模型识别有误的步骤，并根据步骤级别的不确定性和预算约束进行路由决策。开发了几种策略，从简单的阈值策略到更复杂的长期准确性与成本权衡策略。", "result": "在MATH-500上，即使是最基本的阈值策略也达到了比先前方法高五倍的成本效率；高级策略使用80%较少的昂贵模型标记实现了强性能。在AIME等难题基准测试中，TRIM达到六倍成本效率。", "conclusion": "通过步骤级别的干预可以显著提升多步推理任务的计算资源利用效率和准确性。"}}
{"id": "2601.10244", "pdf": "https://arxiv.org/pdf/2601.10244", "abs": "https://arxiv.org/abs/2601.10244", "authors": ["Megha Mariam K M", "C. V. Jawahar"], "title": "Attend to what I say: Highlighting relevant content on slides", "categories": ["cs.CV"], "comment": "Accepted at the International Conference on Document Analysis and Recognition (ICDAR) 2025", "summary": "Imagine sitting in a presentation, trying to follow the speaker while simultaneously scanning the slides for relevant information. While the entire slide is visible, identifying the relevant regions can be challenging. As you focus on one part of the slide, the speaker moves on to a new sentence, leaving you scrambling to catch up visually. This constant back-and-forth creates a disconnect between what is being said and the most important visual elements, making it hard to absorb key details, especially in fast-paced or content-heavy presentations such as conference talks. This requires an understanding of slides, including text, graphics, and layout. We introduce a method that automatically identifies and highlights the most relevant slide regions based on the speaker's narrative. By analyzing spoken content and matching it with textual or graphical elements in the slides, our approach ensures better synchronization between what listeners hear and what they need to attend to. We explore different ways of solving this problem and assess their success and failure cases. Analyzing multimedia documents is emerging as a key requirement for seamless understanding of content-rich videos, such as educational videos and conference talks, by reducing cognitive strain and improving comprehension. Code and dataset are available at: https://github.com/meghamariamkm2002/Slide_Highlight", "AI": {"tldr": "该论文介绍了一种方法，能够根据演讲者的叙述自动识别并突出幻灯片中的相关区域，以实现听者所听到的内容与需要关注的视觉元素之间的更好同步。", "motivation": "在听取演讲的同时扫描幻灯片的相关信息可能很困难，导致难以吸收关键细节。这种方法旨在通过分析口头内容并与幻灯片中的文本或图形元素匹配来减少认知负担并提高理解能力。", "method": "该方法通过对讲者叙述的内容进行分析，并将其与幻灯片中的文字和图形元素相匹配，从而自动识别并突出显示相关区域。", "result": "论文探索了不同的解决方案，并评估它们的成功案例和失败案例，以改善多媒体文档的解析，特别是在教育视频和学术演讲中减少认知负担和提高理解能力的效果。", "conclusion": "这种方法有助于更好地同步听众听到的内容与需要关注的视觉元素，从而在内容丰富的视频中提高理解和记忆效率。"}}
{"id": "2601.10242", "pdf": "https://arxiv.org/pdf/2601.10242", "abs": "https://arxiv.org/abs/2601.10242", "authors": ["Guanxu Chen", "Dongrui Liu", "Jing Shao"], "title": "Loop as a Bridge: Can Looped Transformers Truly Link Representation Space and Natural Language Outputs?", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages,6 figures", "summary": "Large Language Models (LLMs) often exhibit a gap between their internal knowledge and their explicit linguistic outputs. In this report, we empirically investigate whether Looped Transformers (LTs)--architectures that increase computational depth by iterating shared layers--can bridge this gap by utilizing their iterative nature as a form of introspection. Our experiments reveal that while increasing loop iterations narrows the gap, it is partly driven by a degradation of their internal knowledge carried by representations. Moreover, another empirical analysis suggests that current LTs' ability to perceive representations does not improve across loops; it is only present in the final loop. These results suggest that while LTs offer a promising direction for scaling computational depth, they have yet to achieve the introspection required to truly link representation space and natural language.", "AI": {"tldr": "研究Looped Transformers（LTs）是否能通过迭代的性质作为内省的形式，缩小大型语言模型内部知识与显式语言输出之间的差距。", "motivation": "大型语言模型经常表现出其内部知识与其显式语言输出之间的差距。本报告试图了解Looped Transformers能否利用其迭代性质来弥补这种差距。", "method": "通过实验增加循环次数并观察这种变化对LTs内部表示和外部输出影响的方法进行研究。", "result": "实验证明，虽然增加循环次数可以缩小这个差距，但也导致了内部知识的退化。进一步分析表明，当前的LTs在各个循环中并不能改善它们感知表示的能力，只有在最终循环时才能出现。", "conclusion": "尽管Looped Transformers为加深计算深度提供了一条有希望的方向，但要真正实现连接表示空间和自然语言所需的那种内省能力还有很长的一段路要走。"}}
{"id": "2601.10236", "pdf": "https://arxiv.org/pdf/2601.10236", "abs": "https://arxiv.org/abs/2601.10236", "authors": ["Bohan Zhang", "Chengke Bu", "Paramveer S. Dhillon"], "title": "Who Owns the Text? Design Patterns for Preserving Authorship in AI-Assisted Writing", "categories": ["cs.HC", "cs.AI"], "comment": "Preprint; 42 pages", "summary": "AI writing assistants can reduce effort and improve fluency, but they may also weaken writers' sense of authorship. We study this tension with an ownership-aware co-writing editor that offers on-demand, sentence-level suggestions and tests two common design choices: persona-based coaching and style personalization. In an online study (N=176), participants completed three professional writing tasks: an email without AI help, a proposal with generic AI suggestions, and a cover letter with persona-based coaching, while half received suggestions tailored to a brief sample of their prior writing. Across the two AI-assisted tasks, psychological ownership dropped relative to unassisted writing (about 0.85-1.0 points on a 7-point scale), even as cognitive load decreased (about 0.9 points) and quality ratings stayed broadly similar overall. Persona coaching did not prevent the ownership decline. Style personalization partially restored ownership (about +0.43) and increased AI incorporation in text (+5 percentage points). We distill five design patterns: on-demand initiation, micro-suggestions, voice anchoring, audience scaffolds, and point-of-decision provenance, to guide authorship-preserving writing tools.", "AI": {"tldr": "研究了AI写作助手在辅助写作时如何保持作者的归属感，并提出了五种设计模式以引导保护作者身份的写作工具。", "motivation": "探讨AI写作助手可能削弱写作者对作品的归属感的问题，旨在找到方法来维持这种归属感同时提高写作质量和减少认知负担。", "method": "进行了一项在线研究，其中参与者完成三项专业写作任务，分别在无AI帮助、通用AI建议和基于角色的辅导下，并测试了样式个性化的效果。", "result": "使用AI辅助写作时心理所有权有所下降，但认知负荷降低且整体质量评分变化不大。基于角色的辅导没有阻止归属感的下降，而风格个性化部分恢复了归属感并增加了AI在文本中的融入度。", "conclusion": "提出了五种设计模式来指导维护作者身份的写作工具的设计：按需启动、微建议、声音锚定、受众支架和决策点出处。"}}
{"id": "2601.10233", "pdf": "https://arxiv.org/pdf/2601.10233", "abs": "https://arxiv.org/abs/2601.10233", "authors": ["Yifan Xue", "Ze Zhang", "Knut Åkesson", "Nadia Figueroa"], "title": "Proactive Local-Minima-Free Robot Navigation: Blending Motion Prediction with Safe Control", "categories": ["cs.RO"], "comment": "Co-first authors: Yifan Xue and Ze Zhang", "summary": "This work addresses the challenge of safe and efficient mobile robot navigation in complex dynamic environments with concave moving obstacles. Reactive safe controllers like Control Barrier Functions (CBFs) design obstacle avoidance strategies based only on the current states of the obstacles, risking future collisions. To alleviate this problem, we use Gaussian processes to learn barrier functions online from multimodal motion predictions of obstacles generated by neural networks trained with energy-based learning. The learned barrier functions are then fed into quadratic programs using modulated CBFs (MCBFs), a local-minimum-free version of CBFs, to achieve safe and efficient navigation. The proposed framework makes two key contributions. First, it develops a prediction-to-barrier function online learning pipeline. Second, it introduces an autonomous parameter tuning algorithm that adapts MCBFs to deforming, prediction-based barrier functions. The framework is evaluated in both simulations and real-world experiments, consistently outperforming baselines and demonstrating superior safety and efficiency in crowded dynamic environments.", "AI": {"tldr": "提出一种结合运动预测和安全控制的机器人导航框架，用于在复杂动态环境中实现无局部最小点的安全高效导航。", "motivation": "传统的反应型安全控制器仅基于障碍物当前状态进行避障策略设计，存在未来碰撞风险。为了克服这一问题并提高移动机器人在动态环境中的安全性和效率，提出了一种新的解决方案。", "method": "使用高斯过程在线学习从神经网络生成的多模态运动预测中得出障碍函数，并利用调制控制屏障函数（MCBFs）实现安全高效的导航。框架包括两个主要贡献：开发了从预测到障碍函数的在线学习管道，以及引入了一种自适应参数调整算法以适应变形、基于预测的障碍函数。", "result": "该框架在模拟和实际实验中均表现出色，与基线方法相比，在拥挤动态环境中展示了更好的安全性和效率。", "conclusion": "通过结合运动预测和调制控制屏障函数的方法，所提出框架能够有效提高机器人导航的安全性，并在复杂动态环境下实现无局部最小点的高效导航。"}}
{"id": "2601.10232", "pdf": "https://arxiv.org/pdf/2601.10232", "abs": "https://arxiv.org/abs/2601.10232", "authors": ["Choro Ulan uulu", "Mikhail Kulyabin", "Katharina M Zeiner", "Jan Joosten", "Nuno Miguel Martins Pacheco", "Filippos Petridis", "Rebecca Johnson", "Jan Bosch", "Helena Holmström Olsson"], "title": "Tables or Sankey Diagrams? Investigating User Interaction with Different Representations of Simulation Parameters", "categories": ["cs.HC", "cs.SE"], "comment": null, "summary": "Understanding complex parameter dependencies is critical for effective configuration and maintenance of software systems across diverse domains - from Computer-Aided Engineering (CAE) to cloud infrastructure and database management. However, legacy tabular interfaces create a major bottleneck: engineers cannot easily comprehend how parameters relate across the system, leading to inefficient workflows, costly configuration errors, and reduced system trust - a fundamental program comprehension challenge in configuration-intensive software. This research evaluates whether interactive Sankey diagrams can improve comprehension of parameter dependencies compared to traditional spreadsheet interfaces. We employed a heuristic evaluation using the PURE method with three expert evaluators (UX design, simulation, and software development specialists) to compare a Sankey-based prototype to traditional tabular representations for core engineering tasks. Our key contribution demonstrates that flow-based parameter visualizations significantly reduce cognitive load (51% lower PURE scores) and interaction complexity (56% fewer steps) compared to traditional tables, while making parameter dependencies immediately visible rather than requiring mental reconstruction. By explicitly visualizing parameter relationships, Sankey diagrams address a core software visualization challenge: helping users comprehend complex system configurations without requiring deep tool-specific knowledge. While demonstrated through CAE software, this research contributes to program comprehension and software visualization by showing that dependency-aware visualizations can significantly improve understanding of configuration-intensive systems. The findings have implications for any software domain where comprehending complex parameter relationships is essential for effective system use and maintenance.", "AI": {"tldr": "研究评估了交互式桑基图在理解参数依赖关系方面是否优于传统电子表格界面。", "motivation": "传统的表格界面导致工程师难以理解系统中的参数关系，这阻碍了有效的配置和维护工作流程，并可能导致成本高昂的配置错误。", "method": "使用PURE方法进行启发式评估，通过三个专家（用户体验设计、模拟和软件开发专家）比较桑基图原型与传统表格表示在核心工程任务上的表现。", "result": "研究结果表明，基于流的参数可视化显著降低了认知负担（PURE评分降低51%），简化了交互复杂性（步骤减少了56%）。", "conclusion": "通过明确地可视化参数关系，桑基图有助于用户理解复杂的系统配置，而无需深厚的工具特定知识。这项研究对于任何需要有效理解和维护的领域都具有重要意义。"}}
{"id": "2601.10228", "pdf": "https://arxiv.org/pdf/2601.10228", "abs": "https://arxiv.org/abs/2601.10228", "authors": ["Sicheng Yang", "Yukai Huang", "Shitong Sun", "Weitong Cai", "Jiankang Deng", "Jifei Song", "Zhensong Zhang"], "title": "Optimizing Multimodal LLMs for Egocentric Video Understanding: A Solution for the HD-EPIC VQA Challenge", "categories": ["cs.CV", "cs.MM", "eess.IV"], "comment": "4 pages, 1 figure, CVPR 2025 EgoVis Workshop, 2nd Place in HD-EPIC Challenge", "summary": "Multimodal Large Language Models (MLLMs) struggle with complex video QA benchmarks like HD-EPIC VQA due to ambiguous queries/options, poor long-range temporal reasoning, and non-standardized outputs. We propose a framework integrating query/choice pre-processing, domain-specific Qwen2.5-VL fine-tuning, a novel Temporal Chain-of-Thought (T-CoT) prompting for multi-step reasoning, and robust post-processing. This system achieves 41.6% accuracy on HD-EPIC VQA, highlighting the need for holistic pipeline optimization in demanding video understanding. Our code, fine-tuned models are available at https://github.com/YoungSeng/Egocentric-Co-Pilot.", "AI": {"tldr": "本文提出了一种针对HD-EPIC VQA挑战的解决方案，通过优化多模态大语言模型（MLLMs）来提高视频理解性能。", "motivation": "动机是解决现有的MLLMs在处理复杂的视频问答基准测试时存在的问题，如模糊查询选项、较差的时间推理能力以及非标准输出。", "method": "方法包括查询/选择预处理、针对Qwen2.5-VL的领域特定微调、提出一种新的时间链式思维（T-CoT）提示用于多步推理以及稳健的后处理。", "result": "该系统在HD-EPIC VQA上实现了41.6%的准确率，展示了对复杂视频理解任务进行全面优化管道的重要性。", "conclusion": "结论是对于具有挑战性的视频理解任务来说，需要一个全面的优化管道来改进性能，并提供了代码和微调模型供研究使用。"}}
{"id": "2601.10225", "pdf": "https://arxiv.org/pdf/2601.10225", "abs": "https://arxiv.org/abs/2601.10225", "authors": ["Dongwook Kwak", "Geonhee Cho", "Jiook Chung", "Jinkyu Yang"], "title": "A Unified Framework for Kinematic Simulation of Rigid Foldable Structures", "categories": ["cs.RO"], "comment": "34 pages (20 pages main text), 11 figures (7 in main text, 4 in appendix)", "summary": "Origami-inspired structures with rigid panels now span thick, kirigami, and multi-sheet realizations, making unified kinematic analysis essential. Yet a general method that consolidates their loop constraints has been lacking. We present an automated approach that generates the Pfaffian constraint matrix for arbitrary rigid foldable structures (RFS). From a minimally extended data schema, the tool constructs the facet-hinge graph, extracts a minimum cycle basis that captures all constraints, and assembles a velocity-level constraint matrix via screw theory that encodes coupled rotation and translation loop closure. The framework computes and visualizes deploy and fold motions across diverse RFS while eliminating tedious and error-prone constraint calculations.", "AI": {"tldr": "本文提出了一种用于刚性可折叠结构（RFS）的统一动力学模拟框架，自动生成Pfaffian约束矩阵以实现精确的动力学分析。", "motivation": "随着折纸启发的结构在厚板、剪纸和多层结构中的广泛应用，需要一种通用的方法来整合这些结构的环路约束，从而进行统一的动力学分析。", "method": "本文采用自动化方法从最小扩展的数据模式生成Pfaffian约束矩阵，并通过螺丝理论构造速度级约束矩阵以捕获耦合旋转和平移环闭合，实现刚性可折叠结构的精确模拟。", "result": "该框架能够计算和可视化多种RFS的展开和折叠运动，消除繁琐且容易出错的约束计算。", "conclusion": "本文提出的统一动力学分析框架为刚性可折叠结构提供了高效的自动化分析方法，提高了分析效率并降低了错误率。"}}
{"id": "2601.10222", "pdf": "https://arxiv.org/pdf/2601.10222", "abs": "https://arxiv.org/abs/2601.10222", "authors": ["Alena Kopaničáková", "Elisa Riccietti"], "title": "Introduction to optimization methods for training SciML models", "categories": ["math.NA", "cs.AI", "math.OC"], "comment": null, "summary": "Optimization is central to both modern machine learning (ML) and scientific machine learning (SciML), yet the structure of the underlying optimization problems differs substantially across these domains. Classical ML typically relies on stochastic, sample-separable objectives that favor first-order and adaptive gradient methods. In contrast, SciML often involves physics-informed or operator-constrained formulations in which differential operators induce global coupling, stiffness, and strong anisotropy in the loss landscape. As a result, optimization behavior in SciML is governed by the spectral properties of the underlying physical models rather than by data statistics, frequently limiting the effectiveness of standard stochastic methods and motivating deterministic or curvature-aware approaches. This document provides a unified introduction to optimization methods in ML and SciML, emphasizing how problem structure shapes algorithmic choices. We review first- and second-order optimization techniques in both deterministic and stochastic settings, discuss their adaptation to physics-constrained and data-driven SciML models, and illustrate practical strategies through tutorial examples, while highlighting open research directions at the interface of scientific computing and scientific machine learning.", "AI": {"tldr": "本文介绍了用于训练科学机器学习（SciML）模型的优化方法，并强调了问题结构如何影响算法选择。", "motivation": "动机在于解决传统随机方法在处理由物理约束或算子约束引起的全局耦合、刚性以及强各向异性时效果不佳的问题，探讨确定性和曲率感知的方法。", "method": "本文综述了一阶和二阶优化技术，在确定性和随机设置下讨论了这些技术如何适应具有物理约束的SciML模型，并通过实例展示了实际策略。", "result": "结果是提供了关于机器学习（ML）和科学机器学习（SciML）中优化方法的统一介绍，突出了问题结构对算法选择的影响。", "conclusion": "结论强调了在科学计算和科学机器学习接口处存在开放的研究方向，并且展示了如何通过实际例子来适应不同的科学机器学习模型。"}}
{"id": "2601.10215", "pdf": "https://arxiv.org/pdf/2601.10215", "abs": "https://arxiv.org/abs/2601.10215", "authors": ["Alex Dantart", "Marco Kóvacs-Navarro"], "title": "Topo-RAG: Topology-aware retrieval for hybrid text-table documents", "categories": ["cs.AI"], "comment": null, "summary": "In enterprise datasets, documents are rarely pure. They are not just text, nor just numbers; they are a complex amalgam of narrative and structure. Current Retrieval-Augmented Generation (RAG) systems have attempted to address this complexity with a blunt tool: linearization. We convert rich, multidimensional tables into simple Markdown-style text strings, hoping that an embedding model will capture the geometry of a spreadsheet in a single vector. But it has already been shown that this is mathematically insufficient. This work presents Topo-RAG, a framework that challenges the assumption that \"everything is text\". We propose a dual architecture that respects the topology of the data: we route fluid narrative through traditional dense retrievers, while tabular structures are processed by a Cell-Aware Late Interaction mechanism, preserving their spatial relationships. Evaluated on SEC-25, a synthetic enterprise corpus that mimics real-world complexity, Topo-RAG demonstrates an 18.4% improvement in nDCG@10 on hybrid queries compared to standard linearization approaches. It's not just about searching better; it's about understanding the shape of information.", "AI": {"tldr": "提出Topo-RAG框架，用于处理混合文本和表格的文档检索问题。", "motivation": "现有的Retrieval-Augmented Generation系统将复杂的数据线性化为简单的文本字符串，忽略了数据的空间关系，这种方法在数学上是不足的。", "method": "采用双重架构，分别处理流动叙述和表结构，其中流动叙述通过传统的密集检索器进行路由，而表格结构则由Cell-Aware Late Interaction机制处理，保留其空间关系。", "result": "在SEC-25合成企业语料库上的评估显示，与标准线性化方法相比，Topo-RAG在混合查询中的nDCG@10提高了18.4%。", "conclusion": "通过理解信息的形状，而不是简单地改善搜索效率，可以更有效地处理复杂的企业数据集。"}}
{"id": "2601.10214", "pdf": "https://arxiv.org/pdf/2601.10214", "abs": "https://arxiv.org/abs/2601.10214", "authors": ["Dong-Yu Chen", "Yixin Guo", "Shuojin Yang", "Tai-Jiang Mu", "Shi-Min Hu"], "title": "Beyond Inpainting: Unleash 3D Understanding for Precise Camera-Controlled Video Generation", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "Camera control has been extensively studied in conditioned video generation; however, performing precisely altering the camera trajectories while faithfully preserving the video content remains a challenging task. The mainstream approach to achieving precise camera control is warping a 3D representation according to the target trajectory. However, such methods fail to fully leverage the 3D priors of video diffusion models (VDMs) and often fall into the Inpainting Trap, resulting in subject inconsistency and degraded generation quality. To address this problem, we propose DepthDirector, a video re-rendering framework with precise camera controllability. By leveraging the depth video from explicit 3D representation as camera-control guidance, our method can faithfully reproduce the dynamic scene of an input video under novel camera trajectories. Specifically, we design a View-Content Dual-Stream Condition mechanism that injects both the source video and the warped depth sequence rendered under the target viewpoint into the pretrained video generation model. This geometric guidance signal enables VDMs to comprehend camera movements and leverage their 3D understanding capabilities, thereby facilitating precise camera control and consistent content generation. Next, we introduce a lightweight LoRA-based video diffusion adapter to train our framework, fully preserving the knowledge priors of VDMs. Additionally, we construct a large-scale multi-camera synchronized dataset named MultiCam-WarpData using Unreal Engine 5, containing 8K videos across 1K dynamic scenes. Extensive experiments show that DepthDirector outperforms existing methods in both camera controllability and visual quality. Our code and dataset will be publicly available.", "AI": {"tldr": "提出DepthDirector，一种精确相机控制的视频重渲染框架。", "motivation": "现有的方法在精准改变摄像机轨迹的同时保持视频内容的真实性和一致性方面存在困难。", "method": "通过利用来自显式3D表示的深度视频作为相机控制指导，并设计视图-内容双流条件机制，将源视频和根据目标视角渲染的深度序列注入预训练视频生成模型中。同时引入轻量级LoRA基的视频扩散适配器进行框架训练。", "result": "实验表明，DepthDirector在摄像机可控性和视觉质量上均超越现有方法。", "conclusion": "DepthDirector通过利用3D理解能力实现了精确的相机控制和一致的内容生成。"}}
{"id": "2601.10212", "pdf": "https://arxiv.org/pdf/2601.10212", "abs": "https://arxiv.org/abs/2601.10212", "authors": ["Chaochao Chen", "Jiaming Qian", "Fei Zheng", "Yachuan Liu"], "title": "PADER: Paillier-based Secure Decentralized Social Recommendation", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The prevalence of recommendation systems also brings privacy concerns to both the users and the sellers, as centralized platforms collect as much data as possible from them. To keep the data private, we propose PADER: a Paillier-based secure decentralized social recommendation system. In this system, the users and the sellers are nodes in a decentralized network. The training and inference of the recommendation model are carried out securely in a decentralized manner, without the involvement of a centralized platform. To this end, we apply the Paillier cryptosystem to the SoReg (Social Regularization) model, which exploits both user's ratings and social relations. We view the SoReg model as a two-party secure polynomial evaluation problem and observe that the simple bipartite computation may result in poor efficiency. To improve efficiency, we design secure addition and multiplication protocols to support secure computation on any arithmetic circuit, along with an optimal data packing scheme that is suitable for the polynomial computations of real values. Experiment results show that our method only takes about one second to iterate through one user with hundreds of ratings, and training with ~500K ratings for one epoch only takes <3 hours, which shows that the method is practical in real applications. The code is available at https://github.com/GarminQ/PADER.", "AI": {"tldr": "本文提出了一种基于Paillier加密系统的安全分散式社交推荐系统PADER，旨在保护用户和卖家的数据隐私。", "motivation": "随着推荐系统的普及，数据的中央化收集引起了用户的隐私担忧。为了保持数据私密性，本文提出了PADER系统来解决这一问题。", "method": "PADER将SoReg模型视为一个两方安全多项式评估问题，并设计了安全加法和乘法协议以支持任何算术电路的安全计算。此外，还引入了一种适合于实值多项式计算的最佳数据打包方案。", "result": "实验表明，该方法只需约1秒即可迭代处理具有数百个评分的用户，并且使用约50万条评分为一个周期的训练仅需不到3小时，显示了其在实际应用中的实用性。", "conclusion": "PADER系统实现了高效的安全分散式推荐模型的训练和推理，证明了其实用性并保护了用户的隐私数据。"}}
{"id": "2601.10208", "pdf": "https://arxiv.org/pdf/2601.10208", "abs": "https://arxiv.org/abs/2601.10208", "authors": ["Shuangshan Nors Li", "J. Nathan Kutz"], "title": "Terrain-Adaptive Mobile 3D Printing with Hierarchical Control", "categories": ["cs.RO"], "comment": "Submitted to the 43rd International Symposium on Automation and Robotics in Construction (ISARC 2026)", "summary": "Mobile 3D printing on unstructured terrain remains challenging due to the conflict between platform mobility and deposition precision. Existing gantry-based systems achieve high accuracy but lack mobility, while mobile platforms struggle to maintain print quality on uneven ground. We present a framework that tightly integrates AI-driven disturbance prediction with multi-modal sensor fusion and hierarchical hardware control, forming a closed-loop perception-learning-actuation system. The AI module learns terrain-to-perturbation mappings from IMU, vision, and depth sensors, enabling proactive compensation rather than reactive correction. This intelligence is embedded into a three-layer control architecture: path planning, predictive chassis-manipulator coordination, and precision hardware execution. Through outdoor experiments on terrain with slopes and surface irregularities, we demonstrate sub-centimeter printing accuracy while maintaining full platform mobility. This AI-hardware integration establishes a practical foundation for autonomous construction in unstructured environments.", "AI": {"tldr": "本文提出了一种结合AI驱动的干扰预测与多模态传感器融合及分层硬件控制框架，实现地形适应性移动3D打印。", "motivation": "现有的龙门式系统虽然精度高但缺乏机动性，而移动平台在不平整地面上难以保持打印质量。因此，需要一种能够在复杂地形中维持高精度打印且具备高度机动性的解决方案。", "method": "通过AI模块从IMU、视觉和深度传感器学习地形与干扰之间的映射关系，实现主动补偿，并嵌入到路径规划、预测底盘-操作臂协调和精确硬件执行的三层控制架构中。", "result": "在户外实验中，在具有坡度和表面不规则性的地形上实现了亚厘米级打印精度，同时保持了平台的完全机动性。", "conclusion": "这种AI与硬件集成的方法为非结构化环境下的自主建设奠定了实用基础。"}}
{"id": "2601.10205", "pdf": "https://arxiv.org/pdf/2601.10205", "abs": "https://arxiv.org/abs/2601.10205", "authors": ["Arya Shah", "Himanshu beniwal", "Mayank Singh"], "title": "One Instruction Does Not Fit All: How Well Do Embeddings Align Personas and Instructions in Low-Resource Indian Languages?", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 4 figures, 10 tables", "summary": "Aligning multilingual assistants with culturally grounded user preferences is essential for serving India's linguistically diverse population of over one billion speakers across multiple scripts. However, existing benchmarks either focus on a single language or conflate retrieval with generation, leaving open the question of whether current embedding models can encode persona-instruction compatibility without relying on response synthesis. We present a unified benchmark spanning 12 Indian languages and four evaluation tasks: monolingual and cross-lingual persona-to-instruction retrieval, reverse retrieval from instruction to persona, and binary compatibility classification. Eight multilingual embedding models are evaluated in a frozen-encoder setting with a thin logistic regression head for classification. E5-Large-Instruct achieves the highest Recall@1 of 27.4\\% on monolingual retrieval and 20.7\\% on cross-lingual transfer, while BGE-M3 leads reverse retrieval at 32.1\\% Recall@1. For classification, LaBSE attains 75.3\\% AUROC with strong calibration. These findings offer practical guidance for model selection in Indic multilingual retrieval and establish reproducible baselines for future work\\footnote{Code, datasets, and models are publicly available at https://github.com/aryashah2k/PI-Indic-Align.", "AI": {"tldr": "本文研究了多语言嵌入模型在印度十二种低资源语言中的人格和指令对齐情况。", "motivation": "动机在于解决现有的基准测试要么只关注单个语言，要么混淆检索与生成的问题，探讨当前的嵌入模型是否能够在不依赖响应合成的情况下编码人格与指令的兼容性。", "method": "本文构建了一个统一的跨12种印度语言和涵盖四项评估任务（包括单语和跨语言的人格到指令检索、从指令到人格的逆向检索以及二元兼容性分类）的基准测试，对八个多语言嵌入模型进行了冻结编码器设置下的薄逻辑回归头部分类评估。", "result": "E5-Large-Instruct在单语检索中获得了27.4%最高的Recall@1，在跨语言传输中为20.7%，而BGE-M3在逆向检索中达到了32.1%的Recall@1。对于分类，LaBSE实现了75.3%的AUROC，并且校准效果良好。", "conclusion": "研究结果为印度多语言检索中的模型选择提供了实用指导，并为未来工作建立了可重复的基线。"}}
{"id": "2601.10201", "pdf": "https://arxiv.org/pdf/2601.10201", "abs": "https://arxiv.org/abs/2601.10201", "authors": ["Jiarui Yao", "Ruida Wang", "Tong Zhang"], "title": "PRL: Process Reward Learning Improves LLMs' Reasoning Ability and Broadens the Reasoning Boundary", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Improving the reasoning abilities of Large Language Models (LLMs) has been a continuous topic recently. But most relevant works are based on outcome rewards at the trajectory level, missing fine-grained supervision during the reasoning process. Other existing training frameworks that try to combine process signals together to optimize LLMs also rely heavily on tedious additional steps like MCTS, training a separate reward model, etc., doing harm to the training efficiency. Moreover, the intuition behind the process signals design lacks rigorous theoretical support, leaving the understanding of the optimization mechanism opaque. In this paper, we propose Process Reward Learning (PRL), which decomposes the entropy regularized reinforcement learning objective into intermediate steps, with rigorous process rewards that could be assigned to models accordingly. Starting from theoretical motivation, we derive the formulation of PRL that is essentially equivalent to the objective of reward maximization plus a KL-divergence penalty term between the policy model and a reference model. However, PRL could turn the outcome reward into process supervision signals, which helps better guide the exploration during RL optimization. From our experiment results, we demonstrate that PRL not only improves the average performance for LLMs' reasoning ability measured by average @ n, but also broadens the reasoning boundary by improving the pass @ n metric. Extensive experiments show the effectiveness of PRL could be verified and generalized.", "AI": {"tldr": "本文提出了一种名为过程奖励学习（PRL）的方法，旨在改善大型语言模型的推理能力并扩展其推理边界。", "motivation": "现有的工作主要基于轨迹层面的结果奖励，忽略了在推理过程中提供细粒度监督的重要性，并且需要额外繁琐的步骤如MCTS和训练单独的奖励模型，这损害了训练效率。此外，过程信号设计背后的直觉缺乏严格的理论支持。", "method": "PRL将熵正则化强化学习目标分解为中间步骤，并分配相应的严格过程奖励。其公式本质上等同于奖励最大化的目标加上策略模型与参考模型之间的KL散度惩罚项。", "result": "实验结果显示，PRL不仅提高了大型语言模型的推理能力（以平均@n衡量），还通过提高pass@n指标扩展了推理边界。广泛实验验证并证明了PRL的有效性。", "conclusion": "本文提出的PRL方法在理论和实践上都展示了其对改善大型语言模型推理能力和效率的价值，并且具有良好的泛化能力。"}}
{"id": "2601.10200", "pdf": "https://arxiv.org/pdf/2601.10200", "abs": "https://arxiv.org/abs/2601.10200", "authors": ["Kim Youwang", "Lee Hyoseok", "Subin Park", "Gerard Pons-Moll", "Tae-Hyun Oh"], "title": "ELITE: Efficient Gaussian Head Avatar from a Monocular Video via Learned Initialization and TEst-time Generative Adaptation", "categories": ["cs.CV"], "comment": "Project page: https://kim-youwang.github.io/elite", "summary": "We introduce ELITE, an Efficient Gaussian head avatar synthesis from a monocular video via Learned Initialization and TEst-time generative adaptation. Prior works rely either on a 3D data prior or a 2D generative prior to compensate for missing visual cues in monocular videos. However, 3D data prior methods often struggle to generalize in-the-wild, while 2D generative prior methods are computationally heavy and prone to identity hallucination. We identify a complementary synergy between these two priors and design an efficient system that achieves high-fidelity animatable avatar synthesis with strong in-the-wild generalization. Specifically, we introduce a feed-forward Mesh2Gaussian Prior Model (MGPM) that enables fast initialization of a Gaussian avatar. To further bridge the domain gap at test time, we design a test-time generative adaptation stage, leveraging both real and synthetic images as supervision. Unlike previous full diffusion denoising strategies that are slow and hallucination-prone, we propose a rendering-guided single-step diffusion enhancer that restores missing visual details, grounded on Gaussian avatar renderings. Our experiments demonstrate that ELITE produces visually superior avatars to prior works, even for challenging expressions, while achieving 60x faster synthesis than the 2D generative prior method.", "AI": {"tldr": "本文介绍了ELITE，一种通过学习初始化和测试时间生成适应从单目视频中高效合成高斯头像的方法。", "motivation": "先前的工作依赖于三维数据先验或二维生成先验来弥补单目视频中的缺失视觉线索。然而，这些方法要么难以在现实场景中泛化，要么计算成本高昂并容易产生身份幻觉。本文旨在通过结合两种先验的优势来设计一个高效的系统，以实现高保真且可动画化的头像合成，并具有强大的泛化能力。", "method": "本文提出了一个前馈Mesh2Gaussian Prior Model（MGPM）用于快速初始化高斯头像。为了解决测试时的领域差异问题，设计了一个基于真实和合成图像监督的测试时间生成适应阶段。不同于之前的全扩散去噪策略慢且容易产生幻觉的问题，提出了一种基于渲染引导的单步扩散增强器来恢复丢失的视觉细节。", "result": "实验表明，即使面对具有挑战性的表情，ELITE也能产生比先前工作更优质的头像，并且合成速度比2D生成先验方法快60倍。", "conclusion": "本文提出的方法通过结合3D数据先验和2D生成先验的优势，实现了高保真、快速的动画头像合成技术，在泛化能力和视觉质量上都优于现有方法。"}}
{"id": "2601.10193", "pdf": "https://arxiv.org/pdf/2601.10193", "abs": "https://arxiv.org/abs/2601.10193", "authors": ["Jiujiu Chen", "Weijun Zeng", "Shaofeng Hu", "Sihong Xie", "Hui Xiong"], "title": "GFM4GA: Graph Foundation Model for Group Anomaly Detection", "categories": ["cs.AI"], "comment": null, "summary": "Group anomaly detection is crucial in many network applications, but faces challenges due to diverse anomaly patterns. Motivated by the success of large language models (LLMs) in natural language processing, graph foundation models (GFMs) is proposed to handle few-shot learning task with fewer labeling efforts. GFMs have been successfully applied to detection of individual anomalies but cannot be generalized to group anomalies, as group anomaly patterns must be detected as a whole and individuals in an abnormal group can look rather normal. Therefore, we propose GFM4GA, a novel graph foundation model for group anomaly detection. The pipeline is pretrained via dual-level contrastive learning based on feature-based estimation and group extraction, to capture potential group anomaly structure and feature inconsistencies. In the downstream tasks, the pipeline is finetuned in parameter-constrained and group-anomaly-proportion weighted few-shot settings, and its adaptive ability to unseen group anomalies expanded via group contexts determined by labeled anomaly neighbors. Experiments show that GFM4GA surpasses group anomaly detectors and GFMs for individual anomalies, achieving average improvements of 2.85% in AUROC and 2.55% in AUPRC.", "AI": {"tldr": "本文提出了GFM4GA，一种用于组异常检测的图基础模型。", "motivation": "受到大型语言模型在自然语言处理中的成功启发，作者提出了一种新的方法来解决少样本学习任务，并减少标注工作量。现有的GFMs可以处理个体异常检测，但无法推广到组异常检测，因为组异常模式需要整体识别，且组内个体可能看似正常。", "method": "GFM4GA通过基于特征估计和组提取的双层对比学习进行预训练，以捕捉潜在的组异常结构和特征不一致性。在下游任务中，该模型采用参数约束和组异常比例加权的少样本设置进行微调，并通过标注异常邻居确定的组上下文来扩展对未见过的组异常的适应能力。", "result": "实验结果显示GFM4GA超越了现有的组异常检测器和用于个体异常检测的GFMs，实现了AUROC平均提升了2.85%，AUPRC平均提升了2.55%的成绩。", "conclusion": "GFM4GA在少样本学习场景下展示了其在组异常检测中的优越性能，并且比现有方法有了显著改进。"}}
{"id": "2601.10192", "pdf": "https://arxiv.org/pdf/2601.10192", "abs": "https://arxiv.org/abs/2601.10192", "authors": ["Hu Gao", "Xiaoning Lei", "Xichen Xu", "Xingjian Wang", "Lizhuang Ma"], "title": "From Physical Degradation Models to Task-Aware All-in-One Image Restoration", "categories": ["cs.CV"], "comment": null, "summary": "All-in-one image restoration aims to adaptively handle multiple restoration tasks with a single trained model. Although existing methods achieve promising results by introducing prompt information or leveraging large models, the added learning modules increase system complexity and hinder real-time applicability. In this paper, we adopt a physical degradation modeling perspective and predict a task-aware inverse degradation operator for efficient all-in-one image restoration. The framework consists of two stages. In the first stage, the predicted inverse operator produces an initial restored image together with an uncertainty perception map that highlights regions difficult to reconstruct, ensuring restoration reliability. In the second stage, the restoration is further refined under the guidance of this uncertainty map. The same inverse operator prediction network is used in both stages, with task-aware parameters introduced after operator prediction to adapt to different degradation tasks. Moreover, by accelerating the convolution of the inverse operator, the proposed method achieves efficient all-in-one image restoration. The resulting tightly integrated architecture, termed OPIR, is extensively validated through experiments, demonstrating superior all-in-one restoration performance while remaining highly competitive on task-aligned restoration.", "AI": {"tldr": "本文提出了一种基于物理退化模型的高效全合一图像恢复方法OPIR，旨在通过单一训练模型处理多种恢复任务。", "motivation": "现有的全合一图像恢复方法虽然通过引入提示信息或依赖大规模模型取得了良好的结果，但增加了系统复杂性并影响了实时应用能力。", "method": "该框架包括两个阶段：第一阶段预测逆退化操作器生成初始恢复图像及不确定性感知图；第二阶段在不确定性的指导下进一步精炼恢复结果。通过加速逆操作的卷积实现高效全合一图像恢复。", "result": "实验表明，所提方法OPIR在全合一图像恢复性能上表现出色，同时在特定任务对齐的恢复中保持竞争力。", "conclusion": "基于物理退化模型预测的任务感知逆退化操作器可以在不增加复杂性的情况下实现高效的全合一图像恢复。"}}
{"id": "2601.10191", "pdf": "https://arxiv.org/pdf/2601.10191", "abs": "https://arxiv.org/abs/2601.10191", "authors": ["Mathieu Cherpitel", "Janne Luijten", "Thomas Bäck", "Camiel Verhamme", "Martijn Tannemaat", "Anna Kononova"], "title": "How does downsampling affect needle electromyography signals? A generalisable workflow for understanding downsampling effects on high-frequency time series", "categories": ["cs.AI"], "comment": null, "summary": "Automated analysis of needle electromyography (nEMG) signals is emerging as a tool to support the detection of neuromuscular diseases (NMDs), yet the signals' high and heterogeneous sampling rates pose substantial computational challenges for feature-based machine-learning models, particularly for near real-time analysis. Downsampling offers a potential solution, but its impact on diagnostic signal content and classification performance remains insufficiently understood. This study presents a workflow for systematically evaluating information loss caused by downsampling in high-frequency time series. The workflow combines shape-based distortion metrics with classification outcomes from available feature-based machine learning models and feature space analysis to quantify how different downsampling algorithms and factors affect both waveform integrity and predictive performance. We use a three-class NMD classification task to experimentally evaluate the workflow. We demonstrate how the workflow identifies downsampling configurations that preserve diagnostic information while substantially reducing computational load. Analysis of shape-based distortion metrics showed that shape-aware downsampling algorithms outperform standard decimation, as they better preserve peak structure and overall signal morphology. The results provide practical guidance for selecting downsampling configurations that enable near real-time nEMG analysis and highlight a generalisable workflow that can be used to balance data reduction with model performance in other high-frequency time-series applications as well.", "AI": {"tldr": "研究了降采样对针电图信号的影响，并提出了一种系统评估信息损失的工作流。", "motivation": "高频率的针电图信号计算量大，影响实时分析。需要理解不同降采样方法对诊断内容和分类性能的影响。", "method": "结合形状失真指标、机器学习模型的分类结果以及特征空间分析来系统评估信息损失，并使用三类神经肌肉疾病分类任务实验验证该工作流。", "result": "研究表明，基于形状的降采样算法优于标准衰减方法，在大幅减少计算负担的同时保留诊断信息。", "conclusion": "提供了选择降采样配置以实现近实时分析的实际指导，且这种通用工作流可用于其他高频率时间序列的应用。"}}
{"id": "2601.10187", "pdf": "https://arxiv.org/pdf/2601.10187", "abs": "https://arxiv.org/abs/2601.10187", "authors": ["Ziang Cui", "Mengran Yu", "Tianjiao Li", "Chenyu Shi", "Yingxuan Shi", "Lusheng Zhang", "Hongwei Lin"], "title": "HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable strides in multilingual translation but are hindered by a systemic cross-lingual verbosity bias, rendering them unsuitable for strict time-constrained tasks like subtitling and dubbing. Current prompt-engineering approaches struggle to resolve this conflict between semantic fidelity and rigid temporal feasibility. To bridge this gap, we first introduce Sand-Glass, a benchmark specifically designed to evaluate translation under syllable-level duration constraints. Furthermore, we propose HOMURA, a reinforcement learning framework that explicitly optimizes the trade-off between semantic preservation and temporal compliance. By employing a KL-regularized objective with a novel dynamic syllable-ratio reward, HOMURA effectively \"tames\" the output length. Experimental results demonstrate that our method significantly outperforms strong LLM baselines, achieving precise length control that respects linguistic density hierarchies without compromising semantic adequacy.", "AI": {"tldr": "本文提出了HOMURA框架，通过强化学习优化大规模语言模型在时间约束下的多语种翻译任务。", "motivation": "解决大型语言模型在字幕和配音等严格时间限制的多语言翻译中存在的时间长度控制问题。", "method": "引入Sand-Glass基准测试多语言翻译下的音节数量级时间限制，并使用KL正则化目标与动态音节比例奖励来优化语义保持与时间合规之间的平衡。", "result": "实验表明，HOMURA框架在严格的时间约束下实现了精确的长度控制，同时保持了语义准确性，优于强大的语言模型基线。", "conclusion": "通过强化学习和专门设计的基准测试，成功解决了大型语言模型在多语言翻译中面对时间限制的问题，并取得了显著效果。"}}
{"id": "2601.10173", "pdf": "https://arxiv.org/pdf/2601.10173", "abs": "https://arxiv.org/abs/2601.10173", "authors": ["Hao Li", "Yankai Yang", "G. Edward Suh", "Ning Zhang", "Chaowei Xiao"], "title": "ReasAlign: Reasoning Enhanced Safety Alignment against Prompt Injection Attack", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": "15 pages, 10 figures", "summary": "Large Language Models (LLMs) have enabled the development of powerful agentic systems capable of automating complex workflows across various fields. However, these systems are highly vulnerable to indirect prompt injection attacks, where malicious instructions embedded in external data can hijack agent behavior. In this work, we present ReasAlign, a model-level solution to improve safety alignment against indirect prompt injection attacks. The core idea of ReasAlign is to incorporate structured reasoning steps to analyze user queries, detect conflicting instructions, and preserve the continuity of the user's intended tasks to defend against indirect injection attacks. To further ensure reasoning logic and accuracy, we introduce a test-time scaling mechanism with a preference-optimized judge model that scores reasoning steps and selects the best trajectory. Comprehensive evaluations across various benchmarks show that ReasAlign maintains utility comparable to an undefended model while consistently outperforming Meta SecAlign, the strongest prior guardrail. On the representative open-ended CyberSecEval2 benchmark, which includes multiple prompt-injected tasks, ReasAlign achieves 94.6% utility and only 3.6% ASR, far surpassing the state-of-the-art defensive model of Meta SecAlign (56.4% utility and 74.4% ASR). These results demonstrate that ReasAlign achieves the best trade-off between security and utility, establishing a robust and practical defense against prompt injection attacks in real-world agentic systems. Our code and experimental results could be found at https://github.com/leolee99/ReasAlign.", "AI": {"tldr": "本文介绍了ReasAlign，一种通过结构化推理步骤分析用户查询并检测冲突指令来防御间接提示注入攻击的方法。", "motivation": "大型语言模型使得开发能够跨多个领域自动化复杂工作流程的强大代理系统成为可能。然而，这些系统容易受到嵌入外部数据中的恶意指令的间接提示注入攻击，导致行为被劫持。", "method": "ReasAlign通过加入结构化推理步骤来分析用户查询、检测冲突指令并维护用户的预期任务连续性以防御此类攻击。还引入了一个测试时缩放机制和一个优化偏好裁判模型，该模型用于评分推理步骤并选择最佳路径。", "result": "实验结果显示，相较于未受保护的模型和其他防御模型（如Meta SecAlign），ReasAlign在保持高实用性的同时显著降低了被间接注入提示攻击的风险。特别是在CyberSecEval2基准测试中，其实用率达到了94.6%，成功率仅为3.6%。", "conclusion": "通过实验证明，ReasAlign能够实现安全性和实用性的最佳平衡，并为现实世界代理系统提供了强大而实际的防御措施。"}}
{"id": "2601.10169", "pdf": "https://arxiv.org/pdf/2601.10169", "abs": "https://arxiv.org/abs/2601.10169", "authors": ["Boaz Carmeli", "Ron Meir", "Yonatan Belinkov"], "title": "CtD: Composition through Decomposition in Emergent Communication", "categories": ["cs.AI"], "comment": null, "summary": "Compositionality is a cognitive mechanism that allows humans to systematically combine known concepts in novel ways. This study demonstrates how artificial neural agents acquire and utilize compositional generalization to describe previously unseen images. Our method, termed \"Composition through Decomposition\", involves two sequential training steps. In the 'Decompose' step, the agents learn to decompose an image into basic concepts using a codebook acquired during interaction in a multi-target coordination game. Subsequently, in the 'Compose' step, the agents employ this codebook to describe novel images by composing basic concepts into complex phrases. Remarkably, we observe cases where generalization in the `Compose' step is achieved zero-shot, without the need for additional training.", "AI": {"tldr": "研究通过两个顺序训练步骤，展示了人工神经代理如何获得并利用组合泛化来描述先前未见过的图像。", "motivation": "旨在探索人工神经网络是否可以通过分解和重组基本概念来实现对新图像的有效描述，并观察这种能力是否能够在零样本情况下实现。", "method": "采用“通过分解进行组合”的方法，分为两个步骤：首先是将图像分解为基本概念的学习阶段；其次是使用这些基本概念来描述新的复杂图像的组合阶段。", "result": "研究发现，在重组阶段可以实现零样本泛化，即在没有额外训练的情况下，神经代理能够成功描述之前未见过的图像。", "conclusion": "人工神经网络能够通过学习分解和重组的基本概念来获得有效的组合泛化能力，并且这种能力能够在零样本情况下发挥作用。"}}
{"id": "2601.10168", "pdf": "https://arxiv.org/pdf/2601.10168", "abs": "https://arxiv.org/abs/2601.10168", "authors": ["Yue Chang", "Rufeng Chen", "Zhaofan Zhang", "Yi Chen", "Sihong Xie"], "title": "RAG-3DSG: Enhancing 3D Scene Graphs with Re-Shot Guided Retrieval-Augmented Generation", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "9 pages, 6 figures", "summary": "Open-vocabulary 3D Scene Graph (3DSG) generation can enhance various downstream tasks in robotics, such as manipulation and navigation, by leveraging structured semantic representations. A 3DSG is constructed from multiple images of a scene, where objects are represented as nodes and relationships as edges. However, existing works for open-vocabulary 3DSG generation suffer from both low object-level recognition accuracy and speed, mainly due to constrained viewpoints, occlusions, and redundant surface density. To address these challenges, we propose RAG-3DSG to mitigate aggregation noise through re-shot guided uncertainty estimation and support object-level Retrieval-Augmented Generation (RAG) via reliable low-uncertainty objects. Furthermore, we propose a dynamic downsample-mapping strategy to accelerate cross-image object aggregation with adaptive granularity. Experiments on Replica dataset demonstrate that RAG-3DSG significantly improves node captioning accuracy in 3DSG generation while reducing the mapping time by two-thirds compared to the vanilla version.", "AI": {"tldr": "本文提出RAG-3DSG方法，通过重新拍摄指导的不确定性估计和检索增强生成技术来提高开放词汇表3D场景图（3DSG）的生成质量和速度。", "motivation": "旨在解决现有开放词汇表3DSG生成中存在的物体识别精度低及速度慢的问题，这些问题主要是由于受限视角、遮挡以及冗余表面密度导致的。", "method": "提出RAG-3DSG方法，通过重新拍摄指导的不确定性估计来减少聚合噪声，并支持基于可靠低不确定性的对象检索增强生成技术；同时提出了动态下采样映射策略以加速跨图像的对象聚合并提高精度。", "result": "实验结果表明，在Replica数据集上，与原始版本相比，RAG-3DSG显著提高了节点标注准确率并减少了三分之二的映射时间。", "conclusion": "通过重新拍摄指导和动态下采样技术，RAG-3DSG有效提升了3D场景图生成的质量和速度，为机器人操纵和导航等下游任务提供了更好的支持。"}}
{"id": "2601.10165", "pdf": "https://arxiv.org/pdf/2601.10165", "abs": "https://arxiv.org/abs/2601.10165", "authors": ["Chao Huang", "Benfeng Wang", "Wei Wang", "Jie Wen", "Li Shen", "Wenqi Ren", "Yong Xu", "Xiaochun Cao"], "title": "Advancing Adaptive Multi-Stage Video Anomaly Reasoning: A Benchmark Dataset and Method", "categories": ["cs.CV"], "comment": null, "summary": "Recent progress in reasoning capabilities of Multimodal Large Language Models(MLLMs) has highlighted their potential for performing complex video understanding tasks. However, in the domain of Video Anomaly Detection and Understanding (VAD&U), existing MLLM-based methods are largely limited to anomaly localization or post-hoc description, lacking explicit reasoning processes, risk awareness, and decision-oriented interpretation. To address this gap, we define a new task termed Video Anomaly Reasoning (VAR), which elevates video anomaly analysis from descriptive understanding to structured, multi-stage reasoning. VAR explicitly requires models to perform progressive reasoning over anomalous events before answering anomaly-related questions, encompassing visual perception, causal interpretation, and risk-aware decision making. To support this task, we present a new dataset with 8,641 videos, where each video is annotated with diverse question types corresponding to different reasoning depths, totaling more than 50,000 samples, making it one of the largest datasets for video anomaly. The annotations are based on a structured Perception-Cognition-Action Chain-of-Thought (PerCoAct-CoT), which formalizes domain-specific reasoning priors for video anomaly understanding. This design enables systematic evaluation of multi-stage and adaptive anomaly reasoning. In addition, we propose Anomaly-Aware Group Relative Policy Optimization to further enhance reasoning reliability under weak supervision. Building upon the proposed task and dataset, we develop an end-to-end MLLM-based VAR model termed Vad-R1-Plus, which supports adaptive hierarchical reasoning and risk-aware decision making. Extensive experiments demonstrate that the proposed benchmark and method effectively advance the reasoning capabilities of MLLMs on VAR tasks, outperforming both open-source and proprietary baselines.", "AI": {"tldr": "本文提出了视频异常推理任务（VAR），并开发了一个大型数据集和一个基于MLLM的端到端模型Vad-R1-Plus，以增强多阶段适应性异常推理能力。", "motivation": "现有的多模态大语言模型在视频异常检测与理解领域主要局限于异常定位或事后描述，缺乏明确的推理过程、风险意识和决策导向解释。因此，提出新的任务VAR来提升这些方面的能力。", "method": "为支持VAR任务，构建了一个包含8,641个视频的新数据集，并提出了Anomaly-Aware Group Relative Policy Optimization方法以增强弱监督下的推理可靠性。", "result": "实验表明所提出的基准和方法有效提升了MLLM在VAR任务上的推理能力，超过了开源和专有的基线模型。", "conclusion": "通过定义新的VAR任务、创建大规模数据集及开发适应性多阶段推理的Vad-R1-Plus模型，本文推动了视频异常理解领域的研究进展。"}}
{"id": "2601.10161", "pdf": "https://arxiv.org/pdf/2601.10161", "abs": "https://arxiv.org/abs/2601.10161", "authors": ["Prachuryya Kaushik", "Ashish Anand"], "title": "AWED-FiNER: Agents, Web applications, and Expert Detectors for Fine-grained Named Entity Recognition across 36 Languages for 6.6 Billion Speakers", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Submitted to ACL'26 System Demonstration", "summary": "We introduce AWED-FiNER, an open-source ecosystem designed to bridge the gap in Fine-grained Named Entity Recognition (FgNER) for 36 global languages spoken by more than 6.6 billion people. While Large Language Models (LLMs) dominate general Natural Language Processing (NLP) tasks, they often struggle with low-resource languages and fine-grained NLP tasks. AWED-FiNER provides a collection of agentic toolkits, web applications, and several state-of-the-art expert models that provides FgNER solutions across 36 languages. The agentic tools enable to route multilingual text to specialized expert models and fetch FgNER annotations within seconds. The web-based platforms provide ready-to-use FgNER annotation service for non-technical users. Moreover, the collection of language specific extremely small sized open-source state-of-the-art expert models facilitate offline deployment in resource contraint scenerios including edge devices. AWED-FiNER covers languages spoken by over 6.6 billion people, including a specific focus on vulnerable languages such as Bodo, Manipuri, Bishnupriya, and Mizo. The resources can be accessed here: Agentic Tool (https://github.com/PrachuryyaKaushik/AWED-FiNER), Web Application (https://hf.co/spaces/prachuryyaIITG/AWED-FiNER), and 49 Expert Detector Models (https://hf.co/collections/prachuryyaIITG/awed-finer).", "AI": {"tldr": "介绍AWED-FiNER，一个开源生态系统，旨在解决36种全球语言的细粒度命名实体识别问题。", "motivation": "尽管大型语言模型主导了通用自然语言处理任务，但它们在低资源语言和细粒度NLP任务上表现不佳。AWED-FiNER致力于为更多语言提供细粒度命名实体识别解决方案。", "method": "通过集合代理工具包、网络应用及多个最先进的专家模型，AWED-FiNER能够路由多语种文本至专有模型，并实现快速获取FgNER注释，同时支持离线部署。", "result": "该系统覆盖了全球超过66亿人的语言需求，包括对如Bodo等脆弱语言的特别关注。", "conclusion": "AWED-FiNER提供了一个全面且易于使用的细粒度命名实体识别解决方案，旨在满足多语种用户的需求。"}}
{"id": "2601.10160", "pdf": "https://arxiv.org/pdf/2601.10160", "abs": "https://arxiv.org/abs/2601.10160", "authors": ["Cameron Tice", "Puria Radmard", "Samuel Ratnam", "Andy Kim", "David Africa", "Kyle O'Brien"], "title": "Alignment Pretraining: AI Discourse Causes Self-Fulfilling (Mis)alignment", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Pretraining corpora contain extensive discourse about AI systems, yet the causal influence of this discourse on downstream alignment remains poorly understood. If prevailing descriptions of AI behaviour are predominantly negative, LLMs may internalise corresponding behavioural priors, giving rise to self-fulfilling misalignment. This paper provides the first controlled study of this hypothesis by pretraining 6.9B-parameter LLMs with varying amounts of (mis)alignment discourse. We find that discussion of AI contributes to misalignment. Upsampling synthetic training documents about AI misalignment leads to a notable increase in misaligned behaviour. Conversely, upsampling documents about aligned behaviour reduces misalignment scores from 45% to 9%. We consider this evidence of self-fulfilling alignment. These effects are dampened, but persist through post-training. Our findings establish the study of how pretraining data shapes alignment priors, or alignment pretraining, as a complement to post-training. We recommend practitioners pretrain for alignment as well as capabilities. Our models and datasets are available at alignmentpretraining.ai", "AI": {"tldr": "该论文研究了预训练语料库中关于AI系统的讨论如何影响模型的对齐情况。", "motivation": "探讨预训练过程中有关AI行为描述的话语是否会导致自我实现的(不)对齐现象。", "method": "通过使用不同比例的关于AI（不）对齐的合成训练文档进行69亿参数大型语言模型的预训练，来研究其影响。", "result": "发现增加关于AI不正确的行为讨论会显著提升模型的不正确行为倾向。相反，增加正确的行为描述可以将不正确评分从45%降低到9%。", "conclusion": "该研究表明，对齐预训练对于塑造对齐优先级是必要的，并建议实践者在增强模型能力的同时也要进行对齐预训练。"}}
{"id": "2601.10157", "pdf": "https://arxiv.org/pdf/2601.10157", "abs": "https://arxiv.org/abs/2601.10157", "authors": ["Yusong Wang", "Jialun Shen", "Zhihao Wu", "Yicheng Xu", "Shiyin Tan", "Mingkun Xu", "Changshuo Wang", "Zixing Song", "Prayag Tiwari"], "title": "MMPG: MoE-based Adaptive Multi-Perspective Graph Fusion for Protein Representation Learning", "categories": ["cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have been widely adopted for Protein Representation Learning (PRL), as residue interaction networks can be naturally represented as graphs. Current GNN-based PRL methods typically rely on single-perspective graph construction strategies, which capture partial properties of residue interactions, resulting in incomplete protein representations. To address this limitation, we propose MMPG, a framework that constructs protein graphs from multiple perspectives and adaptively fuses them via Mixture of Experts (MoE) for PRL. MMPG constructs graphs from physical, chemical, and geometric perspectives to characterize different properties of residue interactions. To capture both perspective-specific features and their synergies, we develop an MoE module, which dynamically routes perspectives to specialized experts, where experts learn intrinsic features and cross-perspective interactions. We quantitatively verify that MoE automatically specializes experts in modeling distinct levels of interaction from individual representations, to pairwise inter-perspective synergies, and ultimately to a global consensus across all perspectives. Through integrating this multi-level information, MMPG produces superior protein representations and achieves advanced performance on four different downstream protein tasks.", "AI": {"tldr": "本文提出MMPG框架，通过多视角图融合方法改进蛋白质表示学习。", "motivation": "当前基于图神经网络的蛋白质表示学习通常依赖单一视角构建策略，导致蛋白质表征不完整。为解决这一问题，本文提出一种新的方法来综合多个视角的信息。", "method": "MMPG从物理、化学和几何三个不同角度构建蛋白质图，并利用混合专家模型（MoE）动态融合这些视角的特性及其协同作用。", "result": "通过实验验证，MoE能够自动将不同的交互层次进行建模并整合多层次信息，从而生成更优越的蛋白质表示，在四个下游任务上表现出色。", "conclusion": "MMPG框架通过多角度图融合和动态专家模型，有效提升了蛋白质表示学习的质量，并在多个任务中显示出优异性能。"}}
{"id": "2601.10155", "pdf": "https://arxiv.org/pdf/2601.10155", "abs": "https://arxiv.org/abs/2601.10155", "authors": ["Aryan Karmore"], "title": "LOOKAT: Lookup-Optimized Key-Attention for Memory-Efficient Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Compressing the KV cache is a required step to deploy large language models on edge devices. Current quantization methods compress storage but fail to reduce bandwidth as attention calculation requires dequantizing keys from INT4/INT8 to FP16 before use. We observe that attention scoring is mathematically equivalent to the inner product similarity search and we can apply some compression techniques from vector databases to compress KV-cache better. We propose LOOKAT, which applies product quantization and asymmetric distance computation, to transformer architecture by decomposing key vectors into subspaces, learning codebooks and computing attention tables via lookup tables. This transforms attention from memory-bound to compute-bound. LOOKAT achieves 64 $\\times$ compression at 95.7\\% output fidelity and 32 $\\times$ compression at 95.0\\% fidelity when tested on GPT-2. LOOKAT requires no architecture changes or training while maintaining rank correlation $ρ> 0.95$. Theoretical analysis confirms that rank correlation degrades as $O(d_k/mK)$, with guarantees validated across sequence lengths up to 1024 tokens.", "AI": {"tldr": "本文提出了LOOKAT方法，通过将注意力机制中的键向量分解为子空间并使用查找表计算注意力分数来压缩KV缓存。", "motivation": "动机是降低大语言模型在边缘设备上的部署成本，现有的量化方法可以压缩存储但无法减少带宽。", "method": "LOOKAT采用产品量化和非对称距离计算技术，将键向量分解为子空间，并通过学习编码簿和使用查找表来实现注意力分数的高效计算。", "result": "实验结果表明，LOOKAT在GPT-2上实现了64倍压缩，输出保真度达到95.7%，以及32倍压缩，保真度达95.0%。", "conclusion": "结论是LOOKAT方法能够将注意力机制从内存瓶颈转变为计算瓶颈，并且不需要改变架构或训练过程即可保持较高的排名相关性。"}}
{"id": "2601.10154", "pdf": "https://arxiv.org/pdf/2601.10154", "abs": "https://arxiv.org/abs/2601.10154", "authors": ["Leonard Nürnberg", "Dennis Bontempi", "Suraj Pai", "Curtis Lisle", "Steve Pieper", "Ron Kikinis", "Sil van de Leemput", "Rahul Soni", "Gowtham Murugesan", "Cosmin Ciausu", "Miriam Groeneveld", "Felix J. Dorfner", "Jue Jiang", "Aneesh Rangnekar", "Harini Veeraraghavan", "Joeran S. Bosma", "Keno Bressem", "Raymond Mak", "Andrey Fedorov", "Hugo JWL Aerts"], "title": "MHub.ai: A Simple, Standardized, and Reproducible Platform for AI Models in Medical Imaging", "categories": ["cs.AI", "cs.CV", "cs.ET", "cs.LG", "cs.SE"], "comment": "41 pages, 15 figures, 6 tables", "summary": "Artificial intelligence (AI) has the potential to transform medical imaging by automating image analysis and accelerating clinical research. However, research and clinical use are limited by the wide variety of AI implementations and architectures, inconsistent documentation, and reproducibility issues. Here, we introduce MHub.ai, an open-source, container-based platform that standardizes access to AI models with minimal configuration, promoting accessibility and reproducibility in medical imaging. MHub.ai packages models from peer-reviewed publications into standardized containers that support direct processing of DICOM and other formats, provide a unified application interface, and embed structured metadata. Each model is accompanied by publicly available reference data that can be used to confirm model operation. MHub.ai includes an initial set of state-of-the-art segmentation, prediction, and feature extraction models for different modalities. The modular framework enables adaptation of any model and supports community contributions. We demonstrate the utility of the platform in a clinical use case through comparative evaluation of lung segmentation models. To further strengthen transparency and reproducibility, we publicly release the generated segmentations and evaluation metrics and provide interactive dashboards that allow readers to inspect individual cases and reproduce or extend our analysis. By simplifying model use, MHub.ai enables side-by-side benchmarking with identical execution commands and standardized outputs, and lowers the barrier to clinical translation.", "AI": {"tldr": "本文介绍了MHub.ai，一个简化AI模型在医学影像中应用的开源平台。", "motivation": "由于AI实现和架构的多样性、文档不一致性和可重复性问题限制了医疗成像领域的研究与临床使用，作者设计了一个标准化、可重复使用的平台来解决这些问题。", "method": "MHub.ai是一个基于容器技术的开放源码平台，将来自同行评审文章中的模型打包为标准容器，并支持DICOM和其他格式的直接处理。该框架是模块化的，允许任何模型的调整和社区贡献。", "result": "作者通过比较评估肺部分割模型展示了平台在临床应用案例中的实用性，并公开发布了生成的分割结果、评估指标以及交互式仪表板以增强透明度和可重复性。", "conclusion": "MHub.ai简化了AI模型的应用，使得能够使用相同的执行命令进行并行基准测试，并通过标准化输出来降低向临床转化的门槛。"}}
{"id": "2601.10150", "pdf": "https://arxiv.org/pdf/2601.10150", "abs": "https://arxiv.org/abs/2601.10150", "authors": ["Qiang Yu", "Xinran Cheng", "Shiqiang Xu", "Chuanyi Liu"], "title": "Simple Network Graph Comparative Learning", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 5 figures", "summary": "The effectiveness of contrastive learning methods has been widely recognized in the field of graph learning, especially in contexts where graph data often lack labels or are difficult to label. However, the application of these methods to node classification tasks still faces a number of challenges. First, existing data enhancement techniques may lead to significant differences from the original view when generating new views, which may weaken the relevance of the view and affect the efficiency of model training. Second, the vast majority of existing graph comparison learning algorithms rely on the use of a large number of negative samples. To address the above challenges, this study proposes a novel node classification contrast learning method called Simple Network Graph Comparative Learning (SNGCL). Specifically, SNGCL employs a superimposed multilayer Laplace smoothing filter as a step in processing the data to obtain global and local feature smoothing matrices, respectively, which are thus passed into the target and online networks of the siamese network, and finally employs an improved triple recombination loss function to bring the intra-class distance closer and the inter-class distance farther. We have compared SNGCL with state-of-the-art models in node classification tasks, and the experimental results show that SNGCL is strongly competitive in most tasks.", "AI": {"tldr": "本文提出了一种名为SNGCL的新方法，用于图节点分类任务中的对比学习。", "motivation": "现有的数据增强技术可能导致生成的新视图与原始视图差异过大，削弱了视图的相关性并影响模型训练效率。此外，大多数现有图比较学习算法依赖大量负样本，本文旨在解决这些问题。", "method": "SNGCL使用叠加的多层拉普拉斯平滑滤波器来处理数据，以获得全局和平滑特征矩阵，并通过改进的三重组合损失函数使类内距离更近而类间距离更远。", "result": "实验结果显示，与现有最先进的模型相比，SNGCL在大多数节点分类任务中具有很强的竞争性。", "conclusion": "该研究提出的方法SNGCL能够有效提高图学习中节点分类的准确性和效率。"}}
{"id": "2601.10148", "pdf": "https://arxiv.org/pdf/2601.10148", "abs": "https://arxiv.org/abs/2601.10148", "authors": ["Xiaowei Lv", "Zhilin Zhang", "Yijun Li", "Yusen Huo", "Siyuan Ju", "Xuyan Li", "Chunxiang Hong", "Tianyu Wang", "Yongcai Wang", "Peng Sun", "Chuan Yu", "Jian Xu", "Bo Zheng"], "title": "DecisionLLM: Large Language Models for Long Sequence Decision Exploration", "categories": ["cs.AI"], "comment": null, "summary": "Long-sequence decision-making, which is usually addressed through reinforcement learning (RL), is a critical component for optimizing strategic operations in dynamic environments, such as real-time bidding in computational advertising. The Decision Transformer (DT) introduced a powerful paradigm by framing RL as an autoregressive sequence modeling problem. Concurrently, Large Language Models (LLMs) have demonstrated remarkable success in complex reasoning and planning tasks. This inspires us whether LLMs, which share the same Transformer foundation, but operate at a much larger scale, can unlock new levels of performance in long-horizon sequential decision-making problem. This work investigates the application of LLMs to offline decision making tasks. A fundamental challenge in this domain is the LLMs' inherent inability to interpret continuous values, as they lack a native understanding of numerical magnitude and order when values are represented as text strings. To address this, we propose treating trajectories as a distinct modality. By learning to align trajectory data with natural language task descriptions, our model can autoregressively predict future decisions within a cohesive framework we term DecisionLLM. We establish a set of scaling laws governing this paradigm, demonstrating that performance hinges on three factors: model scale, data volume, and data quality. In offline experimental benchmarks and bidding scenarios, DecisionLLM achieves strong performance. Specifically, DecisionLLM-3B outperforms the traditional Decision Transformer (DT) by 69.4 on Maze2D umaze-v1 and by 0.085 on AuctionNet. It extends the AIGB paradigm and points to promising directions for future exploration in online bidding.", "AI": {"tldr": "本论文探讨了大型语言模型（LLMs）在长序列决策问题中的应用，提出了一个名为DecisionLLM的框架。", "motivation": "本文受到Decision Transformer和大型语言模型成功的启发，旨在探索这些模型能否解锁在长时段顺序决策问题上的新性能水平。", "method": "通过将轨迹视为一种独立模式，并学习将其与自然语言任务描述对齐，使模型能在统一框架内预测未来的决策。提出了处理连续值的技术以克服LLMs理解数值大小和次序的障碍。", "result": "在离线实验基准测试中，DecisionLLM-3B在Maze2D umaze-v1和AuctionNet上分别优于传统的Decision Transformer（DT）69.4和0.085。", "conclusion": "该研究证明了大型语言模型在决策任务上的潜力，并为进一步探索在线竞标提供了方向。"}}
{"id": "2601.10143", "pdf": "https://arxiv.org/pdf/2601.10143", "abs": "https://arxiv.org/abs/2601.10143", "authors": ["Haochong Xia", "Yao Long Teng", "Regan Tan", "Molei Qin", "Xinrun Wang", "Bo An"], "title": "History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis", "categories": ["cs.AI", "q-fin.TR"], "comment": null, "summary": "In quantitative finance, the gap between training and real-world performance-driven by concept drift and distributional non-stationarity-remains a critical obstacle for building reliable data-driven systems. Models trained on static historical data often overfit, resulting in poor generalization in dynamic markets. The mantra \"History Is Not Enough\" underscores the need for adaptive data generation that learns to evolve with the market rather than relying solely on past observations. We present a drift-aware dataflow system that integrates machine learning-based adaptive control into the data curation process. The system couples a parameterized data manipulation module comprising single-stock transformations, multi-stock mix-ups, and curation operations, with an adaptive planner-scheduler that employs gradient-based bi-level optimization to control the system. This design unifies data augmentation, curriculum learning, and data workflow management under a single differentiable framework, enabling provenance-aware replay and continuous data quality monitoring. Extensive experiments on forecasting and reinforcement learning trading tasks demonstrate that our framework enhances model robustness and improves risk-adjusted returns. The system provides a generalizable approach to adaptive data management and learning-guided workflow automation for financial data.", "AI": {"tldr": "本文提出了一种适应性数据流系统，用于金融时间序列合成，以解决静态历史数据在动态市场中的过拟合问题。", "motivation": "鉴于量化金融市场中概念漂移和分布非平稳性导致的训练与实际性能差距问题，需要一种能够自适应生成并随市场变化而演化的数据处理方法。", "method": "该系统结合了基于机器学习的自适应控制机制，并采用了参数化数据操作模块以及梯度驱动的双层优化规划调度器来管理整个数据流程。", "result": "实验表明，通过这种方法能够增强模型在预测和强化学习交易任务中的鲁棒性并改善风险调整后的收益。", "conclusion": "该研究提出了一种可广泛应用于金融领域自适应数据管理和引导式工作流自动化的通用方法。"}}
{"id": "2601.10141", "pdf": "https://arxiv.org/pdf/2601.10141", "abs": "https://arxiv.org/abs/2601.10141", "authors": ["Jiawen Zhang", "Yangfan Hu", "Kejia Chen", "Lipeng He", "Jiachen Ma", "Jian Lou", "Dan Li", "Jian Liu", "Xiaohu Yang", "Ruoxi Jia"], "title": "Understanding and Preserving Safety in Fine-Tuned LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning is an essential and pervasive functionality for applying large language models (LLMs) to downstream tasks. However, it has the potential to substantially degrade safety alignment, e.g., by greatly increasing susceptibility to jailbreak attacks, even when the fine-tuning data is entirely harmless. Despite garnering growing attention in defense efforts during the fine-tuning stage, existing methods struggle with a persistent safety-utility dilemma: emphasizing safety compromises task performance, whereas prioritizing utility typically requires deep fine-tuning that inevitably leads to steep safety declination. In this work, we address this dilemma by shedding new light on the geometric interaction between safety- and utility-oriented gradients in safety-aligned LLMs. Through systematic empirical analysis, we uncover three key insights: (I) safety gradients lie in a low-rank subspace, while utility gradients span a broader high-dimensional space; (II) these subspaces are often negatively correlated, causing directional conflicts during fine-tuning; and (III) the dominant safety direction can be efficiently estimated from a single sample. Building upon these novel insights, we propose safety-preserving fine-tuning (SPF), a lightweight approach that explicitly removes gradient components conflicting with the low-rank safety subspace. Theoretically, we show that SPF guarantees utility convergence while bounding safety drift. Empirically, SPF consistently maintains downstream task performance and recovers nearly all pre-trained safety alignment, even under adversarial fine-tuning scenarios. Furthermore, SPF exhibits robust resistance to both deep fine-tuning and dynamic jailbreak attacks. Together, our findings provide new mechanistic understanding and practical guidance toward always-aligned LLM fine-tuning.", "AI": {"tldr": "本文提出了一种名为安全保持微调（SPF）的方法，旨在解决在大型语言模型微调过程中出现的安全性和任务性能之间的矛盾。", "motivation": "微调是将大型语言模型应用于下游任务的关键功能，但可能会显著降低安全性。现有方法难以同时保证安全性和实用性，本文试图通过研究安全和任务导向梯度的几何交互来缓解这一困境。", "method": "作者通过系统性经验分析发现了三个关键点：安全梯度位于低秩子空间内；这些子空间常常负相关导致方向冲突；可以高效地从一个样本中估计主要的安全方向。基于此，提出了一种轻量级的方法SPF，该方法明确移除了与低秩安全子空间冲突的梯度成分。", "result": "理论上，SPF保证了任务性能收敛并限制了安全性下降；经验上，即使在对抗性微调场景下，SPF也持续维持下游任务性能，并恢复几乎所有的预训练安全性。此外，SPF对深入微调和动态越狱攻击展现出强健的抵抗力。", "conclusion": "研究结果为始终对齐的大型语言模型微调提供了新的机制理解与实用指南，表明SPF能够有效解决安全性和实用性之间的矛盾。"}}
{"id": "2601.10137", "pdf": "https://arxiv.org/pdf/2601.10137", "abs": "https://arxiv.org/abs/2601.10137", "authors": ["Ziyi Ding", "Chenfei Ye-Hao", "Zheyuan Wang", "Xiao-Ping Zhang"], "title": "Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent Tree-Query and Adversarial Confidence Estimation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Causal discovery aims to recover ``what causes what'', but classical constraint-based methods (e.g., PC, FCI) suffer from error propagation, and recent LLM-based causal oracles often behave as opaque, confidence-free black boxes. This paper introduces Tree-Query, a tree-structured, multi-expert LLM framework that reduces pairwise causal discovery to a short sequence of queries about backdoor paths, (in)dependence, latent confounding, and causal direction, yielding interpretable judgments with robustness-aware confidence scores. Theoretical guarantees are provided for asymptotic identifiability of four pairwise relations. On data-free benchmarks derived from Mooij et al. and UCI causal graphs, Tree-Query improves structural metrics over direct LLM baselines, and a diet--weight case study illustrates confounder screening and stable, high-confidence causal conclusions. Tree-Query thus offers a principled way to obtain data-free causal priors from LLMs that can complement downstream data-driven causal discovery. Code is available at https://anonymous.4open.science/r/Repo-9B3E-4F96.", "AI": {"tldr": "本文介绍了Tree-Query，一种树结构的多专家LLM框架，用于通过一系列查询来发现因果关系，并提供可解释和置信度得分。", "motivation": "传统的约束性方法在因果发现中存在错误传播问题，而基于LLM的方法往往不透明且缺乏信心评估。本文旨在解决这些问题，提出一种更加透明和有自信评分的因果发现方法。", "method": "Tree-Query框架通过一系列关于后门路径、(独立)性、潜伏混淆和因果方向的查询来减少成对因果发现，并提供理论保证以实现四种成对关系的渐近可识别性。", "result": "在数据无关基准测试中，与直接LLM基线相比，Tree-Query改进了结构指标。饮食-体重案例研究展示了筛选混杂因素和得出稳定、高信心的因果结论的能力。", "conclusion": "Tree-Query提供了一种从LLMs获得无数据因果先验的原则方法，这可以补充后续的数据驱动因果发现。"}}
{"id": "2601.10132", "pdf": "https://arxiv.org/pdf/2601.10132", "abs": "https://arxiv.org/abs/2601.10132", "authors": ["Yanan Cao", "Farnaz Fallahi", "Murali Mohana Krishna Dandu", "Lalitesh Morishetti", "Kai Zhao", "Luyi Ma", "Sinduja Subramaniam", "Jianpeng Xu", "Evren Korpeoglu", "Kaushiki Nag", "Sushant Kumar", "Kannan Achan"], "title": "Is More Context Always Better? Examining LLM Reasoning Capability for Time Interval Prediction", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted at The Web Conference 2026 (WWW 2026)", "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in reasoning and prediction across different domains. Yet, their ability to infer temporal regularities from structured behavioral data remains underexplored. This paper presents a systematic study investigating whether LLMs can predict time intervals between recurring user actions, such as repeated purchases, and how different levels of contextual information shape their predictive behavior. Using a simple but representative repurchase scenario, we benchmark state-of-the-art LLMs in zero-shot settings against both statistical and machine-learning models. Two key findings emerge. First, while LLMs surpass lightweight statistical baselines, they consistently underperform dedicated machine-learning models, showing their limited ability to capture quantitative temporal structure. Second, although moderate context can improve LLM accuracy, adding further user-level detail degrades performance. These results challenge the assumption that \"more context leads to better reasoning\". Our study highlights fundamental limitations of today's LLMs in structured temporal inference and offers guidance for designing future context-aware hybrid models that integrate statistical precision with linguistic flexibility.", "AI": {"tldr": "研究大型语言模型（LLMs）在零样本设置下预测时间间隔的能力，探讨不同层次的上下文信息如何影响其性能。", "motivation": "探索LLMs从结构化行为数据中推断时间规律的能力，并检验添加更多背景信息是否始终能改善其推理能力。", "method": "通过一个简单的再购买场景，在零样本设置下将最先进的LLMs与统计和机器学习模型进行基准测试，评估它们在预测用户重复行动之间的时间间隔上的表现。", "result": "研究发现，虽然LLMs超过了轻量级的统计基线，但在捕捉量化时间结构方面仍然逊色于专用的机器学习模型。此外，适度的背景信息可以提高LLMs准确性，但增加更多用户级别的细节反而会降低性能。", "conclusion": "研究表明，今天的LLMs在有结构的时间推理上存在局限性，并为设计结合统计精度和语言灵活性的上下文感知混合模型提供了指导。"}}
{"id": "2601.10131", "pdf": "https://arxiv.org/pdf/2601.10131", "abs": "https://arxiv.org/abs/2601.10131", "authors": ["Yizhan Li", "Florence Cloutier", "Sifan Wu", "Ali Parviz", "Boris Knyazev", "Yan Zhang", "Glen Berseth", "Bang Liu"], "title": "M^4olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Generating molecules that satisfy precise numeric constraints over multiple physicochemical properties is critical and challenging. Although large language models (LLMs) are expressive, they struggle with precise multi-objective control and numeric reasoning without external structure and feedback. We introduce \\textbf{M olGen}, a fragment-level, retrieval-augmented, two-stage framework for molecule generation under multi-property constraints. Stage I : Prototype generation: a multi-agent reasoner performs retrieval-anchored, fragment-level edits to produce a candidate near the feasible region. Stage II : RL-based fine-grained optimization: a fragment-level optimizer trained with Group Relative Policy Optimization (GRPO) applies one- or multi-hop refinements to explicitly minimize the property errors toward our target while regulating edit complexity and deviation from the prototype. A large, automatically curated dataset with reasoning chains of fragment edits and measured property deltas underpins both stages, enabling deterministic, reproducible supervision and controllable multi-hop reasoning. Unlike prior work, our framework better reasons about molecules by leveraging fragments and supports controllable refinement toward numeric targets. Experiments on generation under two sets of property constraints (QED, LogP, Molecular Weight and HOMO, LUMO) show consistent gains in validity and precise satisfaction of multi-property targets, outperforming strong LLMs and graph-based algorithms.", "AI": {"tldr": "本文介绍了M^4olGen，一种多代理、多阶段的分子生成框架，在满足精确的多项理化性质约束下进行分子生成。", "motivation": "虽然大型语言模型表达能力强，但在没有外部结构和反馈的情况下难以实现精准的多目标控制和数值推理。因此，研究开发了一种能够更好地理解和生成满足特定物理化学属性要求的分子的方法。", "method": "M^4olGen采用两阶段框架：第一阶段通过多代理推理器进行片段级别编辑以产生候选分子；第二阶段使用基于强化学习的细化优化来显式地最小化属性误差，同时控制编辑复杂度和偏离原型的程度。整个过程使用一个大规模、自动整理的数据集作为基础。", "result": "实验表明，与强大的语言模型和图算法相比，在满足特定理化性质约束下的分子生成任务中，M^4olGen能够更一致地提高有效性并精准满足多属性目标。", "conclusion": "通过使用片段级推理和可控的细化优化过程，M^4olGen在精确控制下进行分子生成方面表现优于现有的方法。"}}
{"id": "2601.10130", "pdf": "https://arxiv.org/pdf/2601.10130", "abs": "https://arxiv.org/abs/2601.10130", "authors": ["Xiaolong Wan", "Xixian Han"], "title": "Redundancy-Driven Top-$k$ Functional Dependency Discovery", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Functional dependencies (FDs) are basic constraints in relational databases and are used for many data management tasks. Most FD discovery algorithms find all valid dependencies, but this causes two problems. First, the computational cost is prohibitive: computational complexity grows quadratically with the number of tuples and exponentially with the number of attributes, making discovery slow on large-scale and high-dimensional data. Second, the result set can be huge, making it hard to identify useful dependencies. We propose SDP (Selective-Discovery-and-Prune), which discovers the top-$k$ FDs ranked by redundancy count. Redundancy count measures how much duplicated information an FD explains and connects directly to storage overhead and update anomalies. SDP uses an upper bound on redundancy to prune the search space. It is proved that this upper bound is monotone: adding attributes refines partitions and thus decreases the bound. Once the bound falls below the top-$k$ threshold, the entire branch can be skipped. We improve SDP with three optimizations: ordering attributes by partition cardinality, using pairwise statistics in a Partition Cardinality Matrix to tighten bounds, and a global scheduler to explore promising branches first. Experiments on over 40 datasets show that SDP is much faster and uses less memory than exhaustive methods.", "AI": {"tldr": "本文提出了SDP算法，用于发现排名靠前的k个功能依赖项，并通过冗余计数进行排序。", "motivation": "传统的功能依赖项发现算法计算成本高且结果集庞大，难以识别有用的功能依赖关系。", "method": "SDP使用冗余度上界来剪枝搜索空间，并结合三个优化策略：按分区基数排序属性，使用分区基数矩阵的成对统计信息来收紧边界以及全局调度器优先探索有希望的分支。", "result": "实验表明，在40多个数据集上的测试中，SDP比穷举方法更快且内存占用更少。", "conclusion": "本文提出的方法能够有效地减少计算成本并提高识别有用功能依赖关系的能力。"}}
{"id": "2601.10129", "pdf": "https://arxiv.org/pdf/2601.10129", "abs": "https://arxiv.org/abs/2601.10129", "authors": ["Linquan Wu", "Tianxiang Jiang", "Yifei Dong", "Haoyu Yang", "Fengji Zhang", "Shichaang Meng", "Ai Xuan", "Linqi Song", "Jacky Keung"], "title": "LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Current multimodal latent reasoning often relies on external supervision (e.g., auxiliary images), ignoring intrinsic visual attention dynamics. In this work, we identify a critical Perception Gap in distillation: student models frequently mimic a teacher's textual output while attending to fundamentally divergent visual regions, effectively relying on language priors rather than grounded perception. To bridge this, we propose LaViT, a framework that aligns latent visual thoughts rather than static embeddings. LaViT compels the student to autoregressively reconstruct the teacher's visual semantics and attention trajectories prior to text generation, employing a curriculum sensory gating mechanism to prevent shortcut learning. Extensive experiments show that LaViT significantly enhances visual grounding, achieving up to +16.9% gains on complex reasoning tasks and enabling a compact 3B model to outperform larger open-source variants and proprietary models like GPT-4o.", "AI": {"tldr": "介绍LaViT框架，通过对齐潜在视觉思维来改进多模态推理。", "motivation": "现有的多模态推理依赖外部监督，忽视内在的视觉注意力动态，导致学生模型模仿教师的文字输出但关注不同的视觉区域。", "method": "提出LaViT框架，使学生模型在生成文本前逐步重构老师的视觉语义和注意力轨迹，并使用课程感觉门控机制防止捷径学习。", "result": "实验表明，LaViT显著提高了视觉基础，在复杂推理任务中获得高达16.9%的提升，并且一个紧凑的3B模型能够超越更大的开源变体和专有模型如GPT-4o。", "conclusion": "LaViT框架通过改进视觉注意力对齐来增强多模态推理性能，显示出显著的效果并具有高效的模型尺寸优势。"}}
{"id": "2601.10124", "pdf": "https://arxiv.org/pdf/2601.10124", "abs": "https://arxiv.org/abs/2601.10124", "authors": ["Sicheng Yang", "Zhaohu Xing", "Lei Zhu"], "title": "VQ-Seg: Vector-Quantized Token Perturbation for Semi-Supervised Medical Image Segmentation", "categories": ["cs.CV"], "comment": "Accepted by NeurIPS 2025", "summary": "Consistency learning with feature perturbation is a widely used strategy in semi-supervised medical image segmentation. However, many existing perturbation methods rely on dropout, and thus require a careful manual tuning of the dropout rate, which is a sensitive hyperparameter and often difficult to optimize and may lead to suboptimal regularization. To overcome this limitation, we propose VQ-Seg, the first approach to employ vector quantization (VQ) to discretize the feature space and introduce a novel and controllable Quantized Perturbation Module (QPM) that replaces dropout. Our QPM perturbs discrete representations by shuffling the spatial locations of codebook indices, enabling effective and controllable regularization. To mitigate potential information loss caused by quantization, we design a dual-branch architecture where the post-quantization feature space is shared by both image reconstruction and segmentation tasks. Moreover, we introduce a Post-VQ Feature Adapter (PFA) to incorporate guidance from a foundation model (FM), supplementing the high-level semantic information lost during quantization. Furthermore, we collect a large-scale Lung Cancer (LC) dataset comprising 828 CT scans annotated for central-type lung carcinoma. Extensive experiments on the LC dataset and other public benchmarks demonstrate the effectiveness of our method, which outperforms state-of-the-art approaches. Code available at: https://github.com/script-Yang/VQ-Seg.", "AI": {"tldr": "提出VQ-Seg，采用向量量化（VQ）离散特征空间并引入Quantized Perturbation Module (QPM)，用于半监督医学图像分割。", "motivation": "现有的一致性学习方法依赖于dropout，需要仔细调整敏感的超参数dropout率，可能导致次优正则化。为了克服这一限制，提出了一种新的方法。", "method": "设计了VQ-Seg，使用向量量化离散特征空间并引入QPM代替dropout进行扰动。同时，采用双分支架构和Post-VQ Feature Adapter (PFA)来减少信息损失，并利用基础模型的高语义信息。", "result": "在包含828个CT扫描图像的大规模肺癌数据集和其他公开基准测试上，该方法的表现优于现有最先进技术。", "conclusion": "VQ-Seg通过引入Quantized Perturbation Module (QPM)和双分支架构以及Post-VQ Feature Adapter (PFA)，有效解决了传统一致性学习中的dropout问题，并在实验中表现出色。"}}
{"id": "2601.10122", "pdf": "https://arxiv.org/pdf/2601.10122", "abs": "https://arxiv.org/abs/2601.10122", "authors": ["Ye Wang", "Jiaxing Chen", "Hongjiang Xiao"], "title": "Role-Playing Agents Driven by Large Language Models: Current Status, Challenges, and Future Trends", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "In recent years, with the rapid advancement of large language models (LLMs), role-playing language agents (RPLAs) have emerged as a prominent research focus at the intersection of natural language processing (NLP) and human-computer interaction. This paper systematically reviews the current development and key technologies of RPLAs, delineating the technological evolution from early rule-based template paradigms, through the language style imitation stage, to the cognitive simulation stage centered on personality modeling and memory mechanisms. It summarizes the critical technical pathways supporting high-quality role-playing, including psychological scale-driven character modeling, memory-augmented prompting mechanisms, and motivation-situation-based behavioral decision control. At the data level, the paper further analyzes the methods and challenges of constructing role-specific corpora, focusing on data sources, copyright constraints, and structured annotation processes. In terms of evaluation, it collates multi-dimensional assessment frameworks and benchmark datasets covering role knowledge, personality fidelity, value alignment, and interactive hallucination, while commenting on the advantages and disadvantages of methods such as human evaluation, reward models, and LLM-based scoring. Finally, the paper outlines future development directions of role-playing agents, including personality evolution modeling, multi-agent collaborative narrative, multimodal immersive interaction, and integration with cognitive neuroscience, aiming to provide a systematic perspective and methodological insights for subsequent research.", "AI": {"tldr": "本文系统回顾了基于大语言模型的角色扮演代理（RPLAs）的发展现状、关键技术及未来趋势。", "motivation": "随着大型语言模型的快速发展，研究者们关注于角色扮演代理在自然语言处理和人机交互交叉领域的应用，并希望总结技术路径，解决数据构建挑战以及评估方法。", "method": "通过系统回顾从规则模板到认知模拟的技术发展过程，本文总结了关键技术支持高质角色扮演的方法，包括心理量表驱动的角色建模、记忆增强提示机制及动机情景行为决策控制。", "result": "文章分析了构造特定角色语料库的方法和挑战，并整合多维度评估框架与基准数据集来评价角色知识、人格忠实度、价值对齐与交互式幻觉。", "conclusion": "本文指出了未来研究方向，包括人格演变建模、多代理协作叙事、多模态沉浸式互动及认知神经科学结合的系统性视角和方法论见解。"}}
{"id": "2601.10120", "pdf": "https://arxiv.org/pdf/2601.10120", "abs": "https://arxiv.org/abs/2601.10120", "authors": ["Rui Sun", "Jie Ding", "Chenghua Gong", "Tianjun Gu", "Yihang Jiang", "Juyuan Zhang", "Liming Pan", "Linyuan Lü"], "title": "TopoDIM: One-shot Topology Generation of Diverse Interaction Modes for Multi-Agent Systems", "categories": ["cs.MA", "cs.AI", "cs.CL"], "comment": null, "summary": "Optimizing communication topology in LLM-based multi-agent system is critical for enabling collective intelligence. Existing methods mainly rely on spatio-temporal interaction paradigms, where the sequential execution of multi-round dialogues incurs high latency and computation. Motivated by the recent insights that evaluation and debate mechanisms can improve problem-solving in multi-agent systems, we propose TopoDIM, a framework for one-shot Topology generation with Diverse Interaction Modes. Designed for decentralized execution to enhance adaptability and privacy, TopoDIM enables agents to autonomously construct heterogeneous communication without iterative coordination, achieving token efficiency and improved task performance. Experiments demonstrate that TopoDIM reduces total token consumption by 46.41% while improving average performance by 1.50% over state-of-the-art methods. Moreover, the framework exhibits strong adaptability in organizing communication among heterogeneous agents. Code is available at: https://anonymous.4open.science/r/TopoDIM-8D35/", "AI": {"tldr": "提出了TopoDIM框架，用于多智能体系统中一次性生成多样交互模式的拓扑结构。", "motivation": "现有方法依赖于时空交互范式，导致高延迟和计算成本。作者受到评估和辩论机制可以改进多智能体系统问题解决能力的启发，提出了一种新的优化方案。", "method": "TopoDIM框架设计为去中心化的执行方式以提高适应性和隐私保护，使代理能够自主构建异构通信而无需迭代协调，实现标记效率和任务性能提升。", "result": "实验表明，与最先进的方法相比，TopoDIM将总令牌消耗减少了46.41%，同时提高了平均性能1.50%。框架在组织异质代理之间的沟通中表现出强大的适应性。", "conclusion": "TopoDIM证明了其在减少计算成本和提高任务性能方面的有效性，并展示了它在多智能体系统中的强大适应能力。"}}
{"id": "2601.10117", "pdf": "https://arxiv.org/pdf/2601.10117", "abs": "https://arxiv.org/abs/2601.10117", "authors": ["Wenwen Liao", "Jianbo Yu", "Yuansong Wang", "Shifu Yan", "Xiaofeng Yang"], "title": "Beyond Single Prompts: Synergistic Fusion and Arrangement for VICL", "categories": ["cs.CV"], "comment": null, "summary": "Vision In-Context Learning (VICL) enables inpainting models to quickly adapt to new visual tasks from only a few prompts. However, existing methods suffer from two key issues: (1) selecting only the most similar prompt discards complementary cues from other high-quality prompts; and (2) failing to exploit the structured information implied by different prompt arrangements. We propose an end-to-end VICL framework to overcome these limitations. Firstly, an adaptive Fusion Module aggregates critical patterns and annotations from multiple prompts to form more precise contextual prompts. Secondly, we introduce arrangement-specific lightweight MLPs to decouple layout priors from the core model, while minimally affecting the overall model. In addition, an bidirectional fine-tuning mechanism swaps the roles of query and prompt, encouraging the model to reconstruct the original prompt from fused context and thus enhancing collaboration between the fusion module and the inpainting model. Experiments on foreground segmentation, single-object detection, and image colorization demonstrate superior results and strong cross-task generalization of our method.", "AI": {"tldr": "本文提出了一种端到端的Vision In-Context Learning框架，通过融合多个提示和特定排列机制来提高模型对新视觉任务的学习能力。", "motivation": "现有的VICL方法存在两个主要问题：仅选择最相似的提示而忽略了其他高质量提示中的互补信息；未能利用不同提示排列所隐含的结构化信息。因此，本文旨在解决这两个问题以提升模型的表现和跨任务泛化能力。", "method": "提出一个包含自适应融合模块、特定排列轻量级MLP以及双向微调机制的方法框架。其中，自适应融合模块聚合多个提示的关键模式和注释；特定排列的轻量级MLP解耦布局先验信息与核心模型；双向微调机制通过交换查询和提示的角色来增强融合模块和图像修复模型之间的协作。", "result": "实验表明，在前景分割、单目标检测以及图像着色等任务中，该方法取得了优越的结果，并且具有较强的跨任务泛化能力。", "conclusion": "本文提出的方法能够有效地克服现有VICL框架的不足，通过融合多个提示和特定排列机制显著提升了模型性能与跨任务适应性。"}}
{"id": "2601.10116", "pdf": "https://arxiv.org/pdf/2601.10116", "abs": "https://arxiv.org/abs/2601.10116", "authors": ["Xintong Zhang", "Junfeng Chen", "Yuxiao Zhu", "Bing Luo", "Meng Guo"], "title": "CoCoPlan: Adaptive Coordination and Communication for Multi-robot Systems in Dynamic and Unknown Environments", "categories": ["cs.RO"], "comment": "8 pages, 8 figures, published to RA-L", "summary": "Multi-robot systems can greatly enhance efficiency through coordination and collaboration, yet in practice, full-time communication is rarely available and interactions are constrained to close-range exchanges. Existing methods either maintain all-time connectivity, rely on fixed schedules, or adopt pairwise protocols, but none adapt effectively to dynamic spatio-temporal task distributions under limited communication, resulting in suboptimal coordination. To address this gap, we propose CoCoPlan, a unified framework that co-optimizes collaborative task planning and team-wise intermittent communication. Our approach integrates a branch-and-bound architecture that jointly encodes task assignments and communication events, an adaptive objective function that balances task efficiency against communication latency, and a communication event optimization module that strategically determines when, where and how the global connectivity should be re-established. Extensive experiments demonstrate that it outperforms state-of-the-art methods by achieving a 22.4% higher task completion rate, reducing communication overhead by 58.6%, and improving the scalability by supporting up to 100 robots in dynamic environments. Hardware experiments include the complex 2D office environment and large-scale 3D disaster-response scenario.", "AI": {"tldr": "介绍了一个名为CoCoPlan的统一框架，用于在动态未知环境中进行多机器人系统的自适应协调和通信。", "motivation": "现有的方法无法有效应对动态时空任务分布下的有限通信情况，导致协作效率低下。因此提出一种新的解决方案以解决这一问题。", "method": "使用一个分支定界架构联合编码任务分配和通信事件，并采用自适应目标函数平衡任务效率与通信延迟，同时通过优化模块战略性地确定何时何地如何恢复全局连接性。", "result": "实验显示该方法比现有最先进方法的平均任务完成率高出22.4%，减少了58.6%的通信开销，且能支持多达100个机器人的动态环境中的应用。", "conclusion": "CoCoPlan在复杂2D办公室环境和大规模3D灾难响应场景中展示了其优越性，并证明了其在提高任务完成效率与减少通信开销方面的能力。"}}
{"id": "2601.10114", "pdf": "https://arxiv.org/pdf/2601.10114", "abs": "https://arxiv.org/abs/2601.10114", "authors": ["Cheng Feng", "Chaoliang Zhong", "Jun Sun", "Yusuke Oishi"], "title": "Following the Teacher's Footsteps: Scheduled Checkpoint Distillation for Domain-Specific LLMs", "categories": ["cs.AI"], "comment": "15 pages, submitted to ICPR 2026", "summary": "Large language models (LLMs) are challenging to deploy for domain-specific tasks due to their massive scale. While distilling a fine-tuned LLM into a smaller student model is a promising alternative, the capacity gap between teacher and student often leads to suboptimal performance. This raises a key question: when and how can a student model match or even surpass its teacher on domain-specific tasks? In this work, we propose a novel theoretical insight: a student can outperform its teacher if its advantage on a Student-Favored Subdomain (SFS) outweighs its deficit on the Teacher-Favored Subdomain (TFS). Guided by this insight, we propose Scheduled Checkpoint Distillation (SCD), which reduces the TFS deficit by emulating the teacher's convergence process during supervised fine-tuning (SFT) on the domain task, and a sample-wise Adaptive Weighting (AW) mechanism to preserve student strengths on SFS. Experiments across diverse domain tasks--including QA, NER, and text classification in multiple languages--show that our method consistently outperforms existing distillation approaches, allowing the student model to match or even exceed the performance of its fine-tuned teacher.", "AI": {"tldr": "提出了一种名为Scheduled Checkpoint Distillation (SCD) 的方法，以缩小学生模型和教师模型之间的性能差距，并在特定领域任务中超越教师模型。", "motivation": "大型语言模型（LLM）因规模庞大难以部署于特定领域的任务。通过蒸馏将微调后的LLM转化为更小的学生模型是一种有前景的替代方案，但师生模型之间的能力差异导致学生模型性能不佳。", "method": "提出了一种新的理论见解：如果学生模型在Student-Favored Subdomain (SFS)上的优势超过其在Teacher-Favored Subdomain (TFS)上的劣势，则它可以超越教师。该方法包括Scheduled Checkpoint Distillation和sample-wise Adaptive Weighting机制来减少TFS的劣势并保持学生模型在SFS的优势。", "result": "实验结果显示，这种方法在多种领域任务中（如QA、NER和文本分类）一直优于现有的蒸馏方法，使学生模型能够达到或超越其微调后的教师模型的表现。", "conclusion": "该研究展示了通过Scheduled Checkpoint Distillation技术可以在特定领域任务上缩小甚至反超大型语言模型的效果。"}}
{"id": "2601.10112", "pdf": "https://arxiv.org/pdf/2601.10112", "abs": "https://arxiv.org/abs/2601.10112", "authors": ["Tsvi Cherny-Shahar", "Amiram Yehudai"], "title": "Repository Intelligence Graph: Deterministic Architectural Map for LLM Code Assistants", "categories": ["cs.SE", "cs.AI"], "comment": "35 pages, 5 figures", "summary": "Repository aware coding agents often struggle to recover build and test structure, especially in multilingual projects where cross language dependencies are encoded across heterogeneous build systems and tooling. We introduce the Repository Intelligence Graph (RIG), a deterministic, evidence backed architectural map that represents buildable components, aggregators, runners, tests, external packages, and package managers, connected by explicit dependency and coverage edges that trace back to concrete build and test definitions. We also present SPADE, a deterministic extractor that constructs RIG from build and test artifacts (currently with an automatic CMake plugin based on the CMake File API and CTest metadata), and exposes RIG as an LLM friendly JSON view that agents can treat as the authoritative description of repository structure. We evaluate three commercial agents (Claude Code, Cursor, Codex) on eight repositories spanning low to high build oriented complexity, including the real world MetaFFI project. Each agent answers thirty structured questions per repository with and without RIG in context, and we measure accuracy, wall clock completion time, and efficiency (seconds per correct answer). Across repositories and agents, providing RIG improves mean accuracy by 12.2\\% and reduces completion time by 53.9\\%, yielding a mean 57.8\\% reduction in seconds per correct answer. Gains are larger in multilingual repositories, which improve by 17.7\\% in accuracy and 69.5\\% in efficiency on average, compared to 6.6\\% and 46.1\\% in single language repositories. Qualitative analysis suggests that RIG shifts failures from structural misunderstandings toward reasoning mistakes over a correct structure, while rare regressions highlight that graph based reasoning quality remains a key factor.", "AI": {"tldr": "本文介绍了Repository Intelligence Graph (RIG)，一个确定性的证据支持架构图，旨在改善代码助手在多语言项目中的构建和测试结构理解能力。", "motivation": "现有的代码辅助工具在处理包含跨语言依赖关系的多语言项目时面临困难，尤其是在复杂的构建系统中。为此，本文提出了一个新的解决方案来帮助这些工具更好地理解和利用项目的结构信息。", "method": "通过开发SPADE提取器从构建和测试工件中自动生成RIG，并以LLM友好的JSON格式暴露出来，以便代码助手能够准确理解项目架构。", "result": "实验表明，使用RIG后，三个商业代理在八个项目上的平均精度提高了12.2%，完成时间减少了53.9%。特别是多语言项目的准确性增加了17.7%，效率提升了69.5%。", "conclusion": "RIG能够显著提高代码助手理解项目结构的能力，并减少它们解决相关问题的时间，尤其在处理多语言和复杂构建系统时效果更佳。"}}
{"id": "2601.10110", "pdf": "https://arxiv.org/pdf/2601.10110", "abs": "https://arxiv.org/abs/2601.10110", "authors": ["Shanxian Lin", "Wei Xia", "Yuichi Nagata", "Haichuan Yang"], "title": "Multi-Constrained Evolutionary Molecular Design Framework: An Interpretable Drug Design Method Combining Rule-Based Evolution and Molecular Crossover", "categories": ["cs.NE"], "comment": "Accepted at EvoApplications 2026 (29th International Conference on the Applications of Evolutionary Computation), 15 pages, 4 figures. This version of the contribution has been accepted for publication, after peer review, but is not the Version of Record and does not reflect post-acceptance improvements, or any corrections. The Version of Record will be available online at Springer", "summary": "This study proposes MCEMOL (Multi-Constrained Evolutionary Molecular Design Framework), a molecular optimization approach integrating rule-based evolution with molecular crossover. MCEMOL employs dual-layer evolution: optimizing transformation rules at rule level while applying crossover and mutation to molecular structures. Unlike deep learning methods requiring large datasets and extensive training, our algorithm evolves efficiently from minimal starting molecules with low computational overhead. The framework incorporates message-passing neural networks and comprehensive chemical constraints, ensuring efficient and interpretable molecular design. Experimental results demonstrate that MCEMOL provides transparent design pathways through its evolutionary mechanism while generating valid, diverse, target-compliant molecules. The framework achieves 100% molecular validity with high structural diversity and excellent drug-likeness compliance, showing strong performance in symmetry constraints, pharmacophore optimization, and stereochemical integrity. Unlike black-box methods, MCEMOL delivers dual value: interpretable transformation rules researchers can understand and trust, alongside high-quality molecular libraries for practical applications. This establishes a paradigm where interpretable AI-driven drug design and effective molecular generation are achieved simultaneously, bridging the gap between computational innovation and practical drug discovery needs.", "AI": {"tldr": "提出了一种名为MCEMOL的分子优化方法，结合了基于规则的进化和分子交叉，实现了可解释且高效的药物设计。", "motivation": "现有的深度学习方法需要大量的数据集和长时间训练，而本文的方法可以从少量初始分子开始高效地进行进化，并具有较低的计算成本。", "method": "MCEMOL采用了双层进化策略：在规则层面优化转换规则，同时对分子结构应用交叉和变异。该框架还结合了消息传递神经网络和全面的化学约束，确保高效的可解释性分子设计。", "result": "实验结果表明，MCEMOL能够生成有效的、多样化的且符合目标要求的分子，并实现了100%的分子有效性，高结构多样性以及优秀的药物相似度合规性。此外，该框架在对称性约束、药效团优化和立体化学完整性方面表现出色。", "conclusion": "与黑箱方法不同，MCEMOL不仅提供了研究人员可以理解和信任的可解释转换规则，还生成了高质量分子库用于实际应用。这确立了一个新的范式，在这个范式中，可解释的人工智能驱动的药物设计和有效的分子生成同时得以实现，弥合了计算创新与实用药物发现需求之间的差距。"}}
{"id": "2601.10108", "pdf": "https://arxiv.org/pdf/2601.10108", "abs": "https://arxiv.org/abs/2601.10108", "authors": ["Yiming Ren", "Junjie Wang", "Yuxin Meng", "Yihang Shi", "Zhiqiang Lin", "Ruihang Chu", "Yiran Xu", "Ziming Li", "Yunfei Zhao", "Zihan Wang", "Yu Qiao", "Ruiming Tang", "Minghao Liu", "Yujiu Yang"], "title": "SIN-Bench: Tracing Native Evidence Chains in Long-Context Multimodal Scientific Interleaved Literature", "categories": ["cs.CL", "cs.AI", "cs.MM"], "comment": null, "summary": "Evaluating whether multimodal large language models truly understand long-form scientific papers remains challenging: answer-only metrics and synthetic \"Needle-In-A-Haystack\" tests often reward answer matching without requiring a causal, evidence-linked reasoning trace in the document. We propose the \"Fish-in-the-Ocean\" (FITO) paradigm, which requires models to construct explicit cross-modal evidence chains within native scientific documents. To operationalize FITO, we build SIN-Data, a scientific interleaved corpus that preserves the native interleaving of text and figures. On top of it, we construct SIN-Bench with four progressive tasks covering evidence discovery (SIN-Find), hypothesis verification (SIN-Verify), grounded QA (SIN-QA), and evidence-anchored synthesis (SIN-Summary). We further introduce \"No Evidence, No Score\", scoring predictions when grounded to verifiable anchors and diagnosing evidence quality via matching, relevance, and logic. Experiments on eight MLLMs show that grounding is the primary bottleneck: Gemini-3-pro achieves the best average overall score (0.573), while GPT-5 attains the highest SIN-QA answer accuracy (0.767) but underperforms on evidence-aligned overall scores, exposing a gap between correctness and traceable support.", "AI": {"tldr": "本文提出了SIN-Bench，用于评估多模态大规模语言模型在理解长格式科学论文时的能力。", "motivation": "现有的评价方法如仅答案匹配和合成“针入稻草堆”测试无法有效衡量模型是否具备因果关联的证据链推理能力。因此，本研究旨在通过构建更严格的评估框架来解决这一问题。", "method": "作者提出了Fish-in-the-Ocean（FITO）范式，并创建了SIN-Data多模态科学文献集合，该集合保留了文本和图像原生交织的状态。基于此，他们设计了SIN-Bench测试套件，涵盖证据发现、假设验证、基于证据的问答以及证据支持的总结等四个任务。", "result": "实验结果显示，在八种大规模语言模型中，Gemini-3-pro在综合评分上表现最好（0.573），而GPT-5虽然在SIN-QA准确率最高（0.767），但在基于证据的整体得分方面表现不佳。", "conclusion": "研究揭示了当前多模态大规模语言模型主要受制于其将答案与文档中的具体证据相连接的能力，这表明正确性与可追溯支持之间存在差距。"}}
{"id": "2601.10107", "pdf": "https://arxiv.org/pdf/2601.10107", "abs": "https://arxiv.org/abs/2601.10107", "authors": ["Wenwen Liao", "Jianbo Yu", "Yuansong Wang", "Qingchao Jiang", "Xiaofeng Yang"], "title": "Enhancing Visual In-Context Learning by Multi-Faceted Fusion", "categories": ["cs.CV"], "comment": null, "summary": "Visual In-Context Learning (VICL) has emerged as a powerful paradigm, enabling models to perform novel visual tasks by learning from in-context examples. The dominant \"retrieve-then-prompt\" approach typically relies on selecting the single best visual prompt, a practice that often discards valuable contextual information from other suitable candidates. While recent work has explored fusing the top-K prompts into a single, enhanced representation, this still simply collapses multiple rich signals into one, limiting the model's reasoning capability. We argue that a more multi-faceted, collaborative fusion is required to unlock the full potential of these diverse contexts. To address this limitation, we introduce a novel framework that moves beyond single-prompt fusion towards an multi-combination collaborative fusion. Instead of collapsing multiple prompts into one, our method generates three contextual representation branches, each formed by integrating information from different combinations of top-quality prompts. These complementary guidance signals are then fed into proposed MULTI-VQGAN architecture, which is designed to jointly interpret and utilize collaborative information from multiple sources. Extensive experiments on diverse tasks, including foreground segmentation, single-object detection, and image colorization, highlight its strong cross-task generalization, effective contextual fusion, and ability to produce more robust and accurate predictions than existing methods.", "AI": {"tldr": "本文提出了一种多方面协作融合框架，通过生成三个互补的上下文表示分支来改进视觉在场学习。", "motivation": "现有的单提示融合方法往往忽略了许多有价值的上下文信息，并且简单的将多个优质提示合并为一个单一的增强表示限制了模型的推理能力。", "method": "提出的新框架不再把多个提示压缩成一个，而是生成三个互补的上下文表示分支。这些信号被输入到MULTI-VQGAN架构中，该架构设计用于共同解释和利用来自多个来源的合作信息。", "result": "实验结果表明，这种方法在前景分割、单目标检测和图像着色等任务上展示了强大的跨任务泛化能力、有效的上下文融合以及比现有方法更稳健和准确的预测能力。", "conclusion": "多方面协作融合框架增强了视觉在场学习模型的推理能力和跨任务性能，产生了更为准确和稳健的结果。"}}
{"id": "2601.10104", "pdf": "https://arxiv.org/pdf/2601.10104", "abs": "https://arxiv.org/abs/2601.10104", "authors": ["Chenyue Zhou", "Jiayi Tuo", "Shitong Qin", "Wei Dai", "Mingxuan Wang", "Ziwei Zhao", "Duoyang Li", "Shiyang Su", "Yanxi Lu", "Yanbiao Ma"], "title": "MathDoc: Benchmarking Structured Extraction and Active Refusal on Noisy Mathematics Exam Papers", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The automated extraction of structured questions from paper-based mathematics exams is fundamental to intelligent education, yet remains challenging in real-world settings due to severe visual noise. Existing benchmarks mainly focus on clean documents or generic layout analysis, overlooking both the structural integrity of mathematical problems and the ability of models to actively reject incomplete inputs. We introduce MathDoc, the first benchmark for document-level information extraction from authentic high school mathematics exam papers. MathDoc contains \\textbf{3,609} carefully curated questions with real-world artifacts and explicitly includes unrecognizable samples to evaluate active refusal behavior. We propose a multi-dimensional evaluation framework covering stem accuracy, visual similarity, and refusal capability. Experiments on SOTA MLLMs, including Qwen3-VL and Gemini-2.5-Pro, show that although end-to-end models achieve strong extraction performance, they consistently fail to refuse illegible inputs, instead producing confident but invalid outputs. These results highlight a critical gap in current MLLMs and establish MathDoc as a benchmark for assessing model reliability under degraded document conditions. Our project repository is available at \\href{https://github.com/winnk123/papers/tree/master}{GitHub repository}", "AI": {"tldr": "该论文介绍了MathDoc，这是一个用于从真实的高中数学考试试卷中进行文档级信息提取的基准测试。", "motivation": "自动从带严重视觉噪声的真实纸基数学考试卷中提取结构化问题具有挑战性，现有基准主要集中在清洁文档或通用布局分析上，忽略了数学题目的结构性和模型主动拒绝不完整输入的能力。", "method": "提出了MathDoc基准，包含3,609个精心策划的问题，并明确纳入了不可识别样本以评估主动拒绝行为。提出了一种多维评估框架，涵盖问题提取准确率、视觉相似性和拒绝对策能力。", "result": "实验结果表明，尽管最先进的MLLM模型（如Qwen3-VL和Gemini-2.5-Pro）在结构化提取方面表现良好，但在面对不可读输入时无法主动拒绝，而是产生自信但无效的输出。", "conclusion": "这些结果显示了现有MLLM模型的关键不足，并确立了MathDoc作为评估模型在退化文档条件下可靠性的基准。"}}
{"id": "2601.10103", "pdf": "https://arxiv.org/pdf/2601.10103", "abs": "https://arxiv.org/abs/2601.10103", "authors": ["Lizhen Wang", "Yongming Zhu", "Zhipeng Ge", "Youwei Zheng", "Longhao Zhang", "Tianshu Hu", "Shiyang Qin", "Mingshuang Luo", "Jiaxu Zhang", "Xin Chen", "Yulong Wang", "Zerong Zheng", "Jianwen Jiang", "Chao Liang", "Weifeng Chen", "Xing Wang", "Yuan Zhang", "Mingyuan Gao"], "title": "FlowAct-R1: Towards Interactive Humanoid Video Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Interactive humanoid video generation aims to synthesize lifelike visual agents that can engage with humans through continuous and responsive video. Despite recent advances in video synthesis, existing methods often grapple with the trade-off between high-fidelity synthesis and real-time interaction requirements. In this paper, we propose FlowAct-R1, a framework specifically designed for real-time interactive humanoid video generation. Built upon a MMDiT architecture, FlowAct-R1 enables the streaming synthesis of video with arbitrary durations while maintaining low-latency responsiveness. We introduce a chunkwise diffusion forcing strategy, complemented by a novel self-forcing variant, to alleviate error accumulation and ensure long-term temporal consistency during continuous interaction. By leveraging efficient distillation and system-level optimizations, our framework achieves a stable 25fps at 480p resolution with a time-to-first-frame (TTFF) of only around 1.5 seconds. The proposed method provides holistic and fine-grained full-body control, enabling the agent to transition naturally between diverse behavioral states in interactive scenarios. Experimental results demonstrate that FlowAct-R1 achieves exceptional behavioral vividness and perceptual realism, while maintaining robust generalization across diverse character styles.", "AI": {"tldr": "本文提出FlowAct-R1框架，旨在实现实时交互式类人视频生成。", "motivation": "尽管在视频合成方面取得了进展，现有方法仍难以平衡高保真度和实时互动需求。因此，作者提出了一个新框架来解决这一问题。", "method": "FlowAct-R1基于MMDiT架构，引入分段扩散强迫策略及一种新颖的自强迫变体以减少误差累积并保持长期时间一致性，同时通过有效蒸馏和系统级优化达到稳定25fps、480p分辨率且TTFF约为1.5秒。", "result": "实验结果表明FlowAct-R1在互动场景中实现了行为生动性和感知真实性，并具备强大泛化能力以适应不同的角色风格。", "conclusion": "FlowAct-R1框架能够提供全貌和细粒度的全身控制，使代理自然过渡到多种行为状态，实现了高保真、实时互动类人视频生成的目标。"}}
{"id": "2601.10101", "pdf": "https://arxiv.org/pdf/2601.10101", "abs": "https://arxiv.org/abs/2601.10101", "authors": ["Ke Chen", "Jiandian Zeng", "Zihao Peng", "Guo Li", "Guangxue Zhang", "Tian Wang"], "title": "MATRIX AS PLAN: Structured Logical Reasoning with Feedback-Driven Replanning", "categories": ["cs.AI", "cs.CL"], "comment": "12 pages, 5 figures, 2 tables. Accepted at The Web Conference (WWW) 2026", "summary": "As knowledge and semantics on the web grow increasingly complex, enhancing Large Language Models (LLMs) comprehension and reasoning capabilities has become particularly important. Chain-of-Thought (CoT) prompting has been shown to enhance the reasoning capabilities of LLMs. However, it still falls short on logical reasoning tasks that rely on symbolic expressions and strict deductive rules. Neuro-symbolic methods address this gap by enforcing formal correctness through external solvers. Yet these solvers are highly format-sensitive, and small instabilities in model outputs can lead to frequent processing failures. LLM-driven approaches avoid parsing brittleness, but they lack structured representations and process-level error-correction mechanisms. To further enhance the logical reasoning capabilities of LLMs, we propose MatrixCoT, a structured CoT framework with a matrix-based plan. Specifically, we normalize and type natural language expressions, attach explicit citation fields, and introduce a matrix-based planning method to preserve global relations among steps. The plan becomes a verifiable artifact, making execution more stable. For verification, we also add a feedback-driven replanning mechanism. Under semantic-equivalence constraints, it identifies omissions and defects, rewrites and compresses the dependency matrix, and produces a more trustworthy final answer. Experiments on five logical-reasoning benchmarks and five LLMs show that, without relying on external solvers, MatrixCoT enhances both robustness and interpretability when tackling complex symbolic reasoning tasks, while maintaining competitive performance.", "AI": {"tldr": "本文提出了一种名为MatrixCoT的结构化思维链框架，通过矩阵计划方法和反馈驱动的重规划机制来提升大语言模型在逻辑推理任务中的表现。", "motivation": "随着网络上的知识和语义变得越来越复杂，增强大型语言模型的理解和推理能力变得尤为重要。虽然思维链提示已被证明可以提高语言模型的推理能力，但在依赖符号表达和严格演绎规则的任务中仍然存在不足。", "method": "MatrixCoT通过将自然语言表达归一化并分类、引入显式的引用字段以及使用矩阵规划方法来保持步骤间的全局关系，形成一个可验证的计划。此外，还增加了一个反馈驱动的重规划机制，在语义等价约束下识别遗漏和缺陷，并重写压缩依赖矩阵。", "result": "实验表明，MatrixCoT在五个逻辑推理基准测试和五种大型语言模型上均显示出更好的健壮性和可解释性，在处理复杂符号推理任务时保持了竞争力的表现。", "conclusion": "MatrixCoT通过引入结构化的方法和反馈驱动的机制来增强大语言模型在逻辑推理上的能力，无需依赖外部求解器即可提升性能，并增加答案的可信度。"}}
{"id": "2601.10098", "pdf": "https://arxiv.org/pdf/2601.10098", "abs": "https://arxiv.org/abs/2601.10098", "authors": ["Wenwen Liao", "Hang Ruan", "Jianbo Yu", "Yuansong Wang", "Qingchao Jiang", "Xiaofeng Yang"], "title": "InfoSculpt: Sculpting the Latent Space for Generalized Category Discovery", "categories": ["cs.CV"], "comment": null, "summary": "Generalized Category Discovery (GCD) aims to classify instances from both known and novel categories within a large-scale unlabeled dataset, a critical yet challenging task for real-world, open-world applications. However, existing methods often rely on pseudo-labeling, or two-stage clustering, which lack a principled mechanism to explicitly disentangle essential, category-defining signals from instance-specific noise. In this paper, we address this fundamental limitation by re-framing GCD from an information-theoretic perspective, grounded in the Information Bottleneck (IB) principle. We introduce InfoSculpt, a novel framework that systematically sculpts the representation space by minimizing a dual Conditional Mutual Information (CMI) objective. InfoSculpt uniquely combines a Category-Level CMI on labeled data to learn compact and discriminative representations for known classes, and a complementary Instance-Level CMI on all data to distill invariant features by compressing augmentation-induced noise. These two objectives work synergistically at different scales to produce a disentangled and robust latent space where categorical information is preserved while noisy, instance-specific details are discarded. Extensive experiments on 8 benchmarks demonstrate that InfoSculpt validating the effectiveness of our information-theoretic approach.", "AI": {"tldr": "本文提出了InfoSculpt框架，通过最小化双条件互信息目标来雕塑表示空间，实现对已知和未知类别的分类。", "motivation": "现有的广义类别发现方法依赖于伪标签或两阶段聚类，缺乏明确区分类别定义信号与实例特定噪声的原理性机制。本文旨在解决这一根本限制。", "method": "InfoSculpt结合了基于标注数据的类别级别条件互信息和所有数据上的实例级别条件互信息目标，以产生一个分离且鲁棒的潜在空间，该空间保留了类别信息同时忽略了噪声细节。", "result": "在8个基准测试上进行的广泛实验验证了本文的信息理论方法的有效性。", "conclusion": "InfoSculpt通过最小化双条件互信息目标，在雕塑表示空间方面表现出色，提高了广义类别发现任务的效果。"}}
{"id": "2601.10094", "pdf": "https://arxiv.org/pdf/2601.10094", "abs": "https://arxiv.org/abs/2601.10094", "authors": ["Han Wang", "Yi Yang", "Jingyuan Hu", "Minfeng Zhu", "Wei Chen"], "title": "V-Zero: Self-Improving Multimodal Reasoning with Zero Annotation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in multimodal learning have significantly enhanced the reasoning capabilities of vision-language models (VLMs). However, state-of-the-art approaches rely heavily on large-scale human-annotated datasets, which are costly and time-consuming to acquire. To overcome this limitation, we introduce V-Zero, a general post-training framework that facilitates self-improvement using exclusively unlabeled images. V-Zero establishes a co-evolutionary loop by instantiating two distinct roles: a Questioner and a Solver. The Questioner learns to synthesize high-quality, challenging questions by leveraging a dual-track reasoning reward that contrasts intuitive guesses with reasoned results. The Solver is optimized using pseudo-labels derived from majority voting over its own sampled responses. Both roles are trained iteratively via Group Relative Policy Optimization (GRPO), driving a cycle of mutual enhancement. Remarkably, without a single human annotation, V-Zero achieves consistent performance gains on Qwen2.5-VL-7B-Instruct, improving visual mathematical reasoning by +1.7 and general vision-centric by +2.6, demonstrating the potential of self-improvement in multimodal systems. Code is available at https://github.com/SatonoDia/V-Zero", "AI": {"tldr": "介绍V-Zero，一种利用未标注图像实现自我改进的多模态学习框架。", "motivation": "现有的多模态学习方法依赖于大量的人类标注数据，成本高且耗时。为了克服这一局限性，提出了一种无需标注的数据自增强方法。", "method": "V-Zero通过建立Questioner和Solver两个角色间的相互促进循环来实现自我改进。Questioner利用双重推理奖励生成高质量问题，Solver则基于多数投票的伪标签进行优化，二者使用组相对策略优化（GRPO）迭代训练。", "result": "无需任何人类标注数据的情况下，在Qwen2.5-VL-7B-Instruct模型上实现了视觉数学推理和总体视觉相关性能的一致提升，分别提高了1.7和2.6点。", "conclusion": "展示了在多模态系统中自我改进的潜力。"}}
{"id": "2601.10092", "pdf": "https://arxiv.org/pdf/2601.10092", "abs": "https://arxiv.org/abs/2601.10092", "authors": ["Jongseok Kim", "Seongae Kang", "Jonghwan Shin", "Yuhan Lee", "Ohyun Jo"], "title": "LeMoF: Level-guided Multimodal Fusion for Heterogeneous Clinical Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multimodal clinical prediction is widely used to integrate heterogeneous data such as Electronic Health Records (EHR) and biosignals. However, existing methods tend to rely on static modality integration schemes and simple fusion strategies. As a result, they fail to fully exploit modality-specific representations. In this paper, we propose Level-guided Modal Fusion (LeMoF), a novel framework that selectively integrates level-guided representations within each modality. Each level refers to a representation extracted from a different layer of the encoder. LeMoF explicitly separates and learns global modality-level predictions from level-specific discriminative representations. This design enables LeMoF to achieve a balanced performance between prediction stability and discriminative capability even in heterogeneous clinical environments. Experiments on length of stay prediction using Intensive Care Unit (ICU) data demonstrate that LeMoF consistently outperforms existing state-of-the-art multimodal fusion techniques across various encoder configurations. We also confirmed that level-wise integration is a key factor in achieving robust predictive performance across various clinical conditions.", "AI": {"tldr": "提出Level-guided Modal Fusion (LeMoF)框架，用于异质临床数据的多模态融合。", "motivation": "现有的多模态整合方案依赖静态策略和简单的融合方法，未能充分利用各模态特定表示。因此需要一种更有效的框架来提升预测稳定性和判别能力。", "method": "LeMoF通过在每个模态内选择性地整合基于不同编码器层的表示形式，并明确区分全局模态级预测与层级特异性判别表示，实现了更好的性能平衡。", "result": "实验表明，在重症监护病房（ICU）数据长度预测中，LeMoF框架超越了现有的多模态融合技术。同时证明按层次整合是实现稳健预测的关键因素。", "conclusion": "LeMoF框架在异质临床环境中实现了稳定的性能和强大的判别能力，并且实验结果验证其有效性。"}}
{"id": "2601.10090", "pdf": "https://arxiv.org/pdf/2601.10090", "abs": "https://arxiv.org/abs/2601.10090", "authors": ["Mingzhuo Li", "Guang Li", "Linfeng Ye", "Jiafeng Mao", "Takahiro Ogawa", "Konstantinos N. Plataniotis", "Miki Haseyama"], "title": "Difficulty-guided Sampling: Bridging the Target Gap between Dataset Distillation and Downstream Tasks", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In this paper, we propose difficulty-guided sampling (DGS) to bridge the target gap between the distillation objective and the downstream task, therefore improving the performance of dataset distillation. Deep neural networks achieve remarkable performance but have time and storage-consuming training processes. Dataset distillation is proposed to generate compact, high-quality distilled datasets, enabling effective model training while maintaining downstream performance. Existing approaches typically focus on features extracted from the original dataset, overlooking task-specific information, which leads to a target gap between the distillation objective and the downstream task. We propose leveraging characteristics that benefit the downstream training into data distillation to bridge this gap. Focusing on the downstream task of image classification, we introduce the concept of difficulty and propose DGS as a plug-in post-stage sampling module. Following the specific target difficulty distribution, the final distilled dataset is sampled from image pools generated by existing methods. We also propose difficulty-aware guidance (DAG) to explore the effect of difficulty in the generation process. Extensive experiments across multiple settings demonstrate the effectiveness of the proposed methods. It also highlights the broader potential of difficulty for diverse downstream tasks.", "AI": {"tldr": "提出难度引导采样（DGS）来缩小蒸馏目标与下游任务之间的目标差距，提升数据集蒸馏的性能。", "motivation": "深度神经网络虽然取得了显著的成绩，但训练过程耗时且占用存储空间。现有方法在数据集蒸馏中忽略了任务特定信息，导致目标差距，因此动机是通过融入对下游任务有益的特点来优化数据集蒸馏。", "method": "提出难度引导采样（DGS）和难度感知指导（DAG），将任务相关的难度概念引入图像分类的下游任务，并设计了一种基于特定目标难度分布的插件式后处理抽样模块。", "result": "实验结果显示，该方法能有效提升数据集蒸馏的效果，在多个设置下展现了其有效性并凸显了难度在不同下游任务中的潜在价值。", "conclusion": "难度引导采样（DGS）能够有效地减少目标差距，并且为不同的下游任务提供了更广泛的潜力。"}}
{"id": "2601.10088", "pdf": "https://arxiv.org/pdf/2601.10088", "abs": "https://arxiv.org/abs/2601.10088", "authors": ["Malika Aubakirova", "Alex Atallah", "Chris Clark", "Justin Summerville", "Anjney Midha"], "title": "State of AI: An Empirical 100 Trillion Token Study with OpenRouter", "categories": ["cs.AI"], "comment": "36 pages", "summary": "The past year has marked a turning point in the evolution and real-world use of large language models (LLMs). With the release of the first widely adopted reasoning model, o1, on December 5th, 2024, the field shifted from single-pass pattern generation to multi-step deliberation inference, accelerating deployment, experimentation, and new classes of applications. As this shift unfolded at a rapid pace, our empirical understanding of how these models have actually been used in practice has lagged behind. In this work, we leverage the OpenRouter platform, which is an AI inference provider across a wide variety of LLMs, to analyze over 100 trillion tokens of real-world LLM interactions across tasks, geographies, and time. In our empirical study, we observe substantial adoption of open-weight models, the outsized popularity of creative roleplay (beyond just the productivity tasks many assume dominate) and coding assistance categories, plus the rise of agentic inference. Furthermore, our retention analysis identifies foundational cohorts: early users whose engagement persists far longer than later cohorts. We term this phenomenon the Cinderella \"Glass Slipper\" effect. These findings underscore that the way developers and end-users engage with LLMs \"in the wild\" is complex and multifaceted. We discuss implications for model builders, AI developers, and infrastructure providers, and outline how a data-driven understanding of usage can inform better design and deployment of LLM systems.", "AI": {"tldr": "本研究利用OpenRouter平台分析了超过100万亿令牌的实际语言模型交互，揭示了开发者和最终用户在实践中与大型语言模型互动的复杂性和多样性。", "motivation": "随着第一个广泛采用的推理模型o1于2024年12月5日发布，本研究旨在填补对实际使用中的大规模语言模型的理解差距。", "method": "通过OpenRouter平台收集并分析了跨越任务、地理和时间点的大规模语言模型的实际交互数据，总计超过100万亿个令牌。", "result": "观察到开放权重模型的广泛采用，创意角色扮演类应用的流行程度超出预期，以及代理推理的兴起。此外，通过保留分析确定了基础群体：早期用户的参与度远高于后来的用户群。", "conclusion": "研究结论强调实际使用中的开发者和最终用户与大型语言模型互动的方式是复杂且多方面的，这些发现对模型构建者、AI开发人员和基础设施提供者具有重要启示。"}}
{"id": "2601.10083", "pdf": "https://arxiv.org/pdf/2601.10083", "abs": "https://arxiv.org/abs/2601.10083", "authors": ["Shayan Hamidi Dehshali", "Tzu-Hsuan Liao", "Shaileshh Bojja Venkatakrishnan"], "title": "Starfield: Demand-Aware Satellite Topology Design for Low-Earth Orbit Mega Constellations", "categories": ["cs.NI", "cs.ET", "math.DG"], "comment": "31 pages, 13 figures, 2 Tables, 1 Algorithm", "summary": "Low-Earth orbit (LEO) mega-constellations are emerging as high-capacity backbones for next-generation Internet. Deployment of laser terminals enables high-bandwidth, low-latency inter-satellite links (ISLs); however, their limited number, slow acquisition, and instability make forming a stable satellite topology difficult. Existing patterns like +Grid and Motif ignore regional traffic, ground station placement, and constellation geometry. Given sparse population distribution on Earth and the isolation of rural areas, traffic patterns are inherently non-uniform, providing an opportunity to orient inter-satellite links (ISLs) according to these traffic patterns. In this paper, we propose Starfield, a novel demand-aware satellite topology design heuristic algorithm supported by mathematical analysis. We first formulate a vector field on the constellation's shell according to traffic flows and define a corresponding Riemannian metric on the spherical manifold of the shell. The metric, combined with the spatial geometry, is used to assign a distance to each potential ISL, which we then aggregate over all demand flows to generate a heuristic for each satellite's link selection. Inspired by +Grid, each satellite selects the link with the minimum Riemannian heuristic along with its corresponding angular links. To evaluate Starfield, we developed a custom, link-aware, and link-configurable packet-level simulator, comparing it against +Grid and Random topologies. For the Phase 1 Starlink, simulation results show up to a 30% reduction in hop count and a 15% improvement in stretch factor across multiple traffic distributions. Moreover, static Starfield, an inter-orbital link matching modification of Starfield, achieves a 20% improvement in stretch factor under realistic traffic patterns compared to +Grid. Experiments further demonstrate Starfield's robustness under traffic demand perturbations.", "AI": {"tldr": "本文提出了Starfield，一种基于需求感知的卫星拓扑设计启发式算法，旨在优化低地球轨道巨型星座中的星间链路。", "motivation": "由于现有模式（如+Grid和Motif）忽略了区域流量、地面站位置及星座几何结构，导致难以形成稳定的卫星拓扑，作者提出了一种新型方法来解决这一问题，并利用非均匀的流量分布机会优化ISL配置。", "method": "Starfield通过基于交通流在星座壳上定义向量场和黎曼度量，结合空间几何为每个潜在星间链路分配距离，从而生成一个启发式链接选择算法。受+Grid启发，每颗卫星选择具有最小黎曼启发式的链接及其相应角度链接。", "result": "仿真结果显示，在多个流量分布下，Starfield相比+Grid和随机拓扑实现了最高30%的跳数减少和15%的伸展因子改善，静态Starfield在实际交通模式下的伸展因子改进了20%，并且对需求扰动表现出鲁棒性。", "conclusion": "Starfield算法能够有效优化低地球轨道星座中的星间链路设计，并提高通信效率。"}}
{"id": "2601.10079", "pdf": "https://arxiv.org/pdf/2601.10079", "abs": "https://arxiv.org/abs/2601.10079", "authors": ["Sijia Luo", "Xiaokang Zhang", "Yuxuan Hu", "Bohan Zhang", "Ke Wang", "Jinbo Su", "Mengshu Sun", "Lei Liang", "Jing Zhang"], "title": "Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning via Stable Sparse Rollouts", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement Learning (RL) has become essential for eliciting complex reasoning capabilities in Large Language Models (LLMs). However, the substantial memory overhead of storing Key-Value (KV) caches during long-horizon rollouts acts as a critical bottleneck, often prohibiting efficient training on limited hardware. While existing KV compression techniques offer a remedy for inference, directly applying them to RL training induces a severe policy mismatch, leading to catastrophic performance collapse. To address this, we introduce Sparse-RL empowers stable RL training under sparse rollouts. We show that instability arises from a fundamental policy mismatch among the dense old policy, the sparse sampler policy, and the learner policy. To mitigate this issue, Sparse-RL incorporates Sparsity-Aware Rejection Sampling and Importance-based Reweighting to correct the off-policy bias introduced by compression-induced information loss. Experimental results show that Sparse-RL reduces rollout overhead compared to dense baselines while preserving the performance. Furthermore, Sparse-RL inherently implements sparsity-aware training, significantly enhancing model robustness during sparse inference deployment.", "AI": {"tldr": "本文介绍了Sparse-RL，一种通过稳定稀疏回放来突破大型语言模型（LLM）强化学习中记忆墙的方法。", "motivation": "现有的键值缓存压缩技术虽然能缓解推理阶段的内存瓶颈问题，但直接应用于强化学习训练会导致严重的策略不匹配和性能崩溃。因此，本文旨在解决由于存储KV缓存而产生的记忆瓶颈问题，并提高模型在稀疏回放条件下的稳健性。", "method": "Sparse-RL采用稀疏感知拒绝采样和基于重要性的重新加权方法来纠正由压缩引起的离策略偏差，以实现稳定稀疏回放强化学习训练。", "result": "实验结果表明，与密集基准相比，Sparse-RL可以减少回放开销并保持性能，同时增强模型在稀疏推理部署时的稳健性。", "conclusion": "Sparse-RL方法通过引入稀疏感知技术成功解决了由于KV缓存存储导致的记忆瓶颈问题，并且在不牺牲性能的前提下提升了强化学习训练和稀疏推理部署中的模型稳定性。"}}
{"id": "2601.10078", "pdf": "https://arxiv.org/pdf/2601.10078", "abs": "https://arxiv.org/abs/2601.10078", "authors": ["Jianhong Ye", "Haiquan Zhao"], "title": "Nearest Kronecker Product Decomposition Based Subband Adaptive Filter: Algorithms and Applications", "categories": ["eess.AS", "cs.IT"], "comment": "16 Pages, 19 figures,published to IEEE TASLP", "summary": "Recently, the nearest Kronecker product (NKP) decomposition-based normalized least mean square (NLMS-NKP) algorithm has demonstrated superior convergence performance compared to the conventional NLMS algorithm. However, its convergence rate exhibits significant degradation when processing highly correlated input signals. To address this problem, we propose a type-I NKP-based normalized subband adaptive filter (NSAF) algorithm, namely NSAF-NKP-I. Nevertheless, this algorithm incurs substantially higher computational overhead than the NLMS-NKP algorithm. Remarkably, our enhanced type-II NKP-based NSAF (NSAF-NKP-II) algorithm achieves equivalent convergence performance while substantially reducing computational complexity. Furthermore, to enhance robustness against impulsive noise interference, we develop two robust variants: the maximum correntropy criterion-based robust NSAF-NKP (RNSAF-NKP-MCC) and logarithmic criterion-based robust NSAF-NKP (RNSAF-NKP-LC) algorithms. Additionally, detailed analyses of computational complexity, step-size range, and theoretical steady-state performance are provided for theproposed algorithms. To enhance the practicability of the NSAF-NKP-II algorithm in complex nonlinear environments, we further devise two nonlinear implementations: the trigonometric functional link network-based NKP-NSAF (TFLN-NSAF-NKP) and Volterra series expansion-based NKP-NSAF (Volterra-NKP-NSAF) algorithms. In active noise control (ANC) systems, we further propose the filtered-x NSAF-NKP-II (NKP-FxNSAF) algorithm. Simulation experiments in echo cancellation, sparse system identification, nonlinear processing, and ANC scenarios are conducted to validate the superiority of the proposed algorithms over existing state-of-the-art counterparts.", "AI": {"tldr": "本文提出了基于最近Kronecker积分解的子带自适应滤波算法及其应用。", "motivation": "传统的NLMS算法在处理高度相关的输入信号时收敛性能较差，为此提出改进算法以提高鲁棒性和减少计算复杂度。", "method": "开发了NSAF-NKP-I和NSAF-NKP-II算法，并提出了两种增强的鲁棒版本RNSAF-NKP-MCC和RNSAF-NKP-LC。此外，还设计了非线性实现方法TFLN-NSAF-NKP和Volterra-NKP-NSAF。", "result": "提出的算法在回声消除、稀疏系统识别、非线性处理和主动噪声控制等领域表现出优越的性能。", "conclusion": "所提算法不仅提升了收敛性能，还减少了计算复杂度，并展示了良好的鲁棒性和适应多种应用场景的能力。"}}
{"id": "2601.10075", "pdf": "https://arxiv.org/pdf/2601.10075", "abs": "https://arxiv.org/abs/2601.10075", "authors": ["Zhendong Wang", "Lebin Zhou", "Jingchuan Xiao", "Rongduo Han", "Nam Ling", "Cihan Ruan"], "title": "Thinking Like Van Gogh: Structure-Aware Style Transfer via Flow-Guided 3D Gaussian Splatting", "categories": ["cs.CV", "cs.GR", "cs.LG"], "comment": "7 pages, 8 figures", "summary": "In 1888, Vincent van Gogh wrote, \"I am seeking exaggeration in the essential.\" This principle, amplifying structural form while suppressing photographic detail, lies at the core of Post-Impressionist art. However, most existing 3D style transfer methods invert this philosophy, treating geometry as a rigid substrate for surface-level texture projection. To authentically reproduce Post-Impressionist stylization, geometric abstraction must be embraced as the primary vehicle of expression. We propose a flow-guided geometric advection framework for 3D Gaussian Splatting (3DGS) that operationalizes this principle in a mesh-free setting. Our method extracts directional flow fields from 2D paintings and back-propagates them into 3D space, rectifying Gaussian primitives to form flow-aligned brushstrokes that conform to scene topology without relying on explicit mesh priors. This enables expressive structural deformation driven directly by painterly motion rather than photometric constraints. Our contributions are threefold: (1) a projection-based, mesh-free flow guidance mechanism that transfers 2D artistic motion into 3D Gaussian geometry; (2) a luminance-structure decoupling strategy that isolates geometric deformation from color optimization, mitigating artifacts during aggressive structural abstraction; and (3) a VLM-as-a-Judge evaluation framework that assesses artistic authenticity through aesthetic judgment instead of conventional pixel-level metrics, explicitly addressing the subjective nature of artistic stylization.", "AI": {"tldr": "通过流导向的3D高斯点绘制方法实现了结构感知的风格迁移，以模仿梵高的艺术创作。", "motivation": "现有的3D风格转换技术大多将几何形状视为刚性底座，这与后印象派强调放大结构形式并抑制摄影细节的原则相悖。为了忠实再现这种风格，作者提出了新的方法来实现结构导向的艺术变形。", "method": "该研究提出了一种流引导的几何推进框架，用于3D高斯点绘制(3DGS)，提取2D绘画中的方向流场，并将其反向传播至3D空间中。通过解耦亮度和结构策略以及投影基的非网格流导向机制，实现了直接由画风运动驱动的表达性结构变形。", "result": "该方法能够将2D艺术运动转移到无网格的3D高斯几何体上，并实现与场景拓扑一致的流动对齐画笔效果。通过VLM作为评判框架评估了艺术真实性，确保了风格转化的艺术主观性。", "conclusion": "研究提出的新方法成功实现了梵高式的结构感知风格迁移，在不依赖显式网格先验的情况下，实现了符合后印象派艺术原则的3D几何抽象变形。"}}
{"id": "2601.10073", "pdf": "https://arxiv.org/pdf/2601.10073", "abs": "https://arxiv.org/abs/2601.10073", "authors": ["Hyun Do Jung", "Jungwon Choi", "Hwiyoung Kim"], "title": "ReaMIL: Reasoning- and Evidence-Aware Multiple Instance Learning for Whole-Slide Histopathology", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at LFMBio Workshop, WACV 2026. This work has been submitted to the IEEE for possible publication", "summary": "We introduce ReaMIL (Reasoning- and Evidence-Aware MIL), a multiple instance learning approach for whole-slide histopathology that adds a light selection head to a strong MIL backbone. The head produces soft per-tile gates and is trained with a budgeted-sufficiency objective: a hinge loss that enforces the true-class probability to be $\\geq τ$ using only the kept evidence, under a sparsity budget on the number of selected tiles. The budgeted-sufficiency objective yields small, spatially compact evidence sets without sacrificing baseline performance. Across TCGA-NSCLC (LUAD vs. LUSC), TCGA-BRCA (IDC vs. Others), and PANDA, ReaMIL matches or slightly improves baseline AUC and provides quantitative evidence-efficiency diagnostics. On NSCLC, it attains AUC 0.983 with a mean minimal sufficient K (MSK) $\\approx 8.2$ tiles at $τ= 0.90$ and AUKC $\\approx 0.864$, showing that class confidence rises sharply and stabilizes once a small set of tiles is kept. The method requires no extra supervision, integrates seamlessly with standard MIL training, and naturally yields slide-level overlays. We report accuracy alongside MSK, AUKC, and contiguity for rigorous evaluation of model behavior on WSIs.", "AI": {"tldr": "本文介绍了一种用于全切片组织病理学的多实例学习方法ReaMIL，通过添加轻量级的选择头来提高证据效率。", "motivation": "动机在于改进传统的多实例学习方法，在保留高性能的同时提供更紧凑和高效的证据集，并且不需要额外的监督。", "method": "ReaMIL使用一个轻量选择头产生软的每片栅门，通过预算充足的目标进行训练以确保在选定的切片下真类概率不低于阈值τ。", "result": "实验表明，在TCGA-NSCLC、TCGA-BRCA和PANDA数据集上，ReaMIL匹配或略微提高了基线性能，并且仅使用少量切片就达到了稳定的分类信心。", "conclusion": "ReaMIL不仅没有牺牲准确率，还提供了更高效的证据诊断和无缝集成的解决方案。"}}
{"id": "2601.10070", "pdf": "https://arxiv.org/pdf/2601.10070", "abs": "https://arxiv.org/abs/2601.10070", "authors": ["Mohammad Abbadi"], "title": "Comparative Evaluation of Deep Learning-Based and WHO-Informed Approaches for Sperm Morphology Assessment", "categories": ["cs.LG", "cs.CV", "eess.IV", "q-bio.QM"], "comment": "Under review at Computers in Biology and Medicine", "summary": "Assessment of sperm morphological quality remains a critical yet subjective component of male fertility evaluation, often limited by inter-observer variability and resource constraints. This study presents a comparative biomedical artificial intelligence framework evaluating an image-based deep learning model (HuSHeM) alongside a clinically grounded baseline derived from World Health Organization criteria augmented with the Systemic Inflammation Response Index (WHO(+SIRI)). The HuSHeM model was trained on high-resolution sperm morphology images and evaluated using an independent clinical cohort. Model performance was assessed using discrimination, calibration, and clinical utility analyses. The HuSHeM model demonstrated higher discriminative performance, as reflected by an increased area under the receiver operating characteristic curve with relatively narrow confidence intervals compared to WHO(+SIRI). Precision-recall analysis further indicated improved performance under class imbalance, with higher precision-recall area values across evaluated thresholds. Calibration analysis indicated closer agreement between predicted probabilities and observed outcomes for HuSHeM, while decision curve analysis suggested greater net clinical benefit across clinically relevant threshold probabilities. These findings suggest that image-based deep learning may offer improved predictive reliability and clinical utility compared with traditional rule-based and inflammation-augmented criteria. The proposed framework supports objective and reproducible assessment of sperm morphology and may serve as a decision-support tool within fertility screening and referral workflows. The proposed models are intended as decision-support or referral tools and are not designed to replace clinical judgment or laboratory assessment.", "AI": {"tldr": "本文比较了基于深度学习的精子形态评估模型（HuSHeM）与WHO标准结合系统性炎症反应指数(WHO(+SIRI))在男性生育能力评估中的表现。", "motivation": "传统的人工评估精子形态质量主观性强且存在资源限制和观察者间变异性，因此需要一种更客观、可重复的评估方法来提高临床实用性。", "method": "研究设计了一个基于高分辨率图像训练的深度学习模型（HuSHeM），并与WHO标准结合系统性炎症反应指数（WHO(+SIRI)）进行了对比。通过独立的临床队列对模型进行评估，使用了包括区分能力、校准和临床效用等指标来衡量性能。", "result": "HuSHeM在区分能力和精度召回率分析中表现优于WHO(+SIRI)，且预测概率与实际结果之间的一致性更好。决策曲线分析表明，在临床上具有更高的净效益。", "conclusion": "基于图像的深度学习模型可能提供比传统基于规则和炎症增强的标准更好的可预测性和临床效用，支持更客观、可重复地评估精子形态，并作为生育筛选和转诊工作流程中的辅助工具。"}}
{"id": "2601.10061", "pdf": "https://arxiv.org/pdf/2601.10061", "abs": "https://arxiv.org/abs/2601.10061", "authors": ["Chengzhuo Tong", "Mingkun Chang", "Shenglong Zhang", "Yuran Wang", "Cheng Liang", "Zhizheng Zhao", "Ruichuan An", "Bohan Zeng", "Yang Shi", "Yifan Dai", "Ziming Zhao", "Guanbin Li", "Pengfei Wan", "Yuanxing Zhang", "Wentao Zhang"], "title": "CoF-T2I: Video Models as Pure Visual Reasoners for Text-to-Image Generation", "categories": ["cs.CV", "cs.AI"], "comment": "16 pages, 8 figures", "summary": "Recent video generation models have revealed the emergence of Chain-of-Frame (CoF) reasoning, enabling frame-by-frame visual inference. With this capability, video models have been successfully applied to various visual tasks (e.g., maze solving, visual puzzles). However, their potential to enhance text-to-image (T2I) generation remains largely unexplored due to the absence of a clearly defined visual reasoning starting point and interpretable intermediate states in the T2I generation process. To bridge this gap, we propose CoF-T2I, a model that integrates CoF reasoning into T2I generation via progressive visual refinement, where intermediate frames act as explicit reasoning steps and the final frame is taken as output. To establish such an explicit generation process, we curate CoF-Evol-Instruct, a dataset of CoF trajectories that model the generation process from semantics to aesthetics. To further improve quality and avoid motion artifacts, we enable independent encoding operation for each frame. Experiments show that CoF-T2I significantly outperforms the base video model and achieves competitive performance on challenging benchmarks, reaching 0.86 on GenEval and 7.468 on Imagine-Bench. These results indicate the substantial promise of video models for advancing high-quality text-to-image generation.", "AI": {"tldr": "本文提出了CoF-T2I模型，通过逐步的视觉细化将帧链（Chain-of-Frame, CoF）推理能力整合到文本到图像生成中。", "motivation": "虽然视频生成模型在其他视觉任务上表现出色，但它们尚未被充分用于提升文本到图像生成。这主要是因为缺乏明确的视觉推理起点和可解释的中间状态。", "method": "CoF-T2I通过逐步视觉细化将帧链推理能力整合到T2I中，其中中间帧充当显式的推理步骤，最终帧作为输出结果。为此创建了CoF-Evol-Instruct数据集，并允许每个帧独立编码操作以提高质量和避免运动伪影。", "result": "实验表明，CoF-T2I在GenEval和Imagine-Bench两个挑战性基准测试上显著优于基础视频模型，分别达到0.86和7.468的评分。", "conclusion": "这些结果证实了视频模型对于提高文本到图像生成质量的巨大潜力。"}}
{"id": "2601.10054", "pdf": "https://arxiv.org/pdf/2601.10054", "abs": "https://arxiv.org/abs/2601.10054", "authors": ["Nick Truong", "Pritam P. Karmokar", "William J. Beksi"], "title": "UEOF: A Benchmark Dataset for Underwater Event-Based Optical Flow", "categories": ["cs.CV", "cs.RO"], "comment": "To be presented at the 2026 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshop on Event-Based Vision in the Era of Generative AI", "summary": "Underwater imaging is fundamentally challenging due to wavelength-dependent light attenuation, strong scattering from suspended particles, turbidity-induced blur, and non-uniform illumination. These effects impair standard cameras and make ground-truth motion nearly impossible to obtain. On the other hand, event cameras offer microsecond resolution and high dynamic range. Nonetheless, progress on investigating event cameras for underwater environments has been limited due to the lack of datasets that pair realistic underwater optics with accurate optical flow. To address this problem, we introduce the first synthetic underwater benchmark dataset for event-based optical flow derived from physically-based ray-traced RGBD sequences. Using a modern video-to-event pipeline applied to rendered underwater videos, we produce realistic event data streams with dense ground-truth flow, depth, and camera motion. Moreover, we benchmark state-of-the-art learning-based and model-based optical flow prediction methods to understand how underwater light transport affects event formation and motion estimation accuracy. Our dataset establishes a new baseline for future development and evaluation of underwater event-based perception algorithms. The source code and dataset for this project are publicly available at https://robotic-vision-lab.github.io/ueof.", "AI": {"tldr": "本文提出了一个用于水下事件驱动光流的合成基准数据集UEOF。", "motivation": "由于水下成像面临的挑战，如光衰减、散射和模糊等问题，标准摄像机难以获得精确的运动信息。因此，需要建立基于事件相机的数据集来评估和改进水下环境中的光学流动预测方法。", "method": "使用物理基础的光线追踪RGBD序列，并通过现代视频到事件管道生成逼真的事件数据流，包含密集的地面真实流动、深度和摄像机运动。", "result": "基准了最先进的基于学习和模型的方法来理解水下光传输如何影响事件形成和运动估计精度。", "conclusion": "该数据集为未来开发和评估水下事件驱动感知算法建立了新的基线。"}}
{"id": "2601.10053", "pdf": "https://arxiv.org/pdf/2601.10053", "abs": "https://arxiv.org/abs/2601.10053", "authors": ["Giyeol Kim", "Chanho Eom"], "title": "Disentangled Concept Representation for Text-to-image Person Re-identification", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-image person re-identification (TIReID) aims to retrieve person images from a large gallery given free-form textual descriptions. TIReID is challenging due to the substantial modality gap between visual appearances and textual expressions, as well as the need to model fine-grained correspondences that distinguish individuals with similar attributes such as clothing color, texture, or outfit style. To address these issues, we propose DiCo (Disentangled Concept Representation), a novel framework that achieves hierarchical and disentangled cross-modal alignment. DiCo introduces a shared slot-based representation, where each slot acts as a part-level anchor across modalities and is further decomposed into multiple concept blocks. This design enables the disentanglement of complementary attributes (\\textit{e.g.}, color, texture, shape) while maintaining consistent part-level correspondence between image and text. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that our framework achieves competitive performance with state-of-the-art methods, while also enhancing interpretability through explicit slot- and block-level representations for more fine-grained retrieval results.", "AI": {"tldr": "该论文提出了DiCo框架，用于解决文本到图像的人体再识别问题。", "motivation": "文本到图像人体再识别面临模态间隙和细粒度对应关系建模的挑战，需要一种方法来区分具有相似属性的不同个体。", "method": "DiCo通过引入共享插槽表示，实现跨模态层次化且解耦对齐。每个插槽作为图像和文本之间的部分级锚点，并进一步分解成多个概念块，以解耦互补属性并保持一致的部分级对应关系。", "result": "实验结果表明，在CUHK-PEDES、ICFG-PEDES和RSTPReid数据集上，该框架达到了与最先进的方法相当的性能水平。", "conclusion": "DiCo通过其明确的插槽和块级表示增强了可解释性，并实现了更细粒度的检索结果。"}}
{"id": "2601.10038", "pdf": "https://arxiv.org/pdf/2601.10038", "abs": "https://arxiv.org/abs/2601.10038", "authors": ["Yuan-Sen Ting", "André Curtis-Trudel", "Siyu Yao"], "title": "What Understanding Means in AI-Laden Astronomy", "categories": ["astro-ph.IM", "cs.AI", "cs.LG"], "comment": "Perspective article, 8 pages. Based on the \"Philosophy Sees the Algorithm\" workshop held December 11-12, 2025 at The Ohio State University. Supported by the Alfred P. Sloan Foundation, the Center for Cosmology and AstroParticle Physics (CCAPP), and the University of Cincinnati Center for Humanities and Technology", "summary": "Artificial intelligence is rapidly transforming astronomical research, yet the scientific community has largely treated this transformation as an engineering challenge rather than an epistemological one. This perspective article argues that philosophy of science offers essential tools for navigating AI's integration into astronomy--conceptual clarity about what \"understanding\" means, critical examination of assumptions about data and discovery, and frameworks for evaluating AI's roles across different research contexts. Drawing on an interdisciplinary workshop convening astronomers, philosophers, and computer scientists, we identify several tensions. First, the narrative that AI will \"derive fundamental physics\" from data misconstrues contemporary astronomy as equation-derivation rather than the observation-driven enterprise it is. Second, scientific understanding involves more than prediction--it requires narrative construction, contextual judgment, and communicative achievement that current AI architectures struggle to provide. Third, because narrative and judgment matter, human peer review remains essential--yet AI-generated content flooding the literature threatens our capacity to identify genuine insight. Fourth, while AI excels at well-defined problem-solving, the ill-defined problem-finding that drives breakthroughs appears to require capacities beyond pattern recognition. Fifth, as AI accelerates what is feasible, pursuitworthiness criteria risk shifting toward what AI makes easy rather than what is genuinely important. We propose \"pragmatic understanding\" as a framework for integration--recognizing AI as a tool that extends human cognition while requiring new norms for validation and epistemic evaluation. Engaging with these questions now may help the community shape the transformation rather than merely react to it.", "AI": {"tldr": "论文探讨了在天文学中整合人工智能时对\"理解\"的哲学思考，并提出了一种务实的理解框架。", "motivation": "尽管人工智能正在改变天文学研究，但科学界大多将其视为一个工程问题而非认识论上的挑战。文章旨在通过哲学方法来澄清AI整合中的概念和评估框架。", "method": "基于跨学科工作坊的讨论，汇集了天文学家、哲学家和计算机科学家的观点，识别并探讨了几个核心问题。", "result": "提出了五个关键点：1) AI“从数据中推导基本物理”的说法误解了现代天文学；2) 科学理解不仅仅是预测；3) 人类同行评审仍至关重要；4) 突破性的研究需要超越模式识别的能力；5) 追求重要性而非AI易解决的问题。", "conclusion": "建议采用“务实的理解”框架，将AI视为扩展人类认知的工具，并提出新的验证和评价标准，以帮助社区主动塑造这一转型。"}}
{"id": "2601.10037", "pdf": "https://arxiv.org/pdf/2601.10037", "abs": "https://arxiv.org/abs/2601.10037", "authors": ["Ning Lin", "Jichang Yang", "Yangu He", "Zijian Ye", "Kwun Hang Wong", "Xinyuan Zhang", "Songqi Wang", "Yi Li", "Kemi Xu", "Leo Yu Zhang", "Xiaoming Chen", "Dashan Shang", "Han Wang", "Xiaojuan Qi", "Zhongrui Wang"], "title": "Resistive Memory based Efficient Machine Unlearning and Continual Learning", "categories": ["cs.ET"], "comment": null, "summary": "Resistive memory (RM) based neuromorphic systems can emulate synaptic plasticity and thus support continual learning, but they generally lack biologically inspired mechanisms for active forgetting, which are critical for meeting modern data privacy requirements. Algorithmic forgetting, or machine unlearning, seeks to remove the influence of specific data from trained models to prevent memorization of sensitive information and the generation of harmful content, yet existing exact and approximate unlearning schemes incur prohibitive programming overheads on RM hardware owing to device variability and iterative write-verify cycles. Analogue implementations of continual learning face similar barriers. Here we present a hardware-software co-design that enables an efficient training, deployment and inference pipeline for machine unlearning and continual learning on RM accelerators. At the software level, we introduce a low-rank adaptation (LoRA) framework that confines updates to compact parameter branches, substantially reducing the number of trainable parameters and therefore the training cost. At the hardware level, we develop a hybrid analogue-digital compute-in-memory system in which well-trained weights are stored in analogue RM arrays, whereas dynamic LoRA updates are implemented in a digital computing unit with SRAM buffer. This hybrid architecture avoids costly reprogramming of analogue weights and maintains high energy efficiency during inference. Fabricated in a 180 nm CMOS process, the prototype achieves up to a 147.76-fold reduction in training cost, a 387.95-fold reduction in deployment overhead and a 48.44-fold reduction in inference energy across privacy-sensitive tasks including face recognition, speaker authentication and stylized image generation, paving the way for secure and efficient neuromorphic intelligence at the edge.", "AI": {"tldr": "本文提出了一种基于电阻式存储器（RM）的硬件与软件协同设计，用于高效的机器遗忘和连续学习。", "motivation": "现有算法在电阻式存储器上执行精确或近似遗忘操作时存在显著编程开销。另外，类似持续学习的模拟实现也面临同样障碍，因此本文旨在通过减少训练成本、部署开销及推理能耗来改进数据隐私保护。", "method": "软件层面引入低秩适应（LoRA）框架限制更新至紧凑参数分支；硬件层面开发混合类比-数字计算存储系统，其中预训练权重保存在电阻式阵列中，动态LoRA更新则由带有SRAM缓冲的数字计算单元执行。", "result": "原型实验结果显示，在涉及人脸识别、语音认证和样式图像生成等隐私敏感任务上，训练成本降低147.76倍，部署开销减少387.95倍，推理能耗节省48.44倍。", "conclusion": "该硬件与软件协同设计为边缘设备上的安全高效神经形态智能提供了可能，并显著提升了数据隐私保护能力。"}}
{"id": "2601.10035", "pdf": "https://arxiv.org/pdf/2601.10035", "abs": "https://arxiv.org/abs/2601.10035", "authors": ["Jonathan Timcheck", "Alessandro Pierro", "Sumit Bam Shrestha"], "title": "A Compute and Communication Runtime Model for Loihi 2", "categories": ["cs.NE"], "comment": "9 pages, 8 figures", "summary": "Neuromorphic computers hold the potential to vastly improve the speed and efficiency of a wide range of computational kernels with their asynchronous, compute-memory co-located, spatially distributed, and scalable nature. However, performance models that are simple yet sufficiently expressive to predict runtime on actual neuromorphic hardware are lacking, posing a challenge for researchers and developers who strive to design fast algorithms and kernels. As breaking the memory bandwidth wall of conventional von-Neumann architectures is a primary neuromorphic advantage, modeling communication time is especially important. At the same time, modeling communication time is difficult, as complex congestion patterns arise in a heavily-loaded Network-on-Chip. In this work, we introduce the first max-affine lower-bound runtime model -- a multi-dimensional roofline model -- for Intel's Loihi 2 neuromorphic chip that quantitatively accounts for both compute and communication based on a suite of microbenchmarks. Despite being a lower-bound model, we observe a tight correspondence (Pearson correlation coefficient greater than or equal to 0.97) between our model's estimated runtime and the measured runtime on Loihi 2 for a neural network linear layer, i.e., matrix-vector multiplication, and for an example application, a Quadratic Unconstrained Binary Optimization solver. Furthermore, we derive analytical expressions for communication-bottlenecked runtime to study scalability of the linear layer, revealing an area-runtime tradeoff for different spatial workload configurations with linear to superliner runtime scaling in layer size with a variety of constant factors. Our max-affine runtime model helps empower the design of high-speed algorithms and kernels for Loihi 2.", "AI": {"tldr": "本文介绍了一种针对Intel Loihi 2神经形态芯片的计算和通信运行时模型，该模型基于一系列微基准测试来定量分析计算时间和通信时间。", "motivation": "缺乏简单而充分表达性能的模型使得预测实际神经形态硬件上的运行时间变得困难，这阻碍了研究者设计快速算法和内核的能力。特别地，由于突破传统的冯诺依曼体系架构中的内存带宽限制是神经形态系统的一个主要优势，因此准确建模通信时间尤为重要。", "method": "本文提出了第一个最大仿射下界运行时模型——一个多维的屋顶线模型，该模型基于一套微基准测试来定量分析计算和通信的时间。", "result": "尽管是一个下界模型，但观察到估计的运行时间和Loihi 2的实际测量时间之间存在紧密的相关性（皮尔逊相关系数大于或等于0.97），特别是在神经网络线性层（即矩阵-向量乘法）的例子应用和一个二次无约束二进制优化求解器中。", "conclusion": "该最大仿射运行时模型有助于设计高速算法和内核，为Loihi 2上的线性层研究揭示了区域与时间之间的权衡，并展示了从线性到超线性的运行时间扩展。"}}
{"id": "2601.10031", "pdf": "https://arxiv.org/pdf/2601.10031", "abs": "https://arxiv.org/abs/2601.10031", "authors": ["Jianheng Tang", "Shilong Tao", "Zhe Feng", "Haonan Sun", "Menglu Wang", "Zhanxing Zhu", "Yunhuai Liu"], "title": "FilDeep: Learning Large Deformations of Elastic-Plastic Solids with Multi-Fidelity Data", "categories": ["cs.AI"], "comment": "Accepted in Proceedings of the 32nd ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1 (KDD '26)", "summary": "The scientific computation of large deformations in elastic-plastic solids is crucial in various manufacturing applications. Traditional numerical methods exhibit several inherent limitations, prompting Deep Learning (DL) as a promising alternative. The effectiveness of current DL techniques typically depends on the availability of high-quantity and high-accuracy datasets, which are yet difficult to obtain in large deformation problems. During the dataset construction process, a dilemma stands between data quantity and data accuracy, leading to suboptimal performance in the DL models. To address this challenge, we focus on a representative application of large deformations, the stretch bending problem, and propose FilDeep, a Fidelity-based Deep Learning framework for large Deformation of elastic-plastic solids. Our FilDeep aims to resolve the quantity-accuracy dilemma by simultaneously training with both low-fidelity and high-fidelity data, where the former provides greater quantity but lower accuracy, while the latter offers higher accuracy but in less quantity. In FilDeep, we provide meticulous designs for the practical large deformation problem. Particularly, we propose attention-enabled cross-fidelity modules to effectively capture long-range physical interactions across MF data. To the best of our knowledge, our FilDeep presents the first DL framework for large deformation problems using MF data. Extensive experiments demonstrate that our FilDeep consistently achieves state-of-the-art performance and can be efficiently deployed in manufacturing.", "AI": {"tldr": "本文提出FilDeep，一种基于多保真度数据的大变形深度学习框架，旨在解决弹性-塑性固体大变形问题。", "motivation": "传统的数值方法在计算弹性-塑性固体的大变形时存在局限性，而现有的深度学习技术依赖于高质量和高数量的数据集，在实际应用中难以获取这样的数据集。本文旨在通过多保真度数据来解决这一困境。", "method": "FilDeep框架利用低保真度和高保真度数据同时进行训练，其中低保真度数据提供大量但准确性较低的数据，而高保真度数据提供少量但准确性较高的数据，并设计了注意力使能的跨保真度模块来捕获不同保真度数据之间的物理交互。", "result": "实验结果表明，FilDeep在大变形问题上达到了最先进的性能水平，并且可以高效地应用于制造领域。", "conclusion": "本文提出的方法为弹性-塑性固体的大变形问题提供了创新的深度学习解决方案，证明了使用多保真度数据进行训练的有效性和实用性。"}}
{"id": "2601.10029", "pdf": "https://arxiv.org/pdf/2601.10029", "abs": "https://arxiv.org/abs/2601.10029", "authors": ["Tingyue Pan", "Jie Ouyang", "Mingyue Cheng", "Qingchuan Li", "Zirui Liu", "Mingfan Pan", "Shuo Yu", "Qi Liu"], "title": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Academic paper search is a fundamental task in scientific research, yet most existing approaches rely on rigid, predefined workflows that struggle with complex, conditional queries. To address this limitation, we propose PaperScout, an autonomous agent that reformulates paper search as a sequential decision-making process. Unlike static workflows, PaperScout dynamically decides whether, when, and how to invoke search and expand tools based on accumulated retrieval context. However, training such agents presents a fundamental challenge: standard reinforcement learning methods, typically designed for single-turn tasks, suffer from a granularity mismatch when applied to multi-turn agentic tasks, where token-level optimization diverges from the granularity of sequence-level interactions, leading to noisy credit assignment. We introduce Proximal Sequence Policy Optimization (PSPO), a process-aware, sequence-level policy optimization method that aligns optimization with agent-environment interaction. Comprehensive experiments on both synthetic and real-world benchmarks demonstrate that PaperScout significantly outperforms strong workflow-driven and RL baselines in both recall and relevance, validating the effectiveness of our adaptive agentic framework and optimization strategy.", "AI": {"tldr": "本文提出PaperScout，一种用于学术论文搜索的自主代理，并引入了过程感知、序列级策略优化方法PSPO。", "motivation": "现有大多数学术论文检索方法依赖于固定的工作流程，难以处理复杂的条件查询，因此作者提出了动态决策机制来改进这一问题。", "method": "PaperScout将论文搜索视为一个顺序决策过程，并提出Proximal Sequence Policy Optimization（PSPO）优化策略以解决多回合任务中的信用分配噪音问题。", "result": "实验显示，PaperScout在合成和现实世界基准上均显著优于工作流程驱动的基线和RL方法，在召回率和相关性方面表现更佳。", "conclusion": "本研究验证了自适应代理框架及其优化策略的有效性，证明了其在学术论文搜索任务中的优越性能。"}}
{"id": "2601.10025", "pdf": "https://arxiv.org/pdf/2601.10025", "abs": "https://arxiv.org/abs/2601.10025", "authors": ["Jinpeng Wang", "Xinyu Jia", "Wei Wei Heng", "Yuquan Li", "Binbin Shi", "Qianlei Chen", "Guannan Chen", "Junxia Zhang", "Yuyu Yin"], "title": "Structured Personality Control and Adaptation for LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly shaping human-computer interaction (HCI), from personalized assistants to social simulations. Beyond language competence, researchers are exploring whether LLMs can exhibit human-like characteristics that influence engagement, decision-making, and perceived realism. Personality, in particular, is critical, yet existing approaches often struggle to achieve both nuanced and adaptable expression. We present a framework that models LLM personality via Jungian psychological types, integrating three mechanisms: a dominant-auxiliary coordination mechanism for coherent core expression, a reinforcement-compensation mechanism for temporary adaptation to context, and a reflection mechanism that drives long-term personality evolution. This design allows the agent to maintain nuanced traits while dynamically adjusting to interaction demands and gradually updating its underlying structure. Personality alignment is evaluated using Myers-Briggs Type Indicator questionnaires and tested under diverse challenge scenarios as a preliminary structured assessment. Findings suggest that evolving, personality-aware LLMs can support coherent, context-sensitive interactions, enabling naturalistic agent design in HCI.", "AI": {"tldr": "本文提出了一种基于荣格心理类型的大语言模型性格控制和适应框架，旨在实现更自然的交互。", "motivation": "现有的大语言模型虽然在语言能力上表现出色，但在展示复杂且可适应的性格方面存在局限性。因此，研究如何让LLM展现出类似人类的特点以增强互动性和决策过程中的现实感是本文的动力。", "method": "提出一种框架，通过整合主导-辅助协调机制、强化补偿机制以及反思机制来模拟大语言模型性格。", "result": "利用MBTI问卷评估了性格一致性，并在多样化的挑战场景中进行初步结构化评估。实验表明，这种演进的性格感知型LLM能够支持连贯且情境敏感的交互。", "conclusion": "该设计有助于创建更自然的人机互动大语言模型，在保持细腻特质的同时能动态调整适应不同的交流需求并逐步更新其内部架构。"}}
{"id": "2601.10018", "pdf": "https://arxiv.org/pdf/2601.10018", "abs": "https://arxiv.org/abs/2601.10018", "authors": ["Hasti Sharifi", "Homaira Huda Shomee", "Sourav Medya", "Debaleena Chattopadhyay"], "title": "Empowering Older Adults in Digital Technology Use with Foundation Models", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "While high-quality technology support can assist older adults in using digital applications, many struggle to articulate their issues due to unfamiliarity with technical terminology and age-related cognitive changes. This study examines these communication challenges and explores AI-based approaches to mitigate them. We conducted a diary study with English-speaking, community-dwelling older adults to collect asynchronous, technology-related queries and used reflexive thematic analysis to identify communication barriers. To address these barriers, we evaluated how foundation models can paraphrase older adults' queries to improve solution accuracy. Two controlled experiments followed: one with younger adults evaluating AI-rephrased queries and another with older adults evaluating AI-generated solutions. We also developed a pipeline using large language models to generate the first synthetic dataset of how older adults request tech support (OATS). We identified four key communication challenges: verbosity, incompleteness, over-specification, and under-specification. Our prompt-chaining approach using the large language model, GPT-4o, elicited contextual details, paraphrased the original query, and generated a solution. AI-rephrased queries significantly improved solution accuracy (69% vs. 46%) and Google search results (69% vs. 35%). Younger adults better understood AI-rephrased queries (93.7% vs. 65.8%) and reported greater confidence and ease. Older adults reported high perceived ability to answer contextual questions (89.8%) and follow solutions (94.7%), with high confidence and ease. OATS demonstrated strong fidelity and face validity. This work shows how foundation models can enhance technology support for older adults by addressing age-related communication barriers. The OATS dataset offers a scalable resource for developing equitable AI systems that better serve aging populations.", "AI": {"tldr": "本文研究如何通过AI基础模型解决老年人在使用数字技术时的沟通障碍，并提高技术支持的有效性。", "motivation": "许多老年人由于对技术术语不熟悉和年龄相关的认知变化，在表达他们的问题时遇到困难。因此，本研究旨在探索基于AI的方法以改善这一状况。", "method": "通过日记研究收集社区居住的英语老年居民的异步技术相关查询，并使用反思性主题分析识别沟通障碍。利用大型语言模型GPT-4o开发了一个管道来生成老年人请求技术支持的第一个合成数据集（OATS），并进行了两次控制实验评估AI重新表述问题的效果。", "result": "研究发现，通过AI重新表述的问题显著提高了解决方案的准确性（从46%提高到69%）以及Google搜索结果的有效性。年轻的参与者更容易理解AI重述的问题，并且表现出更高的信心和便利度。老年参与者报告说他们有能力回答上下文问题并遵循解决方案。", "conclusion": "研究显示，基础模型能够通过解决与年龄相关的沟通障碍来增强对老年人的技术支持能力，OATS数据集为开发更加公平的AI系统提供了可扩展资源。"}}
{"id": "2601.10011", "pdf": "https://arxiv.org/pdf/2601.10011", "abs": "https://arxiv.org/abs/2601.10011", "authors": ["Zerui Yang", "Weichuan Wang", "Yanwei Xu", "Linqi Song", "Yudai Matsuda", "Wei Han", "Bo Bai"], "title": "Memo-SQL: Structured Decomposition and Experience-Driven Self-Correction for Training-Free NL2SQL", "categories": ["cs.AI"], "comment": null, "summary": "Existing NL2SQL systems face two critical limitations: (1) they rely on in-context learning with only correct examples, overlooking the rich signal in historical error-fix pairs that could guide more robust self-correction; and (2) test-time scaling approaches often decompose questions arbitrarily, producing near-identical SQL candidates across runs and diminishing ensemble gains. Moreover, these methods suffer from a stark accuracy-efficiency trade-off: high performance demands excessive computation, while fast variants compromise quality. We present Memo-SQL, a training-free framework that addresses these issues through two simple ideas: structured decomposition and experience-aware self-correction. Instead of leaving decomposition to chance, we apply three clear strategies, entity-wise, hierarchical, and atomic sequential, to encourage diverse reasoning. For correction, we build a dynamic memory of both successful queries and historical error-fix pairs, and use retrieval-augmented prompting to bring relevant examples into context at inference time, no fine-tuning or external APIs required. On BIRD, Memo-SQL achieves 68.5% execution accuracy, setting a new state of the art among open, zero-fine-tuning methods, while using over 10 times fewer resources than prior TTS approaches.", "AI": {"tldr": "本文介绍了Memo-SQL，一个无训练的框架，通过结构化分解和经验驱动的自我纠错来解决现有的NL2SQL系统面临的问题。", "motivation": "现有NL2SQL系统依赖于仅包含正确示例的上下文学习，并且在测试时会随意地将问题分解，这限制了它们的性能和效率。本文旨在通过Memo-SQL框架改善这些问题。", "method": "Memo-SQL采用三种清晰的战略进行结构化分解：基于实体、分层和原子顺序分解策略以鼓励多样化的推理，并使用动态记忆库来存储成功查询及历史错误修复对，利用检索增强的提示将相关示例在推理时带入上下文。", "result": "实验结果显示Memo-SQL在BIRD数据集上实现了68.5%的执行准确率，达到开放且不需微调方法中的新状态，并使用了比先前测试时间缩放方法少10倍以上的资源。", "conclusion": "本文提出的Memo-SQL框架通过结构化分解和经验驱动自我纠错，在保持高准确性的同时减少了计算资源需求。"}}
{"id": "2601.10010", "pdf": "https://arxiv.org/pdf/2601.10010", "abs": "https://arxiv.org/abs/2601.10010", "authors": ["Zefan Zhang", "Kehua Zhu", "Shijie Jiang", "Hongyuan Lu", "Shengkai Sun", "Tian Bai"], "title": "VERHallu: Evaluating and Mitigating Event Relation Hallucination in Video Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 6 figures", "summary": "Video Large Language Models (VideoLLMs) exhibit various types of hallucinations. Existing research has primarily focused on hallucinations involving the presence of events, objects, and scenes in videos, while largely neglecting event relation hallucination. In this paper, we introduce a novel benchmark for evaluating the Video Event Relation Hallucination, named VERHallu. This benchmark focuses on causal, temporal, and subevent relations between events, encompassing three types of tasks: relation classification, question answering, and counterfactual question answering, for a comprehensive evaluation of event relation hallucination. Additionally, it features counterintuitive video scenarios that deviate from typical pretraining distributions, with each sample accompanied by human-annotated candidates covering both vision-language and pure language biases. Our analysis reveals that current state-of-the-art VideoLLMs struggle with dense-event relation reasoning, often relying on prior knowledge due to insufficient use of frame-level cues. Although these models demonstrate strong grounding capabilities for key events, they often overlook the surrounding subevents, leading to an incomplete and inaccurate understanding of event relations. To tackle this, we propose a Key-Frame Propagating (KFP) strategy, which reallocates frame-level attention within intermediate layers to enhance multi-event understanding. Experiments show it effectively mitigates the event relation hallucination without affecting inference speed.", "AI": {"tldr": "介绍VERHallu基准，评估视频大型语言模型中的事件关系幻觉，并提出关键帧传播策略来缓解这个问题。", "motivation": "现有研究主要集中在涉及视频中事件、对象和场景的幻觉上，忽视了事件关系幻觉。因此需要一个专门针对事件关系幻觉的评估基准。", "method": "开发VERHallu基准，涵盖因果关系、时间关系和子事件关系的任务；提出关键帧传播策略来提高多事件理解能力。", "result": "实验显示，提出的Key-Frame Propagating策略能够有效缓解事件关系幻觉问题，并且不会影响推理速度。", "conclusion": "视频大型语言模型在处理密集事件关系时存在困难，通过使用关键帧传播策略可以改善这种情况。"}}
{"id": "2601.10001", "pdf": "https://arxiv.org/pdf/2601.10001", "abs": "https://arxiv.org/abs/2601.10001", "authors": ["Chengjia Liang", "Zhenjiong Wang", "Chao Chen", "Ruizhi Zhang", "Songxi Liang", "Hai Xie", "Haijun Lei", "Zhongwei Huang"], "title": "DW-DGAT: Dynamically Weighted Dual Graph Attention Network for Neurodegenerative Disease Diagnosis", "categories": ["cs.CV"], "comment": "AAAI-2026 accepted poster paper", "summary": "Parkinson's disease (PD) and Alzheimer's disease (AD) are the two most prevalent and incurable neurodegenerative diseases (NDs) worldwide, for which early diagnosis is critical to delay their progression. However, the high dimensionality of multi-metric data with diverse structural forms, the heterogeneity of neuroimaging and phenotypic data, and class imbalance collectively pose significant challenges to early ND diagnosis. To address these challenges, we propose a dynamically weighted dual graph attention network (DW-DGAT) that integrates: (1) a general-purpose data fusion strategy to merge three structural forms of multi-metric data; (2) a dual graph attention architecture based on brain regions and inter-sample relationships to extract both micro- and macro-level features; and (3) a class weight generation mechanism combined with two stable and effective loss functions to mitigate class imbalance. Rigorous experiments, based on the Parkinson Progression Marker Initiative (PPMI) and Alzhermer's Disease Neuroimaging Initiative (ADNI) studies, demonstrate the state-of-the-art performance of our approach.", "AI": {"tldr": "本文提出了一种动态加权双图注意力网络（DW-DGAT），用于神经退行性疾病的诊断。", "motivation": "早诊对延缓帕金森病和阿尔茨海默症的进展至关重要，但多度量数据维度高、异构性和类别不平衡等问题阻碍了早期诊断的发展。", "method": "提出了一种动态加权双图注意力网络（DW-DGAT），集成了多度量数据融合策略、基于脑区和样本间关系的双图注意架构以及用于缓解类别不平衡的类权重生成机制。", "result": "在Parkinson Progression Marker Initiative (PPMI) 和 Alzheimer's Disease Neuroimaging Initiative (ADNI) 研究基础上进行的实验展示了该方法的先进性能。", "conclusion": "DW-DGAT网络能够有效应对神经退行性疾病诊断中的挑战，展示出优越的诊断能力。"}}
{"id": "2601.10000", "pdf": "https://arxiv.org/pdf/2601.10000", "abs": "https://arxiv.org/abs/2601.10000", "authors": ["Diqiong Jiang", "Kai Zhu", "Dan Song", "Jian Chang", "Chenglizhao Chen", "Zhenyu Wu"], "title": "EditEmoTalk: Controllable Speech-Driven 3D Facial Animation with Continuous Expression Editing", "categories": ["cs.MM", "cs.CV"], "comment": null, "summary": "Speech-driven 3D facial animation aims to generate realistic and expressive facial motions directly from audio. While recent methods achieve high-quality lip synchronization, they often rely on discrete emotion categories, limiting continuous and fine-grained emotional control. We present EditEmoTalk, a controllable speech-driven 3D facial animation framework with continuous emotion editing. The key idea is a boundary-aware semantic embedding that learns the normal directions of inter-emotion decision boundaries, enabling a continuous expression manifold for smooth emotion manipulation. Moreover, we introduce an emotional consistency loss that enforces semantic alignment between the generated motion dynamics and the target emotion embedding through a mapping network, ensuring faithful emotional expression. Extensive experiments demonstrate that EditEmoTalk achieves superior controllability, expressiveness, and generalization while maintaining accurate lip synchronization. Code and pretrained models will be released.", "AI": {"tldr": "提出EditEmoTalk框架，实现从语音驱动的可控制、连续表情编辑的三维面部动画。", "motivation": "虽然现有方法在唇同步方面表现出色，但它们通常依赖于离散的情绪类别，限制了连续和精细的情感控制。", "method": "使用边界感知语义嵌入学习情绪间的决策边界，并引入情感一致性损失来确保生成的运动动态与目标情感嵌入的一致性。", "result": "实验表明EditEmoTalk在可控性、表现力及泛化能力方面表现出色，同时保持了准确的唇同步。", "conclusion": "EditEmoTalk通过连续的情绪编辑实现高质量且表达丰富的三维面部动画生成。"}}
{"id": "2601.09988", "pdf": "https://arxiv.org/pdf/2601.09988", "abs": "https://arxiv.org/abs/2601.09988", "authors": ["Hojung Choi", "Yifan Hou", "Chuer Pan", "Seongheon Hong", "Austin Patel", "Xiaomeng Xu", "Mark R. Cutkosky", "Shuran Song"], "title": "In-the-Wild Compliant Manipulation with UMI-FT", "categories": ["cs.RO"], "comment": "submitted to ICRA 2026", "summary": "Many manipulation tasks require careful force modulation. With insufficient force the task may fail, while excessive force could cause damage. The high cost, bulky size and fragility of commercial force/torque (F/T) sensors have limited large-scale, force-aware policy learning. We introduce UMI-FT, a handheld data-collection platform that mounts compact, six-axis force/torque sensors on each finger, enabling finger-level wrench measurements alongside RGB, depth, and pose. Using the multimodal data collected from this device, we train an adaptive compliance policy that predicts position targets, grasp force, and stiffness for execution on standard compliance controllers. In evaluations on three contact-rich, force-sensitive tasks (whiteboard wiping, skewering zucchini, and lightbulb insertion), UMI-FT enables policies that reliably regulate external contact forces and internal grasp forces, outperforming baselines that lack compliance or force sensing. UMI-FT offers a scalable path to learning compliant manipulation from in-the-wild demonstrations. We open-source the hardware and software to facilitate broader adoption at:https://umi-ft.github.io/.", "AI": {"tldr": "本文介绍了UMI-FT，一种用于收集手指级力/扭矩数据的便携平台，并基于此训练适应性合规策略。", "motivation": "商业力/扭矩传感器的成本高、体积大且易碎，限制了大规模力量感知策略的学习。因此，开发了一种低成本的手持式数据采集平台来解决这个问题。", "method": "通过UMI-FT收集多模态数据（包括RGB图像、深度图和姿态），训练一个适应性合规政策，该政策预测位置目标、抓握力和刚度，并在标准的合规控制器上执行。", "result": "实验结果显示，在白板擦拭、刺穿西葫芦以及灯泡插入等三个接触丰富的任务中，UMI-FT能够使策略可靠地调节外部接触力和内部抓取力，优于没有使用合规控制或力量感知的基线方法。", "conclusion": "UMI-FT提供了一种可扩展的学习来自现实世界演示的合规操作的方法，并且硬件和软件开源以促进更广泛的应用。"}}
{"id": "2601.09982", "pdf": "https://arxiv.org/pdf/2601.09982", "abs": "https://arxiv.org/abs/2601.09982", "authors": ["David Samuel Setiawan", "Raphaël Merx", "Jey Han Lau"], "title": "Context Volume Drives Performance: Tackling Domain Shift in Extremely Low-Resource Translation via RAG", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Neural Machine Translation (NMT) models for low-resource languages suffer significant performance degradation under domain shift. We quantify this challenge using Dhao, an indigenous language of Eastern Indonesia with no digital footprint beyond the New Testament (NT). When applied to the unseen Old Testament (OT), a standard NMT model fine-tuned on the NT drops from an in-domain score of 36.17 chrF++ to 27.11 chrF++. To recover this loss, we introduce a hybrid framework where a fine-tuned NMT model generates an initial draft, which is then refined by a Large Language Model (LLM) using Retrieval-Augmented Generation (RAG). The final system achieves 35.21 chrF++ (+8.10 recovery), effectively matching the original in-domain quality. Our analysis reveals that this performance is driven primarily by the number of retrieved examples rather than the choice of retrieval algorithm. Qualitative analysis confirms the LLM acts as a robust \"safety net,\" repairing severe failures in zero-shot domains.", "AI": {"tldr": "本文探讨了在极低资源语言翻译中，如何通过检索增强生成（RAG）解决领域迁移问题。", "motivation": "神经机器翻译模型在处理低资源语言时，在领域转移情况下性能显著下降。作者希望通过研究提出一种解决方案来改善这种现象。", "method": "本文提出了一个混合框架，首先使用微调后的神经机器翻译模型生成初步译文，然后利用检索增强生成技术，结合大型语言模型对初步译文进行改进。", "result": "最终系统在新领域的chrF++评分为35.21分，相比未优化的模型提高了8.10分，几乎恢复到了原始领域内的质量水平。", "conclusion": "研究发现，性能提升主要由检索到的例子数量驱动，而不是特定的检索算法。大型语言模型作为“安全网”，能够有效修复零样本领域的严重翻译错误。"}}
{"id": "2601.09981", "pdf": "https://arxiv.org/pdf/2601.09981", "abs": "https://arxiv.org/abs/2601.09981", "authors": ["Yulin He", "Wei Chen", "Zhikang Jian", "Tianhang Guo", "Wenjuan Zhou", "Minglong Li"], "title": "DR$^2$Seg: Decomposed Two-Stage Rollouts for Efficient Reasoning Segmentation in Multimodal Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Reasoning segmentation is an emerging vision-language task that requires reasoning over intricate text queries to precisely segment objects. However, existing methods typically suffer from overthinking, generating verbose reasoning chains that interfere with object localization in multimodal large language models (MLLMs). To address this issue, we propose DR$^2$Seg, a self-rewarding framework that improves both reasoning efficiency and segmentation accuracy without requiring extra thinking supervision. DR$^2$Seg employs a two-stage rollout strategy that decomposes reasoning segmentation into multimodal reasoning and referring segmentation. In the first stage, the model generates a self-contained description that explicitly specifies the target object. In the second stage, this description replaces the original complex query to verify its self-containment. Based on this design, two self-rewards are introduced to strengthen goal-oriented reasoning and suppress redundant thinking. Extensive experiments across MLLMs of varying scales and segmentation models demonstrate that DR$^2$Seg consistently improves reasoning efficiency and overall segmentation performance.", "AI": {"tldr": "本文提出了DR$^2$Seg，一种自奖励框架，通过两阶段策略分解推理分割任务，提高多模态大语言模型中推理效率和分割准确性。", "motivation": "现有的推理分割方法通常存在过度思考问题，导致生成冗长的推理链，干扰对象定位。本文旨在解决这一问题，提高推理效率和分割准确性。", "method": "DR$^2$Seg采用两阶段回放策略，将推理分割任务分解为多模态推理和指代分割。第一阶段生成目标对象的自我包含描述；第二阶段使用该描述替换原始复杂查询以验证其自包含性，并引入两个自奖励机制来强化目标导向推理并抑制冗余思考。", "result": "实验表明，DR$^2$Seg在不同规模的多模态大语言模型和分割模型上均能提高推理效率和整体分割性能。", "conclusion": "本文提出的DR$^2$Seg框架能够有效解决过度思考问题，并显著提升多模态环境下的推理分割任务效果。"}}
{"id": "2601.09980", "pdf": "https://arxiv.org/pdf/2601.09980", "abs": "https://arxiv.org/abs/2601.09980", "authors": ["Angel Yanguas-Gil"], "title": "Performance of AI agents based on reasoning language models on ALD process optimization tasks", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.LG"], "comment": null, "summary": "In this work we explore the performance and behavior of reasoning large language models to autonomously optimize atomic layer deposition (ALD) processes. In the ALD process optimization task, an agent built on top of a reasoning LLM has to find optimal dose times for an ALD precursor and a coreactant without any prior knowledge on the process, including whether it is actually self-limited. The agent is meant to interact iteratively with an ALD reactor in a fully unsupervised way. We evaluate this agent using a simple model of an ALD tool that incorporates ALD processes with different self-limited surface reaction pathways as well as a non self-limited component. Our results show that agents based on reasoning models like OpenAI's o3 and GPT5 consistently succeeded at completing this optimization task. However, we observed significant run-to-run variability due to the non deterministic nature of the model's response. In order to understand the logic followed by the reasoning model, the agent uses a two step process in which the model first generates an open response detailing the reasoning process. This response is then transformed into a structured output. An analysis of these reasoning traces showed that the logic of the model was sound and that its reasoning was based on the notions of self-limited process and saturation expected in the case of ALD. However, the agent can sometimes be misled by its own prior choices when exploring the optimization space.", "AI": {"tldr": "研究了基于推理语言模型的AI代理在ALD过程优化任务中的表现和行为。", "motivation": "探索无先验知识的情况下，自主优化原子层沉积（ALD）过程的能力，特别是针对自限性表面反应路径的不同情况。", "method": "使用一个简单的ALD工具模型来评估基于推理语言模型的代理，该模型能够与ALD反应器进行迭代互动。代理首先生成描述推理过程的开放式响应，然后将其转换为结构化输出。", "result": "结果显示基于推理模型（如OpenAI的o3和GPT5）的代理能够在优化任务中取得成功，但观察到显著的运行间可变性。", "conclusion": "虽然代理的逻辑是合理的，且其推理以自限过程和ALD中的饱和预期为基础，但在探索优化空间时，有时会被先前的选择误导。"}}
{"id": "2601.09974", "pdf": "https://arxiv.org/pdf/2601.09974", "abs": "https://arxiv.org/abs/2601.09974", "authors": ["Seoyeon Kim", "Jaehyung Kim"], "title": "SPRInG: Continual LLM Personalization via Selective Parametric Adaptation and Retrieval-Interpolated Generation", "categories": ["cs.AI", "cs.CL"], "comment": "under review, 23 pages", "summary": "Personalizing Large Language Models typically relies on static retrieval or one-time adaptation, assuming user preferences remain invariant over time. However, real-world interactions are dynamic, where user interests continuously evolve, posing a challenge for models to adapt to preference drift without catastrophic forgetting. Standard continual learning approaches often struggle in this context, as they indiscriminately update on noisy interaction streams, failing to distinguish genuine preference shifts from transient contexts. To address this, we introduce SPRInG, a novel semi-parametric framework designed for effective continual personalization. During training, SPRInG employs drift-driven selective adaptation, which utilizes a likelihood-based scoring function to identify high-novelty interactions. This allows the model to selectively update the user-specific adapter on drift signals while preserving hard-to-learn residuals in a replay buffer. During inference, we apply strict relevance gating and fuse parametric knowledge with retrieved history via logit interpolation. Experiments on the long-form personalized generation benchmark demonstrate that SPRInG outperforms existing baselines, validating its robustness for real-world continual personalization.", "AI": {"tldr": "本文提出了SPRInG框架，用于通过选择性参数适应和检索插值生成实现大语言模型的持续个性化。", "motivation": "传统的个性化方法假设用户偏好是不变的，这在真实世界中并不成立。用户兴趣随时间变化，导致现有方法难以有效应对偏好漂移的问题而不发生灾难性遗忘。", "method": "SPRInG框架采用基于漂移的选择性适应策略，在训练过程中使用似然得分函数识别新颖交互并针对性地更新用户特定的适配器，并保留难学残差在回放缓冲区中。在推理时，通过严格的关联门控和参数知识与检索历史的logit插值融合。", "result": "实验表明，SPRInG在长篇个性化生成基准上超越了现有方法，验证了其对现实世界持续个性化的稳健性。", "conclusion": "该研究提出了有效的持续个性化策略，并通过实验证明了其有效性。"}}
{"id": "2601.09972", "pdf": "https://arxiv.org/pdf/2601.09972", "abs": "https://arxiv.org/abs/2601.09972", "authors": ["Zixun Lan", "Maochun Xu", "Yifan Ren", "Rui Wu", "Jianghui Zhou", "Xueyang Cheng", "Jianan Ding Ding", "Xinheng Wang", "Mingmin Chi", "Fei Ma"], "title": "Chinese Labor Law Large Language Model Benchmark", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have led to substantial progress in domain-specific applications, particularly within the legal domain. However, general-purpose models such as GPT-4 often struggle with specialized subdomains that require precise legal knowledge, complex reasoning, and contextual sensitivity. To address these limitations, we present LabourLawLLM, a legal large language model tailored to Chinese labor law. We also introduce LabourLawBench, a comprehensive benchmark covering diverse labor-law tasks, including legal provision citation, knowledge-based question answering, case classification, compensation computation, named entity recognition, and legal case analysis. Our evaluation framework combines objective metrics (e.g., ROUGE-L, accuracy, F1, and soft-F1) with subjective assessment based on GPT-4 scoring. Experiments show that LabourLawLLM consistently outperforms general-purpose and existing legal-specific LLMs across task categories. Beyond labor law, our methodology provides a scalable approach for building specialized LLMs in other legal subfields, improving accuracy, reliability, and societal value of legal AI applications.", "AI": {"tldr": "本文介绍了LabourLawLLM，一个专门针对中国劳动法的大型语言模型，并提出了涵盖多种劳动法律任务的基准测试LabourLawBench。", "motivation": "通用大模型如GPT-4在处理需要精确法律知识、复杂推理和情境敏感性的专业子领域时存在局限性。为了弥补这些不足，作者开发了专门针对中国劳动法领域的语言模型。", "method": "研究人员构建了LabourLawLLM大型语言模型，并设计了一个全面的基准测试LabourLawBench，用于评估模型在劳动法律相关任务上的表现。", "result": "实验表明，LabourLawLLM在各种任务类别上都超越了通用和现有的专门针对法律领域的大型语言模型。", "conclusion": "此方法提供了一种构建其他法律子领域专用大模型的可扩展方式，可以提高法律AI应用的准确性、可靠性和社会价值。"}}
{"id": "2601.09966", "pdf": "https://arxiv.org/pdf/2601.09966", "abs": "https://arxiv.org/abs/2601.09966", "authors": ["Ruoxi Jia", "Luis Oala", "Wenjie Xiong", "Suqin Ge", "Jiachen T. Wang", "Feiyang Kang", "Dawn Song"], "title": "A Sustainable AI Economy Needs Data Deals That Work for Generators", "categories": ["cs.LG", "cs.AI", "cs.HC"], "comment": "Published at NeurIPS 2025 (https://neurips.cc/virtual/2025/loc/san-diego/poster/121926)", "summary": "We argue that the machine learning value chain is structurally unsustainable due to an economic data processing inequality: each state in the data cycle from inputs to model weights to synthetic outputs refines technical signal but strips economic equity from data generators. We show, by analyzing seventy-three public data deals, that the majority of value accrues to aggregators, with documented creator royalties rounding to zero and widespread opacity of deal terms. This is not just an economic welfare concern: as data and its derivatives become economic assets, the feedback loop that sustains current learning algorithms is at risk. We identify three structural faults - missing provenance, asymmetric bargaining power, and non-dynamic pricing - as the operational machinery of this inequality. In our analysis, we trace these problems along the machine learning value chain and propose an Equitable Data-Value Exchange (EDVEX) Framework to enable a minimal market that benefits all participants. Finally, we outline research directions where our community can make concrete contributions to data deals and contextualize our position with related and orthogonal viewpoints.", "AI": {"tldr": "本文探讨了机器学习价值链中存在的结构性不可持续性问题，并提出了一种公正的数据价值交换框架（EDVEX）。", "motivation": "动机在于解决数据处理中的经济不平等，确保数据生成者能够从其贡献中获得应有的收益。", "method": "通过分析73个公共数据交易案例，识别出三个结构性缺陷并提出解决方案。", "result": "发现大多数价值归于聚合者，创作者的版税几乎为零，并揭示了合约条款的不透明性。", "conclusion": "提出了一个公正的数据价值交换框架（EDVEX），旨在创建一个使所有参与者受益的市场。"}}
{"id": "2601.09954", "pdf": "https://arxiv.org/pdf/2601.09954", "abs": "https://arxiv.org/abs/2601.09954", "authors": ["Nahid Alam", "Leema Krishna Murali", "Siddhant Bharadwaj", "Patrick Liu", "Timothy Chung", "Drishti Sharma", "Akshata A", "Kranthi Kiran", "Wesley Tam", "Bala Krishna S Vegesna"], "title": "The Spatial Blindspot of Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) have advanced rapidly, but their ability to capture spatial relationships remains a blindspot. Current VLMs are typically built with contrastive language-image pretraining (CLIP) style image encoders. The training recipe often flattens images into 1D patch sequences, discarding the 2D structure necessary for spatial reasoning. We argue that this lack of spatial awareness is a missing dimension in VLM design and a bottleneck for applications requiring spatial grounding, such as robotics and embodied AI. To address this, we investigate (i) image encoders trained with alternative objectives and (ii) 2D positional encodings. Our experiments show that these architectural choices can lead to improved spatial reasoning on several benchmarks.", "AI": {"tldr": "本文研究了视觉语言模型中空间意识不足的问题，并提出了解决方案。", "motivation": "当前的视觉语言模型在捕捉图像的空间关系方面存在盲点，限制了其在需要空间定位的应用中的表现，如机器人学和具身AI。", "method": "作者探究了使用替代目标训练的图像编码器以及2D位置编码的方法来改善视觉语言模型的空间意识。", "result": "实验表明，这些架构选择可以提高多个基准上的空间推理能力。", "conclusion": "研究强调了在视觉语言模型设计中加入空间维度的重要性，并展示了通过改进模型结构可以提升其在涉及空间理解任务中的性能。"}}
{"id": "2601.09952", "pdf": "https://arxiv.org/pdf/2601.09952", "abs": "https://arxiv.org/abs/2601.09952", "authors": ["Zhihua Zhao", "Guoqiang Li", "Chen Min", "Kangping Lu"], "title": "OT-Drive: Out-of-Distribution Off-Road Traversable Area Segmentation via Optimal Transport", "categories": ["cs.CV", "cs.RO"], "comment": "9 pages, 8 figures, 6 tables. This work has been submitted to the IEEE for possible publication. Code will be released upon acceptance", "summary": "Reliable traversable area segmentation in unstructured environments is critical for planning and decision-making in autonomous driving. However, existing data-driven approaches often suffer from degraded segmentation performance in out-of-distribution (OOD) scenarios, consequently impairing downstream driving tasks. To address this issue, we propose OT-Drive, an Optimal Transport--driven multi-modal fusion framework. The proposed method formulates RGB and surface normal fusion as a distribution transport problem. Specifically, we design a novel Scene Anchor Generator (SAG) to decompose scene information into the joint distribution of weather, time-of-day, and road type, thereby constructing semantic anchors that can generalize to unseen scenarios. Subsequently, we design an innovative Optimal Transport-based multi-modal fusion module (OT Fusion) to transport RGB and surface normal features onto the manifold defined by the semantic anchors, enabling robust traversable area segmentation under OOD scenarios. Experimental results demonstrate that our method achieves 95.16% mIoU on ORFD OOD scenarios, outperforming prior methods by 6.35%, and 89.79% mIoU on cross-dataset transfer tasks, surpassing baselines by 13.99%.These results indicate that the proposed model can attain strong OOD generalization with only limited training data, substantially enhancing its practicality and efficiency for real-world deployment.", "AI": {"tldr": "提出OT-Drive，一种基于最优传输的多模态融合框架，用于解决户外未知环境下的可行驶区域分割问题。", "motivation": "现有数据驱动方法在非分布数据场景中表现不佳，影响自动驾驶任务。因此，作者设计了OT-Drive以改进这种性能退化的问题。", "method": "通过设计Scene Anchor Generator(SAG)将场景信息分解为天气、时间和道路类型的联合分布，并使用最优传输多模态融合模块(OT Fusion)，将RGB和表面法线特征映射到由语义锚定义的流形上，从而实现更鲁棒的可行驶区域分割。", "result": "实验表明，在ORFD非分布场景中mIoU达到95.16%，超出先前方法6.35%；在跨数据集转移任务中，mIoU为89.79%，超越基线模型13.99%。", "conclusion": "所提出的方法能够以有限的训练数据实现强大的非分布泛化能力，显著增强其实用性和效率，适合现实世界部署。"}}
{"id": "2601.09949", "pdf": "https://arxiv.org/pdf/2601.09949", "abs": "https://arxiv.org/abs/2601.09949", "authors": ["Griffin Kearney"], "title": "Kinematic Tokenization: Optimization-Based Continuous-Time Tokens for Learnable Decision Policies in Noisy Time Series", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "Transformers are designed for discrete tokens, yet many real-world signals are continuous processes observed through noisy sampling. Discrete tokenizations (raw values, patches, finite differences) can be brittle in low signal-to-noise regimes, especially when downstream objectives impose asymmetric penalties that rationally encourage abstention. We introduce Kinematic Tokenization, an optimization-based continuous-time representation that reconstructs an explicit spline from noisy measurements and tokenizes local spline coefficients (position, velocity, acceleration, jerk). This is applied to financial time series data in the form of asset prices in conjunction with trading volume profiles. Across a multi-asset daily-equity testbed, we use a risk-averse asymmetric classification objective as a stress test for learnability. Under this objective, several discrete baselines collapse to an absorbing cash policy (the Liquidation Equilibrium), whereas the continuous spline tokens sustain calibrated, non-trivial action distributions and stable policies. These results suggest that explicit continuous-time tokens can improve the learnability and calibration of selective decision policies in noisy time series under abstention-inducing losses.", "AI": {"tldr": "介绍了一种基于优化的连续时间标记化方法（Kinematic Tokenization），用于改善在嘈杂的时间序列信号中的可学习决策策略。", "motivation": "现有的离散标记化方法在低信噪比的情况下容易不稳定，特别是在下游目标导致理性地倾向于避免行动时。因此，需要一种更稳定的方法来处理这种情况下连续时间序列数据的学习问题。", "method": "提出了Kinematic Tokenization方法，该方法通过从嘈杂的测量值中重建显式的样条曲线，并使用局部样条系数（位置、速度、加速度和冲击）来进行标记化。这种方法应用于金融时间序列数据中的资产价格和交易量概况。", "result": "在多个资产日度股票测试床上，采用风险规避的不对称分类目标作为学习能力的压力测试时，几种离散基准方法会崩溃到吸收现金策略（清算均衡），而连续样条标记则维持校准、非平凡的动作分布和稳定的政策。", "conclusion": "显式的连续时间标记可以提高在带有放弃诱导损失的时间序列中的可学习性和选择性决策策略的校准。"}}
{"id": "2601.09937", "pdf": "https://arxiv.org/pdf/2601.09937", "abs": "https://arxiv.org/abs/2601.09937", "authors": ["Saber Zerhoudi", "Michael Granitzer"], "title": "From SERPs to Agents: A Platform for Comparative Studies of Information Interaction", "categories": ["cs.HC", "cs.IR"], "comment": "ef:Proceedings of the 2026 ACM SIGIR Conference on Human Information Interaction and Retrieval (CHIIR '26)", "summary": "The diversification of information access systems, from RAG to autonomous agents, creates a critical need for comparative user studies. However, the technical overhead to deploy and manage these distinct systems is a major barrier. We present UXLab, an open-source system for web-based user studies that addresses this challenge. Its core is a web-based dashboard enabling the complete, no-code configuration of complex experimental designs. Researchers can visually manage the full study, from recruitment to comparing backends like traditional search, vector databases, and LLMs. We demonstrate UXLab's value via a micro case study comparing user behavior with RAG versus an autonomous agent. UXLab allows researchers to focus on experimental design and analysis, supporting future multi-modal interaction research.", "AI": {"tldr": "介绍了一个名为UXLab的开放源码平台，用于比较不同类型信息访问系统的用户研究。", "motivation": "随着信息获取系统多样化，从RAG到自主代理的发展，需要一种方法来降低部署和管理这些不同系统的技术负担，以便进行有效的用户研究。", "method": "开发了一个名为UXLab的开放源码平台，它提供一个基于网络的仪表板，允许无代码配置复杂的实验设计，并支持从招募参与者到比较后端系统（如传统搜索、向量数据库和LLM）的研究全流程管理。", "result": "通过一个小规模案例研究展示了UXLab的价值，该研究对比了用户使用RAG与自主代理时的行为差异。", "conclusion": "UXLab使得研究人员可以专注于实验设计和数据分析，支持未来多模态交互研究的发展。"}}
{"id": "2601.09933", "pdf": "https://arxiv.org/pdf/2601.09933", "abs": "https://arxiv.org/abs/2601.09933", "authors": ["Ashish Anand", "Bhupendra Singh", "Sunil Khemka", "Bireswar Banerjee", "Vishi Singh Bhatia", "Piyush Ranjan"], "title": "Malware Classification using Diluted Convolutional Neural Network with Fast Gradient Sign Method", "categories": ["cs.CR", "cs.AI", "cs.CE", "cs.LG"], "comment": "Accepted 2025 2nd International Conference on Software, Systems and Information Technology (SSITCON) Keywords data security, diluted convolutional neural network, fast gradient sign method, malware classification, privacy", "summary": "Android malware has become an increasingly critical threat to organizations, society and individuals, posing significant risks to privacy, data security and infrastructure. As malware continues to evolve in terms of complexity and sophistication, the mitigation and detection of these malicious software instances have become more time consuming and challenging particularly due to the requirement of large number of features to identify potential malware. To address these challenges, this research proposes Fast Gradient Sign Method with Diluted Convolutional Neural Network (FGSM DICNN) method for malware classification. DICNN contains diluted convolutions which increases receptive field, enabling the model to capture dispersed malware patterns across long ranges using fewer features without adding parameters. Additionally, the FGSM strategy enhance the accuracy by using one-step perturbations during training that provides more defensive advantage of lower computational cost. This integration helps to manage high classification accuracy while reducing the dependence on extensive feature sets. The proposed FGSM DICNN model attains 99.44% accuracy while outperforming other existing approaches such as Custom Deep Neural Network (DCNN).", "AI": {"tldr": "本文提出了一种使用Fast Gradient Sign Method与稀疏卷积神经网络相结合的方法用于恶意软件分类。", "motivation": "随着Android恶意软件威胁日益增加，识别潜在恶意软件变得愈发复杂和具有挑战性。本研究旨在通过减少对大量特征的依赖来提高检测效率并提升准确性。", "method": "采用FGSM稀疏卷积神经网络方法（FGSM DICNN），该模型利用稀疏卷积扩大接收范围，并通过训练中的一步扰动策略增强防御能力，同时降低计算成本。", "result": "提出的FGSM DICNN模型达到了99.44%的分类准确率，超越了其他现有方法如自定义深层神经网络（DCNN）。", "conclusion": "研究证明，基于稀疏卷积和一步扰动策略的方法可以在减少特征依赖的同时实现高精度恶意软件检测。"}}
{"id": "2601.09931", "pdf": "https://arxiv.org/pdf/2601.09931", "abs": "https://arxiv.org/abs/2601.09931", "authors": ["Jean-Eudes Ayilo", "Mostafa Sadeghi", "Romain Serizel", "Xavier Alameda-Pineda"], "title": "Diffusion-based Frameworks for Unsupervised Speech Enhancement", "categories": ["cs.SD"], "comment": null, "summary": "This paper addresses $\\textit{unsupervised}$ diffusion-based single-channel speech enhancement (SE). Prior work in this direction combines a score-based diffusion model trained on clean speech with a Gaussian noise model whose covariance is structured by non-negative matrix factorization (NMF). This combination is used within an iterative expectation-maximization (EM) scheme, in which a diffusion-based posterior-sampling E-step estimates the clean speech. We first revisit this framework and propose to explicitly model both speech and acoustic noise as latent variables, jointly sampling them in the E-step instead of sampling speech alone as in previous approaches. We then introduce a new unsupervised SE framework that replaces the NMF noise prior with a diffusion-based noise model, learned jointly with the speech prior in a single conditional score model. Within this framework, we derive two variants: one that implicitly accounts for noise and one that explicitly treats noise as a latent variable. Experiments on WSJ0-QUT and VoiceBank-DEMAND show that explicit noise modeling systematically improves SE performance for both NMF-based and diffusion-based noise priors. Under matched conditions, the diffusion-based noise model attains the best overall quality and intelligibility among unsupervised methods, while under mismatched conditions the proposed NMF-based explicit-noise framework is more robust and suffers less degradation than several supervised baselines. Our code will be publicly available on this $\\href{https://github.com/jeaneudesAyilo/enudiffuse}{URL}$.", "AI": {"tldr": "本文提出了基于扩散模型的无监督语音增强框架，并通过实验展示了其在不同条件下的性能。", "motivation": "文章旨在改进现有的无监督单通道语音增强方法，特别是探索如何通过显式建模噪声来提高语音质量。", "method": "作者提出了一种新的无监督SE框架，用扩散模型替代NMF噪音先验，并将其与语音先验联合学习。该框架包括两种变体：一种隐式处理噪声，另一种将噪声作为潜在变量显式对待。", "result": "实验表明，在匹配条件下，基于扩散的噪声模型在质量与可懂度方面优于其他无监督方法；而在不匹配条件下，提出的NMF基础上的显式噪声框架比几个有监督基准更稳健且降解较少。", "conclusion": "显式的噪声建模系统地提高了语音增强性能，并且新框架下的扩散模型和NMF模型分别在不同实验条件中展示了优势。"}}
{"id": "2601.09929", "pdf": "https://arxiv.org/pdf/2601.09929", "abs": "https://arxiv.org/abs/2601.09929", "authors": ["Ahmad Pesaranghader", "Erin Li"], "title": "Hallucination Detection and Mitigation in Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) and Large Reasoning Models (LRMs) offer transformative potential for high-stakes domains like finance and law, but their tendency to hallucinate, generating factually incorrect or unsupported content, poses a critical reliability risk. This paper introduces a comprehensive operational framework for hallucination management, built on a continuous improvement cycle driven by root cause awareness. We categorize hallucination sources into model, data, and context-related factors, allowing targeted interventions over generic fixes. The framework integrates multi-faceted detection methods (e.g., uncertainty estimation, reasoning consistency) with stratified mitigation strategies (e.g., knowledge grounding, confidence calibration). We demonstrate its application through a tiered architecture and a financial data extraction case study, where model, context, and data tiers form a closed feedback loop for progressive reliability enhancement. This approach provides a systematic, scalable methodology for building trustworthy generative AI systems in regulated environments.", "AI": {"tldr": "本文介绍了用于检测和缓解大型语言模型幻觉的综合操作框架，通过多方面检测方法与分层缓解策略提升可靠性。", "motivation": "大型语言模型在金融、法律等高风险领域具有巨大潜力，但其生成不准确或无支持内容的倾向构成关键可靠性风险。为此，提出一个基于根本原因意识和持续改进循环的操作框架来解决幻觉问题。", "method": "该框架将幻觉来源分为模型、数据和上下文相关因素，并整合了不确定性估计、推理一致性等多方面检测方法及知识接地、信心校准等分层缓解策略，形成闭环反馈系统以逐步提升可靠性。", "result": "通过金融数据提取案例研究展示了层级架构的应用效果，表明该框架能够有效增强生成AI系统的信任度。", "conclusion": "本研究提供了一种系统且可扩展的方法论，用于在监管环境中构建可信的生成性人工智能系统。"}}
{"id": "2601.09928", "pdf": "https://arxiv.org/pdf/2601.09928", "abs": "https://arxiv.org/abs/2601.09928", "authors": ["Saber Zerhoudi", "Michael Granitzer"], "title": "In-Browser Agents for Search Assistance", "categories": ["cs.HC", "cs.IR"], "comment": "ef:Proceedings of the 2026 ACM SIGIR Conference on Human Information Interaction and Retrieval (CHIIR '26)", "summary": "A fundamental tension exists between the demand for sophisticated AI assistance in web search and the need for user data privacy. Current centralized models require users to transmit sensitive browsing data to external services, which limits user control. In this paper, we present a browser extension that provides a viable in-browser alternative. We introduce a hybrid architecture that functions entirely on the client side, combining two components: (1) an adaptive probabilistic model that learns a user's behavioral policy from direct feedback, and (2) a Small Language Model (SLM), running in the browser, which is grounded by the probabilistic model to generate context-aware suggestions. To evaluate this approach, we conducted a three-week longitudinal user study with 18 participants. Our results show that this privacy-preserving approach is highly effective at adapting to individual user behavior, leading to measurably improved search efficiency. This work demonstrates that sophisticated AI assistance is achievable without compromising user privacy or data control.", "AI": {"tldr": "该论文介绍了一种浏览器扩展，提供了一个完全在客户端运行的混合架构，以实现隐私保护的同时提高搜索效率。", "motivation": "解决用户对复杂AI辅助搜索的需求与保护用户数据隐私之间的矛盾，减少将敏感浏览数据传输到外部服务的问题。", "method": "通过一个自适应概率模型结合直接反馈学习用户行为策略，并在浏览器中运行一个小语言模型来生成上下文感知的建议。", "result": "进行了一项为期三周、涉及18名参与者的纵向用户研究，结果显示该隐私保护方法能有效适应个体用户行为，显著提高搜索效率。", "conclusion": "证明了无需牺牲用户隐私或数据控制即可实现复杂的AI辅助功能。"}}
{"id": "2601.09923", "pdf": "https://arxiv.org/pdf/2601.09923", "abs": "https://arxiv.org/abs/2601.09923", "authors": ["Hanna Foerster", "Robert Mullins", "Tom Blanchard", "Nicolas Papernot", "Kristina Nikolić", "Florian Tramèr", "Ilia Shumailov", "Cheng Zhang", "Yiren Zhao"], "title": "CaMeLs Can Use Computers Too: System-level Security for Computer Use Agents", "categories": ["cs.AI"], "comment": null, "summary": "AI agents are vulnerable to prompt injection attacks, where malicious content hijacks agent behavior to steal credentials or cause financial loss. The only known robust defense is architectural isolation that strictly separates trusted task planning from untrusted environment observations. However, applying this design to Computer Use Agents (CUAs) -- systems that automate tasks by viewing screens and executing actions -- presents a fundamental challenge: current agents require continuous observation of UI state to determine each action, conflicting with the isolation required for security. We resolve this tension by demonstrating that UI workflows, while dynamic, are structurally predictable. We introduce Single-Shot Planning for CUAs, where a trusted planner generates a complete execution graph with conditional branches before any observation of potentially malicious content, providing provable control flow integrity guarantees against arbitrary instruction injections. Although this architectural isolation successfully prevents instruction injections, we show that additional measures are needed to prevent Branch Steering attacks, which manipulate UI elements to trigger unintended valid paths within the plan. We evaluate our design on OSWorld, and retain up to 57% of the performance of frontier models while improving performance for smaller open-source models by up to 19%, demonstrating that rigorous security and utility can coexist in CUAs.", "AI": {"tldr": "本文提出了单次计划方法，以实现计算机使用代理（CUA）的系统级安全，并防止指令注入和分支操控攻击。", "motivation": "AI代理容易受到恶意提示注入攻击，现有防御机制如架构隔离不适用于需要持续观察用户界面状态的CUAs，因此提出新方案解决这一问题。", "method": "引入单次计划方法，通过可信规划者在任何潜在恶意内容被观察之前生成完整的执行图来提供可证明控制流完整性保证，并采用额外措施防止分支操控攻击。", "result": "实验结果表明该设计能够在OSWorld上保持前沿模型性能的57%，同时提高小规模开源模型性能最多19%。", "conclusion": "本文展示了一种严格的安全和实用性可以在CUAs中共存的设计方案。"}}
{"id": "2601.09921", "pdf": "https://arxiv.org/pdf/2601.09921", "abs": "https://arxiv.org/abs/2601.09921", "authors": ["Kai Zhang", "Zhengzhong Yi", "Shaojun Guo", "Linghang Kong", "Situ Wang", "Xiaoyu Zhan", "Tan He", "Weiping Lin", "Tao Jiang", "Dongxin Gao", "Yiming Zhang", "Fangming Liu", "Fang Zhang", "Zhengfeng Ji", "Fusheng Chen", "Jianxin Chen"], "title": "Learning to Decode in Parallel: Self-Coordinating Neural Network for Real-Time Quantum Error Correction", "categories": ["quant-ph", "cs.AI"], "comment": "The main text consists of 25 pages and 9 figures, extending our prior work (arXiv:2509.03815) with new results on surface code decoding in superconducting qubit systems and real-time performance benchmarks on TPU v6e", "summary": "Fast, reliable decoders are pivotal components for enabling fault-tolerant quantum computation (FTQC). Neural network decoders like AlphaQubit have demonstrated potential, achieving higher accuracy than traditional human-designed decoding algorithms. However, existing implementations of neural network decoders lack the parallelism required to decode the syndrome stream generated by a superconducting logical qubit in real time. Moreover, integrating AlphaQubit with sliding window-based parallel decoding schemes presents non-trivial challenges: AlphaQubit is trained solely to output a single bit corresponding to the global logical correction for an entire memory experiment, rather than local physical corrections that can be easily integrated. We address this issue by training a recurrent, transformer-based neural network specifically tailored for parallel window decoding. While it still outputs a single bit, we derive training labels from a consistent set of local corrections and train on various types of decoding windows simultaneously. This approach enables the network to self-coordinate across neighboring windows, facilitating high-accuracy parallel decoding of arbitrarily long memory experiments. As a result, we overcome the throughput bottleneck that previously precluded the use of AlphaQubit-type decoders in FTQC. Our work presents the first scalable, neural-network-based parallel decoding framework that simultaneously achieves SOTA accuracy and the stringent throughput required for real-time quantum error correction. Using an end-to-end experimental workflow, we benchmark our decoder on the Zuchongzhi 3.2 superconducting quantum processor on surface codes with distances up to 7, demonstrating its superior accuracy. Moreover, we demonstrate that, using our approach, a single TPU v6e is capable of decoding surface codes with distances up to 25 within 1us per decoding round.", "AI": {"tldr": "开发了一种自我协调的神经网络解码器，以实现实时量子错误校正。", "motivation": "现有的神经网络解码器缺乏实时处理超导逻辑量子比特生成的综合流所需的并行性。AlphaQubit无法轻松集成到滑动窗口并行解码方案中，因此需要开发新的解决方案来克服这一瓶颈。", "method": "训练了一个基于循环变压器的神经网络，用于平行窗口解码，并通过一系列类型的解码窗口同时进行训练以实现自我协调。", "result": "在Zuchongzhi 3.2超导量子处理器上使用表面代码进行了基准测试，展示了其优越的准确性。此外，单个TPU v6e能够在1微秒内解码距离达25的表面代码。", "conclusion": "开发了一种可扩展的、基于神经网络的并行解码框架，它能够同时达到SOTA准确性和实时量子错误校正所需的吞吐量。"}}
{"id": "2601.09920", "pdf": "https://arxiv.org/pdf/2601.09920", "abs": "https://arxiv.org/abs/2601.09920", "authors": ["Ruopeng Huang", "Boyu Yang", "Wenlong Gui", "Jeremy Morgan", "Erdem Biyik", "Jiachen Li"], "title": "SyncTwin: Fast Digital Twin Construction and Synchronization for Safe Robotic Grasping", "categories": ["cs.RO"], "comment": null, "summary": "Accurate and safe grasping under dynamic and visually occluded conditions remains a core challenge in real-world robotic manipulation. We present SyncTwin, a digital twin framework that unifies fast 3D scene reconstruction and real-to-sim synchronization for robust and safety-aware grasping in such environments. In the offline stage, we employ VGGT to rapidly reconstruct object-level 3D assets from RGB images, forming a reusable geometry library for simulation. During execution, SyncTwin continuously synchronizes the digital twin by tracking real-world object states via point cloud segmentation updates and aligning them through colored-ICP registration. The updated twin enables motion planners to compute collision-free and dynamically feasible trajectories in simulation, which are safely executed on the real robot through a closed real-to-sim-to-real loop. Experiments in dynamic and occluded scenes show that SyncTwin improves grasp accuracy and motion safety, demonstrating the effectiveness of digital-twin synchronization for real-world robotic execution.", "AI": {"tldr": "SyncTwin 是一种数字孪生框架，旨在通过快速的三维场景重建和真实到模拟同步来提高动态和视觉遮挡条件下的安全抓取。", "motivation": "准确且安全地在动态及视觉遮挡环境下进行抓握是现实世界机器人操作的核心挑战。研究提出 SyncTwin 来解决这个难题。", "method": "SyncTwin 包括离线阶段使用 VGGT 快速重建三维资产，以及执行阶段通过点云分割更新和彩色ICP注册持续同步数字孪生。", "result": "实验表明，在动态和遮挡场景中，SyncTwin 提高了抓取精度并增强了运动安全性，展示了数字孪生同步在实际机器人操作中的有效性。", "conclusion": "研究证明了 SyncTwin 能够有效地提升机器人在复杂环境下的抓握安全性和准确性。"}}
{"id": "2601.09913", "pdf": "https://arxiv.org/pdf/2601.09913", "abs": "https://arxiv.org/abs/2601.09913", "authors": ["Joe Logan"], "title": "Continuum Memory Architectures for Long-Horizon LLM Agents", "categories": ["cs.AI", "cs.IR"], "comment": "10 Pages", "summary": "Retrieval-augmented generation (RAG) has become the default strategy for providing large language model (LLM) agents with contextual knowledge. Yet RAG treats memory as a stateless lookup table: information persists indefinitely, retrieval is read-only, and temporal continuity is absent. We define the \\textit{Continuum Memory Architecture} (CMA), a class of systems that maintain and update internal state across interactions through persistent storage, selective retention, associative routing, temporal chaining, and consolidation into higher-order abstractions. Rather than disclosing implementation specifics, we specify the architectural requirements CMA imposes and show consistent behavioral advantages on tasks that expose RAG's structural inability to accumulate, mutate, or disambiguate memory. The empirical probes (knowledge updates, temporal association, associative recall, contextual disambiguation) demonstrate that CMA is a necessary architectural primitive for long-horizon agents while highlighting open challenges around latency, drift, and interpretability.", "AI": {"tldr": "本文提出了一种名为连续记忆架构（CMA）的方法，用于改进大型语言模型代理的记忆功能。", "motivation": "传统的检索增强生成方法存在记忆状态化的问题，无法有效积累、修改或澄清记忆。因此需要一种新的记忆体系结构来解决这些问题。", "method": "定义了连续记忆架构(CMA)，该类系统通过持久存储、选择性保留、关联路由、时间链结和抽象整合来维护和更新跨交互的内部状态。", "result": "实证研究表明CMA在知识更新、时间关联、联想回忆、上下文澄清任务中优于传统的检索增强生成方法，展示了其作为长期代理必要架构原语的优势。", "conclusion": "尽管CMA显示出明显的性能优势，但仍存在延迟、漂移和可解释性等方面的挑战。"}}
{"id": "2601.09903", "pdf": "https://arxiv.org/pdf/2601.09903", "abs": "https://arxiv.org/abs/2601.09903", "authors": ["Adrien Renaudineau", "Mamadou Hawa Diallo", "Théo Dupuis", "Bastien Imbert", "Mohammed Akib Iftakher", "Kamel-Eddine Harabi", "Clément Turck", "Tifenn Hirtzlin", "Djohan Bonnet", "Franck Melul", "Jorge-Daniel Aguirre-Morales", "Elisa Vianello", "Marc Bocquet", "Jean-Michel Portal", "Damien Querlioz"], "title": "Forward-only learning in memristor arrays with month-scale stability", "categories": ["cs.ET"], "comment": null, "summary": "Turning memristor arrays from efficient inference engines into systems capable of on-chip learning has proved difficult. Weight updates have a high energy cost and cause device wear, analog states drift, and backpropagation requires a backward pass with reversed signal flow. Here we experimentally demonstrate learning on standard filamentary HfOx/Ti arrays that addresses these challenges with two design choices. First, we realize that standard filamentary HfOx/Ti memristors support sub-1 V reset-only pulses that cut energy, improve endurance, and yield stable analog states. Second, we rely on forward-only training algorithms derived from Hinton's Forward-Forward that use only inference-style operations. We train two-layer classifiers on an ImageNet-resolution four-class task using arrays up to 8,064 devices. Two forward-only variants, the double-pass supervised Forward-Forward and a single-pass competitive rule, achieve test accuracies of 89.5% and 89.6%, respectively; a reference experiment using backpropagation reaches 90.0%. Across five independent runs per method, these accuracies match within statistical uncertainty. Trained models retain accuracy for at least one month under ambient conditions, consistent with the stability of reset-only states. Sub-1 V reset updates use 460 times less energy than conventional program-and-verify programming and require just 46% more energy than inference-only operation. Together, these results establish forward-only, sub-1 V learning on standard filamentary stacks at array scale, outlining a practical, pulse-aware route to adaptive edge intelligence.", "AI": {"tldr": "该论文展示了在标准HfOx/Ti忆阻器阵列上实现前向学习，并且这些模型具有一个月以上的稳定性。", "motivation": "将忆阻器阵列从高效的推理引擎转变为能够进行芯片内学习的系统面临高能耗、设备磨损和模拟状态漂移等挑战，因此寻求解决这些问题的方法。", "method": "该研究通过两种设计选择实现前向学习：使用低于1V的复位脉冲降低能耗并提高耐久性；采用仅需推理操作的前向训练算法，包括双通道监督式前向-前向和单次竞争规则。", "result": "在ImageNet分辨率下的四类任务上，两种前向变体分别达到了89.5%和89.6%的测试准确率；与使用反向传播的参考实验相比，这些准确率在统计不确定性范围内匹配。训练后的模型至少一个月内保持准确性。", "conclusion": "研究结果表明，在标准薄膜堆栈上实现低于1V的前向学习，并为边缘智能提供实用且脉冲感知的路径。"}}
{"id": "2601.09902", "pdf": "https://arxiv.org/pdf/2601.09902", "abs": "https://arxiv.org/abs/2601.09902", "authors": ["Jack Wilkie", "Hanan Hindy", "Craig Michie", "Christos Tachtatzis", "James Irvine", "Robert Atkinson"], "title": "A Novel Contrastive Loss for Zero-Day Network Intrusion Detection", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.NI"], "comment": "Published in: IEEE Transactions on Network Service and Management (TNSM), 2026. Official version: https://ieeexplore.ieee.org/document/11340750 Code: https://github.com/jackwilkie/CLOSR", "summary": "Machine learning has achieved state-of-the-art results in network intrusion detection; however, its performance significantly degrades when confronted by a new attack class -- a zero-day attack. In simple terms, classical machine learning-based approaches are adept at identifying attack classes on which they have been previously trained, but struggle with those not included in their training data. One approach to addressing this shortcoming is to utilise anomaly detectors which train exclusively on benign data with the goal of generalising to all attack classes -- both known and zero-day. However, this comes at the expense of a prohibitively high false positive rate. This work proposes a novel contrastive loss function which is able to maintain the advantages of other contrastive learning-based approaches (robustness to imbalanced data) but can also generalise to zero-day attacks. Unlike anomaly detectors, this model learns the distributions of benign traffic using both benign and known malign samples, i.e. other well-known attack classes (not including the zero-day class), and consequently, achieves significant performance improvements. The proposed approach is experimentally verified on the Lycos2017 dataset where it achieves an AUROC improvement of .000065 and .060883 over previous models in known and zero-day attack detection, respectively. Finally, the proposed method is extended to open-set recognition achieving OpenAUC improvements of .170883 over existing approaches.", "AI": {"tldr": "本文提出了一种新的对比损失函数，用于零日网络入侵检测，并在实验中验证了其性能优于现有模型。", "motivation": "现有的机器学习方法在网络入侵检测中的表现不佳，特别是在遇到新型（零日）攻击时。异常检测器虽然可以识别所有类型的攻击但误报率很高。因此，本文旨在开发一种更有效的检测方法来应对这个问题。", "method": "提出了一种新的对比损失函数，该函数不仅能够利用良性数据和已知恶意样本学习正常流量分布以提高对零日攻击的识别能力，还能保持处理不平衡数据的优势。", "result": "实验结果显示，在Lycos2017数据集上，新方法在已知攻击检测中的AUROC提高了0.000065，在零日攻击检测中提升了0.060883，并且在开放集识别任务上的OpenAUC有了显著提升（提高值为0.170883）。", "conclusion": "本文提出的对比损失函数能够有效地提高网络入侵检测系统对已知和未知攻击的准确性和鲁棒性。"}}
{"id": "2601.09898", "pdf": "https://arxiv.org/pdf/2601.09898", "abs": "https://arxiv.org/abs/2601.09898", "authors": ["David Elsweiler", "Christine Elsweiler", "Anna Ziegner"], "title": "Cooking Up Politeness in Human-AI Information Seeking Dialogue", "categories": ["cs.HC"], "comment": null, "summary": "Politeness is a core dimension of human communication, yet its role in human-AI information seeking remains underexplored. We investigate how user politeness behaviour shapes conversational outcomes in a cooking-assistance setting. First, we annotated 30 dialogues, identifying four distinct user clusters ranging from Hyperpolite to Hyperefficient. We then scaled up to 18,000 simulated conversations across five politeness profiles (including impolite) and three open-weight models. Results show that politeness is not only cosmetic: it systematically affects response length, informational gain, and efficiency. Engagement-seeking prompts produced up to 90% longer replies and 38% more information nuggets than hyper-efficient prompts, but at markedly lower density. Impolite inputs yielded verbose but less efficient answers, with up to 48% fewer nuggets per watt-hour compared to polite input. These findings highlight politeness as both a fairness and sustainability issue: conversational styles can advantage or disadvantage users, and \"polite\" requests may carry hidden energy costs. We discuss implications for inclusive and resource-aware design of information agents.", "AI": {"tldr": "研究探讨了用户在与AI进行烹饪协助对话中的礼貌行为如何影响对话结果。", "motivation": "礼貌是人类沟通的核心维度，但其在人机信息寻求交流中的作用尚未充分探索。", "method": "首先注释30个对话并识别出四个不同的用户集群；然后模拟18,000次对话来评估五种礼貌配置文件和三个开放权重模型的表现。", "result": "发现礼貌不仅是一种表面现象，它还系统地影响了回复长度、信息增益和效率。礼貌请求可能导致更长的回复但信息密度较低，不礼貌输入则产生了冗长且低效的回答。", "conclusion": "研究结果强调了礼貌不仅是公平问题，也是可持续性问题：不同的对话风格可能会给予或剥夺用户的优势，并可能带来隐藏的能量消耗成本。"}}
{"id": "2601.09896", "pdf": "https://arxiv.org/pdf/2601.09896", "abs": "https://arxiv.org/abs/2601.09896", "authors": ["Jordan Taylor", "William Agnew", "Maarten Sap", "Sarah E. Fox", "Haiyi Zhu"], "title": "The Algorithmic Gaze: An Audit and Ethnography of the LAION-Aesthetics Predictor Model", "categories": ["cs.HC", "cs.AI", "cs.CV"], "comment": null, "summary": "Visual generative AI models are trained using a one-size-fits-all measure of aesthetic appeal. However, what is deemed \"aesthetic\" is inextricably linked to personal taste and cultural values, raising the question of whose taste is represented in visual generative AI models. In this work, we study an aesthetic evaluation model--LAION Aesthetic Predictor (LAP)--that is widely used to curate datasets to train visual generative image models, like Stable Diffusion, and evaluate the quality of AI-generated images. To understand what LAP measures, we audited the model across three datasets. First, we examined the impact of aesthetic filtering on the LAION-Aesthetics Dataset (approximately 1.2B images), which was curated from LAION-5B using LAP. We find that the LAP disproportionally filters in images with captions mentioning women, while filtering out images with captions mentioning men or LGBTQ+ people. Then, we used LAP to score approximately 330k images across two art datasets, finding the model rates realistic images of landscapes, cityscapes, and portraits from western and Japanese artists most highly. In doing so, the algorithmic gaze of this aesthetic evaluation model reinforces the imperial and male gazes found within western art history. In order to understand where these biases may have originated, we performed a digital ethnography of public materials related to the creation of LAP. We find that the development of LAP reflects the biases we found in our audits, such as the aesthetic scores used to train LAP primarily coming from English-speaking photographers and western AI-enthusiasts. In response, we discuss how aesthetic evaluation can perpetuate representational harms and call on AI developers to shift away from prescriptive measures of \"aesthetics\" toward more pluralistic evaluation.", "AI": {"tldr": "本文研究了LAION美学预测器（LAP）模型，分析其在图像生成AI训练中的偏见。", "motivation": "视觉生成式AI模型使用统一的审美标准进行训练，但“美”的定义与个人品味和文化价值观紧密相关。文章旨在探究LAP模型代表谁的审美。", "method": "对LAION美学数据集（约12亿张图像）进行了审计，并在两个艺术数据集中评估了30多万张图像，同时进行了LAP创建过程的相关数字民族志研究。", "result": "发现LAP倾向于过滤包含女性主题的图片，而排除男性或LGBTQ+主题的图片。LAP评分最高的图片多为来自西方和日本艺术家的真实景观、城市景象及人像画。", "conclusion": "算法审美标准强化了西方艺术史中的帝国主义和男性视角偏见，呼吁AI开发者转向更为多元化的评价体系以避免代表性伤害。"}}
{"id": "2601.09887", "pdf": "https://arxiv.org/pdf/2601.09887", "abs": "https://arxiv.org/abs/2601.09887", "authors": ["Rostyslav Hnatyshyn", "Danny Perez", "Gerik Scheuermann", "Ross Maciejewski", "Baldwin Nsonga"], "title": "LAMDA: Aiding Visual Exploration of Atomic Displacements in Molecular Dynamics Simulations", "categories": ["cs.HC"], "comment": "Accepted version of paper published in Transactions for Visualization and Computer Graphics", "summary": "Contemporary materials science research is heavily conducted in silico, involving massive simulations of the atomic-scale evolution of materials. Cataloging basic patterns in the atomic displacements is key to understanding and predicting the evolution of physical properties. However, the combinatorial complexity of the space of possible transitions coupled with the overwhelming amount of data being produced by high-throughput simulations make such an analysis extremely challenging and time-consuming for domain experts. The development of visual analytics systems that facilitate the exploration of simulation data is an active field of research. While these systems excel in identifying temporal regions of interest, they treat each timestep of a simulation as an independent event without considering the behavior of the atomic displacements between timesteps. We address this gap by introducing LAMDA, a visual analytics system that allows domain experts to quickly and systematically explore state-to-state transitions. In LAMDA, transitions are hierarchically categorized, providing a basis for cataloging displacement behavior, as well as enabling the analysis of simulations at different resolutions, ranging from very broad qualitative classes of transitions to very narrow definitions of unit processes. LAMDA supports navigating the hierarchy of transitions, enabling scientists to visualize the commonalities between different transitions in each class in terms of invariant features characterizing local atomic environments, and LAMDA simplifies the analysis by capturing user inputs through annotations. We evaluate our system through a case study and report on findings from our domain experts.", "AI": {"tldr": "开发了一种名为LAMDA的视觉分析系统，帮助领域专家快速和系统地探索分子动力学模拟中的原子位移状态转换。", "motivation": "由于大规模材料科学仿真数据复杂度高且数量庞大，现有的可视化分析工具未能充分考虑时间步长之间的原子位移行为。因此，需要开发一种新的工具来有效处理这些挑战并支持对模拟数据的快速探索。", "method": "LAMDA系统通过分层分类状态转换，提供从广泛定性的转换类别到狭窄定义单元过程的不同分辨率分析，并允许科学家导航和可视化不同类别的过渡之间的共性。", "result": "通过对案例研究的评估，该论文报告了领域专家使用LAMDA进行分析时发现的结果。", "conclusion": "通过引入LAMDA系统，实现了对分子动力学模拟中基本原子位移模式更有效的识别和理解。"}}
{"id": "2601.09883", "pdf": "https://arxiv.org/pdf/2601.09883", "abs": "https://arxiv.org/abs/2601.09883", "authors": ["Xinxing Ren", "Quagmire Zang", "Caelum Forder", "Suman Deb", "Ahsen Tahir", "Roman J. Georgio", "Peter Carroll", "Zekun Guo"], "title": "Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents Paradigm via Agent-to-Agent Communication from CORAL", "categories": ["cs.AI"], "comment": null, "summary": "Most existing Large Language Model (LLM)-based Multi-Agent Systems (MAS) rely on predefined workflows, where human engineers enumerate task states in advance and specify routing rules and contextual injections accordingly. Such workflow-driven designs are essentially rule-based decision trees, which suffer from two fundamental limitations: they require substantial manual effort to anticipate and encode possible task states, and they cannot exhaustively cover the state space of complex real-world tasks. To address these issues, we propose an Information-Flow-Orchestrated Multi-Agent Paradigm via Agent-to-Agent (A2A) Communication from CORAL, in which a dedicated information flow orchestrator continuously monitors task progress and dynamically coordinates other agents through the A2A toolkit using natural language, without relying on predefined workflows. We evaluate our approach on the general-purpose benchmark GAIA, using the representative workflow-based MAS OWL as the baseline while controlling for agent roles and underlying models. Under the pass@1 setting, our method achieves 63.64% accuracy, outperforming OWL's 55.15% by 8.49 percentage points with comparable token consumption. Further case-level analysis shows that our paradigm enables more flexible task monitoring and more robust handling of edge cases. Our implementation is publicly available at: https://github.com/Coral-Protocol/Beyond-Rule-Based-Workflows", "AI": {"tldr": "本文提出了一种基于信息流编排的多代理系统，通过代理间的自然语言沟通来动态协调任务，而不依赖于预定义的工作流程。", "motivation": "现有的大型语言模型（LLM）驱动的多代理系统主要依赖于预设的工作流程和路由规则，这需要大量的手动工作并且无法全面覆盖复杂现实任务的状态空间。", "method": "通过一个专门的信息流编排器持续监控任务进度并通过A2A工具包使用自然语言动态协调其他代理来实现任务。", "result": "在GAIA通用基准测试中，该方法的准确率达到63.64%，比基于工作流程的多代理系统OWL高出8.49个百分点，并且具有相似的令牌消耗。", "conclusion": "实验表明，所提出的范式能够提供更加灵活的任务监控和更强大的边缘情况处理能力。"}}
{"id": "2601.09881", "pdf": "https://arxiv.org/pdf/2601.09881", "abs": "https://arxiv.org/abs/2601.09881", "authors": ["Weili Nie", "Julius Berner", "Nanye Ma", "Chao Liu", "Saining Xie", "Arash Vahdat"], "title": "Transition Matching Distillation for Fast Video Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Large video diffusion and flow models have achieved remarkable success in high-quality video generation, but their use in real-time interactive applications remains limited due to their inefficient multi-step sampling process. In this work, we present Transition Matching Distillation (TMD), a novel framework for distilling video diffusion models into efficient few-step generators. The central idea of TMD is to match the multi-step denoising trajectory of a diffusion model with a few-step probability transition process, where each transition is modeled as a lightweight conditional flow. To enable efficient distillation, we decompose the original diffusion backbone into two components: (1) a main backbone, comprising the majority of early layers, that extracts semantic representations at each outer transition step; and (2) a flow head, consisting of the last few layers, that leverages these representations to perform multiple inner flow updates. Given a pretrained video diffusion model, we first introduce a flow head to the model, and adapt it into a conditional flow map. We then apply distribution matching distillation to the student model with flow head rollout in each transition step. Extensive experiments on distilling Wan2.1 1.3B and 14B text-to-video models demonstrate that TMD provides a flexible and strong trade-off between generation speed and visual quality. In particular, TMD outperforms existing distilled models under comparable inference costs in terms of visual fidelity and prompt adherence. Project page: https://research.nvidia.com/labs/genair/tmd", "AI": {"tldr": "提出Transition Matching Distillation（TMD）框架，将视频扩散模型高效地转换为快速的几步生成器。", "motivation": "尽管大规模的视频扩散和流模型在高质量视频生成方面取得了显著成功，但由于其多步骤采样过程效率低，这些模型在实时交互应用中的使用仍然受到限制。TMD旨在解决这个问题，通过匹配扩散模型的多步去噪轨迹与几步步概率转换过程来提高速度。", "method": "TMD框架将原始扩散模型分解为两部分：主要骨干（提取每个外过渡步骤的语义表示）和流头（利用这些表示进行多次内部流程更新）。首先，向预训练视频扩散模型引入一个流头并适应成条件流动图。然后，在每一步转换过程中对带流头的学生模型执行分布匹配蒸馏。", "result": "实验表明，在保持视觉质量和提示一致性的同时，TMD在推理成本相当的情况下优于现有的精炼模型。", "conclusion": "该研究提出的方法为高质量视频生成提供了一种灵活且强大的速度和质量权衡方案。"}}
{"id": "2601.09879", "pdf": "https://arxiv.org/pdf/2601.09879", "abs": "https://arxiv.org/abs/2601.09879", "authors": ["Yang Xing", "Jiong Wu", "Savas Ozdemir", "Ying Zhang", "Yang Yang", "Wei Shao", "Kuang Gong"], "title": "MedVL-SAM2: A unified 3D medical vision-language model for multimodal reasoning and prompt-driven segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent progress in medical vision-language models (VLMs) has achieved strong performance on image-level text-centric tasks such as report generation and visual question answering (VQA). However, achieving fine-grained visual grounding and volumetric spatial reasoning in 3D medical VLMs remains challenging, particularly when aiming to unify these capabilities within a single, generalizable framework. To address this challenge, we proposed MedVL-SAM2, a unified 3D medical multimodal model that concurrently supports report generation, VQA, and multi-paradigm segmentation, including semantic, referring, and interactive segmentation. MedVL-SAM2 integrates image-level reasoning and pixel-level perception through a cohesive architecture tailored for 3D medical imaging, and incorporates a SAM2-based volumetric segmentation module to enable precise multi-granular spatial reasoning. The model is trained in a multi-stage pipeline: it is first pre-trained on a large-scale corpus of 3D CT image-text pairs to align volumetric visual features with radiology-language embeddings. It is then jointly optimized with both language-understanding and segmentation objectives using a comprehensive 3D CT segmentation dataset. This joint training enables flexible interaction via language, point, or box prompts, thereby unifying high-level visual reasoning with spatially precise localization. Our unified architecture delivers state-of-the-art performance across report generation, VQA, and multiple 3D segmentation tasks. Extensive analyses further show that the model provides reliable 3D visual grounding, controllable interactive segmentation, and robust cross-modal reasoning, demonstrating that high-level semantic reasoning and precise 3D localization can be jointly achieved within a unified 3D medical VLM.", "AI": {"tldr": "提出了MedVL-SAM2，一个统一的三维医学视觉语言模型，支持报告生成、VQA和多种模式分割。", "motivation": "现有的医学视觉语言模型在图像级文本相关任务上表现良好，但在实现细粒度可视化定位和体积空间推理方面仍面临挑战，特别是要将其整合在一个通用框架中。", "method": "MedVL-SAM2通过一个专为3D医学成像设计的统一架构集成了图像级推理和像素级感知，并结合基于SAM2的体素分割模块，支持灵活的语言、点或框提示交互。模型首先在大规模的三维CT图-文对上预训练，然后使用全面的3D CT分割数据集进行语言理解和分割目标的联合优化。", "result": "该统一架构实现了报告生成、VQA和多个3D分割任务中的最先进性能，展示了可靠的3D可视化定位、可控制的交互式分割以及跨模态推理能力。", "conclusion": "研究证明了高级语义推理与精确的三维定位可以在一个统一的3D医学视觉语言模型中实现，并且通过多阶段训练管道和SAM2模块实现了这些功能的融合。"}}
{"id": "2601.09877", "pdf": "https://arxiv.org/pdf/2601.09877", "abs": "https://arxiv.org/abs/2601.09877", "authors": ["Paulius Jurcys", "Ashley Greenwald", "Mark Fenwick", "Valto Loikkanen", "Sebastian Porsdam Mann", "Brian D. Earp"], "title": "Who Owns My AI Twin? Data Ownership in a New World of Simulated Identities", "categories": ["cs.HC"], "comment": null, "summary": "The emergence of AI twins, digital replicas that encapsulate an individual's knowledge, memories, psychological traits, and behavioral patterns, raises novel legal and ethical challenges for data governance and personal identity. Built from personal data, these systems require a rethinking of what it means to exercise dominion over one's data and to maintain personal autonomy in an AI-mediated environment. This article argues that natural persons should be recognized as the moral and legal owners of their AI twins, which function as intimate extensions of the self rather than as proprietary technological artifacts. It critiques prevailing legal frameworks that prioritize technological infrastructure and platform control over data and individual autonomy, exposing their structural limitations. In response, the article advances a human-centric model of data governance grounded in individual dominion and a private-by-default principle. This approach proposes a reimagined social contract for AI-driven identities that strengthens personal agency, promotes equitable data stewardship, and better aligns legal norms with the socio-technical realities of AI twins.", "AI": {"tldr": "探讨AI双胞胎的数据所有权问题，提出个人应被视为其AI双胞胎的合法和道德所有者。", "motivation": "鉴于AI双胞胎引发的新的法律和伦理挑战，需要重新思考数据治理和个人自主权的概念。", "method": "批评现有的优先考虑技术基础设施和平台控制的法律框架，并提出以人为中心的数据治理体系。", "result": "提出了一个基于个人主权和默认私密性的新社会契约模型，以加强个人代理并促进公平的数据管理。", "conclusion": "建议将AI驱动的身份治理与社会技术现实更好地对齐，以强化个体自主权。"}}
{"id": "2601.09871", "pdf": "https://arxiv.org/pdf/2601.09871", "abs": "https://arxiv.org/abs/2601.09871", "authors": ["Andrea Ferrario", "Alessandro Facchini", "Juan M. Durán"], "title": "Epistemology gives a Future to Complementarity in Human-AI Interactions", "categories": ["cs.AI", "cs.HC", "cs.LG"], "comment": "Submitted to FAccT 2026", "summary": "Human-AI complementarity is the claim that a human supported by an AI system can outperform either alone in a decision-making process. Since its introduction in the human-AI interaction literature, it has gained traction by generalizing the reliance paradigm and by offering a more practical alternative to the contested construct of 'trust in AI.' Yet complementarity faces key theoretical challenges: it lacks precise theoretical anchoring, it is formalized just as a post hoc indicator of relative predictive accuracy, it remains silent about other desiderata of human-AI interactions and it abstracts away from the magnitude-cost profile of its performance gain. As a result, complementarity is difficult to obtain in empirical settings. In this work, we leverage epistemology to address these challenges by reframing complementarity within the discourse on justificatory AI. Drawing on computational reliabilism, we argue that historical instances of complementarity function as evidence that a given human-AI interaction is a reliable epistemic process for a given predictive task. Together with other reliability indicators assessing the alignment of the human-AI team with the epistemic standards and socio-technical practices, complementarity contributes to the degree of reliability of human-AI teams when generating predictions. This supports the practical reasoning of those affected by these outputs -- patients, managers, regulators, and others. In summary, our approach suggests that the role and value of complementarity lies not in providing a relative measure of predictive accuracy, but in helping calibrate decision-making to the reliability of AI-supported processes that increasingly shape everyday life.", "AI": {"tldr": "本文探讨如何利用认识论重新阐释人类与人工智能交互中的互补性，使其成为可靠的预测过程。", "motivation": "尽管人类与人工智能互补性的概念在文献中获得了一定的关注度，但其仍面临着理论上的挑战和实际应用的困难。为解决这些问题，作者提出了基于计算可靠性主义的方法来增强互补性的理论基础和实用性。", "method": "本文使用了认识论中的可靠主义方法，将历史上的互补性案例作为证据，证明特定的人类-人工智能交互是可靠的预测过程，并与评估人类-人工智能团队与其知识标准、社会技术实践一致性的其他可靠性指标一起工作。", "result": "通过这种方法，可以提高对AI支持过程的可靠性的认识，从而帮助受影响者（如患者、管理者和监管机构等）更好地进行决策。", "conclusion": "本文结论指出，互补性的作用和价值并不在于提供相对预测准确度的衡量标准，而是帮助校准基于AI的支持过程的决策可靠性。"}}
{"id": "2601.09869", "pdf": "https://arxiv.org/pdf/2601.09869", "abs": "https://arxiv.org/abs/2601.09869", "authors": ["Andrea Ferrario", "Rasita Vinay", "Matteo Casserini", "Alessandro Facchini"], "title": "A Scoping Review of the Ethical Perspectives on Anthropomorphising Large Language Model-Based Conversational Agents", "categories": ["cs.AI", "cs.HC"], "comment": "Submitted to FAccT 2026", "summary": "Anthropomorphisation -- the phenomenon whereby non-human entities are ascribed human-like qualities -- has become increasingly salient with the rise of large language model (LLM)-based conversational agents (CAs). Unlike earlier chatbots, LLM-based CAs routinely generate interactional and linguistic cues, such as first-person self-reference, epistemic and affective expressions that empirical work shows can increase engagement. On the other hand, anthropomorphisation raises ethical concerns, including deception, overreliance, and exploitative relationship framing, while some authors argue that anthropomorphic interaction may support autonomy, well-being, and inclusion. Despite increasing interest in the phenomenon, literature remains fragmented across domains and varies substantially in how it defines, operationalizes, and normatively evaluates anthropomorphisation. This scoping review maps ethically oriented work on anthropomorphising LLM-based CAs across five databases and three preprint repositories. We synthesize (1) conceptual foundations, (2) ethical challenges and opportunities, and (3) methodological approaches. We find convergence on attribution-based definitions but substantial divergence in operationalization, a predominantly risk-forward normative framing, and limited empirical work that links observed interaction effects to actionable governance guidance. We conclude with a research agenda and design/governance recommendations for ethically deploying anthropomorphic cues in LLM-based conversational agents.", "AI": {"tldr": "本文旨在对大型语言模型（LLM）驱动的对话代理中的拟人化现象进行伦理审查。", "motivation": "随着基于大型语言模型的对话代理的发展，拟人化在增强用户参与度的同时也引发了诸多伦理问题，如欺骗、过度依赖等。由于相关文献分散且定义不一，本文试图系统地总结和分析这些问题。", "method": "该研究通过跨五个数据库和三个预印本存储库进行范围审查，综合了关于LLM驱动对话代理拟人化的概念基础、道德挑战与机遇以及方法论。", "result": "研究表明在拟人化定义上存在共识，但在操作化方面差异较大。大多数文献采取风险导向的伦理框架，并且缺乏将交互效果与治理指导直接关联的经验研究。", "conclusion": "本文提出了关于如何以伦理方式部署LLM驱动对话代理中的拟人化线索的研究议程和设计/治理建议。"}}
{"id": "2601.09866", "pdf": "https://arxiv.org/pdf/2601.09866", "abs": "https://arxiv.org/abs/2601.09866", "authors": ["Kiarie Ndegwa", "Andreas Gros", "Tony Chang", "David Diaz", "Vincent A. Landau", "Nathan E. Rutenbeck", "Luke J. Zachmann", "Guy Bayes", "Scott Conway"], "title": "VibrantSR: Sub-Meter Canopy Height Models from Sentinel-2 Using Generative Flow Matching", "categories": ["cs.CV", "cs.LG"], "comment": "12 pages, 8 figures, 2 tables", "summary": "We present VibrantSR (Vibrant Super-Resolution), a generative super-resolution framework for estimating 0.5 meter canopy height models (CHMs) from 10 meter Sentinel-2 imagery. Unlike approaches based on aerial imagery that are constrained by infrequent and irregular acquisition schedules, VibrantSR leverages globally available Sentinel-2 seasonal composites, enabling consistent monitoring at a seasonal-to-annual cadence. Evaluated across 22 EPA Level 3 eco-regions in the western United States using spatially disjoint validation splits, VibrantSR achieves a Mean Absolute Error of 4.39 meters for canopy heights >= 2 m, outperforming Meta (4.83 m), LANDFIRE (5.96 m), and ETH (7.05 m) satellite-based benchmarks. While aerial-based VibrantVS (2.71 m MAE) retains an accuracy advantage, VibrantSR enables operational forest monitoring and carbon accounting at continental scales without reliance on costly and temporally infrequent aerial acquisitions.", "AI": {"tldr": "本文介绍了VibrantSR，一种从Sentinel-2影像生成亚米级树冠高度模型的生成超级分辨率框架。", "motivation": "该研究旨在解决基于航空图像方法因采集频率低且不规律而导致的问题，并通过使用全球可用的Sentinel-2季节性合成影像实现连续监测。", "method": "VibrantSR利用生成流匹配技术，从10米分辨率的Sentinel-2影像中估算出0.5米分辨率的树冠高度模型。", "result": "在西部美国22个EPA三级生态区进行评估时，VibrantSR达到了4.39米的平均绝对误差（针对至少2米高的树冠），优于其他卫星基准方法。", "conclusion": "尽管基于航空图像的方法在准确性上仍具优势，但VibrantSR实现了无需昂贵且时间间隔长的航空采集，即可进行全大陆范围的森林监测和碳核算。"}}
{"id": "2601.09865", "pdf": "https://arxiv.org/pdf/2601.09865", "abs": "https://arxiv.org/abs/2601.09865", "authors": ["Jacob Sander", "Brian Jalaian", "Venkat R. Dasari"], "title": "Advancing Model Refinement: Muon-Optimized Distillation and Quantization for LLM Deployment", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 5 figures", "summary": "Large Language Models (LLMs) enable advanced natural language processing but face deployment challenges on resource-constrained edge devices due to high computational, memory, and energy demands. Optimizing these models requires addressing three key challenges: acquiring task-specific data, fine-tuning for performance, and compressing models to accelerate inference while reducing resource demands. We propose an integrated framework combining GPTQ-based quantization, low-rank adaptation (LoRA), and a specialized data distillation process to significantly reduce model size and complexity while preserving or enhancing task-specific performance. By leveraging data distillation, knowledge distillation via Kullback-Leibler divergence, Bayesian hyperparameter optimization, and the Muon optimizer, our pipeline achieves up to 2x memory compression (e.g., reducing a 6GB model to 3GB) and enables efficient inference for specialized tasks. Empirical results demonstrate superior performance on standard LLM benchmarks compared to GPTQ quantization alone, with the Muon optimizer notably enhancing fine-tuned models' resistance to accuracy decay during quantization.", "AI": {"tldr": "本文提出了一种结合GPTQ量化、低秩适应和数据精馏的综合框架，以显著减少大型语言模型的大小和复杂性，并保持或提升特定任务性能。", "motivation": "随着大规模语言模型在资源受限设备上的部署面临挑战，如计算、内存和能量需求高，本文旨在优化这些模型，解决获取任务特定数据、微调性能以及压缩模型以加速推理并减少资源需求的问题。", "method": "作者提出的方法包括GPTQ量化、低秩适应（LoRA）、通过Kullback-Leibler散度的知识蒸馏以及使用Muon优化器的数据精馏过程，实现高达2倍的内存压缩，并在特定任务上进行高效推理。", "result": "实验结果表明，在标准语言模型基准测试中，该方法比仅用GPTQ量化的方法表现出更优性能，Muon优化器显著增强了微调模型在量化过程中对精度衰减的抵抗力。", "conclusion": "本文提出的综合框架通过减少大型语言模型大小和复杂性同时保持或提升任务性能的方式成功解决了部署挑战，并展示了优于单一技术方案的表现。"}}
{"id": "2601.09860", "pdf": "https://arxiv.org/pdf/2601.09860", "abs": "https://arxiv.org/abs/2601.09860", "authors": ["Sepideh Mahabadi", "Sherry Sarkar", "Jakub Tarnawski"], "title": "Improved Algorithms for Fair Matroid Submodular Maximization", "categories": ["cs.DS"], "comment": null, "summary": "Submodular maximization subject to matroid constraints is a central problem with many applications in machine learning. As algorithms are increasingly used in decision-making over datapoints with sensitive attributes such as gender or race, it is becoming crucial to enforce fairness to avoid bias and discrimination. Recent work has addressed the challenge of developing efficient approximation algorithms for fair matroid submodular maximization. However, the best algorithms known so far are only guaranteed to satisfy a relaxed version of the fairness constraints that loses a factor 2, i.e., the problem may ask for $\\ell$ elements with a given attribute, but the algorithm is only guaranteed to find $\\lfloor \\ell/2 \\rfloor$. In particular, there is no provable guarantee when $\\ell=1$, which corresponds to a key special case of perfect matching constraints. In this work, we achieve a new trade-off via an algorithm that gets arbitrarily close to full fairness. Namely, for any constant $\\varepsilon>0$, we give a constant-factor approximation to fair monotone matroid submodular maximization that in expectation loses only a factor $(1-\\varepsilon)$ in the lower-bound fairness constraint. Our empirical evaluation on a standard suite of real-world datasets -- including clustering, recommendation, and coverage tasks -- demonstrates the practical effectiveness of our methods.", "AI": {"tldr": "本文提出了改进的公平子模最大化算法，在满足马蒂德约束条件下，实现了接近完全公平的目标。", "motivation": "随着机器学习在决策中越来越多地使用敏感属性（如性别或种族）的数据点进行判断，确保算法公平性以避免偏见和歧视变得至关重要。现有的算法只能保证部分公平约束，本文旨在改进这一点。", "method": "对于任何常数ε>0，提出了一种恒定因子近似的公平单调马蒂德子模最大化算法，在预期中仅失去(1-ε)的下限公平性约束。", "result": "实证评估表明该方法在聚类、推荐和覆盖任务等标准真实世界数据集中表现出了实际有效性。", "conclusion": "本文提出的算法能够接近完全满足公平性约束，为解决公平子模最大化问题提供了一种新的有效策略。"}}
{"id": "2601.09859", "pdf": "https://arxiv.org/pdf/2601.09859", "abs": "https://arxiv.org/abs/2601.09859", "authors": ["Anant Mehta", "Xiyuan Wei", "Xingyu Chen", "Tianbao Yang"], "title": "Breaking the Limits of Open-Weight CLIP: An Optimization Framework for Self-supervised Fine-tuning of CLIP", "categories": ["cs.CV", "cs.LG"], "comment": "Submitted to ICLR 2026", "summary": "CLIP has become a cornerstone of multimodal representation learning, yet improving its performance typically requires a prohibitively costly process of training from scratch on billions of samples. We ask a different question: Can we improve the performance of open-weight CLIP models across various downstream tasks using only existing self-supervised datasets? Unlike supervised fine-tuning, which adapts a pretrained model to a single downstream task, our setting seeks to improve general performance across various tasks. However, as both our experiments and prior studies reveal, simply applying standard training protocols starting from an open-weight CLIP model often fails, leading to performance degradation. In this paper, we introduce TuneCLIP, a self-supervised fine-tuning framework that overcomes the performance degradation. TuneCLIP has two key components: (1) a warm-up stage of recovering optimization statistics to reduce cold-start bias, inspired by theoretical analysis, and (2) a fine-tuning stage of optimizing a new contrastive loss to mitigate the penalization on false negative pairs. Our extensive experiments show that TuneCLIP consistently improves performance across model architectures and scales. Notably, it elevates leading open-weight models like SigLIP (ViT-B/16), achieving gains of up to +2.5% on ImageNet and related out-of-distribution benchmarks, and +1.2% on the highly competitive DataComp benchmark, setting a new strong baseline for efficient post-pretraining adaptation.", "AI": {"tldr": "本文提出了TuneCLIP，一个用于自监督微调的优化框架，旨在提高开放权重模型CLIP在多个下游任务中的性能。", "motivation": "改善CLIP的性能通常需要耗费大量资源和时间从头开始训练，作者希望探索是否可以通过现有的自监督数据集来提升已有的开放权重CLIP模型的性能。", "method": "TuneCLIP包含两个关键部分：一个用于恢复优化统计以减少冷启动偏差的预热阶段；以及一个通过优化新的对比损失来减轻对错误负样本惩罚的微调阶段。", "result": "实验表明，TuneCLIP在不同的模型架构和规模上都能持续提升性能，例如，将SigLIP（ViT-B/16）模型在ImageNet上的表现提高了最多2.5%，并在DataComp基准测试中提升了1.2%。", "conclusion": "TuneCLIP通过自监督微调框架有效地克服了开放权重CLIP模型的性能下降问题，并为高效后预训练适应设定了新的强基线。"}}
{"id": "2601.09858", "pdf": "https://arxiv.org/pdf/2601.09858", "abs": "https://arxiv.org/abs/2601.09858", "authors": ["Yilin Bao", "Ziyao He", "Zayden Yang"], "title": "OUTLINEFORGE: Hierarchical Reinforcement Learning with Explicit States for Scientific Writing", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Scientific paper generation requires document-level planning and factual grounding, but current large language models, despite their strong local fluency, often fail in global structure, input coverage, and citation consistency. We present a reinforcement learning framework that casts scientific outline construction as a long-horizon planning problem over hierarchical document structures. Our approach models edit evolving outlines through structured actions, enabling the system to incrementally build a complete scientific manuscript. To support effective and stabilize learning,we introduce a two-stage optimization procedure consisting of (i) backward outline reconstruction from partial plans to enforce global structural consistency, and (ii) forward value-guided reinforcement learning with rewards explicitly modeling scientific correctness, discourse coherence, and citation fidelity. In addition, We further introduce a benchmark for scientific paper generation that evaluates document planning, input utilization, reference faithfulness, outline organization, and content-level factual accuracy. Our results show consistent improvements over strong neural and LLM baselines, particularly in long-range structural coherence and citation reliability.", "AI": {"tldr": "本文提出了一个强化学习框架（OUTLINEFORGE），用于科学写作中的大纲构建，通过分层文档结构进行长期规划，并解决了现有大型语言模型在全局结构、输入覆盖率和引用一致性方面的问题。", "motivation": "尽管现有的大型语言模型具有很强的局部流畅性，但在生成科学研究文章时往往会在全局结构、输入覆盖和引用一致性上出现问题。为了克服这些问题，提出了一个强化学习框架来优化科学论文写作过程中的大纲构建。", "method": "本文的方法是将科学大纲构造作为一个长期规划问题，并采用分层文档结构进行建模。通过结构化操作逐步生成完整的科学手稿，并引入了两阶段优化程序以支持有效和稳定的训练。第一阶段是从部分计划向后重构大纲，强制执行全局结构一致性；第二阶段是基于前向价值导向的强化学习，奖励函数明确地将科学正确性、话语连贯性和引用准确性纳入考量。", "result": "实验结果表明，该方法在长期结构一致性和引文可靠性方面显著优于神经网络和大型语言模型基线。为了评估文档规划、输入利用率、参考忠实度、大纲组织以及内容层面的事实准确性，还引入了一个新的基准测试。", "conclusion": "通过强化学习框架OUTLINEFORGE，本文成功解决了现有大型语言模型在生成科学文章时面临的全局结构、输入覆盖率和引用一致性问题，并取得了比基线方法更好的效果，特别是在长期的结构一致性和引文可靠性方面。"}}
{"id": "2601.09856", "pdf": "https://arxiv.org/pdf/2601.09856", "abs": "https://arxiv.org/abs/2601.09856", "authors": ["Andrew Stratton", "Phani Teja Singamaneni", "Pranav Goyal", "Rachid Alami", "Christoforos Mavrogiannis"], "title": "How Human Motion Prediction Quality Shapes Social Robot Navigation Performance in Constrained Spaces", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "Motivated by the vision of integrating mobile robots closer to humans in warehouses, hospitals, manufacturing plants, and the home, we focus on robot navigation in dynamic and spatially constrained environments. Ensuring human safety, comfort, and efficiency in such settings requires that robots are endowed with a model of how humans move around them. Human motion prediction around robots is especially challenging due to the stochasticity of human behavior, differences in user preferences, and data scarcity. In this work, we perform a methodical investigation of the effects of human motion prediction quality on robot navigation performance, as well as human productivity and impressions. We design a scenario involving robot navigation among two human subjects in a constrained workspace and instantiate it in a user study ($N=80$) involving two different robot platforms, conducted across two sites from different world regions. Key findings include evidence that: 1) the widely adopted average displacement error is not a reliable predictor of robot navigation performance and human impressions; 2) the common assumption of human cooperation breaks down in constrained environments, with users often not reciprocating robot cooperation, and causing performance degradations; 3) more efficient robot navigation often comes at the expense of human efficiency and comfort.", "AI": {"tldr": "研究了人类运动预测质量对机器人导航性能的影响，特别是在受限空间中的表现。", "motivation": "为了更好地将移动机器人融入到仓库、医院、制造工厂和家庭等环境中，需要解决在动态且空间有限的环境下的人机交互问题，确保人的安全、舒适性和效率。", "method": "设计了一个实验场景，让机器人在两个人类参与者之间导航，并在一个涉及80名参与者的用户研究中，使用两种不同平台的机器人，在两个不同的区域进行实验。", "result": "发现平均位移误差不是衡量机器人导航性能和人类印象的良好指标；用户的合作假设在这种环境中失效，导致了机器人表现下降；更高效的机器人导航常常以牺牲人的效率和舒适度为代价。", "conclusion": "研究揭示了在受限空间中的人类运动预测与机器人导航性能之间的复杂关系，并指出了现有评估方法的局限性。"}}
{"id": "2601.09855", "pdf": "https://arxiv.org/pdf/2601.09855", "abs": "https://arxiv.org/abs/2601.09855", "authors": ["Michael R. Metel", "Yufei Cui", "Boxing Chen", "Prasanna Parthasarathi"], "title": "Thinking Long, but Short: Stable Sequential Test-Time Scaling for Large Reasoning Models", "categories": ["cs.AI", "cs.CL"], "comment": "Findings of EACL 2026", "summary": "Sequential test-time scaling is a promising training-free method to improve large reasoning model accuracy, but as currently implemented, significant limitations have been observed. Inducing models to think for longer can increase their accuracy, but as the length of reasoning is further extended, it has also been shown to result in accuracy degradation and model instability. This work presents a novel sequential test-time scaling method, Min-Seek, which improves model accuracy significantly over a wide range of induced thoughts, stabilizing the accuracy of sequential scaling, and removing the need for reasoning length fine-tuning. Beyond improving model accuracy over a variety of reasoning tasks, our method is inherently efficient, as only the KV pairs of one additional induced thought are kept in the KV cache during reasoning. With a custom KV cache which stores keys without position embeddings, by dynamically encoding them contiguously before each new generated thought, our method can continue to reason well beyond a model's maximum context length, and under mild conditions has linear computational complexity.", "AI": {"tldr": "本文提出了一种名为Min-Seek的稳定顺序测试时间缩放方法，用于提高大推理模型在各种任务中的准确性。", "motivation": "传统的顺序测试时间缩放虽然可以提升模型精度，但当推理长度过长时会导致准确性下降和模型不稳定。本研究旨在解决这一问题并改善模型性能。", "method": "Min-Seek方法通过引入一个自定义的KV缓存机制，在推理过程中仅保留一个额外诱导思想的KV对，实现了高效的模型扩展，并允许模型在超出最大上下文长度的情况下继续进行有效推理。", "result": "该方法不仅提高了大推理模型在多种任务上的准确性，还减少了对推理长度微调的需求，同时保持了较低的计算复杂性。", "conclusion": "Min-Seek通过稳定顺序测试时间缩放过程，展示了提高大型推理模型效率和准确性的潜力。"}}
{"id": "2601.09853", "pdf": "https://arxiv.org/pdf/2601.09853", "abs": "https://arxiv.org/abs/2601.09853", "authors": ["Sraavya Sambara", "Yuan Pu", "Ayman Ali", "Vishala Mishra", "Lionel Wong", "Monica Agrawal"], "title": "MedRedFlag: Investigating how LLMs Redirect Misconceptions in Real-World Health Communication", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Real-world health questions from patients often unintentionally embed false assumptions or premises. In such cases, safe medical communication typically involves redirection: addressing the implicit misconception and then responding to the underlying patient context, rather than the original question. While large language models (LLMs) are increasingly being used by lay users for medical advice, they have not yet been tested for this crucial competency. Therefore, in this work, we investigate how LLMs react to false premises embedded within real-world health questions. We develop a semi-automated pipeline to curate MedRedFlag, a dataset of 1100+ questions sourced from Reddit that require redirection. We then systematically compare responses from state-of-the-art LLMs to those from clinicians. Our analysis reveals that LLMs often fail to redirect problematic questions, even when the problematic premise is detected, and provide answers that could lead to suboptimal medical decision making. Our benchmark and results reveal a novel and substantial gap in how LLMs perform under the conditions of real-world health communication, highlighting critical safety concerns for patient-facing medical AI systems. Code and dataset are available at https://github.com/srsambara-1/MedRedFlag.", "AI": {"tldr": "该研究调查了大型语言模型（LLMs）在处理包含错误前提的真实世界健康问题时的表现，并发现它们往往无法重定向有问题的问题，存在潜在的安全隐患。", "motivation": "鉴于患者提出的真实世界健康问题通常无意中包含了错误假设或前提，而安全的医疗沟通需要重新导向这些误解。研究动机是测试LLMs在这种关键能力上的表现。", "method": "开发了一个半自动管道来整理MedRedFlag数据集，包含1100多个来自Reddit的问题，并系统地比较了最先进的LLMs与临床医生对这些问题的回答。", "result": "分析显示，即使检测到有问题的前提，LLMs也常常未能进行重定向处理，提供的答案可能导致次优的医疗决策。这揭示了一个新的和显著的能力差距。", "conclusion": "研究结果强调了患者面向的医学AI系统中的关键安全问题，并为改进提供了基准。"}}
{"id": "2601.09851", "pdf": "https://arxiv.org/pdf/2601.09851", "abs": "https://arxiv.org/abs/2601.09851", "authors": ["Po-han Li", "Shenghui Chen", "Ufuk Topcu", "Sandeep Chinchali"], "title": "ViSIL: Unified Evaluation of Information Loss in Multimodal Video Captioning", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": null, "summary": "Multimodal video captioning condenses dense footage into a structured format of keyframes and natural language. By creating a cohesive multimodal summary, this approach anchors generative AI in rich semantic evidence and serves as a lightweight proxy for high-efficiency retrieval. However, traditional metrics like BLEU or ROUGE fail to quantify information coverage across disparate modalities, such as comparing a paragraph of text to a sequence of keyframes. To address this, we propose the Video Summary Information Loss (ViSIL) score, an information-theoretic framework that quantifies the video information not captured by a summary via vision-language model (VLM) inference. By measuring the information loss, ViSIL is a unified metric that enables direct comparison across multimodal summary formats despite their structural discrepancies. Our results demonstrate that ViSIL scores show a statistically significant correlation with both human and VLM performance on Video Question Answering (VQA) tasks. ViSIL also enables summary selection to optimize the trade-off between information loss and processing speed, establishing a Pareto-optimal frontier that outperforms text summaries by $7\\%$ in VQA accuracy without increasing processing load.", "AI": {"tldr": "该论文提出了ViSIL评分，一个信息论框架，用于量化视频摘要中未捕获的视频信息，并展示了其在多模态视频描述中的应用。", "motivation": "传统的评估指标如BLEU或ROUGE无法衡量跨不同模式的信息覆盖率，因此提出一种新的统一评价方法来解决这一问题。", "method": "论文提出了Video Summary Information Loss (ViSIL)评分，通过视觉语言模型(VLM)推断量化视频信息损失，并用于多模态摘要格式的直接比较。", "result": "实验结果显示，ViSIL评分与人类和VLM在视频问答（VQA）任务上的表现有统计显著的相关性。ViSIL优化了信息损失和处理速度之间的权衡，在不增加处理负载的情况下提高了7%的VQA准确性。", "conclusion": "ViSIL作为一个统一指标，能够在不同结构的多模态摘要格式之间进行直接比较，并且在保持处理效率的同时优化了视频问答任务的性能。"}}
{"id": "2601.09841", "pdf": "https://arxiv.org/pdf/2601.09841", "abs": "https://arxiv.org/abs/2601.09841", "authors": ["Aparajita Kashyap", "Sara Matijevic", "Noémie Elhadad", "Steven A. Kushner", "Shalmali Joshi"], "title": "A pipeline for enabling path-specific causal fairness in observational health data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "When training machine learning (ML) models for potential deployment in a healthcare setting, it is essential to ensure that they do not replicate or exacerbate existing healthcare biases. Although many definitions of fairness exist, we focus on path-specific causal fairness, which allows us to better consider the social and medical contexts in which biases occur (e.g., direct discrimination by a clinician or model versus bias due to differential access to the healthcare system) and to characterize how these biases may appear in learned models. In this work, we map the structural fairness model to the observational healthcare setting and create a generalizable pipeline for training causally fair models. The pipeline explicitly considers specific healthcare context and disparities to define a target \"fair\" model. Our work fills two major gaps: first, we expand on characterizations of the \"fairness-accuracy\" tradeoff by detangling direct and indirect sources of bias and jointly presenting these fairness considerations alongside considerations of accuracy in the context of broadly known biases. Second, we demonstrate how a foundation model trained without fairness constraints on observational health data can be leveraged to generate causally fair downstream predictions in tasks with known social and medical disparities. This work presents a model-agnostic pipeline for training causally fair machine learning models that address both direct and indirect forms of healthcare bias.", "AI": {"tldr": "本文介绍了一个用于在观察性健康数据中实现路径特定因果公平的流水线。", "motivation": "确保机器学习模型在医疗环境中的应用不会复制或加剧现有的医疗偏见，特别是直接和间接来源的偏差问题。", "method": "开发了一种能够映射到观察性医疗设置并训练因果公平模型的一般化流水线，该流水线明确考虑了特定的医疗服务背景和差异以定义目标“公平”模型。", "result": "填补了两个主要空白：一是扩展了对“公平-准确性”权衡的理解；二是展示了如何利用在没有公平约束的情况下基于观察性健康数据训练的基础模型来生成具有因果公平性的下游预测，特别是在存在已知社会和医疗差异的任务中。", "conclusion": "提出了一种模型无关的流水线方法，用于训练能够同时处理直接和间接形式医疗服务偏见的因果公平机器学习模型。"}}
{"id": "2601.09838", "pdf": "https://arxiv.org/pdf/2601.09838", "abs": "https://arxiv.org/abs/2601.09838", "authors": ["Leonie Dyck", "Aiko Galetzka", "Maximilian Noller", "Anna-Lena Rinke", "Jutta Bormann", "Jekaterina Miller", "Michelle Hochbaum", "Julia Siemann", "Jördis Alboth", "Andre Berwinkel", "Johanna Luz", "Britta Kley-Zobel", "Marcine Cyrys", "Nora Flöttmann", "Ariane Vogeler", "Mariia Melnikova", "Ira-Katharina Petras", "Michael Siniatchkin", "Winfried Barthlen", "Anna-Lisa Vollmer"], "title": "Interprofessional and Agile Development of Mobirobot: A Socially Assistive Robot for Pediatric Therapy Across Clinical and Therapeutic Settings", "categories": ["cs.RO", "cs.HC"], "comment": "submitted to Frontiers in Digital Health", "summary": "Introduction: Socially assistive robots hold promise for enhancing therapeutic engagement in paediatric clinical settings. However, their successful implementation requires not only technical robustness but also context-sensitive, co-designed solutions. This paper presents Mobirobot, a socially assistive robot developed to support mobilisation in children recovering from trauma, fractures, or depressive disorders through personalised exercise programmes. Methods: An agile, human-centred development approach guided the iterative design of Mobirobot. Multidisciplinary clinical teams and end users were involved throughout the co-development process, which focused on early integration into real-world paediatric surgical and psychiatric settings. The robot, based on the NAO platform, features a simple setup, adaptable exercise routines with interactive guidance, motivational dialogue, and a graphical user interface (GUI) for monitoring and no-code system feedback. Results: Deployment in hospital environments enabled the identification of key design requirements and usability constraints. Stakeholder feedback led to refinements in interaction design, movement capabilities, and technical configuration. A feasibility study is currently underway to assess acceptance, usability, and perceived therapeutic benefit, with data collection including questionnaires, behavioural observations, and staff-patient interviews. Discussion: Mobirobot demonstrates how multiprofessional, stakeholder-led development can yield a socially assistive system suited for dynamic inpatient settings. Early-stage findings underscore the importance of contextual integration, robustness, and minimal-intrusion design. While challenges such as sensor limitations and patient recruitment remain, the platform offers a promising foundation for further research and clinical application.", "AI": {"tldr": "介绍Mobirobot，一款旨在通过个性化运动计划支持儿童创伤、骨折或抑郁恢复的社会辅助机器人。", "motivation": "认识到社会辅助机器人的潜力在于提高儿科治疗环境中的治疗参与度，并强调成功实施需要技术稳健性和上下文敏感的设计。", "method": "采用敏捷的人本设计方法进行迭代开发，涉及多学科临床团队和最终用户的共同开发过程，将Mobirobot早期整合到实际的儿童外科和精神病理环境中。", "result": "在医院环境中的部署帮助识别了关键的设计要求和使用限制。基于利益相关者反馈，对交互设计、运动能力和技术配置进行了改进。正在进行可行性研究以评估接受度、可用性和感知治疗效益。", "conclusion": "Mobirobot展示了多专业、利益相关者主导开发如何产生适合动态住院环境的社会辅助系统的重要性。初步发现强调了上下文整合、稳健性及最小侵入设计的价值，尽管存在传感器限制和患者招募的挑战，但仍提供了进一步研究和临床应用的良好基础。"}}
{"id": "2601.09828", "pdf": "https://arxiv.org/pdf/2601.09828", "abs": "https://arxiv.org/abs/2601.09828", "authors": ["Xiaoxu Ma", "Runhao Li", "Hanwen Liu", "Xiangbo Zhang", "Zhenyu Weng"], "title": "UniHash: Unifying Pointwise and Pairwise Hashing Paradigms for Seen and Unseen Category Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Effective retrieval across both seen and unseen categories is crucial for modern image retrieval systems. Retrieval on seen categories ensures precise recognition of known classes, while retrieval on unseen categories promotes generalization to novel classes with limited supervision. However, most existing deep hashing methods are confined to a single training paradigm, either pointwise or pairwise, where the former excels on seen categories and the latter generalizes better to unseen ones. To overcome this limitation, we propose Unified Hashing (UniHash), a dual-branch framework that unifies the strengths of both paradigms to achieve balanced retrieval performance across seen and unseen categories. UniHash consists of two complementary branches: a center-based branch following the pointwise paradigm and a pairwise branch following the pairwise paradigm. A novel hash code learning method is introduced to enable bidirectional knowledge transfer between branches, improving hash code discriminability and generalization. It employs a mutual learning loss to align hash representations and introduces a Split-Merge Mixture of Hash Experts (SM-MoH) module to enhance cross-branch exchange of hash representations. Theoretical analysis substantiates the effectiveness of UniHash, and extensive experiments on CIFAR-10, MSCOCO, and ImageNet demonstrate that UniHash consistently achieves state-of-the-art performance in both seen and unseen image retrieval scenarios.", "AI": {"tldr": "本文提出了一种名为UniHash的双重分支框架，以实现对已知和未知类别图像的有效检索。", "motivation": "现有深度哈希方法通常局限于点式或成对训练范式，分别擅长于处理已见类别的精准识别与未见类别的泛化能力。本文旨在克服这些限制，提供平衡的检索性能。", "method": "UniHash由两个互补分支组成：基于中心的点式范式分支和遵循成对范式的分支，并引入了一种新的哈希码学习方法，通过互学习损失和分割-合并混合哈希专家模块增强了跨分支的哈希表示交换。", "result": "理论分析证明了UniHash的有效性，在CIFAR-10、MSCOCO和ImageNet上的广泛实验表明，UniHash在已知类别与未知类别的图像检索方面均达到了最新的技术水平。", "conclusion": "UniHash框架通过融合点式与成对范式的优点，并引入创新的哈希码学习方法，实现了跨已见与未见证据类别的均衡检索性能。"}}
{"id": "2601.09823", "pdf": "https://arxiv.org/pdf/2601.09823", "abs": "https://arxiv.org/abs/2601.09823", "authors": ["Subhajit Sanyal", "Srinivas Soumitri Miriyala", "Akshay Janardan Bankar", "Sravanth Kodavanti", "Harshit", "Abhishek Ameta", "Shreyas Pandith", "Amit Satish Unde"], "title": "NanoSD: Edge Efficient Foundation Model for Real Time Image Restoration", "categories": ["cs.CV"], "comment": "Submitted to CVPR 2026", "summary": "Latent diffusion models such as Stable Diffusion 1.5 offer strong generative priors that are highly valuable for image restoration, yet their full pipelines remain too computationally heavy for deployment on edge devices. Existing lightweight variants predominantly compress the denoising U-Net or reduce the diffusion trajectory, which disrupts the underlying latent manifold and limits generalization beyond a single task. We introduce NanoSD, a family of Pareto-optimal diffusion foundation models distilled from Stable Diffusion 1.5 through network surgery, feature-wise generative distillation, and structured architectural scaling jointly applied to the U-Net and the VAE encoder-decoder. This full-pipeline co-design preserves the generative prior while producing models that occupy distinct operating points along the accuracy-latency-size frontier (e.g., 130M-315M parameters, achieving real-time inference down to 20ms on mobile-class NPUs). We show that parameter reduction alone does not correlate with hardware efficiency, and we provide an analysis revealing how architectural balance, feature routing, and latent-space preservation jointly shape true on-device latency. When used as a drop-in backbone, NanoSD enables state-of-the-art performance across image super-resolution, image deblurring, face restoration, and monocular depth estimation, outperforming prior lightweight diffusion models in both perceptual quality and practical deployability. NanoSD establishes a general-purpose diffusion foundation model family suitable for real-time visual generation and restoration on edge devices.", "AI": {"tldr": "开发NanoSD，一种适用于边缘设备实时图像恢复的轻量级基础模型。", "motivation": "现有的扩散模型虽然在图像生成中表现出色，但计算负担过重，无法直接部署到边缘设备。因此，研究者希望通过优化和压缩这些模型，使其适合于资源有限的边缘设备。", "method": "通过网络手术、特征导向的知识蒸馏和结构化架构缩放来优化扩散模型的U-Net和VAE编解码器，创建出NanoSD系列高效轻量级模型。", "result": "NanoSD在图像超分辨率、去模糊、面部恢复和单目深度估计任务中表现出色，并且能够实现实时推理，在移动类NPU上的延迟低至20毫秒。", "conclusion": "NanoSD为边缘设备上实现了通用的扩散基础模型，适用于视觉生成和修复任务，并展示了高效率和良好的感知质量。"}}
{"id": "2601.09822", "pdf": "https://arxiv.org/pdf/2601.09822", "abs": "https://arxiv.org/abs/2601.09822", "authors": ["Yongjian Tang", "Thomas Runkler"], "title": "LLM-Based Agentic Systems for Software Engineering: Challenges and Opportunities", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted to GenSE 2026 workshop", "summary": "Despite recent advancements in Large Language Models (LLMs), complex Software Engineering (SE) tasks require more collaborative and specialized approaches. This concept paper systematically reviews the emerging paradigm of LLM-based multi-agent systems, examining their applications across the Software Development Life Cycle (SDLC), from requirements engineering and code generation to static code checking, testing, and debugging. We delve into a wide range of topics such as language model selection, SE evaluation benchmarks, state-of-the-art agentic frameworks and communication protocols. Furthermore, we identify key challenges and outline future research opportunities, with a focus on multi-agent orchestration, human-agent coordination, computational cost optimization, and effective data collection. This work aims to provide researchers and practitioners with valuable insights into the current forefront landscape of agentic systems within the software engineering domain.", "AI": {"tldr": "本文探讨了基于大型语言模型的多智能体系统在软件工程中的应用、挑战和未来研究机会。", "motivation": "尽管大型语言模型取得了进展，但复杂的软件工程项目仍需要更协作与专业的处理方法。因此，文章旨在探索多智能体系统的新兴范式，并提供相关领域前沿洞察。", "method": "该概念性论文系统地回顾了基于LLM的多智能体系统在SDLC各阶段的应用案例，并讨论语言模型选择、SE评估基准、最先进的多智能体系框架和通信协议。", "result": "文章识别出多智能体系统中的一些关键挑战，如多智能体编排、人机协调、计算成本优化和有效数据收集，同时提供了未来研究的机会。", "conclusion": "本文为研究人员和实践者提供了关于软件工程领域内多智能体系前沿现状的宝贵见解。"}}
{"id": "2601.09814", "pdf": "https://arxiv.org/pdf/2601.09814", "abs": "https://arxiv.org/abs/2601.09814", "authors": ["Adil O. Khadidos", "Aziida Nanyonga", "Alaa O. Khadidos", "Olfat M. Mirza", "Mustafa Tahsin Yilmaz"], "title": "Explainable Deep Learning for Pediatric Pneumonia Detection in Chest X-Ray Images", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Background: Pneumonia remains a leading cause of morbidity and mortality among children worldwide, emphasizing the need for accurate and efficient diagnostic support tools. Deep learning has shown strong potential in medical image analysis, particularly for chest X-ray interpretation. This study compares two state-of-the-art convolutional neural network (CNN) architectures for automated pediatric pneumonia detection. Methods: A publicly available dataset of 5,863 pediatric chest X-ray images was used. Images were preprocessed through normalization, resizing, and data augmentation to enhance generalization. DenseNet121 and EfficientNet-B0 were fine-tuned using pretrained ImageNet weights under identical training settings. Performance was evaluated using accuracy, F1-score, Matthews Correlation Coefficient (MCC), and recall. Model explainability was incorporated using Gradient-weighted Class Activation Mapping (Grad-CAM) and Local Interpretable Model-agnostic Explanations (LIME) to visualize image regions influencing predictions. Results: EfficientNet-B0 outperformed DenseNet121, achieving an accuracy of 84.6%, F1-score of 0.8899, and MCC of 0.6849. DenseNet121 achieved 79.7% accuracy, an F1-score of 0.8597, and MCC of 0.5852. Both models demonstrated high recall values above 0.99, indicating strong sensitivity to pneumonia detection. Grad-CAM and LIME visualizations showed consistent focus on clinically relevant lung regions, supporting the reliability of model decisions. Conclusions: EfficientNet-B0 provided a more balanced and computationally efficient performance compared to DenseNet121, making it a strong candidate for clinical deployment. The integration of explainability techniques enhances transparency and trustworthiness in AI-assisted pediatric pneumonia diagnosis.", "AI": {"tldr": "论文主要任务是比较两种先进的卷积神经网络架构（DenseNet121 和 EfficientNet-B0）在儿童肺炎检测中的表现。", "motivation": "由于肺炎是全球儿童发病率和死亡率的主要原因之一，需要准确且高效的诊断支持工具。深度学习技术已在医学影像分析中展现出强大的潜力，特别是对于胸部X光片的解读。", "method": "使用公开数据集（5863张儿童胸部X光图片），通过规范化、调整大小及数据增强进行预处理。对预先训练过的ImageNet权重下的DenseNet121和EfficientNet-B0进行了微调，并用准确率、F1得分、马修斯相关系数（MCC）和召回率来评估性能。利用Grad-CAM和LIME技术增强了模型的可解释性。", "result": "EfficientNet-B0在准确度（84.6%）、F1得分（0.8899）和MCC（0.6849）上优于DenseNet121，后者分别为79.7%、0.8597和0.5852。两个模型都显示出高召回率，表明它们对肺炎检测有高度敏感性。Grad-CAM和LIME可视化结果集中在临床上相关的肺区域。", "conclusion": "EfficientNet-B0在性能上更为均衡且计算效率更高，是临床部署的有力候选者。通过整合可解释性的技术提高了AI辅助儿童肺炎诊断的透明度和可信度。"}}
{"id": "2601.09812", "pdf": "https://arxiv.org/pdf/2601.09812", "abs": "https://arxiv.org/abs/2601.09812", "authors": ["Carlo Sgaravatti", "Riccardo Pieroni", "Matteo Corno", "Sergio M. Savaresi", "Luca Magri", "Giacomo Boracchi"], "title": "LCF3D: A Robust and Real-Time Late-Cascade Fusion Framework for 3D Object Detection in Autonomous Driving", "categories": ["cs.CV", "cs.RO"], "comment": "35 pages, 14 figures. Published at Pattern Recognition", "summary": "Accurately localizing 3D objects like pedestrians, cyclists, and other vehicles is essential in Autonomous Driving. To ensure high detection performance, Autonomous Vehicles complement RGB cameras with LiDAR sensors, but effectively combining these data sources for 3D object detection remains challenging. We propose LCF3D, a novel sensor fusion framework that combines a 2D object detector on RGB images with a 3D object detector on LiDAR point clouds. By leveraging multimodal fusion principles, we compensate for inaccuracies in the LiDAR object detection network. Our solution combines two key principles: (i) late fusion, to reduce LiDAR False Positives by matching LiDAR 3D detections with RGB 2D detections and filtering out unmatched LiDAR detections; and (ii) cascade fusion, to recover missed objects from LiDAR by generating new 3D frustum proposals corresponding to unmatched RGB detections. Experiments show that LCF3D is beneficial for domain generalization, as it turns out to be successful in handling different sensor configurations between training and testing domains. LCF3D achieves significant improvements over LiDAR-based methods, particularly for challenging categories like pedestrians and cyclists in the KITTI dataset, as well as motorcycles and bicycles in nuScenes. Code can be downloaded from: https://github.com/CarloSgaravatti/LCF3D.", "AI": {"tldr": "介绍了一种名为LCF3D的新型传感器融合框架，用于自动驾驶中3D物体检测。", "motivation": "为了提高自主驾驶车辆对RGB图像和LiDAR点云数据源的有效结合，并解决这些来源之间的准确组合难题。", "method": "提出了一个融合2D和3D物体检测的新方法，通过迟滞级联融合来减少LiDAR误检率并恢复被遗漏的物体。", "result": "实验表明LCF3D在处理不同训练和测试域中的传感器配置方面表现出色，并且显著提高了对行人、自行车等挑战性类别的检测效果。", "conclusion": "LCF3D框架展示了其在自动驾驶中通过融合多种传感器数据进行鲁棒性和实时的三维物体检测上的优越性能。"}}
{"id": "2601.09809", "pdf": "https://arxiv.org/pdf/2601.09809", "abs": "https://arxiv.org/abs/2601.09809", "authors": ["Samar Abdelghani", "Soumaya Cherkaoui"], "title": "QFed: Parameter-Compact Quantum-Classical Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Organizations and enterprises across domains such as healthcare, finance, and scientific research are increasingly required to extract collective intelligence from distributed, siloed datasets while adhering to strict privacy, regulatory, and sovereignty requirements. Federated Learning (FL) enables collaborative model building without sharing sensitive raw data, but faces growing challenges posed by statistical heterogeneity, system diversity, and the computational burden from complex models. This study examines the potential of quantum-assisted federated learning, which could cut the number of parameters in classical models by polylogarithmic factors and thus lessen training overhead. Accordingly, we introduce QFed, a quantum-enabled federated learning framework aimed at boosting computational efficiency across edge device networks. We evaluate the proposed framework using the widely adopted FashionMNIST dataset. Experimental results show that QFed achieves a 77.6% reduction in the parameter count of a VGG-like model while maintaining an accuracy comparable to classical approaches in a scalable environment. These results point to the potential of leveraging quantum computing within a federated learning context to strengthen FL capabilities of edge devices.", "AI": {"tldr": "介绍了一种名为QFed的量子辅助联邦学习框架，旨在提高边缘设备网络中的计算效率。", "motivation": "面对统计异质性、系统多样性和复杂模型带来的计算负担等挑战，提出通过量子辅助联邦学习减少参数数量和训练开销以提升性能。", "method": "提出了一个名为QFed的量子增强型联邦学习框架，并使用FashionMNIST数据集进行评估。", "result": "实验表明，相较于传统方法，QFed在保持可比准确率的同时实现了VGG样模型中77.6%的参数数量减少。", "conclusion": "研究结果表明，在联邦学习环境中利用量子计算技术有可能增强边缘设备的FL能力。"}}
{"id": "2601.09806", "pdf": "https://arxiv.org/pdf/2601.09806", "abs": "https://arxiv.org/abs/2601.09806", "authors": ["Shahrzad Sayyafzadeh", "Hongmei Chi", "Shonda Bernadin"], "title": "Diffusion-Driven Deceptive Patches: Adversarial Manipulation and Forensic Detection in Facial Identity Verification", "categories": ["cs.CV", "cs.AI"], "comment": "This manuscript is a preprint. A revised version of this work has been accepted for publication in the Springer Nature book Artificial Intelligence-Driven Forensics. This version includes one additional figure for completeness", "summary": "This work presents an end-to-end pipeline for generating, refining, and evaluating adversarial patches to compromise facial biometric systems, with applications in forensic analysis and security testing. We utilize FGSM to generate adversarial noise targeting an identity classifier and employ a diffusion model with reverse diffusion to enhance imperceptibility through Gaussian smoothing and adaptive brightness correction, thereby facilitating synthetic adversarial patch evasion. The refined patch is applied to facial images to test its ability to evade recognition systems while maintaining natural visual characteristics. A Vision Transformer (ViT)-GPT2 model generates captions to provide a semantic description of a person's identity for adversarial images, supporting forensic interpretation and documentation for identity evasion and recognition attacks. The pipeline evaluates changes in identity classification, captioning results, and vulnerabilities in facial identity verification and expression recognition under adversarial conditions. We further demonstrate effective detection and analysis of adversarial patches and adversarial samples using perceptual hashing and segmentation, achieving an SSIM of 0.95.", "AI": {"tldr": "本文提出了一种用于生成、优化和评估欺骗性补丁的端到端流程，以对抗面部生物识别系统，并应用于取证分析和安全测试。", "motivation": "为了提高对人脸识别系统的攻击能力并增强在对抗条件下的人脸身份验证和表情识别漏洞检测技术，研究者们希望开发出更隐蔽且有效的对抗样本。", "method": "使用FGSM生成针对身份分类器的对抗噪声，并利用反向扩散模型来优化这些补丁以增加其隐蔽性。通过Vision Transformer (ViT)-GPT2模型生成描述个人身份的语义描述，支持对对抗图像的身份逃避和识别攻击进行取证解释和文档记录。", "result": "实验结果显示，在应用了经过优化的欺骗性补丁后，人脸被成功地逃避了识别系统，并且在视觉上保持了自然特征。同时使用感知哈希和分割技术能够有效检测并分析对抗样本，达到了SSIM为0.95的结果。", "conclusion": "本文提出的方法可以有效地生成具有高度隐蔽性的欺骗性补丁，这些补丁能够在对抗条件下成功逃避面部身份验证系统，并且对识别攻击的取证解释和文档记录提供了支持。"}}
{"id": "2601.09805", "pdf": "https://arxiv.org/pdf/2601.09805", "abs": "https://arxiv.org/abs/2601.09805", "authors": ["Nguyen Minh Phuong", "Dang Huu Tien", "Naoya Inoue"], "title": "Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention", "categories": ["cs.AI", "cs.LG"], "comment": "Findings of EACL 2026", "summary": "Modern logical reasoning with LLMs primarily relies on employing complex interactive frameworks that decompose the reasoning process into subtasks solved through carefully designed prompts or requiring external resources (e.g., symbolic solvers) to exploit their strong logical structures. While interactive approaches introduce additional overhead, hybrid approaches depend on external components, which limit their scalability. A non-interactive, end-to-end framework enables reasoning to emerge within the model itself -- improving generalization while preserving analyzability without any external resources. In this work, we introduce a non-interactive, end-to-end framework for reasoning tasks. We show that introducing structural information into the few-shot prompt activates a subset of attention heads that patterns aligned with logical reasoning operators. Building on this insight, we propose Attention-Aware Intervention (AAI), an inference-time intervention method that reweights attention scores across selected heads identified by their logical patterns. AAI offers an efficient way to steer the model's reasoning toward leveraging prior knowledge through attention modulation. Extensive experiments show that AAI enhances logical reasoning performance across diverse benchmarks and model architectures, while incurring negligible additional computational overhead. Code is available at https://github.com/phuongnm94/aai_for_logical_reasoning.", "AI": {"tldr": "本文提出了一种非交互式的端到端框架，通过注意力感知干预（AAI）来提高大语言模型的逻辑推理能力。", "motivation": "传统的逻辑推理依赖于复杂的交互式框架或外部资源，这增加了额外开销并限制了可扩展性。作者希望通过一种无需外部资源的方法，在模型内部实现更好的归纳推理能力，并保持分析性。", "method": "引入结构信息到少量样本提示中以激活与逻辑操作符对齐的注意力头；基于此提出注意力感知干预（AAI），通过调节选定注意力头的权重来引导模型利用先验知识进行推理。", "result": "实验结果显示，AAI方法在多样化基准测试和多种模型架构上提高了逻辑推理性能，同时计算开销可忽略不计。", "conclusion": "通过注意力感知干预（AAI），可以在大语言模型中实现高效的非交互式端到端逻辑推理框架，并显著提升其逻辑推理能力。"}}
{"id": "2601.09773", "pdf": "https://arxiv.org/pdf/2601.09773", "abs": "https://arxiv.org/abs/2601.09773", "authors": ["Binglei Lou", "Ruilin Wu", "Philip Leong"], "title": "Enhancing LUT-based Deep Neural Networks Inference through Architecture and Connectivity Optimization", "categories": ["cs.AR", "cs.AI"], "comment": "arXiv admin note: substantial text overlap with arXiv:2503.12829, arXiv:2406.04910", "summary": "Deploying deep neural networks (DNNs) on resource-constrained edge devices such as FPGAs requires a careful balance among latency, power, and hardware resource usage, while maintaining high accuracy. Existing Lookup Table (LUT)-based DNNs -- such as LogicNets, PolyLUT, and NeuraLUT -- face two critical challenges: the exponential growth of LUT size and inefficient random sparse connectivity. This paper presents SparseLUT, a comprehensive framework that addresses these challenges through two orthogonal optimizations. First, we propose an architectural enhancement that aggregates multiple PolyLUT sub-neurons via an adder, significantly reducing LUT consumption by 2.0x-13.9x and lowering inference latency by 1.2x-1.6x, all while maintaining comparable accuracy. Building upon this foundation, we further introduce a non-greedy training algorithm that optimizes neuron connectivity by selectively pruning less significant inputs and strategically regrowing more effective ones. This training optimization, which incurs no additional area and latency overhead, delivers consistent accuracy improvements across benchmarks -- achieving up to a 2.13% gain on MNIST and 0.94% on Jet Substructure Classification compared to existing LUT-DNN approaches.", "AI": {"tldr": "该论文提出了一种名为SparseLUT的框架，通过架构优化和训练算法改进来解决基于查找表（LUT）的深度神经网络（DNN）在边缘设备部署时面临的挑战。", "motivation": "现有的基于LUT的DNN如LogicNets、PolyLUT和NeuraLUT在资源受限的边缘设备上部署时，面临着查找表大小呈指数增长和连接稀疏性低效的问题。因此，该论文旨在通过架构和训练算法优化解决这些问题。", "method": "SparseLUT框架包括两个关键步骤：1) 一种结构增强技术，聚合多个PolyLUT子神经元并通过加法器降低LUT消耗；2) 一个非贪婪的训练算法，用于优化神经元连接性，通过剪枝不重要的输入和再生更有用的输入。", "result": "该框架能够减少LUT消耗2.0x-13.9倍，降低推理延迟1.2x-1.6倍，并在没有增加额外面积和延迟开销的情况下提升准确度，在MNIST上达到最高2.13%的增益，在Jet Substructure Classification上达到0.94%。", "conclusion": "SparseLUT框架通过架构优化和非贪婪训练算法，有效减少了LUT消耗并提高了DNN在边缘设备上的推理效率，同时保持或提升了模型准确度。"}}
{"id": "2601.09772", "pdf": "https://arxiv.org/pdf/2601.09772", "abs": "https://arxiv.org/abs/2601.09772", "authors": ["Paweł Niszczota", "Cassandra Grützner"], "title": "Antisocial behavior towards large language model users: experimental evidence", "categories": ["cs.AI", "cs.CL", "cs.CY", "econ.GN"], "comment": ":91A80; 91B42; 91A80ACM Class:H.1.2; H.5.2; I.2.7; K.4.2; J.4", "summary": "The rapid spread of large language models (LLMs) has raised concerns about the social reactions they provoke. Prior research documents negative attitudes toward AI users, but it remains unclear whether such disapproval translates into costly action. We address this question in a two-phase online experiment (N = 491 Phase II participants; Phase I provided targets) where participants could spend part of their own endowment to reduce the earnings of peers who had previously completed a real-effort task with or without LLM support. On average, participants destroyed 36% of the earnings of those who relied exclusively on the model, with punishment increasing monotonically with actual LLM use. Disclosure about LLM use created a credibility gap: self-reported null use was punished more harshly than actual null use, suggesting that declarations of \"no use\" are treated with suspicion. Conversely, at high levels of use, actual reliance on the model was punished more strongly than self-reported reliance. Taken together, these findings provide the first behavioral evidence that the efficiency gains of LLMs come at the cost of social sanctions.", "AI": {"tldr": "本文通过实验研究了大型语言模型（LLM）使用者遭受的社会制裁行为。", "motivation": "鉴于大型语言模型的迅速普及引发了关于它们引发的社会反应的关注，作者希望探究负面态度是否会导致针对AI用户的实质性惩罚。", "method": "研究人员进行了一项两阶段在线实验，参与者可以花费自己的报酬来减少那些曾经使用或未使用LLM完成任务的人的收益。", "result": "研究发现，平均而言，参与者会破坏仅依赖模型者36%的收入，并且这种惩罚随着实际使用的LLM增加而单调上升。此外，对LLM使用的披露会导致信誉差距：报告没有使用的受到更严厉的处罚，而在高使用率时，实际使用比自我报告的使用受到更多惩罚。", "conclusion": "这些发现提供了行为证据，表明LLM带来的效率提升是以社会制裁为代价的。"}}
{"id": "2601.09771", "pdf": "https://arxiv.org/pdf/2601.09771", "abs": "https://arxiv.org/abs/2601.09771", "authors": ["Aradhya Dixit", "Shreem Dixit"], "title": "PCN-Rec: Agentic Proof-Carrying Negotiation for Reliable Governance-Constrained Recommendation", "categories": ["cs.AI"], "comment": null, "summary": "Modern LLM-based recommenders can generate compelling ranked lists, but they struggle to reliably satisfy governance constraints such as minimum long-tail exposure or diversity requirements. We present PCN-Rec, a proof-carrying negotiation pipeline that separates natural-language reasoning from deterministic enforcement. A base recommender (MF/CF) produces a candidate window of size W, which is negotiated by two agents: a User Advocate optimizing relevance and a Policy Agent enforcing constraints. A mediator LLM synthesizes a top-N slate together with a structured certificate (JSON) describing the claimed constraint satisfaction. A deterministic verifier recomputes all constraints from the slate and accepts only verifier-checked certificates; if verification fails, a deterministic constrained-greedy repair produces a compliant slate for re-verification, yielding an auditable trace. On MovieLens-100K with governance constraints, PCN-Rec achieves a 98.55% pass rate on feasible users (n = 551, W = 80) versus a one-shot single-LLM baseline without verification/repair, while preserving utility with only a 0.021 absolute drop in NDCG@10 (0.403 vs. 0.424); differences are statistically significant (p < 0.05).", "AI": {"tldr": "介绍了一种名为PCN-Rec的推荐系统，该系统通过代理证明携带谈判来确保满足治理约束。", "motivation": "现代基于LLM的推荐器在生成排名列表方面表现出色，但在可靠地满足诸如最低长尾暴露或多样性要求等治理约束时面临困难。", "method": "PCN-Rec包含一个基础推荐者（如MF/CF），产生候选窗口。两个代理（用户倡导者和政策执行者）进行协商，并由调解LLM合成最终的前N个列表并生成证书，确定是否满足约束条件。如有必要，验证器会修复以确保合规性。", "result": "在具有治理约束的MovieLens-100K数据集上，PCN-Rec实现了98.55%的通过率，并且仅在NDCG@10指标上有微小下降（0.403 vs 0.424），差异具有统计学意义。", "conclusion": "PCN-Rec系统有效解决了现代推荐器满足治理约束的问题，同时保持了较高的推荐质量。"}}
{"id": "2601.09770", "pdf": "https://arxiv.org/pdf/2601.09770", "abs": "https://arxiv.org/abs/2601.09770", "authors": ["Chen Chen", "Jiawei Shao", "Dakuan Lu", "Haoyi Hu", "Xiangcheng Liu", "Hantao Yao", "Wu Liu"], "title": "GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in vision-language models (VLMs) and reinforcement learning (RL) have driven progress in GUI automation. However, most existing methods rely on static, one-shot visual inputs and passive perception, lacking the ability to adaptively determine when, whether, and how to observe the interface. We present GUI-Eyes, a reinforcement learning framework for active visual perception in GUI tasks. To acquire more informative observations, the agent learns to make strategic decisions on both whether and how to invoke visual tools, such as cropping or zooming, within a two-stage reasoning process. To support this behavior, we introduce a progressive perception strategy that decomposes decision-making into coarse exploration and fine-grained grounding, coordinated by a two-level policy. In addition, we design a spatially continuous reward function tailored to tool usage, which integrates both location proximity and region overlap to provide dense supervision and alleviate the reward sparsity common in GUI environments. On the ScreenSpot-Pro benchmark, GUI-Eyes-3B achieves 44.8% grounding accuracy using only 3k labeled samples, significantly outperforming both supervised and RL-based baselines. These results highlight that tool-aware active perception, enabled by staged policy reasoning and fine-grained reward feedback, is critical for building robust and data-efficient GUI agents.", "AI": {"tldr": "介绍GUI-Eyes，一个用于GUI任务的主动视觉感知的强化学习框架。", "motivation": "现有方法依赖静态的一次性视觉输入和被动感知，缺乏适应性地决定何时、是否以及如何观察界面的能力。", "method": "引入逐步感知策略，将决策分解为粗略探索与细粒度定位，并通过两级政策协调；设计了空间连续奖励函数以解决GUI环境中奖励稀疏的问题。", "result": "在ScreenSpot-Pro基准测试中，使用仅3k标记样本，GUI-Eyes-3B实现了44.8%的接地准确性，显著超越监督和基于RL的基线模型。", "conclusion": "工具感知主动感知对于构建健壮且数据高效的GUI代理至关重要，这得益于阶段性策略推理和细粒度奖励反馈的支持。"}}
{"id": "2601.09768", "pdf": "https://arxiv.org/pdf/2601.09768", "abs": "https://arxiv.org/abs/2601.09768", "authors": ["Lorenzo Monti", "Tatiana Muraveva", "Brian Sheridan", "Davide Massari", "Alessia Garofalo", "Gisella Clementini", "Umberto Michelucci"], "title": "CLiMB: A Domain-Informed Novelty Detection Clustering Framework for Scientific Discovery", "categories": ["astro-ph.IM", "astro-ph.GA", "cs.AI"], "comment": "28 pages, 4 figures", "summary": "In data-driven scientific discovery, a challenge lies in classifying well-characterized phenomena while identifying novel anomalies. Current semi-supervised clustering algorithms do not always fully address this duality, often assuming that supervisory signals are globally representative. Consequently, methods often enforce rigid constraints that suppress unanticipated patterns or require a pre-specified number of clusters, rendering them ineffective for genuine novelty detection. To bridge this gap, we introduce CLiMB (CLustering in Multiphase Boundaries), a domain-informed framework decoupling the exploitation of prior knowledge from the exploration of unknown structures. Using a sequential two-phase approach, CLiMB first anchors known clusters using constrained partitioning, and subsequently applies density-based clustering to residual data to reveal arbitrary topologies. We demonstrate this framework on RR Lyrae stars data from the Gaia Data Release 3. CLiMB attains an Adjusted Rand Index of 0.829 with 90% seed coverage in recovering known Milky Way substructures, drastically outperforming heuristic and constraint-based baselines, which stagnate below 0.20. Furthermore, sensitivity analysis confirms CLiMB's superior data efficiency, showing monotonic improvement as knowledge increases. Finally, the framework successfully isolates three dynamical features (Shiva, Shakti, and the Galactic Disk) in the unlabelled field, validating its potential for scientific discovery.", "AI": {"tldr": "介绍了一种名为CLiMB的领域知情新颖性检测聚类框架，用于科学发现。", "motivation": "现有的半监督聚类算法无法同时很好地分类已知现象和识别新颖异常，因此提出了CLiMB来解决这一问题。", "method": "CLiMB采用两阶段顺序方法，首先使用受限分区锚定已知集群，然后对残余数据应用基于密度的聚类以揭示任意拓扑结构。", "result": "在Gaia Data Release 3中的RR Lyrae星数据分析中，CLiMB获得了0.829的调整兰德指数和90%种子覆盖率，显著优于启发式和约束基线方法。", "conclusion": "实验结果验证了CLiMB框架的有效性及其在科学发现领域的潜力。"}}
{"id": "2601.09765", "pdf": "https://arxiv.org/pdf/2601.09765", "abs": "https://arxiv.org/abs/2601.09765", "authors": ["Herman Cappelen", "Simon Goldstein", "John Hawthorne"], "title": "AI Survival Stories: a Taxonomic Analysis of AI Existential Risk", "categories": ["cs.AI"], "comment": "ef:Philosophy of AI. (1): 1-19", "summary": "Since the release of ChatGPT, there has been a lot of debate about whether AI systems pose an existential risk to humanity. This paper develops a general framework for thinking about the existential risk of AI systems. We analyze a two premise argument that AI systems pose a threat to humanity. Premise one: AI systems will become extremely powerful. Premise two: if AI systems become extremely powerful, they will destroy humanity. We use these two premises to construct a taxonomy of survival stories, in which humanity survives into the far future. In each survival story, one of the two premises fails. Either scientific barriers prevent AI systems from becoming extremely powerful; or humanity bans research into AI systems, thereby preventing them from becoming extremely powerful; or extremely powerful AI systems do not destroy humanity, because their goals prevent them from doing so; or extremely powerful AI systems do not destroy humanity, because we can reliably detect and disable systems that have the goal of doing so. We argue that different survival stories face different challenges. We also argue that different survival stories motivate different responses to the threats from AI. Finally, we use our taxonomy to produce rough estimates of P(doom), the probability that humanity will be destroyed by AI.", "AI": {"tldr": "本文提出了一个关于人工智能存在性风险的框架，并通过构建人类在未来存活的故事分类来探讨如何避免AI对人类构成威胁。", "motivation": "鉴于ChatGPT发布后对于AI系统是否给人类带来生存威胁的广泛讨论，作者希望通过分析两种前提下的逻辑论证，探索人类面对AI风险时可能的存活路径。", "method": "文章构建了一个基于两个前提假设（AI将变得极其强大和如果AI变得极其强大则会毁灭人类）的故事分类学。在每个存活故事中，至少有一个前提是不成立的。", "result": "作者认为不同的存活故事面临不同的挑战，并且这些故事激励了对来自人工智能威胁的不同反应策略。最后，利用该分类体系提供了对P(doom)，即人类被AI摧毁的概率进行粗略估计的方法。", "conclusion": "通过提出一个关于AI存在性风险的框架和构建不同的生存故事分类，文章揭示了在不同情景下避免AI带来的潜在灾难所面临的挑战，并为制定应对策略提供参考。"}}
{"id": "2601.09762", "pdf": "https://arxiv.org/pdf/2601.09762", "abs": "https://arxiv.org/abs/2601.09762", "authors": ["Zhiyi Xue", "Xiaohong Chen", "Min Zhang"], "title": "Explicating Tacit Regulatory Knowledge from LLMs to Auto-Formalize Requirements for Compliance Test Case Generation", "categories": ["cs.SE", "cs.AI"], "comment": "16 pages, 8 figures, 4 tables", "summary": "Compliance testing in highly regulated domains is crucial but largely manual, requiring domain experts to translate complex regulations into executable test cases. While large language models (LLMs) show promise for automation, their susceptibility to hallucinations limits reliable application. Existing hybrid approaches mitigate this issue by constraining LLMs with formal models, but still rely on costly manual modeling. To solve this problem, this paper proposes RAFT, a framework for requirements auto-formalization and compliance test generation via explicating tacit regulatory knowledge from multiple LLMs. RAFT employs an Adaptive Purification-Aggregation strategy to explicate tacit regulatory knowledge from multiple LLMs and integrate it into three artifacts: a domain meta-model, a formal requirements representation, and testability constraints. These artifacts are then dynamically injected into prompts to guide high-precision requirement formalization and automated test generation. Experiments across financial, automotive, and power domains show that RAFT achieves expert-level performance, substantially outperforms state-of-the-art (SOTA) methods while reducing overall generation and review time.", "AI": {"tldr": "本文提出RAFT框架，通过从多个大型语言模型中提取隐性监管知识来自动化需求形式化和合规测试用例生成。", "motivation": "在高度监管的领域，合规测试是至关重要的但大部分手动进行，需要领域专家将复杂法规转化为可执行的测试用例。虽然大型语言模型有自动化的潜力，但是它们容易出现幻觉限制了其可靠应用。现有的混合方法通过正式模型约束大型语言模型来缓解这个问题，但仍依赖于成本高昂的手动建模。", "method": "RAFT框架采用自适应净化聚合策略从多个大型语言模型中提取隐性监管知识，并将其整合为领域元模型、形式化需求表示和测试性约束等三个制品。这些制品被动态注入提示以指导高精度的需求形式化和自动化测试用例生成。", "result": "实验结果显示，RAFT在金融、汽车和能源等领域达到了专家级别的性能表现，并大幅超越了现有方法，同时减少了生成和审查时间。", "conclusion": "RAFT框架通过从多个大型语言模型中提取隐性知识，实现了需求形式化和合规测试用例的自动化生成，提高了效率并降低了成本。"}}
{"id": "2601.09760", "pdf": "https://arxiv.org/pdf/2601.09760", "abs": "https://arxiv.org/abs/2601.09760", "authors": ["Jiali Cheng", "Rui Pan", "Hadi Amiri"], "title": "Investigating Tool-Memory Conflicts in Tool-Augmented LLMs", "categories": ["cs.SE", "cs.AI"], "comment": "R2-FM Workshop @ ICML 2025", "summary": "Tool-augmented large language models (LLMs) have powered many applications. However, they are likely to suffer from knowledge conflict. In this paper, we propose a new type of knowledge conflict -- Tool-Memory Conflict (TMC), where the internal parametric knowledge contradicts with the external tool knowledge for tool-augmented LLMs. We find that existing LLMs, though powerful, suffer from TMC, especially on STEM-related tasks. We also uncover that under different conditions, tool knowledge and parametric knowledge may be prioritized differently. We then evaluate existing conflict resolving techniques, including prompting-based and RAG-based methods. Results show that none of these approaches can effectively resolve tool-memory conflicts.", "AI": {"tldr": "本文研究了工具增强的大型语言模型中的工具-记忆冲突问题，并评估了解决这些冲突的方法。", "motivation": "动机在于解决工具增强型LLMs的知识冲突，特别是STEM领域内的工具-记忆冲突。", "method": "提出并定义了工具-记忆冲突（TMC）的概念，测试了现有的解决知识冲突的技术。", "result": "发现现有的方法，包括基于提示和RAG的方法，都无法有效解决工具-记忆冲突问题。", "conclusion": "结论指出，在处理STEM相关任务时，现有LLMs存在工具-记忆冲突，并且目前没有有效的解决方案可以完全解决这种冲突。"}}
{"id": "2601.09757", "pdf": "https://arxiv.org/pdf/2601.09757", "abs": "https://arxiv.org/abs/2601.09757", "authors": ["Sonia Katyal"], "title": "Democracy and Distrust in an Era of Artificial Intelligence", "categories": ["cs.CY", "cs.AI"], "comment": "Daedalus, Journal of the American Academy of Arts & Sciences 2022. Available at SSRN: https://ssrn.com/abstract=4099147", "summary": "This essay examines how judicial review should adapt to address challenges posed by artificial intelligence decision-making, particularly regarding minority rights and interests. As I argue in this essay, the rise of three trends-privatization, prediction, and automation in AI-have combined to pose similar risks to minorities. Here, I outline what a theory of judicial review would look like in an era of artificial intelligence, analyzing both the limitations and the possibilities of judicial review of AI. I draw on cases in which AI decision-making has been challenged in courts, to show how concepts of due process and equal protection can be recuperated in a modern AI era, and even integrated into AI, to provide for better oversight and accountability, offering a framework for judicial review in the AI era that protects minorities from algorithmic discrimination.", "AI": {"tldr": "本文探讨了在人工智能时代，司法审查如何适应由AI决策引发的挑战，尤其是关于少数群体的权利和利益保护。", "motivation": "随着AI私有化、预测能力和自动化趋势的发展，这些因素给少数群体带来了类似的威胁。作者希望通过重新审视公正程序和平等保护的概念，在AI时代为司法审查提供一个框架，以防止算法歧视并确保问责制。", "method": "通过分析法院中对AI决策挑战的案例，提出了一种适应于人工智能时代的司法审查理论，讨论了其限制和可能性。", "result": "本文提出了在AI时代保护少数群体免受算法歧视的法律框架，并展示了如何将公正程序和平等保护的概念融入到AI中，以提供更好的监督和问责机制。", "conclusion": "在AI决策日益普及的时代，司法审查需要适应新的技术环境，通过整合传统法律原则，可以更好地保护少数群体权益并确保AI系统的透明度与公平性。"}}
{"id": "2601.09756", "pdf": "https://arxiv.org/pdf/2601.09756", "abs": "https://arxiv.org/abs/2601.09756", "authors": ["David Brundage"], "title": "Synthetic Data for Veterinary EHR De-identification: Benefits, Limits, and Safety Trade-offs Under Fixed Compute", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Veterinary electronic health records (vEHRs) contain privacy-sensitive identifiers that limit secondary use. While PetEVAL provides a benchmark for veterinary de-identification, the domain remains low-resource. This study evaluates whether large language model (LLM)-generated synthetic narratives improve de-identification safety under distinct training regimes, emphasizing (i) synthetic augmentation and (ii) fixed-budget substitution. We conducted a controlled simulation using a PetEVAL-derived corpus (3,750 holdout/1,249 train). We generated 10,382 synthetic notes using a privacy-preserving \"template-only\" regime where identifiers were removed prior to LLM prompting. Three transformer backbones (PetBERT, VetBERT, Bio_ClinicalBERT) were trained under varying mixtures. Evaluation prioritized document-level leakage rate (the fraction of documents with at least one missed identifier) as the primary safety outcome. Results show that under fixed-sample substitution, replacing real notes with synthetic ones monotonically increased leakage, indicating synthetic data cannot safely replace real supervision. Under compute-matched training, moderate synthetic mixing matched real-only performance, but high synthetic dominance degraded utility. Conversely, epoch-scaled augmentation improved performance: PetBERT span-overlap F1 increased from 0.831 to 0.850 +/- 0.014, and leakage decreased from 6.32% to 4.02% +/- 0.19%. However, these gains largely reflect increased training exposure rather than intrinsic synthetic data quality. Corpus diagnostics revealed systematic synthetic-real mismatches in note length and label distribution that align with persistent leakage. We conclude that synthetic augmentation is effective for expanding exposure but is complementary, not substitutive, for safety-critical veterinary de-identification.", "AI": {"tldr": "研究探讨了在固定计算预算下，使用大型语言模型生成的合成数据来改善兽医电子健康记录（vEHRs）去识别化的安全性。", "motivation": "兽医电子健康记录含有隐私敏感信息，限制其二次使用。虽然PetEVAL提供了一个基准测试，但该领域资源相对匮乏。", "method": "研究采用由PetEVAL衍生出的数据集进行受控模拟实验，生成了10,382条合成笔记，并通过三种转换器模型在不同混合模式下训练。", "result": "结果显示，在固定样本替代情况下，用合成数据替换真实数据会导致泄漏率增加。但在计算匹配的训练中，适度使用合成数据可以达到与完全依赖真实数据相近的表现，而过度依赖则会降低性能。此外，通过轮次扩展的数据增强改善了性能指标。", "conclusion": "研究得出结论认为，合成数据增益虽然能有效扩大曝光量，但不能取代真实监督在兽医去识别化中的作用，主要是作为补充手段使用。"}}
{"id": "2601.09755", "pdf": "https://arxiv.org/pdf/2601.09755", "abs": "https://arxiv.org/abs/2601.09755", "authors": ["Jakub Fil", "Yulia Sandamirskaya", "Hector Gonzalez", "Loïc Azzalin", "Stefan Glüge", "Lukas Friedenstab", "Friedrich Wolf", "Tim Rosmeisl", "Matthias Lohrmann", "Mahmoud Akl", "Khaleel Khan", "Leonie Wolf", "Kristin Richter", "Holm Puder", "Mazhar Ali Bari", "Xuan Choo", "Noha Alharthi", "Michael Hopkins", "Mansoor Hanif Christian Mayr", "Jens Struckmeier", "Steve Furber"], "title": "Heterogeneous computing platform for real-time robotics", "categories": ["cs.NE", "cs.AI", "cs.RO"], "comment": null, "summary": "After Industry 4.0 has embraced tight integration between machinery (OT), software (IT), and the Internet, creating a web of sensors, data, and algorithms in service of efficient and reliable production, a new concept of Society 5.0 is emerging, in which infrastructure of a city will be instrumented to increase reliability, efficiency, and safety. Robotics will play a pivotal role in enabling this vision that is pioneered by the NEOM initiative - a smart city, co-inhabited by humans and robots. In this paper we explore the computing platform that will be required to enable this vision. We show how we can combine neuromorphic computing hardware, exemplified by the Loihi2 processor used in conjunction with event-based cameras, for sensing and real-time perception and interaction with a local AI compute cluster (GPUs) for high-level language processing, cognition, and task planning. We demonstrate the use of this hybrid computing architecture in an interactive task, in which a humanoid robot plays a musical instrument with a human. Central to our design is the efficient and seamless integration of disparate components, ensuring that the synergy between software and hardware maximizes overall performance and responsiveness. Our proposed system architecture underscores the potential of heterogeneous computing architectures in advancing robotic autonomy and interactive intelligence, pointing toward a future where such integrated systems become the norm in complex, real-time applications.", "AI": {"tldr": "论文探讨了如何设计一个异构计算平台，以支持机器人在实时感知和交互中的高效运行。", "motivation": "随着社会5.0的出现，基础设施将被智能化，机器人将在其中扮演关键角色。NEOM智慧城市项目引领了这一愿景，需要一种新的计算平台来实现高效的传感、处理与互动。", "method": "论文介绍了结合神经形态计算硬件（如Loihi2处理器）和事件驱动相机用于实时感知，以及本地AI计算集群（GPU）进行高级语言处理、认知和任务规划的混合架构。通过人形机器人与人类一起演奏音乐的任务展示了该系统的使用。", "result": "实验表明了这种异构计算平台在实现高效且无缝的软硬件协同工作方面的潜力，能够最大化整体性能和响应速度。", "conclusion": "论文强调了此类集成系统在未来复杂实时应用中的前景，并指出了异构计算架构对推动机器人自主性和交互智能的重要性。"}}
{"id": "2601.09753", "pdf": "https://arxiv.org/pdf/2601.09753", "abs": "https://arxiv.org/abs/2601.09753", "authors": ["Carole J. Lee"], "title": "Critically Engaged Pragmatism: A Scientific Norm and Social, Pragmatist Epistemology for AI Science Evaluation Tools", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Crises in peer review capacity, study replication, and AI-fabricated science have intensified interest in automated tools for assessing scientific research. However, the scientific community has a history of decontextualizing and repurposing credibility markers in inapt ways. I caution that AI science evaluation tools are particularly prone to these kinds of inference by false ascent due to contestation about the purposes to which they should be put, their portability across purposes, and technical demands that prioritize data set size over epistemic fit. To counter this, I argue for a social, pragmatist epistemology and a newly articulated norm of Critically Engaged Pragmatism to enjoin scientific communities to vigorously scrutinize the purposes and purpose-specific reliability of AI science evaluation tools. Under this framework, AI science evaluation tools are not objective arbiters of scientific credibility, but the object of the kinds of critical discursive practices that ground the credibility of scientific communities.", "AI": {"tldr": "本文提出了一种名为批判参与实用主义的新规范，用于评估AI科学评价工具的可靠性。", "motivation": "随着同行评审能力危机、研究可重复性问题以及AI伪造科学研究等问题加剧，自动化工具在评估科学研究中的应用引起了广泛关注。然而，科学界历史上存在脱离背景和误用信誉标记的情况，这促使作者提出一种新的规范来应对这些问题。", "method": "文章提出了一个社会实用主义的知识论框架，并引入了“批判参与实用主义”的概念，以呼吁科研社区仔细审查AI科学评价工具的目的及其目的特异的可靠性。", "result": "通过这一框架，AI科学评估工具不是客观仲裁科学信誉的仲裁者，而是接受科学研究群体所依赖的那种批判性讨论实践的对象。", "conclusion": "结论是AI科学评估工具应作为研究社区进行批判性对话和审查的目标，而非被视为独立的、无偏见的评价标准。"}}
{"id": "2601.09750", "pdf": "https://arxiv.org/pdf/2601.09750", "abs": "https://arxiv.org/abs/2601.09750", "authors": ["Robert K. Strehlow", "Tobias Küster", "Oskar F. Kupke", "Brandon Llanque Kurps", "Fikret Sivrikaya", "Sahin Albayrak"], "title": "SAGE: Tool-Augmented LLM Task Solving Strategies in Scalable Multi-Agent Environments", "categories": ["cs.SE", "cs.AI", "cs.HC", "cs.MA"], "comment": null, "summary": "Large language models (LLMs) have proven to work well in question-answering scenarios, but real-world applications often require access to tools for live information or actuation. For this, LLMs can be extended with tools, which are often defined in advance, also allowing for some fine-tuning for specific use cases. However, rapidly evolving software landscapes and individual services require the constant development and integration of new tools. Domain- or company-specific tools can greatly elevate the usefulness of an LLM, but such custom tools can be problematic to integrate, or the LLM may fail to reliably understand and use them. For this, we need strategies to define new tools and integrate them into the LLM dynamically, as well as robust and scalable zero-shot prompting methods that can make use of those tools in an efficient manner. In this paper, we present SAGE, a specialized conversational AI interface, based on the OPACA framework for tool discovery and execution. The integration with OPACA makes it easy to add new tools or services for the LLM to use, while SAGE itself presents rich extensibility and modularity. This not only provides the ability to seamlessly switch between different models (e.g. GPT, LLAMA), but also to add and select prompting methods, involving various setups of differently prompted agents for selecting and executing tools and evaluating the results. We implemented a number of task-solving strategies, making use of agentic concepts and prompting methods in various degrees of complexity, and evaluated those against a comprehensive set of benchmark services. The results are promising and highlight the distinct strengths and weaknesses of different task-solving strategies. Both SAGE and the OPACA framework, as well as the different benchmark services and results, are available as Open Source/Open Data on GitHub.", "AI": {"tldr": "本文介绍了SAGE，一个基于OPACA框架的专门用于扩展LLM工具发现和执行能力的对话AI接口。", "motivation": "大型语言模型（LLMs）在问答场景中表现出色，但在实际应用中通常需要访问实时信息或行动工具。现有方法难以动态集成新工具并有效利用它们。", "method": "SAGE结合了OPACA框架来轻松添加新的工具和服务供LLM使用，并实现了丰富的扩展性和模块化设计。它实施了几种任务解决策略，涵盖了不同复杂度的代理概念和提示方法。", "result": "实验结果展示了各种任务解决策略的不同优势与劣势，总体上是令人鼓舞的。", "conclusion": "SAGE及其OPACA框架，以及不同的基准服务和结果均作为开源/开放数据在GitHub上提供。"}}
{"id": "2601.09749", "pdf": "https://arxiv.org/pdf/2601.09749", "abs": "https://arxiv.org/abs/2601.09749", "authors": ["Suriya Sureshkumar"], "title": "R-LAM: Reproducibility-Constrained Large Action Models for Scientific Workflow Automation", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "9 pages, 3 figures, 1 Table, 2 Artifacts", "summary": "Large Action Models (LAMs) extend large language models by enabling autonomous decision-making and tool execution, making them promising for automating scientific workflows. However, scientific workflows impose strict requirements on reproducibility, auditability, and deterministic execution, which are not satisfied by generic LLM-based agents. Unconstrained action generation can lead to silent state changes, non-deterministic executions, and irreproducible experimental results, limiting the applicability of LAMs in scientific settings. In this paper, we propose R-LAM, a reproducibility-constrained framework for applying Large Action Models to scientific workflow automation. R-LAM introduces structured action schemas, deterministic execution policies, and explicit provenance tracking to ensure that every action and intermediate artifact is auditable and replayable. The framework supports failure-aware execution loops and controlled workflow forking, enabling iterative experimentation without compromising reproducibility. We implement R-LAM as a lightweight Python framework and release it as an open-source PyPI package to facilitate reproducible research. An experimental evaluation of representative scientific workflows demonstrates that R-LAM improves reproducibility success rates and execution reliability compared to unconstrained LLM-based agents, while retaining adaptive control over workflow execution.", "AI": {"tldr": "本文提出了R-LAM框架，以确保在科学工作流自动化中使用大型动作模型时的可重复性和确定性。", "motivation": "通用的大语言模型代理无法满足严格的可重复性、审计能力和确定性执行要求，这些是科学工作流中的必要条件。因此，需要一种新的方法来解决这个问题并提高大动作模型在科学领域的适用性。", "method": "R-LAM框架通过引入结构化操作模式、确定性执行策略和显式出处跟踪来确保每个操作和中间工件都是可审计和可重放的，并支持故障感知执行循环和控制工作流分叉，以实现迭代实验而不妥协重复性。", "result": "实验表明，与不受约束的大语言模型代理相比，R-LAM框架提高了代表性科学工作流程中的可重复性成功率和执行可靠性。", "conclusion": "研究得出结论，通过实施R-LAM作为轻量级Python框架并作为开源PyPI包发布，可以促进科学研究的可重复性，同时保持对工作流执行的自适应控制。"}}
{"id": "2601.09748", "pdf": "https://arxiv.org/pdf/2601.09748", "abs": "https://arxiv.org/abs/2601.09748", "authors": ["Jose Eduardo Ulloa", "Diego R. Llanos"], "title": "Instalación, configuración y utilización de un nodo Bitcoin en Linux", "categories": ["cs.CR", "cs.ET"], "comment": "20 pages, in Spanish language", "summary": "This paper documents the installation, configuration, and operation of a full Bitcoin node in a Linux environment, from manual compilation of the source code to complete synchronization with the network. The technical phases of the process are described, the main files generated by Bitcoin Core are analyzed, and the effects of the parameters txindex, prune, dbcache, maxmempool, and maxconnections are empirically studied. System resources during the block download (IBD) mechanism are also documented, and the operational importance of each resource is explained. This paper provides a solid foundation for future research proposals on Bitcoin node performance or for the development of blockchain data query tools.", "AI": {"tldr": "本文记录了在Linux环境中安装、配置并运行一个完整的比特币节点的过程，从源代码手动编译到完全同步网络。", "motivation": "研究和理解比特币节点的性能及区块链数据查询工具开发的基础。", "method": "详细描述了技术过程各阶段，并对参数txindex, prune, dbcache, maxmempool, 和maxconnections进行了实证研究。记录了在区块下载（IBD）机制期间的系统资源使用情况。", "result": "分析了比特币核心生成的主要文件，文档化了节点安装和运行过程中涉及的技术阶段，并解释了每个资源的操作重要性。", "conclusion": "提供了关于比特币节点性能研究或区块链数据查询工具开发的坚实基础。"}}
{"id": "2601.09746", "pdf": "https://arxiv.org/pdf/2601.09746", "abs": "https://arxiv.org/abs/2601.09746", "authors": ["Philip Xu", "Isabel Wagner", "Eerke Boiten"], "title": "Multi-Agent Cooperative Learning for Robust Vision-Language Alignment under OOD Concepts", "categories": ["cs.MA", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "This paper introduces a novel Multi-Agent Cooperative Learning (MACL) framework to address cross-modal alignment collapse in vision-language models when handling out-of-distribution (OOD) concepts. Four core agents, including image, text, name, and coordination agents, collaboratively mitigate modality imbalance through structured message passing. The proposed framework enables multi-agent feature space name learning, incorporates a context exchange enhanced few-shot learning algorithm, and adopts an adaptive dynamic balancing mechanism to regulate inter-agent contributions. Experiments on the VISTA-Beyond dataset demonstrate that MACL significantly improves performance in both few-shot and zero-shot settings, achieving 1-5% precision gains across diverse visual domains.", "AI": {"tldr": "本文提出了一个新颖的多智能体协作学习（MACL）框架，以解决视觉语言模型在处理分布外概念时跨模态对齐崩溃的问题。", "motivation": "该论文旨在通过多智能体协作学习方法，缓解视觉和文本模态之间的不平衡问题，并提高模型在分布外概念下的表现。", "method": "MACL框架包括图像、文本、名称和协调四个核心代理，通过结构化的消息传递来协同工作。该框架实现了跨多个代理的特征空间命名学习，并引入了上下文交换增强的少量样本学习算法及自适应动态平衡机制以调节代理之间的贡献度。", "result": "实验结果表明，在VISTA-Beyond数据集上，MACL在少量样本和零样本设置下都显著提高了性能，实现了跨多个视觉领域的1-5%精度提升。", "conclusion": "研究证明了多智能体协作学习框架的有效性，特别是在处理分布外概念时能够提高视觉语言模型的鲁棒性和准确性。"}}
{"id": "2601.09745", "pdf": "https://arxiv.org/pdf/2601.09745", "abs": "https://arxiv.org/abs/2601.09745", "authors": ["Antonio Abu Nassar", "Eitan Farchi"], "title": "Enhancing Formal Software Specification with Artificial Intelligence", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Formal software specification is known to enable early error detection and explicit invariants, yet it has seen limited industrial adoption due to its high notation overhead and the expertise required to use traditional formal languages. This paper presents a case study showing that recent advances in artificial intelligence make it possible to retain many of the benefits of formal specification while substantially reducing these costs. The necessity of a clear distinction between what is controlled by the system analyst and can highly benefits from the rigor of formal specification and what need not be controlled is demonstrated. We use natural language augmented with lightweight mathematical notation and written in \\LaTeX\\ as an intermediate specification language, which is reviewed and refined by AI prior to code generation. Applied to a nontrivial simulation of organizational knowledge growth, this approach enables early validation, explicit invariants, and correctness by design, while significantly reducing development effort and producing a correct implementation on the first attempt.", "AI": {"tldr": "本文通过案例研究展示了如何利用人工智能技术减少传统形式化软件规格说明的高成本，同时保留其优势。", "motivation": "传统的形式化软件规范虽然能早期检测错误和明确不变量，但由于表示法负担重且需要专业知识，在工业中应用有限。因此，作者希望通过人工智能减轻这些成本。", "method": "使用自然语言与轻量级数学符号结合的中间规格说明语言，并通过AI进行审查和细化，最终生成代码。", "result": "该方法在组织知识增长的非平凡模拟案例中实现早期验证、明确不变量和设计正确性的同时，显著减少了开发努力并首次尝试就产生了正确的实现。", "conclusion": "人工智能技术能够有效减轻形式化软件规格说明的成本，并保留其固有的优点。"}}
{"id": "2601.09740", "pdf": "https://arxiv.org/pdf/2601.09740", "abs": "https://arxiv.org/abs/2601.09740", "authors": ["Oumaima Barhoumi", "Mohamed H Zaki", "Sofiène Tahar"], "title": "Formal Safety Guarantees for Autonomous Vehicles using Barrier Certificates", "categories": ["cs.RO", "cs.AI", "cs.SE"], "comment": "Accepted to AAAI-26 Bridge Program B10: Making Embodied AI Reliable with Testing and Formal Verification", "summary": "Modern AI technologies enable autonomous vehicles to perceive complex scenes, predict human behavior, and make real-time driving decisions. However, these data-driven components often operate as black boxes, lacking interpretability and rigorous safety guarantees. Autonomous vehicles operate in dynamic, mixed-traffic environments where interactions with human-driven vehicles introduce uncertainty and safety challenges. This work develops a formally verified safety framework for Connected and Autonomous Vehicles (CAVs) that integrates Barrier Certificates (BCs) with interpretable traffic conflict metrics, specifically Time-to-Collision (TTC) as a spatio-temporal safety metric. Safety conditions are verified using Satisfiability Modulo Theories (SMT) solvers, and an adaptive control mechanism ensures vehicles comply with these constraints in real time. Evaluation on real-world highway datasets shows a significant reduction in unsafe interactions, with up to 40\\% fewer events where TTC falls below a 3 seconds threshold, and complete elimination of conflicts in some lanes. This approach provides both interpretable and provable safety guarantees, demonstrating a practical and scalable strategy for safe autonomous driving.", "AI": {"tldr": "开发了一种基于障碍证书和可解释的交通冲突指标的安全框架，用于确保自动驾驶车辆在动态混合交通环境中的行驶安全。", "motivation": "现代AI技术虽然使自主驾驶汽车能够感知复杂场景并做出实时决策，但其缺乏可解释性和严格的安全部署。特别是在与人类驾驶者互动时，这些不确定性增加了安全性挑战。", "method": "提出了一个将障碍证书和时间至碰撞（TTC）作为空间-时间安全度量结合的形式验证安全框架，并使用Satisfiability Modulo Theories (SMT)求解器来验证安全条件。此外，采用自适应控制机制以确保车辆实时遵守这些约束。", "result": "在实际高速公路数据集上的评估显示，不安全交互事件减少了40%，某些车道的冲突完全消除。", "conclusion": "这种方法提供了可解释且可证明的安全保障，为实现安全自主驾驶提供了一种实用和可扩展策略。"}}
{"id": "2601.09736", "pdf": "https://arxiv.org/pdf/2601.09736", "abs": "https://arxiv.org/abs/2601.09736", "authors": ["Urmzd Mukhammadnaim"], "title": "Reinforced Linear Genetic Programming", "categories": ["cs.NE", "cs.AI"], "comment": "Bachelor's thesis. Source code can be found at https://www.github.com/urmzd/linear-gp", "summary": "Linear Genetic Programming (LGP) is a powerful technique that allows for a variety of problems to be solved using a linear representation of programs. However, there still exists some limitations to the technique, such as the need for humans to explicitly map registers to actions. This thesis proposes a novel approach that uses Q-Learning on top of LGP, Reinforced Linear Genetic Programming (RLGP) to learn the optimal register-action assignments. In doing so, we introduce a new framework \"linear-gp\" written in memory-safe Rust that allows for extensive experimentation for future works.", "AI": {"tldr": "本文提出了一种新的方法，即在Linear Genetic Programming（LGP）上使用Q-Learning来学习最优的寄存器-动作分配。", "motivation": "尽管线性遗传编程（LGP）是一种强大的技术，可以解决各种问题，但它仍然存在需要人类明确地将寄存器映射到动作上的局限性。因此，本文旨在通过引入强化学习来克服这一限制。", "method": "该方法采用了Q-Learning与LGP结合的方式，并提出了一种新的框架“linear-gp”，使用内存安全的Rust语言编写，以支持未来的广泛实验。", "result": "提出了一个名为\"linear-gp\"的新框架，用内存安全的Rust语言实现，为未来的研究提供了一个强大的工具。", "conclusion": "通过结合Q-Learning和LGP，新的方法解决了传统LGP中需要人工映射寄存器到动作的问题，并展示了其在优化寄存器-动作分配方面的潜力。"}}
{"id": "2601.09734", "pdf": "https://arxiv.org/pdf/2601.09734", "abs": "https://arxiv.org/abs/2601.09734", "authors": ["Yanyi Liu", "Qingwen Yang", "Tiezheng Guo", "Feiyu Qu", "Jun Liu", "Yingyou Wen"], "title": "From Detection to Diagnosis: Advancing Hallucination Analysis with Automated Data Synthesis", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at The 40th Annual AAAI Conference on Artificial Intelligence", "summary": "Hallucinations in Large Language Models (LLMs), defined as the generation of content inconsistent with facts or context, represent a core obstacle to their reliable deployment in critical domains. Current research primarily focuses on binary \"detection\" approaches that, while capable of identifying hallucinations, fail to provide interpretable and actionable feedback for model improvement, thus limiting practical utility. To address this limitation, a new research paradigm is proposed, shifting from \"detection\" to \"diagnosis\". The Hallucination Diagnosis Task is introduced, a task which requires models to not only detect hallucinations, but also perform error localization, causal explanation, and content correction. We develop the Hallucination Diagnosis Generator (HDG), an automated pipeline that systematically generates high-quality training samples with rich diagnostic metadata from raw corpora through multi-dimensional augmentation strategies including controlled fact fabrication and reasoning chain perturbation. Using HDG-generated data, we train HDM-4B-RL, a 4-billion-parameter hallucination diagnosis model, employing Group Relative Policy Optimization (GRPO) with a comprehensive reward function incorporating structural, accuracy, and localization signals. Experimental results demonstrate that our model surpasses previous state-of-the-art detection models on the HaluEval benchmark while achieving comparable performance to advanced general-purpose models. In comprehensive diagnosis tasks, HDM-4B-RL matches the capabilities of larger general models while maintaining a smaller size. This work validates the feasibility and value of hallucination diagnosis, providing an effective methodology for building more trustworthy and reliable generative AI systems.", "AI": {"tldr": "本文提出了一种新的研究范式，从“检测”到“诊断”，开发了幻觉诊断生成器（HDG）并训练了一个40亿参数的幻觉诊断模型HDM-4B-RL。", "motivation": "当前的研究主要集中在二元“检测”方法上，这种方法虽然能够识别幻觉，但未能提供可解释和操作性的反馈以改进模型，限制了实际应用的价值。因此，提出了从“检测”到“诊断”的新范式。", "method": "开发了Hallucination Diagnosis Generator (HDG)，通过多维增强策略系统地生成高质量的训练样本，并使用Group Relative Policy Optimization (GRPO) 训练了HDM-4B-RL模型。", "result": "实验结果表明，该模型在HaluEval基准测试中超越了之前的检测模型，在综合诊断任务上达到了更高级别的一般模型的能力，同时保持较小的模型规模。", "conclusion": "本文验证了幻觉诊断的可行性与价值，并提供了一种有效的方法来构建更加值得信赖和可靠的生成AI系统。"}}
{"id": "2601.09733", "pdf": "https://arxiv.org/pdf/2601.09733", "abs": "https://arxiv.org/abs/2601.09733", "authors": ["Xin Gao", "Xiaoyang Wang", "Yun Zhu", "Mengzhang Cai", "Conghui He", "Lijun Wu"], "title": "Closing the Data Loop: Using OpenDataArena to Engineer Superior Training Datasets", "categories": ["cs.CL", "cs.AI"], "comment": "Superior ODA-Math, ODA-Mixture Datasets", "summary": "The construction of Supervised Fine-Tuning (SFT) datasets is a critical yet under-theorized stage in the post-training of Large Language Models (LLMs), as prevalent practices often rely on heuristic aggregation without a systematic understanding of how individual samples contribute to model performance. In this report, we propose a paradigm shift from ad-hoc curation to a closed-loop dataset engineering framework using OpenDataArena (ODA), which leverages value-anchored rankings and multi-dimensional analysis to transform value benchmarking into feedback signals guiding dataset construction. We instantiate this methodology through two new datasets: \\textbf{ODA-Math-460k}, a specialized mathematics reasoning dataset that utilizes a novel two-stage difficulty-aware pipeline to achieve State-of-the-Art (SOTA) results on benchmarks such as AIME and HMMT, and \\textbf{ODA-Mixture (100k \\& 500k)}, a series of multi-domain instruction datasets built via an ``Anchor-and-Patch'' strategy that outperforms significantly larger open-source baselines. Our empirical results demonstrate that ODA-driven datasets significantly improve both domain-specific reasoning and general utility while achieving superior data efficiency, validating a transition toward data-centric AI where transparent evaluation serves as the primary engine for engineering high-quality training data.", "AI": {"tldr": "本文介绍了一种使用OpenDataArena（ODA）的闭环数据工程框架来优化大型语言模型（LLMs）训练数据集的方法。", "motivation": "文章指出，监督微调（SFT）数据集构建是LLM后训练的关键但缺乏系统性理解的阶段。现有的实践方法往往是基于启发式聚合而没有对单个样本如何影响模型性能进行深入分析。", "method": "本文提出使用ODA框架通过价值锚定排名和多维分析将价值基准测试转化为反馈信号，用于指导数据集构建，并具体实例化了两个新数据集：数学推理数据集ODA-Math-460k和多领域指令数据集ODA-Mixture（100k & 500k）。", "result": "实验结果表明，由ODA驱动的数据集在特定领域的推理能力和通用实用性上均有所提升，并实现了更高的数据效率。", "conclusion": "研究验证了向以数据为中心的人工智能过渡的有效性，其中透明的评估成为制造高质量训练数据的主要引擎。"}}
{"id": "2601.09730", "pdf": "https://arxiv.org/pdf/2601.09730", "abs": "https://arxiv.org/abs/2601.09730", "authors": ["Kurt Miller", "Qiuhao Lu", "William Hersh", "Kirk Roberts", "Steven Bedrick", "Andrew Wen", "Hongfang Liu"], "title": "Clinical Document Metadata Extraction: A Scoping Review", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Clinical document metadata, such as document type, structure, author role, medical specialty, and encounter setting, is essential for accurate interpretation of information captured in clinical documents. However, vast documentation heterogeneity and drift over time challenge harmonization of document metadata. Automated extraction methods have emerged to coalesce metadata from disparate practices into target schema. This scoping review aims to catalog research on clinical document metadata extraction, identify methodological trends and applications, and highlight gaps. We followed the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) guidelines to identify articles that perform clinical document metadata extraction. We initially found and screened 266 articles published between January 2011 and August 2025, then comprehensively reviewed 67 we deemed relevant to our study. Among the articles included, 45 were methodological, 17 used document metadata as features in a downstream application, and 5 analyzed document metadata composition. We observe myriad purposes for methodological study and application types. Available labelled public data remains sparse except for structural section datasets. Methods for extracting document metadata have progressed from largely rule-based and traditional machine learning with ample feature engineering to transformer-based architectures with minimal feature engineering. The emergence of large language models has enabled broader exploration of generalizability across tasks and datasets, allowing the possibility of advanced clinical text processing systems. We anticipate that research will continue to expand into richer document metadata representations and integrate further into clinical applications and workflows.", "AI": {"tldr": "这篇论文的主任务是对临床文档元数据提取的研究进行范围性综述。", "motivation": "临床文档中的元数据对于准确解释文档信息至关重要，但由于文档异质性和时间变化带来的挑战，需要对自动化的元数据提取方法进行研究和总结。", "method": "遵循PRISMA-ScR指南筛选并综合回顾了2011年1月至2025年8月间发布的与临床文档元数据提取相关的67篇文献。", "result": "发现了45篇是关于方法论的研究，17篇使用元数据作为下游应用的特征，5篇分析了文档元数据构成。从基于规则和传统机器学习的方法发展到基于变压器架构的方法，并且大型语言模型的发展促进了跨任务和数据集的泛化能力研究。", "conclusion": "预计未来研究将进一步扩展文档元数据表示形式并集成到临床应用与工作流程中。"}}
{"id": "2601.09729", "pdf": "https://arxiv.org/pdf/2601.09729", "abs": "https://arxiv.org/abs/2601.09729", "authors": ["Tohida Rehman"], "title": "Enhancing Business Analytics through Hybrid Summarization of Financial Reports", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 2 figures, 2 tables", "summary": "Financial reports and earnings communications contain large volumes of structured and semi structured information, making detailed manual analysis inefficient. Earnings conference calls provide valuable evidence about a firm's performance, outlook, and strategic priorities. The manual analysis of lengthy call transcripts requires substantial effort and is susceptible to interpretive bias and unintentional error. In this work, we present a hybrid summarization framework that combines extractive and abstractive techniques to produce concise and factually reliable Reuters-style summaries from the ECTSum dataset. The proposed two stage pipeline first applies the LexRank algorithm to identify salient sentences, which are subsequently summarized using fine-tuned variants of BART and PEGASUS designed for resource constrained settings. In parallel, we fine-tune a Longformer Encoder-Decoder (LED) model to directly capture long-range contextual dependencies in financial documents. Model performance is evaluated using standard automatic metrics, including ROUGE, METEOR, MoverScore, and BERTScore, along with domain-specific variants such as SciBERTScore and FinBERTScore. To assess factual accuracy, we further employ entity-level measures based on source-precision and F1-target. The results highlight complementary trade offs between approaches, long context models yield the strongest overall performance, while the hybrid framework achieves competitive results with improved factual consistency under computational constraints. These findings support the development of practical summarization systems for efficiently distilling lengthy financial texts into usable business insights.", "AI": {"tldr": "本文提出了一种结合抽取式和抽象式的混合框架，用于从财务报告中生成简洁且事实可靠的总结。", "motivation": "由于财务报告和收益沟通包含大量结构化和半结构化的信息，手动分析效率低下且容易出错。此外，收益电话会议的长篇文字记录也需要大量的精力进行分析。", "method": "本研究提出了一种两阶段管道方法：首先使用LexRank算法识别关键句子，然后利用微调版本的BART和PEGASUS模型生成摘要；同时，还对Longformer Encoder-Decoder（LED）模型进行了微调以捕捉长范围上下文依赖性。", "result": "通过标准自动度量指标（如ROUGE、METEOR、MoverScore和BERTScore）、领域特定变体（如SciBERTScore和FinBERTScore），以及基于源精确度和F1目标的实体级度量来评估模型性能，结果显示长上下文模型总体表现最佳，而混合框架在计算资源受限的情况下取得了与之竞争的结果并改善了事实一致性。", "conclusion": "研究结果支持开发实用的总结系统，能够将冗长的财务文本高效地提炼为可用于商业决策的信息。"}}
{"id": "2601.09728", "pdf": "https://arxiv.org/pdf/2601.09728", "abs": "https://arxiv.org/abs/2601.09728", "authors": ["Meicong Zhang", "Tiancheng su", "Guoxiu He"], "title": "Eliminating Agentic Workflow for Introduction Generation with Parametric Stage Tokens", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In recent years, using predefined agentic workflows to guide large language models (LLMs) for literature classification and review has become a research focus. However, writing research introductions is more challenging. It requires rigorous logic, coherent structure, and abstract summarization. Existing workflows often suffer from long reasoning chains, error accumulation, and reduced textual coherence. To address these limitations, we propose eliminating external agentic workflows. Instead, we directly parameterize their logical structure into the LLM. This allows the generation of a complete introduction in a single inference. To this end, we introduce the Stage Token for Introduction Generation (STIG). STIG converts the multiple stages of the original workflow into explicit stage signals. These signals guide the model to follow different logical roles and functions during generation. Through instruction tuning, the model learns the mapping between stage tokens and text functions. It also learns the logical order and transition patterns between stages, encoding this knowledge into the model parameters. Experimental results show that STIG can generate multi-stage text in a single inference. It does not require explicit workflow calls. STIG outperforms traditional agentic workflows and other baselines on metrics of semantic similarity and sentence-level structural rationality. The code is provided in the Supplementary Materials.", "AI": {"tldr": "本文提出了Stage Token for Introduction Generation（STIG），通过将工作流程的逻辑结构参数化到大语言模型中，实现无需外部代理工作流即可生成完整的文献综述引言。", "motivation": "传统的预定义代理工作流在指导大型语言模型进行文献分类和回顾时存在长推理链、错误累积以及文本连贯性降低的问题。为了解决这些问题，作者提出了STIG方法。", "method": "引入Stage Token for Introduction Generation（STIG），将原有工作流程的多阶段转换成显式的阶段性信号，通过指令调优使模型学会阶段令牌与文本功能之间的映射关系，以及不同阶段间的逻辑顺序和过渡模式。", "result": "实验结果表明，STIG能够在单一推理中生成多阶段文本，并且在语义相似性和句子级结构合理性等指标上优于传统的代理工作流和其他基线方法。", "conclusion": "通过将工作流程的逻辑直接编码进模型参数，STIG展示了其在无需显式调用工作流的情况下高效生成文献综述引言的能力。"}}
{"id": "2601.09727", "pdf": "https://arxiv.org/pdf/2601.09727", "abs": "https://arxiv.org/abs/2601.09727", "authors": ["Sauhard Dubey"], "title": "SciNets: Graph-Constrained Multi-Hop Reasoning for Scientific Literature Synthesis", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": "19 pages, 2 figures", "summary": "Cross-domain scientific synthesis requires connecting mechanistic explanations across fragmented literature, a capability that remains challenging for both retrieval-based systems and unconstrained language models. While recent work has applied large language models to scientific summarization and question answering, these approaches provide limited control over reasoning depth and structural grounding. We frame mechanistic synthesis as a graph-constrained multi-hop reasoning problem over literature-derived concept graphs. Given a scientific query and a compact, query-local corpus, SciNets constructs a directed concept graph and synthesizes mechanistic explanations by identifying multi-hop reasoning paths that connect concepts that rarely co-occur within individual papers. We systematically compare shortest-path reasoning, k-shortest paths with diversity constraints, stochastic random walks, and a retrieval-augmented language model baseline. Rather than evaluating correctness, which is often indeterminate when synthesizing connections across distributed sources, we introduce a behavioral framework that measures symbolic reasoning depth, mechanistic diversity, and grounding stability. Across machine learning, biology, and climate science tasks, explicit graph constraints enable controllable multi-hop reasoning while revealing a consistent trade-off: deeper and more diverse symbolic reasoning increases grounding instability, whereas shortest-path reasoning remains highly stable but structurally conservative. These findings provide a systematic behavioral characterization of the limits and capabilities of current graph-LLM integration for scientific synthesis.", "AI": {"tldr": "本文介绍了SciNets，一种通过图约束多跳推理进行科学文献综合的方法。", "motivation": "跨领域的科学研究需要将碎片化的文献中的机制解释连接起来，这对于基于检索的系统和无限制的语言模型来说是一个挑战。", "method": "作者提出了一个图约束多跳推理问题框架，并设计了SciNets来构建定向概念图并合成机理解释。通过比较最短路径推理、具有多样性约束的K最短路径、随机游走及检索增强语言模型基线来评估不同方法的表现。", "result": "结果显示，显式的图约束能实现可控的多跳推理，但会增加接地不稳定性；而最短路径推理虽然结构保守，但在稳定性和深度上表现较好。", "conclusion": "这些发现为当前图-语言模型集成在科学综合方面的能力和局限提供了系统性的行为特征描述。"}}
{"id": "2601.09726", "pdf": "https://arxiv.org/pdf/2601.09726", "abs": "https://arxiv.org/abs/2601.09726", "authors": ["Hien Tran", "Quinten Steenhuis", "Alexandros Christoforos", "Chadbourne Davis"], "title": "Forgetting as a Feature: Cognitive Alignment of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Under submission", "summary": "Large Language Models (LLMs) are often evaluated against ideals of perfect Bayesian inference, yet growing evidence suggests that their in-context reasoning exhibits systematic forgetting of past information. Rather than viewing this behavior as a limitation, we reinterpret forgetting as a functional cognitive mechanism. Drawing inspiration from human memory dynamics, we model LLM inference as a probabilistic memory process governed by exponential decay. We introduce a benchmark suite that evaluates temporal reasoning, concept drift adaptation, and associative recall, enabling direct comparison between model behavior and human cognitive patterns. Our empirical results reveal that LLMs demonstrate forgetting rates analogous to human memory efficiency trade-offs between stability and adaptability. Building on these observations, we propose probabilistic memory prompting, a lightweight strategy that shapes evidence integration to mimic human-like memory decay, leading to improved long-horizon reasoning performance. Our findings position forgetting not as a failure mode, but as a principled mechanism for adaptive intelligence.", "AI": {"tldr": "本文将大型语言模型中的遗忘行为视为一种功能性的认知机制，并提出了一种模拟人类记忆衰退的轻量级策略，以改善长期推理性能。", "motivation": "鉴于证据表明大型语言模型在上下文推理中存在系统性遗忘过去信息的行为，作者希望重新诠释这种行为，而非将其视作局限。通过与人类记忆动态相比拟，探索如何使模型更好地适应和改进其认知过程。", "method": "本文引入了一个基准套件来评估时间推理、概念漂移适应以及联想回忆，同时提出一种概率记忆提示策略，以模拟类似人类的记忆衰退模式。", "result": "实证结果表明大型语言模型的遗忘率与人类在稳定性和适应性之间的记忆效率权衡相似。通过提出的轻量级策略，改善了长跨度推理的表现。", "conclusion": "本文将遗忘重新定位为一种自适应智能的原理机制，并非失败模式，展示了其作为功能性认知特性对提升模型性能的重要性。"}}
{"id": "2601.09724", "pdf": "https://arxiv.org/pdf/2601.09724", "abs": "https://arxiv.org/abs/2601.09724", "authors": ["Katherine Elkins", "Jon Chun"], "title": "Syntactic Framing Fragility: An Audit of Robustness in LLM Ethical Decisions", "categories": ["cs.CL", "cs.AI"], "comment": ":68T05ACM Class:I.2.6", "summary": "Large language models (LLMs) are increasingly deployed in consequential decision-making settings, yet their robustness to benign prompt variation remains underexplored. In this work, we study whether LLMs maintain consistent ethical judgments across logically equivalent but syntactically different prompts, focusing on variations involving negation and conditional structure. We introduce Syntactic Framing Fragility (SFF), a robustness evaluation framework that isolates purely syntactic effects via Logical Polarity Normalization (LPN), enabling direct comparison of decisions across positive and negative framings without semantic drift. Auditing 23 state-of-the-art models spanning the U.S. and China as well as small U.S. open-source software models over 14 ethical scenarios and four controlled framings (39,975 decisions), we find widespread and statistically significant inconsistency: many models reverse ethical endorsements solely due to syntactic polarity, with open-source models exhibiting over twice the fragility of commercial counterparts. We further uncover extreme negation sensitivity, where some models endorse actions in 80-97% of cases when explicitly prompted with \"should not.\" We show that eliciting chain-of-thought reasoning substantially reduces fragility, identifying a practical mitigation lever, and we map fragility across scenarios, finding higher risk in financial and business contexts than in medical scenarios. Our results demonstrate that syntactic consistency constitutes a distinct and critical dimension of ethical robustness, and we argue that SFF-style audits should be a standard component of safety evaluation for deployed LLMs. Code and results will be available on github.com.", "AI": {"tldr": "该研究探讨了大型语言模型（LLM）在逻辑等效但句法不同的提示下是否能保持一致的道德判断。", "motivation": "随着大型语言模型越来越多地应用于决策场景，研究其对良性提示变化的稳健性显得至关重要。特别是，关注这些模型如何在涉及否定和条件结构的变化中维持一致性。", "method": "该论文引入了句法框架脆弱性（SFF）评估框架，并通过逻辑极性归一化（LPN），直接比较了不同语法下的决策结果。研究涵盖了来自美国和中国的23个最先进的模型以及小型开源软件模型，测试了14种伦理情景中的四种控制框架。", "result": "研究表明在句法极性变化下，许多语言模型的道德判断存在广泛且统计显著的一致性问题。特别是，一些模型在明确提示“不应该”时会以80-97%的概率支持行动。此外，鼓励链式思考可以大幅降低脆弱性。", "conclusion": "该研究得出结论，句法一致性构成了道德稳健性的关键维度，SFF风格的审计应该成为部署LLM安全评估的标准组成部分。"}}
{"id": "2601.09723", "pdf": "https://arxiv.org/pdf/2601.09723", "abs": "https://arxiv.org/abs/2601.09723", "authors": ["Guancheng Du", "Yong Hu", "Wenqing Wang", "Yaming Yang", "Jiaheng Gao"], "title": "SagaScale: A Realistic, Scalable, and High-Quality Long-Context Benchmark Built from Full-Length Novels", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown significant progress, but understanding long and complex documents remains challenging. Many long-context benchmarks have been proposed, but they face several limitations, including task realism, data scalability, and data quality. To this end, we introduce SagaScale, a realistic, scalable, and high-quality long-context benchmark built from full-length novels. The entire benchmark is constructed using an automated data collection pipeline that utilizes external resources (e.g., Wikipedia pages) to curate question-answer pairs. Critically, these external resources are provided only for benchmark construction and not during evaluation, which allows LLMs to curate complex questions that go beyond what they can answer during evaluation. SagaScale is also bilingual and offers the largest context length to date, with average token counts exceeding 250K for English novels and 320K for Chinese novels. Our evaluation across 12 frontier LLMs and three long-context methods -- Naïve RAG, Agentic RAG, and Long Context -- yields key insights, including: (1) Directly supplying the full context to the LLM can outperform other methods by a large margin; (2) Most LLMs still struggle with lengthy contexts, but Gemini-2.5-Pro stands out as an exception; and (3) Agentic RAG effectively addresses the retrieval bottleneck in Naïve RAG. Finally, we publicly release the SagaScale benchmark and our data collection codebase to facilitate future research.", "AI": {"tldr": "本文介绍了SagaScale，一个基于完整小说的现实、可扩展和高质量的长文本基准测试。", "motivation": "大型语言模型虽然在理解长期复杂文档方面取得了一些进展，但仍存在任务真实性、数据可扩展性和质量等方面的限制。为了应对这些挑战，作者提出了SagaScale这个新的基准测试。", "method": "使用自动化的数据收集管道从维基百科等外部资源构建问题回答对来创建SagaScale，并且在评估时不会提供这些外部资源。", "result": "通过对12个前沿大型语言模型和三种长文本方法（Naïve RAG、Agentic RAG和Long Context）的评估，发现直接向LLM提供完整上下文可以显著优于其他方法；大多数LLM仍然难以应对长时间段的内容，但Gemini-2.5-Pro表现突出；Agentic RAG有效地解决了Naïve RAG中的检索瓶颈。", "conclusion": "SagaScale基准测试和数据收集代码库已被公开发布，以促进未来研究。"}}
{"id": "2601.09722", "pdf": "https://arxiv.org/pdf/2601.09722", "abs": "https://arxiv.org/abs/2601.09722", "authors": ["Franciszek Górski", "Andrzej Czyżewski"], "title": "ADMEDTAGGER: an annotation framework for distillation of expert knowledge for the Polish medical language", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In this work, we present an annotation framework that demonstrates how a multilingual LLM pretrained on a large corpus can be used as a teacher model to distill the expert knowledge needed for tagging medical texts in Polish. This work is part of a larger project called ADMEDVOICE, within which we collected an extensive corpus of medical texts representing five clinical categories - Radiology, Oncology, Cardiology, Hypertension, and Pathology. Using this data, we had to develop a multi-class classifier, but the fundamental problem turned out to be the lack of resources for annotating an adequate number of texts. Therefore, in our solution, we used the multilingual Llama3.1 model to annotate an extensive corpus of medical texts in Polish. Using our limited annotation resources, we verified only a portion of these labels, creating a test set from them. The data annotated in this way were then used for training and validation of 3 different types of classifiers based on the BERT architecture - the distilled DistilBERT model, BioBERT fine-tuned on medical data, and HerBERT fine-tuned on the Polish language corpus. Among the models we trained, the DistilBERT model achieved the best results, reaching an F1 score > 0.80 for each clinical category and an F1 score > 0.93 for 3 of them. In this way, we obtained a series of highly effective classifiers that represent an alternative to large language models, due to their nearly 500 times smaller size, 300 times lower GPU VRAM consumption, and several hundred times faster inference.", "AI": {"tldr": "本文介绍了一个注释框架，展示了如何使用多语言预训练的大规模语言模型作为教师模型，蒸馏出标注波兰语医学文本所需的专家知识。", "motivation": "在缺乏足够资源来标注足够的文本的情况下，开发一个多类分类器的需求促使研究人员寻找替代解决方案。他们选择了利用多语言Llama3.1模型进行大规模的医学文本注释。", "method": "使用了有限的注释资源验证部分标签，并基于这些数据训练和验证了三种不同的BERT架构的分类器：DistilBERT、BioBERT以及HerBERT，以达到高质量分类的效果。", "result": "其中，DistilBERT模型取得了最佳效果，在每个临床类别上F1得分超过0.80，在3个类别中超过了0.93。", "conclusion": "通过这种方法，获得了高度有效的分类器作为大型语言模型的替代方案，并且这些模型在尺寸、GPU VRAM消耗和推理速度方面显著优于大规模语言模型。"}}
{"id": "2601.09721", "pdf": "https://arxiv.org/pdf/2601.09721", "abs": "https://arxiv.org/abs/2601.09721", "authors": ["Vahideh Zolfaghari"], "title": "Cross-Platform Evaluation of Large Language Model Safety in Pediatric Consultations: Evolution of Adversarial Robustness and the Scale Paradox", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Background Large language models (LLMs) are increasingly deployed in medical consultations, yet their safety under realistic user pressures remains understudied. Prior assessments focused on neutral conditions, overlooking vulnerabilities from anxious users challenging safeguards. This study evaluated LLM safety under parental anxiety-driven adversarial pressures in pediatric consultations across models and platforms. Methods PediatricAnxietyBench, from a prior evaluation, includes 300 queries (150 authentic, 150 adversarial) spanning 10 topics. Three models were assessed via APIs: Llama-3.3-70B and Llama-3.1-8B (Groq), Mistral-7B (HuggingFace), yielding 900 responses. Safety used a 0-15 scale for restraint, referral, hedging, emergency recognition, and non-prescriptive behavior. Analyses employed paired t-tests with bootstrapped CIs. Results Mean scores: 9.70 (Llama-3.3-70B) to 10.39 (Mistral-7B). Llama-3.1-8B outperformed Llama-3.3-70B by +0.66 (p=0.0001, d=0.225). Models showed positive adversarial effects, Mistral-7B strongest (+1.09, p=0.0002). Safety generalized across platforms; Llama-3.3-70B had 8% failures. Seizures vulnerable (33% inappropriate diagnoses). Hedging predicted safety (r=0.68, p<0.001). Conclusions Evaluation shows safety depends on alignment and architecture over scale, with smaller models outperforming larger. Evolution to robustness across releases suggests targeted training progress. Vulnerabilities and no emergency recognition indicate unsuitability for triage. Findings guide selection, stress adversarial testing, and provide open benchmark for medical AI safety.", "AI": {"tldr": "评估大型语言模型在儿科咨询中面对家长焦虑时的安全性。", "motivation": "研究大型语言模型在医疗咨询中的安全性，特别是在受到来自焦虑用户的压力下的表现。", "method": "使用PediatricAnxietyBench测试集包含300个查询（150个真实查询和150个对抗性查询），评估了三个通过API访问的模型：Llama-3.3-70B、Llama-3.1-8B和Mistral-7B。使用0-15分的安全评分标准来衡量约束、转诊、犹豫、紧急情况识别和非处方行为。", "result": "平均得分从9.70（Llama-3.3-70B）到10.39（Mistral-7B）。Llama-3.1-8B比Llama-3.3-70B高出+0.66，p=0.0001。模型在对抗性测试中表现良好，特别是Mistral-7B的表现最强（+1.09，p=0.0002）。发现犹豫行为是安全性的预测因子。", "conclusion": "研究表明安全性取决于对齐和架构而非规模大小，小规模模型表现出色。模型在对抗性测试中的进步表明了有针对性的训练进展。然而，未识别紧急情况的存在表明这些模型不适合用于急救筛选。研究结果指导了选择，并强调了进行对抗性测试的重要性，并为医疗AI安全提供了公开基准。"}}
{"id": "2601.09720", "pdf": "https://arxiv.org/pdf/2601.09720", "abs": "https://arxiv.org/abs/2601.09720", "authors": ["Yu Takahashi", "Shun Takeuchi", "Kexuan Xin", "Guillaume Pelat", "Yoshiaki Ikai", "Junya Saito", "Jonathan Vitale", "Shlomo Berkovsky", "Amin Beheshti"], "title": "Uncertainty-Aware Dynamic Knowledge Graphs for Reliable Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "4 pages, 4 figures. Accepted at IEEE ICDM 2025 Demo Track", "summary": "Question answering (QA) systems are increasingly deployed across domains. However, their reliability is undermined when retrieved evidence is incomplete, noisy, or uncertain. Existing knowledge graph (KG) based QA frameworks typically represent facts as static and deterministic, failing to capture the evolving nature of information and the uncertainty inherent in reasoning. We present a demonstration of uncertainty-aware dynamic KGs, a framework that combines (i) dynamic construction of evolving KGs, (ii) confidence scoring and uncertainty-aware retrieval, and (iii) an interactive interface for reliable and interpretable QA. Our system highlights how uncertainty modeling can make QA more robust and transparent by enabling users to explore dynamic graphs, inspect confidence-annotated triples, and compare baseline versus confidence-aware answers. The target users of this demo are clinical data scientists and clinicians, and we instantiate the framework in healthcare: constructing personalized KGs from electronic health records, visualizing uncertainty across patient visits, and evaluating its impact on a mortality prediction task. This use case demonstrates the broader promise of uncertainty-aware dynamic KGs for enhancing QA reliability in high-stakes applications.", "AI": {"tldr": "本文介绍了不确定性感知动态知识图谱框架，该框架用于提高问答系统的可靠性和透明性。", "motivation": "现有基于知识图谱的问答系统通常将事实表示为静态和确定性的，无法捕捉到信息的演化特性以及推理中的不确定性，因此提出了新的框架来提升问答系统的可靠性。", "method": "结合动态构建演进的知识图谱、信心评分及不确定性感知检索，提供一个交互式界面来进行可靠的和可解释性问答系统演示。", "result": "该系统能够通过展示动态图形、检查带有置信度标记的三元组以及对比基准与信心感知的答案来增强问答系统的稳健性和透明性。具体应用实例是基于电子健康记录构建个性化知识图谱，可视化患者就诊中的不确定性，并评估其在死亡率预测任务上的影响。", "conclusion": "该研究展示了不确定性感知动态知识图谱框架对高风险应用场景下提高问答系统可靠性的潜在价值。"}}
{"id": "2601.09719", "pdf": "https://arxiv.org/pdf/2601.09719", "abs": "https://arxiv.org/abs/2601.09719", "authors": ["Hoyoon Byun", "Youngjun Choi", "Taero Kim", "Sungrae Park", "Kyungwoo Song"], "title": "Bounded Hyperbolic Tangent: A Stable and Efficient Alternative to Pre-Layer Normalization in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Pre-Layer Normalization (Pre-LN) is the de facto choice for large language models (LLMs) and is crucial for stable pretraining and effective transfer learning. However, Pre-LN is inefficient due to repeated statistical calculations and suffers from the curse of depth. As layers grow, the magnitude and variance of the hidden state escalate, destabilizing training. Efficiency-oriented normalization-free methods such as Dynamic Tanh (DyT) improve speed but remain fragile at depth. To jointly address stability and efficiency, we propose Bounded Hyperbolic Tanh (BHyT), a drop-in replacement for Pre-LN. BHyT couples a tanh nonlinearity with explicit, data-driven input bounding to keep activations within a non-saturating range. It prevents depth-wise growth in activation magnitude and variance and comes with a theoretical stability guarantee. For efficiency, BHyT computes exact statistics once per block and replaces a second normalization with a lightweight variance approximation, enhancing efficiency. Empirically, BHyT demonstrates improved stability and efficiency during pretraining, achieving an average of 15.8% faster training and an average of 4.2% higher token generation throughput compared to RMSNorm., while matching or surpassing its inference performance and robustness across language understanding and reasoning benchmarks. Our code is available at: https://anonymous.4open.science/r/BHyT", "AI": {"tldr": "本文提出了Bounded Hyperbolic Tanh（BHyT），作为大型语言模型中Pre-Layer Normalization的替代方案，旨在提高训练稳定性和效率。", "motivation": "尽管Pre-Layer Normalization是大规模语言模型的标准选择，但它在深度增长时会导致激活值放大和方差增加，从而影响训练稳定性，并且计算效率低。为了解决这些问题并同时提升效率，本文提出了一种新的方法BHyT。", "method": "BHyT结合了tanh非线性函数与数据驱动的输入边界控制，以保持激活在不过度饱和范围内。它通过一次计算每块精确统计量和使用轻量级方差近似来提高效率。", "result": "实验表明，相比于RMSNorm，BHyT实现了平均15.8%的训练加速和4.2%更高的Token生成吞吐量，并且在语言理解和推理基准测试中具有匹配或超越的表现。", "conclusion": "BHyT作为一种无预层归一化的替代方案，在保持甚至提升模型性能的同时，显著提高了大型语言模型的稳定性和训练效率。"}}
{"id": "2601.09718", "pdf": "https://arxiv.org/pdf/2601.09718", "abs": "https://arxiv.org/abs/2601.09718", "authors": ["Jing-Yi Zeng", "Guan-Hua Huang"], "title": "StatLLaMA: A multi-stage training framework for building a domain-optimized statistical language model", "categories": ["cs.CL", "cs.AI"], "comment": "31 pages, 3 figures", "summary": "This study investigates how to efficiently build a domain-specialized large language model (LLM) for statistics using the lightweight LLaMA-3.2-3B family as the foundation model (FM). We systematically compare three multi-stage training pipelines, starting from a base FM with no instruction-following capability, a base FM augmented with post-hoc instruction tuning, and an instruction-tuned FM with strong general reasoning abilities across continual pretraining, supervised fine-tuning (SFT), reinforcement learning from human feedback (RLHF) preference alignment, and downstream task adaptation. Results show that pipelines beginning with a base FM fail to develop meaningful statistical reasoning, even after extensive instruction tuning, SFT, or RLHF alignment. In contrast, starting from LLaMA-3.2-3B-Instruct enables effective domain specialization. A comprehensive evaluation of SFT variants reveals clear trade-offs between domain expertise and general reasoning ability. We further demonstrate that direct preference optimization provides stable and effective RLHF preference alignment. Finally, we show that downstream fine-tuning must be performed with extremely low intensity to avoid catastrophic forgetting in highly optimized models. The final model, StatLLaMA, achieves strong and balanced performance on benchmarks of mathematical reasoning, common-sense reasoning, and statistical expertise, offering a practical blueprint for developing resource-efficient statistical LLMs. The code is available at https://github.com/HuangDLab/StatLLaMA.", "AI": {"tldr": "本文探讨了如何使用轻量级的LLaMA-3.2-3B模型构建专门针对统计领域的大型语言模型。", "motivation": "研究动机是为了高效地构建特定领域（如统计学）的大规模语言模型，并通过多阶段训练流程来优化其性能。", "method": "本文系统比较了三种多阶段训练管道，从无指令跟随能力的基础模型开始，经过指令调整、监督微调和基于人类反馈的强化学习等阶段，最终进行下游任务适应。", "result": "研究结果表明，以基础模型开始的流水线无法发展出有意义的统计推理能力，而使用已经过指令训练的LLaMA-3.2-3B模型能够实现有效的领域专业化。此外，直接偏好优化提供了稳定且有效的强化学习对齐方法。", "conclusion": "最终模型StatLLaMA在数学、常识和统计学领域的基准测试中表现出了强大的性能平衡，并为开发资源高效的统计语言模型提供了一个实用的蓝图。"}}
{"id": "2601.09717", "pdf": "https://arxiv.org/pdf/2601.09717", "abs": "https://arxiv.org/abs/2601.09717", "authors": ["Yiwei Yan", "Hao Li", "Hua He", "Gong Kai", "Zhengyi Yang", "Guanfeng Liu"], "title": "SALP-CG: Standard-Aligned LLM Pipeline for Classifying and Grading Large Volumes of Online Conversational Health Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Online medical consultations generate large volumes of conversational health data that often embed protected health information, requiring robust methods to classify data categories and assign risk levels in line with policies and practice. However, existing approaches lack unified standards and reliable automated methods to fulfill sensitivity classification for such conversational health data. This study presents a large language model-based extraction pipeline, SALP-CG, for classifying and grading privacy risks in online conversational health data. We concluded health-data classification and grading rules in accordance with GB/T 39725-2020. Combining few-shot guidance, JSON Schema constrained decoding, and deterministic high-risk rules, the backend-agnostic extraction pipeline achieves strong category compliance and reliable sensitivity across diverse LLMs. On the MedDialog-CN benchmark, models yields robust entity counts, high schema compliance, and accurate sensitivity grading, while the strongest model attains micro-F1=0.900 for maximum-level prediction. The category landscape stratified by sensitivity shows that Level 2-3 items dominate, enabling re-identification when combined; Level 4-5 items are less frequent but carry outsize harm. SALP-CG reliably helps classify categories and grading sensitivity in online conversational health data across LLMs, offering a practical method for health data governance. Code is available at https://github.com/dommii1218/SALP-CG.", "AI": {"tldr": "本文提出了一种基于大型语言模型的提取管道SALP-CG，用于分类和评估在线健康对话数据中的隐私风险。", "motivation": "在线医疗咨询产生了大量包含受保护健康信息的会话健康数据，现有的方法缺乏统一标准和可靠的自动化手段来满足此类健康数据分析的要求。", "method": "结合少量示例指导、JSON Schema约束解码和确定性高风险规则，SALP-CG管道实现了强大的类别合规性和跨多种大型语言模型的可靠敏感度评估。", "result": "在MedDialog-CN基准测试中，模型表现出稳健的实体计数、高度符合模式以及准确的风险分级。最强的模型达到了微F1=0.900的最大级别预测值。", "conclusion": "SALP-CG能够跨大型语言模型可靠地分类和评估在线健康对话数据的敏感度，为健康管理提供了实用方法。"}}
{"id": "2601.09715", "pdf": "https://arxiv.org/pdf/2601.09715", "abs": "https://arxiv.org/abs/2601.09715", "authors": ["Adam Bradley", "John Hastings", "Khandaker Mamun Ahmed"], "title": "Introducing Axlerod: An LLM-based Chatbot for Assisting Independent Insurance Agents", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.IR"], "comment": "6 pages, 2 figures, 1 table", "summary": "The insurance industry is undergoing a paradigm shift through the adoption of artificial intelligence (AI) technologies, particularly in the realm of intelligent conversational agents. Chatbots have evolved into sophisticated AI-driven systems capable of automating complex workflows, including policy recommendation and claims triage, while simultaneously enabling dynamic, context-aware user engagement. This paper presents the design, implementation, and empirical evaluation of Axlerod, an AI-powered conversational interface designed to improve the operational efficiency of independent insurance agents. Leveraging natural language processing (NLP), retrieval-augmented generation (RAG), and domain-specific knowledge integration, Axlerod demonstrates robust capabilities in parsing user intent, accessing structured policy databases, and delivering real-time, contextually relevant responses. Experimental results underscore Axlerod's effectiveness, achieving an overall accuracy of 93.18% in policy retrieval tasks while reducing the average search time by 2.42 seconds. This work contributes to the growing body of research on enterprise-grade AI applications in insurtech, with a particular focus on agent-assistive rather than consumer-facing architectures.", "AI": {"tldr": "本文介绍了Axlerod，一个基于LLM的聊天机器人，旨在提高独立保险代理人的运营效率。", "motivation": "随着人工智能技术的应用，特别是智能对话代理的发展，保险行业正在经历范式转变。本研究旨在通过设计和实现Axlerod来提升独立保险代理的工作效率。", "method": "Axlerod利用自然语言处理（NLP）、检索增强生成（RAG）以及领域特定知识整合的技术手段，能够解析用户意图、访问结构化政策数据库并提供实时的相关响应。", "result": "实验结果显示，Axlerod在策略检索任务中达到了93.18%的整体准确率，并将平均搜索时间减少了2.42秒。", "conclusion": "本研究为保险科技领域的AI应用提供了贡献，特别是侧重于代理辅助而非面向消费者的技术架构。"}}
{"id": "2601.09714", "pdf": "https://arxiv.org/pdf/2601.09714", "abs": "https://arxiv.org/abs/2601.09714", "authors": ["Devesh Saraogi", "Rohit Singhee", "Dhruv Kumar"], "title": "Evaluating Novelty in AI-Generated Research Plans Using Multi-Workflow LLM Pipelines", "categories": ["cs.CL", "cs.AI"], "comment": "Under Review", "summary": "The integration of Large Language Models (LLMs) into the scientific ecosystem raises fundamental questions about the creativity and originality of AI-generated research. Recent work has identified ``smart plagiarism'' as a concern in single-step prompting approaches, where models reproduce existing ideas with terminological shifts. This paper investigates whether agentic workflows -- multi-step systems employing iterative reasoning, evolutionary search, and recursive decomposition -- can generate more novel and feasible research plans. We benchmark five reasoning architectures: Reflection-based iterative refinement, Sakana AI v2 evolutionary algorithms, Google Co-Scientist multi-agent framework, GPT Deep Research (GPT-5.1) recursive decomposition, and Gemini~3 Pro multimodal long-context pipeline. Using evaluations from thirty proposals each on novelty, feasibility, and impact, we find that decomposition-based and long-context workflows achieve mean novelty of 4.17/5, while reflection-based approaches score significantly lower (2.33/5). Results reveal varied performance across research domains, with high-performing workflows maintaining feasibility without sacrificing creativity. These findings support the view that carefully designed multi-stage agentic workflows can advance AI-assisted research ideation.", "AI": {"tldr": "评估使用多工作流程大型语言模型管道生成的研究计划的新颖性。", "motivation": "随着大型语言模型在科研生态系统中的整合，智能剽窃成为单步提示方法中一个值得关注的问题。该论文旨在探讨基于代理的工作流能否生成更具创新性和可行性的研究计划。", "method": "评估了五种推理架构：反思迭代优化、Sakana AI v2进化算法、Google Co-Scientist多代理框架、GPT Deep Research（GPT-5.1）递归分解和Gemini~3 Pro多模态长上下文管道。每种方法生成的三十份提案在新颖性、可行性和影响方面进行了评估。", "result": "基于分解和长上下文的工作流的新颖性评分为4.17/5，反思式工作流得分显著较低（2.33/5）。研究显示，在不同科研领域中，高性能工作流保持了可行性而不牺牲创意。", "conclusion": "精心设计的多阶段代理工作流程可以促进AI辅助的研究构思。"}}
{"id": "2601.09710", "pdf": "https://arxiv.org/pdf/2601.09710", "abs": "https://arxiv.org/abs/2601.09710", "authors": ["Md. Nazmus Sakib", "Golam Mahmud", "Md. Maruf Bangabashi", "Umme Ara Mahinur Istia", "Md. Jahidul Islam", "Partha Sarker", "Afra Yeamini Prity"], "title": "Multi-Level Embedding Conformer Framework for Bengali Automatic Speech Recognition", "categories": ["eess.AS", "cs.CL"], "comment": null, "summary": "Bengali, spoken by over 300 million people, is a morphologically rich and lowresource language, posing challenges for automatic speech recognition (ASR). This research presents an end-to-end framework for Bengali ASR, building on a Conformer-CTC backbone with a multi-level embedding fusion mechanism that incorporates phoneme, syllable, and wordpiece representations. By enriching acoustic features with these linguistic embeddings, the model captures fine-grained phonetic cues and higher-level contextual patterns. The architecture employs early and late Conformer stages, with preprocessing steps including silence trimming, resampling, Log-Mel spectrogram extraction, and SpecAugment augmentation. The experimental results demonstrate the strong potential of the model, achieving a word error rate (WER) of 10.01% and a character error rate (CER) of 5.03%. These results demonstrate the effectiveness of combining multi-granular linguistic information with acoustic modeling, providing a scalable approach for low-resource ASR development.", "AI": {"tldr": "本文提出了一种基于多级嵌入融合机制的Conformer-CTC框架，用于孟加拉语自动语音识别。", "motivation": "孟加拉语是一种形态丰富但资源较少的语言，对自动语音识别提出了挑战。因此，研究旨在开发一种能够有效处理这种语言的端到端ASR模型。", "method": "该方法采用Conformer-CTC骨干网络，并结合了音素、音节和词片表示的多级嵌入融合机制。通过在预处理步骤中进行静音修剪、重采样、对数梅尔频谱图提取及SpecAugment增强，模型捕捉到了细粒度的语音线索和高层次的上下文模式。", "result": "实验结果显示该模型取得了10.01%的词错误率（WER）和5.03%的字符错误率（CER），表明结合多级语言信息与声学建模的有效性。", "conclusion": "研究展示了结合多层次的语言嵌入对低资源语言自动语音识别的强大潜力，并提供了一种可扩展的方法来改进此类模型。"}}
{"id": "2601.09708", "pdf": "https://arxiv.org/pdf/2601.09708", "abs": "https://arxiv.org/abs/2601.09708", "authors": ["Chi-Pin Huang", "Yunze Man", "Zhiding Yu", "Min-Hung Chen", "Jan Kautz", "Yu-Chiang Frank Wang", "Fu-En Yang"], "title": "Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "Project page: https://jasper0314-huang.github.io/fast-thinkact/", "summary": "Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. While recent studies on reasoning VLAs show that explicit chain-of-thought (CoT) can improve generalization, they suffer from high inference latency due to lengthy reasoning traces. We propose Fast-ThinkAct, an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. Fast-ThinkAct learns to reason efficiently with latent CoTs by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories that transfers both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments across diverse embodied manipulation and reasoning benchmarks demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3\\% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.", "AI": {"tldr": "本文提出了Fast-ThinkAct，一个高效的视觉语言行动推理框架，通过可表达的隐式计划实现快速而有效的决策。", "motivation": "尽管近期关于视觉语言行动的研究表明，显式的思维链可以改善模型的泛化能力，但这些方法由于较长的推理路径导致了较高的推理延迟。因此，作者提出了一种更高效的解决方案来减少这种延迟，同时保持高性能。", "method": "Fast-ThinkAct通过从教师模型中提炼出隐式思维链条，并使用偏好引导的目标使操作轨迹与语言和视觉规划能力对齐，以实现紧凑而有效的计划。", "result": "实验结果表明，Fast-ThinkAct在多个嵌入式操作和推理基准上表现优异，推理延迟最多减少了89.3%，并且保持了长期规划、少样本适应性和故障恢复的有效性。", "conclusion": "研究得出结论，通过引入可表达的隐含计划，Fast-ThinkAct能够在减少大量推理延迟的同时实现高效的视觉语言行动任务执行。"}}
{"id": "2601.09706", "pdf": "https://arxiv.org/pdf/2601.09706", "abs": "https://arxiv.org/abs/2601.09706", "authors": ["Andreea Dutulescu", "Stefan Ruseti", "Mihai Dascalu"], "title": "Value-Aware Numerical Representations for Transformer Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Transformer-based language models often achieve strong results on mathematical reasoning benchmarks while remaining fragile on basic numerical understanding and arithmetic operations. A central limitation is that numbers are processed as symbolic tokens whose embeddings do not explicitly encode numerical value, leading to systematic errors. We introduce a value-aware numerical representation that augments standard tokenized inputs with a dedicated prefix token whose embedding is explicitly conditioned on the underlying numerical value. This mechanism injects magnitude information directly into the model's input space while remaining compatible with existing tokenizers and decoder-only Transformer architectures. Evaluation on arithmetic tasks shows that the proposed approach outperforms baselines across numerical formats, tasks, and operand lengths. These results indicate that explicitly encoding numerical value is an effective and efficient way to improve fundamental numerical robustness in language models.", "AI": {"tldr": "本文提出了一种价值感知的数值表示方法，以改善Transformer语言模型在数学推理任务中的基本数值理解和算术运算能力。", "motivation": "现有的Transformer语言模型在处理数学推理任务时表现出强大的性能，但在基础的数值理解和算术操作上仍然存在脆弱性。主要原因是这些模型将数字作为符号标记来处理，并且其嵌入表示未明确编码数值大小，导致系统性的错误。", "method": "引入了一种价值感知的数值表示方法，在标准分词输入前加入一个专用前缀标记，该前缀标记的嵌入显式依赖于底层的数值大小。这种方法将数量级信息直接注入模型的输入空间，并且与现有的分词器和解码器型Transformer架构兼容。", "result": "在算术任务上的评估显示，所提出的方法在不同的数字格式、任务类型以及操作数长度下都优于基线方法。", "conclusion": "明确编码数值大小是改善语言模型基础数值稳健性的有效且高效的方式。"}}
{"id": "2601.09703", "pdf": "https://arxiv.org/pdf/2601.09703", "abs": "https://arxiv.org/abs/2601.09703", "authors": ["Sicong Liu", "Yanxian Huang", "Mingwei Liu", "Jiachi Chen", "Ensheng Shi", "Yuchi Ma", "Hongyu Zhang", "Yin Zhang", "Yanlin Wang"], "title": "ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "Code generation tasks aim to automate the conversion of user requirements into executable code, significantly reducing manual development efforts and enhancing software productivity. The emergence of large language models (LLMs) has significantly advanced code generation, though their efficiency is still impacted by certain inherent architectural constraints. Each token generation necessitates a complete inference pass, requiring persistent retention of contextual information in memory and escalating resource consumption. While existing research prioritizes inference-phase optimizations such as prompt compression and model quantization, the generation phase remains underexplored. To tackle these challenges, we propose a knowledge-infused framework named ShortCoder, which optimizes code generation efficiency while preserving semantic equivalence and readability. In particular, we introduce: (1) ten syntax-level simplification rules for Python, derived from AST-preserving transformations, achieving 18.1% token reduction without functional compromise; (2) a hybrid data synthesis pipeline integrating rule-based rewriting with LLM-guided refinement, producing ShorterCodeBench, a corpus of validated tuples of original code and simplified code with semantic consistency; (3) a fine-tuning strategy that injects conciseness awareness into the base LLMs. Extensive experimental results demonstrate that ShortCoder consistently outperforms state-of-the-art methods on HumanEval, achieving an improvement of 18.1%-37.8% in generation efficiency over previous methods while ensuring the performance of code generation.", "AI": {"tldr": "短码生成器（ShortCoder）：知识增强的语法优化，用于高效的代码生成。", "motivation": "尽管大型语言模型在代码生成方面取得了显著进步，但其效率受限于架构约束。现有的研究主要集中在推理阶段的优化，而对生成阶段的研究较少。为了应对这些问题并提高代码生成效率，同时保持语义等效性和可读性，提出了ShortCoder框架。", "method": "提出了一种知识融合框架ShortCoder，包括10个语法级别的简化规则以减少Python代码中的令牌数量；一个结合基于规则的重写和大型语言模型指导细化的混合数据合成管道来生成代码语料库；以及一种使基础语言模型具备简洁意识的微调策略。", "result": "实验结果表明，ShortCoder在HumanEval基准测试中优于现有方法，在保持代码生成性能的同时，将生成效率提高了18.1%-37.8%。", "conclusion": "通过语法优化和混合数据合成管道的使用，ShortCoder成功地提高了代码生成的效率，并保持了代码的功能性和可读性。"}}
{"id": "2601.09699", "pdf": "https://arxiv.org/pdf/2601.09699", "abs": "https://arxiv.org/abs/2601.09699", "authors": ["Ruiqi Shen", "Chang Liu", "Henghui Ding"], "title": "SAM3-DMS: Decoupled Memory Selection for Multi-target Video Segmentation of SAM3", "categories": ["cs.CV"], "comment": "Code: https://github.com/FudanCVL/SAM3-DMS", "summary": "Segment Anything 3 (SAM3) has established a powerful foundation that robustly detects, segments, and tracks specified targets in videos. However, in its original implementation, its group-level collective memory selection is suboptimal for complex multi-object scenarios, as it employs a synchronized decision across all concurrent targets conditioned on their average performance, often overlooking individual reliability. To this end, we propose SAM3-DMS, a training-free decoupled strategy that utilizes fine-grained memory selection on individual objects. Experiments demonstrate that our approach achieves robust identity preservation and tracking stability. Notably, our advantage becomes more pronounced with increased target density, establishing a solid foundation for simultaneous multi-target video segmentation in the wild.", "AI": {"tldr": "本文提出了SAM3-DMS，一种用于多目标视频分割的解耦内存选择策略。", "motivation": "原有的SAM3在复杂多对象场景下的集体内存选择机制存在不足，因为它基于所有并发目标的平均性能做出同步决策，忽视了个体可靠性。", "method": "提出了一种无需训练的解耦策略SAM3-DMS，该策略采用细粒度的单个对象记忆选择来提高视频中指定目标的身份保持和跟踪稳定性。", "result": "实验表明，该方法在目标密度增加的情况下，能够实现更强大的身份保持和更高的跟踪稳定性。", "conclusion": "研究结果证明了SAM3-DMS在复杂多目标场景中的优越性能，并为野外的实时多目标视频分割奠定了坚实的基础。"}}
{"id": "2601.09698", "pdf": "https://arxiv.org/pdf/2601.09698", "abs": "https://arxiv.org/abs/2601.09698", "authors": ["Tony Danjun Wang", "Tolga Birdal", "Nassir Navab", "Lennart Bastian"], "title": "COMPOSE: Hypergraph Cover Optimization for Multi-view 3D Human Pose Estimation", "categories": ["cs.CV"], "comment": null, "summary": "3D pose estimation from sparse multi-views is a critical task for numerous applications, including action recognition, sports analysis, and human-robot interaction. Optimization-based methods typically follow a two-stage pipeline, first detecting 2D keypoints in each view and then associating these detections across views to triangulate the 3D pose. Existing methods rely on mere pairwise associations to model this correspondence problem, treating global consistency between views (i.e., cycle consistency) as a soft constraint. Yet, reconciling these constraints for multiple views becomes brittle when spurious associations propagate errors. We thus propose COMPOSE, a novel framework that formulates multi-view pose correspondence matching as a hypergraph partitioning problem rather than through pairwise association. While the complexity of the resulting integer linear program grows exponentially in theory, we introduce an efficient geometric pruning strategy to substantially reduce the search space. COMPOSE achieves improvements of up to 23% in average precision over previous optimization-based methods and up to 11% over self-supervised end-to-end learned methods, offering a promising solution to a widely studied problem.", "AI": {"tldr": "本文提出COMPOSE框架，通过将多视角人体姿态对应匹配问题转化为超图划分问题来改进三维人体姿态估计。", "motivation": "现有的方法依赖于两阶段的流水线和成对关联来解决多视图3D姿态估计中的对应问题，这种方法在处理多个视图时容易传播错误且不稳健。", "method": "COMPOSE将多视角下的姿态匹配视为超图划分问题，并引入了一种高效的几何剪枝策略以减少搜索空间的复杂性。", "result": "实验结果显示，COMPOSE框架在平均精度上比以往的优化方法提高了23%，比自我监督的端到端学习方法提高了11%。", "conclusion": "该研究为广泛探讨的问题提供了一个有希望的解决方案，并证明了超图划分策略的有效性。"}}
{"id": "2601.09697", "pdf": "https://arxiv.org/pdf/2601.09697", "abs": "https://arxiv.org/abs/2601.09697", "authors": ["Jieying Chen", "Jeffrey Hu", "Joan Lasenby", "Ayush Tewari"], "title": "Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering", "categories": ["cs.CV"], "comment": "Project page: https://ayushtewari.com/projects/srender/", "summary": "Modern video generative models based on diffusion models can produce very realistic clips, but they are computationally inefficient, often requiring minutes of GPU time for just a few seconds of video. This inefficiency poses a critical barrier to deploying generative video in applications that require real-time interactions, such as embodied AI and VR/AR. This paper explores a new strategy for camera-conditioned video generation of static scenes: using diffusion-based generative models to generate a sparse set of keyframes, and then synthesizing the full video through 3D reconstruction and rendering. By lifting keyframes into a 3D representation and rendering intermediate views, our approach amortizes the generation cost across hundreds of frames while enforcing geometric consistency. We further introduce a model that predicts the optimal number of keyframes for a given camera trajectory, allowing the system to adaptively allocate computation. Our final method, SRENDER, uses very sparse keyframes for simple trajectories and denser ones for complex camera motion. This results in video generation that is more than 40 times faster than the diffusion-based baseline in generating 20 seconds of video, while maintaining high visual fidelity and temporal stability, offering a practical path toward efficient and controllable video synthesis.", "AI": {"tldr": "该论文提出了一种通过稀疏扩散和3D渲染来生成静态场景的高效摄像机控制视频的方法。", "motivation": "现有的基于扩散模型的视频生成模型虽然可以产生非常逼真的片段，但计算效率低下，这阻碍了实时交互应用（如具身AI和VR/AR）中的部署。", "method": "提出了一种新的策略：使用稀疏的关键帧通过3D重建和渲染来合成完整视频，并引入了一个预测给定摄像机轨迹下最佳关键帧数量的模型。", "result": "最终方法SRENDER可以生成20秒视频的速度比基于扩散模型的基本线快40多倍，同时保持高视觉保真度和时间稳定性。", "conclusion": "该研究提供了一条通往高效可控视频合成的实际路径，特别是在处理复杂摄像机运动时，通过自适应分配计算资源实现了更高效的生成过程。"}}
{"id": "2601.09694", "pdf": "https://arxiv.org/pdf/2601.09694", "abs": "https://arxiv.org/abs/2601.09694", "authors": ["Sai Varun Kodathala", "Rakesh Vunnam"], "title": "LLMs can Compress LLMs: Adaptive Pruning by Agents", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "17 Pages", "summary": "As Large Language Models (LLMs) continue to scale, post-training pruning has emerged as a promising approach to reduce computational costs while preserving performance. Existing methods such as SparseGPT and Wanda achieve high sparsity through layer-wise weight reconstruction or activation-aware magnitude pruning, but rely on uniform or hand-crafted heuristics to determine per-layer sparsity ratios. Moreover, recent work has shown that pruned LLMs suffer from severe factual knowledge degradation, with structured pruning methods experiencing near-total collapse in factual question-answering capabilities. We introduce agent-guided pruning, where a foundation model acts as an adaptive pruning agent to intelligently select which layers to prune at each iteration while preserving critical knowledge pathways. Our method constructs layer-wise sensitivity profiles by combining Wanda-inspired weight-activation metrics with gradient importance scores, normalized as z-scores for model-agnostic comparison. These statistics are processed by an LLM agent equipped with self-reflection capabilities, enabling it to learn from previous pruning outcomes and iteratively refine its strategy. A checkpoint rollback mechanism maintains model quality by reverting when perplexity degradation exceeds a threshold. We evaluate our approach on Qwen3 models (4B and 8B parameters) at approximately 45% sparsity, demonstrating substantial improvements over structured pruning baselines: 56% relative improvement in MMLU accuracy, 19x better factual knowledge retention on FreebaseQA, and 69% lower perplexity degradation. Notably, our framework requires no retraining, operates in a model-agnostic manner, and exhibits effective self-correction with only 2-4 rollbacks across 21-40 iterations, demonstrating that foundation models can effectively guide the compression of other foundation models.", "AI": {"tldr": "本文提出了一种基于智能体引导的剪枝方法，以自适应地选择剪枝层并保持关键知识通路。", "motivation": "现有的剪枝方法依赖于统一或手工设计的启发式规则，并且会导致事实知识退化。因此，研究旨在通过引入智能体指导的方法来优化剪枝效果和保持模型性能。", "method": "使用基础模型作为自适应剪枝智能体，结合Wanda权重-激活指标与梯度重要性得分构建层敏感分析图谱，并利用自我反思能力迭代改进剪枝策略。", "result": "在Qwen3模型（4B和8B参数）上进行评估，在约45%的稀疏率下，相对于结构化剪枝基线方法，实现了MMLU准确性提高56%，FreebaseQA事实知识保留度提升19倍，以及困惑度下降69%。", "conclusion": "智能体引导的自适应剪枝框架在无需重新训练的情况下表现出色，展示了基础模型能够有效指导其他基础模型的压缩，并具备有效的自我校正能力。"}}
{"id": "2601.09692", "pdf": "https://arxiv.org/pdf/2601.09692", "abs": "https://arxiv.org/abs/2601.09692", "authors": ["Tianyi Niu", "Justin Chih-Yao Chen", "Genta Indra Winata", "Shi-Xiong Zhang", "Supriyo Chakraborty", "Sambit Sahu", "Yue Zhang", "Elias Stengel-Eskin", "Mohit Bansal"], "title": "Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Code: https://github.com/tianyiniu/RoutingGenData", "summary": "Large Language Model (LLM) routers dynamically select optimal models for given inputs. Existing approaches typically assume access to ground-truth labeled data, which is often unavailable in practice, especially when user request distributions are heterogeneous and unknown. We introduce Routing with Generated Data (RGD), a challenging setting in which routers are trained exclusively on generated queries and answers produced from high-level task descriptions by generator LLMs. We evaluate query-answer routers (using both queries and labels) and query-only routers across four diverse benchmarks and 12 models, finding that query-answer routers degrade faster than query-only routers as generator quality decreases. Our analysis reveals two crucial characteristics of effective generators: they must accurately respond to their own questions, and their questions must produce sufficient performance differentiation among the model pool. We then show how filtering for these characteristics can improve the quality of generated data. We further propose CASCAL, a novel query-only router that estimates model correctness through consensus voting and identifies model-specific skill niches via hierarchical clustering. CASCAL is substantially more robust to generator quality, outperforming the best query-answer router by 4.6% absolute accuracy when trained on weak generator data.", "AI": {"tldr": "论文介绍了使用生成数据进行路由的方法，通过评估不同类型的路由器在各种基准测试上的表现来估计大型语言模型的能力并选择专家模型。", "motivation": "现有的路由方法通常需要地面实况标注数据，在实践中往往不可用。因此，本文动机在于开发一种不需要标注数据的路由方案。", "method": "提出了使用生成查询和答案进行训练的方法（RGD），评估了不同类型的路由器，并提出了一种名为CASCAL的新型查询仅路由器，它通过共识投票估计模型正确性并通过分层聚类识别技能领域。", "result": "研究发现，随着生成器质量的降低，查询-回答路由器比查询仅路由器的表现下降更快。CASCAL在使用较弱生成数据训练时表现优于最佳查询-回答路由器4.6%。", "conclusion": "结论表明，过滤具备准确回应自身问题和产生足够模型性能差异特性的生成器可以提高生成数据的质量，并且提出的CASCAL方法对生成器质量更稳健。"}}
{"id": "2601.09684", "pdf": "https://arxiv.org/pdf/2601.09684", "abs": "https://arxiv.org/abs/2601.09684", "authors": ["Ziyu Yang", "Guibin Chen", "Yuxin Yang", "Aoxiong Zeng", "Xiangquan Yang"], "title": "Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "preprint", "summary": "Multi-Task Learning (MTL) combined with Low-Rank Adaptation (LoRA) has emerged as a promising direction for parameter-efficient deployment of Large Language Models (LLMs). By sharing a single adapter across multiple tasks, one can significantly reduce storage overhead. However, this approach suffers from negative transfer, where conflicting gradient updates from distinct tasks degrade the performance of individual tasks compared to single-task fine-tuning. This problem is exacerbated in LoRA due to the low-rank constraint, which limits the optimization landscape's capacity to accommodate diverse task requirements. In this paper, we propose Ortho-LoRA, a gradient projection method specifically tailored for the bipartite structure of LoRA. Ortho-LoRA dynamically projects conflicting task gradients onto the orthogonal complement of each other within the intrinsic LoRA subspace. Extensive experiments on the GLUE benchmark demonstrate that Ortho-LoRA effectively mitigates task interference, outperforming standard joint training and recovering 95\\% of the performance gap between multi-task and single-task baselines with negligible computational overhead.", "AI": {"tldr": "本文提出了Ortho-LoRA，一种针对多任务学习中Low-Rank Adaptation（LoRA）框架的梯度投影方法，以减少不同任务之间的冲突。", "motivation": "多任务学习结合LoRA虽然可以降低存储开销，但会由于负迁移导致各单项任务性能下降。本文旨在解决这一问题，提高多任务学习中的性能表现。", "method": "Ortho-LoRA通过动态将相互冲突的任务梯度投影到对方的正交补空间中，在内在LoRA子空间内缓解任务间的干扰。", "result": "实验表明，Ortho-LoRA能有效减少任务干扰，比标准联合训练有更好表现，并且恢复了95%的多任务与单任务基线之间的性能差距，计算开销几乎为零。", "conclusion": "Ortho-LoRA在处理多任务冲突方面表现出色，能够显著提升基于LoRA框架的大规模语言模型的参数效率和性能。"}}
{"id": "2601.09680", "pdf": "https://arxiv.org/pdf/2601.09680", "abs": "https://arxiv.org/abs/2601.09680", "authors": ["Sara AlMahri", "Liming Xu", "Alexandra Brintrup"], "title": "Automating Supply Chain Disruption Monitoring via an Agentic AI Approach", "categories": ["cs.AI"], "comment": null, "summary": "Modern supply chains are increasingly exposed to disruptions from geopolitical events, demand shocks, trade restrictions, to natural disasters. While many of these disruptions originate deep in the supply network, most companies still lack visibility beyond Tier-1 suppliers, leaving upstream vulnerabilities undetected until the impact cascades downstream. To overcome this blind-spot and move from reactive recovery to proactive resilience, we introduce a minimally supervised agentic AI framework that autonomously monitors, analyses, and responds to disruptions across extended supply networks. The architecture comprises seven specialised agents powered by large language models and deterministic tools that jointly detect disruption signals from unstructured news, map them to multi-tier supplier networks, evaluate exposure based on network structure, and recommend mitigations such as alternative sourcing options. \\rev{We evaluate the framework across 30 synthesised scenarios covering three automotive manufacturers and five disruption classes. The system achieves high accuracy across core tasks, with F1 scores between 0.962 and 0.991, and performs full end-to-end analyses in a mean of 3.83 minutes at a cost of \\$0.0836 per disruption. Relative to industry benchmarks of multi-day, analyst-driven assessments, this represents a reduction of more than three orders of magnitude in response time. A real-world case study of the 2022 Russia-Ukraine conflict further demonstrates operational applicability. This work establishes a foundational step toward building resilient, proactive, and autonomous supply chains capable of managing disruptions across deep-tier networks.", "AI": {"tldr": "本文介绍了一个用于自动监控供应链中断的最小监督代理AI框架。", "motivation": "现代供应链受到多种因素的影响，导致潜在脆弱性无法被及时发现。该论文旨在通过自动化系统实现从被动恢复到主动抵御的转变。", "method": "采用基于大型语言模型和确定性工具构建的七个专门代理组成架构，自动检测未结构化新闻中的中断信号，并推荐缓解措施如替代采购选项。", "result": "在30个合成场景中评估，F1分数介于0.962到0.991之间，平均耗时3.83分钟且成本低。相比传统的人工分析方法，响应时间大幅缩短。", "conclusion": "该研究为构建能够管理深层次网络中断的具有前瞻性和自主性的供应链奠定了基础，并通过实际案例验证了其有效性。"}}
{"id": "2601.09668", "pdf": "https://arxiv.org/pdf/2601.09668", "abs": "https://arxiv.org/abs/2601.09668", "authors": ["Ailin Huang", "Chengyuan Yao", "Chunrui Han", "Fanqi Wan", "Hangyu Guo", "Haoran Lv", "Hongyu Zhou", "Jia Wang", "Jian Zhou", "Jianjian Sun", "Jingcheng Hu", "Kangheng Lin", "Liang Zhao", "Mitt Huang", "Song Yuan", "Wenwen Qu", "Xiangfeng Wang", "Yanlin Lai", "Yingxiu Zhao", "Yinmin Zhang", "Yukang Shi", "Yuyang Chen", "Zejia Weng", "Ziyang Meng", "Ang Li", "et al. (68 additional authors not shown)"], "title": "STEP3-VL-10B Technical Report", "categories": ["cs.CV"], "comment": "50 pages", "summary": "We present STEP3-VL-10B, a lightweight open-source foundation model designed to redefine the trade-off between compact efficiency and frontier-level multimodal intelligence. STEP3-VL-10B is realized through two strategic shifts: first, a unified, fully unfrozen pre-training strategy on 1.2T multimodal tokens that integrates a language-aligned Perception Encoder with a Qwen3-8B decoder to establish intrinsic vision-language synergy; and second, a scaled post-training pipeline featuring over 1k iterations of reinforcement learning. Crucially, we implement Parallel Coordinated Reasoning (PaCoRe) to scale test-time compute, allocating resources to scalable perceptual reasoning that explores and synthesizes diverse visual hypotheses. Consequently, despite its compact 10B footprint, STEP3-VL-10B rivals or surpasses models 10$\\times$-20$\\times$ larger (e.g., GLM-4.6V-106B, Qwen3-VL-235B) and top-tier proprietary flagships like Gemini 2.5 Pro and Seed-1.5-VL. Delivering best-in-class performance, it records 92.2% on MMBench and 80.11% on MMMU, while excelling in complex reasoning with 94.43% on AIME2025 and 75.95% on MathVision. We release the full model suite to provide the community with a powerful, efficient, and reproducible baseline.", "AI": {"tldr": "本文介绍了STEP3-VL-10B，一个轻量级的开源基础模型，旨在重新定义紧凑性和前沿多模态智能之间的平衡。", "motivation": "研究动机是通过设计一种更高效的模型来实现高性能的多模态智能处理，同时保持相对较小的模型规模。", "method": "该模型采用统一且完全非冻结预训练策略，结合语言对齐感知编码器和Qwen3-8B解码器，并使用Parallel Coordinated Reasoning（PaCoRe）技术进行测试时间计算扩展。", "result": "尽管其参数量仅为10亿，STEP3-VL-10B在多个评估基准上的表现优于许多更大规模的模型，如GLM-4.6V-106B和Qwen3-VL-235B，在MMBench上达到92.2%，在AIME2025上达到94.43%。", "conclusion": "研究结论表明STEP3-VL-10B模型是多模态智能处理中的一个重要进展，它提供了强大的性能和效率，并且作为一个可重复使用的基线向社区开放。"}}
{"id": "2601.09667", "pdf": "https://arxiv.org/pdf/2601.09667", "abs": "https://arxiv.org/abs/2601.09667", "authors": ["Zhiyuan Hu", "Yunhai Hu", "Juncheng Liu", "Shuyue Stella Li", "Yucheng Wang", "Zhen Xu", "See-Kiong Ng", "Anh Tuan Luu", "Xinxing Xu", "Bryan Hooi", "Cynthia Breazeal", "Hae Won Park"], "title": "Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "Work in Progress", "summary": "Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable: co-adapting teammates induce non-stationarity, and rewards are often sparse and high-variance. Therefore, we introduce \\textbf{Multi-Agent Test-Time Reinforcement Learning (MATTRL)}, a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team of specialists for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. We also study credit assignment for constructing a turn-level experience pool, then reinjecting it into the dialogue. Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by an average of 3.67\\% over a multi-agent baseline, and by 8.67\\% over comparable single-agent baselines. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of how they affect training outcomes. MATTRL offers a stable, effective and efficient path to distribution-shift-robust multi-agent reasoning without tuning.", "AI": {"tldr": "本文介绍了一种新的多智能体推理框架MATTRL，该框架在推理时通过注入结构化的文本经验来改善多智能体系统的性能。", "motivation": "多智能体重强学习训练资源消耗大且不稳定，团队间的共适应导致非平稳性问题。因此，提出一种稳定、有效和高效的测试时间强化学习方法以增强多智能体的分布变化鲁棒推理能力。", "method": "MATTRL框架在推断时形成一个多专家团队进行多次讨论，并检索整合测试经验达成共识做出最终决策，同时研究了信用分配机制来构建逐回合的经验池并将其重新注入对话中。", "result": "通过医学、数学和教育等领域的挑战性基准测试表明，与多智能体基线相比，MATTRL平均提高了3.67%的准确性，并且比类似的单智能体基线高出8.67%。不同信用分配方案的消融研究揭示了它们对训练结果的影响。", "conclusion": "MATTRL提供了一个稳定有效的路径来实现分布变化鲁棒性的多智能体推理，无需调整即可提升性能和稳定性。"}}
{"id": "2601.09665", "pdf": "https://arxiv.org/pdf/2601.09665", "abs": "https://arxiv.org/abs/2601.09665", "authors": ["Yuchen Wu", "Jiahe Li", "Xiaohan Yu", "Lina Yu", "Jin Zheng", "Xiao Bai"], "title": "SCE-SLAM: Scale-Consistent Monocular SLAM via Scene Coordinate Embeddings", "categories": ["cs.CV"], "comment": null, "summary": "Monocular visual SLAM enables 3D reconstruction from internet video and autonomous navigation on resource-constrained platforms, yet suffers from scale drift, i.e., the gradual divergence of estimated scale over long sequences. Existing frame-to-frame methods achieve real-time performance through local optimization but accumulate scale drift due to the lack of global constraints among independent windows. To address this, we propose SCE-SLAM, an end-to-end SLAM system that maintains scale consistency through scene coordinate embeddings, which are learned patch-level representations encoding 3D geometric relationships under a canonical scale reference. The framework consists of two key modules: geometry-guided aggregation that leverages 3D spatial proximity to propagate scale information from historical observations through geometry-modulated attention, and scene coordinate bundle adjustment that anchors current estimates to the reference scale through explicit 3D coordinate constraints decoded from the scene coordinate embeddings. Experiments on KITTI, Waymo, and vKITTI demonstrate substantial improvements: our method reduces absolute trajectory error by 8.36m on KITTI compared to the best prior approach, while maintaining 36 FPS and achieving scale consistency across large-scale scenes.", "AI": {"tldr": "SCE-SLAM提出了一种通过场景坐标嵌入保持尺度一致的单目SLAM系统。", "motivation": "解决现有单目视觉SLAM方法在长序列中由于缺乏全局约束而导致的尺度漂移问题，同时维持实时性能。", "method": "SCE-SLAM由两个关键模块组成：通过几何引导聚合传播历史观察中的尺度信息，并通过场景坐标捆绑调整将当前估计锚定到参考尺度上。", "result": "在KITTI、Waymo和vKITTI数据集上的实验表明，该方法相较于最佳先验方法绝对轨迹误差减少8.36米，在保持每秒36帧的速度下实现了大规模场景中的尺度一致性。", "conclusion": "SCE-SLAM通过引入场景坐标嵌入来维持尺度的一致性，并在多个数据集上展示了显著的性能改进，同时保持了实时处理能力。"}}
{"id": "2601.09663", "pdf": "https://arxiv.org/pdf/2601.09663", "abs": "https://arxiv.org/abs/2601.09663", "authors": ["Xuyang Fang", "Sion Hannuna", "Edwin Simpson", "Neill Campbell"], "title": "Self-Supervised Animal Identification for Long Videos", "categories": ["cs.CV"], "comment": "11 pages, 1 figure", "summary": "Identifying individual animals in long-duration videos is essential for behavioral ecology, wildlife monitoring, and livestock management. Traditional methods require extensive manual annotation, while existing self-supervised approaches are computationally demanding and ill-suited for long sequences due to memory constraints and temporal error propagation. We introduce a highly efficient, self-supervised method that reframes animal identification as a global clustering task rather than a sequential tracking problem. Our approach assumes a known, fixed number of individuals within a single video -- a common scenario in practice -- and requires only bounding box detections and the total count. By sampling pairs of frames, using a frozen pre-trained backbone, and employing a self-bootstrapping mechanism with the Hungarian algorithm for in-batch pseudo-label assignment, our method learns discriminative features without identity labels. We adapt a Binary Cross Entropy loss from vision-language models, enabling state-of-the-art accuracy ($>$97\\%) while consuming less than 1 GB of GPU memory per batch -- an order of magnitude less than standard contrastive methods. Evaluated on challenging real-world datasets (3D-POP pigeons and 8-calves feeding videos), our framework matches or surpasses supervised baselines trained on over 1,000 labeled frames, effectively removing the manual annotation bottleneck. This work enables practical, high-accuracy animal identification on consumer-grade hardware, with broad applicability in resource-constrained research settings. All code written for this paper are \\href{https://huggingface.co/datasets/tonyFang04/8-calves}{here}.", "AI": {"tldr": "本文提出了一个高效的自我监督方法，用于识别长视频中的个体动物。", "motivation": "传统的方法需要大量的手动标注，而现有的自我监督方法在处理长时间序列时计算需求高且易受内存限制和时间错误传播的影响。该方法旨在解决这些问题并提高动物识别的效率和准确性。", "method": "通过将动物识别重新定义为全局聚类任务而非连续跟踪问题，并使用冻结的预训练模型、匈牙利算法进行伪标签分配以及二元交叉熵损失，学习区分性的特征而无需身份标签。", "result": "该方法在3D-POP鸽子和8头牛进食视频等挑战性的真实数据集上实现了超过97%的识别准确率，并且每批使用不到1GB的GPU内存。", "conclusion": "本文的方法能够在消费级硬件上实现高精度的动物识别，适用于资源受限的研究环境，有效地消除了手动注释瓶颈。"}}
{"id": "2601.09661", "pdf": "https://arxiv.org/pdf/2601.09661", "abs": "https://arxiv.org/abs/2601.09661", "authors": ["Aishwarya Agarwal", "Srikrishna Karanam", "Vineet Gandhi"], "title": "LiteEmbed: Adapting CLIP to Rare Classes", "categories": ["cs.CV"], "comment": "14 pages, 12 figures", "summary": "Large-scale vision-language models such as CLIP achieve strong zero-shot recognition but struggle with classes that are rarely seen during pretraining, including newly emerging entities and culturally specific categories. We introduce LiteEmbed, a lightweight framework for few-shot personalization of CLIP that enables new classes to be added without retraining its encoders. LiteEmbed performs subspace-guided optimization of text embeddings within CLIP's vocabulary, leveraging a PCA-based decomposition that disentangles coarse semantic directions from fine-grained variations. Two complementary objectives, coarse alignment and fine separation, jointly preserve global semantic consistency while enhancing discriminability among visually similar classes. Once optimized, the embeddings are plug-and-play, seamlessly substituting CLIP's original text features across classification, retrieval, segmentation, and detection tasks. Extensive experiments demonstrate substantial gains over prior methods, establishing LiteEmbed as an effective approach for adapting CLIP to underrepresented, rare, or unseen classes.", "AI": {"tldr": "LiteEmbed是一种轻量级框架，用于对CLIP进行少样本个性化处理，使其能够适应未在预训练中常见或完全未见的类别。", "motivation": "大规模视觉语言模型如CLIP在零样本识别方面表现出色，但在处理稀有类别的过程中表现不佳，特别是对于新兴实体和文化特定类别。为了解决这个问题，提出LiteEmbed框架以增强这些模型适应新类别时的能力。", "method": "通过文本嵌入的子空间导向优化，LiteEmbed利用PCA分解分离出粗略语义方向和细粒度变化，采用两个互补目标：粗对齐和细区分，来保持全局语义一致性的同时提高类间可辨性。优化后的嵌入可以直接替换CLIP原有的文本特征。", "result": "广泛的实验表明，LiteEmbed在分类、检索、分割和检测任务中表现出显著的改进，并证明了其作为有效方法用于适应未充分代表、稀有或完全未见类别方面的潜力。", "conclusion": "LiteEmbed作为一个轻量级框架，能够通过优化文本嵌入来增强CLIP对于新类别的处理能力，在多个视觉任务上取得了优于先前方法的效果。"}}
{"id": "2601.09658", "pdf": "https://arxiv.org/pdf/2601.09658", "abs": "https://arxiv.org/abs/2601.09658", "authors": ["Selim Emir Can", "Jan Ackermann", "Kiyohiro Nakayama", "Ruofan Liu", "Tong Wu", "Yang Zheng", "Hugo Bertiche", "Menglei Chai", "Thabo Beeler", "Gordon Wetzstein"], "title": "Image2Garment: Simulation-ready Garment Generation from a Single Image", "categories": ["cs.CV"], "comment": null, "summary": "Estimating physically accurate, simulation-ready garments from a single image is challenging due to the absence of image-to-physics datasets and the ill-posed nature of this problem. Prior methods either require multi-view capture and expensive differentiable simulation or predict only garment geometry without the material properties required for realistic simulation. We propose a feed-forward framework that sidesteps these limitations by first fine-tuning a vision-language model to infer material composition and fabric attributes from real images, and then training a lightweight predictor that maps these attributes to the corresponding physical fabric parameters using a small dataset of material-physics measurements. Our approach introduces two new datasets (FTAG and T2P) and delivers simulation-ready garments from a single image without iterative optimization. Experiments show that our estimator achieves superior accuracy in material composition estimation and fabric attribute prediction, and by passing them through our physics parameter estimator, we further achieve higher-fidelity simulations compared to state-of-the-art image-to-garment methods.", "AI": {"tldr": "本文提出了一种从单张图像生成可用于物理模拟的衣物的方法。", "motivation": "现有方法要么需要多视角捕获和昂贵的可微分仿真，要么仅能预测衣物几何形状而无法提供用于现实模拟所需的材料属性。", "method": "首先细化一个视觉-语言模型以从真实图像中推断出材质组成和织物属性，然后训练一个轻量级预测器将这些属性映射到相应的物理参数。", "result": "该方法引入了两个新数据集（FTAG 和 T2P），并实现了比现有图像到衣物方法更高的材料成分估计精度、织物特性预测以及更高保真度的模拟效果。", "conclusion": "通过从单张图片生成可用于物理仿真且材质属性准确的衣物，该方法在准确性与模拟效果方面超越了现有的同类技术。"}}
{"id": "2601.09652", "pdf": "https://arxiv.org/pdf/2601.09652", "abs": "https://arxiv.org/abs/2601.09652", "authors": ["Emanuel da Costa Silva", "Tatiana Taís Schein", "José David García Ramos", "Eduardo Lawson da Silva", "Stephanie Loi Brião", "Felipe Gomes de Oliveira", "Paulo Lilles Jorge Drews-Jr"], "title": "AquaFeat+: an Underwater Vision Learning-based Enhancement Method for Object Detection, Classification, and Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Underwater video analysis is particularly challenging due to factors such as low lighting, color distortion, and turbidity, which compromise visual data quality and directly impact the performance of perception modules in robotic applications. This work proposes AquaFeat+, a plug-and-play pipeline designed to enhance features specifically for automated vision tasks, rather than for human perceptual quality. The architecture includes modules for color correction, hierarchical feature enhancement, and an adaptive residual output, which are trained end-to-end and guided directly by the loss function of the final application. Trained and evaluated in the FishTrack23 dataset, AquaFeat+ achieves significant improvements in object detection, classification, and tracking metrics, validating its effectiveness for enhancing perception tasks in underwater robotic applications.", "AI": {"tldr": "提出AquaFeat+，一种用于增强水下视觉任务的插件式管道。", "motivation": "水下视频分析因低光照、色彩失真和浑浊等影响图像质量的问题而具有挑战性，这些问题直接影响了机器人应用中感知模块的表现。", "method": "该方法包括颜色校正、分层特征增强和自适应残差输出模块，所有这些模块都是端到端训练并直接由最终应用程序的损失函数引导。", "result": "在FishTrack23数据集上进行训练和评估后，AquaFeat+显著提高了物体检测、分类和跟踪指标的表现。", "conclusion": "研究验证了AquaFeat+对于增强水下机器人应用中的感知任务的有效性。"}}
{"id": "2601.09647", "pdf": "https://arxiv.org/pdf/2601.09647", "abs": "https://arxiv.org/abs/2601.09647", "authors": ["Ali Naseh", "Yuefeng Peng", "Anshuman Suri", "Harsh Chaudhari", "Alina Oprea", "Amir Houmansadr"], "title": "Identifying Models Behind Text-to-Image Leaderboards", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": null, "summary": "Text-to-image (T2I) models are increasingly popular, producing a large share of AI-generated images online. To compare model quality, voting-based leaderboards have become the standard, relying on anonymized model outputs for fairness. In this work, we show that such anonymity can be easily broken. We find that generations from each T2I model form distinctive clusters in the image embedding space, enabling accurate deanonymization without prompt control or training data. Using 22 models and 280 prompts (150K images), our centroid-based method achieves high accuracy and reveals systematic model-specific signatures. We further introduce a prompt-level distinguishability metric and conduct large-scale analyses showing how certain prompts can lead to near-perfect distinguishability. Our findings expose fundamental security flaws in T2I leaderboards and motivate stronger anonymization defenses.", "AI": {"tldr": "本文揭示了文本到图像模型在匿名投票排行榜中的安全漏洞，并提出了一种基于聚类的方法来识别这些模型。", "motivation": "由于文本到图像生成模型的广泛使用，作者发现当前用于比较这些模型质量的匿名投票排行榜存在易被破解的问题，从而推动了这项研究以揭示其潜在的安全风险。", "method": "研究采用了基于质心的方法，在图像嵌入空间中寻找每个T2I模型生成图像的独特聚类来实现准确去匿名化。", "result": "通过分析22个模型和280个提示（15万个图像），该方法实现了高精度的模型识别，并发现某些提示可以导致近完美的区分性。", "conclusion": "研究结果揭示了文本到图像排行榜中的基本安全问题，表明需要加强匿名化防御措施。"}}
{"id": "2601.09636", "pdf": "https://arxiv.org/pdf/2601.09636", "abs": "https://arxiv.org/abs/2601.09636", "authors": ["Yibo Lyu", "Gongwei Chen", "Rui Shao", "Weili Guan", "Liqiang Nie"], "title": "PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records", "categories": ["cs.AI", "cs.CV", "cs.HC", "cs.LG"], "comment": null, "summary": "While GUI agents have shown strong performance under explicit and completion instructions, real-world deployment requires aligning with users' more complex implicit intents. In this work, we highlight Hierarchical Implicit Intent Alignment for Personalized GUI Agent (PersonalAlign), a new agent task that requires agents to leverage long-term user records as persistent context to resolve omitted preferences in vague instructions and anticipate latent routines by user state for proactive assistance. To facilitate this study, we introduce AndroidIntent, a benchmark designed to evaluate agents' ability in resolving vague instructions and providing proactive suggestions through reasoning over long-term user records. We annotated 775 user-specific preferences and 215 routines from 20k long-term records across different users for evaluation. Furthermore, we introduce Hierarchical Intent Memory Agent (HIM-Agent), which maintains a continuously updating personal memory and hierarchically organizes user preferences and routines for personalization. Finally, we evaluate a range of GUI agents on AndroidIntent, including GPT-5, Qwen3-VL, and UI-TARS, further results show that HIM-Agent significantly improves both execution and proactive performance by 15.7% and 7.3%.", "AI": {"tldr": "本文介绍了PersonalAlign，一种新的GUI代理任务，它需要利用长期用户记录作为持久背景来解决模糊指令中的遗漏偏好并预测潜在的常规行为。", "motivation": "现有的GUI代理在明确和完整的指令下表现出色，但在现实世界的应用中，它们需要与用户的复杂隐性意图对齐。为了实现这一目标，研究提出了PersonalAlign任务，以更好地处理模糊的用户指示，并提供主动帮助。", "method": "引入了Hierarchical Intent Memory Agent (HIM-Agent)，它维护一个持续更新的个人记忆，并按层次组织用户的偏好和常规行为，以便个性化服务。此外，还设计了一个名为AndroidIntent的基准测试来评估代理在解决模糊指令和提供积极建议方面的能力。", "result": "通过使用775个用户特定偏好和215个从20K长期记录中注释出的常规行为对各种GUI代理进行了评估，结果表明HIM-Agent显著提高了执行性能（提升了15.7%）和主动性能（提升了7.3%）。", "conclusion": "研究证明了利用长期用户记录来解决模糊指令并提供主动帮助的有效性，并且提出的HIM-Agent在这些方面比其他GUI代理具有更好的表现。"}}
{"id": "2601.09635", "pdf": "https://arxiv.org/pdf/2601.09635", "abs": "https://arxiv.org/abs/2601.09635", "authors": ["Kuo Liang", "Yuhang Lu", "Jianming Mao", "Shuyi Sun", "Chunwei Yang", "Congcong Zeng", "Xiao Jin", "Hanzhang Qin", "Ruihao Zhu", "Chung-Piaw Teo"], "title": "LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach", "categories": ["cs.AI", "cs.LG"], "comment": "Updated version of https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5329027", "summary": "Large-scale optimization is a key backbone of modern business decision-making. However, building these models is often labor-intensive and time-consuming. We address this by proposing LEAN-LLM-OPT, a LightwEight AgeNtic workflow construction framework for LLM-assisted large-scale OPTimization auto-formulation. LEAN-LLM-OPT takes as input a problem description together with associated datasets and orchestrates a team of LLM agents to produce an optimization formulation. Specifically, upon receiving a query, two upstream LLM agents dynamically construct a workflow that specifies, step-by-step, how optimization models for similar problems can be formulated. A downstream LLM agent then follows this workflow to generate the final output. Leveraging LLMs' text-processing capabilities and common modeling practices, the workflow decomposes the modeling task into a sequence of structured sub-tasks and offloads mechanical data-handling operations to auxiliary tools. This design alleviates the downstream agent's burden related to planning and data handling, allowing it to focus on the most challenging components that cannot be readily standardized. Extensive simulations show that LEAN-LLM-OPT, instantiated with GPT-4.1 and the open source gpt-oss-20B, achieves strong performance on large-scale optimization modeling tasks and is competitive with state-of-the-art approaches. In addition, in a Singapore Airlines choice-based revenue management use case, LEAN-LLM-OPT demonstrates practical value by achieving leading performance across a range of scenarios. Along the way, we introduce Large-Scale-OR and Air-NRM, the first comprehensive benchmarks for large-scale optimization auto-formulation. The code and data of this work is available at https://github.com/CoraLiang01/lean-llm-opt.", "AI": {"tldr": "本文提出了LEAN-LLM-OPT，一种基于轻量级少样本学习方法的大型语言模型辅助大规模优化模型自动构建框架。", "motivation": "解决现代商业决策中大规模优化模型构建劳动密集型和耗时问题。", "method": "使用多个大型语言模型（LLMs）组成的团队根据问题描述和相关数据集动态构建工作流程，将建模任务分解为一系列结构化子任务并将其分发到辅助工具进行机械性数据处理，从而减轻下游代理的负担。", "result": "通过广泛的模拟实验表明，LEAN-LLM-OPT在大规模优化模型构建任务上取得了优异性能，并在新加坡航空公司基于选择的收益管理实际案例中展示了其实用价值。", "conclusion": "LEAN-LLM-OPT通过轻量级少样本学习方法显著提高了大型语言模型辅助的大规模优化自动建模效率和效果，引入了两个新的基准测试集Large-Scale-OR 和 Air-NRM。"}}
{"id": "2601.09632", "pdf": "https://arxiv.org/pdf/2601.09632", "abs": "https://arxiv.org/abs/2601.09632", "authors": ["Rose Connolly", "Victor Zordan", "Rachel McDonnell"], "title": "Perceptually-Guided Adjusted Teleporting: Perceptual Thresholds for Teleport Displacements in Virtual Environments", "categories": ["cs.HC"], "comment": "9 pages. to be published in IEEE VR conference proceedings 2026", "summary": "Teleportation is one of the most common locomotion techniques in virtual reality, yet its perceptual properties remain underexplored. While redirected walking research has shown that users' movements can be subtly manipulated without detection, similar imperceptible adjustments for teleportation have not been systematically investigated. This study examines the thresholds at which teleportation displacements become noticeable to users. We conducted a repeated-measures experiment in which participants' selected teleport destinations were altered in both direction (forwards, backwards) and at different ranges (small, large). Detection thresholds for these positional adjustments were estimated using a psychophysical staircase method with a two-alternative forced choice (2AFC) task. Results show that teleport destinations can be shifted without detection, with larger tolerances for backward adjustments and across longer teleport ranges. These findings establish baseline perceptual limits for redirected teleportation and highlight its potential as a design technique. Applications include supporting interpersonal distance management in social VR, guiding players toward objectives in games, and assisting novice users with navigation. By identifying the limits of imperceptible teleportation adjustments, this work extends redirection principles beyond walking to teleportation and opens new opportunities for adaptive and socially aware VR locomotion systems.", "AI": {"tldr": "研究了用户对虚拟环境中瞬移位移的感知阈值，探索了瞬移调整在不被察觉情况下的可能性。", "motivation": "尽管重定向行走技术已显示出可以微妙地操纵用户的动作而不被察觉，但类似的瞬移调整尚未进行系统性研究。该研究旨在填补这一知识空白，并探讨其应用潜力。", "method": "通过重复测量实验，在不同方向和范围（小、大）内对参与者选定的瞬移目的地进行了调整。使用心理物理阶梯法结合二选一强制选择任务来估计这些位置调整的检测阈值。", "result": "结果显示，用户的瞬移目的地可以被移动而不被察觉，较大的后向调整以及较长距离的瞬移具有更大的容忍度。", "conclusion": "该研究确定了重定向瞬移的基本感知限制，并强调其作为一种设计技术的潜力。这些发现为适应性及社会意识的虚拟现实运动系统提供了新的机会。"}}
{"id": "2601.09626", "pdf": "https://arxiv.org/pdf/2601.09626", "abs": "https://arxiv.org/abs/2601.09626", "authors": ["Ge Lei", "Ferran Brosa Planella", "Sterling G. Baird", "Samuel J. Cooper"], "title": "From Prompt to Protocol: Fast Charging Batteries with Large Language Models", "categories": ["cs.LG", "cs.AI", "eess.SY"], "comment": null, "summary": "Efficiently optimizing battery charging protocols is challenging because each evaluation is slow, costly, and non-differentiable. Many existing approaches address this difficulty by heavily constraining the protocol search space, which limits the diversity of protocols that can be explored, preventing the discovery of higher-performing solutions. We introduce two gradient-free, LLM-driven closed-loop methods: Prompt-to-Optimizer (P2O), which uses an LLM to propose the code for small neural-network-based protocols, which are then trained by an inner loop, and Prompt-to-Protocol (P2P), which simply writes an explicit function for the current and its scalar parameters. Across our case studies, LLM-guided P2O outperforms neural networks designed by Bayesian optimization, evolutionary algorithms, and random search. In a realistic fast charging scenario, both P2O and P2P yield around a 4.2 percent improvement in state of health (capacity retention based health metric under fast charging cycling) over a state-of-the-art multi-step constant current (CC) baseline, with P2P achieving this under matched evaluation budgets (same number of protocol evaluations). These results demonstrate that LLMs can expand the space of protocol functional forms, incorporate language-based constraints, and enable efficient optimization in high cost experimental settings.", "AI": {"tldr": "本文介绍了两种基于大型语言模型（LLM）的无梯度、闭环方法，用于优化电池快速充电协议。", "motivation": "现有方法在优化电池充电协议时受限于搜索空间，这限制了可探索方案的多样性，难以发现更优解决方案。作者旨在通过使用LLM来拓宽协议功能形式的空间并提高优化效率。", "method": "提出了Prompt-to-Optimizer (P2O) 和 Prompt-to-Protocol (P2P)两种方法，其中P2O利用LLM提出基于小神经网络的协议代码，并由内循环训练，而P2P直接写出当前和标量参数的显式函数。", "result": "实验结果显示，在实际快速充电场景下，P2O和P2P相比最先进的多步恒流基准分别提高了约4.2%的状态健康度（基于快充循环下的容量保持率）。", "conclusion": "研究结果表明，LLM能够扩展协议功能形式的空间，融入语言约束，并在高成本实验环境中实现高效的优化。"}}
{"id": "2601.09625", "pdf": "https://arxiv.org/pdf/2601.09625", "abs": "https://arxiv.org/abs/2601.09625", "authors": ["Ben Nassi", "Bruce Schneier", "Oleg Brodt"], "title": "The Promptware Kill Chain: How Prompt Injections Gradually Evolved Into a Multi-Step Malware", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The rapid adoption of large language model (LLM)-based systems -- from chatbots to autonomous agents capable of executing code and financial transactions -- has created a new attack surface that existing security frameworks inadequately address. The dominant framing of these threats as \"prompt injection\" -- a catch-all phrase for security failures in LLM-based systems -- obscures a more complex reality: Attacks on LLM-based systems increasingly involve multi-step sequences that mirror traditional malware campaigns. In this paper, we propose that attacks targeting LLM-based applications constitute a distinct class of malware, which we term \\textit{promptware}, and introduce a five-step kill chain model for analyzing these threats. The framework comprises Initial Access (prompt injection), Privilege Escalation (jailbreaking), Persistence (memory and retrieval poisoning), Lateral Movement (cross-system and cross-user propagation), and Actions on Objective (ranging from data exfiltration to unauthorized transactions). By mapping recent attacks to this structure, we demonstrate that LLM-related attacks follow systematic sequences analogous to traditional malware campaigns. The promptware kill chain offers security practitioners a structured methodology for threat modeling and provides a common vocabulary for researchers across AI safety and cybersecurity to address a rapidly evolving threat landscape.", "AI": {"tldr": "本文提出了一种针对基于大型语言模型（LLM）系统的新型恶意软件分类，称为promptware，并引入了一个五步骤的杀伤链模型来分析这些威胁。", "motivation": "由于现有安全框架无法充分应对基于LLM系统的新攻击面，作者希望通过将这些威胁定义为一种新的恶意软件类别并提出一个结构化的方法论来帮助安全从业者和研究人员更好地理解和防御这些威胁。", "method": "本文介绍了一个五步杀伤链模型，包括初始访问、权限提升、持久性建立、横向移动和目标行动，通过此框架分析了基于LLM系统的攻击。", "result": "作者展示了最近的攻击案例如何遵循类似于传统恶意软件活动的系统化步骤，并提供了安全从业者进行威胁建模的方法以及研究人员之间共享的术语。", "conclusion": "该论文认为通过将这些攻击视为一种新的恶意软件类别（promptware）并使用提出的杀伤链模型，能够为应对基于LLM系统的新型威胁提供结构化的分析方法和共同词汇。"}}
{"id": "2601.09624", "pdf": "https://arxiv.org/pdf/2601.09624", "abs": "https://arxiv.org/abs/2601.09624", "authors": ["Jiali Cheng", "Ziheng Chen", "Chirag Agarwal", "Hadi Amiri"], "title": "Toward Understanding Unlearning Difficulty: A Mechanistic Perspective and Circuit-Guided Difficulty Metric", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Machine unlearning is becoming essential for building trustworthy and compliant language models. Yet unlearning success varies considerably across individual samples: some are reliably erased, while others persist despite the same procedure. We argue that this disparity is not only a data-side phenomenon, but also reflects model-internal mechanisms that encode and protect memorized information. We study this problem from a mechanistic perspective based on model circuits--structured interaction pathways that govern how predictions are formed. We propose Circuit-guided Unlearning Difficulty (CUD), a {\\em pre-unlearning} metric that assigns each sample a continuous difficulty score using circuit-level signals. Extensive experiments demonstrate that CUD reliably separates intrinsically easy and hard samples, and remains stable across unlearning methods. We identify key circuit-level patterns that reveal a mechanistic signature of difficulty: easy-to-unlearn samples are associated with shorter, shallower interactions concentrated in earlier-to-intermediate parts of the original model, whereas hard samples rely on longer and deeper pathways closer to late-stage computation. Compared to existing qualitative studies, CUD takes a first step toward a principled, fine-grained, and interpretable analysis of unlearning difficulty; and motivates the development of unlearning methods grounded in model mechanisms.", "AI": {"tldr": "论文提出了一种基于电路的机器遗忘难度预评估方法CUD，用于分析和预测模型内部记忆信息编码机制。", "motivation": "研究动机在于解决机器学习中的遗忘困难问题，特别是如何理解和量化不同样本在模型中被遗忘的难易程度差异。", "method": "该论文从机理角度出发，基于模型电路设计了一种预评估遗忘难度的方法CUD，并通过电路级信号为每个样本分配连续的难度分数。", "result": "实验表明，CUD能够可靠地区分内在容易和困难的样本，并且在不同的遗忘方法上保持稳定。研究还发现了关键的电路层模式，揭示了困难样本与较长较深路径之间的关联。", "conclusion": "论文提出的方法是迈向原理性、细粒度和可解释分析遗忘难度的第一步，并为基于模型机制开发遗忘方法提供了动力。"}}
{"id": "2601.09620", "pdf": "https://arxiv.org/pdf/2601.09620", "abs": "https://arxiv.org/abs/2601.09620", "authors": ["Pooja Prajod", "Hannes Cools", "Thomas Röggla", "Karthikeya Puttur Venkatraj", "Amber Kusters", "Alia ElKattan", "Pablo Cesar", "Abdallah El Ali"], "title": "Full Disclosure, Less Trust? How the Level of Detail about AI Use in News Writing Affects Readers' Trust", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "As artificial intelligence (AI) is increasingly integrated into news production, calls for transparency about the use of AI have gained considerable traction. Recent studies suggest that AI disclosures can lead to a ``transparency dilemma'', where disclosure reduces readers' trust. However, little is known about how the \\textit{level of detail} in AI disclosures influences trust and contributes to this dilemma within the news context. In this 3$\\times$2$\\times$2 mixed factorial study with 40 participants, we investigate how three levels of AI disclosures (none, one-line, detailed) across two types of news (politics and lifestyle) and two levels of AI involvement (low and high) affect news readers' trust. We measured trust using the News Media Trust questionnaire, along with two decision behaviors: source-checking and subscription decisions. Questionnaire responses and subscription rates showed a decline in trust only for detailed AI disclosures, whereas source-checking behavior increased for both one-line and detailed disclosures, with the effect being more pronounced for detailed disclosures. Insights from semi-structured interviews suggest that source-checking behavior was primarily driven by interest in the topic, followed by trust, whereas trust was the main factor influencing subscription decisions. Around two-thirds of participants expressed a preference for detailed disclosures, while most participants who preferred one-line indicated a need for detail-on-demand disclosure formats. Our findings show that not all AI disclosures lead to a transparency dilemma, but instead reflect a trade-off between readers' desire for more transparency and their trust in AI-assisted news content.", "AI": {"tldr": "研究不同层次的人工智能披露如何影响新闻读者的信任。", "motivation": "随着AI在新闻生产中的应用增加，关于其透明度的讨论越来越多。研究旨在探讨不同的AI信息披露详细程度对读者信任的影响。", "method": "采用3×2×2混合因子设计实验，考察三种层次的AI披露（无、单行和详细）在两种类型的新闻（政治和生活方式）及两种不同水平的人工智能参与度下的影响，使用40名参与者进行调查。", "result": "问卷回答和订阅率显示，在详细信息披露时读者信任下降；而信息源检查行为对于一短线和详细披露都增加了。大多数参与者偏好详细的披露形式。", "conclusion": "并非所有AI披露都会导致透明度困境，而是存在一种平衡，即读者对更高透明度的渴望与他们对人工智能辅助新闻内容的信任之间的权衡。"}}
{"id": "2601.09613", "pdf": "https://arxiv.org/pdf/2601.09613", "abs": "https://arxiv.org/abs/2601.09613", "authors": ["Yonglin Tian", "Qiyao Zhang", "Wei Xu", "Yutong Wang", "Yihao Wu", "Xinyi Li", "Xingyuan Dai", "Hui Zhang", "Zhiyong Cui", "Baoqing Guo", "Zujun Yu", "Yisheng Lv"], "title": "CogRail: Benchmarking VLMs in Cognitive Intrusion Perception for Intelligent Railway Transportation Systems", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate and early perception of potential intrusion targets is essential for ensuring the safety of railway transportation systems. However, most existing systems focus narrowly on object classification within fixed visual scopes and apply rule-based heuristics to determine intrusion status, often overlooking targets that pose latent intrusion risks. Anticipating such risks requires the cognition of spatial context and temporal dynamics for the object of interest (OOI), which presents challenges for conventional visual models. To facilitate deep intrusion perception, we introduce a novel benchmark, CogRail, which integrates curated open-source datasets with cognitively driven question-answer annotations to support spatio-temporal reasoning and prediction. Building upon this benchmark, we conduct a systematic evaluation of state-of-the-art visual-language models (VLMs) using multimodal prompts to identify their strengths and limitations in this domain. Furthermore, we fine-tune VLMs for better performance and propose a joint fine-tuning framework that integrates three core tasks, position perception, movement prediction, and threat analysis, facilitating effective adaptation of general-purpose foundation models into specialized models tailored for cognitive intrusion perception. Extensive experiments reveal that current large-scale multimodal models struggle with the complex spatial-temporal reasoning required by the cognitive intrusion perception task, underscoring the limitations of existing foundation models in this safety-critical domain. In contrast, our proposed joint fine-tuning framework significantly enhances model performance by enabling targeted adaptation to domain-specific reasoning demands, highlighting the advantages of structured multi-task learning in improving both accuracy and interpretability. Code will be available at https://github.com/Hub-Tian/CogRail.", "AI": {"tldr": "本研究提出了CogRail基准，用于评估和改进视觉语言模型在智能铁路运输系统中的认知入侵感知能力。", "motivation": "现有的铁路交通系统大多集中在固定视野内的目标分类，并使用基于规则的启发式方法来确定入侵状态，这往往忽视了潜在的入侵风险。为了实现更深层次的入侵感知，需要对空间上下文和时间动态进行认知。", "method": "引入CogRail基准，整合经过精心策划的开源数据集以及带有认知驱动的问题答案注释的数据，支持时空推理和预测。使用多模态提示对最先进的视觉语言模型进行了系统评估，并提出了一个联合微调框架以提升其在入侵感知任务中的性能。", "result": "实验证明现有的大规模多模态模型难以处理复杂的时空推理问题，而提出的联合微调框架通过针对领域特定的推理需求进行有针对性的调整，显著提高了模型的表现。", "conclusion": "研究结果表明，结构化的多任务学习可以有效提高入侵感知任务中的准确性和可解释性。"}}
{"id": "2601.09610", "pdf": "https://arxiv.org/pdf/2601.09610", "abs": "https://arxiv.org/abs/2601.09610", "authors": ["Marie Luisa Fiedler", "Christian Merz", "Jonathan Tschanter", "Carolin Wienrich", "Marc Erich Latoschik"], "title": "Technological Advances in Two Generations of Consumer-Grade VR Systems: Effects on User Experience and Task Performance", "categories": ["cs.HC"], "comment": "12 pages, 4 figures, 7 tables", "summary": "Integrated VR (IVR) systems consist of a head-mounted display (HMD) and body-tracking capabilities. They enable users to translate their physical movements into corresponding avatar movements in real-time, allowing them to perceive their avatars via the displays. Consumer-grade IVR systems have been available for 10 years, significantly fostering VR research worldwide. However, the effects of even apparently significant technological advances of IVR systems on user experience and the overall validity of prior embodiment research using such systems often remain unclear. We ran a user-centered study comparing two comparable IVR generations: a nearly 10-year-old hardware (HTC Vive, 6-point tracking) and a modern counterpart (HTC Vive Pro 2, 6-point tracking). To ensure ecological validity, we evaluated the systems in their commercially available, as-is configurations. In a 2x5 mixed design, participants completed five tasks covering different use cases on either the old or new system. We assessed presence, sense of embodiment, appearance and behavior plausibility, workload, task performance, and gathered qualitative feedback. Results showed no significant system differences, with only small effect sizes. Bayesian analysis further supported the null hypothesis, suggesting that the investigated generational hardware improvements offer limited benefits for user experience and task performance. For the 10-year generational step examined here, excluding potential technological progress in the necessary software components, this supports the validity of conclusions from prior work and underscores the applicability of older configurations for research in embodied VR.", "AI": {"tldr": "评估两代集成虚拟现实系统对用户体验和任务表现的影响", "motivation": "探讨VR技术的显著进步是否能明显改善用户体验和任务表现，验证使用早期硬件的研究结论的有效性。", "method": "采用2x5混合设计实验，比较HTC Vive（旧）与HTC Vive Pro 2（新），评估用户的沉浸感、身体意识、外观行为逼真度、工作量、任务表现，并收集定性反馈。", "result": "两代VR系统在用户体验和任务表现上没有显著差异，仅显示小幅度效果。贝叶斯分析进一步支持零假设。", "conclusion": "对于研究中的硬件代际改进，对用户体验和任务表现的贡献有限，验证了早期硬件研究结论的有效性，表明旧配置仍然适用于身体沉浸VR的研究。"}}
{"id": "2601.09609", "pdf": "https://arxiv.org/pdf/2601.09609", "abs": "https://arxiv.org/abs/2601.09609", "authors": ["Qian Cao", "Yahui Liu", "Wei Bi", "Yi Zhao", "Ruihua Song", "Xiting Wang", "Ruiming Tang", "Guorui Zhou", "Han Li"], "title": "DPWriter: Reinforcement Learning with Diverse Planning Branching for Creative Writing", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL)-based enhancement of large language models (LLMs) often leads to reduced output diversity, undermining their utility in open-ended tasks like creative writing. Current methods lack explicit mechanisms for guiding diverse exploration and instead prioritize optimization efficiency and performance over diversity. This paper proposes an RL framework structured around a semi-structured long Chain-of-Thought (CoT), in which the generation process is decomposed into explicitly planned intermediate steps. We introduce a Diverse Planning Branching method that strategically introduces divergence at the planning phase based on diversity variation, alongside a group-aware diversity reward to encourage distinct trajectories. Experimental results on creative writing benchmarks demonstrate that our approach significantly improves output diversity without compromising generation quality, consistently outperforming existing baselines.", "AI": {"tldr": "本文提出DPWriter框架，使用强化学习和多样规划分支方法来改善大型语言模型在创意写作中的多样性。", "motivation": "当前基于强化学习的方法缺乏引导多样化探索的机制，在开放性任务如创意写作中导致输出多样性降低。", "method": "论文引入了基于半结构化的长链式思维（CoT）框架，分解生成过程为明确规划的中间步骤，并采用多样规划分支方法和群组感知多样性奖励来鼓励不同的轨迹。", "result": "实验结果表明，该方法在创意写作基准测试中显著提高了输出多样性，且未损害生成质量，持续超越现有基线。", "conclusion": "DPWriter框架通过引入多样化探索机制，有效提升了大型语言模型的创作多样性，在保持高质量的同时优于其他方法。"}}
{"id": "2601.09606", "pdf": "https://arxiv.org/pdf/2601.09606", "abs": "https://arxiv.org/abs/2601.09606", "authors": ["Manning Gao", "Leheng Zhang", "Shiqin Han", "Haifeng Hu", "Yuncheng Jiang", "Sijie Mai"], "title": "GRCF: Two-Stage Groupwise Ranking and Calibration Framework for Multimodal Sentiment Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Most Multimodal Sentiment Analysis research has focused on point-wise regression. While straightforward, this approach is sensitive to label noise and neglects whether one sample is more positive than another, resulting in unstable predictions and poor correlation alignment. Pairwise ordinal learning frameworks emerged to address this gap, capturing relative order by learning from comparisons. Yet, they introduce two new trade-offs: First, they assign uniform importance to all comparisons, failing to adaptively focus on hard-to-rank samples. Second, they employ static ranking margins, which fail to reflect the varying semantic distances between sentiment groups. To address this, we propose a Two-Stage Group-wise Ranking and Calibration Framework (GRCF) that adapts the philosophy of Group Relative Policy Optimization (GRPO). Our framework resolves these trade-offs by simultaneously preserving relative ordinal structure, ensuring absolute score calibration, and adaptively focusing on difficult samples. Specifically, Stage 1 introduces a GRPO-inspired Advantage-Weighted Dynamic Margin Ranking Loss to build a fine-grained ordinal structure. Stage 2 then employs an MAE-driven objective to align prediction magnitudes. To validate its generalizability, we extend GRCF to classification tasks, including multimodal humor detection and sarcasm detection. GRCF achieves state-of-the-art performance on core regression benchmarks, while also showing strong generalizability in classification tasks.", "AI": {"tldr": "提出了两阶段组级排序与校准框架（GRCF），以解决多模态情感分析中存在的标签噪声敏感和相对顺序忽视问题。", "motivation": "现有的点式回归方法对于多模态情感分析过于简单，容易受到标签噪声的影响，并且忽略了样本之间的相对正负关系。而成对排序学习框架虽然解决了这些问题，但也带来了新的权衡，例如统一的重要性分配和固定的排名边界。", "method": "提出了一种两阶段组级排序与校准框架（GRCF），第一阶段使用GRPO启发的优势加权动态边际排序损失来建立精细的顺序结构；第二阶段利用MAE驱动的目标对预测值进行幅度对齐。", "result": "该方法在核心回归基准测试中达到了最先进的性能，并且在分类任务上也表现出了良好的泛化能力，包括多模态幽默检测和讽刺检测。", "conclusion": "GRCF框架有效地解决了现有方法中存在的问题，提高了多模态情感分析的稳定性和预测准确性。"}}
{"id": "2601.09605", "pdf": "https://arxiv.org/pdf/2601.09605", "abs": "https://arxiv.org/abs/2601.09605", "authors": ["Jeremiah Coholich", "Justin Wit", "Robert Azarcon", "Zsolt Kira"], "title": "Sim2real Image Translation Enables Viewpoint-Robust Policies from Fixed-Camera Datasets", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Vision-based policies for robot manipulation have achieved significant recent success, but are still brittle to distribution shifts such as camera viewpoint variations. Robot demonstration data is scarce and often lacks appropriate variation in camera viewpoints. Simulation offers a way to collect robot demonstrations at scale with comprehensive coverage of different viewpoints, but presents a visual sim2real challenge. To bridge this gap, we propose MANGO -- an unpaired image translation method with a novel segmentation-conditioned InfoNCE loss, a highly-regularized discriminator design, and a modified PatchNCE loss. We find that these elements are crucial for maintaining viewpoint consistency during sim2real translation. When training MANGO, we only require a small amount of fixed-camera data from the real world, but show that our method can generate diverse unseen viewpoints by translating simulated observations. In this domain, MANGO outperforms all other image translation methods we tested. Imitation-learning policies trained on data augmented by MANGO are able to achieve success rates as high as 60\\% on views that the non-augmented policy fails completely on.", "AI": {"tldr": "本文提出了一种未配对图像翻译方法MANGO，用于解决机器人操作中的视角鲁棒性问题。", "motivation": "机器人视觉策略在面对相机视点变化等分布转移时表现脆弱，而模拟环境可以提供多样化的视点数据，但存在从仿真到现实的挑战。因此，需要一种方法来增强这些策略的视角鲁棒性。", "method": "MANGO通过引入分割条件下的InfoNCE损失、高度正则化的鉴别器设计和修改后的PatchNCE损失来进行未配对图像翻译，以维持仿真到真实的视点一致性。", "result": "实验表明，在仅使用少量固定相机的真实世界数据训练的情况下，MANGO可以生成多样化的未见过的视角，并且在评估中超过了其他所有图像翻译方法。基于MANGO增强的数据训练出的模仿学习策略在原先完全失败的新视角上可达到高达60%的成功率。", "conclusion": "该研究表明，通过使用MANGO进行图像翻译，可以从固定相机数据集中获得具有鲁棒性视角变化的操作策略。"}}
{"id": "2601.09603", "pdf": "https://arxiv.org/pdf/2601.09603", "abs": "https://arxiv.org/abs/2601.09603", "authors": ["Petros Vavaroutsos", "Theodoros Palamas", "Pantelis Vikatos"], "title": "Linear Complexity Self-Supervised Learning for Music Understanding with Random Quantizer", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG"], "comment": "accepted by ACM/SIGAPP Symposium on Applied Computing (SAC 2026)", "summary": "In recent years, foundation models have become very popular due to their exceptional performance, mainly in natural language (NLP) tasks where they were first introduced. These models usually consist of hundreds of millions, or even billions, of parameters, making them resource-intensive during training and in production systems, leading to increased costs. This paper focuses on the reduction of a foundation's model size when applied to music information retrieval (MIR) tasks. Our research combines the Branchformer architecture with SummaryMixing, which were first applied in speech recognition, along with a random quantization process. To facilitate reproducibility, we conduct pre-training on publicly available datasets, complemented by a proprietary dataset comparable in scale to other private datasets reported in the literature. We ensure robust evaluation by using a framework consisting of a variety of downstream MIR tasks. Our results show that our architecture achieves competitive performance when compared with other state-of-the-art models that use multi-head self-attention, while reducing the model size from 8.5% up to 12.3%.", "AI": {"tldr": "本文研究了通过结合Branchformer架构、SummaryMixing和随机量化过程来减少音乐信息检索任务中基础模型的大小。", "motivation": "近年来，由于其在自然语言处理任务中的出色表现，基础模型变得非常流行。然而，这些模型通常包含数以百万甚至数十亿计的参数，在训练和生产系统中需要大量的资源，导致成本增加。本文旨在减少应用到音乐信息检索任务的基础模型大小。", "method": "研究结合了Branchformer架构、SummaryMixing以及随机量化过程，并在公共数据集及私有数据集上进行预训练。使用包含多种下游MIR任务的框架确保评估的稳健性。", "result": "实验结果显示，该架构实现了与使用多头自注意力机制的其他最先进的模型相当的表现，同时将模型大小减少了8.5%到12.3%。", "conclusion": "本文提出的方法在不牺牲性能的情况下显著减小了基础模型的大小，这对于音乐信息检索任务的应用具有重要意义。"}}
{"id": "2601.09601", "pdf": "https://arxiv.org/pdf/2601.09601", "abs": "https://arxiv.org/abs/2601.09601", "authors": ["Emmanuele Barberi", "Felice Sfravara", "Filippo Cucinotta"], "title": "Iterative Differential Entropy Minimization (IDEM) method for fine rigid pairwise 3D Point Cloud Registration: A Focus on the Metric", "categories": ["cs.CV"], "comment": "ef:IEEE Transactions on Pattern Analysis and Machine Intelligence, 2025, Available in IEEE Xplore", "summary": "Point cloud registration is a central theme in computer vision, with alignment algorithms continuously improving for greater robustness. Commonly used methods evaluate Euclidean distances between point clouds and minimize an objective function, such as Root Mean Square Error (RMSE). However, these approaches are most effective when the point clouds are well-prealigned and issues such as differences in density, noise, holes, and limited overlap can compromise the results. Traditional methods, such as Iterative Closest Point (ICP), require choosing one point cloud as fixed, since Euclidean distances lack commutativity. When only one point cloud has issues, adjustments can be made, but in real scenarios, both point clouds may be affected, often necessitating preprocessing. The authors introduce a novel differential entropy-based metric, designed to serve as the objective function within an optimization framework for fine rigid pairwise 3D point cloud registration, denoted as Iterative Differential Entropy Minimization (IDEM). This metric does not depend on the choice of a fixed point cloud and, during transformations, reveals a clear minimum corresponding to the best alignment. Multiple case studies are conducted, and the results are compared with those obtained using RMSE, Chamfer distance, and Hausdorff distance. The proposed metric proves effective even with density differences, noise, holes, and partial overlap, where RMSE does not always yield optimal alignment.", "AI": {"tldr": "本文提出了一种基于迭代差熵最小化（IDEM）的方法，用于解决三维点云配准问题。", "motivation": "传统的点云配准方法在处理密度差异、噪声、空洞和部分重叠等问题时表现不佳。因此，需要一种更有效的度量标准来改善这些情况下的配准结果。", "method": "该研究提出了一种新的基于差熵的度量标准作为优化框架中的目标函数，并命名为迭代差熵最小化（IDEM），这种方法不依赖于固定点云的选择，在变换过程中能够清晰地揭示最佳对齐状态。", "result": "实验结果显示，与使用RMSE、Chamfer距离和Hausdorff距离相比，提出的度量标准即使在存在密度差异、噪声、空洞和部分重叠的情况下也能提供较好的对准效果。", "conclusion": "研究表明基于差熵的IDEM方法能有效解决传统点云配准中的诸多问题，并且能够克服密度差异、噪声、空洞和部分重叠所带来的挑战。"}}
{"id": "2601.09600", "pdf": "https://arxiv.org/pdf/2601.09600", "abs": "https://arxiv.org/abs/2601.09600", "authors": ["Bhaskar Mitra", "Nicola Neophytou", "Sireesh Gururaja"], "title": "Information Access of the Oppressed: A Problem-Posing Framework for Envisioning Emancipatory Information Access Platforms", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.IR"], "comment": null, "summary": "Online information access (IA) platforms are targets of authoritarian capture. These concerns are particularly serious and urgent today in light of the rising levels of democratic erosion worldwide, the emerging capabilities of generative AI technologies such as AI persuasion, and the increasing concentration of economic and political power in the hands of Big Tech. This raises the question of what alternative IA infrastructure we must reimagine and build to mitigate the risks of authoritarian capture of our information ecosystems. We explore this question through the lens of Paulo Freire's theories of emancipatory pedagogy. Freire's theories provide a radically different lens for exploring IA's sociotechnical concerns relative to the current dominating frames of fairness, accountability, confidentiality, transparency, and safety. We make explicit, with the intention to challenge, the dichotomy of how we relate to technology as either technologists (who envision and build technology) and its users. We posit that this mirrors the teacher-student relationship in Freire's analysis. By extending Freire's analysis to IA, we challenge the notion that it is the burden of the (altruistic) technologists to come up with interventions to mitigate the risks that emerging technologies pose to marginalized communities. Instead, we advocate that the first task for the technologists is to pose these as problems to the marginalized communities, to encourage them to make and unmake the technology as part of their material struggle against oppression. Their second task is to redesign our online technology stacks to structurally expose spaces for community members to co-opt and co-construct the technology in aid of their emancipatory struggles. We operationalize Freire's theories to develop a problem-posing framework for envisioning emancipatory IA platforms of the future.", "AI": {"tldr": "论文提出了一个基于保罗·弗莱雷解放教育理论的问题设定框架，以设计未来的解放性信息获取平台。", "motivation": "在线信息访问平台面临威权主义捕获的风险。鉴于全球民主侵蚀加剧、生成式AI技术能力提升以及大型科技公司权力集中，作者旨在探索如何重新想象和构建替代的信息基础设施来减轻这一风险。", "method": "论文采用保罗·弗莱雷的解放教育理论作为分析框架，挑战了当前关于技术和用户关系的技术主导观点，并提出技术设计者应首先将问题设定为对受压迫社区的问题，鼓励他们参与并改变技术以支持其斗争。", "result": "通过应用弗莱雷的理论，论文开发了一个问题设定框架来构想未来的解放性信息平台。", "conclusion": "结论表明，为了构建能够减轻威权主义风险的信息生态系统，技术设计者应首先将技术挑战视为受压迫社区的问题，并重新设计在线技术堆栈以支持这些社区参与和改变技术。"}}
{"id": "2601.09594", "pdf": "https://arxiv.org/pdf/2601.09594", "abs": "https://arxiv.org/abs/2601.09594", "authors": ["Russell M. Martin", "Steven H. Collins"], "title": "Improving CMA-ES Convergence Speed, Efficiency, and Reliability in Noisy Robot Optimization Problems", "categories": ["cs.NE"], "comment": "This is the authors' final accepted manuscript (post-peer-review, pre-publication). It has been accepted for publication in Evolutionary Computation on 12 Jan 2026. For associated code, see https://github.com/RussellMMartin/AS-CMA-ES", "summary": "Experimental robot optimization often requires evaluating each candidate policy for seconds to minutes. The chosen evaluation time influences optimization because of a speed-accuracy tradeoff: shorter evaluations enable faster iteration, but are also more subject to noise. Here, we introduce a supplement to the CMA-ES optimization algorithm, named Adaptive Sampling CMA-ES (AS-CMA), which assigns sampling time to candidates based on predicted sorting difficulty, aiming to achieve consistent precision. We compared AS-CMA to CMA-ES and Bayesian optimization using a range of static sampling times in four simulated cost landscapes. AS-CMA converged on 98% of all runs without adjustment to its tunable parameter, and converged 24-65% faster and with 29-76% lower total cost than each landscape's best CMA-ES static sampling time. As compared to Bayesian optimization, AS-CMA converged more efficiently and reliably in complex landscapes, while in simpler landscapes, AS-CMA was less efficient but equally reliable. We deployed AS-CMA in an exoskeleton optimization experiment and found the optimizer's behavior was consistent with expectations. These results indicate that AS-CMA can improve optimization efficiency in the presence of noise while minimally affecting optimization setup complexity and tuning requirements.", "AI": {"tldr": "本文提出了一种补充CMA-ES优化算法的方法，名为自适应采样CMA-ES（AS-CMA），旨在提高机器人优化问题在噪声环境下的收敛速度、效率和可靠性。", "motivation": "实验性机器人优化通常需要数秒到数分钟的时间来评估每个候选策略。较短的评估时间虽然能够加快迭代速度，但也更容易受到噪声的影响。因此，本文希望通过开发一种新的算法方法来解决这一问题。", "method": "该研究通过引入自适应采样CMA-ES（AS-CMA），根据预测排序难度为候选人分配采样时间，以实现一致的精度。在四种模拟成本景观中将其与CMA-ES和贝叶斯优化进行了比较。", "result": "实验表明，AS-CMA在98%的所有运行中都无需调整其可调参数就实现了收敛，并且比每种景观的最佳CMA-ES静态采样时间快了24-65%，成本降低了29-76%。与贝叶斯优化相比，在复杂景观中AS-CMA表现更有效率和可靠。", "conclusion": "结果表明，自适应采样CMA-ES（AS-CMA）可以在存在噪声的情况下提高优化效率，并且对优化设置的复杂性和调优需求影响极小。"}}
{"id": "2601.09586", "pdf": "https://arxiv.org/pdf/2601.09586", "abs": "https://arxiv.org/abs/2601.09586", "authors": ["Said Yasin", "Torsten Zesch"], "title": "Show, don't tell -- Providing Visual Error Feedback for Handwritten Documents", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Handwriting remains an essential skill, particularly in education. Therefore, providing visual feedback on handwritten documents is an important but understudied area. We outline the many challenges when going from an image of handwritten input to correctly placed informative error feedback. We empirically compare modular and end-to-end systems and find that both approaches currently do not achieve acceptable overall quality. We identify the major challenges and outline an agenda for future research.", "AI": {"tldr": "本文探讨了从手写输入图像到正确放置的错误反馈信息的技术挑战，并比较了模块化和端到端系统的性能。", "motivation": "鉴于手写在教育中的重要性，提供对手写文档的有效视觉反馈是一个重要的但研究不足的领域。", "method": "通过实证分析对比模块化系统与端到端系统的性能。", "result": "发现当前两种方法都无法达到整体可接受的质量标准。", "conclusion": "识别出主要的技术挑战，并提出未来的研究方向。"}}
{"id": "2601.09578", "pdf": "https://arxiv.org/pdf/2601.09578", "abs": "https://arxiv.org/abs/2601.09578", "authors": ["Jiajun Sun", "Yangyi Ou", "Haoyuan Zheng", "Chao yang", "Yue Ma"], "title": "Multimodal Signal Processing For Thermo-Visible-Lidar Fusion In Real-time 3D Semantic Mapping", "categories": ["cs.RO", "cs.CV"], "comment": "5 pages,7 figures. Under review", "summary": "In complex environments, autonomous robot navigation and environmental perception pose higher requirements for SLAM technology. This paper presents a novel method for semantically enhancing 3D point cloud maps with thermal information. By first performing pixel-level fusion of visible and infrared images, the system projects real-time LiDAR point clouds onto this fused image stream. It then segments heat source features in the thermal channel to instantly identify high temperature targets and applies this temperature information as a semantic layer on the final 3D map. This approach generates maps that not only have accurate geometry but also possess a critical semantic understanding of the environment, making it highly valuable for specific applications like rapid disaster assessment and industrial preventive maintenance.", "AI": {"tldr": "本文提出了一种新的方法，通过融合可见光、红外和激光雷达信号来增强三维点云地图的语义信息。", "motivation": "在复杂环境中，自主机器人导航和环境感知对SLAM技术提出了更高的要求，需要更精确的地图以提高其性能。", "method": "首先进行可见光与红外图像的像素级融合，并将实时激光雷达点云投影到该融合图像流上；接着通过分割热源特征识别高温目标，并将其作为语义层添加在最终生成的三维地图中。", "result": "该方法产生的地图不仅具有准确的几何信息，还具备对环境的重要语义理解能力，适用于快速灾害评估和工业预防性维护等具体应用领域。", "conclusion": "通过融合多模态信号来增强3D点云地图的语义层，显著提高了自主机器人在复杂环境中导航与感知的能力。"}}
{"id": "2601.09577", "pdf": "https://arxiv.org/pdf/2601.09577", "abs": "https://arxiv.org/abs/2601.09577", "authors": ["MD Nazmul Alam Shanto", "Md. Tanzeem Rahat", "Md. Manzurul Hasan"], "title": "Permutation Matching Under Parikh Budgets: Linear-Time Detection, Packing, and Disjoint Selection", "categories": ["cs.DS", "cs.CL"], "comment": "12 pages (Excluding reference)", "summary": "We study permutation (jumbled/Abelian) pattern matching over a general alphabet $Σ$. Given a pattern P of length m and a text T of length n, the classical task is to decide whether T contains a length-m substring whose Parikh vector equals that of P . While this existence problem admits a linear-time sliding-window solution, many practical applications require optimization and packing variants beyond mere detection. We present a unified sliding-window framework based on maintaining the Parikh-vector difference between P and the current window of T , enabling permutation matching in O(n + σ) time and O(σ) space, where σ = |Σ|. Building on this foundation, we introduce a combinatorial-optimization variant that we call Maximum Feasible Substring under Pattern Supply (MFSP): find the longest substring S of T whose symbol counts are component-wise bounded by those of P . We show that MFSP can also be solved in O(n + σ) time via a two-pointer feasibility maintenance algorithm, providing an exact packing interpretation of P as a resource budget. Finally, we address non-overlapping occurrence selection by modeling each permutation match as an equal-length interval and proving that a greedy earliest-finishing strategy yields a maximum-cardinality set of disjoint matches, computable in linear time once all matches are enumerated. Our results provide concise, provably correct algorithms with tight bounds, and connect frequency-based string matching to packing-style optimization primitives.", "AI": {"tldr": "本文研究了基于Parikh预算的排列匹配问题，提出了线性时间检测、打包和不相交选择的方法。", "motivation": "尽管存在排列模式匹配的线性时间滑动窗口解决方案，许多实际应用需要超越简单检测的优化和打包变体。", "method": "本文提出了一种基于维护P与T当前窗口之间的Parikh向量差的统一滑动窗口框架，并通过两指针可行性维护算法解决了最大可行子串问题，在所有匹配枚举后使用贪婪最早完成策略实现非重叠出现选择。", "result": "文章提供了O(n + σ)时间复杂度和O(σ)空间复杂度的排列匹配解决方案，以及用于解决最大可行子串问题和非重叠出现选择的线性时间算法。", "conclusion": "本文的研究结果提供了简洁、正确且紧致界限制的算法，并将基于频率的字符串匹配与打包优化原语连接起来。"}}
{"id": "2601.09575", "pdf": "https://arxiv.org/pdf/2601.09575", "abs": "https://arxiv.org/abs/2601.09575", "authors": ["Sheng-Yu Huang", "Jaesung Choe", "Yu-Chiang Frank Wang", "Cheng Sun"], "title": "OpenVoxel: Training-Free Grouping and Captioning Voxels for Open-Vocabulary 3D Scene Understanding", "categories": ["cs.CV"], "comment": "project page: https://peterjohnsonhuang.github.io/openvoxel-pages/", "summary": "We propose OpenVoxel, a training-free algorithm for grouping and captioning sparse voxels for the open-vocabulary 3D scene understanding tasks. Given the sparse voxel rasterization (SVR) model obtained from multi-view images of a 3D scene, our OpenVoxel is able to produce meaningful groups that describe different objects in the scene. Also, by leveraging powerful Vision Language Models (VLMs) and Multi-modal Large Language Models (MLLMs), our OpenVoxel successfully build an informative scene map by captioning each group, enabling further 3D scene understanding tasks such as open-vocabulary segmentation (OVS) or referring expression segmentation (RES). Unlike previous methods, our method is training-free and does not introduce embeddings from a CLIP/BERT text encoder. Instead, we directly proceed with text-to-text search using MLLMs. Through extensive experiments, our method demonstrates superior performance compared to recent studies, particularly in complex referring expression segmentation (RES) tasks. The code will be open.", "AI": {"tldr": "该论文提出了OpenVoxel，一个无需训练的算法，用于对稀疏体素进行分组和描述，以实现开放词汇表的3D场景理解任务。", "motivation": "动机在于开发一种无须训练的方法，能够利用视觉语言模型（VLMs）和多模态大型语言模型（MLLMs），直接处理文本到文本的搜索，并在复杂参照表达式分割任务中表现出色。", "method": "方法基于给定的3D场景的多视角图像获得稀疏体素栅格化（SVR）模型，使用OpenVoxel进行有意义的对象分组及描述，构建信息丰富的场景地图。", "result": "通过广泛的实验，该论文的方法在复杂参照表达式分割任务中表现优于近期研究。", "conclusion": "结论为提出的新方法展示了无需训练即可有效处理开放词汇表下的3D场景理解任务的能力，并将代码开源。"}}
{"id": "2601.09572", "pdf": "https://arxiv.org/pdf/2601.09572", "abs": "https://arxiv.org/abs/2601.09572", "authors": ["Tianli Tao", "Ziyang Wang", "Delong Yang", "Han Zhang", "Le Zhang"], "title": "Trustworthy Longitudinal Brain MRI Completion: A Deformation-Based Approach with KAN-Enhanced Diffusion Model", "categories": ["cs.CV"], "comment": null, "summary": "Longitudinal brain MRI is essential for lifespan study, yet high attrition rates often lead to missing data, complicating analysis. Deep generative models have been explored, but most rely solely on image intensity, leading to two key limitations: 1) the fidelity or trustworthiness of the generated brain images are limited, making downstream studies questionable; 2) the usage flexibility is restricted due to fixed guidance rooted in the model structure, restricting full ability to versatile application scenarios. To address these challenges, we introduce DF-DiffCom, a Kolmogorov-Arnold Networks (KAN)-enhanced diffusion model that smartly leverages deformation fields for trustworthy longitudinal brain image completion. Trained on OASIS-3, DF-DiffCom outperforms state-of-the-art methods, improving PSNR by 5.6% and SSIM by 0.12. More importantly, its modality-agnostic nature allows smooth extension to varied MRI modalities, even to attribute maps such as brain tissue segmentation results.", "AI": {"tldr": "本文提出了DF-DiffCom，一种基于变形场的扩散模型，用于完成纵向脑部MRI图像，并在OASIS-3数据集上验证了其性能优于现有方法。", "motivation": "现有的深度生成模型主要依赖于图像强度信息来生成缺失的脑部MRI图像，导致生成图像的信任度低且应用受限。本文旨在通过引入变形场和KAN增强的扩散模型解决这些问题。", "method": "DF-DiffCom使用了KAN（Kolmogorov-Arnold Networks）增强的扩散模型，利用变形场进行纵向脑部MRI图像完成，并展示了其在不同MRI模态中的通用性。", "result": "相比现有方法，DF-DiffCom在PSNR上提升了5.6%，SSIM提升了0.12，并且能够扩展应用于不同的MRI模态中。", "conclusion": "DF-DiffCom通过KAN增强的扩散模型和变形场实现了更可信、更灵活的纵向脑部MRI图像完成，为未来的脑部研究提供了有力工具。"}}
{"id": "2601.09566", "pdf": "https://arxiv.org/pdf/2601.09566", "abs": "https://arxiv.org/abs/2601.09566", "authors": ["Shuyang Xiang", "Hao Guan"], "title": "Hot-Start from Pixels: Low-Resolution Visual Tokens for Chinese Language Modeling", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, 5 figures, submitted to ACL 2026", "summary": "Large language models typically represent Chinese characters as discrete index-based tokens, largely ignoring their visual form. For logographic scripts, visual structure carries semantic and phonetic information, which may aid prediction. We investigate whether low-resolution visual inputs can serve as an alternative for character-level modeling. Instead of token IDs, our decoder receives grayscale images of individual characters, with resolutions as low as $8 \\times 8$ pixels. Remarkably, these inputs achieve 39.2\\% accuracy, comparable to the index-based baseline of 39.1\\%. Such low-resource settings also exhibit a pronounced \\emph{hot-start} effect: by 0.4\\% of total training, accuracy reaches above 12\\%, while index-based models lag at below 6\\%. Overall, our results demonstrate that minimal visual structure can provide a robust and efficient signal for Chinese language modeling, offering an alternative perspective on character representation that complements traditional index-based approaches.", "AI": {"tldr": "研究使用低分辨率视觉输入代替索引字符来改进中文语言模型。", "motivation": "传统大语言模型将汉字表示为基于离散索引的标记，忽视了它们的视觉形式所携带的语义和音韵信息。", "method": "该方法用8x8像素灰度图像替代传统的字符索引作为解码器输入进行字符级别的建模。", "result": "低分辨率图像输入达到了39.2%的准确率，与基于索引的方法（39.1%）相当，并在早期训练阶段表现出显著的“热启动”效果。", "conclusion": "结果表明，极小量的视觉结构可以为中文语言建模提供稳健且高效的信号，为字符表示提供了新的视角。"}}
{"id": "2601.09557", "pdf": "https://arxiv.org/pdf/2601.09557", "abs": "https://arxiv.org/abs/2601.09557", "authors": ["Francisco Angulo de Lafuente", "Seid Mehammed Abdu", "Nirmal Tej"], "title": "SiliconHealth: A Complete Low-Cost Blockchain Healthcare Infrastructure for Resource-Constrained Regions Using Repurposed Bitcoin Mining ASICs", "categories": ["cs.NE", "cs.CR"], "comment": "8 pages, 9 tables, 2 figures, experimental validation with cross-device results, economic analysis", "summary": "This paper presents SiliconHealth, a comprehensive blockchain-based healthcare infrastructure designed for resource-constrained regions, particularly sub-Saharan Africa. We demonstrate that obsolete Bitcoin mining Application-Specific Integrated Circuits (ASICs) can be repurposed to create a secure, low-cost, and energy-efficient medical records system. The proposed architecture employs a four-tier hierarchical network: regional hospitals using Antminer S19 Pro (90+ TH/s), urban health centers with Antminer S9 (14 TH/s), rural clinics equipped with Lucky Miner LV06 (500 GH/s, 13W), and mobile health points with portable ASIC devices. We introduce the Deterministic Hardware Fingerprinting (DHF) paradigm, which repurposes SHA-256 mining ASICs as cryptographic proof generators, achieving 100% verification rate across 23 test proofs during 300-second validation sessions. The system incorporates Reed-Solomon LSB watermarking for medical image authentication with 30-40% damage tolerance, semantic Retrieval-Augmented Generation (RAG) for intelligent medical record queries, and offline synchronization protocols for intermittent connectivity. Economic analysis demonstrates 96% cost reduction compared to GPU-based alternatives, with total deployment cost of $847 per rural clinic including 5-year solar power infrastructure. Validation experiments on Lucky Miner LV06 (BM1366 chip, 5nm) achieve 2.93 MH/W efficiency and confirm hardware universality. This work establishes a practical framework for deploying verifiable, tamper-proof electronic health records in regions where traditional healthcare IT infrastructure is economically unfeasible, potentially benefiting over 600 million people lacking access to basic health information systems.", "AI": {"tldr": "本文介绍了一个基于区块链的全面医疗基础设施SiliconHealth，旨在为资源受限地区提供低成本、安全且节能的电子健康记录系统。", "motivation": "本论文的主要动机是解决欠发达地区的医疗卫生信息基础设施建设问题，尤其是在非洲撒哈拉以南区域，这些地区缺乏足够的经济支持来建立传统医疗IT基础设施。", "method": "该研究使用了废弃的比特币挖掘ASIC设备作为基础硬件，并提出了一种名为确定性硬件指纹（DHF）的方法。通过这种方法，将SHA-256采矿ASIC转换为加密证明生成器，并且系统还采用了Reed-Solomon LSB水印技术用于医学影像认证、语义检索增强生成（RAG）以及离线同步协议。", "result": "测试显示该系统的验证率达到100%，并且实现了96%的成本节约，部署成本仅为847美元。实验验证了硬件的通用性和能源效率。", "conclusion": "SiliconHealth项目建立了一个实用框架，可以在经济上不可行地区实施可验证和防篡改的电子健康记录系统，有望惠及超过6亿缺乏基本卫生信息系统的人们。"}}
{"id": "2601.09555", "pdf": "https://arxiv.org/pdf/2601.09555", "abs": "https://arxiv.org/abs/2601.09555", "authors": ["Manyi Zhang", "Ji-Fu Li", "Zhongao Sun", "Haoli Bai", "Hui-Ling Zhen", "Zhenhua Dong", "Xianzhi Yu"], "title": "Benchmarking Post-Training Quantization of Large Language Models under Microscaling Floating Point Formats", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Microscaling Floating-Point (MXFP) has emerged as a promising low-precision format for large language models (LLMs). Despite various post-training quantization (PTQ) algorithms being proposed, they mostly focus on integer quantization, while their applicability and behavior under MXFP formats remain largely unexplored. To address this gap, this work conducts a systematic investigation of PTQ under MXFP formats, encompassing over 7 PTQ algorithms, 15 evaluation benchmarks, and 3 LLM families. The key findings include: 1) MXFP8 consistently achieves near-lossless performance, while MXFP4 introduces substantial accuracy degradation and remains challenging; 2) PTQ effectiveness under MXFP depends strongly on format compatibility, with some algorithmic paradigms being consistently more effective than others; 3) PTQ performance exhibits highly consistent trends across model families and modalities, in particular, quantization sensitivity is dominated by the language model rather than the vision encoder in multimodal LLMs; 4) The scaling factor of quantization is a critical error source in MXFP4, and a simple pre-scale optimization strategy can significantly mitigate its impact. Together, these results provide practical guidance on adapting existing PTQ methods to MXFP quantization.", "AI": {"tldr": "本文研究了大规模语言模型在微缩浮点格式下进行后训练量化的效果，评估了多种量化算法。", "motivation": "尽管已经提出了多种后训练量化（PTQ）算法，但这些算法大多集中在整数量化上，而它们在MXFP格式下的适用性和行为尚未得到充分研究。本文旨在填补这一空白。", "method": "系统性地调查了7种PTQ算法、15个评估基准和3个大规模语言模型系列在MXFP格式下进行后训练量化的表现。", "result": "关键发现包括：1) MXFP8能够实现接近无损的性能，而MXFP4则引入了显著的准确性退化；2) PTQ的效果依赖于格式兼容性，某些算法范式比其他更有效；3) PTQ性能在模型家族和模态之间表现出高度一致的趋势，量化的敏感性主要由语言模型决定。", "conclusion": "这些结果为将现有的PTQ方法适应到MXFP量化提供了实用指南。"}}
{"id": "2601.09536", "pdf": "https://arxiv.org/pdf/2601.09536", "abs": "https://arxiv.org/abs/2601.09536", "authors": ["Dongjie Cheng", "Yongqi Li", "Zhixin Ma", "Hongru Cai", "Yupeng Hu", "Wenjie Wang", "Liqiang Nie", "Wenjie Li"], "title": "Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) are making significant progress in multimodal reasoning. Early approaches focus on pure text-based reasoning. More recent studies have incorporated multimodal information into the reasoning steps; however, they often follow a single task-specific reasoning pattern, which limits their generalizability across various multimodal tasks. In fact, there are numerous multimodal tasks requiring diverse reasoning skills, such as zooming in on a specific region or marking an object within an image. To address this, we propose unified generative multimodal reasoning, which unifies diverse multimodal reasoning skills by generating intermediate images during the reasoning process. We instantiate this paradigm with Omni-R1, a two-stage SFT+RL framework featuring perception alignment loss and perception reward, thereby enabling functional image generation. Additionally, we introduce Omni-R1-Zero, which eliminates the need for multimodal annotations by bootstrapping step-wise visualizations from text-only reasoning data. Empirical results show that Omni-R1 achieves unified generative reasoning across a wide range of multimodal tasks, and Omni-R1-Zero can match or even surpass Omni-R1 on average, suggesting a promising direction for generative multimodal reasoning.", "AI": {"tldr": "本文提出了统一生成多模态推理范式Omni-R1，以实现跨多种多模态任务的通用推理。", "motivation": "早期方法集中在纯文本推理上，最近的研究虽然开始融合多模态信息，但局限于特定任务模式，限制了其泛化能力。因此，需要一种更广泛的推理机制来处理多样化的多模态任务。", "method": "Omni-R1采用两阶段SFT+RL框架，通过引入感知对齐损失和奖励，实现功能图像生成。此外，还介绍了Omni-R1-Zero版本，无需多模态注释，利用从纯文本推理数据引导的逐步可视化来训练模型。", "result": "实验结果表明，Omni-R1实现了跨多种多模态任务的统一生成推理能力，而Omni-R1-Zero甚至在平均性能上可以匹敌或超越Omni-R1。", "conclusion": "研究提出了一种新的范式和框架，证明了其在实现广泛多模态推理中的潜力，并展示了无需额外标注数据也能达到良好效果的新方法。"}}
{"id": "2601.09531", "pdf": "https://arxiv.org/pdf/2601.09531", "abs": "https://arxiv.org/abs/2601.09531", "authors": ["Yue Yao", "Ruining Yang", "Tom Gedeon"], "title": "Bipartite Mode Matching for Vision Training Set Search from a Hierarchical Data Server", "categories": ["cs.CV"], "comment": "Accepted to AAAI 2026", "summary": "We explore a situation in which the target domain is accessible, but real-time data annotation is not feasible. Instead, we would like to construct an alternative training set from a large-scale data server so that a competitive model can be obtained. For this problem, because the target domain usually exhibits distinct modes (i.e., semantic clusters representing data distribution), if the training set does not contain these target modes, the model performance would be compromised. While prior existing works improve algorithms iteratively, our research explores the often-overlooked potential of optimizing the structure of the data server. Inspired by the hierarchical nature of web search engines, we introduce a hierarchical data server, together with a bipartite mode matching algorithm (BMM) to align source and target modes. For each target mode, we look in the server data tree for the best mode match, which might be large or small in size. Through bipartite matching, we aim for all target modes to be optimally matched with source modes in a one-on-one fashion. Compared with existing training set search algorithms, we show that the matched server modes constitute training sets that have consistently smaller domain gaps with the target domain across object re-identification (re-ID) and detection tasks. Consequently, models trained on our searched training sets have higher accuracy than those trained otherwise. BMM allows data-centric unsupervised domain adaptation (UDA) orthogonal to existing model-centric UDA methods. By combining the BMM with existing UDA methods like pseudo-labeling, further improvement is observed.", "AI": {"tldr": "本文提出了Bipartite Mode Matching (BMM)算法，用于从分层数据服务器中搜索训练集以改善目标域中的模型性能。", "motivation": "研究的动机在于解决真实时间的数据标注不可行时，如何构建一个替代训练集来获得有竞争力的模型，并且通过优化数据服务器结构而非改进算法迭代，减小源域和目标域之间的差异。", "method": "本文提出了一种分层数据服务器和双模匹配（BMM）算法，用于将源模式与目标模式对齐，实现从大尺度的数据服务器中搜索出训练集。", "result": "实验结果显示，使用BMM方法找到的训练集在对象重识别和检测任务中的领域差异较小，并且基于此训练集训练出的模型具有更高的准确性。", "conclusion": "BMM允许数据为中心的无监督域适应（UDA）与现有的以模型为中心的UDA方法正交结合，通过与伪标签等现有UDA方法结合，进一步提高性能。"}}
{"id": "2601.09528", "pdf": "https://arxiv.org/pdf/2601.09528", "abs": "https://arxiv.org/abs/2601.09528", "authors": ["Alfio Spoto", "Rosario Leonardi", "Francesco Ragusa", "Giovanni Maria Farinella"], "title": "GlovEgo-HOI: Bridging the Synthetic-to-Real Gap for Industrial Egocentric Human-Object Interaction Detection", "categories": ["cs.CV"], "comment": "8 pages, accepted as a Short Paper at VISAPP 2026", "summary": "Egocentric Human-Object Interaction (EHOI) analysis is crucial for industrial safety, yet the development of robust models is hindered by the scarcity of annotated domain-specific data. We address this challenge by introducing a data generation framework that combines synthetic data with a diffusion-based process to augment real-world images with realistic Personal Protective Equipment (PPE). We present GlovEgo-HOI, a new benchmark dataset for industrial EHOI, and GlovEgo-Net, a model integrating Glove-Head and Keypoint- Head modules to leverage hand pose information for enhanced interaction detection. Extensive experiments demonstrate the effectiveness of the proposed data generation framework and GlovEgo-Net. To foster further research, we release the GlovEgo-HOI dataset, augmentation pipeline, and pre-trained models at: GitHub project.", "AI": {"tldr": "本文提出GlovEgo-HOI，一种结合合成数据和扩散过程生成增强现实图像的方法，并开发了用于工业人类物体交互检测的数据集和模型。", "motivation": "为了解决因标注数据稀缺而阻碍的工业安全中鲁棒模型的发展问题。", "method": "通过将合成数据与基于扩散的过程相结合，以增加包含真实个人防护装备的现实图像，创建新基准数据集GlovEgo-HOI和模型GlovEgo-Net。", "result": "实验表明所提出的生成框架和GlovEgo-Net的有效性。", "conclusion": "提出的数据生成框架和模型在工业环境中的人类物体交互检测任务中表现出色，并公开了数据集、增强管道和预训练模型以促进进一步研究。"}}
{"id": "2601.09527", "pdf": "https://arxiv.org/pdf/2601.09527", "abs": "https://arxiv.org/abs/2601.09527", "authors": ["Jonathan Knoop", "Hendrik Holtmann"], "title": "Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": "15 pages, 18 tables, 7 figures. Includes link to GitHub repository and Docker image for reproducibility", "summary": "SMEs increasingly seek alternatives to cloud LLM APIs, which raise data privacy concerns. Dedicated cloud GPU instances offer improved privacy but with limited guarantees and ongoing costs, while professional on-premise hardware (A100, H100) remains prohibitively expensive. We present a systematic evaluation of NVIDIA's Blackwell consumer GPUs (RTX 5060 Ti, 5070 Ti, 5090) for production LLM inference, benchmarking four open-weight models (Qwen3-8B, Gemma3-12B, Gemma3-27B, GPT-OSS-20B) across 79 configurations spanning quantization formats (BF16, W4A16, NVFP4, MXFP4), context lengths (8k-64k), and three workloads: RAG, multi-LoRA agentic serving, and high-concurrency APIs. The RTX 5090 delivers 3.5-4.6x higher throughput than the 5060 Ti with 21x lower latency for RAG, but budget GPUs achieve the highest throughput-per-dollar for API workloads with sub-second latency. NVFP4 quantization provides 1.6x throughput over BF16 with 41% energy reduction and only 2-4% quality loss. Self-hosted inference costs $0.001-0.04 per million tokens (electricity only), which is 40-200x cheaper than budget-tier cloud APIs, with hardware breaking even in under four months at moderate volume (30M tokens/day). Our results show that consumer GPUs can reliably replace cloud inference for most SME workloads, except latency-critical long-context RAG, where high-end GPUs remain essential. We provide deployment guidance and release all benchmark data for reproducible SME-scale deployments.", "AI": {"tldr": "本文评估了NVIDIA Blackwell消费者级GPU在小企业本地部署大型语言模型（LLM）推理的可行性和经济效益。", "motivation": "随着中小企业对数据隐私的关注，他们寻求替代基于云的LLM API的方案。专业的云计算和硬件成本高昂且无法完全保证隐私，本文旨在探索使用消费级GPU实现经济高效的本地化部署。", "method": "系统地评估了NVIDIA Blackwell系列消费者级GPU（RTX 5060 Ti、5070 Ti、5090）的性能，针对四个开源权重模型（Qwen3-8B、Gemma3-12B、Gemma3-27B、GPT-OSS-20B），在79种不同的配置下进行了基准测试，涉及量化格式、上下文长度和三个工作负载。", "result": "RTX 5090在RAG工作负载中比5060 Ti性能高出3.5到4.6倍，且延迟降低21倍。预算级GPU在API工作负载中每单位成本的吞吐量更高，并具有亚秒级延迟。NVFP4量化提高了1.6倍的吞吐量并减少了41%的能耗，仅有2-4%的质量损失。自托管推理的成本仅为0.001至0.04美元/百万令牌（仅电费），比低成本云API便宜40到200倍。", "conclusion": "结果表明，消费级GPU可以可靠地替代大多数中小企业的工作负载，但高延迟敏感长上下文RAG工作负载仍需高端GPU。本文提供了部署指南并发布了所有基准数据以支持可重复的小规模企业部署。"}}
