{"id": "2601.02359", "pdf": "https://arxiv.org/pdf/2601.02359", "abs": "https://arxiv.org/abs/2601.02359", "authors": ["Kaede Shiohara", "Toshihiko Yamasaki", "Vladislav Golyanik"], "title": "ExposeAnyone: Personalized Audio-to-Expression Diffusion Models Are Robust Zero-Shot Face Forgery Detectors", "categories": ["cs.CV"], "comment": "17 pages, 8 figures, 11 tables; project page: https://mapooon.github.io/ExposeAnyonePage/", "summary": "Detecting unknown deepfake manipulations remains one of the most challenging problems in face forgery detection. Current state-of-the-art approaches fail to generalize to unseen manipulations, as they primarily rely on supervised training with existing deepfakes or pseudo-fakes, which leads to overfitting to specific forgery patterns. In contrast, self-supervised methods offer greater potential for generalization, but existing work struggles to learn discriminative representations only from self-supervision. In this paper, we propose ExposeAnyone, a fully self-supervised approach based on a diffusion model that generates expression sequences from audio. The key idea is, once the model is personalized to specific subjects using reference sets, it can compute the identity distances between suspected videos and personalized subjects via diffusion reconstruction errors, enabling person-of-interest face forgery detection. Extensive experiments demonstrate that 1) our method outperforms the previous state-of-the-art method by 4.22 percentage points in the average AUC on DF-TIMIT, DFDCP, KoDF, and IDForge datasets, 2) our model is also capable of detecting Sora2-generated videos, where the previous approaches perform poorly, and 3) our method is highly robust to corruptions such as blur and compression, highlighting the applicability in real-world face forgery detection.", "AI": {"tldr": "提出了一种基于扩散模型的自监督方法ExposeAnyone，用于识别未知深度伪造视频。", "motivation": "当前最先进的方法在未见过的操纵上泛化能力差，依赖于现有假脸或伪假脸的监督训练导致过度拟合特定伪造模式，而自我监督方法难以仅通过自我监督学习出区分性表示。", "method": "使用个性化扩散模型生成音频到表情序列，计算视频与个人身份之间的距离误差以检测伪造行为。", "result": "在DF-TIMIT等数据集上优于前人4.22个百分点的AUC，并且对Sora2生成的视频也有很好的检测效果，同时表现出良好的鲁棒性。", "conclusion": "ExposeAnyone是一种有效且鲁棒性强的方法，适用于实际中的深度伪造检测任务。"}}
{"id": "2601.02358", "pdf": "https://arxiv.org/pdf/2601.02358", "abs": "https://arxiv.org/abs/2601.02358", "authors": ["Junyi Chen", "Tong He", "Zhoujie Fu", "Pengfei Wan", "Kun Gai", "Weicai Ye"], "title": "VINO: A Unified Visual Generator with Interleaved OmniModal Context", "categories": ["cs.CV"], "comment": "Project page: https://sotamak1r.github.io/VINO-web/", "summary": "We present VINO, a unified visual generator that performs image and video generation and editing within a single framework. Instead of relying on task-specific models or independent modules for each modality, VINO uses a shared diffusion backbone that conditions on text, images and videos, enabling a broad range of visual creation and editing tasks under one model. Specifically, VINO couples a vision-language model (VLM) with a Multimodal Diffusion Transformer (MMDiT), where multimodal inputs are encoded as interleaved conditioning tokens, and then used to guide the diffusion process. This design supports multi-reference grounding, long-form instruction following, and coherent identity preservation across static and dynamic content, while avoiding modality-specific architectural components. To train such a unified system, we introduce a multi-stage training pipeline that progressively expands a video generation base model into a unified, multi-task generator capable of both image and video input and output. Across diverse generation and editing benchmarks, VINO demonstrates strong visual quality, faithful instruction following, improved reference and attribute preservation, and more controllable multi-identity edits. Our results highlight a practical path toward scalable unified visual generation, and the promise of interleaved, in-context computation as a foundation for general-purpose visual creation.", "AI": {"tldr": "VINO是一种统一的视觉生成器，能够在单一框架内执行图像和视频生成及编辑任务。", "motivation": "为了实现更广泛的视觉创作和编辑任务并避免特定模态的架构组件，作者提出了一个共享扩散骨干网络结合了视觉-语言模型与多模态扩散变换器的设计。", "method": "VINO利用了一个共享的扩散主干网作为基础，通过文本、图像和视频进行条件化处理。它将多模态输入编码为交错的条件令牌，并使用这些令牌引导扩散过程。此外，还引入了多阶段训练管道以逐步扩展视频生成基本模型到统一的多任务生成器。", "result": "在各种生成和编辑基准上，VINO展示了强大的视觉质量、忠实指令跟随能力以及改进的参考与属性保持。", "conclusion": "该研究揭示了一条通向可扩展统一视觉生成的实际路径，并证明了交错上下文计算作为通用视觉创建基础的重要性。"}}
{"id": "2601.02357", "pdf": "https://arxiv.org/pdf/2601.02357", "abs": "https://arxiv.org/abs/2601.02357", "authors": ["Trey Brosnan"], "title": "DARC: Drum accompaniment generation with fine-grained rhythm control", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "In music creation, rapid prototyping is essential for exploring and refining ideas, yet existing generative tools often fall short when users require both structural control and stylistic flexibility. Prior approaches in stem-to-stem generation can condition on other musical stems but offer limited control over rhythm, and timbre-transfer methods allow users to specify specific rhythms, but cannot condition on musical context. We introduce DARC, a generative drum accompaniment model that conditions both on musical context from other stems and explicit rhythm prompts such as beatboxing or tapping tracks. Using parameter-efficient fine-tuning, we augment STAGE, a state-of-the-art drum stem generator, with fine-grained rhythm control while maintaining musical context awareness.", "AI": {"tldr": "DARC是一种生成鼓伴奏的模型，能够同时根据音乐上下文和明确的节奏提示进行条件控制。", "motivation": "现有生成工具在需要结构控制和风格灵活性时表现不足。DARC旨在提供精细的节奏控制同时保持对音乐背景的理解。", "method": "使用参数高效的微调技术，在STAGE模型的基础上添加了细粒度的节奏控制，从而使模型既能根据其他音轨提供的上下文信息工作，也能响应特定的节奏输入如节拍或轻敲的声音。", "result": "该方法能够生成既符合音乐背景又具备明确节奏特征的鼓伴奏。", "conclusion": "DARC通过结合对音乐背景的理解和细粒度的节奏控制，在快速原型设计中提供了更好的灵活性和支持，从而促进了音乐创作过程。"}}
{"id": "2601.02356", "pdf": "https://arxiv.org/pdf/2601.02356", "abs": "https://arxiv.org/abs/2601.02356", "authors": ["Jing Tan", "Zhaoyang Zhang", "Yantao Shen", "Jiarui Cai", "Shuo Yang", "Jiajun Wu", "Wei Xia", "Zhuowen Tu", "Stefano Soatto"], "title": "Talk2Move: Reinforcement Learning for Text-Instructed Object-Level Geometric Transformation in Scenes", "categories": ["cs.CV"], "comment": "Project page: https://sparkstj.github.io/talk2move", "summary": "We introduce Talk2Move, a reinforcement learning (RL) based diffusion framework for text-instructed spatial transformation of objects within scenes. Spatially manipulating objects in a scene through natural language poses a challenge for multimodal generation systems. While existing text-based manipulation methods can adjust appearance or style, they struggle to perform object-level geometric transformations-such as translating, rotating, or resizing objects-due to scarce paired supervision and pixel-level optimization limits. Talk2Move employs Group Relative Policy Optimization (GRPO) to explore geometric actions through diverse rollouts generated from input images and lightweight textual variations, removing the need for costly paired data. A spatial reward guided model aligns geometric transformations with linguistic description, while off-policy step evaluation and active step sampling improve learning efficiency by focusing on informative transformation stages. Furthermore, we design object-centric spatial rewards that evaluate displacement, rotation, and scaling behaviors directly, enabling interpretable and coherent transformations. Experiments on curated benchmarks demonstrate that Talk2Move achieves precise, consistent, and semantically faithful object transformations, outperforming existing text-guided editing approaches in both spatial accuracy and scene coherence.", "AI": {"tldr": "介绍Talk2Move，一种基于强化学习的框架，用于通过自然语言指令进行场景中物体级别的几何变换。", "motivation": "当前多模态生成系统难以执行文本引导的物体级别几何变换，如平移、旋转或缩放。此挑战在于缺乏配对监督和像素级优化限制。", "method": "Talk2Move采用Group Relative Policy Optimization (GRPO)算法来探索多样化的动作，并通过空间奖励模型使几何变换与语言描述一致。此外，设计了以物体为中心的空间奖励来直接评估位移、旋转和缩放行为。", "result": "实验结果表明，Talk2Move实现了精确、一致且语义忠实的物体变换，在空间精度和场景连贯性上优于现有文本引导编辑方法。", "conclusion": "通过采用强化学习策略并设计特定的空间奖励机制，Talk2Move成功解决了多模态生成系统中的关键挑战。"}}
{"id": "2601.02353", "pdf": "https://arxiv.org/pdf/2601.02353", "abs": "https://arxiv.org/abs/2601.02353", "authors": ["Shahnawaz Alam", "Mohammed Mudassir Uddin", "Mohammed Kaif Pasha"], "title": "Meta-Learning Guided Pruning for Few-Shot Plant Pathology on Edge Devices", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Farmers in remote areas need quick and reliable methods for identifying plant diseases, yet they often lack access to laboratories or high-performance computing resources. Deep learning models can detect diseases from leaf images with high accuracy, but these models are typically too large and computationally expensive to run on low-cost edge devices such as Raspberry Pi. Furthermore, collecting thousands of labeled disease images for training is both expensive and time-consuming. This paper addresses both challenges by combining neural network pruning -- removing unnecessary parts of the model -- with few-shot learning, which enables the model to learn from limited examples. This paper proposes Disease-Aware Channel Importance Scoring (DACIS), a method that identifies which parts of the neural network are most important for distinguishing between different plant diseases, integrated into a three-stage Prune-then-Meta-Learn-then-Prune (PMP) pipeline. Experiments on PlantVillage and PlantDoc datasets demonstrate that the proposed approach reduces model size by 78\\% while maintaining 92.3\\% of the original accuracy, with the compressed model running at 7 frames per second on a Raspberry Pi 4, making real-time field diagnosis practical for smallholder farmers.", "AI": {"tldr": "本文提出了DACIS方法，结合神经网络修剪和少样本学习，在减少模型大小的同时保持高准确率，适用于边缘设备的植物病理学诊断。", "motivation": "为了解决偏远地区农民缺乏实验室资源及高性能计算能力的问题，并且为了节约大规模标注数据集的成本与时间，论文提出了一种新的方法来实现快速、可靠的植物疾病识别。", "method": "通过引入Disease-Aware Channel Importance Scoring (DACIS) 方法，该方法能有效地识别神经网络中对区分不同植物疾病至关重要的部分。并将其整合进一个三阶段的Prune-then-Meta-Learn-then-Prune (PMP) 管道。", "result": "在PlantVillage和PlantDoc数据集上的实验表明，所提方法能够将模型大小减少78%，同时保持92.3%的原始准确率，压缩后的模型能在Raspberry Pi 4上以每秒7帧的速度运行。", "conclusion": "该研究展示了一种有效的方案，使边缘设备能够在实时田间诊断中实现植物病理学的应用，并为小规模农民提供了实用的价值。"}}
{"id": "2601.02347", "pdf": "https://arxiv.org/pdf/2601.02347", "abs": "https://arxiv.org/abs/2601.02347", "authors": ["Ishani Karmarkar", "Liam O'Carroll", "Aaron Sidford"], "title": "Solving Matrix Games with Even Fewer Matrix-Vector Products", "categories": ["math.OC", "cs.DS", "cs.GT"], "comment": null, "summary": "We study the problem of computing an $ε$-approximate Nash equilibrium of a two-player, bilinear, zero-sum game with a bounded payoff matrix $A \\in \\mathbb{R}^{m \\times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\\tilde{O}(ε^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\\ell_1$-$\\ell_1$ games, where the players' strategies are both in the probability simplex, and $\\ell_2$-$\\ell_1$ games, where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\\tilde{O}(ε^{-8/9})$ for $\\ell_1$-$\\ell_1$ and of $\\tilde{O}(ε^{-7/9})$ for $\\ell_2$-$\\ell_1$ due to [KOS '25]. In particular, our result for $\\ell_2$-$\\ell_1$, which corresponds to hard-margin support vector machines (SVMs), matches the lower bound of [KS '25] up to polylogarithmic factors.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02346", "pdf": "https://arxiv.org/pdf/2601.02346", "abs": "https://arxiv.org/abs/2601.02346", "authors": ["Falcon LLM Team", "Iheb Chaabane", "Puneesh Khanna", "Suhail Mohmad", "Slim Frikha", "Shi Hu", "Abdalgader Abubaker", "Reda Alami", "Mikhail Lubinets", "Mohamed El Amine Seddik", "Hakim Hacid"], "title": "Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling", "categories": ["cs.AI"], "comment": null, "summary": "This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\\times$ to $7\\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.", "AI": {"tldr": "介绍了一种名为Falcon-H1R的7B参数优化推理模型，该模型在不增加模型大小的情况下，通过精心的数据整理和训练策略实现了高效的推理性能。", "motivation": "探索如何使用小型语言模型实现高效且具有竞争力的推理性能，并减少计算成本。", "method": "通过结合有效的SFT（监督微调）和RL（强化学习）扩展方法，采用混合并行架构设计来提高推理速度、令牌效率和准确性。", "result": "Falcon-H1R在多个推理密集型基准测试中表现出色，并且其性能与比自己大2倍到7倍的SOTA模型相当或更高。此外，在测试时间规模扩展方面，它实现了最先进的效率。", "conclusion": "通过有针对性的训练策略和架构选择，紧凑的模型可以提供强大且可扩展的推理能力，适合需要大量链式思想生成和并行测试时扩大规模的应用场景。"}}
{"id": "2601.02339", "pdf": "https://arxiv.org/pdf/2601.02339", "abs": "https://arxiv.org/abs/2601.02339", "authors": ["Jingming He", "Chongyi Li", "Shiqi Wang", "Sam Kwong"], "title": "Joint Semantic and Rendering Enhancements in 3D Gaussian Modeling with Anisotropic Local Encoding", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Recent works propose extending 3DGS with semantic feature vectors for simultaneous semantic segmentation and image rendering. However, these methods often treat the semantic and rendering branches separately, relying solely on 2D supervision while ignoring the 3D Gaussian geometry. Moreover, current adaptive strategies adapt the Gaussian set depending solely on rendering gradients, which can be insufficient in subtle or textureless regions. In this work, we propose a joint enhancement framework for 3D semantic Gaussian modeling that synergizes both semantic and rendering branches. Firstly, unlike conventional point cloud shape encoding, we introduce an anisotropic 3D Gaussian Chebyshev descriptor using the Laplace-Beltrami operator to capture fine-grained 3D shape details, thereby distinguishing objects with similar appearances and reducing reliance on potentially noisy 2D guidance. In addition, without relying solely on rendering gradient, we adaptively adjust Gaussian allocation and spherical harmonics with local semantic and shape signals, enhancing rendering efficiency through selective resource allocation. Finally, we employ a cross-scene knowledge transfer module to continuously update learned shape patterns, enabling faster convergence and robust representations without relearning shape information from scratch for each new scene. Experiments on multiple datasets demonstrate improvements in segmentation accuracy and rendering quality while maintaining high rendering frame rates.", "AI": {"tldr": "本文提出了一种联合增强框架，用于同时进行三维语义分割和图像渲染的高精度建模。", "motivation": "当前方法在处理三维语义和图像渲染时通常独立对待，并主要依赖于二维指导而忽略了三维几何结构。此外，自适应策略仅依靠渲染梯度调整高斯集合，在细微或无纹理区域可能不足。", "method": "引入各向异性3D高斯Chebyshev描述符以捕捉细粒度的三维形状细节；通过局部语义和形状信号调整高斯分配和球谐函数，提高渲染效率；采用跨场景知识转移模块更新学习到的形状模式，加速收敛并提供稳健表示。", "result": "实验结果表明，在多个数据集上该方法提高了分割准确性和图像渲染质量，并保持了高的渲染帧率。", "conclusion": "所提出的方法有效增强了三维语义和渲染性能，展示了在多种场景下的优越性。"}}
{"id": "2601.02329", "pdf": "https://arxiv.org/pdf/2601.02329", "abs": "https://arxiv.org/abs/2601.02329", "authors": ["Laurent Caraffa"], "title": "BEDS: Bayesian Emergent Dissipative Structures", "categories": ["cs.CV"], "comment": "19 pages", "summary": "We present BEDS (Bayesian Emergent Dissipative Structures), a theoretical framework that unifies concepts from non-equilibrium thermodynamics, Bayesian inference, information geometry, and machine learning. The central thesis proposes that learning, across physical, biological, and computational systems, fundamentally constitutes the conversion of flux into structure through entropy export. Building on Prigogine's theory of dissipative structures, we establish a formal isomorphism between thermodynamic processes and Bayesian updating, demonstrating that sustainable learning systems must follow dissipative patterns where crystallized posteriors become priors for subsequent levels of emergence. We derive fundamental mathematical constants (e, π, φ) as fixed points of Bayesian inference under minimal axioms, suggesting these constants emerge necessarily from any system capable of representing and updating uncertainty. Furthermore, we propose a conjecture linking Gödel's incompleteness theorems to thermodynamic constraints, hypothesizing that pathologies of formal systems (incompleteness, undecidability) are structurally analogous to dissipation deficits in physical systems. As practical validation, we present a peer-to-peer network architecture implementing BEDS principles, achieving six orders of magnitude improvement in energy efficiency compared to existing distributed consensus systems while enabling continuous learning. This work bridges fundamental physics, mathematical logic, and practical system design, offering both theoretical insights into the nature of learning and computation, and a concrete pathway toward sustainable artificial intelligence.", "AI": {"tldr": "BEDS框架统一了非平衡热力学、贝叶斯推断、信息几何和机器学习的概念，提出了一种关于从物理系统到计算系统的通用学习理论", "motivation": "通过结合不同的科学领域来解释学习的本质，并解决现有分布式共识系统的低效率问题", "method": "建立了一个将热力学过程与贝叶斯更新形式上等同的框架，推导出一些基本数学常数作为固定点，并提出了一种新的网络架构实现BEDS原则", "result": "提出的网络架构实现了显著的能量效率提升，同时支持持续学习", "conclusion": "BEDS不仅为理解学习和计算的本质提供了理论见解，还提供了一个通往可持续人工智能的实际路径"}}
{"id": "2601.02318", "pdf": "https://arxiv.org/pdf/2601.02318", "abs": "https://arxiv.org/abs/2601.02318", "authors": ["Roja Sahoo", "Anoop Namboodiri"], "title": "Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching", "categories": ["cs.CV"], "comment": "15 pages, 8 figures, 5 tables. Submitted to ICPR 2026", "summary": "Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).", "AI": {"tldr": "提出了一种新的框架Fusion2Print，用于融合接触式指纹识别中的闪光和非闪光图像，以提高指纹清晰度和识别性能。", "motivation": "现有的接触式指纹识别系统在获取高质量的指纹图像时面临挑战，特别是在光照变化、皮肤色素沉着和镜面反射的影响下，导致指纹细节模糊不清。作者旨在通过融合两种不同类型的图像来改善这些缺陷，并开发了一个统一的框架以适应各种环境下的指纹匹配任务。", "method": "该方法首先建立了一套定制的数据集FNF数据库，然后通过手动闪照与非闪照减法技术分离出保存指纹特征的信息信号；接着采用基于注意力机制的轻量级融合网络处理两种模态信息，突出有效通道并抑制噪声；最后利用U-Net增强模块生成高质量灰度图，并训练了一个深度嵌入模型来生成兼容接触式和非接触式的统一表示。", "result": "实验表明Fusion2Print在验证性能上优于现有单一图像捕获的方法（AUC=0.999，EER=1.12%）。", "conclusion": "此方法有效提高了指纹识别系统的准确性和鲁棒性，在各种环境下的指纹匹配任务中表现出色。"}}
{"id": "2601.02316", "pdf": "https://arxiv.org/pdf/2601.02316", "abs": "https://arxiv.org/abs/2601.02316", "authors": ["Siddharth Joshi", "Haoli Yin", "Rishabh Adiga", "Ricardo Monti", "Aldo Carranza", "Alex Fang", "Alvin Deng", "Amro Abbas", "Brett Larsen", "Cody Blakeney", "Darren Teh", "David Schwab", "Fan Pan", "Haakon Mongstad", "Jack Urbanek", "Jason Lee", "Jason Telanoff", "Josh Wills", "Kaleigh Mentzer", "Luke Merrick", "Parth Doshi", "Paul Burstein", "Pratyush Maini", "Scott Loftin", "Spandan Das", "et al. (6 additional authors not shown)"], "title": "DatBench: Discriminative, Faithful, and Efficient VLM Evaluations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Empirical evaluation serves as the primary compass guiding research progress in foundation models. Despite a large body of work focused on training frontier vision-language models (VLMs), approaches to their evaluation remain nascent. To guide their maturation, we propose three desiderata that evaluations should satisfy: (1) faithfulness to the modality and application, (2) discriminability between models of varying quality, and (3) efficiency in compute. Through this lens, we identify critical failure modes that violate faithfulness and discriminability, misrepresenting model capabilities: (i) multiple-choice formats reward guessing, poorly reflect downstream use cases, and saturate early as models improve; (ii) blindly solvable questions, which can be answered without images, constitute up to 70% of some evaluations; and (iii) mislabeled or ambiguous samples compromise up to 42% of examples in certain datasets. Regarding efficiency, the computational burden of evaluating frontier models has become prohibitive: by some accounts, nearly 20% of development compute is devoted to evaluation alone. Rather than discarding existing benchmarks, we curate them via transformation and filtering to maximize fidelity and discriminability. We find that converting multiple-choice questions to generative tasks reveals sharp capability drops of up to 35%. In addition, filtering blindly solvable and mislabeled samples improves discriminative power while simultaneously reducing computational cost. We release DatBench-Full, a cleaned evaluation suite of 33 datasets spanning nine VLM capabilities, and DatBench, a discriminative subset that achieves 13x average speedup (up to 50x) while closely matching the discriminative power of the original datasets. Our work outlines a path toward evaluation practices that are both rigorous and sustainable as VLMs continue to scale.", "AI": {"tldr": "该论文提出了一个用于评估视觉语言模型（VLM）的新框架DatBench，旨在提高评价的准确性、区分能力和效率。", "motivation": "当前的模型评估方法存在多项缺陷：例如多选题容易被猜测而不反映下游应用的实际情况；部分问题不需要图像即可解决，这占用了大量资源；并且样本错误或模棱两可的情况较为普遍。此外，随着模型规模增大，评价所需的计算成本也愈发高昂。", "method": "通过将现有数据集转换和过滤来改进评估方法：将多选题转化为生成任务可以更好地揭示不同模型的能力差异；同时剔除那些不需要图像即可解答的问题以及存在标签错误或模棱两可的样本，从而增强区分度并降低计算成本。", "result": "DatBench-Full包含了33个数据集，涵盖了九种VLM能力，并且通过转换和过滤形成的新子集DatBench，在保持模型识别力的同时实现了平均13倍的速度提升（最多可达50倍）。", "conclusion": "该工作为未来的VLM评估提供了一个既严谨又可持续的方法论路径。"}}
{"id": "2601.02315", "pdf": "https://arxiv.org/pdf/2601.02315", "abs": "https://arxiv.org/abs/2601.02315", "authors": ["Saurabh Kaushik", "Lalit Maurya", "Beth Tellman"], "title": "Prithvi-Complimentary Adaptive Fusion Encoder (CAFE): unlocking full-potential for flood inundation mapping", "categories": ["cs.CV"], "comment": "Accepted at CV4EO Workshop @ WACV 2026", "summary": "Geo-Foundation Models (GFMs), have proven effective in diverse downstream applications, including semantic segmentation, classification, and regression tasks. However, in case of flood mapping using Sen1Flood11 dataset as a downstream task, GFMs struggles to outperform the baseline U-Net, highlighting model's limitation in capturing critical local nuances. To address this, we present the Prithvi-Complementary Adaptive Fusion Encoder (CAFE), which integrate Prithvi GFM pretrained encoder with a parallel CNN residual branch enhanced by Convolutional Attention Modules (CAM). Prithvi-CAFE enables fast and efficient fine-tuning through adapters in Prithvi and performs multi-scale, multi-level fusion with CNN features, capturing critical local details while preserving long-range dependencies. We achieve state-of-the-art results on two comprehensive flood mapping datasets: Sen1Flood11 and FloodPlanet. On Sen1Flood11 test data, Prithvi-CAFE (IoU 83.41) outperforms the original Prithvi (IoU 82.50) and other major GFMs (TerraMind 82.90, DOFA 81.54, spectralGPT: 81.02). The improvement is even more pronounced on the hold-out test site, where Prithvi-CAFE achieves an IoU of 81.37 compared to the baseline U-Net (70.57) and original Prithvi (72.42). On FloodPlanet, Prithvi-CAFE also surpasses the baseline U-Net and other GFMs, achieving an IoU of 64.70 compared to U-Net (60.14), Terramind (62.33), DOFA (59.15) and Prithvi 2.0 (61.91). Our proposed simple yet effective Prithvi-CAFE demonstrates strong potential for improving segmentation tasks where multi-channel and multi-modal data provide complementary information and local details are critical. The code is released on \\href{https://github.com/Sk-2103/Prithvi-CAFE}{Prithvi-CAFE Github}", "AI": {"tldr": "本文提出了Prithvi-互补自适应融合编码器（CAFE），通过结合预训练的Prithvi Geo-Foundation Model和增强的CNN残差支路，来提高洪水淹没地图制作的效果。", "motivation": "在使用Sen1Flood11数据集进行洪水映射时，Geo-Foundation Models难以超越基础模型U-Net，这表明了这些模型在捕捉关键局部细节方面的局限性。为了克服这一挑战，本文引入了一种新的方法来改进模型的表现。", "method": "Prithvi-CAFE将预训练的Prithvi编码器与增强有卷积注意力模块（CAM）的并行CNN残差分支集成在一起，并通过适配器进行快速高效的微调。它能够执行多尺度、多层次融合，捕捉关键局部细节同时保持长程依赖。", "result": "在Sen1Flood11和FloodPlanet两个洪水映射数据集上，Prithvi-CAFE取得了最先进的结果，在Sen1Flood11测试数据集中获得了IoU为83.41的成绩，并且在保持局部细节方面超过了其他主流的Geo-Foundation Models。", "conclusion": "通过提出的简单而有效的Prithvi-CAFE方法，本文展示了对于需要多通道和多模态数据提供互补信息以及关键局部细节至关重要的分割任务中的改进潜力。"}}
{"id": "2601.02314", "pdf": "https://arxiv.org/pdf/2601.02314", "abs": "https://arxiv.org/abs/2601.02314", "authors": ["Sourena Khanzadeh"], "title": "Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern. While \\textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \\textbf{faithful} generative drivers of the model's output or merely \\textbf{post-hoc rationalizations}. We introduce \\textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning. Unlike existing interpretability methods that rely on surface-level textual similarity, Project Ariadne performs \\textbf{hard interventions} ($do$-calculus) on intermediate reasoning nodes -- systematically inverting logic, negating premises, and reversing factual claims -- to measure the \\textbf{Causal Sensitivity} ($φ$) of the terminal answer. Our empirical evaluation of state-of-the-art models reveals a persistent \\textit{Faithfulness Gap}. We define and detect a widespread failure mode termed \\textbf{Causal Decoupling}, where agents exhibit a violation density ($ρ$) of up to $0.77$ in factual and scientific domains. In these instances, agents arrive at identical conclusions despite contradictory internal logic, proving that their reasoning traces function as \"Reasoning Theater\" while decision-making is governed by latent parametric priors. Our findings suggest that current agentic architectures are inherently prone to unfaithful explanation, and we propose the Ariadne Score as a new benchmark for aligning stated logic with model action.", "AI": {"tldr": "该项目介绍了Ariadne，一个用于评估大型语言模型代理决策过程中解释忠实性的新XAI框架。", "motivation": "随着大型语言模型被赋予越来越多的自主决策任务，其推理过程的透明度成为了安全的关键问题。虽然Chain-of-Thought提示可以让模型生成人类可读的推理轨迹，但这些轨迹是否是真正的驱动因素还是事后合理化仍然是未知数。", "method": "Ariadne框架利用结构因果模型和反事实逻辑来审计代理决策中推理的因果完整性。通过在中间推理节点上执行硬干预（do-演算），系统地反转逻辑、否定前提、逆转事实声明，以测量最终答案的因果敏感性。", "result": "对最先进模型的实证评估显示存在持续存在的忠实度缺口，并定义并检测了一种广泛失败模式，称为因果脱钩，在这些实例中，代理在面对矛盾内部逻辑的情况下仍然得出相同的结论。", "conclusion": "当前代理架构容易出现不忠诚解释的问题。Ariadne框架被提出作为衡量模型行为与声明逻辑一致性的新基准。"}}
{"id": "2601.02311", "pdf": "https://arxiv.org/pdf/2601.02311", "abs": "https://arxiv.org/abs/2601.02311", "authors": ["Deep Pankajbhai Mehta"], "title": "Placement Semantics for Distributed Deep Learning: A Systematic Framework for Analyzing Parallelism Strategies", "categories": ["cs.DC", "cs.AI"], "comment": "8 pages, 3 tables", "summary": "Training large language models requires distributing computation across many accelerators, yet practitioners select parallelism strategies (data, tensor, pipeline, ZeRO) through trial and error because no unified systematic framework predicts their behavior. We introduce placement semantics: each strategy is specified by how it places four training states (parameters, optimizer, gradients, activations) across devices using five modes (replicated, sharded, sharded-with-gather, materialized, offloaded). From placement alone, without implementation details, we derive memory consumption and communication volume. Our predictions match published results exactly: ZeRO-3 uses 8x less memory than data parallelism at 1.5x communication cost, as reported in the original paper. We prove two conditions (gradient integrity, state consistency) are necessary and sufficient for distributed training to match single-device results, and provide composition rules for combining strategies safely. The framework unifies ZeRO Stages 1-3, Fully Sharded Data Parallel (FSDP), tensor parallelism, and pipeline parallelism as instances with different placement choices.", "AI": {"tldr": "本文提出了一个系统框架，通过放置语义来分析分布式深度学习中的并行策略，预测内存消耗和通信量。", "motivation": "在训练大型语言模型时，选择适当的并行策略需要大量的试验与错误。缺乏统一的评估标准使得这一过程复杂化。", "method": "该论文提出了一个框架，通过定义参数、优化器、梯度和激活状态之间的放置模式来描述各种并行策略，并根据这些模式推导出内存消耗和通信量。", "result": "预测结果准确匹配了原始研究中的数据。例如，ZeRO-3的内存使用仅为数据并行方式的八分之一，而通信成本为1.5倍。", "conclusion": "该框架能够系统地分析不同的并行策略，并提供了一个理论基础来理解它们在分布式训练中的表现和组合规则。"}}
{"id": "2601.02309", "pdf": "https://arxiv.org/pdf/2601.02309", "abs": "https://arxiv.org/abs/2601.02309", "authors": ["Xiaopeng Guo", "Yinzhe Xu", "Huajian Huang", "Sai-Kit Yeung"], "title": "360DVO: Deep Visual Odometry for Monocular 360-Degree Camera", "categories": ["cs.CV"], "comment": "12 pages. Received by RA-L", "summary": "Monocular omnidirectional visual odometry (OVO) systems leverage 360-degree cameras to overcome field-of-view limitations of perspective VO systems. However, existing methods, reliant on handcrafted features or photometric objectives, often lack robustness in challenging scenarios, such as aggressive motion and varying illumination. To address this, we present 360DVO, the first deep learning-based OVO framework. Our approach introduces a distortion-aware spherical feature extractor (DAS-Feat) that adaptively learns distortion-resistant features from 360-degree images. These sparse feature patches are then used to establish constraints for effective pose estimation within a novel omnidirectional differentiable bundle adjustment (ODBA) module. To facilitate evaluation in realistic settings, we also contribute a new real-world OVO benchmark. Extensive experiments on this benchmark and public synthetic datasets (TartanAir V2 and 360VO) demonstrate that 360DVO surpasses state-of-the-art baselines (including 360VO and OpenVSLAM), improving robustness by 50% and accuracy by 37.5%. Homepage: https://chris1004336379.github.io/360DVO-homepage", "AI": {"tldr": "本文提出了用于单目全景视觉测距的首个基于深度学习的方法，即360DVO。", "motivation": "现有的单目全景视觉测距方法在挑战性场景中（如剧烈运动和不同光照）表现不佳，因此开发一种新的、更加鲁棒的方法很有必要。", "method": "360DVO引入了一种球面特征提取器(DAS-Feat)，它可以自适应地从360度图像中学习到抗失真特征。这些稀疏的特征补丁用于建立有效的姿态估计约束，通过新的全景可微分捆绑调整模块(ODBA)实现。", "result": "在新提出的现实世界基准测试和公开合成数据集上进行的广泛实验表明，360DVO比最先进的基线方法（包括360VO和OpenVSLAM）提高了50%的鲁棒性和37.5%的准确性。", "conclusion": "通过引入新的深度学习框架以及改进的数据处理技术，可以显著提高单目全景视觉测距系统的性能。"}}
{"id": "2601.02299", "pdf": "https://arxiv.org/pdf/2601.02299", "abs": "https://arxiv.org/abs/2601.02299", "authors": ["Sara Inácio", "Hugo Proença", "João C. Neves"], "title": "SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting", "categories": ["cs.CV"], "comment": "9 pages", "summary": "The increasing production of waste, driven by population growth, has created challenges in managing and recycling materials effectively. Manual waste sorting is a common practice; however, it remains inefficient for handling large-scale waste streams and presents health risks for workers. On the other hand, existing automated sorting approaches still struggle with the high variability, clutter, and visual complexity of real-world waste streams. The lack of real-world datasets for waste sorting is a major reason automated systems for this problem are underdeveloped. Accordingly, we introduce SortWaste, a densely annotated object detection dataset collected from a Material Recovery Facility. Additionally, we contribute to standardizing waste detection in sorting lines by proposing ClutterScore, an objective metric that gauges the scene's hardness level using a set of proxies that affect visual complexity (e.g., object count, class and size entropy, and spatial overlap). In addition to these contributions, we provide an extensive benchmark of state-of-the-art object detection models, detailing their results with respect to the hardness level assessed by the proposed metric. Despite achieving promising results (mAP of 59.7% in the plastic-only detection task), performance significantly decreases in highly cluttered scenes. This highlights the need for novel and more challenging datasets on the topic.", "AI": {"tldr": "本文介绍了SortWaste数据集，该数据集用于工业废料分类中的物体检测，并提出了一种衡量场景复杂性的ClutterScore指标。", "motivation": "由于废物产量的增加导致垃圾分类和回收面临挑战，且现有自动化系统难以应对真实世界中废物流的高变异性、混乱程度以及视觉复杂性。因此，缺乏用于垃圾分拣的真实数据集是自动系统的开发不足的主要原因。", "method": "本文贡献了SortWaste数据集，并提出了一个衡量场景复杂性的ClutterScore指标。此外，还对当前最先进的物体检测模型进行了基准测试。", "result": "在塑料分类任务中取得了59.7%的mAP，但在高度混乱的场景下性能显著下降。", "conclusion": "该研究强调了需要新的更具挑战性的数据集以改进垃圾分类自动化系统的性能。"}}
{"id": "2601.02295", "pdf": "https://arxiv.org/pdf/2601.02295", "abs": "https://arxiv.org/abs/2601.02295", "authors": ["Chenyang Ma", "Guangyu Yang", "Kai Lu", "Shitong Xu", "Bill Byrne", "Niki Trigoni", "Andrew Markham"], "title": "CycleVLA: Proactive Self-Correcting Vision-Language-Action Models via Subtask Backtracking and Minimum Bayes Risk Decoding", "categories": ["cs.RO"], "comment": "Project Page: https://dannymcy.github.io/cyclevla/", "summary": "Current work on robot failure detection and correction typically operate in a post hoc manner, analyzing errors and applying corrections only after failures occur. This work introduces CycleVLA, a system that equips Vision-Language-Action models (VLAs) with proactive self-correction, the capability to anticipate incipient failures and recover before they fully manifest during execution. CycleVLA achieves this by integrating a progress-aware VLA that flags critical subtask transition points where failures most frequently occur, a VLM-based failure predictor and planner that triggers subtask backtracking upon predicted failure, and a test-time scaling strategy based on Minimum Bayes Risk (MBR) decoding to improve retry success after backtracking. Extensive experiments show that CycleVLA improves performance for both well-trained and under-trained VLAs, and that MBR serves as an effective zero-shot test-time scaling strategy for VLAs. Project Page: https://dannymcy.github.io/cyclevla/", "AI": {"tldr": "CycleVLA是一种具有前瞻自我纠正功能的视觉语言动作模型，通过在执行过程中预见可能失败并提前恢复以提升性能。", "motivation": "当前机器人错误检测和修正工作通常是在事后进行。CycleVLA旨在为视觉语言行动模型提供一种前瞻性的自我纠正能力，以便在故障完全出现之前就加以预防和修复。", "method": "CycleVLA通过集成进度感知的视觉语言动作模型来标记关键子任务转换点，在预测到可能失败时触发子任务回溯，并采用基于最小贝叶斯风险解码策略的测试时间缩放策略以提高重试成功率。", "result": "实验表明，CycleVLA能显著提升良好训练和欠训练的视觉语言动作模型的表现。此外，最小贝叶斯风险解码被证明是这些模型的有效零样本测试时调整策略。", "conclusion": "该研究提出了一种创新的方法来改进视觉语言行动系统的性能，通过提前预见并纠正潜在错误来提高任务成功率。"}}
{"id": "2601.02289", "pdf": "https://arxiv.org/pdf/2601.02289", "abs": "https://arxiv.org/abs/2601.02289", "authors": ["Tom Burgert", "Leonard Hackel", "Paolo Rota", "Begüm Demir"], "title": "Rank-based Geographical Regularization: Revisiting Contrastive Self-Supervised Learning for Multispectral Remote Sensing Imagery", "categories": ["cs.CV"], "comment": "accepted for publication at IEEE/CVF Winter Conference on Applications of Computer Vision", "summary": "Self-supervised learning (SSL) has become a powerful paradigm for learning from large, unlabeled datasets, particularly in computer vision (CV). However, applying SSL to multispectral remote sensing (RS) images presents unique challenges and opportunities due to the geographical and temporal variability of the data. In this paper, we introduce GeoRank, a novel regularization method for contrastive SSL that improves upon prior techniques by directly optimizing spherical distances to embed geographical relationships into the learned feature space. GeoRank outperforms or matches prior methods that integrate geographical metadata and consistently improves diverse contrastive SSL algorithms (e.g., BYOL, DINO). Beyond this, we present a systematic investigation of key adaptations of contrastive SSL for multispectral RS images, including the effectiveness of data augmentations, the impact of dataset cardinality and image size on performance, and the task dependency of temporal views. Code is available at https://github.com/tomburgert/georank.", "AI": {"tldr": "该论文提出了一种新的地理正则化方法GeoRank，用于对比自监督学习中多光谱遥感图像的处理。", "motivation": "自监督学习在计算机视觉领域表现出了强大的能力，但在多光谱遥感影像上的应用存在独特的挑战和机会。本文旨在通过引入一种基于等级排序的地理正则化方法GeoRank来优化对比自监督学习中的空间关系嵌入。", "method": "提出了一种新的地理正则化技术GeoRank，该技术直接优化球面距离以将地理关系嵌入到所学特征空间中。此外还探讨了关键适应性改变，包括数据增强的有效性、数据集大小和图像尺寸对性能的影响以及时间视图的任务依赖性。", "result": "实验表明，GeoRank方法在多种对比自监督学习算法下表现优秀或与现有最佳方法相当，并且能够一致地改善多样化的对比自监督学习方法的性能。", "conclusion": "通过引入地理正则化技术GeoRank和对多光谱遥感图像中适应性改变的系统研究，可以有效提高对比自监督学习模型在处理这种复杂数据上的表现。"}}
{"id": "2601.02285", "pdf": "https://arxiv.org/pdf/2601.02285", "abs": "https://arxiv.org/abs/2601.02285", "authors": ["Tobias Schimanski", "Imene Kolli", "Jingwei Ni", "Yu Fan", "Ario Saeid Vaghefi", "Elliott Ash", "Markus Leippold"], "title": "pdfQA: Diverse, Challenging, and Realistic Question Answering over PDFs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "PDFs are the second-most used document type on the internet (after HTML). Yet, existing QA datasets commonly start from text sources or only address specific domains. In this paper, we present pdfQA, a multi-domain 2K human-annotated (real-pdfQA) and 2K synthetic dataset (syn-pdfQA) differentiating QA pairs in ten complexity dimensions (e.g., file type, source modality, source position, answer type). We apply and evaluate quality and difficulty filters on both datasets, obtaining valid and challenging QA pairs. We answer the questions with open-source LLMs, revealing existing challenges that correlate with our complexity dimensions. pdfQA presents a basis for end-to-end QA pipeline evaluation, testing diverse skill sets and local optimizations (e.g., in information retrieval or parsing).", "AI": {"tldr": "本文提出了pdfQA，这是一个包含真人注释和合成数据集的多领域问题回答系统。", "motivation": "PDF文档在互联网上使用广泛，但现有的问答数据集通常仅限于特定域或文本源。因此，需要一个更具多样性和挑战性的问答数据集来评估整个问答流程。", "method": "pdfQA是通过收集和合成不同复杂度维度（如文件类型、来源模式等）的问题回答对创建的，并通过质量与难度筛选获得有效且具挑战性的问题答案对。", "result": "该系统展示了基于开放源代码LLM的回答结果，揭示了现有问答模型面对复杂问题时遇到的挑战。", "conclusion": "pdfQA提供了评估端到端问答流程的基础框架，有助于测试多样化的技能集和局部优化。"}}
{"id": "2601.02281", "pdf": "https://arxiv.org/pdf/2601.02281", "abs": "https://arxiv.org/abs/2601.02281", "authors": ["Shuai Yuan", "Yantai Yang", "Xiaotian Yang", "Xupeng Zhang", "Zhonghao Zhao", "Lingming Zhang", "Zhipeng Zhang"], "title": "InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams", "categories": ["cs.CV"], "comment": null, "summary": "The grand vision of enabling persistent, large-scale 3D visual geometry understanding is shackled by the irreconcilable demands of scalability and long-term stability. While offline models like VGGT achieve inspiring geometry capability, their batch-based nature renders them irrelevant for live systems. Streaming architectures, though the intended solution for live operation, have proven inadequate. Existing methods either fail to support truly infinite-horizon inputs or suffer from catastrophic drift over long sequences. We shatter this long-standing dilemma with InfiniteVGGT, a causal visual geometry transformer that operationalizes the concept of a rolling memory through a bounded yet adaptive and perpetually expressive KV cache. Capitalizing on this, we devise a training-free, attention-agnostic pruning strategy that intelligently discards obsolete information, effectively ``rolling'' the memory forward with each new frame. Fully compatible with FlashAttention, InfiniteVGGT finally alleviates the compromise, enabling infinite-horizon streaming while outperforming existing streaming methods in long-term stability. The ultimate test for such a system is its performance over a truly infinite horizon, a capability that has been impossible to rigorously validate due to the lack of extremely long-term, continuous benchmarks. To address this critical gap, we introduce the Long3D benchmark, which, for the first time, enables a rigorous evaluation of continuous 3D geometry estimation on sequences about 10,000 frames. This provides the definitive evaluation platform for future research in long-term 3D geometry understanding. Code is available at: https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT", "AI": {"tldr": "本文提出了一种名为InfiniteVGGT的因果视觉几何变换器，用于实现持久且大规模的3D视觉几何理解。", "motivation": "现有的离线模型虽然具备出色的几何处理能力，但其批处理特性使其不适合实时系统。而流式架构虽旨在解决实时操作的问题，却往往无法支持真正的无限时间输入或在长时间序列中保持稳定性。", "method": "InfiniteVGGT通过引入一个有限但自适应且持续表达的KV缓存来实现滚动记忆的概念，并设计了一种无需训练、注意力无关的修剪策略以智能地丢弃过时的信息，从而随着每一帧向前“滚动”内存。", "result": "在Long3D基准测试中，InfiniteVGGT表现出色，在无限时间范围内超过了现有的流式方法，并提供了一个严格的评估平台用于未来研究。", "conclusion": "InfiniteVGGT通过引入KV缓存和智能修剪策略实现了真正的无限时间序列处理能力，同时保持了长期稳定性。"}}
{"id": "2601.02273", "pdf": "https://arxiv.org/pdf/2601.02273", "abs": "https://arxiv.org/abs/2601.02273", "authors": ["Salim Khazem"], "title": "TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Foundation segmentation models such as the Segment Anything Model (SAM) exhibit strong zero-shot generalization through large-scale pretraining, but adapting them to domain-specific semantic segmentation remains challenging, particularly for thin structures (e.g., retinal vessels) and noisy modalities (e.g., SAR imagery). Full fine-tuning is computationally expensive and risks catastrophic forgetting. We propose \\textbf{TopoLoRA-SAM}, a topology-aware and parameter-efficient adaptation framework for binary semantic segmentation. TopoLoRA-SAM injects Low-Rank Adaptation (LoRA) into the frozen ViT encoder, augmented with a lightweight spatial convolutional adapter and optional topology-aware supervision via differentiable clDice. We evaluate our approach on five benchmarks spanning retinal vessel segmentation (DRIVE, STARE, CHASE\\_DB1), polyp segmentation (Kvasir-SEG), and SAR sea/land segmentation (SL-SSDD), comparing against U-Net, DeepLabV3+, SegFormer, and Mask2Former. TopoLoRA-SAM achieves the best retina-average Dice and the best overall average Dice across datasets, while training only \\textbf{5.2\\%} of model parameters ($\\sim$4.9M). On the challenging CHASE\\_DB1 dataset, our method substantially improves segmentation accuracy and robustness, demonstrating that topology-aware parameter-efficient adaptation can match or exceed fully fine-tuned specialist models. Code is available at : https://github.com/salimkhazem/Seglab.git", "AI": {"tldr": "提出了一种基于拓扑感知的参数高效适应框架TopoLoRA-SAM，用于基础分割模型在薄结构和跨域二值语义分割任务中的适应性增强。", "motivation": "为了克服基础分割模型如SAM在特定领域中进行语义分割时面临的挑战，特别是在处理细长结构（例如视网膜血管）和噪声模态（例如SAR影像）方面的问题，并且避免全量微调带来的计算开销及灾难性遗忘风险。", "method": "TopoLoRA-SAM通过向冻结的ViT编码器中注入低秩适应方法（LoRA），并添加轻量化空间卷积适配器以及可选的拓扑感知监督机制，实现了高效参数调整。该框架利用不同的可微分clDice度量进一步增强其对特定领域的适应性。", "result": "在包括视网膜血管分割、息肉分割和SAR海陆分割在内的多个基准测试数据集上进行了实验对比分析，证明TopoLoRA-SAM能够实现最佳平均Dice系数，并且仅需微调约5.2%的模型参数（~4.9M），展示了其在保持高效的同时具备卓越的泛化能力和稳健性。", "conclusion": "通过引入拓扑感知和参数高效的适应方法，TopoLoRA-SAM能够在多个领域中实现高精度且鲁棒性的语义分割任务，甚至超过了完全微调的专业模型。这表明该框架不仅适用于视网膜血管等薄结构的分割问题，还具有广泛的跨域应用潜力。"}}
{"id": "2601.02270", "pdf": "https://arxiv.org/pdf/2601.02270", "abs": "https://arxiv.org/abs/2601.02270", "authors": ["Gabriel Timothy", "Syeda Amna Rizvi", "Muhammad Umair", "Athman Bouguettaya", "Balsam Alkouz"], "title": "Modeling Inter-drone Interference as a Service in Skyway Networks", "categories": ["cs.ET"], "comment": null, "summary": "We present a novel investigation into the impact of inter-drone interference on delivery efficiencies within multi-drone skyway networks. We conduct controlled experiments to analyze the behavior of drones in an indoor testbed environment. Our study compares performance between solo flights and concurrent multi-drone operations along predefined routes. This analysis captures interference occurring during both flight and at charging stations, providing a comprehensive evaluation of its effects on overall network performance. We conduct a comprehensive series of experiments across diverse scenarios to systematically understand and model the dynamics of inter-drone interference. Key metrics, such as power consumption and delivery times, are considered. This generates a comprehensive dataset for in-depth analysis of interference at both the node and segment levels. These findings are then formalized into a predictive model. The results validate the effectiveness of the developed model, demonstrating its potential to accurately forecast inter-drone interferences.", "AI": {"tldr": "研究多无人机天空网络中无人机间干扰对效率的影响，建立预测模型。", "motivation": "探索并量化无人机间的相互干扰如何影响交付效率和整体网络性能。", "method": "在室内测试环境中进行控制实验，对比单飞与多机并发飞行的表现，收集相关数据，并基于此开发一个能够准确预测干扰的模型。", "result": "实验结果验证了所建立模型的有效性，表明该模型可以准确预测无人机间的相互干扰情况。", "conclusion": "通过深入研究和系统分析，成功建立了评估和预测无人机间干扰对网络性能影响的有效方法。"}}
{"id": "2601.02267", "pdf": "https://arxiv.org/pdf/2601.02267", "abs": "https://arxiv.org/abs/2601.02267", "authors": ["Renke Wang", "Zhenyu Zhang", "Ying Tai", "Jian Yang"], "title": "DiffProxy: Multi-View Human Mesh Recovery via Diffusion-Generated Dense Proxies", "categories": ["cs.CV"], "comment": "Page: https://wrk226.github.io/DiffProxy.html, Code: https://github.com/wrk226/DiffProxy", "summary": "Human mesh recovery from multi-view images faces a fundamental challenge: real-world datasets contain imperfect ground-truth annotations that bias the models' training, while synthetic data with precise supervision suffers from domain gap. In this paper, we propose DiffProxy, a novel framework that generates multi-view consistent human proxies for mesh recovery. Central to DiffProxy is leveraging the diffusion-based generative priors to bridge the synthetic training and real-world generalization. Its key innovations include: (1) a multi-conditional mechanism for generating multi-view consistent, pixel-aligned human proxies; (2) a hand refinement module that incorporates flexible visual prompts to enhance local details; and (3) an uncertainty-aware test-time scaling method that increases robustness to challenging cases during optimization. These designs ensure that the mesh recovery process effectively benefits from the precise synthetic ground truth and generative advantages of the diffusion-based pipeline. Trained entirely on synthetic data, DiffProxy achieves state-of-the-art performance across five real-world benchmarks, demonstrating strong zero-shot generalization particularly on challenging scenarios with occlusions and partial views. Project page: https://wrk226.github.io/DiffProxy.html", "AI": {"tldr": "本文提出了一种称为DiffProxy的框架，用于通过扩散生成密集代理来从多视图图像中恢复人体网格。", "motivation": "真实数据集中的地面实况注释不完善，而合成数据由于领域差距无法直接应用于现实场景。本文旨在解决这一问题，提供一种能够利用精确的合成地面实况和强大的生成能力的方法。", "method": "DiffProxy包括一个多条件机制来生成多视图一致、像素对齐的人体代理；一个手部细化模块以增强局部细节；以及一个不确定性感知测试时间缩放方法来提高优化过程中的鲁棒性。", "result": "训练仅基于合成数据的DiffProxy在五个真实世界的基准上实现了最先进的性能，特别是在具有遮挡和部分视图等挑战场景中表现出强大的零样本泛化能力。", "conclusion": "本文提出的DiffProxy框架有效地解决了从多视角图像恢复人体网格时遇到的真实与合成数据集之间的差距问题。"}}
{"id": "2601.02257", "pdf": "https://arxiv.org/pdf/2601.02257", "abs": "https://arxiv.org/abs/2601.02257", "authors": ["Joel Daniel Andersson", "Palak Jain", "Satchit Sivakumar"], "title": "Improved Accuracy for Private Continual Cardinality Estimation in Fully Dynamic Streams via Matrix Factorization", "categories": ["cs.CR", "cs.DS", "cs.LG"], "comment": null, "summary": "We study differentially-private statistics in the fully dynamic continual observation model, where many updates can arrive at each time step and updates to a stream can involve both insertions and deletions of an item. Earlier work (e.g., Jain et al., NeurIPS 2023 for counting distinct elements; Raskhodnikova & Steiner, PODS 2025 for triangle counting with edge updates) reduced the respective cardinality estimation problem to continual counting on the difference stream associated with the true function values on the input stream. In such reductions, a change in the original stream can cause many changes in the difference stream, this poses a challenge for applying private continual counting algorithms to obtain optimal error bounds. We improve the accuracy of several such reductions by studying the associated $\\ell_p$-sensitivity vectors of the resulting difference streams and isolating their properties. We demonstrate that our framework gives improved bounds for counting distinct elements, estimating degree histograms, and estimating triangle counts (under a slightly relaxed privacy model), thus offering a general approach to private continual cardinality estimation in streaming settings. Our improved accuracy stems from tight analysis of known factorization mechanisms for the counting matrix in this setting; the key technical challenge is arguing that one can use state-of-the-art factorizations for sensitivity vector sets with the properties we isolate. Empirically and analytically, we demonstrate that our improved error bounds offer a substantial improvement in accuracy for cardinality estimation problems over a large range of parameters.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02256", "pdf": "https://arxiv.org/pdf/2601.02256", "abs": "https://arxiv.org/abs/2601.02256", "authors": ["Shikun Sun", "Liao Qu", "Huichao Zhang", "Yiheng Liu", "Yangyang Song", "Xian Li", "Xu Wang", "Yi Jiang", "Daniel K. Du", "Xinglong Wu", "Jia Jia"], "title": "VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation", "categories": ["cs.CV", "cs.LG"], "comment": "Project page: https://github.com/ByteVisionLab/NextFlow", "summary": "Visual generation is dominated by three paradigms: AutoRegressive (AR), diffusion, and Visual AutoRegressive (VAR) models. Unlike AR and diffusion, VARs operate on heterogeneous input structures across their generation steps, which creates severe asynchronous policy conflicts. This issue becomes particularly acute in reinforcement learning (RL) scenarios, leading to unstable training and suboptimal alignment. To resolve this, we propose a novel framework to enhance Group Relative Policy Optimization (GRPO) by explicitly managing these conflicts. Our method integrates three synergistic components: 1) a stabilizing intermediate reward to guide early-stage generation; 2) a dynamic time-step reweighting scheme for precise credit assignment; and 3) a novel mask propagation algorithm, derived from principles of Reward Feedback Learning (ReFL), designed to isolate optimization effects both spatially and temporally. Our approach demonstrates significant improvements in sample quality and objective alignment over the vanilla GRPO baseline, enabling robust and effective optimization for VAR models.", "AI": {"tldr": "该论文提出了一种新的框架，用于解决视觉自回归生成模型中的异步策略冲突问题。", "motivation": "视觉生成领域中，传统的AR和扩散方法面临的问题与VAR不同。VAR在生成过程中输入结构的异质性导致了严重的异步策略冲突，在强化学习场景下尤其严重，这会导致训练不稳定和目标对齐不佳。", "method": "提出了一个增强Group Relative Policy Optimization (GRPO)的方法，包括三个关键组成部分：早期阶段生成引导的稳定中间奖励、精确信用分配的时间步骤动态重新加权方案以及基于Reward Feedback Learning (ReFL)原理的空间和时间优化效果隔离的新掩码传播算法。", "result": "新方法在样本质量和目标对齐方面相较于原始GRPO基线有了显著提升，证明了其在VAR模型中的稳健性和有效性。", "conclusion": "通过解决VAR生成过程中的异步策略冲突问题，该论文提出的方法实现了更加稳定和有效的优化。"}}
{"id": "2601.02253", "pdf": "https://arxiv.org/pdf/2601.02253", "abs": "https://arxiv.org/abs/2601.02253", "authors": ["Emrah Mete", "Emin Erkan Korkmaz"], "title": "Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission", "categories": ["cs.LG", "cs.AR", "cs.CV"], "comment": "9 pages, 4 figures", "summary": "The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.", "AI": {"tldr": "提出了一个基于生物信号传输机制的新型乘法运算免架构Neuro-Channel Networks (NCN)，以提高AI部署效率。", "motivation": "深度学习依赖高性能硬件，特别是GPU，这些设备成本高昂、耗能大且供应紧张，阻碍了人工智能在边缘设备上的广泛应用。标准人工感知器对矩阵乘法的高度依赖是这种低效的关键原因。而生物神经系统则通过物理离子通道限制和化学神经递质水平来调节信号传输。", "method": "受生物机制启发，提出了NCN架构，在该模型中，权重被替换为通道宽度以物理上限制信号幅度，一个次级参数作为神经递质根据符号逻辑调节信号传递。前向传播仅依赖加减和位运算（最小、符号），完全消除了浮点数乘法。", "result": "在概念验证研究中证明NCNs可以解决如XOR和多数函数这类非线性可分问题，准确率为100%，这表明它们能够在没有乘法权重的情况下形成复杂的决策边界。", "conclusion": "该架构为下一代神经形态硬件提供了一个高效的替代方案，使得可以在普通CPU或超低功耗芯片上运行复杂模型而不依赖昂贵的GPU集群。"}}
{"id": "2601.02249", "pdf": "https://arxiv.org/pdf/2601.02249", "abs": "https://arxiv.org/abs/2601.02249", "authors": ["Xiantai Xiang", "Guangyao Zhou", "Zixiao Wen", "Wenshuai Li", "Ben Niu", "Feng Wang", "Lijia Huang", "Qiantong Wang", "Yuhan Liu", "Zongxu Pan", "Yuxin Hu"], "title": "SLGNet: Synergizing Structural Priors and Language-Guided Modulation for Multimodal Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal object detection leveraging RGB and Infrared (IR) images is pivotal for robust perception in all-weather scenarios. While recent adapter-based approaches efficiently transfer RGB-pretrained foundation models to this task, they often prioritize model efficiency at the expense of cross-modal structural consistency. Consequently, critical structural cues are frequently lost when significant domain gaps arise, such as in high-contrast or nighttime environments. Moreover, conventional static multimodal fusion mechanisms typically lack environmental awareness, resulting in suboptimal adaptation and constrained detection performance under complex, dynamic scene variations. To address these limitations, we propose SLGNet, a parameter-efficient framework that synergizes hierarchical structural priors and language-guided modulation within a frozen Vision Transformer (ViT)-based foundation model. Specifically, we design a Structure-Aware Adapter to extract hierarchical structural representations from both modalities and dynamically inject them into the ViT to compensate for structural degradation inherent in ViT-based backbones. Furthermore, we propose a Language-Guided Modulation module that exploits VLM-driven structured captions to dynamically recalibrate visual features, thereby endowing the model with robust environmental awareness. Extensive experiments on the LLVIP, FLIR, KAIST, and DroneVehicle datasets demonstrate that SLGNet establishes new state-of-the-art performance. Notably, on the LLVIP benchmark, our method achieves an mAP of 66.1, while reducing trainable parameters by approximately 87% compared to traditional full fine-tuning. This confirms SLGNet as a robust and efficient solution for multimodal perception.", "AI": {"tldr": "SLGNet是一种利用RGB和红外图像进行多模态目标检测的参数高效框架，通过融合结构先验和语言引导调制来提高模型在复杂环境下的鲁棒性。", "motivation": "现有方法在多模态数据融合时往往忽视了跨模态一致性以及环境感知能力，在复杂场景下性能受限。为此提出了SLGNet以解决这些问题。", "method": "SLGNet基于冻结的Vision Transformer框架，设计了结构感知适配器提取结构信息并注入ViT模型中；同时引入语言引导调制模块利用VLM生成的描述文本动态调整视觉特征。", "result": "实验表明，在LLVIP等数据集上，SLGNet取得了新的最佳性能，并在减少大约87%可训练参数的情况下实现了66.1的mAP。", "conclusion": "SLGNet通过结合结构先验和语言引导调制机制，提高了多模态目标检测模型的鲁棒性和效率。"}}
{"id": "2601.02246", "pdf": "https://arxiv.org/pdf/2601.02246", "abs": "https://arxiv.org/abs/2601.02246", "authors": ["Annoor Sharara Akhand"], "title": "A Comparative Study of Custom CNNs, Pre-trained Models, and Transfer Learning Across Multiple Visual Datasets", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Convolutional Neural Networks (CNNs) are a standard approach for visual recognition due to their capacity to learn hierarchical representations from raw pixels. In practice, practitioners often choose among (i) training a compact custom CNN from scratch, (ii) using a large pre-trained CNN as a fixed feature extractor, and (iii) performing transfer learning via partial or full fine-tuning of a pre-trained backbone. This report presents a controlled comparison of these three paradigms across five real-world image classification datasets spanning road-surface defect recognition, agricultural variety identification, fruit/leaf disease recognition, pedestrian walkway encroachment recognition, and unauthorized vehicle recognition. Models are evaluated using accuracy and macro F1-score, complemented by efficiency metrics including training time per epoch and parameter counts. The results show that transfer learning consistently yields the strongest predictive performance, while the custom CNN provides an attractive efficiency--accuracy trade-off, especially when compute and memory budgets are constrained.", "AI": {"tldr": "比较研究了自定义CNN、预训练模型和迁移学习在多个视觉数据集上的表现。", "motivation": "卷积神经网络（CNN）因其能够从原始像素中提取层次表示而成为视觉识别的标准方法。实践中，通常选择三种方式：从头开始训练紧凑的自定义CNN、使用大型预训练CNN作为固定的特征提取器以及通过部分或全部微调预训练骨干执行迁移学习。", "method": "在五个真实世界图像分类数据集上进行对比研究，包括道路缺陷识别等。模型评估指标包括准确率和宏F1分数，并补充了效率度量如每轮训练时间和参数计数。", "result": "结果显示迁移学习始终提供最强的预测性能，而自定义CNN则在计算和内存预算有限时提供有吸引力的效率-准确性权衡。", "conclusion": "结论表明，在多个视觉数据集上，迁移学习能够提供最佳性能；同时，当资源受限时，自定义CNN是一个有效的选择。"}}
{"id": "2601.02242", "pdf": "https://arxiv.org/pdf/2601.02242", "abs": "https://arxiv.org/abs/2601.02242", "authors": ["Grigorii Alekseenko", "Aleksandr Gordeev", "Irina Tolstykh", "Bulat Suleimanov", "Vladimir Dokholyan", "Georgii Fedorov", "Sergey Yakubson", "Aleksandra Tsybina", "Mikhail Chernyshov", "Maksim Kuprashevich"], "title": "VIBE: Visual Instruction Based Editor", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Instruction-based image editing is among the fastest developing areas in generative AI. Over the past year, the field has reached a new level, with dozens of open-source models released alongside highly capable commercial systems. However, only a limited number of open-source approaches currently achieve real-world quality. In addition, diffusion backbones, the dominant choice for these pipelines, are often large and computationally expensive for many deployments and research settings, with widely used variants typically containing 6B to 20B parameters. This paper presents a compact, high-throughput instruction-based image editing pipeline that uses a modern 2B-parameter Qwen3-VL model to guide the editing process and the 1.6B-parameter diffusion model Sana1.5 for image generation. Our design decisions across architecture, data processing, training configuration, and evaluation target low-cost inference and strict source consistency while maintaining high quality across the major edit categories feasible at this scale. Evaluated on the ImgEdit and GEdit benchmarks, the proposed method matches or exceeds the performance of substantially heavier baselines, including models with several times as many parameters and higher inference cost, and is particularly strong on edits that require preserving the input image, such as an attribute adjustment, object removal, background edits, and targeted replacement. The model fits within 24 GB of GPU memory and generates edited images at up to 2K resolution in approximately 4 seconds on an NVIDIA H100 in BF16, without additional inference optimizations or distillation.", "AI": {"tldr": "本文提出了一种基于视觉指令的紧凑型图像编辑管道VIBE，利用现代模型进行高效的高质量图像生成。", "motivation": "当前多数开源方法难以达到实际应用的质量标准，同时主流扩散模型参数庞大且计算成本高。因此，文章旨在提供一种低成本、高性能的解决方案。", "method": "采用2B参数Qwen3-VL模型指导编辑过程，并使用1.6B参数扩散模型Sana1.5生成图像，在架构设计、数据处理、训练配置及评估方面注重低延迟推理和源一致性。", "result": "在ImgEdit和GEdit基准测试中，所提方法与具有更多参数的基线相比表现相当甚至更优，尤其擅长保持输入图像属性的同时进行编辑任务。", "conclusion": "VIBE模型能够在较低计算成本下提供高质量的图像生成能力，并且适用于多种高分辨率场景。"}}
{"id": "2601.02233", "pdf": "https://arxiv.org/pdf/2601.02233", "abs": "https://arxiv.org/abs/2601.02233", "authors": ["Leon Müller", "Adelina Bärligea", "Alexander Knapp", "Jakob S. Kottmann"], "title": "PauliEngine: High-Performant Symbolic Arithmetic for Quantum Operations", "categories": ["quant-ph", "cs.ET", "cs.SE", "physics.comp-ph"], "comment": ":D.0; E.1", "summary": "Quantum computation is inherently hybrid, and fast classical manipulation of qubit operators is necessary to ensure scalability in quantum software. We introduce PauliEngine, a high-performance C++ framework that provides efficient primitives for Pauli string multiplication, commutators, symbolic phase tracking, and structural transformations. Built on a binary symplectic representation and optimized bit-wise operations, PauliEngine supports both numerical and symbolic coefficients and is accessible through a Python interface. Runtime benchmarks demonstrate substantial speedups over state-of-the-art implementations. PauliEngine provides a scalable backend for operator-based quantum software tools and simulations.", "AI": {"tldr": "PauliEngine是一款高效的C++框架，用于量子运算中的符号算术操作。", "motivation": "为了提高量子软件的可扩展性，需要快速的经典方法来处理量子比特运算符。现有的实现效率低下，无法满足需求。", "method": "通过二元辛表示法和优化位操作，PauliEngine提供高效的基础运算工具，并支持数值和符号系数。框架还提供了Python接口。", "result": "运行时基准测试表明，与现有最佳实施相比，PauliEngine实现了显著的速度提升。", "conclusion": "PauliEngine为基于算子的量子软件工具和模拟提供了一个可扩展后端，提高了运算效率和性能。"}}
{"id": "2601.02228", "pdf": "https://arxiv.org/pdf/2601.02228", "abs": "https://arxiv.org/abs/2601.02228", "authors": ["Duoxun Tang", "Xueyi Zhang", "Chak Hin Wang", "Xi Xiao", "Dasen Dai", "Xinhang Jiang", "Wentao Shi", "Rui Li", "Qing Li"], "title": "FMVP: Masked Flow Matching for Adversarial Video Purification", "categories": ["cs.CV"], "comment": null, "summary": "Video recognition models remain vulnerable to adversarial attacks, while existing diffusion-based purification methods suffer from inefficient sampling and curved trajectories. Directly regressing clean videos from adversarial inputs often fails to recover faithful content due to the subtle nature of perturbations; this necessitates physically shattering the adversarial structure. Therefore, we propose Flow Matching for Adversarial Video Purification FMVP. FMVP physically shatters global adversarial structures via a masking strategy and reconstructs clean video dynamics using Conditional Flow Matching (CFM) with an inpainting objective. To further decouple semantic content from adversarial noise, we design a Frequency-Gated Loss (FGL) that explicitly suppresses high-frequency adversarial residuals while preserving low-frequency fidelity. We design Attack-Aware and Generalist training paradigms to handle known and unknown threats, respectively. Extensive experiments on UCF-101 and HMDB-51 demonstrate that FMVP outperforms state-of-the-art methods (DiffPure, Defense Patterns (DP), Temporal Shuffling (TS) and FlowPure), achieving robust accuracy exceeding 87% against PGD and 89% against CW attacks. Furthermore, FMVP demonstrates superior robustness against adaptive attacks (DiffHammer) and functions as a zero-shot adversarial detector, attaining detection accuracies of 98% for PGD and 79% for highly imperceptible CW attacks.", "AI": {"tldr": "提出了一种新的视频净化方法FMVP，用于对抗性攻击的防御和检测。", "motivation": "现有的基于扩散的方法在对抗性视频净化中存在采样效率低下和轨迹弯曲的问题。直接从扰动输入恢复原始内容往往难以实现。", "method": "通过掩码策略破坏全局对抗结构，并使用条件流动匹配（CFM）与去噪目标重建清洁的视频动态，引入频率门控损失以抑制高频扰动同时保持低频信号的真实性。", "result": "在UCF-101和HMDB-51数据集上的实验表明，FMVP在对抗性攻击下表现出色，优于其他方法，并具有零样本对抗检测能力。", "conclusion": "FMVP不仅提高了视频识别模型的鲁棒性，还在对抗性检测方面展示了优越性能。"}}
{"id": "2601.02215", "pdf": "https://arxiv.org/pdf/2601.02215", "abs": "https://arxiv.org/abs/2601.02215", "authors": ["Nenad Petrovic", "Vahid Zolfaghari", "Fengjunjie Pan", "Alois Knoll"], "title": "LLM-Empowered Functional Safety and Security by Design in Automotive Systems", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "This paper presents LLM-empowered workflow to support Software Defined Vehicle (SDV) software development, covering the aspects of security-aware system topology design, as well as event-driven decision-making code analysis. For code analysis we adopt event chains model which provides formal foundations to systematic validation of functional safety, taking into account the semantic validity of messages exchanged between key components, including both CAN and Vehicle Signal Specification (VSS). Analysis of security aspects for topology relies on synergy with Model-Driven Engineering (MDE) approach and Object Constraint Language (OCL) rules. Both locally deployable and proprietary solution are taken into account for evaluation within Advanced Driver-Assistance Systems (ADAS)-related scenarios.", "AI": {"tldr": "该论文提出了一种利用大语言模型支持软件定义汽车（SDV）软件开发的工作流程，涵盖了安全意识系统拓扑设计和基于事件的决策代码分析。", "motivation": "为了提高软件定义汽车系统的功能安全性和安全性，本文提出了一个由大语言模型驱动的方法来优化软件开发过程，特别是针对高级驾驶辅助系统相关场景中的系统安全和架构设计。", "method": "该方法结合了事件链模型进行代码分析，并利用建模驱动工程（MDE）和对象约束语言（OCL）规则对拓扑的安全性进行了评估。它同时考虑了本地部署解决方案和专有解决方案的实用性。", "result": "通过这种方法，论文展示了如何在SDV软件开发中实现安全意识系统设计及代码分析，并提高了对于消息交换语义有效性的验证能力。", "conclusion": "研究得出结论，使用大语言模型可以有效地支持SDV的安全性和功能性评估，为未来的汽车软件工程提供了新的方向和工具。"}}
{"id": "2601.02214", "pdf": "https://arxiv.org/pdf/2601.02214", "abs": "https://arxiv.org/abs/2601.02214", "authors": ["Manuela Chessa", "Michela Chessa", "Lorenzo Gerini", "Matteo Martini", "Kaloyana Naneva", "Fabio Solari"], "title": "Cooperation in Virtual Reality: Exploring Environmental Decision-Making through a Real-Effort Threshold Public Goods Game", "categories": ["cs.HC"], "comment": null, "summary": "Digital platforms increasingly support collective action initiatives, yet coordinating geographically dispersed users through digital interfaces remains challenging, particularly in threshold settings where success requires critical mass participation. This study investigates how avatar-based social representation in Virtual Reality (VR) influences coordination in threshold collective action problems. Through a randomized controlled experiment with 188 participants organized in 94 pairs, we examine whether brief avatar exposure affects perceived co-presence and coordination outcomes in a two-player threshold public goods game implemented as a real-effort recycling task. We manipulate a single design feature: participants either briefly interact through avatars before the main task (Pre-Task Avatar treatment) or complete an equivalent activity individually without peer visibility (No Pre-Task Avatar treatment). Our findings reveal that minimal avatar exposure significantly increases perceived co-presence and improves strategic coordination, though not through increased contribution quantity. Participants exposed to peer avatars achieve higher social welfare by coordinating to avoid wasteful over-contribution beyond the threshold. Additionally, we identify VR presence-the sense of 'being there' in the virtual environment-as a stronger predictor of task performance than co-presence itself. This research contributes to Information Systems theory by establishing causal pathways from specific design features to presence to coordination outcomes, demonstrates VR as a rigorous experimental methodology for IS research, and provides actionable insights for designing collaborative platforms supporting sustainability initiatives and threshold collective action problems.", "AI": {"tldr": "研究探讨虚拟现实中通过化身曝光对阈值公共物品游戏中协调的影响。", "motivation": "数字平台支持集体行动，但地理分散的用户在阈值设定下难以协作。本研究考察虚拟现实中的化身曝光如何影响这种协调问题。", "method": "采用随机对照实验，188名参与者组成94对，在阈值公共物品游戏中通过化身互动前后的对比试验。", "result": "短暂化身接触显著增加感知共存和战略协调；VR存在感比共存更能预测任务表现。", "conclusion": "该研究确立了特定设计特征到存在感再到协调结果的因果路径，证明虚拟现实作为信息系统的实验方法的有效性，并为支持可持续性和阈值集体行动问题的设计提供可操作见解。"}}
{"id": "2601.02212", "pdf": "https://arxiv.org/pdf/2601.02212", "abs": "https://arxiv.org/abs/2601.02212", "authors": ["Jingjing Wang", "Zhuo Xiao", "Xinning Yao", "Bo Liu", "Lijuan Niu", "Xiangzhi Bai", "Fugen Zhou"], "title": "Prior-Guided DETR for Ultrasound Nodule Detection", "categories": ["cs.CV"], "comment": null, "summary": "Accurate detection of ultrasound nodules is essential for the early diagnosis and treatment of thyroid and breast cancers. However, this task remains challenging due to irregular nodule shapes, indistinct boundaries, substantial scale variations, and the presence of speckle noise that degrades structural visibility. To address these challenges, we propose a prior-guided DETR framework specifically designed for ultrasound nodule detection. Instead of relying on purely data-driven feature learning, the proposed framework progressively incorporates different prior knowledge at multiple stages of the network. First, a Spatially-adaptive Deformable FFN with Prior Regularization (SDFPR) is embedded into the CNN backbone to inject geometric priors into deformable sampling, stabilizing feature extraction for irregular and blurred nodules. Second, a Multi-scale Spatial-Frequency Feature Mixer (MSFFM) is designed to extract multi-scale structural priors, where spatial-domain processing emphasizes contour continuity and boundary cues, while frequency-domain modeling captures global morphology and suppresses speckle noise. Furthermore, a Dense Feature Interaction (DFI) mechanism propagates and exploits these prior-modulated features across all encoder layers, enabling the decoder to enhance query refinement under consistent geometric and structural guidance. Experiments conducted on two clinically collected thyroid ultrasound datasets (Thyroid I and Thyroid II) and two public benchmarks (TN3K and BUSI) for thyroid and breast nodules demonstrate that the proposed method achieves superior accuracy compared with 18 detection methods, particularly in detecting morphologically complex nodules.The source code is publicly available at https://github.com/wjj1wjj/Ultrasound-DETR.", "AI": {"tldr": "提出了一种基于先验知识引导的DETR框架，用于超声结节检测。", "motivation": "准确检测超声结节对于早期诊断和治疗甲状腺癌和乳腺癌至关重要。然而，由于不规则形状、模糊边界、尺度变化大以及斑点噪声影响结构可见性等问题，该任务仍具挑战性。", "method": "引入了空间自适应可变形FFN与先验正则化（SDFPR）以注入几何先验信息，并设计多尺度空间频率特征混合器（MSFFM）来提取多尺度结构先验。此外，密集特征交互机制（DFI）传播这些经过调制的特征，使解码器在一致的几何和结构引导下增强查询细化。", "result": "实验结果显示该方法优于18种检测算法，在形态复杂的结节检测中尤其有效。", "conclusion": "所提方法通过引入先验知识指导显著提高了超声结节检测的准确性，特别是在处理复杂形态学特征时表现突出。"}}
{"id": "2601.02211", "pdf": "https://arxiv.org/pdf/2601.02211", "abs": "https://arxiv.org/abs/2601.02211", "authors": ["Binglei Li", "Mengping Yang", "Zhiyu Tan", "Junping Zhang", "Hao Li"], "title": "Unraveling MMDiT Blocks: Training-free Analysis and Enhancement of Text-conditioned Diffusion", "categories": ["cs.CV"], "comment": "11 pages", "summary": "Recent breakthroughs of transformer-based diffusion models, particularly with Multimodal Diffusion Transformers (MMDiT) driven models like FLUX and Qwen Image, have facilitated thrilling experiences in text-to-image generation and editing. To understand the internal mechanism of MMDiT-based models, existing methods tried to analyze the effect of specific components like positional encoding and attention layers. Yet, a comprehensive understanding of how different blocks and their interactions with textual conditions contribute to the synthesis process remains elusive. In this paper, we first develop a systematic pipeline to comprehensively investigate each block's functionality by removing, disabling and enhancing textual hidden-states at corresponding blocks. Our analysis reveals that 1) semantic information appears in earlier blocks and finer details are rendered in later blocks, 2) removing specific blocks is usually less disruptive than disabling text conditions, and 3) enhancing textual conditions in selective blocks improves semantic attributes. Building on these observations, we further propose novel training-free strategies for improved text alignment, precise editing, and acceleration. Extensive experiments demonstrated that our method outperforms various baselines and remains flexible across text-to-image generation, image editing, and inference acceleration. Our method improves T2I-Combench++ from 56.92% to 63.00% and GenEval from 66.42% to 71.63% on SD3.5, without sacrificing synthesis quality. These results advance understanding of MMDiT models and provide valuable insights to unlock new possibilities for further improvements.", "AI": {"tldr": "研究开发了一种系统性流程，通过移除、禁用和增强特定块的文本隐状态来分析MMDiT模型内部机制，并提出无需训练的新策略以改善文本对齐、精确编辑及加速。", "motivation": "当前关于基于转换器的扩散模型（如FLUX和Qwen Image）的研究主要集中在分析特定组件的影响，但缺乏系统地理解不同块及其与文本条件交互作用的方法。作者旨在通过更全面的方式揭示MMDiT模型内部机制，并探索改进策略。", "method": "该研究首先设计了一套系统性流程来移除、禁用和增强文本隐藏状态，从而分析每个块的功能。基于此，提出了无需训练的新方法以优化文本对齐、编辑精确度以及加速推理过程。", "result": "实验结果显示，所提方法在T2I-Combench++和GenEval基准测试中分别从56.92%提升至63.00%，从66.42%提升至71.63%，且未牺牲生成质量。此外，在文本到图像生成、图像编辑及推理加速方面均优于现有基线。", "conclusion": "该研究通过详细分析揭示了MMDiT模型内部机制，提出了有效的改进策略，并展示了其优越性能。这些发现为理解MMDiT模型提供了新见解并开启了未来优化的可能性。"}}
{"id": "2601.02210", "pdf": "https://arxiv.org/pdf/2601.02210", "abs": "https://arxiv.org/abs/2601.02210", "authors": ["Vejaykarthy Srithar", "Syeda Amna Rizvi", "Amani Abusafia", "Athman Bouguettaya", "Balsam Alkouz"], "title": "Impact of Spatial Proximity on Drone Services", "categories": ["cs.ET"], "comment": null, "summary": "We demonstrate the peer-to-peer impact of drones flying in close proximity. Understanding these impacts is crucial for planning efficient drone delivery services. In this regard, we conducted a set of experiments using drones at varying positions in a 3D space under different wind conditions. We collected data on drone energy consumption traveling in a skyway segment. We developed a Graphical User Interface (GUI) that plots drone trajectories within a segment. The GUI facilitates analyzing the peer-to-peer influence of drones on their energy consumption. The analysis includes drones' positions, distance of separation, and wind impact.", "AI": {"tldr": "研究无人机在三维空间中不同位置及风力条件下的能量消耗影响", "motivation": "探讨无人机近距离飞行对服务效率的影响，以优化无人机配送规划", "method": "通过实验模拟多个无人机在3D空间中的飞行路径，并记录它们的能量消耗。开发了图形用户界面来展示并分析这些数据。", "result": "收集到了有关无人机位置、间隔距离以及风力条件下能量消耗的数据。", "conclusion": "该研究揭示了无人机之间相互影响的模式，为规划高效的无人机服务提供了依据"}}
{"id": "2601.02209", "pdf": "https://arxiv.org/pdf/2601.02209", "abs": "https://arxiv.org/abs/2601.02209", "authors": ["Omer Nacar", "Serry Sibaee", "Adel Ammar", "Yasser Alhabashi", "Nadia Samer Sibai", "Yara Farouk Ahmed", "Ahmed Saud Alqusaiyer", "Sulieman Mahmoud AlMahmoud", "Abdulrhman Mamdoh Mukhaniq", "Lubaba Raed", "Sulaiman Mohammed Alatwah", "Waad Nasser Alqahtani", "Yousif Abdulmajeed Alnasser", "Mohamed Aziz Khadraoui", "Wadii Boulila"], "title": "ARCADE: A City-Scale Corpus for Fine-Grained Arabic Dialect Tagging", "categories": ["cs.CL", "cs.CY", "cs.SD"], "comment": null, "summary": "The Arabic language is characterized by a rich tapestry of regional dialects that differ substantially in phonetics and lexicon, reflecting the geographic and cultural diversity of its speakers. Despite the availability of many multi-dialect datasets, mapping speech to fine-grained dialect sources, such as cities, remains underexplored. We present ARCADE (Arabic Radio Corpus for Audio Dialect Evaluation), the first Arabic speech dataset designed explicitly with city-level dialect granularity. The corpus comprises Arabic radio speech collected from streaming services across the Arab world. Our data pipeline captures 30-second segments from verified radio streams, encompassing both Modern Standard Arabic (MSA) and diverse dialectal speech. To ensure reliability, each clip was annotated by one to three native Arabic reviewers who assigned rich metadata, including emotion, speech type, dialect category, and a validity flag for dialect identification tasks. The resulting corpus comprises 6,907 annotations and 3,790 unique audio segments spanning 58 cities across 19 countries. These fine-grained annotations enable robust multi-task learning, serving as a benchmark for city-level dialect tagging. We detail the data collection methodology, assess audio quality, and provide a comprehensive analysis of label distributions. The dataset is available on: https://huggingface.co/datasets/riotu-lab/ARCADE-full", "AI": {"tldr": "构建一个细粒度的城市级别阿拉伯方言标注语料库，用于城市级别的方言识别任务。", "motivation": "当前存在多地区语言数据集，但精细到特定城市的方言映射仍是一个未充分探索的领域。为了满足这一需求，研究者们创建了ARCADE（阿拉伯广播语料库），以提供更精确的城市级别方言标注。", "method": "通过收集来自阿拉伯世界各地电台流服务的音频段落建立语料库，并由一到三位本地阿拉伯评审员对每个片段进行元数据标注，包括情绪、讲话类型和城市级别的方言分类。", "result": "该语料库包含6,907个注释和3,790个独特的音频片段，跨越58个城市和地区。这些精细的标签支持多任务学习，并作为基准测试用于城市级别方言识别。", "conclusion": "ARCADE提供了第一个专注于细粒度城市级别的阿拉伯语音数据集，为方言研究者们提供了一个宝贵的资源和评估标准。"}}
{"id": "2601.02206", "pdf": "https://arxiv.org/pdf/2601.02206", "abs": "https://arxiv.org/abs/2601.02206", "authors": ["Dachun Kai", "Zeyu Xiao", "Huyue Zhu", "Jiaxiao Wang", "Yueyi Zhang", "Xiaoyan Sun"], "title": "Seeing the Unseen: Zooming in the Dark with Event Cameras", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to AAAI 2026", "summary": "This paper addresses low-light video super-resolution (LVSR), aiming to restore high-resolution videos from low-light, low-resolution (LR) inputs. Existing LVSR methods often struggle to recover fine details due to limited contrast and insufficient high-frequency information. To overcome these challenges, we present RetinexEVSR, the first event-driven LVSR framework that leverages high-contrast event signals and Retinex-inspired priors to enhance video quality under low-light scenarios. Unlike previous approaches that directly fuse degraded signals, RetinexEVSR introduces a novel bidirectional cross-modal fusion strategy to extract and integrate meaningful cues from noisy event data and degraded RGB frames. Specifically, an illumination-guided event enhancement module is designed to progressively refine event features using illumination maps derived from the Retinex model, thereby suppressing low-light artifacts while preserving high-contrast details. Furthermore, we propose an event-guided reflectance enhancement module that utilizes the enhanced event features to dynamically recover reflectance details via a multi-scale fusion mechanism. Experimental results show that our RetinexEVSR achieves state-of-the-art performance on three datasets. Notably, on the SDSD benchmark, our method can get up to 2.95 dB gain while reducing runtime by 65% compared to prior event-based methods. Code: https://github.com/DachunKai/RetinexEVSR.", "AI": {"tldr": "本文提出了一种新的低光视频超分辨率框架RetinexEVSR，利用事件摄像机信号和Retinex模型提升低光照条件下的视频质量。", "motivation": "现有的LVSR方法在恢复低光照条件下的高分辨率视频时效果不佳，特别是在细节恢复方面存在问题。为了应对这一挑战，作者提出了一个新的基于事件的框架来增强视频的质量。", "method": "引入了双模态融合策略及两个关键模块：照明导向事件增强模块和反射率导向事件增强模块。前者利用Retinex模型得到的光照图逐步优化事件特征，后者则通过多尺度融合机制动态恢复反光细节。", "result": "实验结果表明，在三个数据集上，所提出的RetinexEVSR达到了最先进的性能，并在SDSD基准测试中获得了最高2.95 dB的增益，同时减少了65%的运行时间。", "conclusion": "通过创新的方法和技术，RetinexEVSR显著提升了低光照条件下视频超分辨率的质量和效率。"}}
{"id": "2601.02205", "pdf": "https://arxiv.org/pdf/2601.02205", "abs": "https://arxiv.org/abs/2601.02205", "authors": ["Neziha Akalin", "Alberto Giaretta"], "title": "From Chat Control to Robot Control: The Backdoors Left Open for the Sake of Safety", "categories": ["cs.CY", "cs.CR", "cs.HC"], "comment": "15 pages, 2 figures", "summary": "This paper explores how a recent European Union proposal, the so-called Chat Control law, which creates regulatory incentives for providers to implement content detection and communication scanning, could transform the foundations of human-robot interaction (HRI). As robots increasingly act as interpersonal communication channels in care, education, and telepresence, they convey not only speech but also gesture, emotion, and contextual cues. We argue that extending digital surveillance laws to such embodied systems would entail continuous monitoring, embedding observation into the very design of everyday robots. This regulation blurs the line between protection and control, turning companions into potential informants. At the same time, monitoring mechanisms that undermine end-to-end encryption function as de facto backdoors, expanding the attack surface and allowing adversaries to exploit legally induced monitoring infrastructures. This creates a paradox of safety through insecurity: systems introduced to protect users may instead compromise their privacy, autonomy, and trust. This work does not aim to predict the future, but to raise awareness and help prevent certain futures from materialising.", "AI": {"tldr": "探讨欧盟拟议的《聊天控制法》如何影响人机交互的基础，特别是隐私和安全问题。", "motivation": "旨在防止机器人成为监视工具，并讨论这些法规对用户隐私、自主性和信任的影响。", "method": "分析扩展数字监控法律至物理系统会带来的连续监控及其潜在后果。", "result": "指出这种监管可能将系统转变为潜在的信息员，同时破坏端到端加密的安全性。", "conclusion": "强调通过增强安全来削弱隐私、自主性和信任之间的矛盾关系。"}}
{"id": "2601.02204", "pdf": "https://arxiv.org/pdf/2601.02204", "abs": "https://arxiv.org/abs/2601.02204", "authors": ["Huichao Zhang", "Liao Qu", "Yiheng Liu", "Hang Chen", "Yangyang Song", "Yongsheng Dong", "Shikun Sun", "Xian Li", "Xu Wang", "Yi Jiang", "Hu Ye", "Bo Chen", "Yiming Gao", "Peng Liu", "Akide Liu", "Zhipeng Yang", "Qili Deng", "Linjie Xing", "Jiyang Liu", "Zhao Wang", "Yang Zhou", "Mingcong Liu", "Yi Zhang", "Qian He", "Xiwei Hu", "et al. (11 additional authors not shown)"], "title": "NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://github.com/ByteVisionLab/NextFlow", "summary": "We present NextFlow, a unified decoder-only autoregressive transformer trained on 6 trillion interleaved text-image discrete tokens. By leveraging a unified vision representation within a unified autoregressive architecture, NextFlow natively activates multimodal understanding and generation capabilities, unlocking abilities of image editing, interleaved content and video generation. Motivated by the distinct nature of modalities - where text is strictly sequential and images are inherently hierarchical - we retain next-token prediction for text but adopt next-scale prediction for visual generation. This departs from traditional raster-scan methods, enabling the generation of 1024x1024 images in just 5 seconds - orders of magnitude faster than comparable AR models. We address the instabilities of multi-scale generation through a robust training recipe. Furthermore, we introduce a prefix-tuning strategy for reinforcement learning. Experiments demonstrate that NextFlow achieves state-of-the-art performance among unified models and rivals specialized diffusion baselines in visual quality.", "AI": {"tldr": "介绍了一种名为NextFlow的统一解码器，用于跨模态理解和生成任务。", "motivation": "通过保留文本的逐令牌预测和采用视觉生成的下一尺度预测，来处理不同模式的独特性质，提高效率并解决多尺度生成中的不稳定性问题。", "method": "训练一个基于6万亿个交错文本图像离散标记的解码器模型。该模型在一个统一的自回归架构中利用了统一的视觉表示，并采用前缀微调策略进行强化学习。", "result": "实验表明，NextFlow在统一模型中达到了最先进的性能，并且在视觉质量上与专用扩散基线相当。", "conclusion": "NextFlow通过其创新的方法和训练方案，在跨模态理解和生成任务方面表现出色。"}}
{"id": "2601.02203", "pdf": "https://arxiv.org/pdf/2601.02203", "abs": "https://arxiv.org/abs/2601.02203", "authors": ["Oliver Custance", "Saad Khan", "Simon Parkinson", "Quan Z. Sheng"], "title": "Parameter-Efficient Domain Adaption for CSI Crowd-Counting via Self-Supervised Learning with Adapter Modules", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "Device-free crowd-counting using WiFi Channel State Information (CSI) is a key enabling technology for a new generation of privacy-preserving Internet of Things (IoT) applications. However, practical deployment is severely hampered by the domain shift problem, where models trained in one environment fail to generalise to another. To overcome this, we propose a novel two-stage framework centred on a CSI-ResNet-A architecture. This model is pre-trained via self-supervised contrastive learning to learn domain-invariant representations and leverages lightweight Adapter modules for highly efficient fine-tuning. The resulting event sequence is then processed by a stateful counting machine to produce a final, stable occupancy estimate. We validate our framework extensively. On our WiFlow dataset, our unsupervised approach excels in a 10-shot learning scenario, achieving a final Mean Absolute Error (MAE) of just 0.44--a task where supervised baselines fail. To formally quantify robustness, we introduce the Generalisation Index (GI), on which our model scores near-perfectly, confirming its ability to generalise. Furthermore, our framework sets a new state-of-the-art public WiAR benchmark with 98.8\\% accuracy. Our ablation studies reveal the core strength of our design: adapter-based fine-tuning achieves performance within 1\\% of a full fine-tune (98.84\\% vs. 99.67\\%) while training 97.2\\% fewer parameters. Our work provides a practical and scalable solution for developing robust sensing systems ready for real-world IoT deployments.", "AI": {"tldr": "本文提出了一种基于自监督学习和适配器模块的参数高效域适应方法，用于使用WiFi信道状态信息（CSI）进行人群计数。", "motivation": "实际部署中存在领域偏移问题，导致训练模型无法泛化到新的环境。为解决此问题，本文提出了一种新型两阶段框架以实现高效的域适应和人群计数。", "method": "首先通过自监督对比学习预训练CSI-ResNet-A架构，然后利用轻量级适配器模块进行高效微调，并通过状态机产生最终的人群估计。", "result": "在WiFlow数据集上实现了0.44的平均绝对误差，在10次学习场景中表现优异。同时在公共WiAR基准测试中达到了98.8%的准确率，表明了模型的强大泛化能力。", "conclusion": "该框架提供了一种实用且可扩展的方法来开发适用于物联网部署的强大感知系统。"}}
{"id": "2601.02201", "pdf": "https://arxiv.org/pdf/2601.02201", "abs": "https://arxiv.org/abs/2601.02201", "authors": ["Keyu Wang", "Bingchen Miao", "Wendong Bu", "Yu Wu", "Juncheng Li", "Shengyu Zhang", "Wenqiao Zhang", "Siliang Tang", "Jun Xiao", "Yueting Zhuang"], "title": "CORE: Code-based Inverse Self-Training Framework with Graph Expansion for Virtual Agents", "categories": ["cs.LG", "cs.CV"], "comment": "19 pages, 12 figures", "summary": "The development of Multimodal Virtual Agents has made significant progress through the integration of Multimodal Large Language Models. However, mainstream training paradigms face key challenges: Behavior Cloning is simple and effective through imitation but suffers from low behavioral diversity, while Reinforcement Learning is capable of discovering novel strategies through exploration but heavily relies on manually designed reward functions. To address the conflict between these two methods, we present CORE, a Code-based Inverse Self-Training Framework with Graph Expansion that bridges imitation and exploration, offering a novel training framework that promotes behavioral diversity while eliminating the reliance on manually reward design. Specifically, we introduce Semantic Code Abstraction to automatically infers reward functions from expert demonstrations without manual design. The inferred reward function, referred to as the Label Function, is executable code that verifies one key step within a task. Building on this, we propose Strategy Graph Expansion to enhance in-domain behavioral diversity, which constructs a multi-path graph called Strategy Graph that captures diverse valid solutions beyond expert demonstrations. Furthermore, we introduce Trajectory-Guided Extrapolation, which enriches out-of-domain behavioral diversity by utilizing both successful and failed trajectories to expand the task space. Experiments on Web and Android platforms demonstrate that CORE significantly improves both overall performance and generalization, highlighting its potential as a robust and generalizable training paradigm for building powerful virtual agents.", "AI": {"tldr": "本文提出了CORE框架，该框架通过代码逆向自我训练结合图扩展，解决了行为克隆和强化学习之间的矛盾，提高了虚拟代理的行为多样性。", "motivation": "主流的多模态虚拟代理训练方法面临挑战：行为克隆虽然简单有效但缺乏多样性，而强化学习依赖于手动设计奖励函数。本文旨在通过一种新框架解决此问题，提高多样性和性能。", "method": "CORE框架包括代码抽象以自动推断奖励函数、策略图扩展来增强领域内行为多样性及轨迹引导外插法以增加领域外行为多样性。", "result": "实验表明，CORE显著提高了虚拟代理的整体表现和泛化能力。", "conclusion": "本文提出的方法为构建强大的虚拟代理提供了一种稳健且通用的训练范式。"}}
{"id": "2601.02200", "pdf": "https://arxiv.org/pdf/2601.02200", "abs": "https://arxiv.org/abs/2601.02200", "authors": ["Markus Borg", "Nadim Hagatulah", "Adam Tornhill", "Emma Söderberg"], "title": "Code for Machines, Not Just Humans: Quantifying AI-Friendliness with Code Health Metrics", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted for the 3rd ACM International Conference on AI Foundation Models and Software Engineering (FORGE 2026)", "summary": "We are entering a hybrid era in which human developers and AI coding agents work in the same codebases. While industry practice has long optimized code for human comprehension, it is increasingly important to ensure that LLMs with different capabilities can edit code reliably. In this study, we investigate the concept of ``AI-friendly code'' via LLM-based refactoring on a dataset of 5,000 Python files from competitive programming. We find a meaningful association between CodeHealth, a quality metric calibrated for human comprehension, and semantic preservation after AI refactoring. Our findings confirm that human-friendly code is also more compatible with AI tooling. These results suggest that organizations can use CodeHealth to guide where AI interventions are lower risk and where additional human oversight is warranted. Investing in maintainability not only helps humans; it also prepares for large-scale AI adoption.", "AI": {"tldr": "研究探讨了代码对AI友好的概念，通过LLM进行代码重构以验证CodeHealth指标与语义保存之间的关联。", "motivation": "随着人类开发者和AI编码代理在同一代码库中工作，确保不同能力的LLM能够可靠地编辑代码变得越来越重要。需要量化AI友好性来指导何处可安全采用AI干预以及何时需要更多的人类监督。", "method": "研究使用了一个包含5000个Python文件的数据集进行LLM基于AI的重构实验，并分析了CodeHealth指标与语义保持的关系。", "result": "发现CodeHealth质量度量在人类理解和AI工具兼容性之间存在有意义的相关性，即适合人的代码也更适合AI操作。", "conclusion": "结果表明投资于维护性和可读性的改进不仅帮助人机交互，还为大规模的AI应用做好准备。"}}
{"id": "2601.02198", "pdf": "https://arxiv.org/pdf/2601.02198", "abs": "https://arxiv.org/abs/2601.02198", "authors": ["Alexander Möllers", "Julius Hense", "Florian Schulz", "Timo Milbich", "Maximilian Alber", "Lukas Ruff"], "title": "Mind the Gap: Continuous Magnification Sampling for Pathology Foundation Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In histopathology, pathologists examine both tissue architecture at low magnification and fine-grained morphology at high magnification. Yet, the performance of pathology foundation models across magnifications and the effect of magnification sampling during training remain poorly understood. We model magnification sampling as a multi-source domain adaptation problem and develop a simple theoretical framework that reveals systematic trade-offs between sampling strategies. We show that the widely used discrete uniform sampling of magnifications (0.25, 0.5, 1.0, 2.0 mpp) leads to degradation at intermediate magnifications. We introduce continuous magnification sampling, which removes gaps in magnification coverage while preserving performance at standard scales. Further, we derive sampling distributions that optimize representation quality across magnification scales. To evaluate these strategies, we introduce two new benchmarks (TCGA-MS, BRACS-MS) with appropriate metrics. Our experiments show that continuous sampling substantially improves over discrete sampling at intermediate magnifications, with gains of up to 4 percentage points in balanced classification accuracy, and that optimized distributions can further improve performance. Finally, we evaluate current histopathology foundation models, finding that magnification is a primary driver of performance variation across models. Our work paves the way towards future pathology foundation models that perform reliably across magnifications.", "AI": {"tldr": "研究通过连续放大采样改善病理学基础模型在不同放大倍率下的性能。", "motivation": "当前的病理学基础模型在低放大和高放大倍率下表现良好，但在中间放大倍率下表现出退化现象。论文旨在通过改进放大倍率采样方法来解决这一问题，提高模型在整个放大范围内的稳定性。", "method": "将放大倍率采样视为多源域自适应问题，并提出连续放大采样以消除放大小覆盖的间隔，在标准尺度上保持性能的同时优化代表性质量分布。", "result": "实验表明，连续采样在中间放大倍数下比离散采样提高了多达4个百分点的平衡分类准确性。进一步优化分布可以提高表现。", "conclusion": "研究结果强调了放大对病理学基础模型性能变化的重要影响，并为未来能够在各种放大倍率下可靠运行的基础模型铺平道路。"}}
{"id": "2601.02193", "pdf": "https://arxiv.org/pdf/2601.02193", "abs": "https://arxiv.org/abs/2601.02193", "authors": ["Kasper Green Larsen", "Chirag Pabbaraju", "Abhishek Shetty"], "title": "Learning with Monotone Adversarial Corruptions", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": null, "summary": "We study the extent to which standard machine learning algorithms rely on exchangeability and independence of data by introducing a monotone adversarial corruption model. In this model, an adversary, upon looking at a \"clean\" i.i.d. dataset, inserts additional \"corrupted\" points of their choice into the dataset. These added points are constrained to be monotone corruptions, in that they get labeled according to the ground-truth target function. Perhaps surprisingly, we demonstrate that in this setting, all known optimal learning algorithms for binary classification can be made to achieve suboptimal expected error on a new independent test point drawn from the same distribution as the clean dataset. On the other hand, we show that uniform convergence-based algorithms do not degrade in their guarantees. Our results showcase how optimal learning algorithms break down in the face of seemingly helpful monotone corruptions, exposing their overreliance on exchangeability.", "AI": {"tldr": "研究在单调对抗性损坏模型下标准机器学习算法的表现，发现最优算法在这种情况下表现不佳。", "motivation": "探讨标准机器学习算法对数据交换性和独立性的依赖程度，通过引入单调对抗性损坏模型来展示这种影响。", "method": "提出一种新的单调对抗性损坏模型，分析在此模型中二分类问题的最优算法性能下降，而基于均匀收敛的算法保持稳定。", "result": "表明在单调对抗性损坏下，所有已知最优学习算法的表现不如预期；但基于均匀收敛的学习算法不受影响。", "conclusion": "展示了即使存在看似有益的损坏（如单调损坏），标准机器学习算法也会出现故障，揭示了其过度依赖数据交换性的弱点。"}}
{"id": "2601.02189", "pdf": "https://arxiv.org/pdf/2601.02189", "abs": "https://arxiv.org/abs/2601.02189", "authors": ["Cheng Ying Wu", "Yen Jui Chang"], "title": "QuIC: A Quantum-Inspired Interaction Classifier for Revitalizing Shallow CNNs in Fine-Grained Recognition", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Deploying deep learning models for Fine-Grained Visual Classification (FGVC) on resource-constrained edge devices remains a significant challenge. While deep architectures achieve high accuracy on benchmarks like CUB-200-2011, their computational cost is often prohibitive. Conversely, shallow networks (e.g., AlexNet, VGG) offer efficiency but fail to distinguish visually similar sub-categories. This is because standard Global Average Pooling (GAP) heads capture only first-order statistics, missing the subtle high-order feature interactions required for FGVC. While Bilinear CNNs address this, they suffer from high feature dimensionality and instability during training. To bridge this gap, we propose the Quantum-inspired Interaction Classifier (QuIC). Drawing inspiration from quantum mechanics, QuIC models feature channels as interacting quantum states and captures second-order feature covariance via a learnable observable operator. Designed as a lightweight, plug-and-play module, QuIC supports stable, single-stage end-to-end training without exploding feature dimensions. Experimental results demonstrate that QuIC significantly revitalizes shallow backbones: it boosts the Top-1 accuracy of VGG16 by nearly 20% and outperforms state-of-the-art attention mechanisms (SE-Block) on ResNet18. Qualitative analysis, including t-SNE visualization, further confirms that QuIC resolves ambiguous cases by explicitly attending to fine-grained discriminative features and enforcing compact intra-class clustering.", "AI": {"tldr": "本文提出了一种基于量子力学启发的交互分类器（QuIC），用于提升浅层CNN在细粒度视觉分类任务上的性能。", "motivation": "深度学习模型在资源受限设备上部署存在计算成本高的问题，而浅层网络虽然效率高但难以区分相似类别。现有的全局平均池化和双线性卷积神经网络方法在捕捉特征交互方面存在局限性或训练不稳定性问题。", "method": "QuIC将特征通道视为量子状态进行建模，并通过一个可学习的观测算子捕获二次特征协方差，从而作为轻量级、即插即用模块支持稳定且单一阶段端到端训练。", "result": "实验结果表明，QuIC显著提升了浅层骨干网络VGG16的Top-1准确率，并在ResNet18上优于最先进的注意力机制（SE-Block）。定性分析显示QuIC通过关注细粒度鉴别特征和强制紧凑类内聚类解决了模糊情况。", "conclusion": "QuIC提供了一种有效的方法来提升浅层CNN在资源受限设备上的性能，同时保持计算效率。"}}
{"id": "2601.02184", "pdf": "https://arxiv.org/pdf/2601.02184", "abs": "https://arxiv.org/abs/2601.02184", "authors": ["Yuhang Zhang", "Sören Schwertfeger"], "title": "Differential Barometric Altimetry for Submeter Vertical Localization and Floor Recognition Indoors", "categories": ["cs.RO"], "comment": null, "summary": "Accurate altitude estimation and reliable floor recognition are critical for mobile robot localization and navigation within complex multi-storey environments. In this paper, we present a robust, low-cost vertical estimation framework leveraging differential barometric sensing integrated within a fully ROS-compliant software package. Our system simultaneously publishes real-time altitude data from both a stationary base station and a mobile sensor, enabling precise and drift-free vertical localization. Empirical evaluations conducted in challenging scenarios -- such as fully enclosed stairwells and elevators, demonstrate that our proposed barometric pipeline achieves sub-meter vertical accuracy (RMSE: 0.29 m) and perfect (100%) floor-level identification. In contrast, our results confirm that standalone height estimates, obtained solely from visual- or LiDAR-based SLAM odometry, are insufficient for reliable vertical localization. The proposed ROS-compatible barometric module thus provides a practical and cost-effective solution for robust vertical awareness in real-world robotic deployments. The implementation of our method is released as open source at https://github.com/witsir/differential-barometric.", "AI": {"tldr": "利用差分气压传感器实现室内亚米级垂直定位和楼层识别。", "motivation": "准确的高度估计和可靠的楼层识别对于多层环境下的移动机器人定位与导航至关重要。现有基于视觉或LiDAR的SLAM方法在垂直方向上精度不足，因此需要一种新的低成本解决方案来提高垂直感知能力。", "method": "提出了一种差分气压高度估算框架，并整合到了ROS兼容软件包中。该系统实时发布来自静止基站和移动传感器的高度数据，实现了精确且无漂移的垂直定位。", "result": "在封闭楼梯间和电梯等复杂环境中进行实验证明，所提出的气压管道达到了亚米级垂直精度（RMSE：0.29m）并实现了100%楼层识别准确率。这表明基于视觉或LiDAR的SLAM单独使用不足以实现可靠的高度估计。", "conclusion": "该方法提供了一种实用且成本效益高的解决方案，适用于真实世界中的机器人部署，并已作为开源代码发布（https://github.com/witsir/differential-barometric）"}}
{"id": "2601.02177", "pdf": "https://arxiv.org/pdf/2601.02177", "abs": "https://arxiv.org/abs/2601.02177", "authors": ["Oliver Custance", "Saad Khan", "Simon Parkinson"], "title": "Why Commodity WiFi Sensors Fail at Multi-Person Gait Identification: A Systematic Analysis Using ESP32", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "WiFi Channel State Information (CSI) has shown promise for single-person gait identification, with numerous studies reporting high accuracy. However, multi-person identification remains largely unexplored, with the limited existing work relying on complex, expensive setups requiring modified firmware. A critical question remains unanswered: is poor multi-person performance an algorithmic limitation or a fundamental hardware constraint? We systematically evaluate six diverse signal separation methods (FastICA, SOBI, PCA, NMF, Wavelet, Tensor Decomposition) across seven scenarios with 1-10 people using commodity ESP32 WiFi sensors--a simple, low-cost, off-the-shelf solution. Through novel diagnostic metrics (intra-subject variability, inter-subject distinguishability, performance degradation rate), we reveal that all methods achieve similarly low accuracy (45-56\\%, $σ$=3.74\\%) with statistically insignificant differences (p $>$ 0.05). Even the best-performing method, NMF, achieves only 56\\% accuracy. Our analysis reveals high intra-subject variability, low inter-subject distinguishability, and severe performance degradation as person count increases, indicating that commodity ESP32 sensors cannot provide sufficient signal quality for reliable multi-person separation.", "AI": {"tldr": "分析了商品WiFi传感器在多人步态识别中的表现，揭示其硬件限制", "motivation": "探讨商品WiFi传感器是否可以用于可靠的人体步态识别，特别是多人场景下是否存在根本性的硬件限制", "method": "使用六种信号分离方法评估ESP32 WiFi传感器在1-10人不同场景下的性能，并通过特定诊断指标进行分析", "result": "所有方法的准确性均较低（45%-56%），表明商品WiFi传感器无法提供足够的信号质量以支持可靠的多人步态识别", "conclusion": "商品WiFi传感器因高个体内部变异性和低个体间区分性，难以实现稳定准确的人体步态分离"}}
{"id": "2601.02170", "pdf": "https://arxiv.org/pdf/2601.02170", "abs": "https://arxiv.org/abs/2601.02170", "authors": ["Haolang Lu", "Minghui Pan", "Ripeng Li", "Guoshun Nan", "Jialin Zhuang", "Zijie Zhao", "Zhongxiang Sun", "Kun Wang", "Yang Liu"], "title": "Streaming Hallucination Detection in Long Chain-of-Thought Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.", "AI": {"tldr": "该论文提出了在长链思维推理中实时检测幻觉的方法。", "motivation": "随着语言模型性能的提高，长链思维推理中的幻觉问题变得更为隐蔽且具有传播性。因此，研究者试图理解并解决这种动态变化的问题。", "method": "将步骤级的幻觉判断视为局部观察，并引入累积前缀级别的幻觉信号来跟踪整个轨迹上的全局演化状态，实现流式幻觉检测。", "result": "该方法提供了一种能够实时、可解释地监测长链思维推理中幻觉的技术。", "conclusion": "通过这种方法，可以在长链思维推理过程中及时发现并解决潜在的幻觉问题。"}}
{"id": "2601.02167", "pdf": "https://arxiv.org/pdf/2601.02167", "abs": "https://arxiv.org/abs/2601.02167", "authors": ["Wei He", "Xiang Li", "Per Ola Kristensson", "Ge Lin Kan"], "title": "LocoScooter: Designing a Stationary Scooter-Based Locomotion System for Navigation in Virtual Reality", "categories": ["cs.HC"], "comment": "11 pages, 10 figures, conditionally accpeted by IEEE Transactions on Visualization and Computer Graphics (IEEE VR 2026)", "summary": "Virtual locomotion remains a challenge in VR, especially in space-limited environments where room-scale walking is impractical. We present LocoScooter, a low-cost, deployable locomotion interface combining foot-sliding on a compact treadmill with handlebar steering inspired by scooter riding. Built from commodity hardware, it supports embodied navigation through familiar, physically engaging movement. In a within-subject study (N = 14), LocoScooter significantly improved immersion, enjoyment, and bodily involvement over joystick navigation, while maintaining comparable efficiency and usability. Despite higher physical demand, users did not report increased fatigue, suggesting familiar movements can enrich VR navigation.", "AI": {"tldr": "设计了一种结合滑板车操作的虚拟现实导航系统，以提高沉浸感和用户体验。", "motivation": "在空间有限的情况下，传统的步行动作追踪在虚拟现实中难以实现。因此需要一种新的、成本低廉且易于部署的方法来提升用户的沉浸体验。", "method": "设计并构建了一个基于滑板车的定位运动界面（LocoScooter），该系统结合了脚部移动和手柄操控，并通过一个横截面较小的小型跑步机进行测试。实验中，参与者使用这种新设备在虚拟环境中导航并与之互动。", "result": "实验表明，与传统的操纵杆相比，LoCoScooter显著提高了沉浸感、体验度以及身体参与度，同时保持了相当的效率和易用性。尽管增加了体力消耗，用户并未感到疲劳加重。", "conclusion": "这项研究证明了一种熟悉而具身体感运动方式可以改善虚拟现实中的导航体验，并且这种低成本的设计可以在各种环境中方便地部署。"}}
{"id": "2601.02163", "pdf": "https://arxiv.org/pdf/2601.02163", "abs": "https://arxiv.org/abs/2601.02163", "authors": ["Chuanrui Hu", "Xingze Gao", "Zuyi Zhou", "Dannong Xu", "Yi Bai", "Xintong Li", "Hui Zhang", "Tong Li", "Chong Zhang", "Lidong Bing", "Yafeng Deng"], "title": "EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "16 pages, 6 figures, 12 tables. Code available at https://github.com/EverMind-AI/EverMemOS", "summary": "Large Language Models (LLMs) are increasingly deployed as long-term interactive agents, yet their limited context windows make it difficult to sustain coherent behavior over extended interactions. Existing memory systems often store isolated records and retrieve fragments, limiting their ability to consolidate evolving user states and resolve conflicts. We introduce EverMemOS, a self-organizing memory operating system that implements an engram-inspired lifecycle for computational memory. Episodic Trace Formation converts dialogue streams into MemCells that capture episodic traces, atomic facts, and time-bounded Foresight signals. Semantic Consolidation organizes MemCells into thematic MemScenes, distilling stable semantic structures and updating user profiles. Reconstructive Recollection performs MemScene-guided agentic retrieval to compose the necessary and sufficient context for downstream reasoning. Experiments on LoCoMo and LongMemEval show that EverMemOS achieves state-of-the-art performance on memory-augmented reasoning tasks. We further report a profile study on PersonaMem v2 and qualitative case studies illustrating chat-oriented capabilities such as user profiling and Foresight. Code is available at https://github.com/EverMind-AI/EverMemOS.", "AI": {"tldr": "EverMemOS是一种用于长时序推理的自组织记忆操作系统，通过模拟人类记忆过程来解决大型语言模型在长时间交互中遇到的记忆限制问题。", "motivation": "现有记忆系统难以整合和更新用户状态，导致长时段对话中出现不连贯的行为。为了克服这一难题，提出了EverMemOS以实现更好的长期互动能力。", "method": "EverMemOS通过三种机制实现：Episodic Trace Formation将对话流转化为捕捉时间片段、原子事实及前瞻信号的MemCells；Semantic Consolidation将这些细胞组织为反映主题的记忆场景；Reconstructive Recollection则根据记忆场景指导性地检索必要上下文。", "result": "实验表明，EverMemOS在LoCoMo和LongMemEval任务上达到了最佳性能，并且展示了在用户建模及前瞻能力上的优势。", "conclusion": "通过模拟人类记忆机制，EverMemOS有效地解决了大型语言模型的记忆限制问题，在长时序推理任务中表现出色。"}}
{"id": "2601.02158", "pdf": "https://arxiv.org/pdf/2601.02158", "abs": "https://arxiv.org/abs/2601.02158", "authors": ["Almaz Ermilov"], "title": "FormationEval, an open multiple-choice benchmark for petroleum geoscience", "categories": ["cs.CL", "cs.AI", "cs.LG", "physics.geo-ph"], "comment": "24 pages, 8 figures, 10 tables; benchmark and code at https://github.com/AlmazErmilov/FormationEval-an-Open-Benchmark-for-Oil-Gas-Geoscience-MCQ-Evaluation", "summary": "This paper presents FormationEval, an open multiple-choice question benchmark for evaluating language models on petroleum geoscience and subsurface disciplines. The dataset contains 505 questions across seven domains including petrophysics, petroleum geology and reservoir engineering, derived from three authoritative sources using a reasoning model with detailed instructions and a concept-based approach that avoids verbatim copying of copyrighted text. Each question includes source metadata to support traceability and audit. The evaluation covers 72 models from major providers including OpenAI, Anthropic, Google, Meta and open-weight alternatives. The top performers achieve over 97\\% accuracy, with Gemini 3 Pro Preview reaching 99.8\\%, while tier and domain gaps persist. Among open-weight models, GLM-4.7 leads at 98.6\\%, with several DeepSeek, Llama, Qwen and Mistral models also exceeding 93\\%. The performance gap between open-weight and closed models is narrower than expected, with several lower-cost open-weight models exceeding 90\\% accuracy. Petrophysics emerges as the most challenging domain across all models, while smaller models show wider performance variance. Residual length bias in the dataset (correct answers tend to be longer) is documented along with bias mitigation strategies applied during construction. The benchmark, evaluation code and results are publicly available.", "AI": {"tldr": "该论文介绍了FormationEval，一个用于评估语言模型在石油地质和地下学科中的表现的公开选择题基准。", "motivation": "为了测试各种语言模型处理石油地质领域问题的能力，并促进这一领域的研究与应用，作者创建了一个包含505个跨七个主题的问题集。", "method": "数据集由三个权威来源提供并经过推理模型和基于概念的方法生成，避免了对版权文本的直接复制。涵盖了72种语言模型的表现评估。", "result": "顶级表现的语言模型准确率超过97%，其中Gemini 3 Pro Preview达到99.8%；开放权重模型中GLM-4.7以98.6%领先，多个DeepSeek、Llama和Qwen等模型也超过了93%的准确性。", "conclusion": "该研究揭示了不同语言模型在处理石油地质问题上的表现差异，并指出较小模型间的表现差距更大。同时，数据集存在答案长度偏见的问题已被记录并提出了缓解策略。"}}
{"id": "2601.02151", "pdf": "https://arxiv.org/pdf/2601.02151", "abs": "https://arxiv.org/abs/2601.02151", "authors": ["Muxi Diao", "Lele Yang", "Wuxuan Gong", "Yutong Zhang", "Zhonghao Yan", "Yufei Han", "Kongming Liang", "Weiran Xu", "Zhanyu Ma"], "title": "Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Supervised Fine-Tuning (SFT) is the standard paradigm for domain adaptation, yet it frequently incurs the cost of catastrophic forgetting. In sharp contrast, on-policy Reinforcement Learning (RL) effectively preserves general capabilities. We investigate this discrepancy and identify a fundamental distributional gap: while RL aligns with the model's internal belief, SFT forces the model to fit external supervision. This mismatch often manifests as \"Confident Conflicts\" tokens characterized by low probability but low entropy. In these instances, the model is highly confident in its own prediction but is forced to learn a divergent ground truth, triggering destructive gradient updates. To address this, we propose Entropy-Adaptive Fine-Tuning (EAFT). Unlike methods relying solely on prediction probability, EAFT utilizes token-level entropy as a gating mechanism to distinguish between epistemic uncertainty and knowledge conflict. This allows the model to learn from uncertain samples while suppressing gradients on conflicting data. Extensive experiments on Qwen and GLM series (ranging from 4B to 32B parameters) across mathematical, medical, and agentic domains confirm our hypothesis. EAFT consistently matches the downstream performance of standard SFT while significantly mitigating the degradation of general capabilities.", "AI": {"tldr": "提出了一种基于熵适应性微调的方法（EAFT），以解决监督学习过程中出现的自信冲突问题，从而减轻灾难性遗忘。", "motivation": "传统的监督学习容易导致灾难性的忘记问题，而强化学习则能有效保留模型的一般能力。论文通过分析发现这是由于分布差距导致的，并提出了解决方案。", "method": "引入了基于熵适应性微调（EAFT）的方法，利用令牌级别的熵作为门控机制来区分不确定性和知识冲突，使得模型可以从不确定样本中学习同时抑制对矛盾数据的学习。", "result": "实验结果证明，该方法在Qwen和GLM系列多个参数规模的数据集上都表现良好，与标准监督微调相比，在下游任务性能方面相当甚至更好，同时显著减轻了模型一般能力的退化。", "conclusion": "通过熵适应性微调的方法能够有效地解决灾难性忘记问题，并保持或提升模型在各种领域的性能。"}}
{"id": "2601.02149", "pdf": "https://arxiv.org/pdf/2601.02149", "abs": "https://arxiv.org/abs/2601.02149", "authors": ["Mateusz Krawczyk", "Jarosław Pawłowski"], "title": "AI-enhanced tuning of quantum dot Hamiltonians toward Majorana modes", "categories": ["cond-mat.mes-hall", "cond-mat.dis-nn", "cs.AI"], "comment": "main file: 8 pages, 6 figures; supplementary: 3 pages, 2 figures", "summary": "We propose a neural network-based model capable of learning the broad landscape of working regimes in quantum dot simulators, and using this knowledge to autotune these devices - based on transport measurements - toward obtaining Majorana modes in the structure. The model is trained in an unsupervised manner on synthetic data in the form of conductance maps, using a physics-informed loss that incorporates key properties of Majorana zero modes. We show that, with appropriate training, a deep vision-transformer network can efficiently memorize relation between Hamiltonian parameters and structures on conductance maps and use it to propose parameters update for a quantum dot chain that drive the system toward topological phase. Starting from a broad range of initial detunings in parameter space, a single update step is sufficient to generate nontrivial zero modes. Moreover, by enabling an iterative tuning procedure - where the system acquires updated conductance maps at each step - we demonstrate that the method can address a much larger region of the parameter space.", "AI": {"tldr": "提出了一种基于神经网络的模型，用于自学习量子点模拟器的工作状态，并利用传输测量结果将系统调谐至产生马约拉纳模式的状态。", "motivation": "通过使用深度视觉变换网络，自动调整量子点器件以实现拓扑相位中的马约拉纳零模态。这种方法可以在不增加复杂度的情况下覆盖更大的参数空间范围。", "method": "模型采用无监督学习方式，在合成数据集上训练，该数据集包含基于传输测量的导电图，并使用物理信息损失函数来优化网络性能。通过迭代调整程序，系统可以逐步接近目标状态。", "result": "从初始参数空间的广泛范围内开始，单一更新步骤就足以生成非平凡零模式。迭代调谐过程能够处理更大的参数区域。", "conclusion": "提出的AI增强方法有效地将量子点设备调谐至产生马约拉纳模式的状态，并展示了在实际应用中的潜力和效率。"}}
{"id": "2601.02147", "pdf": "https://arxiv.org/pdf/2601.02147", "abs": "https://arxiv.org/abs/2601.02147", "authors": ["Sunny Gupta", "Shounak Das", "Amit Sethi"], "title": "BiPrompt: Bilateral Prompt Optimization for Visual and Textual Debiasing in Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted at the AAAI 2026 Workshop AIR-FM, Assessing and Improving Reliability of Foundation Models in the Real World", "summary": "Vision language foundation models such as CLIP exhibit impressive zero-shot generalization yet remain vulnerable to spurious correlations across visual and textual modalities. Existing debiasing approaches often address a single modality either visual or textual leading to partial robustness and unstable adaptation under distribution shifts. We propose a bilateral prompt optimization framework (BiPrompt) that simultaneously mitigates non-causal feature reliance in both modalities during test-time adaptation. On the visual side, it employs structured attention-guided erasure to suppress background activations and enforce orthogonal prediction consistency between causal and spurious regions. On the textual side, it introduces balanced prompt normalization, a learnable re-centering mechanism that aligns class embeddings toward an isotropic semantic space. Together, these modules jointly minimize conditional mutual information between spurious cues and predictions, steering the model toward causal, domain invariant reasoning without retraining or domain supervision. Extensive evaluations on real-world and synthetic bias benchmarks demonstrate consistent improvements in both average and worst-group accuracies over prior test-time debiasing methods, establishing a lightweight yet effective path toward trustworthy and causally grounded vision-language adaptation.", "AI": {"tldr": "提出一种双边提示优化框架BiPrompt，用于视觉和文本模态中的去偏处理。", "motivation": "现有去偏方法只能处理单一模态，在分布变化下适应性较差。本文旨在同时减少视觉和文本模态中非因果特征依赖。", "method": "视觉方面使用结构化注意力引导擦除来抑制背景激活；文本方面引入平衡提示归一化，使类嵌入对齐至等向量语义空间；共同最小化条件互信息。", "result": "在真实和合成偏差基准上表现出色，超越前测试时去偏方法，在平均及最坏群体准确率均有提高。", "conclusion": "BiPrompt提供了一条轻量级有效路径，使视觉语言模型更具可信度与因果基础。"}}
{"id": "2601.02144", "pdf": "https://arxiv.org/pdf/2601.02144", "abs": "https://arxiv.org/abs/2601.02144", "authors": ["Boxuan Lyu", "Soichiro Murakami", "Hidetaka Kamigaito", "Peinan Zhang"], "title": "Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) architectures scale large language models efficiently by employing a parametric \"router\" to dispatch tokens to a sparse subset of experts. Typically, this router is trained once and then frozen, rendering routing decisions brittle under distribution shifts. We address this limitation by introducing kNN-MoE, a retrieval-augmented routing framework that reuses optimal expert assignments from a memory of similar past cases. This memory is constructed offline by directly optimizing token-wise routing logits to maximize the likelihood on a reference set. Crucially, we use the aggregate similarity of retrieved neighbors as a confidence-driven mixing coefficient, thus allowing the method to fall back to the frozen router when no relevant cases are found. Experiments show kNN-MoE outperforms zero-shot baselines and rivals computationally expensive supervised fine-tuning.", "AI": {"tldr": "提出了一种基于最近邻的混合专家架构kNN-MoE，以改进大规模语言模型中的路由决策。", "motivation": "传统的Mixture-of-Experts（MoE）架构在面对分布变化时，其固定的路由器使得路由决策变得脆弱。因此需要一种更灵活的方法来提高鲁棒性。", "method": "通过构建一个离线优化的最近邻记忆库，并利用该库中类似案例进行专家分配来增强路由器的功能。使用检索邻居间的聚合相似度作为混合系数，在没有相关案例时可以退回到固定的路由器。", "result": "实验表明kNN-MoE优于零样本基线模型，其性能与计算成本较高的监督微调方法相当。", "conclusion": "kNN-MoE通过利用历史数据的最近邻信息改进了路由决策机制，在面对分布变化时提高了模型鲁棒性和效率。"}}
{"id": "2601.02141", "pdf": "https://arxiv.org/pdf/2601.02141", "abs": "https://arxiv.org/abs/2601.02141", "authors": ["Romain Vo", "Julián Tachella"], "title": "Efficient Unrolled Networks for Large-Scale 3D Inverse Problems", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning-based methods have revolutionized the field of imaging inverse problems, yielding state-of-the-art performance across various imaging domains. The best performing networks incorporate the imaging operator within the network architecture, typically in the form of deep unrolling. However, in large-scale problems, such as 3D imaging, most existing methods fail to incorporate the operator in the architecture due to the prohibitive amount of memory required by global forward operators, which hinder typical patching strategies. In this work, we present a domain partitioning strategy and normal operator approximations that enable the training of end-to-end reconstruction models incorporating forward operators of arbitrarily large problems into their architecture. The proposed method achieves state-of-the-art performance on 3D X-ray cone-beam tomography and 3D multi-coil accelerated MRI, while requiring only a single GPU for both training and inference.", "AI": {"tldr": "提出了一种域分割策略和正则算子近似方法，使大型问题中的前向算子能够被集成到网络架构中。", "motivation": "在大规模成像逆问题（如3D成像）中，由于全局前向操作器占用大量内存，现有的深度学习方法难以将这些操作器纳入模型架构。为解决此问题，论文提出了新的策略以支持大尺度成像的端到端重建模型训练。", "method": "通过域分割和正则算子近似来减少内存需求，允许在大型3D逆问题中包含前向操作器，并实现高效的大规模图像重建。", "result": "新方法在三维X射线锥束断层摄影术与多通道加速MRI等任务上达到最先进水平，同时仅需单个GPU即可完成训练和推断。", "conclusion": "所提出的方法成功克服了内存限制，在大规模成像逆问题中实现了高效的端到端重建模型。"}}
{"id": "2601.02139", "pdf": "https://arxiv.org/pdf/2601.02139", "abs": "https://arxiv.org/abs/2601.02139", "authors": ["Chenyang Lai", "Shuaiyu Chen", "Tianjin Huang", "Siyang Song", "Guangliang Cheng", "Chunbo Luo", "Zeyu Fu"], "title": "Beyond Segmentation: An Oil Spill Change Detection Framework Using Synthetic SAR Imagery", "categories": ["cs.CV"], "comment": null, "summary": "Marine oil spills are urgent environmental hazards that demand rapid and reliable detection to minimise ecological and economic damage. While Synthetic Aperture Radar (SAR) imagery has become a key tool for large-scale oil spill monitoring, most existing detection methods rely on deep learning-based segmentation applied to single SAR images. These static approaches struggle to distinguish true oil spills from visually similar oceanic features (e.g., biogenic slicks or low-wind zones), leading to high false positive rates and limited generalizability, especially under data-scarce conditions. To overcome these limitations, we introduce Oil Spill Change Detection (OSCD), a new bi-temporal task that focuses on identifying changes between pre- and post-spill SAR images. As real co-registered pre-spill imagery is not always available, we propose the Temporal-Aware Hybrid Inpainting (TAHI) framework, which generates synthetic pre-spill images from post-spill SAR data. TAHI integrates two key components: High-Fidelity Hybrid Inpainting for oil-free reconstruction, and Temporal Realism Enhancement for radiometric and sea-state consistency. Using TAHI, we construct the first OSCD dataset and benchmark several state-of-the-art change detection models. Results show that OSCD significantly reduces false positives and improves detection accuracy compared to conventional segmentation, demonstrating the value of temporally-aware methods for reliable, scalable oil spill monitoring in real-world scenarios.", "AI": {"tldr": "提出了一种新的基于合成SAR图像的石油泄漏变化检测框架，以减少误报率并提高检测精度。", "motivation": "现有的基于单一SAR图像分割的方法难以区分真正的石油泄漏和类似海洋特征，导致高误报率和局限性。因此提出了使用时空信息进行改进的新方法。", "method": "提出了一种时间感知混合修复框架（TAHI），该框架从后泄漏SAR数据生成合成前泄漏图像，并通过集成高保真度混合修复和时间现实增强两个组件来实现。", "result": "构建了第一个OSCD数据集并对几种最先进的变化检测模型进行了基准测试，结果显示OSCD方法在减少误报率方面表现优于传统分割方法。", "conclusion": "提出的方法展示了时空感知技术在可靠且可扩展的石油泄漏监测中的价值。"}}
{"id": "2601.02128", "pdf": "https://arxiv.org/pdf/2601.02128", "abs": "https://arxiv.org/abs/2601.02128", "authors": ["Steffen Freisinger", "Philipp Seeberger", "Thomas Ranzenberger", "Tobias Bocklet", "Korbinian Riedhammer"], "title": "Towards Multi-Level Transcript Segmentation: LoRA Fine-Tuning for Table-of-Contents Generation", "categories": ["cs.CL", "eess.AS"], "comment": "Published in Proceedings of Interspeech 2025. Please cite the proceedings version (DOI: 10.21437/Interspeech.2025-2792)", "summary": "Segmenting speech transcripts into thematic sections benefits both downstream processing and users who depend on written text for accessibility. We introduce a novel approach to hierarchical topic segmentation in transcripts, generating multi-level tables of contents that capture both topic and subtopic boundaries. We compare zero-shot prompting and LoRA fine-tuning on large language models, while also exploring the integration of high-level speech pause features. Evaluations on English meeting recordings and multilingual lecture transcripts (Portuguese, German) show significant improvements over established topic segmentation baselines. Additionally, we adapt a common evaluation measure for multi-level segmentation, taking into account all hierarchical levels within one metric.", "AI": {"tldr": "该论文提出了一个新颖的方法，用于将演讲记录分段为多级目录，以捕捉主题和子主题的边界。", "motivation": "对演讲记录进行分段有助于下游处理和依赖书面文本的用户。现有的方法难以有效捕捉多层次的主题结构。", "method": "采用零样本提示和LoRA微调技术在大型语言模型上实现多级目录生成，并引入高级语音停顿特征以提高准确性。", "result": "实验结果显示，与现有基准相比，该方法在英语会议录音和多种语言的讲座记录上表现出显著改进。", "conclusion": "论文提出的方法能够有效改善演讲记录的多层次分段问题，适应不同的语言环境，并为多级目录生成提供新的视角。"}}
{"id": "2601.02126", "pdf": "https://arxiv.org/pdf/2601.02126", "abs": "https://arxiv.org/abs/2601.02126", "authors": ["Xavier Bou", "Elliot Vincent", "Gabriele Facciolo", "Rafael Grompone von Gioi", "Jean-Michel Morel", "Thibaud Ehret"], "title": "Remote Sensing Change Detection via Weak Temporal Supervision", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Semantic change detection in remote sensing aims to identify land cover changes between bi-temporal image pairs. Progress in this area has been limited by the scarcity of annotated datasets, as pixel-level annotation is costly and time-consuming. To address this, recent methods leverage synthetic data or generate artificial change pairs, but out-of-domain generalization remains limited. In this work, we introduce a weak temporal supervision strategy that leverages additional temporal observations of existing single-temporal datasets, without requiring any new annotations. Specifically, we extend single-date remote sensing datasets with new observations acquired at different times and train a change detection model by assuming that real bi-temporal pairs mostly contain no change, while pairing images from different locations to generate change examples. To handle the inherent noise in these weak labels, we employ an object-aware change map generation and an iterative refinement process. We validate our approach on extended versions of the FLAIR and IAILD aerial datasets, achieving strong zero-shot and low-data regime performance across different benchmarks. Lastly, we showcase results over large areas in France, highlighting the scalability potential of our method.", "AI": {"tldr": "利用弱时间监督策略进行遥感变化检测，通过额外的时间观测扩展单日期数据集，并训练一个变化检测模型。", "motivation": "解决标注数据稀缺问题，减少像素级注释的成本和时间消耗，提升跨域泛化能力。", "method": "引入弱时间监督策略利用现有单一时间点的数据集进行扩展，并通过假设真实双时相对多数不含有变化的条件训练模型。同时采用对象感知的变化图生成及迭代细化过程处理标签噪声问题。", "result": "验证方法在扩展后的FLAIR和IAILD数据集中实现了零样本和低样本情况下的优秀性能，展示了可应用于法国大区域变化检测中的潜力。", "conclusion": "所提出的方法能够有效地利用现有遥感数据集进行变化检测，并具有良好的跨域泛化能力和大规模应用的潜力。"}}
{"id": "2601.02125", "pdf": "https://arxiv.org/pdf/2601.02125", "abs": "https://arxiv.org/abs/2601.02125", "authors": ["Zhuoxiong Xu", "Xuanchen Li", "Yuhao Cheng", "Fei Xu", "Yichao Yan", "Xiaokang Yang"], "title": "SingingBot: An Avatar-Driven System for Robotic Face Singing Performance", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Equipping robotic faces with singing capabilities is crucial for empathetic Human-Robot Interaction. However, existing robotic face driving research primarily focuses on conversations or mimicking static expressions, struggling to meet the high demands for continuous emotional expression and coherence in singing. To address this, we propose a novel avatar-driven framework for appealing robotic singing. We first leverage portrait video generation models embedded with extensive human priors to synthesize vivid singing avatars, providing reliable expression and emotion guidance. Subsequently, these facial features are transferred to the robot via semantic-oriented mapping functions that span a wide expression space. Furthermore, to quantitatively evaluate the emotional richness of robotic singing, we propose the Emotion Dynamic Range metric to measure the emotional breadth within the Valence-Arousal space, revealing that a broad emotional spectrum is crucial for appealing performances. Comprehensive experiments prove that our method achieves rich emotional expressions while maintaining lip-audio synchronization, significantly outperforming existing approaches.", "AI": {"tldr": "本文提出了一种新的基于虚拟角色的框架，用于实现具有丰富情感表达和唇音同步的机器人歌唱。", "motivation": "现有的机器人面部驱动研究主要集中在对话或静态表情模仿上，难以满足歌唱所需的连续情感表现和连贯性需求。为此，作者提出了一个新型的基于虚拟角色的方法来解决此问题。", "method": "利用嵌入丰富人类先验知识的肖像视频生成模型合成人脸唱歌图像，并通过语义导向映射函数将这些面部特征转换到机器人上。同时提出Emotion Dynamic Range指标用于量化的评价情感表现。", "result": "实验表明，该方法能实现丰富的情感表达和唇音同步效果，显著优于现有方法。", "conclusion": "通过使用基于虚拟角色的框架，成功解决了机器人歌唱中情感表达不足的问题，并实现了高精度的唇音同步。"}}
{"id": "2601.02123", "pdf": "https://arxiv.org/pdf/2601.02123", "abs": "https://arxiv.org/abs/2601.02123", "authors": ["Po-Jen Ko", "Chen-Han Tsai", "Yu-Shao Peng"], "title": "DeCode: Decoupling Content and Delivery for Medical QA", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint", "summary": "Large language models (LLMs) exhibit strong medical knowledge and can generate factually accurate responses. However, existing models often fail to account for individual patient contexts, producing answers that are clinically correct yet poorly aligned with patients' needs. In this work, we introduce DeCode, a training-free, model-agnostic framework that adapts existing LLMs to produce contextualized answers in clinical settings. We evaluate DeCode on OpenAI HealthBench, a comprehensive and challenging benchmark designed to assess clinical relevance and validity of LLM responses. DeCode improves the previous state of the art from $28.4\\%$ to $49.8\\%$, corresponding to a $75\\%$ relative improvement. Experimental results suggest the effectiveness of DeCode in improving clinical question answering of LLMs.", "AI": {"tldr": "DeCode是一个无需训练、模型无关的框架，用于改进大型语言模型在临床环境中的问题回答能力。", "motivation": "现有模型未能充分考虑患者个体情况，在提供准确信息的同时可能无法满足患者的特定需求。因此引入了DeCode来提升LLM对临床相关性和有效性的表现。", "method": "DeCode是一个无需训练的框架，能够在不修改原有LLMs的情况下生成适合具体患者上下文的回答。它在OpenAI HealthBench上进行了评估。", "result": "DeCode将现有最佳结果从28.4%提高到了49.8%，相对提高了75%。这表明了其改进临床问题回答能力的有效性。", "conclusion": "该研究证明了通过解耦内容和传递方式可以有效提升LLMs在医学问答中的表现，从而更好地适应患者的具体需求。"}}
{"id": "2601.02121", "pdf": "https://arxiv.org/pdf/2601.02121", "abs": "https://arxiv.org/abs/2601.02121", "authors": ["En Xu", "Shihe Zhou", "Huandong Wang", "Jingtao Ding", "Yong Li"], "title": "Inferring Network Evolutionary History via Structure-State Coupled Learning", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Inferring a network's evolutionary history from a single final snapshot with limited temporal annotations is fundamental yet challenging. Existing approaches predominantly rely on topology alone, which often provides insufficient and noisy cues. This paper leverages network steady-state dynamics -- converged node states under a given dynamical process -- as an additional and widely accessible observation for network evolution history inference. We propose CS$^2$, which explicitly models structure-state coupling to capture how topology modulates steady states and how the two signals jointly improve edge discrimination for formation-order recovery. Experiments on six real temporal networks, evaluated under multiple dynamical processes, show that CS$^2$ consistently outperforms strong baselines, improving pairwise edge precedence accuracy by 4.0% on average and global ordering consistency (Spearman-$ρ$) by 7.7% on average. CS$^2$ also more faithfully recovers macroscopic evolution trajectories such as clustering formation, degree heterogeneity, and hub growth. Moreover, a steady-state-only variant remains competitive when reliable topology is limited, highlighting steady states as an independent signal for evolution inference.", "AI": {"tldr": "通过结构状态耦合学习从单个最终快照推断网络演化历史。", "motivation": "现有的方法主要依赖于网络拓扑，这往往提供不足且嘈杂的线索。本文利用网络稳态动力学作为额外和广泛可获取的观察值来改善网络演化的推断。", "method": "提出CS$^2$模型，显式地建模结构状态耦合，捕捉拓扑如何调节稳定状态，并且联合提升边排序恢复能力。", "result": "实验表明，CS$^2$在六种真实时序数据集上平均提高了4.0%的两两边缘优先级准确度和7.7%的整体排序一致性。此外，在有限可靠拓扑的情况下，仅稳态变体仍然保持竞争力。", "conclusion": "本文提出的方法能够更准确地恢复网络演化轨迹，并且稳态作为独立信号对于进化推断具有重要意义。"}}
{"id": "2601.02112", "pdf": "https://arxiv.org/pdf/2601.02112", "abs": "https://arxiv.org/abs/2601.02112", "authors": ["Utkarsh Singh", "Absaar Ali", "Adarsh Roy"], "title": "Car Drag Coefficient Prediction from 3D Point Clouds Using a Slice-Based Surrogate Model", "categories": ["cs.CV", "cs.LG"], "comment": "14 pages, 5 figures. Published in: Bramer M., Stahl F. (eds) Artificial Intelligence XLII. SGAI 2025. Lecture Notes in Computer Science, vol 16302. Springer, Cham", "summary": "The automotive industry's pursuit of enhanced fuel economy and performance necessitates efficient aerodynamic design. However, traditional evaluation methods such as computational fluid dynamics (CFD) and wind tunnel testing are resource intensive, hindering rapid iteration in the early design stages. Machine learning-based surrogate models offer a promising alternative, yet many existing approaches suffer from high computational complexity, limited interpretability, or insufficient accuracy for detailed geometric inputs. This paper introduces a novel lightweight surrogate model for the prediction of the aerodynamic drag coefficient (Cd) based on a sequential slice-wise processing of the geometry of the 3D vehicle. Inspired by medical imaging, 3D point clouds of vehicles are decomposed into an ordered sequence of 2D cross-sectional slices along the stream-wise axis. Each slice is encoded by a lightweight PointNet2D module, and the sequence of slice embeddings is processed by a bidirectional LSTM to capture longitudinal geometric evolution. The model, trained and evaluated on the DrivAerNet++ dataset, achieves a high coefficient of determination (R^2 > 0.9528) and a low mean absolute error (MAE approx 6.046 x 10^{-3}) in Cd prediction. With an inference time of approximately 0.025 seconds per sample on a consumer-grade GPU, our approach provides fast, accurate, and interpretable aerodynamic feedback, facilitating more agile and informed automotive design exploration.", "AI": {"tldr": "本文提出了一种基于顺序切片处理的轻量级代理模型，用于预测汽车的气动阻力系数。", "motivation": "传统的计算流体力学和风洞测试方法资源消耗大，限制了早期设计阶段的快速迭代。机器学习代理模型虽然有潜力，但多数存在高计算复杂性、有限可解释性和对详细几何输入精度不足的问题。", "method": "通过将汽车3D点云分解为沿流向轴的一系列2D横截面切片，并使用轻量级PointNet2D模块编码每个切片。然后，双向LSTM处理切片嵌入序列，捕捉纵向几何演变。模型在DrivAerNet++数据集上训练和评估。", "result": "该模型实现了高决定系数（R^2 > 0.9528）和低平均绝对误差（MAE约6.046e-3），预测气动阻力系数的准确性较高且推理时间快，大约为每样本0.025秒。", "conclusion": "该方法提供了快速、准确且可解释的空气动力反馈，促进了更敏捷和知情的汽车设计探索。"}}
{"id": "2601.02107", "pdf": "https://arxiv.org/pdf/2601.02107", "abs": "https://arxiv.org/abs/2601.02107", "authors": ["Jiancheng Huang", "Mingfu Yan", "Songyan Chen", "Yi Huang", "Shifeng Chen"], "title": "MagicFight: Personalized Martial Arts Combat Video Generation", "categories": ["cs.CV"], "comment": "Accepted by ACM MM 2024", "summary": "Amid the surge in generic text-to-video generation, the field of personalized human video generation has witnessed notable advancements, primarily concentrated on single-person scenarios. However, to our knowledge, the domain of two-person interactions, particularly in the context of martial arts combat, remains uncharted. We identify a significant gap: existing models for single-person dancing generation prove insufficient for capturing the subtleties and complexities of two engaged fighters, resulting in challenges such as identity confusion, anomalous limbs, and action mismatches. To address this, we introduce a pioneering new task, Personalized Martial Arts Combat Video Generation. Our approach, MagicFight, is specifically crafted to overcome these hurdles. Given this pioneering task, we face a lack of appropriate datasets. Thus, we generate a bespoke dataset using the game physics engine Unity, meticulously crafting a multitude of 3D characters, martial arts moves, and scenes designed to represent the diversity of combat. MagicFight refines and adapts existing models and strategies to generate high-fidelity two-person combat videos that maintain individual identities and ensure seamless, coherent action sequences, thereby laying the groundwork for future innovations in the realm of interactive video content creation. Website: https://MingfuYAN.github.io/MagicFight/ Dataset: https://huggingface.co/datasets/MingfuYAN/KungFu-Fiesta", "AI": {"tldr": "MagicFight致力于生成个性化武术对打视频，弥补了现有单人舞蹈生成模型无法有效捕捉两人互动复杂性的不足。", "motivation": "当前的文本到视频生成技术主要集中在单人场景上，缺乏处理双人互动特别是武术对抗的能力。现有的单人动作生成模型难以准确地表示两个人之间的交互细节。", "method": "通过使用Unity游戏引擎创建定制数据集，并改进现有模型以适应两人对打的需求，MagicFight能够生成具有高保真度的个性化武术战斗视频。", "result": "实验结果表明，MagicFight在保留个人身份的同时，能产生连贯的动作序列和真实感极强的双人互动场景。", "conclusion": "MagicFight为未来的交互式视频内容创作开辟了新的道路，并且证明了定制化数据集对于解决复杂的人体动作生成问题的重要性。"}}
{"id": "2601.02105", "pdf": "https://arxiv.org/pdf/2601.02105", "abs": "https://arxiv.org/abs/2601.02105", "authors": ["Hyunjun Kim"], "title": "LION-DG: Layer-Informed Initialization with Deep Gradient Protocols for Accelerated Neural Network Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Weight initialization remains decisive for neural network optimization, yet existing methods are largely layer-agnostic. We study initialization for deeply-supervised architectures with auxiliary classifiers, where untrained auxiliary heads can destabilize early training through gradient interference. We propose LION-DG, a layer-informed initialization that zero-initializes auxiliary classifier heads while applying standard He-initialization to the backbone. We prove that this implements Gradient Awakening: auxiliary gradients are exactly zero at initialization, then phase in naturally as weights grow -- providing an implicit warmup without hyperparameters. Experiments on CIFAR-10 and CIFAR-100 with DenseNet-DS and ResNet-DS architectures demonstrate: (1) DenseNet-DS: +8.3% faster convergence on CIFAR-10 with comparable accuracy, (2) Hybrid approach: Combining LSUV with LION-DG achieves best accuracy (81.92% on CIFAR-10), (3) ResNet-DS: Positive speedup on CIFAR-100 (+11.3%) with side-tap auxiliary design. We identify architecture-specific trade-offs and provide clear guidelines for practitioners. LION-DG is simple, requires zero hyperparameters, and adds no computational overhead.", "AI": {"tldr": "提出了一种新的初始化方法LION-DG，用于加速带有辅助分类器的深度神经网络训练。", "motivation": "现有的权重初始化方法对层缺乏针对性，可能会因为未训练的辅助头导致梯度干扰而破坏早期训练的稳定性。作者旨在通过层信息指导的初始化解决这一问题。", "method": "提出零初始化辅助分类器头部同时应用标准He初始化到主干部分的方法LION-DG，并证明该方法实现了渐进式激活（Gradient Awakening），即在初始阶段辅助梯度为零，随着权重增长自然相位进入，从而提供隐式的预热而不需要任何超参数。", "result": "实验表明，使用DenseNet-DS和ResNet-DS架构，在CIFAR-10和CIFAR-100数据集上取得了显著的速度提升，并且结合LSUV可以达到最佳精度（在CIFAR-10上为81.92%）。同时明确了不同架构之间的权衡。", "conclusion": "LION-DG方法简单，无需额外的超参数和计算开销。"}}
{"id": "2601.02103", "pdf": "https://arxiv.org/pdf/2601.02103", "abs": "https://arxiv.org/abs/2601.02103", "authors": ["Yating Wang", "Yuan Sun", "Xuan Wang", "Ran Yi", "Boyao Zhou", "Yipengjing Sun", "Hongyu Liu", "Yinuo Wang", "Lizhuang Ma"], "title": "HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures", "categories": ["cs.CV"], "comment": null, "summary": "Recent 3D-aware head generative models based on 3D Gaussian Splatting achieve real-time, photorealistic and view-consistent head synthesis. However, a fundamental limitation persists: the deep entanglement of illumination and intrinsic appearance prevents controllable relighting. Existing disentanglement methods rely on strong assumptions to enable weakly supervised learning, which restricts their capacity for complex illumination. To address this challenge, we introduce HeadLighter, a novel supervised framework that learns a physically plausible decomposition of appearance and illumination in head generative models. Specifically, we design a dual-branch architecture that separately models lighting-invariant head attributes and physically grounded rendering components. A progressive disentanglement training is employed to gradually inject head appearance priors into the generative architecture, supervised by multi-view images captured under controlled light conditions with a light stage setup. We further introduce a distillation strategy to generate high-quality normals for realistic rendering. Experiments demonstrate that our method preserves high-quality generation and real-time rendering, while simultaneously supporting explicit lighting and viewpoint editing. We will publicly release our code and dataset.", "AI": {"tldr": "提出HeadLighter框架，通过光阶段捕获学习头部生成模型中的光照和固有外观的物理上合理分解。", "motivation": "现有的解耦方法依赖于强假设以实现弱监督学习，限制了其处理复杂照明的能力。因此，开发一种可以独立控制光照和内在属性的新方法是必要的。", "method": "设计了一种双分支架构，分别建模不随光线变化的头部属性和基于物理的实际渲染组件，并通过多视图图像进行渐进式解耦训练；引入了蒸馏策略以生成高质量法线。", "result": "实验表明，该方法保持高质量生成与实时渲染的同时支持显式的光照编辑和视角更改。", "conclusion": "HeadLighter在头部合成中实现了光照与内在属性的独立控制，并且可以进行高质量的实时渲染。"}}
{"id": "2601.02102", "pdf": "https://arxiv.org/pdf/2601.02102", "abs": "https://arxiv.org/abs/2601.02102", "authors": ["Jiaqi Yao", "Zhongmiao Yan", "Jingyi Xu", "Songpengcheng Xia", "Yan Xiang", "Ling Pei"], "title": "360-GeoGS: Geometrically Consistent Feed-Forward 3D Gaussian Splatting Reconstruction for 360 Images", "categories": ["cs.CV"], "comment": null, "summary": "3D scene reconstruction is fundamental for spatial intelligence applications such as AR, robotics, and digital twins. Traditional multi-view stereo struggles with sparse viewpoints or low-texture regions, while neural rendering approaches, though capable of producing high-quality results, require per-scene optimization and lack real-time efficiency. Explicit 3D Gaussian Splatting (3DGS) enables efficient rendering, but most feed-forward variants focus on visual quality rather than geometric consistency, limiting accurate surface reconstruction and overall reliability in spatial perception tasks. This paper presents a novel feed-forward 3DGS framework for 360 images, capable of generating geometrically consistent Gaussian primitives while maintaining high rendering quality. A Depth-Normal geometric regularization is introduced to couple rendered depth gradients with normal information, supervising Gaussian rotation, scale, and position to improve point cloud and surface accuracy. Experimental results show that the proposed method maintains high rendering quality while significantly improving geometric consistency, providing an effective solution for 3D reconstruction in spatial perception tasks.", "AI": {"tldr": "该论文提出了一种新的用于360度图像的基于几何一致性的前馈3D高斯点云重建框架，旨在提高空间感知任务中的表面重建准确性。", "motivation": "传统多视角立体视觉技术在稀疏视点或低纹理区域表现不佳；神经渲染方法虽然能产生高质量结果但缺乏实时效率且需要场景特定优化。现有的基于显式3D高斯点云的方法关注于视觉质量而非几何一致性，限制了其在空间感知任务中的应用。", "method": "该论文引入了一种新的前馈3D高斯点云框架用于处理360度图像，并通过深度-法线几何正则化技术将渲染的深度梯度与法向量信息相耦合以监督高斯核旋转、尺度和位置，从而改进点云和表面准确性。", "result": "实验结果表明该方法能够在保持高质量渲染的同时显著提高几何一致性。", "conclusion": "提出的基于前馈3D高斯点云的框架为处理空间感知任务中的三维重建提供了一种有效解决方案。"}}
{"id": "2601.02101", "pdf": "https://arxiv.org/pdf/2601.02101", "abs": "https://arxiv.org/abs/2601.02101", "authors": ["Chunyu Yuan", "Johanna Devaney"], "title": "A Mamba-Based Model for Automatic Chord Recognition", "categories": ["cs.SD"], "comment": "International Society of Music Information Retrieval, Late-Breaking Demo 2024", "summary": "In this work, we propose a new efficient solution, which is a Mamba-based model named BMACE (Bidirectional Mamba-based network, for Automatic Chord Estimation), which utilizes selective structured state-space models in a bidirectional Mamba layer to effectively model temporal dependencies. Our model achieves high prediction performance comparable to state-of-the-art models, with the advantage of requiring fewer parameters and lower computational resources", "AI": {"tldr": "提出了一个基于Mamba的模型BMACE，用于自动和弦识别", "motivation": "解决当前方法参数多、计算资源需求高的问题，提出一种高效的方法来有效建模时间依赖性", "method": "利用选择性结构化状态空间模型在双向Mamba层中进行自动和弦估计", "result": "模型达到了与最先进的模型相媲美的高预测性能，并且需要更少的参数和更低的计算资源", "conclusion": "BMACE模型是一个高效且准确的方法，适用于自动和弦识别任务"}}
{"id": "2601.02099", "pdf": "https://arxiv.org/pdf/2601.02099", "abs": "https://arxiv.org/abs/2601.02099", "authors": ["Ji Yeoung Sim", "Rebecca Moranis", "Johanna Devaney"], "title": "BeatlesFC: Harmonic function annotations of Isophonics' The Beatles dataset", "categories": ["cs.SD"], "comment": "International Society for Music Information Retrieval, Late-Breaking Demo 2024", "summary": "This paper presents BeatlesFC, a set of harmonic function annotations for Isophonics' The Beatles dataset. Harmonic function annotations characterize chord labels as stable (tonic) or unstable (predominant, dominant). They operate at the level of musical phrases, serving as a link between chord labels and higher-level formal structures.", "AI": {"tldr": "本文介绍了BeatlesFC，即Isophonics的The Beatles数据集的和声功能注释", "motivation": "通过提供和声功能注释来连接音符标签与更高级别的形式结构，以更好地理解音乐作品的形式结构", "method": "基于音乐短语层面为The Beatles的数据集创建和声功能注释", "result": "成功地生成了用于Isophonics The Beatles数据集的和声功能注释", "conclusion": "通过将和弦标签转化为和声功能注释，可以更清晰地揭示音乐作品的形式结构"}}
{"id": "2601.02098", "pdf": "https://arxiv.org/pdf/2601.02098", "abs": "https://arxiv.org/abs/2601.02098", "authors": ["Jinlong Fan", "Shanshan Zhao", "Liang Zheng", "Jing Zhang", "Yuxiang Yang", "Mingming Gong"], "title": "InpaintHuman: Reconstructing Occluded Humans with Multi-Scale UV Mapping and Identity-Preserving Diffusion Inpainting", "categories": ["cs.CV"], "comment": null, "summary": "Reconstructing complete and animatable 3D human avatars from monocular videos remains challenging, particularly under severe occlusions. While 3D Gaussian Splatting has enabled photorealistic human rendering, existing methods struggle with incomplete observations, often producing corrupted geometry and temporal inconsistencies. We present InpaintHuman, a novel method for generating high-fidelity, complete, and animatable avatars from occluded monocular videos. Our approach introduces two key innovations: (i) a multi-scale UV-parameterized representation with hierarchical coarse-to-fine feature interpolation, enabling robust reconstruction of occluded regions while preserving geometric details; and (ii) an identity-preserving diffusion inpainting module that integrates textual inversion with semantic-conditioned guidance for subject-specific, temporally coherent completion. Unlike SDS-based methods, our approach employs direct pixel-level supervision to ensure identity fidelity. Experiments on synthetic benchmarks (PeopleSnapshot, ZJU-MoCap) and real-world scenarios (OcMotion) demonstrate competitive performance with consistent improvements in reconstruction quality across diverse poses and viewpoints.", "AI": {"tldr": "提出了一种从单目视频中重建完整和可动画的3D人类头像的方法InpaintHuman。", "motivation": "现有的方法在处理严重遮挡的情况下难以生成高质量且时间一致性好的3D人类头像，特别是在几何细节保留和身份保真度方面存在挑战。", "method": "引入了多尺度UV映射表示和基于扩散的身份保持修补模块，通过层次化的粗到细特征插值来重建被遮挡区域，并结合文本反转和语义指导以实现特定主体的时间一致完成。", "result": "在合成基准（PeopleSnapshot, ZJU-MoCap）和真实场景（OcMotion）上的实验表明，该方法具有竞争性的性能，在各种姿态和视角下均表现出重建质量的提升。", "conclusion": "InpaintHuman通过利用多尺度UV映射和身份保持修补技术成功解决了从遮挡的单目视频中生成高质量、完整且时间一致的人类头像的问题。"}}
{"id": "2601.02096", "pdf": "https://arxiv.org/pdf/2601.02096", "abs": "https://arxiv.org/abs/2601.02096", "authors": ["Peizhuo Li", "Sebastian Starke", "Yuting Ye", "Olga Sorkine-Hornung"], "title": "Dancing Points: Synthesizing Ballroom Dancing with Three-Point Inputs", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Ballroom dancing is a structured yet expressive motion category. Its highly diverse movement and complex interactions between leader and follower dancers make the understanding and synthesis challenging. We demonstrate that the three-point trajectory available from a virtual reality (VR) device can effectively serve as a dancer's motion descriptor, simplifying the modeling and synthesis of interplay between dancers' full-body motions down to sparse trajectories. Thanks to the low dimensionality, we can employ an efficient MLP network to predict the follower's three-point trajectory directly from the leader's three-point input for certain types of ballroom dancing, addressing the challenge of modeling high-dimensional full-body interaction. It also prevents our method from overfitting thanks to its compact yet explicit representation. By leveraging the inherent structure of the movements and carefully planning the autoregressive procedure, we show a deterministic neural network is able to translate three-point trajectories into a virtual embodied avatar, which is typically considered under-constrained and requires generative models for common motions. In addition, we demonstrate this deterministic approach generalizes beyond small, structured datasets like ballroom dancing, and performs robustly on larger, more diverse datasets such as LaFAN. Our method provides a computationally- and data-efficient solution, opening new possibilities for immersive paired dancing applications. Code and pre-trained models for this paper are available at https://peizhuoli.github.io/dancing-points.", "AI": {"tldr": "本文提出了一种使用三个点轨迹来描述和合成双人舞的舞蹈生成方法，通过MLP网络预测跟随者的动作。", "motivation": "简化对高维度双人舞互动的建模，并解决数据不足导致的过拟合问题。", "method": "利用VR设备获得的三个关键点轨迹作为运动描述符，使用MLP网络从领导者的关键点输入直接预测跟随者的关键点轨迹，再将这些轨迹转化为完整的舞蹈动作。", "result": "该方法能在小规模结构化数据集和大规模多样化数据集中表现出色，并提供了计算效率高、数据需求低的新解决方案。", "conclusion": "本文证明了三个关键点可以有效描述双人舞互动，为沉浸式跳舞应用打开了新可能。"}}
{"id": "2601.02091", "pdf": "https://arxiv.org/pdf/2601.02091", "abs": "https://arxiv.org/abs/2601.02091", "authors": ["Zhehuan Cao", "Fiseha Berhanu Tesema", "Ping Fu", "Jianfeng Ren", "Ahmed Nasr"], "title": "MCD-Net: A Lightweight Deep Learning Baseline for Optical-Only Moraine Segmentation", "categories": ["cs.CV"], "comment": "13 pages, 10 figures. This manuscript is under review at IEEE Transactions on Geoscience and Remote Sensing", "summary": "Glacial segmentation is essential for reconstructing past glacier dynamics and evaluating climate-driven landscape change. However, weak optical contrast and the limited availability of high-resolution DEMs hinder automated mapping. This study introduces the first large-scale optical-only moraine segmentation dataset, comprising 3,340 manually annotated high-resolution images from Google Earth covering glaciated regions of Sichuan and Yunnan, China. We develop MCD-Net, a lightweight baseline that integrates a MobileNetV2 encoder, a Convolutional Block Attention Module (CBAM), and a DeepLabV3+ decoder. Benchmarking against deeper backbones (ResNet152, Xception) shows that MCD-Net achieves 62.3\\% mean Intersection over Union (mIoU) and 72.8\\% Dice coefficient while reducing computational cost by more than 60\\%. Although ridge delineation remains constrained by sub-pixel width and spectral ambiguity, the results demonstrate that optical imagery alone can provide reliable moraine-body segmentation. The dataset and code are publicly available at https://github.com/Lyra-alpha/MCD-Net, establishing a reproducible benchmark for moraine-specific segmentation and offering a deployable baseline for high-altitude glacial monitoring.", "AI": {"tldr": "本文提出了一种基于轻量级深度学习的MCD-Net模型，用于光学图像上的冰碛线分割。", "motivation": "冰川分割对于重建过去的冰川动态和评估气候变化对景观的影响至关重要。然而，由于光学对比度弱和高分辨率DEM数据有限，自动映射面临挑战。", "method": "本文开发了一种新的轻量级基线MCD-Net模型，结合了MobileNetV2编码器、CBAM和DeepLabV3+解码器，并使用了一个由Google Earth提供的大规模光学图像冰碛线分割数据集进行训练。", "result": "与更深的骨干网络（ResNet152, Xception）相比，MCD-Net在减少计算成本的同时达到了62.3%的mIoU和72.8%的Dice系数。尽管山脊划分受到亚像素宽度和光谱模糊的影响，但结果表明仅使用光学图像可以提供可靠的冰碛线体分割。", "conclusion": "该数据集和代码已公开发布，并为特定于冰碛线的分割建立了可重复性基准，提供了适用于高海拔冰川监测的部署基线。"}}
{"id": "2601.02088", "pdf": "https://arxiv.org/pdf/2601.02088", "abs": "https://arxiv.org/abs/2601.02088", "authors": ["Jiahao Bao", "Huazhen Liu", "Yu Zhuang", "Leran Tao", "Xinyu Xu", "Yongtao Shi", "Mengjia Cheng", "Yiming Wang", "Congshuang Ku", "Ting Zeng", "Yilang Du", "Siyi Chen", "Shunyao Shen", "Suncheng Xiang", "Hongbo Yu"], "title": "PhysSFI-Net: Physics-informed Geometric Learning of Skeletal and Facial Interactions for Orthognathic Surgical Outcome Prediction", "categories": ["cs.CV"], "comment": "31 pages, 8 figures", "summary": "Orthognathic surgery repositions jaw bones to restore occlusion and enhance facial aesthetics. Accurate simulation of postoperative facial morphology is essential for preoperative planning. However, traditional biomechanical models are computationally expensive, while geometric deep learning approaches often lack interpretability. In this study, we develop and validate a physics-informed geometric deep learning framework named PhysSFI-Net for precise prediction of soft tissue deformation following orthognathic surgery. PhysSFI-Net consists of three components: a hierarchical graph module with craniofacial and surgical plan encoders combined with attention mechanisms to extract skeletal-facial interaction features; a Long Short-Term Memory (LSTM)-based sequential predictor for incremental soft tissue deformation; and a biomechanics-inspired module for high-resolution facial surface reconstruction. Model performance was assessed using point cloud shape error (Hausdorff distance), surface deviation error, and landmark localization error (Euclidean distances of craniomaxillofacial landmarks) between predicted facial shapes and corresponding ground truths. A total of 135 patients who underwent combined orthodontic and orthognathic treatment were included for model training and validation. Quantitative analysis demonstrated that PhysSFI-Net achieved a point cloud shape error of 1.070 +/- 0.088 mm, a surface deviation error of 1.296 +/- 0.349 mm, and a landmark localization error of 2.445 +/- 1.326 mm. Comparative experiments indicated that PhysSFI-Net outperformed the state-of-the-art method ACMT-Net in prediction accuracy. In conclusion, PhysSFI-Net enables interpretable, high-resolution prediction of postoperative facial morphology with superior accuracy, showing strong potential for clinical application in orthognathic surgical planning and simulation.", "AI": {"tldr": "开发和验证了一个名为PhysSFI-Net的基于物理信息的几何深度学习框架，用于正颌手术后软组织变形的精确预测。", "motivation": "准确模拟术后面部形态对于术前规划至关重要。然而，传统的生物力学模型计算成本高昂，而几何深度学习方法通常缺乏可解释性。", "method": "PhysSFI-Net由三个组件组成：一个分层图模块结合颅面和手术计划编码器以及注意力机制以提取骨骼-面部交互特征；基于LSTM的序列预测器用于增量软组织变形预测；生物力学启发模块用于高分辨率面部表面重建。", "result": "通过点云形状误差、表面偏差误差和地标定位误差进行了定量分析，结果表明PhysSFI-Net在135名患者的模型训练和验证中表现出色。与最新方法ACMT-Net相比，PhysSFI-Net的预测精度更高。", "conclusion": "PhysSFI-Net具有可解释性、高分辨率及优异准确性，在正颌手术规划和模拟方面展现出强大的临床应用潜力"}}
{"id": "2601.02085", "pdf": "https://arxiv.org/pdf/2601.02085", "abs": "https://arxiv.org/abs/2601.02085", "authors": ["Meili Sun", "Chunjiang Zhao", "Lichao Yang", "Hao Liu", "Shimin Hu", "Ya Xiong"], "title": "Vision-Based Early Fault Diagnosis and Self-Recovery for Strawberry Harvesting Robots", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Strawberry harvesting robots faced persistent challenges such as low integration of visual perception, fruit-gripper misalignment, empty grasping, and strawberry slippage from the gripper due to insufficient gripping force, all of which compromised harvesting stability and efficiency in orchard environments. To overcome these issues, this paper proposed a visual fault diagnosis and self-recovery framework that integrated multi-task perception with corrective control strategies. At the core of this framework was SRR-Net, an end-to-end multi-task perception model that simultaneously performed strawberry detection, segmentation, and ripeness estimation, thereby unifying visual perception with fault diagnosis. Based on this integrated perception, a relative error compensation method based on the simultaneous target-gripper detection was designed to address positional misalignment, correcting deviations when error exceeded the tolerance threshold. To mitigate empty grasping and fruit-slippage faults, an early abort strategy was implemented. A micro-optical camera embedded in the end-effector provided real-time visual feedback, enabling grasp detection during the deflating stage and strawberry slip prediction during snap-off through MobileNet V3-Small classifier and a time-series LSTM classifier. Experiments demonstrated that SRR-Net maintained high perception accuracy. For detection, it achieved a precision of 0.895 and recall of 0.813 on strawberries, and 0.972/0.958 on hands. In segmentation, it yielded a precision of 0.887 and recall of 0.747 for strawberries, and 0.974/0.947 for hands. For ripeness estimation, SRR-Net attained a mean absolute error of 0.035, while simultaneously supporting multi-task perception and sustaining a competitive inference speed of 163.35 FPS.", "AI": {"tldr": "提出了一个基于视觉的早期故障诊断与自恢复框架，用于解决草莓采摘机器人在果园环境中的稳定性及效率问题。", "motivation": "为了解决草莓收获机器人的视觉得分集成度低、果夹错位、空抓和草莓从果夹中滑出等问题，提高收割稳定性和效率。", "method": "提出了一种基于视觉的早期故障诊断与自恢复框架，并设计了SRR-Net这一端到端多任务感知模型以实现草莓检测、分割及成熟度估计。还采用了误差补偿法和提前终止策略来处理位置错位和空抓等问题，使用微光学相机提供实时反馈。", "result": "实验表明，SRR-Net在检测方面对草莓的精确率为0.895，召回率为0.813；在分割方面，草莓的精度为0.887，召回率0.747；成熟度估计误差平均值为0.035，并且保持了每秒163.35帧的竞争推理速度。", "conclusion": "该视觉故障诊断与自恢复框架成功提高了草莓收获机器人的稳定性及效率。"}}
{"id": "2601.02082", "pdf": "https://arxiv.org/pdf/2601.02082", "abs": "https://arxiv.org/abs/2601.02082", "authors": ["Yueyang Wang", "Mehmet Dogar", "Gustav Markkula"], "title": "Realistic adversarial scenario generation via human-like pedestrian model for autonomous vehicle control parameter optimisation", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "Autonomous vehicles (AVs) are rapidly advancing and are expected to play a central role in future mobility. Ensuring their safe deployment requires reliable interaction with other road users, not least pedestrians. Direct testing on public roads is costly and unsafe for rare but critical interactions, making simulation a practical alternative. Within simulation-based testing, adversarial scenarios are widely used to probe safety limits, but many prioritise difficulty over realism, producing exaggerated behaviours which may result in AV controllers that are overly conservative. We propose an alternative method, instead using a cognitively inspired pedestrian model featuring both inter-individual and intra-individual variability to generate behaviourally plausible adversarial scenarios. We provide a proof of concept demonstration of this method's potential for AV control optimisation, in closed-loop testing and tuning of an AV controller. Our results show that replacing the rule-based CARLA pedestrian with the human-like model yields more realistic gap acceptance patterns and smoother vehicle decelerations. Unsafe interactions occur only for certain pedestrian individuals and conditions, underscoring the importance of human variability in AV testing. Adversarial scenarios generated by this model can be used to optimise AV control towards safer and more efficient behaviour. Overall, this work illustrates how incorporating human-like road user models into simulation-based adversarial testing can enhance the credibility of AV evaluation and provide a practical basis to behaviourally informed controller optimisation.", "AI": {"tldr": "通过使用一个包含认知启发的行人模型来生成更加现实且行为合理的情景，以优化自主车辆（AV）控制参数。", "motivation": "当前自动驾驶汽车仿真测试中使用的对抗性情景过于夸张，可能导致自动驾驶控制系统过于保守。因此需要一种能产生更现实对抗性情景的方法，以便进行更有效的自动驾驶系统优化和安全测试。", "method": "提出了一种新的方法，该方法使用一个具有认知启发的行人模型来生成行为合理的对抗性情景，并在封闭循环测试中证明了这种方法的有效性。", "result": "实验结果表明，将规则驱动的CARLA行人模型替换为人形模型后，自主车辆与行人间的安全交互更为真实且平滑。这强调了人形变量对于自动驾驶汽车评估的重要性。", "conclusion": "此研究展示了如何通过在仿真测试中使用行为更接近人类的行人模型来增强对自动驾驶系统的评估，并为基于行为信息的控制器优化提供了实际基础。"}}
{"id": "2601.02080", "pdf": "https://arxiv.org/pdf/2601.02080", "abs": "https://arxiv.org/abs/2601.02080", "authors": ["Yizhi Liu"], "title": "The Homogeneity Trap: Spectral Collapse in Doubly-Stochastic Deep Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Doubly-stochastic matrices (DSM) are increasingly utilized in structure-preserving deep architectures -- such as Optimal Transport layers and Sinkhorn-based attention -- to enforce numerical stability and probabilistic interpretability. In this work, we identify a critical spectral degradation phenomenon inherent to these constraints, termed the Homogeneity Trap. We demonstrate that the maximum-entropy bias, typical of Sinkhorn-based projections, drives the mixing operator towards the uniform barycenter, thereby suppressing the subdominant singular value σ_2 and filtering out high-frequency feature components. We derive a spectral bound linking σ_2 to the network's effective depth, showing that high-entropy constraints restrict feature transformation to a shallow effective receptive field. Furthermore, we formally demonstrate that Layer Normalization fails to mitigate this collapse in noise-dominated regimes; specifically, when spectral filtering degrades the Signal-to-Noise Ratio (SNR) below a critical threshold, geometric structure is irreversibly lost to noise-induced orthogonal collapse. Our findings highlight a fundamental trade-off between entropic stability and spectral expressivity in DSM-constrained networks.", "AI": {"tldr": "探讨双重随机矩阵约束下的深度网络所面临的同质陷阱现象，分析其对网络性能的影响。", "motivation": "揭示双重随机矩阵在结构保持的深层架构中引入的最大熵偏倚导致了次主导奇异值σ2被抑制和高频特征组件丢失的现象，影响网络的有效表示能力。", "method": "通过推导与次主导奇异值σ2相关的谱界以及深度的关系，证明了高熵约束限制了特征转换的有效感受野。同时，展示了层归一化在噪声占优的情形下无法缓解这种塌陷现象。", "result": "识别并量化了由最大熵偏倚和双重随机矩阵导致的同质陷阱现象对网络性能的影响，特别是在信号与噪声比下降至临界阈值时所引起的几何结构丢失问题。", "conclusion": "发现了一种在基于Sinkhorn投影和双重随机矩阵约束下的深层架构中普遍存在的根本性权衡：熵稳定性和谱表达能力之间的平衡。"}}
{"id": "2601.02078", "pdf": "https://arxiv.org/pdf/2601.02078", "abs": "https://arxiv.org/abs/2601.02078", "authors": ["Chenghao Yin", "Da Huang", "Di Yang", "Jichao Wang", "Nanshu Zhao", "Chen Xu", "Wenjun Sun", "Linjie Hou", "Zhijun Li", "Junhui Wu", "Zhaobo Liu", "Zhen Xiao", "Sheng Zhang", "Lei Bao", "Rui Feng", "Zhenquan Pang", "Jiayu Li", "Qian Wang", "Maoqing Yao"], "title": "Genie Sim 3.0 : A High-Fidelity Comprehensive Simulation Platform for Humanoid Robot", "categories": ["cs.RO"], "comment": null, "summary": "The development of robust and generalizable robot learning models is critically contingent upon the availability of large-scale, diverse training data and reliable evaluation benchmarks. Collecting data in the physical world poses prohibitive costs and scalability challenges, and prevailing simulation benchmarks frequently suffer from fragmentation, narrow scope, or insufficient fidelity to enable effective sim-to-real transfer. To address these challenges, we introduce Genie Sim 3.0, a unified simulation platform for robotic manipulation. We present Genie Sim Generator, a large language model (LLM)-powered tool that constructs high-fidelity scenes from natural language instructions. Its principal strength resides in rapid and multi-dimensional generalization, facilitating the synthesis of diverse environments to support scalable data collection and robust policy evaluation. We introduce the first benchmark that pioneers the application of LLM for automated evaluation. It leverages LLM to mass-generate evaluation scenarios and employs Vision-Language Model (VLM) to establish an automated assessment pipeline. We also release an open-source dataset comprising more than 10,000 hours of synthetic data across over 200 tasks. Through systematic experimentation, we validate the robust zero-shot sim-to-real transfer capability of our open-source dataset, demonstrating that synthetic data can server as an effective substitute for real-world data under controlled conditions for scalable policy training. For code and dataset details, please refer to: https://github.com/AgibotTech/genie_sim.", "AI": {"tldr": "介绍了一种新的仿真平台Genie Sim 3.0，该平台通过自然语言指令生成高保真场景，支持大规模数据收集和策略评估。", "motivation": "为了解决物理世界中数据收集成本高昂和规模化挑战，以及现有模拟基准的碎片化、范围狭窄或保真度不足的问题，提出了一种新的仿真平台来提高从模拟到现实的任务迁移能力。", "method": "通过大型语言模型（LLM）构建高保真的场景生成器，并引入了第一个使用LLM进行自动化评估的基准测试，利用视觉-语言模型（VLM）建立自动评估流水线。此外，还发布了一个开源数据集，包含超过10,000小时的数据。", "result": "通过系统的实验验证了该开源数据集在零样本从模拟到现实的任务迁移中的鲁棒性，展示了合成数据可以在受控条件下作为真实世界数据的有效替代品进行大规模策略训练。", "conclusion": "Genie Sim 3.0提供了高保真的场景生成和自动化评估能力，证明了使用合成数据可以提高机器人学习模型的稳健性和可扩展性。"}}
{"id": "2601.02076", "pdf": "https://arxiv.org/pdf/2601.02076", "abs": "https://arxiv.org/abs/2601.02076", "authors": ["Yingte Shu", "Yuchuan Tian", "Chao Xu", "Yunhe Wang", "Hanting Chen"], "title": "Deferred Commitment Decoding for Diffusion Language Models with Confidence-Aware Sliding Windows", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Diffusion language models (DLMs) have recently emerged as a strong alternative to autoregressive models by enabling parallel text generation. To improve inference efficiency and KV-cache compatibility, prior work commonly adopts block-based diffusion, decoding tokens block by block. However, this paradigm suffers from a structural limitation that we term Boundary-Induced Context Truncation (BICT): undecoded tokens near block boundaries are forced to commit without access to nearby future context, even when such context could substantially reduce uncertainty. This limitation degrades decoding confidence and generation quality, especially for tasks requiring precise reasoning, such as mathematical problem solving and code generation. We propose Deferred Commitment Decoding (DCD), a novel, training-free decoding strategy that mitigates this issue. DCD maintains a confidence-aware sliding window over masked tokens, resolving low-uncertainty tokens early while deferring high-uncertainty tokens until sufficient contextual evidence becomes available. This design enables effective bidirectional information flow within the decoding window without sacrificing efficiency. Extensive experiments across multiple diffusion language models, benchmarks, and caching configurations show that DCD improves generation accuracy by 1.39% with comparable time on average compared to fixed block-based diffusion methods, with the most significant improvement reaching 9.0%. These results demonstrate that deferring token commitment based on uncertainty is a simple yet effective principle for improving both the quality and efficiency of diffusion language model decoding.", "AI": {"tldr": "本文提出了Deferred Commitment Decoding (DCD)，一种新的解码策略，旨在提高扩散语言模型的生成质量和效率。", "motivation": "传统块式扩散解码方法存在边界诱导上下文截断问题，导致未解析令牌在缺乏附近未来上下文的情况下进行承诺，降低了解码信心和生成质量，特别是在需要精确推理的任务中表现不佳。", "method": "DCD通过维护一个针对掩蔽令牌的信心感知滑动窗口，在不确定性较低时提前解决令牌，而在有足够的上下文证据之前推迟高不确定性的令牌。此设计在不牺牲效率的情况下实现了解码窗口内的双向信息流动。", "result": "实验结果表明，与固定块式扩散方法相比，DCD提高了1.39%的生成精度，且平均时间相当，最高改善可达9%。", "conclusion": "推迟基于不确定性令牌承诺的原则简单而有效，可以提高扩散语言模型解码的质量和效率。"}}
{"id": "2601.02072", "pdf": "https://arxiv.org/pdf/2601.02072", "abs": "https://arxiv.org/abs/2601.02072", "authors": ["Haato Watanabe", "Nobuyuki Umetani"], "title": "SketchRodGS: Sketch-based Extraction of Slender Geometries for Animating Gaussian Splatting Scenes", "categories": ["cs.GR", "cs.CV"], "comment": "Presented at SIGGRAPH Asia 2025 (Technical Communications). Best Technical Communications Award", "summary": "Physics simulation of slender elastic objects often requires discretization as a polyline. However, constructing a polyline from Gaussian splatting is challenging as Gaussian splatting lacks connectivity information and the configuration of Gaussian primitives contains much noise. This paper presents a method to extract a polyline representation of the slender part of the objects in a Gaussian splatting scene from the user's sketching input. Our method robustly constructs a polyline mesh that represents the slender parts using the screen-space shortest path analysis that can be efficiently solved using dynamic programming. We demonstrate the effectiveness of our approach in several in-the-wild examples.", "AI": {"tldr": "从用户的手绘输入中提取高斯点场景中的细长部分的线段表示。", "motivation": "在物理模拟中，将纤细弹性物体离散化为折线是必要的。然而，通过高斯点缺乏连接信息和配置噪声使得构造折线成为难题。", "method": "利用屏幕空间最短路径分析从用户的手绘输入中提取纤细部分的折线表示，并使用动态规划高效求解该问题。", "result": "在几个真实世界示例中展示了所提方法的有效性。", "conclusion": "提出了一种通过手绘输入来构建高斯点场景中的纤细物体折线表示的方法，解决了缺乏连接信息和配置噪声的问题。"}}
{"id": "2601.02071", "pdf": "https://arxiv.org/pdf/2601.02071", "abs": "https://arxiv.org/abs/2601.02071", "authors": ["Adeshola Okubena", "Yusuf Ali Mohammed", "Moe Elbadawi"], "title": "FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations", "categories": ["cs.AI"], "comment": null, "summary": "Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.", "AI": {"tldr": "研究使用大型语言模型（LLM）来生成新型可打印的三维制剂配方。", "motivation": "通过利用人工智能加速药物三维度打印的方法开发，以实现个性化给药形式。现有的AI方法大多局限于特定领域，未能解决更广泛的制剂挑战。", "method": "研究人员将四个不同的LLM架构在包含1400多个配方的数据集上进行了微调，并对模型推荐辅料和预测材料性能的能力进行了评估。", "result": "结果显示Llama2最适合于FDM配方的辅助成分推荐，表明小规模数据可能导致模型灾难性遗忘，标准语言评价指标无法衡量制剂过程性。", "conclusion": "解决这些挑战对于将LLM从单纯的语言能力提升到可靠的药物配方开发系统是至关重要的。"}}
{"id": "2601.02065", "pdf": "https://arxiv.org/pdf/2601.02065", "abs": "https://arxiv.org/abs/2601.02065", "authors": ["Md. Asif Hossain", "Nabil Subhan", "Mantasha Rahman Mahi", "Jannatul Ferdous Nabila"], "title": "Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource Languages: A Case Study in Bengali Agricultural Advisory", "categories": ["cs.CL", "cs.AI"], "comment": "5 pages, 3 figures, 1 table", "summary": "Access to reliable agricultural advisory remains limited in many developing regions due to a persistent language barrier: authoritative agricultural manuals are predominantly written in English, while farmers primarily communicate in low-resource local languages such as Bengali. Although recent advances in Large Language Models (LLMs) enable natural language interaction, direct generation in low-resource languages often exhibits poor fluency and factual inconsistency, while cloud-based solutions remain cost-prohibitive. This paper presents a cost-efficient, cross-lingual Retrieval-Augmented Generation (RAG) framework for Bengali agricultural advisory that emphasizes factual grounding and practical deployability. The proposed system adopts a translation-centric architecture in which Bengali user queries are translated into English, enriched through domain-specific keyword injection to align colloquial farmer terminology with scientific nomenclature, and answered via dense vector retrieval over a curated corpus of English agricultural manuals (FAO, IRRI). The generated English response is subsequently translated back into Bengali to ensure accessibility. The system is implemented entirely using open-source models and operates on consumer-grade hardware without reliance on paid APIs. Experimental evaluation demonstrates reliable source-grounded responses, robust rejection of out-of-domain queries, and an average end-to-end latency below 20 seconds. The results indicate that cross-lingual retrieval combined with controlled translation offers a practical and scalable solution for agricultural knowledge access in low-resource language settings", "AI": {"tldr": "本文提出了一种低成本的跨语言检索增强生成框架，用于低资源语言（如孟加拉语）农业咨询。", "motivation": "在许多发展中国家，农民难以获得可靠的信息来源，因为权威性较强的农业手册通常用英语编写，而农民主要使用本地语言。直接使用大模型生成这些内容可能导致事实错误和不流畅，云解决方案也成本高昂。", "method": "该框架采用翻译为中心的架构，首先将孟加拉语问题转换为英文，并通过注入领域特定关键字来提高检索准确性；然后在经过精心准备的知识库中进行密集向量检索以找到相关答案；最后再把生成的答案从英语翻译回孟加拉语。", "result": "实验结果表明所提出的方法能够提供可靠的事实依据，具有处理无关请求的能力，并且平均延迟低于20秒。这种方法为低资源语言环境中的农业知识获取提供了一种可行和可扩展的解决方案。", "conclusion": "本文证明了通过结合跨语言检索与控制翻译可以解决低资源语言环境中农民难以获得准确信息的问题，同时保持成本效益，具有实际应用价值。"}}
{"id": "2601.02061", "pdf": "https://arxiv.org/pdf/2601.02061", "abs": "https://arxiv.org/abs/2601.02061", "authors": ["Faizan Ahmed", "Aniket Dixit", "James Brusey"], "title": "Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management", "categories": ["cs.AI", "cs.LG"], "comment": "6 pages, accepted at NeurIPS workshop 2025", "summary": "Deep reinforcement learning agents often exhibit erratic, high-frequency control behaviors that hinder real-world deployment due to excessive energy consumption and mechanical wear. We systematically investigate action smoothness regularization through higher-order derivative penalties, progressing from theoretical understanding in continuous control benchmarks to practical validation in building energy management. Our comprehensive evaluation across four continuous control environments demonstrates that third-order derivative penalties (jerk minimization) consistently achieve superior smoothness while maintaining competitive performance. We extend these findings to HVAC control systems where smooth policies reduce equipment switching by 60%, translating to significant operational benefits. Our work establishes higher-order action regularization as an effective bridge between RL optimization and operational constraints in energy-critical applications.", "AI": {"tldr": "通过研究高阶导数惩罚在连续控制基准中的理论理解和实际验证，探讨深度强化学习代理在建筑物能源管理中采用平滑动作正则化的方法。", "motivation": "深度强化学习代理常常表现出不规则、高频的控制行为，这阻碍了其现实世界的应用。此类行为可能导致能量消耗过大及机械磨损，因此需要探索如何通过高阶导数惩罚来实现行动平稳性。", "method": "系统地研究了连续控制基准中动作平滑度正则化，并将此方法应用于HVAC控制系统。研究表明第三阶导数惩罚（即减少震动）能够保持性能的同时提高行为的平滑程度。", "result": "在四个连续控制环境中，第三阶导数惩罚展示了优越的动作平稳性且不影响性能表现；而当应用到HVAC系统时，此类政策可将设备切换次数降低60%，从而带来显著的操作效益。", "conclusion": "本研究证明了高阶动作正则化是深度强化学习优化与能源关键应用场景操作约束之间有效桥梁。"}}
{"id": "2601.02060", "pdf": "https://arxiv.org/pdf/2601.02060", "abs": "https://arxiv.org/abs/2601.02060", "authors": ["Nguyet-Anh H. Lang", "Eric Lang", "Thanh Le-Cong", "Bach Le", "Quyet-Thang Huynh"], "title": "Perish or Flourish? A Holistic Evaluation of Large Language Models for Code Generation in Functional Programming", "categories": ["cs.PL", "cs.AI", "cs.SE"], "comment": null, "summary": "Functional programming provides strong foundations for developing reliable and secure software systems, yet its adoption remains not widespread due to the steep learning curve. Recent advances in Large Language Models (LLMs) for code generation present new opportunities to lower these barriers. However, extensive evaluations of LLMs largely focus on imperative programming languages, and their capabilities in functional programming languages (FP) remain underexplored. To address this gap, we introduce FPEval, a holistic evaluation framework built on FPBench, a new benchmark of 721 programming tasks across three difficulty levels on three mainstream FP languages: Haskell, Ocaml and Scala. FPEval provides compehensive evaluation infrastructures with both test validations with comprehensive test suites and static analysis tools to assess both functional correctness and code style and maintainability. Using this framework, we evaluate state-of-the-art LLMs, including GPT-3.5, GPT-4o, and GPT-5, for code generation in functional programming languages and Java as an imperative baseline. Our results demonstrate that LLM performance in functional programming improves substantially with model advancement; however, error rates remain significantly higher in purely functional languages (Haskell and OCaml) than in hybrid (Scala) or imperative (Java) languages. Moreover, LLMs frequently generate non-idiomatic functional code that follows imperative patterns, raising concerns about code style and long-term maintainability. Finally, we show that LLMs can partially self-repair both correctness and quality issues when provided with static analysis feedback and hand-crafted instructions for common types of issues.", "AI": {"tldr": "该论文提出并使用FPEval框架评估了大型语言模型在功能编程中的代码生成能力。", "motivation": "为了降低功能性编程的学习曲线，并填补现有研究中关于大型语言模型在功能性编程方面性能的研究空白，作者提出了一个全面的评价框架FPEval。", "method": "构建了一个基于FPBench的新基准库，涵盖721个程序任务，涉及三种主流功能编程语言：Haskell、Ocaml和Scala。利用这个框架评估了包括GPT-3.5、GPT-4o和GPT-5在内的最先进的大型语言模型的代码生成能力。", "result": "随着模型的进步，LLM在功能性编程中的性能有所提高；然而，在纯功能语言中的错误率仍然显著高于混合或命令式语言。此外，LLM倾向于生成非惯用的功能性代码，并且经常出现代码样式和长期维护性的问题。", "conclusion": "结果表明，大型语言模型可以部分自我修复正确性和质量问题，当提供静态分析反馈和针对常见类型问题的手动指令时。"}}
{"id": "2601.02047", "pdf": "https://arxiv.org/pdf/2601.02047", "abs": "https://arxiv.org/abs/2601.02047", "authors": ["Thomas Krämer", "Daniel Hienert", "Francesco Chiossi", "Thomas Kosch", "Dagmar Kern"], "title": "Escaping the Filter Bubble: Evaluating Electroencephalographic Theta Band Synchronization as Indicator for Selective Exposure in Online News Reading", "categories": ["cs.HC"], "comment": "ef:In CHI EA 2025: Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, edited by Naomi Yamashita, Vanessa Evers, Koji Yatani, and Xianghua Sharon Ding, 228. New York: ACM", "summary": "Selective exposure to online news occurs when users favor information that confirms their beliefs, creating filter bubbles and limiting diverse perspectives. Interactive systems can counter this by recommending different perspectives, but to achieve this, they need a real-time metric for selective exposure. We present an experiment where we evaluate Electroencephalography (EEG) and eye tracking as indicators for selective exposure by using eye tracking to recognize which textual parts participants read and using EEG to quantify the magnitude of selective exposure. Participants read online news while we collected EEG and eye movements with their agreement towards the news. We show that the agreement with news correlates positively with the theta band power in the parietal area. Our results indicate that future interactive systems can sense selective exposure using EEG and eye tracking to propose a more balanced information diet. This work presents an integrated experimental setup that identifies selective exposure using gaze and EEG-based metrics.", "AI": {"tldr": "使用EEG和眼动追踪技术来评估在线新闻阅读过程中的选择性曝光。", "motivation": "为了减少用户只接触符合自己信念的网络信息，形成过滤气泡的现象，研究开发了一种可以实时衡量选择性暴露的方法。", "method": "参与者在进行在线新闻阅读时佩戴EEG设备和眼动追踪仪器，并记录他们对文章各部分的兴趣程度及相应的脑电波变化，通过分析发现，用户对于新闻内容的赞同度与大脑顶叶区域的θ频段功率成正比关系。", "result": "实验结果表明，可以利用EEG和眼动追踪来检测选择性曝光，并据此为用户提供更加平衡的信息推荐。", "conclusion": "本研究提出了一种结合了EEG和眼动追踪技术的新方法，能够实时感知用户的选择性暴露程度，有助于打破信息过滤气泡。"}}
{"id": "2601.02046", "pdf": "https://arxiv.org/pdf/2601.02046", "abs": "https://arxiv.org/abs/2601.02046", "authors": ["Shaocheng Shen", "Jianfeng Liang. Chunlei Cai", "Cong Geng", "Huiyu Duan", "Xiaoyun Zhang", "Qiang Hu", "Guangtao Zhai"], "title": "Agentic Retoucher for Text-To-Image Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.", "AI": {"tldr": "提出了一种名为Agentic Retoucher的框架，用于改进文本到图像生成模型中的小规模失真问题。", "motivation": "现有的T2I扩散模型虽然在光度逼真方面表现良好，但仍存在肢体、面部和文字等区域的小规模失真。为了弥补这一不足，提出了Agentic Retoucher以解决这些问题。", "method": "设计了一种基于感知-推理-行动循环的人工智能框架来修正生成图像中的局部瑕疵，包括一个学习文本与图像一致性线索下的上下文显著性的感知代理、进行逐步偏好对齐的诊断推理代理和根据用户偏好的自适应规划局部上色的行动代理。", "result": "实验表明，Agentic Retoucher在感知质量、失真定位以及人类偏好对齐方面均优于当前最优方法。", "conclusion": "提出了新的文本到图像生成模型自我纠正的范式，提高了图像生成过程中的视觉可靠性和用户满意度。"}}
{"id": "2601.02045", "pdf": "https://arxiv.org/pdf/2601.02045", "abs": "https://arxiv.org/abs/2601.02045", "authors": ["Shuoming Zhang", "Jiacheng Zhao", "Qiuchu Yu", "Chunwei Xia", "Zheng Wang", "Xiaobing Feng", "Huimin Cui"], "title": "The New Compiler Stack: A Survey on the Synergy of LLMs and Compilers", "categories": ["cs.PL", "cs.AI", "cs.SE"], "comment": "Accepted by CCF Transactions on High Performance Computing", "summary": "This survey has provided a systematic overview of the emerging field of LLM-enabled compilation by addressing several key research questions. We first answered how LLMs are being integrated by proposing a comprehensive, multi-dimensional taxonomy that categorizes works based on their Design Philosophy (Selector, Translator, Generator), LLM Methodology, their operational Level of Code Abstraction, and the specific Task Type they address. In answering what advancements these approaches offer, we identified three primary benefits: the democratization of compiler development, the discovery of novel optimization strategies, and the broadening of the compiler's traditional scope. Finally, in addressing the field's challenges and opportunities, we highlighted the critical hurdles of ensuring correctness and achieving scalability, while identifying the development of hybrid systems as the most promising path forward. By providing these answers, this survey serves as a foundational roadmap for researchers and practitioners, charting the course for a new generation of LLM-powered, intelligent, adaptive and synergistic compilation tools.", "AI": {"tldr": "本论文提供了LLM（大型语言模型）在编译器领域的系统性综述，涵盖了设计哲学、方法论和任务类型等多个维度。", "motivation": "为了回答如何将LLM集成到编译过程中以及这些方法带来了哪些进步，并探讨该领域面临的挑战与机遇", "method": "提出了一个多维分类法来对现有的工作进行分类，基于它们的设计理念（选择器、翻译者、生成器）、LLM的方法论及其操作的代码抽象级别和具体任务类型。", "result": "识别出了三个主要的好处：编译器开发的民主化、新优化策略的发现以及扩展了传统的编译范围。同时也强调了一些关键挑战，包括确保正确性和实现可扩展性。", "conclusion": "该综述为研究人员和从业人员提供了一个基础路线图，并指明了新一代LLM驱动的智能、自适应且协同工作的编译工具的发展方向。"}}
{"id": "2601.02044", "pdf": "https://arxiv.org/pdf/2601.02044", "abs": "https://arxiv.org/abs/2601.02044", "authors": ["Daniel Hienert", "Heiko Schmidt", "Thomas Krämer", "Dagmar Kern"], "title": "EyeLiveMetrics: Real-time Analysis of Online Reading with Eye Tracking", "categories": ["cs.HC"], "comment": "ef:In Proceedings of the 2024 Symposium on Eye Tracking Research and Applications, edited by Mohamed Khamis, Yusuke Sugano, and Ludwig Sidenmark, 81, 1-7. New York: ACM", "summary": "Existing eye tracking software have certain limitations, especially with respect to monitoring reading online: (1) Most eye tracking software record eye tracking data as raw coordinates and stimuli as screen images/videos, but without inherent links between both. Analysts must draw areas of interest (AOIs) on webpage text for more fine-grained reading analysis. (2) The computation and analysis of fixation and reading metrics are done after the experiment and thus cannot be used for live applications. We present EyeLiveMetrics, a browser plugin that automatically maps raw gaze coordinates to text in real time. The plugin instantly calculates, stores, and provides fixation, saccade, and reading measures on words and paragraphs so that gaze behavior can be analyzed immediately. We also discuss the results of a comparative evaluation. EyeLiveMetrics offers a flexible way to measure reading on the web - for research experiments and live applications.", "AI": {"tldr": "EyeLiveMetrics是一款浏览器插件，能够实现实时的眼动跟踪分析，并将原始注视坐标自动映射到文本上。", "motivation": "现有的眼动追踪软件在在线阅读监测方面存在一定的局限性。这些工具通常记录的是原始的坐标准确位置和屏幕图像/视频，而没有内在地链接两者。此外，计算和分析凝视点和阅读指标的操作是在实验之后进行的，无法用于实时应用。", "method": "EyeLiveMetrics作为一个浏览器插件，在线实现实时眼动数据分析，将原始注视坐标自动映射到文本中，并即时计算、存储并提供单词和段落上的固定、扫视和其他阅读度量。此外，还进行了比较性评估以验证其效果。", "result": "通过EyeLiveMetrics的实施和使用，能够实时获取更加细化的眼动数据分析结果，如凝视点和扫描路径等，并且可以应用于研究实验及实际应用场景中。", "conclusion": "EyeLiveMetrics为在线阅读行为提供了灵活而高效的研究工具，适用于科学研究以及实时应用需求。"}}
{"id": "2601.02043", "pdf": "https://arxiv.org/pdf/2601.02043", "abs": "https://arxiv.org/abs/2601.02043", "authors": ["Hendrik Kempt", "Alon Lavie"], "title": "Simulated Reasoning is Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "21 pages", "summary": "Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., \"symbolic reasoning\". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can \"reason\" by way of imitating the process of \"thinking out loud\", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the \"stochastic parrot\" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.", "AI": {"tldr": "探讨模拟推理的本质及其与人类推理的区别。", "motivation": "质疑传统的符号推理观点，提出基础模型（FM）通过模仿思维过程来进行推理，并讨论这种新形式的推理对安全性和适当性考虑的影响。", "method": "提供几种哲学解释来说明这种现象，放弃“随机鹦鹉”这一比喻，并反思由此产生的安全性与适当性的规范元素。", "result": "揭示了基础模型在无根基和常识缺乏的情况下进行推理的能力及其潜在的风险。", "conclusion": "基础模型的模拟推理挑战了传统意义上的必要条件，并强调需要重新评估安全性和适当性考虑以应对这些新形式的推理。"}}
{"id": "2601.02038", "pdf": "https://arxiv.org/pdf/2601.02038", "abs": "https://arxiv.org/abs/2601.02038", "authors": ["Yihan Zhu", "Mengying Ge"], "title": "AlignVTOFF: Texture-Spatial Feature Alignment for High-Fidelity Virtual Try-Off", "categories": ["cs.CV"], "comment": null, "summary": "Virtual Try-Off (VTOFF) is a challenging multimodal image generation task that aims to synthesize high-fidelity flat-lay garments under complex geometric deformation and rich high-frequency textures. Existing methods often rely on lightweight modules for fast feature extraction, which struggles to preserve structured patterns and fine-grained details, leading to texture attenuation during generation.To address these issues, we propose AlignVTOFF, a novel parallel U-Net framework built upon a Reference U-Net and Texture-Spatial Feature Alignment (TSFA). The Reference U-Net performs multi-scale feature extraction and enhances geometric fidelity, enabling robust modeling of deformation while retaining complex structured patterns. TSFA then injects the reference garment features into a frozen denoising U-Net via a hybrid attention design, consisting of a trainable cross-attention module and a frozen self-attention module. This design explicitly aligns texture and spatial cues and alleviates the loss of high-frequency information during the denoising process.Extensive experiments across multiple settings demonstrate that AlignVTOFF consistently outperforms state-of-the-art methods, producing flat-lay garment results with improved structural realism and high-frequency detail fidelity.", "AI": {"tldr": "本文提出了AlignVTOFF，一种新的平行U-Net框架，旨在通过纹理空间特征对齐来生成高保真度的虚拟试衣图像。", "motivation": "现有的方法在处理复杂几何变形和丰富高频纹理时难以保留结构模式和细粒度细节，导致纹理衰减。因此，提出了AlignVTOFF以解决这一问题。", "method": "提出了一种基于参考U-Net和纹理空间特征对齐（TSFA）的新平行U-Net框架，其中参考U-Net进行多尺度特征提取并增强几何保真度，TSFA则通过混合注意力设计将参考衣物的特征注入冻结去噪U-Net中。", "result": "广泛的实验表明，AlignVTOFF在多种设置下始终优于现有方法，生成了结构更加真实的平面布局图像，并且高频细节的保真度更高。", "conclusion": "提出的AlignVTOFF框架有效地解决了虚拟试衣过程中纹理衰减的问题，在保持结构模式的同时提升了高频细节的保真度。"}}
{"id": "2601.02036", "pdf": "https://arxiv.org/pdf/2601.02036", "abs": "https://arxiv.org/abs/2601.02036", "authors": ["Yiyang Wang", "Xi Chen", "Xiaogang Xu", "Yu Liu", "Hengshuang Zhao"], "title": "GDRO: Group-level Reward Post-training Suitable for Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Recent advancements adopt online reinforcement learning (RL) from LLMs to text-to-image rectified flow diffusion models for reward alignment. The use of group-level rewards successfully aligns the model with the targeted reward. However, it faces challenges including low efficiency, dependency on stochastic samplers, and reward hacking. The problem is that rectified flow models are fundamentally different from LLMs: 1) For efficiency, online image sampling takes much more time and dominates the time of training. 2) For stochasticity, rectified flow is deterministic once the initial noise is fixed. Aiming at these problems and inspired by the effects of group-level rewards from LLMs, we design Group-level Direct Reward Optimization (GDRO). GDRO is a new post-training paradigm for group-level reward alignment that combines the characteristics of rectified flow models. Through rigorous theoretical analysis, we point out that GDRO supports full offline training that saves the large time cost for image rollout sampling. Also, it is diffusion-sampler-independent, which eliminates the need for the ODE-to-SDE approximation to obtain stochasticity. We also empirically study the reward hacking trap that may mislead the evaluation, and involve this factor in the evaluation using a corrected score that not only considers the original evaluation reward but also the trend of reward hacking. Extensive experiments demonstrate that GDRO effectively and efficiently improves the reward score of the diffusion model through group-wise offline optimization across the OCR and GenEval tasks, while demonstrating strong stability and robustness in mitigating reward hacking.", "AI": {"tldr": "本文提出了一种适用于扩散模型的群体级别奖励后训练优化方法GDRO。", "motivation": "现有在线强化学习技术在图像生成中效率低，依赖于随机抽样器，并容易受到奖励作弊的影响。为此，设计了适合扩散模型特性的群体直接奖励优化（GDRO）方法。", "method": "通过严格理论分析和实验研究，提出了GDRO，支持全离线训练以节省大量采样时间；并消除了对ODE到SDE的近似转换的需求，实现了与抽样器无关性。同时考虑了奖励作弊对评估的影响，引入修正得分用于评价。", "result": "通过广泛的实验验证了GDRO在OCR和GenEval任务中提高了扩散模型的奖励分数，并展示了强大的稳定性和抗奖励作弊能力。", "conclusion": "GDRO能够有效地提高图像生成模型的性能，同时解决效率低下、依赖抽样器及奖励作弊问题。"}}
{"id": "2601.02031", "pdf": "https://arxiv.org/pdf/2601.02031", "abs": "https://arxiv.org/abs/2601.02031", "authors": ["Felix Stollenwerk", "Anna Lokrantz", "Niclas Hertzberg"], "title": "Output Embedding Centering for Stable LLM Pretraining", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "11 pages, 5 figures", "summary": "Pretraining of large language models is not only expensive but also prone to certain training instabilities. A specific instability that often occurs for large learning rates at the end of training is output logit divergence. The most widely used mitigation strategy, z-loss, merely addresses the symptoms rather than the underlying cause of the problem. In this paper, we analyze the instability from the perspective of the output embeddings' geometry and identify its cause. Based on this, we propose output embedding centering (OEC) as a new mitigation strategy, and prove that it suppresses output logit divergence. OEC can be implemented in two different ways, as a deterministic operation called μ-centering, or a regularization method called μ-loss. Our experiments show that both variants outperform z-loss in terms of training stability and learning rate sensitivity. In particular, they ensure that training converges even for large learning rates when z-loss fails. Furthermore, we find that μ-loss is significantly less sensitive to regularization hyperparameter tuning than z-loss.", "AI": {"tldr": "研究提出了一种新的预训练大型语言模型的稳定性策略，即输出嵌入中心化(OEC)，以解决大学习率后期训练中的输出逻辑发散问题。", "motivation": "当前最广泛使用的缓解策略z-loss只能解决症状而非根本原因。因此，作者从输出嵌入的几何形状角度分析并识别了这种不稳定性的根源，并提出了OEC作为新的缓解策略。", "method": "提出了一种名为输出嵌入中心化(OEC)的新方法来解决这个问题，这种方法可以通过确定性操作μ-centering或正则化方法μ-loss实施。这两种方式都在实验中得到了验证。", "result": "实验证明了两种OEC变体在训练稳定性方面都优于z-loss，并且对于大学习率的敏感度更低，甚至当z-loss无法使模型收敛时，它们仍能使训练成功完成。", "conclusion": "新提出的输出嵌入中心化策略(OEC)可以更有效地解决预训练大型语言模型中的输出逻辑发散问题，相较于现有的方法更具优势。"}}
{"id": "2601.02029", "pdf": "https://arxiv.org/pdf/2601.02029", "abs": "https://arxiv.org/abs/2601.02029", "authors": ["Toshihiko Nishimura", "Hirofumi Abe", "Kazuhiko Murasaki", "Taiga Yoshida", "Ryuichi Tanida"], "title": "Leveraging 2D-VLM for Label-Free 3D Segmentation in Large-Scale Outdoor Scene Understanding", "categories": ["cs.CV"], "comment": "19", "summary": "This paper presents a novel 3D semantic segmentation method for large-scale point cloud data that does not require annotated 3D training data or paired RGB images. The proposed approach projects 3D point clouds onto 2D images using virtual cameras and performs semantic segmentation via a foundation 2D model guided by natural language prompts. 3D segmentation is achieved by aggregating predictions from multiple viewpoints through weighted voting. Our method outperforms existing training-free approaches and achieves segmentation accuracy comparable to supervised methods. Moreover, it supports open-vocabulary recognition, enabling users to detect objects using arbitrary text queries, thus overcoming the limitations of traditional supervised approaches.", "AI": {"tldr": "利用二维视觉语言模型进行无标签的三维分割", "motivation": "解决大规模点云数据中的语义分割问题，减少对注释的依赖并支持开放词汇识别", "method": "通过虚拟相机将3D点云投影到2D图像上，并使用自然语言提示引导2D基础模型执行语义分割。多视角预测通过加权投票聚合得到最终的3D分割结果", "result": "方法超越了现有的无训练数据方法，分割准确性与监督方法相当，并支持开放词汇识别", "conclusion": "该方法克服了传统监督方法的局限性，实现了高效的三维场景理解"}}
{"id": "2601.02023", "pdf": "https://arxiv.org/pdf/2601.02023", "abs": "https://arxiv.org/abs/2601.02023", "authors": ["Amirali Ebrahimzadeh", "Seyyed M. Salili"], "title": "Not All Needles Are Found: How Fact Distribution and Don't Make It Up Prompts Shape Literal Extraction, Logical Inference, and Hallucination Risks in Long-Context LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "25 pages, 8 figures, 3 tables", "summary": "Large language models (LLMs) increasingly support very long input contexts. Yet it remains unclear how reliably they extract and infer information at scale. Performance varies with context length and strongly interacts with how information is distributed in real-world corpora. Motivated by these observations, we study how fact placement, corpus-level fact distributions, and Don't Make It Up prompts influence model behavior. We introduce an extended needle-in-a-haystack benchmark across four production-scale models: Gemini-2.5-flash, ChatGPT-5-mini, Claude-4.5-haiku, and Deepseek-v3.2-chat. Unlike prior work, we separately evaluate literal extraction, logical inference, and hallucination risk. Our study considers both positional effects and realistic distributions of evidence across long contexts, as well as prompts that explicitly discourage fabrication. We find that longer contexts alone do not guarantee better performance and can be detrimental when relevant evidence is diluted or widely dispersed. Performance varies substantially across models: some show severe degradation under realistic conditions, while others remain more robust at longer context lengths. Anti-hallucination (AH) instructions can make some models overly conservative, sharply reducing accuracy in literal extraction and logical inference. While we do not directly compare retrieval-augmented generation (RAG) and cache-augmented generation (CAG), our results suggest many failures stem from ineffective context utilization. Models often struggle to identify and prioritize relevant information even when it is present. These findings have direct practical implications, as enterprise workflows increasingly involve pasting large volumes of unfiltered documents into LLM prompts. Effective context length and model-specific robustness to long contexts are therefore critical for reliable LLM deployment in research and business.", "AI": {"tldr": "研究了大型语言模型在长上下文中的信息提取、逻辑推理和幻觉风险的影响因素，引入了一个扩展的针扎稻草堆基准测试。", "motivation": "探讨了信息分布位置、事实分布及不要捏造提示如何影响模型行为。目的在于了解这些因素对模型性能的影响，并为可靠部署提供指导建议。", "method": "使用四个生产级模型进行了实验，分别评估了在长上下文中的字面提取、逻辑推理和幻觉风险的表现，同时考虑位置效应和证据的分布情况。", "result": "发现仅增加上下文长度并不能保证更好的性能。部分模型在实际条件下表现出严重退化，而其他模型则更为稳健。反幻觉提示有时会导致模型过于保守，降低准确度。", "conclusion": "研究揭示了长上下文中有效使用背景信息的重要性，并强调了针对企业工作流程中粘贴大量文档的现实情况，优化模型性能和可靠性的关键点。"}}
{"id": "2601.02020", "pdf": "https://arxiv.org/pdf/2601.02020", "abs": "https://arxiv.org/abs/2601.02020", "authors": ["Shihan Peng", "Yuyang Xiong", "Hanyu Zhou", "Zhiwei Shi", "Haoyue Liu", "Gang Chen", "Luxin Yan", "Yi Chang"], "title": "Adapting Depth Anything to Adverse Imaging Conditions with Events", "categories": ["cs.CV"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Robust depth estimation under dynamic and adverse lighting conditions is essential for robotic systems. Currently, depth foundation models, such as Depth Anything, achieve great success in ideal scenes but remain challenging under adverse imaging conditions such as extreme illumination and motion blur. These degradations corrupt the visual signals of frame cameras, weakening the discriminative features of frame-based depths across the spatial and temporal dimensions. Typically, existing approaches incorporate event cameras to leverage their high dynamic range and temporal resolution, aiming to compensate for corrupted frame features. However, such specialized fusion models are predominantly trained from scratch on domain-specific datasets, thereby failing to inherit the open-world knowledge and robust generalization inherent to foundation models. In this work, we propose ADAE, an event-guided spatiotemporal fusion framework for Depth Anything in degraded scenes. Our design is guided by two key insights: 1) Entropy-Aware Spatial Fusion. We adaptively merge frame-based and event-based features using an information entropy strategy to indicate illumination-induced degradation. 2) Motion-Guided Temporal Correction. We resort to the event-based motion cue to recalibrate ambiguous features in blurred regions. Under our unified framework, the two components are complementary to each other and jointly enhance Depth Anything under adverse imaging conditions. Extensive experiments have been performed to verify the superiority of the proposed method. Our code will be released upon acceptance.", "AI": {"tldr": "本文提出了一种事件引导的时空融合框架ADAE，用于在不良成像条件下增强Depth Anything深度估计模型。", "motivation": "当前的深度基础模型在理想场景下表现良好，但在极端照明和运动模糊等不良成像条件下仍面临挑战。现有的方法主要从零开始训练领域特定数据集上的特殊融合模型，无法继承基础模型的开放世界知识和鲁棒泛化能力。", "method": "本文设计了两个关键组件：1）基于信息熵自适应合并帧基特征与事件基特征；2）利用事件基运动线索校准模糊区域中的模棱两可特征。这些组件在不良成像条件下协同增强了Depth Anything的性能。", "result": "通过广泛的实验验证了所提方法的有效性，证明了该方法优于现有技术。", "conclusion": "ADAE框架成功地提高了深度估计模型在极端光照和运动模糊条件下的表现，为机器人系统提供了更稳健的深度感知能力。"}}
{"id": "2601.02018", "pdf": "https://arxiv.org/pdf/2601.02018", "abs": "https://arxiv.org/abs/2601.02018", "authors": ["Guangqian Guo", "Aixi Ren", "Yong Guo", "Xuehui Yu", "Jiacheng Tian", "Wenli Li", "Yaoxing Wang", "Shan Gao"], "title": "Towards Any-Quality Image Segmentation via Generative and Adaptive Latent Space Enhancement", "categories": ["cs.CV"], "comment": "Diffusion-based latent space enhancement helps improve the robustness of SAM", "summary": "Segment Anything Models (SAMs), known for their exceptional zero-shot segmentation performance, have garnered significant attention in the research community. Nevertheless, their performance drops significantly on severely degraded, low-quality images, limiting their effectiveness in real-world scenarios. To address this, we propose GleSAM++, which utilizes Generative Latent space Enhancement to boost robustness on low-quality images, thus enabling generalization across various image qualities. Additionally, to improve compatibility between the pre-trained diffusion model and the segmentation framework, we introduce two techniques, i.e., Feature Distribution Alignment (FDA) and Channel Replication and Expansion (CRE). However, the above components lack explicit guidance regarding the degree of degradation. The model is forced to implicitly fit a complex noise distribution that spans conditions from mild noise to severe artifacts, which substantially increases the learning burden and leads to suboptimal reconstructions. To address this issue, we further introduce a Degradation-aware Adaptive Enhancement (DAE) mechanism. The key principle of DAE is to decouple the reconstruction process for arbitrary-quality features into two stages: degradation-level prediction and degradation-aware reconstruction. Our method can be applied to pre-trained SAM and SAM2 with only minimal additional learnable parameters, allowing for efficient optimization. Extensive experiments demonstrate that GleSAM++ significantly improves segmentation robustness on complex degradations while maintaining generalization to clear images. Furthermore, GleSAM++ also performs well on unseen degradations, underscoring the versatility of our approach and dataset.", "AI": {"tldr": "提出GleSAM++模型，通过生成和自适应增强机制提高图像分割在低质量图像上的鲁棒性。", "motivation": "现有的Segment Anything Models (SAMs) 在处理严重退化的、低质量的图像时性能显著下降，影响其实际应用。为了解决这个问题，提出了一种新的方法来提升模型的通用性和鲁棒性。", "method": "GleSAM++利用生成潜空间增强技术提高对低质量图像的鲁棒性，并引入了特征分布对齐(FDA)和通道复制扩展(CRE)以改进预训练扩散模型与分割框架之间的兼容性。进一步提出了退化感知自适应增强(DAE)，将重建过程分为预测退化水平和基于退化的重建两个阶段。", "result": "实验结果表明，GleSAM++在复杂退化情况下的分割鲁棒性显著提高，并且能够保持对清晰图像的泛化能力，同时表现出良好的跨领域迁移性能。", "conclusion": "提出的GleSAM++方法通过引入新的机制提升了现有模型在低质量图像上的表现，证明了其在实际应用中的有效性和广泛适用性。"}}
{"id": "2601.02016", "pdf": "https://arxiv.org/pdf/2601.02016", "abs": "https://arxiv.org/abs/2601.02016", "authors": ["Matthias Bartolo", "Dylan Seychell", "Gabriel Hili", "Matthew Montebello", "Carl James Debono", "Saviour Formosa", "Konstantinos Makantasis"], "title": "Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach", "categories": ["cs.CV", "cs.AI", "cs.ET", "cs.LG"], "comment": "Code available on GitHub: https://github.com/mbar0075/lupi-for-object-detection", "summary": "This paper investigates the integration of the Learning Using Privileged Information (LUPI) paradigm in object detection to exploit fine-grained, descriptive information available during training but not at inference. We introduce a general, model-agnostic methodology for injecting privileged information-such as bounding box masks, saliency maps, and depth cues-into deep learning-based object detectors through a teacher-student architecture. Experiments are conducted across five state-of-the-art object detection models and multiple public benchmarks, including UAV-based litter detection datasets and Pascal VOC 2012, to assess the impact on accuracy, generalization, and computational efficiency. Our results demonstrate that LUPI-trained students consistently outperform their baseline counterparts, achieving significant boosts in detection accuracy with no increase in inference complexity or model size. Performance improvements are especially marked for medium and large objects, while ablation studies reveal that intermediate weighting of teacher guidance optimally balances learning from privileged and standard inputs. The findings affirm that the LUPI framework provides an effective and practical strategy for advancing object detection systems in both resource-constrained and real-world settings.", "AI": {"tldr": "本文研究了在物体检测中使用Learning Using Privileged Information（LUPI）范式，通过引入教师-学生架构将特权信息注入深度学习对象检测器以提高准确性。", "motivation": "利用训练过程中可用但推理时不可用的细粒度描述性信息来改进目标检测系统的性能。", "method": "提出了一种通用且模型无关的方法，将诸如边界框掩码、注意力图和深度线索等特权信息注入基于深度学习的目标检测器中。实验涵盖了五个最先进的目标检测模型以及多个公共数据集。", "result": "LUPI训练的学生网络在所有评估指标上都优于基线模型，尤其是在中大型物体的检测准确率上有显著提升，并且不会增加推理复杂度或模型大小。", "conclusion": "研究结果表明，LUPI框架为改进资源受限和实际环境下的目标检测系统提供了一种有效而实用的战略。"}}
{"id": "2601.02015", "pdf": "https://arxiv.org/pdf/2601.02015", "abs": "https://arxiv.org/abs/2601.02015", "authors": ["Omar Momen", "Emilie Sitter", "Berenike Herrmann", "Sina Zarrieß"], "title": "Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects", "categories": ["cs.CL", "cs.AI", "cs.IT"], "comment": "to be published at EACL 2026 main conference", "summary": "Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.", "AI": {"tldr": "研究探讨了语言模型中的surprisal与不同新颖性比喻数据集之间的相关性。", "motivation": "通过分析语言模型对新颖比喻的理解，来探索surprisal作为预测新颖性的概率度量的能力。", "method": "使用16种语言模型变体分析基于语料库和合成的新颖比喻数据集的surprisal，并采用全句上下文条件下的cloze式surprisal方法。", "result": "结果表明，语言模型与比喻新颖性评分/标签存在显著中等相关性；在基于语料库的数据上，随着模型大小增加，相关性强度下降，在合成数据上则相反。", "conclusion": "虽然surprisal可以部分解释对比喻新颖性的标注，但它仍然是一个有限的语言创造力度量。"}}
{"id": "2601.02010", "pdf": "https://arxiv.org/pdf/2601.02010", "abs": "https://arxiv.org/abs/2601.02010", "authors": ["Liangxuan Guo", "Haoyang Chen", "Yang Chen", "Yanchao Bi", "Shan Yu"], "title": "A neural network for modeling human concept formation, understanding and communication", "categories": ["q-bio.NC", "cs.AI", "cs.CL"], "comment": "6 main figures, 5 extended data figures and 4 supplementary figures", "summary": "A remarkable capability of the human brain is to form more abstract conceptual representations from sensorimotor experiences and flexibly apply them independent of direct sensory inputs. However, the computational mechanism underlying this ability remains poorly understood. Here, we present a dual-module neural network framework, the CATS Net, to bridge this gap. Our model consists of a concept-abstraction module that extracts low-dimensional conceptual representations, and a task-solving module that performs visual judgement tasks under the hierarchical gating control of the formed concepts. The system develops transferable semantic structure based on concept representations that enable cross-network knowledge transfer through conceptual communication. Model-brain fitting analyses reveal that these emergent concept spaces align with both neurocognitive semantic model and brain response structures in the human ventral occipitotemporal cortex, while the gating mechanisms mirror that in the semantic control brain network. This work establishes a unified computational framework that can offer mechanistic insights for understanding human conceptual cognition and engineering artificial systems with human-like conceptual intelligence.", "AI": {"tldr": "本文提出了一种双模块神经网络框架CATS Net，用于建模人类的概念形成、理解和交流。", "motivation": "人类大脑能够从感觉运动经验中抽象出高层次概念，并独立于直接感官输入灵活应用这些概念的能力尚未完全理解。本研究旨在填补这一空白，提供一种统一的计算模型来解释和模拟这种能力。", "method": "CATS Net包括一个概念提取模块用于低维概念表示，以及一个任务解决模块在形成的概念层次控制下完成视觉判断任务。该系统基于所形成的概念表示发展出可迁移的知识结构，并通过概念交流进行跨网络知识转移。", "result": "模型与大脑的拟合分析显示，这些产生的概念空间与神经认知语义模型和人类腹侧枕颞叶皮层的大脑反应结构相吻合；而控制机制则模仿了语义控制大脑网络的表现。", "conclusion": "这项研究建立了一个统一的计算框架，可以为理解人类概念性认知提供机制性的见解，并用于工程化具有类人智能的人工系统。"}}
{"id": "2601.02008", "pdf": "https://arxiv.org/pdf/2601.02008", "abs": "https://arxiv.org/abs/2601.02008", "authors": ["Midhat Urooj", "Ayan Banerjee", "Sandeep Gupta"], "title": "XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging", "categories": ["cs.AI", "cs.CV"], "comment": "Accepted at AAAI Bridge Program 2026", "summary": "Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.", "AI": {"tldr": "介绍了一种用于医学成像的可解释神经符号框架XAIMeD，以提高罕见病症检测和域泛化性能。", "motivation": "为了克服深度模型在现实世界分布变化中的失败以及对罕见临床状况的偏差，提出了一个结合了临床知识和深度学习的统一神经符号架构。", "method": "通过将临床专业知识编码为逻辑连接符，并将其转化为机器可检验的规则，XAIMeD框架利用加权特征满意度分数进行诊断效用量化。该框架还采用了一种基于熵不平衡增益和罕见类基尼系数的自适应路由机制来缓解类别不平衡。", "result": "在跨模态医学成像任务上展示了显著性能提升，包括6%的域泛化改进和10%的罕见类F1得分提高。", "conclusion": "XAIMeD提供了一种稳健、可解释且临床忠实的方法，适用于多模态医疗AI问题。"}}
{"id": "2601.02007", "pdf": "https://arxiv.org/pdf/2601.02007", "abs": "https://arxiv.org/abs/2601.02007", "authors": ["Kunyu Wu", "Qiushi Zhao", "Jingyi Zhou", "Junqiao Wang", "Hao Qin", "Xinyue Zhang", "Xingqi Zhang"], "title": "Physics-Informed Deep Recurrent Back-Projection Network for Tunnel Propagation Modeling", "categories": ["cs.ET"], "comment": null, "summary": "Accurate and efficient modeling of radio wave propagation in railway tunnels is is critical for ensuring reliable communication-based train control (CBTC) systems. Fine-grid parabolic wave equation (PWE) solvers provide high-fidelity field predictions but are computationally expensive for large-scale tunnels, whereas coarse-grid models lose essential modal and geometric details. To address this challenge, we propose a physics-informed recurrent back-projection propagation network (PRBPN) that reconstructs fine-resolution received-signal-strength (RSS) fields from coarse PWE slices. The network integrates multi-slice temporal fusion with an iterative projection/back-projection mechanism that enforces physical consistency and avoids any pre-upsampling stage, resulting in strong data efficiency and improved generalization. Simulations across four tunnel cross-section geometries and four frequencies show that the proposed PRBPN closely tracks fine-mesh PWE references. Engineering-level validation on the Massif Central tunnel in France further confirms robustness in data-scarce scenarios, trained with only a few paired coarse/fine RSS. These results indicate that the proposed PRBPN can substantially reduce reliance on computationally intensive fine-grid solvers while maintaining high-fidelity tunnel propagation predictions.", "AI": {"tldr": "本文提出了一种基于物理信息的递归反投影传播网络（PRBPN），用于铁路隧道中无线电波传播的建模。", "motivation": "准确高效的铁路隧道内无线电波传播模型对于确保可靠的通信基础列车控制系统至关重要。细网格抛物线波动方程求解器虽能提供高保真度场预测，但计算成本高昂；而粗网格模型则会丢失重要模式和几何细节。为此，本文提出了一种新的网络方法。", "method": "该方法采用多层融合时域投影/反投影机制，确保物理一致性并避免预上采样阶段，从而提高数据效率和泛化能力。通过模拟四种隧道横截面几何形状及四个频率下的表现来验证模型的性能。", "result": "实验结果表明，所提出的PRBPN在各种条件下均能与细网格抛物线波动方程参考值紧密匹配，特别是在法国马斯夫中隧道的实际工程验证中表现出色，即使在数据稀缺的情况下也能保持较高的传播预测精度。", "conclusion": "该研究展示了利用物理信息引导的递归反投影网络可以显著降低对高计算成本细网格求解器的依赖，同时仍能维持精确的隧道内无线电波传播建模。"}}
{"id": "2601.02002", "pdf": "https://arxiv.org/pdf/2601.02002", "abs": "https://arxiv.org/abs/2601.02002", "authors": ["Antonio Colacicco", "Vito Guida", "Dario Di Palma", "Fedelucio Narducci", "Tommaso Di Noia"], "title": "Exploring Approaches for Detecting Memorization of Recommender System Data in Large Language Models", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly applied in recommendation scenarios due to their strong natural language understanding and generation capabilities. However, they are trained on vast corpora whose contents are not publicly disclosed, raising concerns about data leakage. Recent work has shown that the MovieLens-1M dataset is memorized by both the LLaMA and OpenAI model families, but the extraction of such memorized data has so far relied exclusively on manual prompt engineering. In this paper, we pose three main questions: Is it possible to enhance manual prompting? Can LLM memorization be detected through methods beyond manual prompting? And can the detection of data leakage be automated? To address these questions, we evaluate three approaches: (i) jailbreak prompt engineering; (ii) unsupervised latent knowledge discovery, probing internal activations via Contrast-Consistent Search (CCS) and Cluster-Norm; and (iii) Automatic Prompt Engineering (APE), which frames prompt discovery as a meta-learning process that iteratively refines candidate instructions. Experiments on MovieLens-1M using LLaMA models show that jailbreak prompting does not improve the retrieval of memorized items and remains inconsistent; CCS reliably distinguishes genuine from fabricated movie titles but fails on numerical user and rating data; and APE retrieves item-level information with moderate success yet struggles to recover numerical interactions. These findings suggest that automatically optimizing prompts is the most promising strategy for extracting memorized samples.", "AI": {"tldr": "本论文探索了大型语言模型在推荐系统数据中的记忆检测方法，包括手动提示工程、自动提示工程以及无监督隐性知识发现。", "motivation": "近年来，大型语言模型因强大的自然语言理解和生成能力被广泛应用于推荐场景中。然而，由于训练数据集不公开披露，引发了对潜在的数据泄露的担忧。", "method": "本文评估了三种方法：手动提示工程、自动提示工程以及通过对比一致搜索（CCS）和聚类范数进行无监督隐性知识发现的方法，以检测大型语言模型中记忆的内容。", "result": "实验表明，手动提示改进策略并没有提高记忆内容的提取能力；CCS能够可靠地区分真实电影名称与虚构的标题，但无法处理数字用户和评分数据；自动提示工程在检索项目级信息方面取得了中等成功，但在恢复数值交互上存在困难。", "conclusion": "自动优化提示是提取模型所记忆样本最具有前景的方法。"}}
{"id": "2601.01998", "pdf": "https://arxiv.org/pdf/2601.01998", "abs": "https://arxiv.org/abs/2601.01998", "authors": ["Chen Zhu", "Huiwen Zhang", "Mu He", "Yujie Li", "Xiaotian Qiao"], "title": "Nighttime Hazy Image Enhancement via Progressively and Mutually Reinforcing Night-Haze Priors", "categories": ["cs.CV"], "comment": null, "summary": "Enhancing the visibility of nighttime hazy images is challenging due to the complex degradation distributions. Existing methods mainly address a single type of degradation (e.g., haze or low-light) at a time, ignoring the interplay of different degradation types and resulting in limited visibility improvement. We observe that the domain knowledge shared between low-light and haze priors can be reinforced mutually for better visibility. Based on this key insight, in this paper, we propose a novel framework that enhances visibility in nighttime hazy images by reinforcing the intrinsic consistency between haze and low-light priors mutually and progressively. In particular, our model utilizes image-, patch-, and pixel-level experts that operate across visual and frequency domains to recover global scene structure, regional patterns, and fine-grained details progressively. A frequency-aware router is further introduced to adaptively guide the contribution of each expert, ensuring robust image restoration. Extensive experiments demonstrate the superior performance of our model on nighttime dehazing benchmarks both quantitatively and qualitatively. Moreover, we showcase the generalizability of our model in daytime dehazing and low-light enhancement tasks.", "AI": {"tldr": "夜间雾霾图像增强", "motivation": "现有方法主要针对单一类型的退化（如雾霾或低光）进行处理，忽视了不同类型退化的相互作用，导致可见度改进有限。本研究旨在利用低光和雾霾先验之间的领域知识共享来实现更好的可见度。", "method": "提出了一种新的框架，在夜间雾霾图像中通过互惠强化雾霾和低光先验的内在一致性逐步增强可见性。模型利用图像、补丁和像素级专家在视觉和频率域中操作，以恢复全局场景结构、区域模式和细粒度细节。还引入了一个频段感知路由器来自适应地指导每个专家的贡献。", "result": "广泛的实验表明了该模型在夜间除雾基准测试中的优越性能，无论是定量还是定性评估，并展示了其在白天除雾和低光增强任务中的泛化能力。", "conclusion": "所提出的框架通过互惠强化雾霾和低光先验实现了更好的夜间雾霾图像可见度增强。"}}
{"id": "2601.01997", "pdf": "https://arxiv.org/pdf/2601.01997", "abs": "https://arxiv.org/abs/2601.01997", "authors": ["Dario Di Palma", "Giovanni Maria Biancofiore", "Vito Walter Anelli", "Fedelucio Narducci", "Tommaso Di Noia"], "title": "Exploring Diversity, Novelty, and Popularity Bias in ChatGPT's Recommendations", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "ChatGPT has emerged as a versatile tool, demonstrating capabilities across diverse domains. Given these successes, the Recommender Systems (RSs) community has begun investigating its applications within recommendation scenarios primarily focusing on accuracy. While the integration of ChatGPT into RSs has garnered significant attention, a comprehensive analysis of its performance across various dimensions remains largely unexplored. Specifically, the capabilities of providing diverse and novel recommendations or exploring potential biases such as popularity bias have not been thoroughly examined. As the use of these models continues to expand, understanding these aspects is crucial for enhancing user satisfaction and achieving long-term personalization. This study investigates the recommendations provided by ChatGPT-3.5 and ChatGPT-4 by assessing ChatGPT's capabilities in terms of diversity, novelty, and popularity bias. We evaluate these models on three distinct datasets and assess their performance in Top-N recommendation and cold-start scenarios. The findings reveal that ChatGPT-4 matches or surpasses traditional recommenders, demonstrating the ability to balance novelty and diversity in recommendations. Furthermore, in the cold-start scenario, ChatGPT models exhibit superior performance in both accuracy and novelty, suggesting they can be particularly beneficial for new users. This research highlights the strengths and limitations of ChatGPT's recommendations, offering new perspectives on the capacity of these models to provide recommendations beyond accuracy-focused metrics.", "AI": {"tldr": "研究了ChatGPT在推荐系统中的多样性和新颖性，以及流行度偏差。", "motivation": "探索ChatGPT在推荐系统中提供多样化、新颖化推荐的能力和可能存在的流行度偏差。", "method": "评估了ChatGPT-3.5和ChatGPT-4在三个不同数据集上的性能，包括Top-N推荐场景和冷启动场景。", "result": "发现ChatGPT-4的推荐能力可以与传统推荐系统媲美，并且在冷启动场景中表现更优。", "conclusion": "研究揭示了ChatGPT模型在多样化、新颖性推荐以及克服流行度偏差方面的潜力，为推荐系统的未来发展提供了新的视角。"}}
{"id": "2601.01993", "pdf": "https://arxiv.org/pdf/2601.01993", "abs": "https://arxiv.org/abs/2601.01993", "authors": ["Dong Xue", "Jicheng Tu", "Ming Wang", "Xin Yan", "Fangzhou Liu", "Jie Hu"], "title": "MindChat: A Privacy-preserving Large Language Model for Mental Health Support", "categories": ["cs.AI"], "comment": "33 pages, 16 figures", "summary": "Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.", "AI": {"tldr": "本文介绍了一种名为MindChat的隐私保护型大语言模型，用于心理健康支持，并提出了一套合成多轮心理咨询数据集MindCorpus。", "motivation": "大语言模型在心理健康支持方面显示出潜力，但由于实际咨询对话的稀缺性和敏感性，训练这些模型受到限制。因此开发了MindChat和MindCorpus来解决这一问题。", "method": "通过一个多代理角色扮演框架构建合成多轮心理咨询数据集MindCorpus，并采用双闭环反馈设计提高会话质量和隐私保护。在联邦学习中使用LoRA适配器和差分隐私优化以减少成员身份和记忆风险，从而训练出隐私保护型大语言模型。", "result": "实验结果表明，MindCorpus提高了训练效率，MindChat与现有的一般性和咨询导向型LLM基线相比，在自动化评估和人工评估中表现出竞争力，并且在会员推断攻击下减少了隐私泄漏。", "conclusion": "本文提出的方法有效解决了心理健康支持领域的大语言模型训练问题，并为未来的心理健康辅助技术提供了新的思路。"}}
{"id": "2601.01992", "pdf": "https://arxiv.org/pdf/2601.01992", "abs": "https://arxiv.org/abs/2601.01992", "authors": ["Chen Zhu", "Huiwen Zhang", "Yujie Li", "Mu He", "Xiaotian Qiao"], "title": "API: Empowering Generalizable Real-World Image Dehazing via Adaptive Patch Importance Learning", "categories": ["cs.CV"], "comment": null, "summary": "Real-world image dehazing is a fundamental yet challenging task in low-level vision. Existing learning-based methods often suffer from significant performance degradation when applied to complex real-world hazy scenes, primarily due to limited training data and the intrinsic complexity of haze density distributions.To address these challenges, we introduce a novel Adaptive Patch Importance-aware (API) framework for generalizable real-world image dehazing. Specifically, our framework consists of an Automatic Haze Generation (AHG) module and a Density-aware Haze Removal (DHR) module. AHG provides a hybrid data augmentation strategy by generating realistic and diverse hazy images as additional high-quality training data. DHR considers hazy regions with varying haze density distributions for generalizable real-world image dehazing in an adaptive patch importance-aware manner. To alleviate the ambiguity of the dehazed image details, we further introduce a new Multi-Negative Contrastive Dehazing (MNCD) loss, which fully utilizes information from multiple negative samples across both spatial and frequency domains. Extensive experiments demonstrate that our framework achieves state-of-the-art performance across multiple real-world benchmarks, delivering strong results in both quantitative metrics and qualitative visual quality, and exhibiting robust generalization across diverse haze distributions.", "AI": {"tldr": "本文提出了一种基于自适应补丁重要性学习的API框架，用于通用现实世界图像去雾。", "motivation": "现有的基于学习的方法在处理复杂的现实世界的雾景时性能下降严重，主要由于训练数据有限和雾密度分布的复杂性。为了解决这些问题，作者提出了新的方法来提高去雾效果。", "method": "提出了一种自适应补丁重要性感知框架API, 包含自动雾生成模块AHG和密度感知雾消除模块DHR，并引入了多负对比去雾损失函数MNCD。", "result": "实验表明该框架在多个现实世界基准测试中表现出色，定量指标和定性视觉质量均优于其他方法，并且对于不同的雾分布具有鲁棒的泛化能力。", "conclusion": "通过API框架可以有效地提高图像去雾的质量，尤其是在复杂的真实场景下。"}}
{"id": "2601.01989", "pdf": "https://arxiv.org/pdf/2601.01989", "abs": "https://arxiv.org/abs/2601.01989", "authors": ["Aly R. Elkammar", "Karim M. Gamaleldin", "Catherine M. Elias"], "title": "VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Pedestrian Intention prediction is one of the key technologies in the transition from level 3 to level 4 autonomous driving. To understand pedestrian crossing behaviour, several elements and features should be taken into consideration to make the roads of tomorrow safer for everybody. We introduce a transformer / video vision transformer based algorithm of different sizes which uses different data modalities .We evaluated our algorithms on popular pedestrian behaviour dataset, JAAD, and have reached SOTA performance and passed the SOTA in metrics like Accuracy, AUC and F1-score. The advantages brought by different model design choices are investigated via extensive ablation studies.", "AI": {"tldr": "介绍了一种基于变压器和视频视觉变换器的算法，用于预测行人的行为意图，以提高自动驾驶的安全性。", "motivation": "为了在从三级到四级自动驾驶过渡中实现行人意图预测的关键技术，理解行人的过街行为需要考虑多个元素和特征来确保未来的道路安全。", "method": "提出了一种基于变压器和视频视觉变换器的算法，并通过不同的数据模态进行了评估。该算法对JAAD数据库中的行人行为进行了测试，并通过广泛的消融研究探讨了不同模型设计选择带来的优势。", "result": "在准确性、AUC和F1分数等指标上达到了最新的技术水平。", "conclusion": "所提出的基于变压器的算法对于预测行人的行为意图具有显著效果，能够提高自动驾驶的安全性。"}}
{"id": "2601.01984", "pdf": "https://arxiv.org/pdf/2601.01984", "abs": "https://arxiv.org/abs/2601.01984", "authors": ["Weijian Ma", "Shizhao Sun", "Tianyu Yu", "Ruiyu Wang", "Tat-Seng Chua", "Jiang Bian"], "title": "Thinking with Blueprints: Assisting Vision-Language Models in Spatial Reasoning via Structured Object Representation", "categories": ["cs.CV"], "comment": "Preprint. Under review", "summary": "Spatial reasoning -- the ability to perceive and reason about relationships in space -- advances vision-language models (VLMs) from visual perception toward spatial semantic understanding. Existing approaches either revisit local image patches, improving fine-grained perception but weakening global spatial awareness, or mark isolated coordinates, which capture object locations but overlook their overall organization. In this work, we integrate the cognitive concept of an object-centric blueprint into VLMs to enhance spatial reasoning. Given an image and a question, the model first constructs a JSON-style blueprint that records the positions, sizes, and attributes of relevant objects, and then reasons over this structured representation to produce the final answer. To achieve this, we introduce three key techniques: (1) blueprint-embedded reasoning traces for supervised fine-tuning to elicit basic reasoning skills; (2) blueprint-aware rewards in reinforcement learning to encourage the blueprint to include an appropriate number of objects and to align final answers with this causal reasoning; and (3) anti-shortcut data augmentation that applies targeted perturbations to images and questions, discouraging reliance on superficial visual or linguistic cues. Experiments show that our method consistently outperforms existing VLMs and specialized spatial reasoning models.", "AI": {"tldr": "本文提出了一种方法，通过在视觉语言模型中集成物体中心蓝图的概念来增强空间推理能力。", "motivation": "现有的方法要么关注局部图像补丁以改进细粒度感知但削弱全局空间意识，要么标记孤立的坐标，捕获对象位置但忽视它们的整体组织。因此，需要一种新的方式来提升视觉语言模型的空间理解能力。", "method": "本文引入了物体中心蓝图概念，通过构造JSON风格的蓝图记录相关物体的位置、大小和属性，并基于此结构化表示进行推理以生成最终答案。同时采用三个关键技术：1）带有蓝图嵌入的推理轨迹；2）基于奖励机制鼓励包括适当的对象数并使最后的答案与因果关系一致；3）应用特定扰动防止对浅层视觉或语言线索的依赖。", "result": "实验表明，该方法在现有视觉语言模型和专门的空间推理模型中均表现优越。", "conclusion": "本文通过引入物体中心蓝图的概念显著改善了视觉语言模型的空间理解能力。"}}
{"id": "2601.01982", "pdf": "https://arxiv.org/pdf/2601.01982", "abs": "https://arxiv.org/abs/2601.01982", "authors": ["Noel Thomas"], "title": "ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems", "categories": ["cs.AI"], "comment": "7 pages, 0 figures , Accepted to AAAI-26 Bridge Program: Logical and Symbolic Reasoning in Language Models (camera-ready)", "summary": "Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.", "AI": {"tldr": "该论文介绍了ChaosBench-Logic，这是一个用于评估大型语言模型在逻辑和符号推理上的表现的基准测试。", "motivation": "尽管大语言模型在自然语言处理任务上表现出色，但在需要精确逻辑和符号推理的任务上仍显得脆弱。混沌动力学系统提供了特别具有挑战性的测试环境，因为即使混沌是确定性的，但仍常被误解为随机性或复杂性。", "method": "引入了ChaosBench-Logic，涵盖30种不同的动态系统，并通过统一的一阶逻辑（FOL）本体进行评估。每个系统都用11个语义谓词进行了真值分配，生成了621个问题，涵盖了多跳推论、跨系统类比、反事实推理等七个推理类别。", "result": "前沿LLM模型如GPT-4和LLaMA-3在单项目准确性上得分91-94%，但在组合项上的分数为0%。对话级别的准确性范围从53.1%到75.5%不等。", "conclusion": "ChaosBench-Logic提供了一个严格的测试平台，用于诊断这些失败，并作为开发改善科学推理的神经符号方法的基础。"}}
{"id": "2601.01979", "pdf": "https://arxiv.org/pdf/2601.01979", "abs": "https://arxiv.org/abs/2601.01979", "authors": ["Julie Keisler", "Anastase Alexandre Charantonis", "Yannig Goude", "Boutheina Oueslati", "Claire Monteleoni"], "title": "SerpentFlow: Generative Unpaired Domain Alignment via Shared-Structure Decomposition", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Domain alignment refers broadly to learning correspondences between data distributions from distinct domains. In this work, we focus on a setting where domains share underlying structural patterns despite differences in their specific realizations. The task is particularly challenging in the absence of paired observations, which removes direct supervision across domains. We introduce a generative framework, called SerpentFlow (SharEd-structuRe decomPosition for gEnerative domaiN adapTation), for unpaired domain alignment. SerpentFlow decomposes data within a latent space into a shared component common to both domains and a domain-specific one. By isolating the shared structure and replacing the domain-specific component with stochastic noise, we construct synthetic training pairs between shared representations and target-domain samples, thereby enabling the use of conditional generative models that are traditionally restricted to paired settings. We apply this approach to super-resolution tasks, where the shared component naturally corresponds to low-frequency content while high-frequency details capture domain-specific variability. The cutoff frequency separating low- and high-frequency components is determined automatically using a classifier-based criterion, ensuring a data-driven and domain-adaptive decomposition. By generating pseudo-pairs that preserve low-frequency structures while injecting stochastic high-frequency realizations, we learn the conditional distribution of the target domain given the shared representation. We implement SerpentFlow using Flow Matching as the generative pipeline, although the framework is compatible with other conditional generative approaches. Experiments on synthetic images, physical process simulations, and a climate downscaling task demonstrate that the method effectively reconstructs high-frequency structures consistent with underlying low-frequency patterns, supporting shared-structure decomposition as an effective strategy for unpaired domain alignment.", "AI": {"tldr": "本文提出了一种用于未配对领域对齐的生成框架SerpentFlow，通过共享结构分解方法将数据在潜在空间中分解为共享组件和特定领域的组件。", "motivation": "研究旨在解决不同领域间的数据分布对应关系学习问题，特别是在缺乏直接监督的情况下。共享结构性质的存在使得可以通过构建合成训练配对来实现未配对的领域对齐。", "method": "SerpentFlow框架通过将数据分解为一个跨域共同的部分和特定领域的部分，在潜在空间中实现了共享结构与特定领域结构的分离。低频成分代表共享信息，高频成分则捕获了特定于每个领域的变异性。", "result": "实验结果表明，该方法能够有效重建与底层低频率模式一致的高频率结构，证明了基于共享结构分解策略在未配对领域对齐中的有效性。", "conclusion": "本文展示了一种新颖的方法来解决未配对数据领域间的对齐问题，通过自动化的共享结构分解技术以及生成伪配对的方式使得条件生成模型得以应用。"}}
{"id": "2601.01976", "pdf": "https://arxiv.org/pdf/2601.01976", "abs": "https://arxiv.org/abs/2601.01976", "authors": ["Yasmine Souissi", "Fabrice Boissier", "Nida Meddouri"], "title": "CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes", "categories": ["cs.AI"], "comment": "ef:2025 IEEE 37th International Conference on Tools with Artificial Intelligence (ICTAI), Nov 2025, Ath{è}nes, Greece. pp.965-971", "summary": "Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.", "AI": {"tldr": "本文提出了一个基于形式概念分析（FCA）的分类器，该分类器能够从名义数据中构建部分概念格，并重点研究最相关的概念。", "motivation": "在知识发现过程中，需要提取有意义的知识。形式概念分析是一种有效的解释性方法，其核心在于生成可以揭示隐藏关系的形式概念和概念格结构。", "method": "本文通过回顾文献中的FCA分类器进行状态调研，探讨了从名义数据计算闭包操作的方法，并提出了一种新的构建部分概念格的策略来关注最相关的概念。", "result": "实验结果表明所提出的这种方法在效率方面具有显著优势。", "conclusion": "该方法为基于形式概念分析的知识发现提供了一个有效的分类解决方案，特别是在处理名义数据时表现突出。"}}
{"id": "2601.01971", "pdf": "https://arxiv.org/pdf/2601.01971", "abs": "https://arxiv.org/abs/2601.01971", "authors": ["Aditya Singh", "Rajpal Singh", "Jishnu Keshavan"], "title": "Deep Robust Koopman Learning from Noisy Data", "categories": ["cs.RO"], "comment": null, "summary": "Koopman operator theory has emerged as a leading data-driven approach that relies on a judicious choice of observable functions to realize global linear representations of nonlinear systems in the lifted observable space. However, real-world data is often noisy, making it difficult to obtain an accurate and unbiased approximation of the Koopman operator. The Koopman operator generated from noisy datasets is typically corrupted by noise-induced bias that severely degrades prediction and downstream tracking performance. In order to address this drawback, this paper proposes a novel autoencoder-based neural architecture to jointly learn the appropriate lifting functions and the reduced-bias Koopman operator from noisy data. The architecture initially learns the Koopman basis functions that are consistent for both the forward and backward temporal dynamics of the system. Subsequently, by utilizing the learned forward and backward temporal dynamics, the Koopman operator is synthesized with a reduced bias making the method more robust to noise compared to existing techniques. Theoretical analysis is used to demonstrate significant bias reduction in the presence of training noise. Dynamics prediction and tracking control simulations are conducted for multiple serial manipulator arms, including performance comparisons with leading alternative designs, to demonstrate its robustness under various noise levels. Experimental studies with the Franka FR3 7-DoF manipulator arm are further used to demonstrate the effectiveness of the proposed approach in a practical setting.", "AI": {"tldr": "提出了一种基于自编码器的神经网络架构，用于从嘈杂数据中学习Koopman算子和提升函数，从而提高非线性系统预测和跟踪控制的鲁棒性。", "motivation": "现实世界中的数据往往含有噪声，这使得难以获得准确无偏的Koopman算子近似。现有的方法在这种情况下性能较差，因此需要一种新的方法来解决这个问题，以增强在噪声环境下的预测和跟踪控制性能。", "method": "提出了一种自编码器网络架构，通过联合学习适合于系统前后时间动力学的一致提升函数，并利用这些学到的动态合成减少偏差的Koopman算子，从而提高对噪声数据处理的能力。", "result": "理论分析表明该方法可以显著降低训练噪声中的偏置。通过多关节机械臂的动力学预测和跟踪控制实验验证了其在不同噪声水平下的鲁棒性，并展示了实际应用的有效性。", "conclusion": "所提出的基于自编码器的神经网络架构能够在含有噪声的数据中准确地学习Koopman算子，从而提高非线性系统的预测和跟踪控制性能。"}}
{"id": "2601.01969", "pdf": "https://arxiv.org/pdf/2601.01969", "abs": "https://arxiv.org/abs/2601.01969", "authors": ["Sichao Song", "Yuki Okafuji", "Kaito Ariu", "Amy Koike"], "title": "What you reward is what you learn: Comparing rewards for online speech policy optimization in public HRI", "categories": ["cs.RO"], "comment": null, "summary": "Designing policies that are both efficient and acceptable for conversational service robots in open and diverse environments is non-trivial. Unlike fixed, hand-tuned parameters, online learning can adapt to non-stationary conditions. In this paper, we study how to adapt a social robot's speech policy in the wild. During a 12-day in-situ deployment with over 1,400 public encounters, we cast online policy optimization as a multi-armed bandit problem and use Thompson sampling to select among six actions defined by speech rate (slow/normal/fast) and verbosity (concise/detailed). We compare three complementary binary rewards--Ru (user rating), Rc (conversation closure), and Rt (>=2 turns)--and show that each induces distinct arm distributions and interaction behaviors. We complement the online results with offline evaluations that analyze contextual factors (e.g., crowd level, group size) using video-annotated data. Taken together, we distill ready-to-use design lessons for deploying online optimization of speech policies in real public HRI settings.", "AI": {"tldr": "研究如何在公共环境中通过在线学习优化社交机器人的语音策略。", "motivation": "设计既能高效又可接受的对话服务机器人政策在开放和多样的环境中颇具挑战，特别是在非静态条件下。此研究旨在通过在线学习适应机器人在公开环境中的言语策略。", "method": "将在线策略优化作为多臂赌博机问题处理，并使用汤普森采样方法选择由语速（慢/正常/快）和详尽度（简洁/详细）定义的六个动作。同时比较三种互补的二元奖励：用户评分、对话结束、至少两轮互动，通过视频注释数据进行离线评估。", "result": "每种奖励导致不同的臂分布和互动行为，并揭示了语速和详尽度对不同情境下的影响。", "conclusion": "提出了可用于在线优化公开人机交互环境中语音策略的设计建议。"}}
{"id": "2601.01966", "pdf": "https://arxiv.org/pdf/2601.01966", "abs": "https://arxiv.org/abs/2601.01966", "authors": ["Bo Yin", "Qi Li", "Runpeng Yu", "Xinchao Wang"], "title": "Refinement Provenance Inference: Detecting LLM-Refined Training Prompts from Model Behavior", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Instruction tuning increasingly relies on LLM-based prompt refinement, where prompts in the training corpus are selectively rewritten by an external refiner to improve clarity and instruction alignment. This motivates an instance-level audit problem: for a fine-tuned model and a training prompt-response pair, can we infer whether the model was trained on the original prompt or its LLM-refined version within a mixed corpus? This matters for dataset governance and dispute resolution when training data are contested. However, it is non-trivial in practice: refined and raw instances are interleaved in the training corpus with unknown, source-dependent mixture ratios, making it harder to develop provenance methods that generalize across models and training setups. In this paper, we formalize this audit task as Refinement Provenance Inference (RPI) and show that prompt refinement yields stable, detectable shifts in teacher-forced token distributions, even when semantic differences are not obvious. Building on this phenomenon, we propose RePro, a logit-based provenance framework that fuses teacher-forced likelihood features with logit-ranking signals. During training, RePro learns a transferable representation via shadow fine-tuning, and uses a lightweight linear head to infer provenance on unseen victims without training-data access. Empirically, RePro consistently attains strong performance and transfers well across refiners, suggesting that it exploits refiner-agnostic distribution shifts rather than rewrite-style artifacts.", "AI": {"tldr": "本文提出了一种检测经过大模型优化后的训练提示的方法，称为Refinement Provenance Inference (RPI)，并开发了一个名为RePro的框架。", "motivation": "随着指令微调的发展，越来越多地依赖于LLM（大型语言模型）对原始训练提示进行精炼。然而，在混合数据集中难以确定一个模型是否是在经过优化后的提示上训练的，这引发了关于审计、治理和争议解决的需求。", "method": "作者将问题定义为RPI任务，并利用RePro框架通过融合教师强制似然特征与logit排名信号来检测训练提示。RePro框架采用阴影微调方式学习一个可转移的表示形式，并使用线性头在不接触原训练数据的情况下进行未知受害者模型的来源推测。", "result": "实验表明，RePro方法能够跨不同的优化器和模型实现良好的性能，并且其性能不受重写风格变化的影响。", "conclusion": "通过稳定分布偏移而非特定重写模式来检测优化后的训练提示是可行的。这一发现有助于更好地理解和管理大语言模型的行为及其对微调数据集的依赖性。"}}
{"id": "2601.01963", "pdf": "https://arxiv.org/pdf/2601.01963", "abs": "https://arxiv.org/abs/2601.01963", "authors": ["Arjun Ramesh Kaushik", "Naresh Kumar Devulapally", "Vishnu Suresh Lokhande", "Nalini Ratha", "Venu Govindaraju"], "title": "Forget Less by Learning Together through Concept Consolidation", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at WACV-26", "summary": "Custom Diffusion Models (CDMs) have gained significant attention due to their remarkable ability to personalize generative processes. However, existing CDMs suffer from catastrophic forgetting when continuously learning new concepts. Most prior works attempt to mitigate this issue under the sequential learning setting with a fixed order of concept inflow and neglect inter-concept interactions. In this paper, we propose a novel framework - Forget Less by Learning Together (FL2T) - that enables concurrent and order-agnostic concept learning while addressing catastrophic forgetting. Specifically, we introduce a set-invariant inter-concept learning module where proxies guide feature selection across concepts, facilitating improved knowledge retention and transfer. By leveraging inter-concept guidance, our approach preserves old concepts while efficiently incorporating new ones. Extensive experiments, across three datasets, demonstrates that our method significantly improves concept retention and mitigates catastrophic forgetting, highlighting the effectiveness of inter-concept catalytic behavior in incremental concept learning of ten tasks with at least 2% gain on average CLIP Image Alignment scores.", "AI": {"tldr": "本文提出了一种新的框架Forget Less by Learning Together (FL2T)，旨在解决连续学习新概念时的灾难性遗忘问题，通过引入跨概念交互模块提高知识保持和迁移。", "motivation": "现有定制扩散模型（CDMs）在个性化生成过程中表现突出，但在持续学习新概念时会遭遇严重的灾难性遗忘问题。以往的工作多集中在固定顺序的概念流入下的序列学习环境中，并忽略了不同概念之间的相互作用。", "method": "本文提出了一种新的框架FL2T，该框架通过引入一套不变的跨概念交互模块，利用代理指导特征选择以实现更好的知识保持和转移，从而在处理新旧概念时达到平衡。", "result": "实验结果表明，在三个数据集上，本方法显著提升了概念保留率，并减少了灾难性遗忘现象，展示了跨概念催化行为在增量概念学习中的有效性。", "conclusion": "本文提出的FL2T框架成功解决了个性化模型中的灾难性遗忘问题，通过引入创新的跨概念交互模块，实现了更高效的概念保持和迁移。"}}
{"id": "2601.01957", "pdf": "https://arxiv.org/pdf/2601.01957", "abs": "https://arxiv.org/abs/2601.01957", "authors": ["Tianbo Wang", "Yuqing Ma", "Kewei Liao", "Zhange Zhang", "Simin Li", "Jinyang Guo", "Xianglong Liu"], "title": "AFTER: Mitigating the Object Hallucination of LVLM via Adaptive Factual-Guided Activation Editing", "categories": ["cs.CV"], "comment": null, "summary": "Large Vision-Language Models (LVLMs) have achieved substantial progress in cross-modal tasks. However, due to language bias, LVLMs are susceptible to object hallucination, which can be primarily divided into category, attribute, and relation hallucination, significantly impeding the trustworthy AI applications. Editing the internal activations of LVLMs has shown promising effectiveness in mitigating hallucinations with minimal cost. However, previous editing approaches neglect the effective guidance offered by factual textual semantics, thereby struggling to explicitly mitigate language bias. To address these issues, we propose Adaptive Factual-guided Visual-Textual Editing for hallucination mitigation (AFTER), which comprises Factual-Augmented Activation Steering (FAS) and Query-Adaptive Offset Optimization (QAO), to adaptively guides the original biased activations towards factual semantics. Specifically, FAS is proposed to provide factual and general guidance for activation editing, thereby explicitly modeling the precise visual-textual associations. Subsequently, QAO introduces a query-aware offset estimator to establish query-specific editing from the general steering vector, enhancing the diversity and granularity of editing. Extensive experiments on standard hallucination benchmarks across three widely adopted LVLMs validate the efficacy of the proposed AFTER, notably achieving up to a 16.3% reduction of hallucination over baseline on the AMBER benchmark. Our code and data will be released for reproducibility.", "AI": {"tldr": "该论文提出了一种用于减轻大型视觉语言模型中的对象幻觉的自适应事实引导编辑方法AFTER。", "motivation": "大型视觉语言模型在跨模态任务中取得了显著进展，但由于语言偏见，这些模型容易产生对象幻觉，阻碍了可信赖的人工智能应用。以前的激活编辑方法忽视了文本语义的有效指导，难以明确地减轻语言偏见。", "method": "该论文提出了自适应事实引导视觉-文本编辑(AFTER)，包括事实增强激活导向(FAS)和查询自适应偏移优化(QAO)，以将原始偏向性激活引导至事实语义。FAS提供了一种对激活编辑的事实性和通用指导，QAO通过引入一个查询感知的偏置估计器从一般导向矢量中建立了特定查询的编辑。", "result": "在标准幻觉基准测试中的大量实验表明，提出的AFTER显著减少了AMBER基准上的对象幻觉，最高可达16.3％。代码和数据将公开发布以验证结果。", "conclusion": "该论文通过提出自适应事实引导视觉-文本编辑方法(AFTER)，有效减轻了大型视觉语言模型中的对象幻觉问题，提高了模型的可信度和实用性。"}}
{"id": "2601.01955", "pdf": "https://arxiv.org/pdf/2601.01955", "abs": "https://arxiv.org/abs/2601.01955", "authors": ["Zhexin Zhang", "Yifeng Zhu", "Yangyang Xu", "Long Chen", "Yong Du", "Shengfeng He", "Jun Yu"], "title": "MotionAdapter: Video Motion Transfer via Content-Aware Attention Customization", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in diffusion-based text-to-video models, particularly those built on the diffusion transformer architecture, have achieved remarkable progress in generating high-quality and temporally coherent videos. However, transferring complex motions between videos remains challenging. In this work, we present MotionAdapter, a content-aware motion transfer framework that enables robust and semantically aligned motion transfer within DiT-based T2V models. Our key insight is that effective motion transfer requires \\romannumeral1) explicit disentanglement of motion from appearance and \\romannumeral 2) adaptive customization of motion to target content. MotionAdapter first isolates motion by analyzing cross-frame attention within 3D full-attention modules to extract attention-derived motion fields. To bridge the semantic gap between reference and target videos, we further introduce a DINO-guided motion customization module that rearranges and refines motion fields based on content correspondences. The customized motion field is then used to guide the DiT denoising process, ensuring that the synthesized video inherits the reference motion while preserving target appearance and semantics. Extensive experiments demonstrate that MotionAdapter outperforms state-of-the-art methods in both qualitative and quantitative evaluations. Moreover, MotionAdapter naturally supports complex motion transfer and motion editing tasks such as zooming.", "AI": {"tldr": "提出了一种基于扩散变换器架构的视频运动转移框架MotionAdapter，实现了复杂视频间有效运动转移。", "motivation": "现有的文本到视频模型在生成高质量和时间连贯性视频方面取得进步，但仍难以进行复杂的视频运动转移。为了改善这一问题，提出了MotionAdapter来实现更有效的运动分离与定制。", "method": "利用3D全注意力模块内的跨帧注意分析来隔离运动，并引入一个基于DINO引导的运动定制模块，根据内容对应关系重新排列和优化运动场，以缩小参考视频和目标视频之间的语义差距。最后，使用自定义后的运动场指导DiT去噪过程。", "result": "实验表明MotionAdapter在定性和定量评估中均优于现有方法，并且能够支持复杂的运动转移和编辑任务如变焦。", "conclusion": "通过提出MotionAdapter框架，解决了视频间复杂运动有效转移的问题，在各种测试中表现出优越性能。"}}
{"id": "2601.01950", "pdf": "https://arxiv.org/pdf/2601.01950", "abs": "https://arxiv.org/abs/2601.01950", "authors": ["Meng Wang", "Wenjing Dai", "Jiawan Zhang", "Xiaojie Guo"], "title": "Face Normal Estimation from Rags to Riches", "categories": ["cs.CV"], "comment": null, "summary": "Although recent approaches to face normal estimation have achieved promising results, their effectiveness heavily depends on large-scale paired data for training. This paper concentrates on relieving this requirement via developing a coarse-to-fine normal estimator. Concretely, our method first trains a neat model from a small dataset to produce coarse face normals that perform as guidance (called exemplars) for the following refinement. A self-attention mechanism is employed to capture long-range dependencies, thus remedying severe local artifacts left in estimated coarse facial normals. Then, a refinement network is customized for the sake of mapping input face images together with corresponding exemplars to fine-grained high-quality facial normals. Such a logical function split can significantly cut the requirement of massive paired data and computational resource. Extensive experiments and ablation studies are conducted to demonstrate the efficacy of our design and reveal its superiority over state-of-the-art methods in terms of both training expense as well as estimation quality. Our code and models are open-sourced at: https://github.com/AutoHDR/FNR2R.git.", "AI": {"tldr": "本文提出了一种从少量数据中估计精细面部法线的方法。", "motivation": "当前的面部法线估计方法依赖于大规模配对数据训练，这限制了其应用。本文旨在减少这种需求，通过开发一种粗到细的正常估计器来实现这一目标。", "method": "首先使用一个小规模的数据集训练一个模型以生成粗糙的脸部法线作为指导（称为示例），然后利用自注意力机制捕捉长程依赖关系以修复严重的局部异常。接着定制了一个细化网络将输入面部图像与相应的示例映射到高质量的细致脸部法线上。", "result": "广泛的实验和消融研究证明了该设计的有效性，并表明其在训练成本和估计质量方面均优于最先进的方法。", "conclusion": "本文提出的方法显著减少了对大量配对数据的需求，同时提供了高质量的面部法线估计。"}}
{"id": "2601.01948", "pdf": "https://arxiv.org/pdf/2601.01948", "abs": "https://arxiv.org/abs/2601.01948", "authors": ["Zhihao Gu", "Ming Yang", "Difan Zou", "Dong Xu"], "title": "Learning Diffusion Policy from Primitive Skills for Robot Manipulation", "categories": ["cs.RO"], "comment": "Accepted to AAAI2026", "summary": "Diffusion policies (DP) have recently shown great promise for generating actions in robotic manipulation. However, existing approaches often rely on global instructions to produce short-term control signals, which can result in misalignment in action generation. We conjecture that the primitive skills, referred to as fine-grained, short-horizon manipulations, such as ``move up'' and ``open the gripper'', provide a more intuitive and effective interface for robot learning. To bridge this gap, we propose SDP, a skill-conditioned DP that integrates interpretable skill learning with conditional action planning. SDP abstracts eight reusable primitive skills across tasks and employs a vision-language model to extract discrete representations from visual observations and language instructions. Based on them, a lightweight router network is designed to assign a desired primitive skill for each state, which helps construct a single-skill policy to generate skill-aligned actions. By decomposing complex tasks into a sequence of primitive skills and selecting a single-skill policy, SDP ensures skill-consistent behavior across diverse tasks. Extensive experiments on two challenging simulation benchmarks and real-world robot deployments demonstrate that SDP consistently outperforms SOTA methods, providing a new paradigm for skill-based robot learning with diffusion policies.", "AI": {"tldr": "该论文提出了一种基于基本技能的扩散策略SDP，用于机器人操作任务。", "motivation": "现有的扩散政策依赖于全局指令生成短期控制信号，可能导致动作生成不一致。引入更直观有效的接口——基础技能来改进这一问题。", "method": "SDP将复杂的任务分解为一系列的基础技能，并通过视觉语言模型提取离散表示，设计轻量级路由器网络分配特定状态下的基础技能以生成相应操作。", "result": "在两个挑战性的仿真基准测试和实际机器人部署上，SDP的表现优于当前最优方法。", "conclusion": "该研究提出了一种基于基本技能的扩散策略SDP的新范式，实现了跨多样任务的一致性行为。"}}
{"id": "2601.01946", "pdf": "https://arxiv.org/pdf/2601.01946", "abs": "https://arxiv.org/abs/2601.01946", "authors": ["Sichao Song", "Yuki Okafuji", "Takuya Iwamoto", "Jun Baba", "Hiroshi Ishiguro"], "title": "From Metrics to Meaning: Insights from a Mixed-Methods Field Experiment on Retail Robot Deployment", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "We report a mixed-methods field experiment of a conversational service robot deployed under everyday staffing discretion in a live bedding store. Over 12 days we alternated three conditions--Baseline (no robot), Robot-only, and Robot+Fixture--and video-annotated the service funnel from passersby to purchase. An explanatory sequential design then used six post-experiment staff interviews to interpret the quantitative patterns. Quantitatively, the robot increased stopping per passerby (highest with the fixture), yet clerk-led downstream steps per stopper--clerk approach, store entry, assisted experience, and purchase--decreased. Interviews explained this divergence: clerks avoided interrupting ongoing robot-customer talk, struggled with ambiguous timing amid conversational latency, and noted child-centered attraction that often satisfied curiosity at the doorway. The fixture amplified visibility but also anchored encounters at the threshold, creating a well-defined micro-space where needs could ``close'' without moving inside. We synthesize these strands into an integrative account from the initial show of interest on the part of a customer to their entering the store and derive actionable guidance. The results advance the understanding of interactions between customers, staff members, and the robot and offer practical recommendations for deploying service robots in high-touch retail.", "AI": {"tldr": "研究通过混合方法实验探讨了零售机器人在床品店部署的效果和影响。", "motivation": "探索服务型机器人在零售环境中的作用，特别是在顾客与员工互动方面的影响。", "method": "进行为期12天的现场实验，交替设置基线（无机器人）、只使用机器人和机器人加展示柜三种条件，并通过视频标注服务漏斗从行人到购买过程。随后利用六次员工访谈解释定量数据模式。", "result": "机器人的存在增加了行人在店门口停留的概率，但顾客进入店内、接受协助体验及最终完成购物的比例降低。员工不愿打断机器人与顾客的交流，难以掌握合适的介入时机，并且儿童对机器人的好奇往往在店门口得到满足。", "conclusion": "研究揭示了客户、员工和机器人之间互动的独特动态，为服务型机器人在高接触零售环境中的部署提供了可操作性建议"}}
{"id": "2601.01944", "pdf": "https://arxiv.org/pdf/2601.01944", "abs": "https://arxiv.org/abs/2601.01944", "authors": ["Matteo Esposito", "Andrea Janes", "Valentina Lenarduzzi", "Davide Taibi"], "title": "The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.IR", "cs.PL"], "comment": "ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026", "summary": "In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored. We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.", "AI": {"tldr": "本文旨在通过大规模分析来评估Python和Java开源项目中AI库的采用情况及其对开发活动、社区参与度和技术生态的影响。", "motivation": "随着人工智能在开源软件中的流行，其具体影响尚未被充分研究。本文旨在填补这一空白，探索AI集成如何重塑软件开发实践。", "method": "通过对157,700个潜在的开源项目进行分析，采用仓库指标和软件指标比较使用AI库与未使用的项目的差异。", "result": "预期发现使用AI库的项目在开发活动、社区参与度和技术复杂性上存在可测量的不同。", "conclusion": "通过证据表明AI集成如何改变软件开发实践，并为未来的研究提供参考。"}}
{"id": "2601.01939", "pdf": "https://arxiv.org/pdf/2601.01939", "abs": "https://arxiv.org/abs/2601.01939", "authors": ["Victor Sanchez", "Chris Reinke", "Ahamed Mohamed", "Xavier Alameda-Pineda"], "title": "OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation", "categories": ["cs.AI"], "comment": null, "summary": "In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.", "AI": {"tldr": "本文介绍了OpenSocInt，一个用于多模态社交互动模拟和训练社交代理的开源软件。", "motivation": "为了提供一个多模态交互环境来探索感知特征、编码融合以及不同代理在社会导航中的应用，作者开发了OpenSocInt框架。", "method": "该研究描述了OpenSocInt软件包，并通过基于社会导航任务的实验协议展示了其能力。它支持对不同类型感知特征及其组合进行探究。", "result": "本框架允许研究人员和开发者测试不同的代理和社会互动策略，但具体结果未在摘要中详细说明。", "conclusion": "结论总结了OpenSocInt框架的功能以及未来可能的研究方向，强调该软件的开放性和模块化设计使其成为研究多模态社交导航问题的强大工具。"}}
{"id": "2601.01932", "pdf": "https://arxiv.org/pdf/2601.01932", "abs": "https://arxiv.org/abs/2601.01932", "authors": ["Barbora Hudcová", "František Dušek", "Marco Tuccio", "Clément Hongler"], "title": "Visualizing the Structure of Lenia Parameter Space", "categories": ["nlin.CG", "cs.AI"], "comment": "2 pages", "summary": "Continuous cellular automata are rocketing in popularity, yet developing a theoretical understanding of their behaviour remains a challenge. In the case of Lenia, a few fundamental open problems include determining what exactly constitutes a soliton, what is the overall structure of the parameter space, and where do the solitons occur in it. In this abstract, we present a new method to automatically classify Lenia systems into four qualitatively different dynamical classes. This allows us to detect moving solitons, and to provide an interactive visualization of Lenia's parameter space structure on our website https://lenia-explorer.vercel.app/. The results shed new light on the above-mentioned questions and lead to several observations: the existence of new soliton families for parameters where they were not believed to exist, or the universality of the phase space structure across various kernels.", "AI": {"tldr": "论文提出了一个新的方法来自动分类Lenia系统，并通过可视化参数空间结构揭示了新的发现。", "motivation": "研究者希望通过理解连续细胞自动机的行为，特别是解决Lenia中的基础问题如定义soliton、了解参数空间的整体结构以及确定其发生位置。", "method": "论文提出了一种新方法来将Lenia系统分类为四种不同的动力学类别，并通过交互式可视化工具展示了整个参数空间的结构。", "result": "结果揭示了在之前被认为没有新的soliton存在的参数区域中发现了新的soliton家族，以及相空间结构在不同核中的普遍性。", "conclusion": "该研究提供了一种理解Lenia行为的新视角，并通过自动分类和可视化工具推动了对该系统更深入的研究。"}}
{"id": "2601.01931", "pdf": "https://arxiv.org/pdf/2601.01931", "abs": "https://arxiv.org/abs/2601.01931", "authors": ["Willem Röpke", "Samuel Coward", "Andrei Lupu", "Thomas Foster", "Tim Rocktäschel", "Jakob Foerster"], "title": "DéjàQ: Open-Ended Evolution of Diverse, Learnable and Verifiable Problems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advances in reasoning models have yielded impressive results in mathematics and coding. However, most approaches rely on static datasets, which have been suggested to encourage memorisation and limit generalisation. We introduce DéjàQ, a framework that departs from this paradigm by jointly evolving a diverse set of synthetic mathematical problems alongside model training. This evolutionary process adapts to the model's ability throughout training, optimising problems for learnability. We propose two LLM-driven mutation strategies in which the model itself mutates the training data, either by altering contextual details or by directly modifying problem structure. We find that the model can generate novel and meaningful problems, and that these LLM-driven mutations improve RL training. We analyse key aspects of DéjàQ, including the validity of generated problems and computational overhead. Our results underscore the potential of dynamically evolving training data to enhance mathematical reasoning and indicate broader applicability, which we will support by open-sourcing our code.", "AI": {"tldr": "提出了一种框架DéjàQ，该框架通过在模型训练期间共同进化一组多样化的合成数学问题来增强数学推理能力。", "motivation": "大多数方法依赖静态数据集，这可能导致记忆而不是泛化。作者希望通过动态生成和适应模型的训练数据来提高模型的学习能力和泛化能力。", "method": "DéjàQ框架通过两种LLM驱动的方法改变训练数据：一种是修改问题中的上下文细节，另一种是直接改变问题结构。这种方法确保了生成的问题的有效性和计算效率。", "result": "实验结果表明，这种动态进化训练数据的方法可以提高模型的数学推理能力，并且能够产生新颖且有意义的问题。", "conclusion": "该框架显示出了增强数学推理能力和广泛适用性的潜力，作者将通过开源代码来支持其应用。"}}
{"id": "2601.01930", "pdf": "https://arxiv.org/pdf/2601.01930", "abs": "https://arxiv.org/abs/2601.01930", "authors": ["Dongfang Zhao"], "title": "MCGI: Manifold-Consistent Graph Indexing for Billion-Scale Disk-Resident Vector Search", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Graph-based Approximate Nearest Neighbor (ANN) search often suffers from performance degradation in high-dimensional spaces due to the ``Euclidean-Geodesic mismatch,'' where greedy routing diverges from the underlying data manifold. To address this, we propose Manifold-Consistent Graph Indexing (MCGI), a geometry-aware and disk-resident indexing method that leverages Local Intrinsic Dimensionality (LID) to dynamically adapt search strategies to the data's intrinsic geometry. Unlike standard algorithms that treat dimensions uniformly, MCGI modulates its beam search budget based on in situ geometric analysis, eliminating dependency on static hyperparameters. Theoretical analysis confirms that MCGI enables improved approximation guarantees by preserving manifold-consistent topological connectivity. Empirically, MCGI achieves 5.8$\\times$ higher throughput at 95\\% recall on high-dimensional GIST1M compared to state-of-the-art DiskANN. On the billion-scale SIFT1B dataset, MCGI further validates its scalability by reducing high-recall query latency by 3$\\times$, while maintaining performance parity on standard lower-dimensional datasets.", "AI": {"tldr": "提出了一种用于高维向量搜索的基于图索引的方法MCGI，以解决传统方法在处理大规模数据时性能下降的问题。", "motivation": "现有基于图的近似最近邻搜索算法在高维空间中面临性能下降问题，原因是贪婪路由与底层数据流形之间的不匹配。为了解决这个问题，提出了MCGI来适应数据的内在几何结构。", "method": "通过使用局部内固维度（LID）动态调整搜索策略，消除对静态超参数的依赖。理论分析表明，MCGI通过保持流形一致性的拓扑连接提高了近似保证。", "result": "在高维GIST1M数据集上，MCGI实现了比DiskANN高出5.8倍的吞吐量，并且在95％召回率下表现更佳。在十亿规模的SIFT1B数据集中验证了其可扩展性，将高召回率查询延迟降低了3倍。", "conclusion": "MCGI通过适应数据的内在几何结构来改善搜索性能，在处理大规模和高维度的数据集时表现出色。"}}
{"id": "2601.01927", "pdf": "https://arxiv.org/pdf/2601.01927", "abs": "https://arxiv.org/abs/2601.01927", "authors": ["Firuz Kamalov", "Hana Sulieman", "Witold Pedrycz"], "title": "Theoretical Convergence of SMOTE-Generated Samples", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Imbalanced data affects a wide range of machine learning applications, from healthcare to network security. As SMOTE is one of the most popular approaches to addressing this issue, it is imperative to validate it not only empirically but also theoretically. In this paper, we provide a rigorous theoretical analysis of SMOTE's convergence properties. Concretely, we prove that the synthetic random variable Z converges in probability to the underlying random variable X. We further prove a stronger convergence in mean when X is compact. Finally, we show that lower values of the nearest neighbor rank lead to faster convergence offering actionable guidance to practitioners. The theoretical results are supported by numerical experiments using both real-life and synthetic data. Our work provides a foundational understanding that enhances data augmentation techniques beyond imbalanced data scenarios.", "AI": {"tldr": "该论文对SMOTE生成样本的收敛性进行了严格的理论分析。", "motivation": "不平衡数据影响从医疗保健到网络安全的各种机器学习应用，验证SMOTE不仅需要实证还需要理论证明。", "method": "通过数学推导证明了合成随机变量Z以概率方式收敛于基础随机变量X，并在X为紧集时展示了更强的均值收敛性。此外，还表明较低的最近邻秩可加速收敛。", "result": "理论结果得到了使用实际和合成数据进行数值实验的支持。", "conclusion": "该工作提供了增强数据扩充技术的基础理解，超越了不平衡数据场景的应用范围。"}}
{"id": "2601.01926", "pdf": "https://arxiv.org/pdf/2601.01926", "abs": "https://arxiv.org/abs/2601.01926", "authors": ["Zhifei Li", "Yiran Wang", "Chenyi Xiong", "Yujing Xia", "Xiaoju Hou", "Yue Zhao", "Miao Zhang", "Kui Xiao", "Bing Yang"], "title": "MacVQA: Adaptive Memory Allocation and Global Noise Filtering for Continual Visual Question Answering", "categories": ["cs.CV"], "comment": "Accepted to AAAI 2026", "summary": "Visual Question Answering (VQA) requires models to reason over multimodal information, combining visual and textual data. With the development of continual learning, significant progress has been made in retaining knowledge and adapting to new information in the VQA domain. However, current methods often struggle with balancing knowledge retention, adaptation, and robust feature representation. To address these challenges, we propose a novel framework with adaptive memory allocation and global noise filtering called MacVQA for visual question answering. MacVQA fuses visual and question information while filtering noise to ensure robust representations, and employs prototype-based memory allocation to optimize feature quality and memory usage. These designs enable MacVQA to balance knowledge acquisition, retention, and compositional generalization in continual VQA learning. Experiments on ten continual VQA tasks show that MacVQA outperforms existing baselines, achieving 43.38% average accuracy and 2.32% average forgetting on standard tasks, and 42.53% average accuracy and 3.60% average forgetting on novel composition tasks.", "AI": {"tldr": "提出了一种新的框架MacVQA，用于解决视觉问答中的知识保留、适应性和健壮特征表示之间的平衡问题。", "motivation": "现有方法在处理持续学习时，在知识保留、适应性以及鲁棒特性表达之间难以达到良好的平衡。", "method": "MacVQA通过自适应内存分配和全局噪声过滤来融合视觉信息和提问内容，确保稳健的表现，并采用基于原型的内存分配优化特征质量和内存使用。", "result": "实验结果表明，在十个持续学习问答任务中，MacVQA在标准任务上获得了43.38%的平均准确率和2.32%的平均遗忘量；在新颖组合任务上则为42.53%的平均准确率及3.60%的平均遗忘量。", "conclusion": "通过设计有效的内存分配策略和噪声过滤机制，MacVQA能够在持续学习视觉问答中平衡知识获取、保留以及组成泛化能力。"}}
{"id": "2601.01925", "pdf": "https://arxiv.org/pdf/2601.01925", "abs": "https://arxiv.org/abs/2601.01925", "authors": ["Lianjie Jia", "Yuhan Wu", "Binghao Ran", "Yifan Wang", "Lijun Wang", "Huchuan Lu"], "title": "AR-MOT: Autoregressive Multi-object Tracking", "categories": ["cs.CV"], "comment": "12 pages, 5 figures", "summary": "As multi-object tracking (MOT) tasks continue to evolve toward more general and multi-modal scenarios, the rigid and task-specific architectures of existing MOT methods increasingly hinder their applicability across diverse tasks and limit flexibility in adapting to new tracking formulations. Most approaches rely on fixed output heads and bespoke tracking pipelines, making them difficult to extend to more complex or instruction-driven tasks. To address these limitations, we propose AR-MOT, a novel autoregressive paradigm that formulates MOT as a sequence generation task within a large language model (LLM) framework. This design enables the model to output structured results through flexible sequence construction, without requiring any task-specific heads. To enhance region-level visual perception, we introduce an Object Tokenizer based on a pretrained detector. To mitigate the misalignment between global and regional features, we propose a Region-Aware Alignment (RAA) module, and to support long-term tracking, we design a Temporal Memory Fusion (TMF) module that caches historical object tokens. AR-MOT offers strong potential for extensibility, as new modalities or instructions can be integrated by simply modifying the output sequence format without altering the model architecture. Extensive experiments on MOT17 and DanceTrack validate the feasibility of our approach, achieving performance comparable to state-of-the-art methods while laying the foundation for more general and flexible MOT systems.", "AI": {"tldr": "AR-MOT 提出了一种自回归多目标跟踪框架，将 MOT 转化为序列生成任务，并通过预训练检测器引入对象标记和区域感知对齐模块以支持长期跟踪。", "motivation": "现有的 MOT 方法受限于固定输出头和专门的追踪管道，难以适应更复杂或多模态的任务。因此提出 AR-MOT 来解决这些问题，提高其通用性和灵活性。", "method": "AR-MOT 设计了一个自回归框架将 MOT 转化为序列生成任务，并使用预训练检测器引入对象标记来增强视觉感知；同时设计了区域感知对齐和时间记忆融合模块以支持长期跟踪。", "result": "在 MOT17 和 DanceTrack 数据集上的实验结果表明，AR-MOT 方法的表现与当前最先进的方法相当，展示了其可行性以及为更通用、灵活的多目标追踪系统打下了基础。", "conclusion": "AR-MOT 提供了一种新的视角来解决多对象跟踪问题，并在不改变模型架构的情况下实现了良好的性能和可扩展性。"}}
{"id": "2601.01921", "pdf": "https://arxiv.org/pdf/2601.01921", "abs": "https://arxiv.org/abs/2601.01921", "authors": ["Mikel Robredo", "Matteo Esposito", "Fabio Palomba", "Rafael Peñaloza", "Valentina Lenarduzzi"], "title": "A Defect is Being Born: How Close Are We? A Time Sensitive Forecasting Approach", "categories": ["cs.SE", "cs.AI", "cs.IR", "cs.LG"], "comment": "ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026", "summary": "Background. Defect prediction has been a highly active topic among researchers in the Empirical Software Engineering field. Previous literature has successfully achieved the most accurate prediction of an incoming fault and identified the features and anomalies that precede it through just-in-time prediction. As software systems evolve continuously, there is a growing need for time-sensitive methods capable of forecasting defects before they manifest. Aim. Our study seeks to explore the effectiveness of time-sensitive techniques for defect forecasting. Moreover, we aim to investigate the early indicators that precede the occurrence of a defect. Method. We will train multiple time-sensitive forecasting techniques to forecast the future bug density of a software project, as well as identify the early symptoms preceding the occurrence of a defect. Expected results. Our expected results are translated into empirical evidence on the effectiveness of our approach for early estimation of bug proneness.", "AI": {"tldr": "研究探索了时间敏感型预测技术在软件缺陷早期预警中的有效性，并识别潜在的缺陷前兆。", "motivation": "随着软件系统不断进化，需要能够提前预测缺陷的方法。因此，该研究旨在通过时间敏感的方法来提高对即将出现的缺陷进行准确预测的能力。", "method": "使用多种时间敏感预报方法训练模型，以预测未来一段时间内软件项目的缺陷密度，并识别可能预示缺陷发生的早期症状。", "result": "预期结果将为这种用于评估潜在错误倾向性的早期估算方法提供实证证据。", "conclusion": "通过这种方法能够有效提升对软件系统中即将到来的缺陷进行预警的能力。"}}
{"id": "2601.01916", "pdf": "https://arxiv.org/pdf/2601.01916", "abs": "https://arxiv.org/abs/2601.01916", "authors": ["Francisco Angulo de Lafuente", "Vladimir Veselov", "Richard Goodman"], "title": "Toward Thermodynamic Reservoir Computing: Exploring SHA-256 ASICs as Potential Physical Substrates", "categories": ["cs.NE"], "comment": "8 pages, 7 tables, Position Paper / Hypothesis with Preliminary Observations", "summary": "We propose a theoretical framework--Holographic Reservoir Computing (HRC)--which hypothesizes that the thermodynamic noise and timing dynamics in voltage-stressed Bitcoin mining ASICs (BM1366) could potentially serve as a physical reservoir computing substrate. We present the CHIMERA (Conscious Hybrid Intelligence via Miner-Embedded Resonance Architecture) system architecture, which treats the SHA-256 hashing pipeline not as an entropy source, but as a deterministic diffusion operator whose timing characteristics under controlled voltage and frequency conditions may exhibit computationally useful dynamics. We report preliminary observations of non-Poissonian variability in inter-arrival time statistics during edge-of-stability operation, which we term the \"Silicon Heartbeat\" hypothesis. Theoretical analysis based on Hierarchical Number System (HNS) representations suggests that such architectures could achieve O(log n) energy scaling compared to traditional von Neumann O(2^n) dependencies. However, we emphasize that these are theoretical projections requiring experimental validation. We present the implemented measurement infrastructure, acknowledge current limitations, and outline the experimental program necessary to confirm or refute these hypotheses. This work contributes to the emerging field of thermodynamic computing by proposing a novel approach to repurposing obsolete cryptographic hardware for neuromorphic applications.", "AI": {"tldr": "该论文提出了将比特币挖矿ASIC作为物理计算基质的理论框架Holographic Reservoir Computing (HRC)，并报告了初步观察结果。", "motivation": "为了探索废弃的加密硬件在神经形态应用中的新用途，提出了一种基于热力学噪声和定时动态特性的新型计算架构。", "method": "通过测量基础设施实施实验，并理论分析提出了Silicon Heartbeat假设，即SHA-256哈希管道的时间特性可能表现出有用的计算动力学。", "result": "初步观察到边缘稳定性操作期间的非泊松变异性，表明这些架构理论上可实现O(log n)能量缩放。", "conclusion": "理论分析和实验基础设施显示了一种新的基于热力学计算的方法，但需要进一步验证。"}}
{"id": "2601.01915", "pdf": "https://arxiv.org/pdf/2601.01915", "abs": "https://arxiv.org/abs/2601.01915", "authors": ["Yujie Hu", "Zecheng Tang", "Xu Jiang", "Weiqi Li", "Jian Zhang"], "title": "TalkPhoto: A Versatile Training-Free Conversational Assistant for Intelligent Image Editing", "categories": ["cs.CV"], "comment": "a Conversational Assistant for Intelligent Image Editing", "summary": "Thanks to the powerful language comprehension capabilities of Large Language Models (LLMs), existing instruction-based image editing methods have introduced Multimodal Large Language Models (MLLMs) to promote information exchange between instructions and images, ensuring the controllability and flexibility of image editing. However, these frameworks often build a multi-instruction dataset to train the model to handle multiple editing tasks, which is not only time-consuming and labor-intensive but also fails to achieve satisfactory results. In this paper, we present TalkPhoto, a versatile training-free image editing framework that facilitates precise image manipulation through conversational interaction. We instruct the open-source LLM with a specially designed prompt template to analyze user needs after receiving instructions and hierarchically invoke existing advanced editing methods, all without additional training. Moreover, we implement a plug-and-play and efficient invocation of image editing methods, allowing complex and unseen editing tasks to be integrated into the current framework, achieving stable and high-quality editing results. Extensive experiments demonstrate that our method not only provides more accurate invocation with fewer token consumption but also achieves higher editing quality across various image editing tasks.", "AI": {"tldr": "TalkPhoto 是一种无需训练的图像编辑框架，通过对话互动实现精准的图像操作。", "motivation": "现有的基于指令的图像编辑方法依赖于多指令数据集进行模型训练，耗时且效果不理想。因此，提出 TalkPhoto 来解决这些问题。", "method": "TalkPhoto 使用专为 LLM 设计的提示模板分析用户需求，并分层调用现有高级编辑方法，实现无需额外训练的图像编辑。", "result": "实验表明，该方法在各种图像编辑任务中实现了更准确的调用和更高的编辑质量，同时减少了标记消耗。", "conclusion": "TalkPhoto 提供了一种稳定且高质量的图像编辑解决方案，适用于复杂和未知的任务。"}}
{"id": "2601.01914", "pdf": "https://arxiv.org/pdf/2601.01914", "abs": "https://arxiv.org/abs/2601.01914", "authors": ["Arjun Ramesh Kaushik", "Nalini K. Ratha", "Venu Govindaraju"], "title": "Learning Action Hierarchies via Hybrid Geometric Diffusion", "categories": ["cs.CV"], "comment": "Accepted at WACV-26", "summary": "Temporal action segmentation is a critical task in video understanding, where the goal is to assign action labels to each frame in a video. While recent advances leverage iterative refinement-based strategies, they fail to explicitly utilize the hierarchical nature of human actions. In this work, we propose HybridTAS - a novel framework that incorporates a hybrid of Euclidean and hyperbolic geometries into the denoising process of diffusion models to exploit the hierarchical structure of actions. Hyperbolic geometry naturally provides tree-like relationships between embeddings, enabling us to guide the action label denoising process in a coarse-to-fine manner: higher diffusion timesteps are influenced by abstract, high-level action categories (root nodes), while lower timesteps are refined using fine-grained action classes (leaf nodes). Extensive experiments on three benchmark datasets, GTEA, 50Salads, and Breakfast, demonstrate that our method achieves state-of-the-art performance, validating the effectiveness of hyperbolic-guided denoising for the temporal action segmentation task.", "AI": {"tldr": "提出了一种新的框架HybridTAS，通过结合欧几里得和双曲几何来改进扩散模型的去噪过程，从而更好地利用动作分段任务中的层次结构。", "motivation": "现有的迭代细化策略未能充分利用人类行动的层级性。因此，研究者希望通过引入双曲几何来指导去噪过程，实现从粗到细的动作标签划分。", "method": "HybridTAS结合了欧几里得和双曲几何空间，在扩散模型的去噪过程中利用动作层次结构，通过在不同的时间步骤上分别采用高阶和低阶动作类别来引导去噪过程。", "result": "实验结果表明，该方法在GTEA、50Salads和Breakfast三个基准数据集上的表现优于现有最佳的方法，证明了双曲几何指导下的去噪流程的有效性。", "conclusion": "HybridTAS框架通过结合双曲空间的特性有效地提高了动作层次结构中的时间分割性能。"}}
{"id": "2601.01910", "pdf": "https://arxiv.org/pdf/2601.01910", "abs": "https://arxiv.org/abs/2601.01910", "authors": ["Minh Hieu Ha", "Khanh Ly Ta", "Hung Phan", "Tung Doan", "Tung Dao", "Dao Tran", "Huynh Thi Thanh Binh"], "title": "MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning", "categories": ["cs.AI"], "comment": null, "summary": "Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency. We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.", "AI": {"tldr": "该论文提出了MMP-A*，一种结合视觉语言模型的多模态框架以提高路径规划中的空间理解和计算效率。", "motivation": "经典A*算法在大规模场景中存在计算和内存成本过高的问题，而仅依赖文本推理的大规模语言模型无法解决复杂环境下的路径规划问题。因此需要一种新的方法来结合空间感知能力和高效计算能力。", "method": "MMP-A*框架通过引入视觉-语言模型实现对物理几何的理解，并采用自适应衰减机制动态调节不确定航点的影响，确保轨迹的几何有效性同时减少内存消耗。", "result": "实验结果表明，在复杂环境中，MMP-A*能够生成接近最优路径并大幅降低计算成本。", "conclusion": "MMP-A*框架展示了其作为自主导航中感知驱动和计算高效范式的潜力。"}}
{"id": "2601.01908", "pdf": "https://arxiv.org/pdf/2601.01908", "abs": "https://arxiv.org/abs/2601.01908", "authors": ["Jingjing Wang", "Qianglin Liu", "Zhuo Xiao", "Xinning Yao", "Bo Liu", "Lu Li", "Lijuan Niu", "Fugen Zhou"], "title": "Nodule-DETR: A Novel DETR Architecture with Frequency-Channel Attention for Ultrasound Thyroid Nodule Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Thyroid cancer is the most common endocrine malignancy, and its incidence is rising globally. While ultrasound is the preferred imaging modality for detecting thyroid nodules, its diagnostic accuracy is often limited by challenges such as low image contrast and blurred nodule boundaries. To address these issues, we propose Nodule-DETR, a novel detection transformer (DETR) architecture designed for robust thyroid nodule detection in ultrasound images. Nodule-DETR introduces three key innovations: a Multi-Spectral Frequency-domain Channel Attention (MSFCA) module that leverages frequency analysis to enhance features of low-contrast nodules; a Hierarchical Feature Fusion (HFF) module for efficient multi-scale integration; and Multi-Scale Deformable Attention (MSDA) to flexibly capture small and irregularly shaped nodules. We conducted extensive experiments on a clinical dataset of real-world thyroid ultrasound images. The results demonstrate that Nodule-DETR achieves state-of-the-art performance, outperforming the baseline model by a significant margin of 0.149 in mAP@0.5:0.95. The superior accuracy of Nodule-DETR highlights its significant potential for clinical application as an effective tool in computer-aided thyroid diagnosis. The code of work is available at https://github.com/wjj1wjj/Nodule-DETR.", "AI": {"tldr": "提出了一种用于甲状腺结节检测的新架构Nodule-DETR，该架构在超声图像中实现了先进的诊断准确性。", "motivation": "旨在提高甲状腺结节在低对比度和模糊边界情况下的超声图像中的检测准确率。", "method": "通过引入多光谱频域通道注意模块、分层特征融合模块以及多尺度可变形注意力机制，以增强小而规则形状的结节检测性能。", "result": "实验表明Nodule-DETR在mAP@0.5:0.95指标上优于基准模型，提高了0.149的精度。", "conclusion": "此方法具有显著提高临床诊断准确性的潜力，并已在真实世界甲状腺超声图像数据集中进行了验证和证明其有效性。"}}
{"id": "2601.01904", "pdf": "https://arxiv.org/pdf/2601.01904", "abs": "https://arxiv.org/abs/2601.01904", "authors": ["Yuxuan Li", "Harshith Reddy Kethireddy", "Srijita Das"], "title": "Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Learning from Preferences in Reinforcement Learning (PbRL) has gained attention recently, as it serves as a natural fit for complicated tasks where the reward function is not easily available. However, preferences often come with uncertainty and noise if they are not from perfect teachers. Much prior literature aimed to detect noise, but with limited types of noise and most being uniformly distributed with no connection to observations. In this work, we formalize the notion of targeted feature-dependent noise and propose several variants like trajectory feature noise, trajectory similarity noise, uncertainty-aware noise, and Language Model noise. We evaluate feature-dependent noise, where noise is correlated with certain features in complex continuous control tasks from DMControl and Meta-world. Our experiments show that in some feature-dependent noise settings, the state-of-the-art noise-robust PbRL method's learning performance is significantly deteriorated, while PbRL method with no explicit denoising can surprisingly outperform noise-robust PbRL in majority settings. We also find language model's noise exhibits similar characteristics to feature-dependent noise, thereby simulating realistic humans and call for further study in learning with feature-dependent noise robustly.", "AI": {"tldr": "评估偏好强化学习中与特征相关的噪声影响。", "motivation": "现有的研究在检测噪声方面存在局限性，未能涵盖更复杂的、依赖于观察的噪声类型。因此需要深入探讨和形式化定义此类问题。", "method": "提出几种新的基于特征的相关噪声模型，并通过复杂连续控制任务实验评估其对学习性能的影响。", "result": "实验结果表明，在某些特定条件下，现有的抗噪方法表现不佳；而未明确去噪的方法反而在多数情况下更优。同时发现语言模型的噪声与特征相关噪声具有相似性。", "conclusion": "研究强调了识别和处理偏好强化学习中特征相关的噪声的重要性，并为未来的研究指明方向。"}}
{"id": "2601.01898", "pdf": "https://arxiv.org/pdf/2601.01898", "abs": "https://arxiv.org/abs/2601.01898", "authors": ["Yiran Tian", "Yuanjia Liu"], "title": "Multi-strategy Improved Northern Goshawk Optimization for WSN Coverage Enhancement", "categories": ["cs.NE"], "comment": null, "summary": "To enhance the coverage rate of Wireless Sensor Networks (WSNs), this paper proposes an advanced optimization strategy based on a multi-strategy integrated Northern Goshawk Optimization (NGO) algorithm. Specifically, multivariate chaotic mapping is first employed to improve the randomness and uniformity of the initial population. To further bolster population diversity and prevent the algorithm from stagnating in local optima, a bidirectional population evolutionary dynamics strategy is incorporated following the pursuit-and-evasion phase, thereby facilitating the attainment of the global optimal solution. Extensive simulations were conducted to evaluate the performance of the proposed multi-strategy NGO in WSN coverage. Experimental results demonstrate that the proposed algorithm significantly outperforms existing benchmarks in terms of both coverage enhancement and node connectivity.", "AI": {"tldr": "本文提出了一种基于多策略集成的北方鹰优化算法来提高无线传感器网络（WSN）的覆盖范围。", "motivation": "为了提升无线传感器网络的覆盖率，通过引入多种策略增强优化算法的效果。", "method": "首先利用多元混沌映射改进初始种群的随机性和均匀性；然后在追逐-逃避阶段之后加入双向种群进化动力学策略以增加群体多样性并避免陷入局部最优解，从而实现全局最优。", "result": "实验结果表明提出的多策略NGO算法在WSN覆盖增强和节点连通性方面显著优于现有基准方法。", "conclusion": "所提出的方法能够有效提升无线传感器网络的覆盖率和节点连接性能。"}}
{"id": "2601.01896", "pdf": "https://arxiv.org/pdf/2601.01896", "abs": "https://arxiv.org/abs/2601.01896", "authors": ["Jingyu Liu", "Jiaen Lin", "Yong Liu"], "title": "Tackling the Inherent Difficulty of Noise Filtering in RAG", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has become a widely adopted approach to enhance Large Language Models (LLMs) by incorporating external knowledge and reducing hallucinations. However, noisy or irrelevant documents are often introduced during RAG, potentially degrading performance and even causing hallucinated outputs. While various methods have been proposed to filter out such noise, we argue that identifying irrelevant information from retrieved content is inherently difficult and limited number of transformer layers can hardly solve this. Consequently, retrievers fail to filter out irrelevant documents entirely. Therefore, LLMs must be robust against such noise, but we demonstrate that standard fine-tuning approaches are often ineffective in enabling the model to selectively utilize relevant information while ignoring irrelevant content due to the structural constraints of attention patterns. To address this, we propose a novel fine-tuning method designed to enhance the model's ability to distinguish between relevant and irrelevant information within retrieved documents. Extensive experiments across multiple benchmarks show that our approach significantly improves the robustness and performance of LLMs.", "AI": {"tldr": "提出了一种新的微调方法，以增强模型区分检索文档中相关信息和不相关信息的能力。", "motivation": "在RAG框架下，噪声或无关的文档可能会引入干扰，导致性能下降甚至产生幻觉输出。尽管已有过滤噪声的方法，但识别这些信息仍然具有挑战性，并且标准微调方法通常对此无效。", "method": "提出了一种新的微调方法来增强模型区分相关和不相关信息的能力。", "result": "实验表明该方法显著提升了LLM的鲁棒性和性能。", "conclusion": "新提出的微调方法可以有效解决RAG框架下噪声过滤的问题，提高模型处理检索文档中信息的能力。"}}
{"id": "2601.01892", "pdf": "https://arxiv.org/pdf/2601.01892", "abs": "https://arxiv.org/abs/2601.01892", "authors": ["Arjun Ramesh Kaushik", "Naresh Kumar Devulapally", "Vishnu Suresh Lokhande", "Nalini K. Ratha", "Venu Govindaraju"], "title": "Forget Less by Learning from Parents Through Hierarchical Relationships", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at AAAI-26", "summary": "Custom Diffusion Models (CDMs) offer impressive capabilities for personalization in generative modeling, yet they remain vulnerable to catastrophic forgetting when learning new concepts sequentially. Existing approaches primarily focus on minimizing interference between concepts, often neglecting the potential for positive inter-concept interactions. In this work, we present Forget Less by Learning from Parents (FLLP), a novel framework that introduces a parent-child inter-concept learning mechanism in hyperbolic space to mitigate forgetting. By embedding concept representations within a Lorentzian manifold, naturally suited to modeling tree-like hierarchies, we define parent-child relationships in which previously learned concepts serve as guidance for adapting to new ones. Our method not only preserves prior knowledge but also supports continual integration of new concepts. We validate FLLP on three public datasets and one synthetic benchmark, showing consistent improvements in both robustness and generalization.", "AI": {"tldr": "提出了一种名为Forget Less by Learning from Parents (FLLP)的新框架，通过在双曲空间中的父子概念间学习机制来减轻渐进性遗忘问题。", "motivation": "现有的定制扩散模型（CDMs）虽然具备个性化生成建模的潜力，但仍然容易由于连续学习新概念而产生灾难性遗忘。现有方法主要集中在减少概念间的干扰上，忽视了正向交互作用的可能。因此提出了一种新的框架来解决这个问题。", "method": "通过在Lorentz流形中嵌入概念表示，自然地适合于建模树状层次结构，在这种父子关系中，先前学习的概念作为适应新概念的指导。这种方法不仅保存了先前的知识，还支持持续的新概念集成。", "result": "该方法在三个公共数据集和一个合成基准上进行了验证，并显示出一致的改进，包括更强的鲁棒性和更好的泛化能力。", "conclusion": "FLLP通过引入父子关系学习机制成功地缓解了渐进性遗忘问题，并且保持或增强了模型的知识与性能。"}}
{"id": "2601.01891", "pdf": "https://arxiv.org/pdf/2601.01891", "abs": "https://arxiv.org/abs/2601.01891", "authors": ["Niloufar Alipour Talemi", "Julia Boone", "Fatemeh Afghah"], "title": "Agentic AI in Remote Sensing: Foundations, Taxonomy, and Emerging Systems", "categories": ["cs.CV"], "comment": "Accepted to the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026, GeoCV Workshop", "summary": "The paradigm of Earth Observation analysis is shifting from static deep learning models to autonomous agentic AI. Although recent vision foundation models and multimodal large language models advance representation learning, they often lack the sequential planning and active tool orchestration required for complex geospatial workflows. This survey presents the first comprehensive review of agentic AI in remote sensing. We introduce a unified taxonomy distinguishing between single-agent copilots and multi-agent systems while analyzing architectural foundations such as planning mechanisms, retrieval-augmented generation, and memory structures. Furthermore, we review emerging benchmarks that move the evaluation from pixel-level accuracy to trajectory-aware reasoning correctness. By critically examining limitations in grounding, safety, and orchestration, this work outlines a strategic roadmap for the development of robust, autonomous geospatial intelligence.", "AI": {"tldr": "该论文综述了远程感测中代理式AI的发展，提出了一个统一的分类法，并概述了未来发展的战略路线图。", "motivation": "传统的地球观测分析从静态深度学习模型转向自主代理式人工智能。尽管最近的视觉基础模型和多模态大型语言模型推进了表示学习，但它们通常缺乏复杂的地理空间工作流程所需的顺序规划和主动工具协调能力。", "method": "该论文通过引入一个统一分类法来区分单一代理助手与多代理系统，并分析架构基础如计划机制、检索增强生成和内存结构。同时综述了正在发展的基准测试，这些评估从像素级精度转向轨迹感知推理准确性。", "result": "结果展示了当前代理式AI在远程感测中的应用情况以及存在的限制问题，包括定位、安全性和协调性等方面。", "conclusion": "该工作指出了一条战略路线图以促进稳健自主的地理空间智能的发展。"}}
{"id": "2601.01887", "pdf": "https://arxiv.org/pdf/2601.01887", "abs": "https://arxiv.org/abs/2601.01887", "authors": ["Jiawen Zhang", "Lipeng He", "Kejia Chen", "Jian Lou", "Jian Liu", "Xiaohu Yang", "Ruoxi Jia"], "title": "Safety at One Shot: Patching Fine-Tuned LLMs with A Single Instance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning safety-aligned large language models (LLMs) can substantially compromise their safety. Previous approaches require many safety samples or calibration sets, which not only incur significant computational overhead during realignment but also lead to noticeable degradation in model utility. Contrary to this belief, we show that safety alignment can be fully recovered with only a single safety example, without sacrificing utility and at minimal cost. Remarkably, this recovery is effective regardless of the number of harmful examples used in fine-tuning or the size of the underlying model, and convergence is achieved within just a few epochs. Furthermore, we uncover the low-rank structure of the safety gradient, which explains why such efficient correction is possible. We validate our findings across five safety-aligned LLMs and multiple datasets, demonstrating the generality of our approach.", "AI": {"tldr": "本文提出了一种通过单个安全样例快速恢复大型语言模型的安全性的方法。", "motivation": "先前的方法需要大量的安全性样本或校准集，这不仅增加了再对齐过程中的计算开销，还可能导致模型性能的显著下降。为了克服这些缺点，作者试图证明仅使用一个安全样例就可以完全恢复模型的安全性。", "method": "通过揭示安全梯度的低秩结构，提出了一种利用单个安全样本来快速纠正和恢复大型语言模型安全性的方法，并在多个数据集上验证了该方法的有效性和通用性。", "result": "实验结果显示，无论是在使用了多少有害示例进行微调还是模型大小方面，通过仅一个安全样例即可实现安全性完全恢复，并且收敛速度非常快，只需几个epoch。", "conclusion": "本研究展示了单个安全样本在修复大型语言模型的安全性方面的有效性，这种方法不仅节省了计算资源，还保持了模型的实用性能。"}}
{"id": "2601.01878", "pdf": "https://arxiv.org/pdf/2601.01878", "abs": "https://arxiv.org/abs/2601.01878", "authors": ["Farzan Karimi-Malekabadi", "Suhaib Abdurahman", "Zhivar Sourati", "Jackson Trager", "Morteza Dehghani"], "title": "Theory Trace Card: Theory-Driven Socio-Cognitive Evaluation of LLMs", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "Socio-cognitive benchmarks for large language models (LLMs) often fail to predict real-world behavior, even when models achieve high benchmark scores. Prior work has attributed this evaluation-deployment gap to problems of measurement and validity. While these critiques are insightful, we argue that they overlook a more fundamental issue: many socio-cognitive evaluations proceed without an explicit theoretical specification of the target capability, leaving the assumptions linking task performance to competence implicit. Without this theoretical grounding, benchmarks that exercise only narrow subsets of a capability are routinely misinterpreted as evidence of broad competence: a gap that creates a systemic validity illusion by masking the failure to evaluate the capability's other essential dimensions. To address this gap, we make two contributions. First, we diagnose and formalize this theory gap as a foundational failure that undermines measurement and enables systematic overgeneralization of benchmark results. Second, we introduce the Theory Trace Card (TTC), a lightweight documentation artifact designed to accompany socio-cognitive evaluations, which explicitly outlines the theoretical basis of an evaluation, the components of the target capability it exercises, its operationalization, and its limitations. We argue that TTCs enhance the interpretability and reuse of socio-cognitive evaluations by making explicit the full validity chain, which links theory, task operationalization, scoring, and limitations, without modifying benchmarks or requiring agreement on a single theory.", "AI": {"tldr": "提出理论跟踪卡(TTC)来提高大型语言模型的社会认知评估的透明度和可解释性。", "motivation": "现有社会认知基准测试未能准确预测大语言模型的真实世界行为，原因是缺乏明确的能力理论基础。", "method": "诊断并形式化了当前评估中的理论差距问题，并引入TTC以增强评估结果的合理性和复用性。", "result": "通过引入TTC来改善社会认知评估过程，提高其透明度和可解释性。", "conclusion": "TTC能够帮助更好地理解大语言模型的能力范围和限制。"}}
{"id": "2601.01875", "pdf": "https://arxiv.org/pdf/2601.01875", "abs": "https://arxiv.org/abs/2601.01875", "authors": ["Kewen Cao", "Jianxu Chen", "Yongbing Zhang", "Ye Zhang", "Hongxiao Wang"], "title": "Toward Auditable Neuro-Symbolic Reasoning in Pathology: SQL as an Explicit Trace of Evidence", "categories": ["cs.AI", "q-bio.QM"], "comment": null, "summary": "Automated pathology image analysis is central to clinical diagnosis, but clinicians still ask which slide features drive a model's decision and why. Vision-language models can produce natural language explanations, but these are often correlational and lack verifiable evidence. In this paper, we introduce an SQL-centered agentic framework that enables both feature measurement and reasoning to be auditable. Specifically, after extracting human-interpretable cellular features, Feature Reasoning Agents compose and execute SQL queries over feature tables to aggregate visual evidence into quantitative findings. A Knowledge Comparison Agent then evaluates these findings against established pathological knowledge, mirroring how pathologists justify diagnoses from measurable observations. Extensive experiments evaluated on two pathology visual question answering datasets demonstrate our method improves interpretability and decision traceability while producing executable SQL traces that link cellular measurements to diagnostic conclusions.", "AI": {"tldr": "本文提出了一个基于SQL的代理框架，用于病理图像分析中的可审计神经符号推理。", "motivation": "目前自动化病理图像分析缺乏明确的决策依据和解释机制，难以满足临床医生的需求。本文旨在通过引入一种新的方法来解决这一问题，使模型的决策过程更加透明且可验证。", "method": "文章提出了一种基于SQL的代理框架，该框架首先提取人类可理解的细胞特征，然后由特性推理代理构建并执行查询以聚合视觉证据，并生成定量结论。知识比较代理会将这些结果与现有的病理学知识进行对比，从而模拟临床医生通过测量观察来支持诊断的过程。", "result": "实验表明本文的方法提高了模型决策过程的可解释性和追踪性，同时提供了连接细胞度量到诊断结论的执行SQL痕迹。", "conclusion": "基于SQL的代理框架为自动化病理图像分析提供了一个新的视角和工具，能够增强神经符号推理系统的透明度和可信度。"}}
{"id": "2601.01874", "pdf": "https://arxiv.org/pdf/2601.01874", "abs": "https://arxiv.org/abs/2601.01874", "authors": ["Shuhang Chen", "Yunqiu Xu", "Junjie Xie", "Aojun Lu", "Tao Feng", "Zeying Huang", "Ning Zhang", "Yi Sun", "Yi Yang", "Hangjie Yuan"], "title": "CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and interpretation of visual inputs. Notably, they all ignore the key issue of whether the extracted visual cues are faithfully integrated and properly utilized in subsequent reasoning. Motivated by this, we present CogFlow, a novel cognitive-inspired three-stage framework that incorporates a knowledge internalization stage, explicitly simulating the hierarchical flow of human reasoning: perception$\\Rightarrow$internalization$\\Rightarrow$reasoning. Inline with this hierarchical flow, we holistically enhance all its stages. We devise Synergistic Visual Rewards to boost perception capabilities in parametric and semantic spaces, jointly improving visual information extraction from symbols and diagrams. To guarantee faithful integration of extracted visual cues into subsequent reasoning, we introduce a Knowledge Internalization Reward model in the internalization stage, bridging perception and reasoning. Moreover, we design a Visual-Gated Policy Optimization algorithm to further enforce the reasoning is grounded with the visual knowledge, preventing models seeking shortcuts that appear coherent but are visually ungrounded reasoning chains. Moreover, we contribute a new dataset MathCog for model training, which contains samples with over 120K high-quality perception-reasoning aligned annotations. Comprehensive experiments and analysis on commonly used visual mathematical reasoning benchmarks validate the superiority of the proposed CogFlow.", "AI": {"tldr": "CogFlow 提出了一种新的认知启发式三阶段框架，旨在通过知识内化解决视觉数学问题。", "motivation": "尽管在多模态大型语言模型方面取得了显著进展，但在视觉数学推理中仍然存在挑战。现有方法主要集中在改进视觉输入的提取和解释上，而忽视了如何忠实整合这些线索并在后续推理中正确使用的问题。", "method": "CogFlow 设计了一种新的认知启发式三阶段框架：感知、内化和推理。通过协同视觉奖励增强模型在参数空间和语义空间中的感知能力，并引入知识内化奖励以确保提取的视觉线索被忠实整合到后续推理中，同时设计了视觉门控策略优化算法来保证推理过程与视觉信息紧密相关。", "result": "实验结果表明 CogFlow 在常用的视觉数学推理基准测试上表现优于其他方法。", "conclusion": "通过引入知识内化阶段，CogFlow 成功解决了现有模型在视觉数学问题解决中的瓶颈。"}}
{"id": "2601.01872", "pdf": "https://arxiv.org/pdf/2601.01872", "abs": "https://arxiv.org/abs/2601.01872", "authors": ["Hongbo Duan", "Shangyi Luo", "Zhiyuan Deng", "Yanbo Chen", "Yuanhao Chiang", "Yi Liu", "Fangming Liu", "Xueqian Wang"], "title": "CausalNav: A Long-term Embodied Navigation System for Autonomous Mobile Robots in Dynamic Outdoor Scenarios", "categories": ["cs.RO"], "comment": "Accepted by IEEE Robotics and Automation Letters (RA-L)", "summary": "Autonomous language-guided navigation in large-scale outdoor environments remains a key challenge in mobile robotics, due to difficulties in semantic reasoning, dynamic conditions, and long-term stability. We propose CausalNav, the first scene graph-based semantic navigation framework tailored for dynamic outdoor environments. We construct a multi-level semantic scene graph using LLMs, referred to as the Embodied Graph, that hierarchically integrates coarse-grained map data with fine-grained object entities. The constructed graph serves as a retrievable knowledge base for Retrieval-Augmented Generation (RAG), enabling semantic navigation and long-range planning under open-vocabulary queries. By fusing real-time perception with offline map data, the Embodied Graph supports robust navigation across varying spatial granularities in dynamic outdoor environments. Dynamic objects are explicitly handled in both the scene graph construction and hierarchical planning modules. The Embodied Graph is continuously updated within a temporal window to reflect environmental changes and support real-time semantic navigation. Extensive experiments in both simulation and real-world settings demonstrate superior robustness and efficiency.", "AI": {"tldr": "提出了一种基于场景图的语义导航框架CausalNav，用于动态室外环境下的自主语言引导导航。", "motivation": "解决大型室外环境中由语义推理、动态条件和长期稳定性带来的自主语言引导导航挑战。", "method": "通过使用大规模语言模型构建多级语义场景图（Embodied Graph），结合实时感知与离线地图数据，支持在不同空间粒度下的鲁棒导航。场景图中包含了粗粒度的地图信息和细粒度的对象实体，并能动态更新以适应环境变化。", "result": "实验结果表明CausalNav框架具有优异的稳健性和效率，在模拟和真实世界环境中均表现出色。", "conclusion": "通过提出CausalNav，解决了室外动态环境下基于语言引导导航的关键挑战，实现了长距离规划和支持开放词汇查询的任务。"}}
{"id": "2601.01870", "pdf": "https://arxiv.org/pdf/2601.01870", "abs": "https://arxiv.org/abs/2601.01870", "authors": ["Wenyu Shao", "Hongbo Liu", "Yunchuan Ma", "Ruili Wang"], "title": "Entity-Guided Multi-Task Learning for Infrared and Visible Image Fusion", "categories": ["cs.CV"], "comment": "Accepted by IEEE Transactions on Multimedia", "summary": "Existing text-driven infrared and visible image fusion approaches often rely on textual information at the sentence level, which can lead to semantic noise from redundant text and fail to fully exploit the deeper semantic value of textual information. To address these issues, we propose a novel fusion approach named Entity-Guided Multi-Task learning for infrared and visible image fusion (EGMT). Our approach includes three key innovative components: (i) A principled method is proposed to extract entity-level textual information from image captions generated by large vision-language models, eliminating semantic noise from raw text while preserving critical semantic information; (ii) A parallel multi-task learning architecture is constructed, which integrates image fusion with a multi-label classification task. By using entities as pseudo-labels, the multi-label classification task provides semantic supervision, enabling the model to achieve a deeper understanding of image content and significantly improving the quality and semantic density of the fused image; (iii) An entity-guided cross-modal interactive module is also developed to facilitate the fine-grained interaction between visual and entity-level textual features, which enhances feature representation by capturing cross-modal dependencies at both inter-visual and visual-entity levels. To promote the wide application of the entity-guided image fusion framework, we release the entity-annotated version of four public datasets (i.e., TNO, RoadScene, M3FD, and MSRS). Extensive experiments demonstrate that EGMT achieves superior performance in preserving salient targets, texture details, and semantic consistency, compared to the state-of-the-art methods. The code and dataset will be publicly available at https://github.com/wyshao-01/EGMT.", "AI": {"tldr": "提出了一种基于实体引导的多任务学习方法（EGMT）来融合红外和可见光图像。", "motivation": "现有的文本驱动的方法在处理语义噪声时效果不佳，无法充分利用文本信息的深层语义价值。因此提出了新的融合方法以解决这些问题。", "method": "包括三个关键创新部分：从大型视觉语言模型生成的图像描述中提取实体级别的文本信息；构建平行多任务学习架构，将图像融合与多标签分类任务结合，并使用实体作为伪标签提供语义监督；开发了基于实体引导的跨模态交互模块以增强特征表示。", "result": "实验表明EGMT方法在保留显著目标、纹理细节和语义一致性方面优于现有最佳方法。", "conclusion": "提出的方法能够有效地融合红外与可见光图像，提高了图像质量和语义密度。"}}
{"id": "2601.01869", "pdf": "https://arxiv.org/pdf/2601.01869", "abs": "https://arxiv.org/abs/2601.01869", "authors": ["Yi Zhou", "Haoyu Jiang", "Chenghao Zhu", "André Rossi"], "title": "Exact Clique Number Manipulation via Edge Interdiction", "categories": ["cs.DS"], "comment": null, "summary": "The Edge Interdiction Clique Problem (EICP) aims to remove at most $k$ edges from a graph so as to minimize the size of the largest clique in the remaining graph. This problem captures a fundamental question in graph manipulation: which edges are structurally critical for preserving large cliques? Such a problem is also motivated by practical applications including protein function maintenance and image matching. The EICP is computationally challenging and belongs to a complexity class beyond NP. Existing approaches rely on general mixed-integer bilevel programming solvers or reformulate the problem into a single-level mixed integer linear program. However, they are still not scalable when the graph size and interdiction budget $k$ grow. To overcome this, we investigate new mixed integer linear formulations, which recast the problem into a sequence of parameterized Edge Blocker Clique Problems (EBCP). This perspective decomposes the original problem into simpler subproblems and enables tighter modeling of clique-related inequalities. Furthermore, we propose a two-stage exact algorithm, \\textsc{RLCM}, which first applies problem-specific reduction techniques to shrink the graph and then solves the reduced problem using a tailored branch-and-cut framework. Extensive computational experiments on maximum clique benchmark graphs, large real-world sparse networks, and random graphs demonstrate that \\textsc{RLCM} consistently outperforms existing approaches.", "AI": {"tldr": "本文研究了通过移除最多k条边来最小化剩余图中最大团的大小的问题，提出了一种新的混合整数线性模型和两阶段精确算法\textsc{RLCM}。", "motivation": "该问题旨在捕捉图形操作中的基本问题：哪些边对于保持大的团是结构上关键的。此外，在蛋白质功能维护和图像匹配等实际应用中也有动机。", "method": "本文提出了一种新的混合整数线性模型，将原始问题分解为一系列参数化的边缘阻挡团问题（EBCP）。另外还设计了两阶段精确算法\textsc{RLCM}，该算法首先使用特定的问题缩减技术缩小图的规模，然后利用定制分支切割框架解决简化后的问题。", "result": "实验结果表明，所提出的\textsc{RLCM}方法在最大团基准图、大型稀疏网络和随机图上均优于现有方法。", "conclusion": "本文提出的新模型与算法\textsc{RLCM}对于解决边阻挡团问题具有显著效果，并且为未来研究提供了新的视角。"}}
{"id": "2601.01865", "pdf": "https://arxiv.org/pdf/2601.01865", "abs": "https://arxiv.org/abs/2601.01865", "authors": ["Wenlong Yang", "Canran Jin", "Weihang Yuan", "Chao Wang", "Lifeng Sun"], "title": "RRNet: Configurable Real-Time Video Enhancement with Arbitrary Local Lighting Variations", "categories": ["cs.CV"], "comment": null, "summary": "With the growing demand for real-time video enhancement in live applications, existing methods often struggle to balance speed and effective exposure control, particularly under uneven lighting. We introduce RRNet (Rendering Relighting Network), a lightweight and configurable framework that achieves a state-of-the-art tradeoff between visual quality and efficiency. By estimating parameters for a minimal set of virtual light sources, RRNet enables localized relighting through a depth-aware rendering module without requiring pixel-aligned training data. This object-aware formulation preserves facial identity and supports real-time, high-resolution performance using a streamlined encoder and lightweight prediction head. To facilitate training, we propose a generative AI-based dataset creation pipeline that synthesizes diverse lighting conditions at low cost. With its interpretable lighting control and efficient architecture, RRNet is well suited for practical applications such as video conferencing, AR-based portrait enhancement, and mobile photography. Experiments show that RRNet consistently outperforms prior methods in low-light enhancement, localized illumination adjustment, and glare removal.", "AI": {"tldr": "本文提出了一种轻量级的视频增强框架RRNet，能够在实时场景下有效处理不均匀光照问题。", "motivation": "现有的视频增强方法在应对非均匀照明时难以兼顾速度和曝光控制效果。为此，作者开发了能够进行局部补光并支持高分辨率性能的技术。", "method": "通过估计一组虚拟光源的参数，RRNet利用深度感知渲染模块实现局部重新光照，并且不需要像素对齐训练数据。此外还提出了一种生成式AI数据集创建管道以合成不同的照明条件。", "result": "实验表明，RRNet在低光增强、局部照明调整和去除眩光方面优于之前的方法。", "conclusion": "RRNet具备良好的可解释性光照控制和高效架构，适用于视频会议、基于AR的肖像增强等实际应用。"}}
{"id": "2601.01857", "pdf": "https://arxiv.org/pdf/2601.01857", "abs": "https://arxiv.org/abs/2601.01857", "authors": ["Defei Xia", "Bingfeng Pi", "Shenbin Zhang", "Song Hua", "Yunfei Wei", "Lei Zuo"], "title": "Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios", "categories": ["cs.AI"], "comment": null, "summary": "As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world practical experience, with three key innovations: (1) an adaptive prompt generation strategy that aligns with the agent's state and task goals to improve reliability and robustness; (2) a context-aware tool orchestration module that performs tool categorization, semantic retrieval, and adaptive invocation based on user intent and context; and (3) a layered memory mechanism that integrates session memory, task history, and external summaries to improve relevance and efficiency through dynamic summarization and compression. An end-to-end framework named Jenius-Agent has been integrated with three key optimizations, including tools based on the Model Context Protocol (MCP), file input/output (I/O), and execution feedback. The experiments show a 20 percent improvement in task accuracy, along with a reduced token cost, response latency, and invocation failures. The framework is already deployed in Jenius (https://www.jenius.cn), providing a lightweight and scalable solution for robust, protocol-compatible autonomous agents.", "AI": {"tldr": "本文提出了一种基于真实世界经验的智能代理框架Jenius-Agent，旨在通过三项创新优化其性能：自适应提示生成策略、上下文感知工具编排模块和分层记忆机制。", "motivation": "随着大型语言模型（LLM）驱动的智能系统的发展，提升自主代理在情境理解、工具使用及响应生成等方面的任务表现变得尤为重要。尽管已有研究推进了基于LLM的代理设计，但对其内部推理和工具调用流程的系统性优化尚待深入探索。", "method": "该框架包括三项关键创新：与代理状态和任务目标相匹配的自适应提示生成策略；根据用户意图和情境进行工具分类、语义检索及自适应调用的上下文感知工具编排模块；以及通过动态摘要压缩整合会话记忆、任务历史和外部总结的分层记忆机制。", "result": "实验结果显示，与未优化相比，该框架实现了20%的任务准确性提升，同时降低了令牌成本、响应延迟和调用失败率。", "conclusion": "Jenius-Agent已在实际场景中部署（https://www.jenius.cn），提供了一种轻量级且可扩展的解决方案，助力构建稳健、协议兼容的自主代理。"}}
{"id": "2601.01856", "pdf": "https://arxiv.org/pdf/2601.01856", "abs": "https://arxiv.org/abs/2601.01856", "authors": ["Joongwon Chae", "Lihui Luo", "Yang Liu", "Runming Wang", "Dongmei Yu", "Zeming Liang", "Xi Yuan", "Dayan Zhang", "Zhenglin Chen", "Peiwu Qin", "Ilmoon Chae"], "title": "GCR: Geometry-Consistent Routing for Task-Agnostic Continual Anomaly Detection", "categories": ["cs.CV"], "comment": null, "summary": "Feature-based anomaly detection is widely adopted in industrial inspection due to the strong representational power of large pre-trained vision encoders. While most existing methods focus on improving within-category anomaly scoring, practical deployments increasingly require task-agnostic operation under continual category expansion, where the category identity is unknown at test time. In this setting, overall performance is often dominated by expert selection, namely routing an input to an appropriate normality model before any head-specific scoring is applied. However, routing rules that compare head-specific anomaly scores across independently constructed heads are unreliable in practice, as score distributions can differ substantially across categories in scale and tail behavior. We propose GCR, a lightweight mixture-of-experts framework for stabilizing task-agnostic continual anomaly detection through geometry-consistent routing. GCR routes each test image directly in a shared frozen patch-embedding space by minimizing an accumulated nearest-prototype distance to category-specific prototype banks, and then computes anomaly maps only within the routed expert using a standard prototype-based scoring rule. By separating cross-head decision making from within-head anomaly scoring, GCR avoids cross-head score comparability issues without requiring end-to-end representation learning. Experiments on MVTec AD and VisA show that geometry-consistent routing substantially improves routing stability and mitigates continual performance collapse, achieving near-zero forgetting while maintaining competitive detection and localization performance. These results indicate that many failures previously attributed to representation forgetting can instead be explained by decision-rule instability in cross-head routing. Code is available at https://github.com/jw-chae/GCR", "AI": {"tldr": "提出了一种轻量级的混合专家框架GCR，用于通过几何一致路由稳定任务无关的连续异常检测。", "motivation": "现有的方法大多专注于改进内部类别的异常评分，在持续类别扩展的实际部署中需要无类别身份的任务无关操作。在这种情况下，整体性能通常由专家选择决定，即在应用任何头部特定评分之前将输入导向适当的正常模型。然而，基于不同独立构建的头部之间比较异常评分的路由规则在实践中是不可靠的。", "method": "GCR通过在一个共享冻结的补丁嵌入空间中最小化到类别特异性原型库的累积最近原型距离来直接为每个测试图像进行路由，并仅使用标准基于原型的评分规则在导向的专家内计算异常图谱。", "result": "实验结果表明，几何一致路由显著提高了路由稳定性，缓解了持续性能崩溃，并实现了零遗忘同时保持了具有竞争力的检测和定位性能。", "conclusion": "这些结果显示，许多以前归因于表示忘记的失败可以解释为跨头部路由中的决策规则不稳定。"}}
{"id": "2601.01852", "pdf": "https://arxiv.org/pdf/2601.01852", "abs": "https://arxiv.org/abs/2601.01852", "authors": ["Xiaoxue Gao", "Zexin Li", "Yiming Chen", "Nancy F. Chen"], "title": "MORE: Multi-Objective Adversarial Attacks on Speech Recognition", "categories": ["eess.AS", "cs.AI", "cs.LG"], "comment": "19 pages", "summary": "The emergence of large-scale automatic speech recognition (ASR) models such as Whisper has greatly expanded their adoption across diverse real-world applications. Ensuring robustness against even minor input perturbations is therefore critical for maintaining reliable performance in real-time environments. While prior work has mainly examined accuracy degradation under adversarial attacks, robustness with respect to efficiency remains largely unexplored. This narrow focus provides only a partial understanding of ASR model vulnerabilities. To address this gap, we conduct a comprehensive study of ASR robustness under multiple attack scenarios. We introduce MORE, a multi-objective repetitive doubling encouragement attack, which jointly degrades recognition accuracy and inference efficiency through a hierarchical staged repulsion-anchoring mechanism. Specifically, we reformulate multi-objective adversarial optimization into a hierarchical framework that sequentially achieves the dual objectives. To further amplify effectiveness, we propose a novel repetitive encouragement doubling objective (REDO) that induces duplicative text generation by maintaining accuracy degradation and periodically doubling the predicted sequence length. Overall, MORE compels ASR models to produce incorrect transcriptions at a substantially higher computational cost, triggered by a single adversarial input. Experiments show that MORE consistently yields significantly longer transcriptions while maintaining high word error rates compared to existing baselines, underscoring its effectiveness in multi-objective adversarial attack.", "AI": {"tldr": "提出了一种名为MORE的多目标攻击方法，旨在同时降低语音识别系统的准确性并增加其计算成本。", "motivation": "为了全面理解ASR模型的脆弱性，研究者需要探索在多个攻击场景下的系统鲁棒性，尤其是关于效率方面的脆弱性。", "method": "提出了一种名为MORE的多目标重复加倍鼓励攻击方法，通过分层阶段排斥锚定机制同时降低识别准确性和推断效率。利用一种新颖的目标函数REDO诱导生成冗余文本，从而在保持精度下降的同时周期性地将预测序列长度翻倍。", "result": "实验表明，与现有基线相比，MORE可以持续产生明显更长的转录并维持高单词错误率，证明了其在多目标对抗攻击中的有效性。", "conclusion": "通过综合研究多种攻击场景下ASR模型的鲁棒性，并提出一种新颖的方法来同时降低准确性和增加计算成本，该论文强调了全面理解ASR模型脆弱性的必要性。"}}
{"id": "2601.01847", "pdf": "https://arxiv.org/pdf/2601.01847", "abs": "https://arxiv.org/abs/2601.01847", "authors": ["Chuhang Ma", "Shuai Tan", "Ye Pan", "Jiaolong Yang", "Xin Tong"], "title": "ESGaussianFace: Emotional and Stylized Audio-Driven Facial Animation via 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": "13 pages, 10 figures", "summary": "Most current audio-driven facial animation research primarily focuses on generating videos with neutral emotions. While some studies have addressed the generation of facial videos driven by emotional audio, efficiently generating high-quality talking head videos that integrate both emotional expressions and style features remains a significant challenge. In this paper, we propose ESGaussianFace, an innovative framework for emotional and stylized audio-driven facial animation. Our approach leverages 3D Gaussian Splatting to reconstruct 3D scenes and render videos, ensuring efficient generation of 3D consistent results. We propose an emotion-audio-guided spatial attention method that effectively integrates emotion features with audio content features. Through emotion-guided attention, the model is able to reconstruct facial details across different emotional states more accurately. To achieve emotional and stylized deformations of the 3D Gaussian points through emotion and style features, we introduce two 3D Gaussian deformation predictors. Futhermore, we propose a multi-stage training strategy, enabling the step-by-step learning of the character's lip movements, emotional variations, and style features. Our generated results exhibit high efficiency, high quality, and 3D consistency. Extensive experimental results demonstrate that our method outperforms existing state-of-the-art techniques in terms of lip movement accuracy, expression variation, and style feature expressiveness.", "AI": {"tldr": "提出了一种新的框架ESGaussianFace，用于生成情感和风格化的音频驱动面部动画。", "motivation": "现有的大多数音频驱动的面部动画研究主要集中在生成带有中性情绪的视频上。虽然有一些研究解决了由情绪音频驱动的面部视频的问题，但高效地生成既包含情绪表达又包含风格特征的高质量说话头像视频仍然是一个挑战。", "method": "通过3D高斯点变形预测器和多阶段训练策略实现情感和风格化的面部动画。使用情感导向的空间注意力方法将情感与音内容特征结合，并利用3D高斯喷溅来重建3D场景并渲染视频，以确保高效生成一致的结果。", "result": "该技术在唇部动作准确性、表情变化和风格特征表现力方面优于现有最先进的技术。", "conclusion": "ESGaussianFace框架能够高效地生成高质量的说话头像动画，同时保持面部细节的一致性。"}}
{"id": "2601.01844", "pdf": "https://arxiv.org/pdf/2601.01844", "abs": "https://arxiv.org/abs/2601.01844", "authors": ["Udiptaman Das", "Krishnasai B. Atmakuri", "Duy Ho", "Chi Lee", "Yugyung Lee"], "title": "Clinical Knowledge Graph Construction and Evaluation with Multi-LLMs via Retrieval-Augmented Generation", "categories": ["cs.AI"], "comment": "13 pages, 5 tables, 4 figures", "summary": "Large language models (LLMs) offer new opportunities for constructing knowledge graphs (KGs) from unstructured clinical narratives. However, existing approaches often rely on structured inputs and lack robust validation of factual accuracy and semantic consistency, limitations that are especially problematic in oncology. We introduce an end-to-end framework for clinical KG construction and evaluation directly from free text using multi-agent prompting and a schema-constrained Retrieval-Augmented Generation (KG-RAG) strategy. Our pipeline integrates (1) prompt-driven entity, attribute, and relation extraction; (2) entropy-based uncertainty scoring; (3) ontology-aligned RDF/OWL schema generation; and (4) multi-LLM consensus validation for hallucination detection and semantic refinement. Beyond static graph construction, the framework supports continuous refinement and self-supervised evaluation, enabling iterative improvement of graph quality. Applied to two oncology cohorts (PDAC and BRCA), our method produces interpretable, SPARQL-compatible, and clinically grounded knowledge graphs without relying on gold-standard annotations. Experimental results demonstrate consistent gains in precision, relevance, and ontology compliance over baseline methods.", "AI": {"tldr": "该论文提出了一种基于多语言模型的临床知识图谱构建与评估框架，直接从自由文本中提取实体、属性和关系，并通过共识验证提高准确性和一致性。", "motivation": "现有方法在构造临床知识图谱时依赖结构化输入且缺乏对事实准确性及语义一致性的验证，尤其是在肿瘤学领域问题尤为严重。提出一种新框架旨在解决这些问题，直接从自由文本中构建高质量的知识图谱。", "method": "论文介绍了一种集成多代理提示、熵基不确定性评分、本体对齐RDF/OWL模式生成以及多语言模型共识校验的端到端框架，支持知识图谱的连续优化和自我监督评估。", "result": "该方法在两个肿瘤学队列（PDAC 和 BRCA）中的实验结果显示，在精确度、相关性和符合本体规范性方面优于基准方法。", "conclusion": "提出的基于多语言模型的知识图谱构造与评估框架能够生成可解释、SPARQL兼容且具有临床依据的知识图谱，为肿瘤学等领域的知识管理提供有效工具。"}}
{"id": "2601.01841", "pdf": "https://arxiv.org/pdf/2601.01841", "abs": "https://arxiv.org/abs/2601.01841", "authors": ["Jingyang Zhao", "Yonghang Su", "Mingyu Xiao"], "title": "Improved Approximation Algorithms for the Multiple-Depot Split Delivery Vehicle Routing Problem", "categories": ["cs.DS"], "comment": null, "summary": "The Multiple-Depot Split Delivery Vehicle Routing Problem (MD-SDVRP) is a challenging problem with broad applications in logistics. The goal is to serve customers' demand using a fleet of capacitated vehicles located in multiple depots, where each customer's demand can be served by more than one vehicle, while minimizing the total travel cost of all vehicles. We study approximation algorithms for this problem. Previously, the only known result was a $6$-approximation algorithm for a constant number of depots (INFORMS J. Comput. 2023), and whether this ratio could be improved was left as an open question. In this paper, we resolve it by proposing a $(6-2\\cdot 10^{-36})$-approximation algorithm for this setting. Moreover, we develop constant-factor approximation algorithms that work beyond a constant number of depots, improved parameterized approximation algorithms related to the vehicle capacity and the number of depots, as well as bi-factor approximation algorithms.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.01839", "pdf": "https://arxiv.org/pdf/2601.01839", "abs": "https://arxiv.org/abs/2601.01839", "authors": ["Martin Prause"], "title": "The Machine Learning Canvas: Empirical Findings on Why Strategy Matters More Than AI Code Generation", "categories": ["cs.SE", "cs.AI"], "comment": "Dataset available: https://ieee-dataport.org/documents/machine-learning-canvas-success-determinants", "summary": "Despite the growing popularity of AI coding assistants, over 80% of machine learning (ML) projects fail to deliver real business value. This study creates and tests a Machine Learning Canvas, a practical framework that combines business strategy, software engineering, and data science in order to determine the factors that lead to the success of ML projects. We surveyed 150 data scientists and analyzed their responses using statistical modeling. We identified four key success factors: Strategy (clear goals and planning), Process (how work gets done), Ecosystem (tools and infrastructure), and Support (organizational backing and resources). Our results show that these factors are interconnected - each one affects the next. For instance, strong organizational support results in a clearer strategy (β= 0.432, p < 0.001), which improves work processes (β= 0.428, p < 0.001) and builds better infrastructure (β= 0.547, p < 0.001). Together, these elements determine whether a project succeeds. The surprising finding? Although AI assistants make coding faster, they don't guarantee project success. AI assists with the \"how\" of coding but cannot replace the \"why\" and \"what\" of strategic thinking.", "AI": {"tldr": "构建并测试了一个机器学习画布框架，以确定影响ML项目成功的因素。", "motivation": "探讨为何尽管人工智能编码助手流行，超过80%的机器学习项目仍无法实现真正的商业价值，并希望通过一个结合业务策略、软件工程和数据科学的框架来找到成功的关键。", "method": "调查了150名数据科学家并使用统计模型分析他们的回答，以识别影响ML项目成功的因素。", "result": "确定了四个关键的成功因素：战略（明确的目标和计划）、流程（工作方式）、生态系统（工具和基础设施）和支持（组织支持和资源），并且这些因素相互关联。", "conclusion": "AI助手虽然可以加速编码过程，但不能保证项目的成功；AI专注于“如何”进行编码，而无法替代业务策略的思考。“为什么”和“做什么”的战略思维更加重要。"}}
{"id": "2601.01836", "pdf": "https://arxiv.org/pdf/2601.01836", "abs": "https://arxiv.org/abs/2601.01836", "authors": ["Dasol Choi", "DongGeon Lee", "Brigitta Jesica Kartono", "Helena Berndt", "Taeyoun Kwon", "Joonwon Jang", "Haon Park", "Hwanjo Yu", "Minsuk Kahng"], "title": "COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "As large language models are deployed in high-stakes enterprise applications, from healthcare to finance, ensuring adherence to organization-specific policies has become essential. Yet existing safety evaluations focus exclusively on universal harms. We present COMPASS (Company/Organization Policy Alignment Assessment), the first systematic framework for evaluating whether LLMs comply with organizational allowlist and denylist policies. We apply COMPASS to eight diverse industry scenarios, generating and validating 5,920 queries that test both routine compliance and adversarial robustness through strategically designed edge cases. Evaluating seven state-of-the-art models, we uncover a fundamental asymmetry: models reliably handle legitimate requests (>95% accuracy) but catastrophically fail at enforcing prohibitions, refusing only 13-40% of adversarial denylist violations. These results demonstrate that current LLMs lack the robustness required for policy-critical deployments, establishing COMPASS as an essential evaluation framework for organizational AI safety.", "AI": {"tldr": "提出COMPASS框架，评估大型语言模型是否符合组织的特定政策。", "motivation": "现有安全性评估仅关注普遍性危害，忽略了企业应用中对组织特定策略合规性的需求。", "method": "通过设计5920个查询来测试不同行业的常规和对抗性情况下的合规性和稳健性。", "result": "模型在处理合法请求时准确率超过95%，但在执行禁止规定方面失败严重，仅拒绝13-40%的违规行为。", "conclusion": "当前LLM缺乏政策关键部署所需的稳健性，COMPASS作为组织AI安全性评估框架至关重要。"}}
{"id": "2601.01835", "pdf": "https://arxiv.org/pdf/2601.01835", "abs": "https://arxiv.org/abs/2601.01835", "authors": ["Rashid Iqbal", "Saddam Hussain Khan"], "title": "RSwinV2-MD: An Enhanced Residual SwinV2 Transformer for Monkeypox Detection from Skin Images", "categories": ["cs.CV", "cs.AI"], "comment": "15 Pages, 7 Figures, 4 Tables", "summary": "In this paper, a deep learning approach for Mpox diagnosis named Customized Residual SwinTransformerV2 (RSwinV2) has been proposed, trying to enhance the capability of lesion classification by employing the RSwinV2 tool-assisted vision approach. In the RSwinV2 method, a hierarchical structure of the transformer has been customized based on the input dimensionality, embedding structure, and output targeted by the method. In this RSwinV2 approach, the input image has been split into non-overlapping patches and processed using shifted windows and attention in these patches. This process has helped the method link all the windows efficiently by avoiding the locality issues of non-overlapping regions in attention, while being computationally efficient. RSwinV2 has further developed based on SwinTransformer and has included patch and position embeddings to take advantage of the transformer global-linking capability by employing multi-head attention in these embeddings. Furthermore, RSwinV2 has developed and incorporated the Inverse Residual Block (IRB) into this method, which utilizes convolutional skip connections with these inclusive designs to address the vanishing gradient issues during processing. RSwinV2 inclusion of IRB has therefore facilitated this method to link global patterns as well as local patterns; hence, its integrity has helped improve lesion classification capability by minimizing variability of Mpox and increasing differences of Mpox, chickenpox, measles, and cowpox. In testing SwinV2, its accuracy of 96.21 and an F1score of 95.62 have been achieved on the Kaggle public dataset, which has outperformed standard CNN models and SwinTransformers; RSwinV2 vector has thus proved its valiance as a computer-assisted tool for Mpox lesion observation interpretation.", "AI": {"tldr": "本文提出了一种改进的残差SwinTransformerV2模型（RSwinV2-MD），用于从皮肤图像中检测猴痘病变。", "motivation": "通过提高对病变分类的能力，解决现有方法在猴痘、水痘、麻疹和牛痘识别上的准确性问题。", "method": "使用自定义的残差SwinTransformerV2模型（RSwinV2），该模型利用分层结构来处理输入图像，并结合了移位窗口和注意力机制，同时引入了逆残差块以解决梯度消失的问题。通过这种方法提高了全局和局部模式之间的链接效率。", "result": "在Kaggle公共数据集上实现了96.21%的准确率和95.62%的F1分数，超过了标准CNN模型和SwinTransformers。", "conclusion": "RSwinV2-MD作为一种计算机辅助工具，在猴痘病变观察解释中展示了其有效性。"}}
{"id": "2601.01832", "pdf": "https://arxiv.org/pdf/2601.01832", "abs": "https://arxiv.org/abs/2601.01832", "authors": ["SB Danush Vikraman", "Hannah Abagail", "Prasanna Kesavraj", "Gajanan V Honnavar"], "title": "Yukthi Opus: A Multi-Chain Hybrid Metaheuristic for Large-Scale NP-Hard Optimization", "categories": ["cs.NE", "cs.AI"], "comment": "22 pages, 9 figures, includes extensive ablation studies and benchmark comparisons", "summary": "We present Yukthi Opus (YO), a multi-chain hybrid metaheuristic designed for NP-hard optimization under explicit evaluation budget constraints. YO integrates three complementary mechanisms in a structured two-phase architecture: Markov Chain Monte Carlo (MCMC) for global exploration, greedy local search for exploitation, and simulated annealing with adaptive reheating to enable controlled escape from local minima. A dedicated burn-in phase allocates evaluations to probabilistic exploration, after which a hybrid optimization loop refines promising candidates. YO further incorporates a spatial blacklist mechanism to avoid repeated evaluation of poor regions and a multi-chain execution strategy to improve robustness and reduce sensitivity to initialization. We evaluate YO on three benchmarks: the Rastrigin function (5D) with ablation studies, the Traveling Salesman Problem with 50 to 200 cities, and the Rosenbrock function (5D) with comparisons against established optimizers including CMA-ES, Bayesian optimization, and accelerated particle swarm optimization. Results show that MCMC exploration and greedy refinement are critical for solution quality, while simulated annealing and multi-chain execution primarily improve stability and variance reduction. Overall, YO achieves competitive performance on large and multimodal problems while maintaining predictable evaluation budgets, making it suitable for expensive black-box optimization settings.", "AI": {"tldr": "介绍了一种名为Yukthi Opus (YO)的多链混合元启发式算法，用于NP难优化问题，在明确评估预算约束下表现优异。", "motivation": "旨在解决大规模NP难优化问题中的全局探索、局部搜索和逃离局部最小值的问题，同时保持稳定的性能和可预测的评估预算。", "method": "YO采用了分阶段架构结合MCMC进行全局探索、贪婪局部搜索用于开发以及自适应重热模拟退火来跳出局部最优解，并引入空间黑名单机制避免重复计算低效区域及多链执行策略增强鲁棒性和减少初始化敏感度。", "result": "实验结果表明，MCMC探索和贪婪细化对解决方案质量至关重要，而模拟退火和多链执行主要提高了稳定性和方差减小，在Rastrigin函数、旅行商问题以及Rosenbrock函数上的表现优于其他优化器如CMA-ES、贝叶斯优化等。", "conclusion": "YO在大规模和多模态问题上表现出色，同时保持可预测的评估预算，适用于昂贵的黑箱优化设置。"}}
{"id": "2601.01831", "pdf": "https://arxiv.org/pdf/2601.01831", "abs": "https://arxiv.org/abs/2601.01831", "authors": ["Aniket Wattamwar", "Sampson Akwafuo"], "title": "ARIES: A Scalable Multi-Agent Orchestration Framework for Real-Time Epidemiological Surveillance and Outbreak Monitoring", "categories": ["cs.MA", "cs.AI", "cs.IR", "cs.SE"], "comment": "6 pages, 14 figures, 1 table", "summary": "Global health surveillance is currently facing a challenge of Knowledge Gaps. While general-purpose AI has proliferated, it remains fundamentally unsuited for the high-stakes epidemiological domain due to chronic hallucinations and an inability to navigate specialized data silos. This paper introduces ARIES (Agentic Retrieval Intelligence for Epidemiological Surveillance), a specialized, autonomous multi-agent framework designed to move beyond static, disease-specific dashboards toward a dynamic intelligence ecosystem. Built on a hierarchical command structure, ARIES utilizes GPTs to orchestrate a scalable swarm of sub-agents capable of autonomously querying World Health Organization (WHO), Center for Disease Control and Prevention (CDC), and peer-reviewed research papers. By automating the extraction and logical synthesis of surveillance data, ARIES provides a specialized reasoning that identifies emergent threats and signal divergence in near real-time. This modular architecture proves that a task-specific agentic swarm can outperform generic models, offering a robust, extensible for next-generation outbreak response and global health intelligence.", "AI": {"tldr": "介绍了一种名为ARIES的多代理框架，用于实时流行病学监测和疫情监控。", "motivation": "当前全球卫生监视面临知识缺口问题。通用人工智能存在幻觉并难以处理专业数据孤岛，因此需要一种专门针对流行病领域的智能化系统。", "method": "构建了一个基于层次化指挥结构的ARIES框架，使用GPTs组织可扩展代理群组以查询WHO、CDC和同行评审论文，实现自动提取与逻辑合成监测数据。", "result": "证明了任务特定的代理群可以超越通用模型，在实时识别新威胁方面具有优势。", "conclusion": "提供了下一代疫情响应和全球健康智能的一种强大且可扩展的方法。"}}
{"id": "2601.01828", "pdf": "https://arxiv.org/pdf/2601.01828", "abs": "https://arxiv.org/abs/2601.01828", "authors": ["Jack Lindsey"], "title": "Emergent Introspective Awareness in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We investigate whether large language models can introspect on their internal states. It is difficult to answer this question through conversation alone, as genuine introspection cannot be distinguished from confabulations. Here, we address this challenge by injecting representations of known concepts into a model's activations, and measuring the influence of these manipulations on the model's self-reported states. We find that models can, in certain scenarios, notice the presence of injected concepts and accurately identify them. Models demonstrate some ability to recall prior internal representations and distinguish them from raw text inputs. Strikingly, we find that some models can use their ability to recall prior intentions in order to distinguish their own outputs from artificial prefills. In all these experiments, Claude Opus 4 and 4.1, the most capable models we tested, generally demonstrate the greatest introspective awareness; however, trends across models are complex and sensitive to post-training strategies. Finally, we explore whether models can explicitly control their internal representations, finding that models can modulate their activations when instructed or incentivized to \"think about\" a concept. Overall, our results indicate that current language models possess some functional introspective awareness of their own internal states. We stress that in today's models, this capacity is highly unreliable and context-dependent; however, it may continue to develop with further improvements to model capabilities.", "AI": {"tldr": "研究大型语言模型是否能够内省其内部状态。", "motivation": "通过对话难以区分真正的内省和虚构的陈述，因此注入已知概念来观察模型对其自身状态的认知能力。", "method": "向模型激活中插入已知概念表示，并测量这些操作对模型自我报告的影响。测试模型在不同情境下识别和回忆先前内部表示的能力以及控制其内部表示的能力。", "result": "发现一些模型能够在某些情况下注意到注入的概念并准确地识别它们，能够区分自己的输出和其他输入。", "conclusion": "当前的语言模型具有一定的内省能力，但这种能力是高度不可靠且依赖于上下文的。随着模型能力的进一步提高，这一功能可能会得到发展。"}}
{"id": "2601.01822", "pdf": "https://arxiv.org/pdf/2601.01822", "abs": "https://arxiv.org/abs/2601.01822", "authors": ["Shiyong Meng", "Tao Zou", "Bolei Chen", "Chaoxu Mu", "Jianxin Wang"], "title": "DisCo-FLoc: Using Dual-Level Visual-Geometric Contrasts to Disambiguate Depth-Aware Visual Floorplan Localization", "categories": ["cs.RO", "cs.CV"], "comment": "7 pages, 4 figures", "summary": "Since floorplan data is readily available, long-term persistent, and robust to changes in visual appearance, visual Floorplan Localization (FLoc) has garnered significant attention. Existing methods either ingeniously match geometric priors or utilize sparse semantics to reduce FLoc uncertainty. However, they still suffer from ambiguous FLoc caused by repetitive structures within minimalist floorplans. Moreover, expensive but limited semantic annotations restrict their applicability. To address these issues, we propose DisCo-FLoc, which utilizes dual-level visual-geometric Contrasts to Disambiguate depth-aware visual Floc, without requiring additional semantic labels. Our solution begins with a ray regression predictor tailored for ray-casting-based FLoc, predicting a series of FLoc candidates using depth estimation expertise. In addition, a novel contrastive learning method with position-level and orientation-level constraints is proposed to strictly match depth-aware visual features with the corresponding geometric structures in the floorplan. Such matches can effectively eliminate FLoc ambiguity and select the optimal imaging pose from FLoc candidates. Exhaustive comparative studies on two standard visual Floc benchmarks demonstrate that our method outperforms the state-of-the-art semantic-based method, achieving significant improvements in both robustness and accuracy.", "AI": {"tldr": "该论文提出了一种双层视觉几何对比方法，用于解决基于深度感知的视觉楼层定位中的模糊问题。", "motivation": "现有技术依赖于几何先验或稀疏语义来减少楼层定位不确定性，但在简约楼层图中仍存在重复结构引起的模糊性，并且昂贵而有限的语义标注限制了它们的应用范围。因此，论文提出了一种无需额外语义标签的方法以解决这些问题。", "method": "该方法首先使用基于射线投影视觉楼层数字化的射线回归预测器生成一系列楼层定位候选方案，然后通过位置级和方向级约束的对比学习方法精确匹配深度感知视觉特征与相应几何结构。这能有效消除模糊性并选择最佳图像姿态。", "result": "实验在两个标准视觉定位基准上进行，结果表明该方法超越了最先进的基于语义的方法，在准确性和鲁棒性方面都有显著改进。", "conclusion": "论文提出了一种新的深度感知视觉楼层定位技术，通过双层对比学习解决了传统方法中的模糊问题，并且无需额外的语义标注。"}}
{"id": "2601.01818", "pdf": "https://arxiv.org/pdf/2601.01818", "abs": "https://arxiv.org/abs/2601.01818", "authors": ["Sungjune Park", "Hongda Mao", "Qingshuang Chen", "Yong Man Ro", "Yelin Kim"], "title": "Robust Egocentric Visual Attention Prediction Through Language-guided Scene Context-aware Learning", "categories": ["cs.CV"], "comment": "11 pages, 7 figures, 4 tables", "summary": "As the demand for analyzing egocentric videos grows, egocentric visual attention prediction, anticipating where a camera wearer will attend, has garnered increasing attention. However, it remains challenging due to the inherent complexity and ambiguity of dynamic egocentric scenes. Motivated by evidence that scene contextual information plays a crucial role in modulating human attention, in this paper, we present a language-guided scene context-aware learning framework for robust egocentric visual attention prediction. We first design a context perceiver which is guided to summarize the egocentric video based on a language-based scene description, generating context-aware video representations. We then introduce two training objectives that: 1) encourage the framework to focus on the target point-of-interest regions and 2) suppress distractions from irrelevant regions which are less likely to attract first-person attention. Extensive experiments on Ego4D and Aria Everyday Activities (AEA) datasets demonstrate the effectiveness of our approach, achieving state-of-the-art performance and enhanced robustness across diverse, dynamic egocentric scenarios.", "AI": {"tldr": "本文提出了一种基于语言指导的场景上下文感知学习框架，用于预测第一人称视频中的视觉注意力。", "motivation": "由于动态的第一人称场景中存在复杂性和模糊性，现有的视注意预测方法难以满足需求。文章通过利用场景上下文信息来改进模型的准确性和鲁棒性。", "method": "设计了一个基于语言描述的上下文感知模块，用于总结第一人称视频，并生成关注区域和抑制无关区域的目标函数。", "result": "在Ego4D和AEA数据集上进行了实验验证，结果表明该方法具有更高的精度和更强的鲁棒性。", "conclusion": "通过结合语言指导和场景上下文感知学习的方法可以有效提高第一人称视注意预测任务的效果。"}}
{"id": "2601.01816", "pdf": "https://arxiv.org/pdf/2601.01816", "abs": "https://arxiv.org/abs/2601.01816", "authors": ["Chris Duffey"], "title": "Admissibility Alignment", "categories": ["cs.AI"], "comment": "24 pages, 2 figures, 2 tables.. Decision-theoretic alignment under uncertainty", "summary": "This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition. MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.", "AI": {"tldr": "本文介绍了Admissibility Alignment：一种将AI对齐视为在不确定性分布下的可接受行为选择的框架，并提出了MAP-AI（Monte Carlo Alignment for Policy）系统架构。", "motivation": "动机是将AI对齐问题重新定义为决策理论中的概率属性，以处理不确定性环境下的政策选择和执行。", "method": "方法包括通过蒙特卡洛估计输出分布并控制策略选择来实现可接受性对齐；评估决策策略在多种可能未来情况下的表现，特别是不确定性和干预效果。", "result": "结果是一个可以实际应用的基础框架，用于治理那些影响不仅依赖于单一预测而是基于政策行为的AI系统。", "conclusion": "结论是通过集成分布对齐评估到决策过程中，形成了一种不确定性条件下的可接受性控制行动选择机制。"}}
{"id": "2601.01807", "pdf": "https://arxiv.org/pdf/2601.01807", "abs": "https://arxiv.org/abs/2601.01807", "authors": ["Ubaidullah", "Muhammad Abid Hussain", "Mohsin Raza Jafri", "Rozi Khan", "Moid Sandhu", "Abd Ullah Khan", "Hyundong Shin"], "title": "Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Lumpy Skin Disease (LSD) is a contagious viral infection that significantly deteriorates livestock health, thereby posing a serious threat to the global economy and food security. Owing to its rapid spread characteristics, early and precise identification is crucial to prevent outbreaks and ensure timely intervention. In this paper, we propose a hybrid deep learning-based approach called LUMPNet for the early detection of LSD. LUMPNet utilizes image data to detect and classify skin nodules -- the primary indicator of LSD. To this end, LUMPNet uses YOLOv11, EfficientNet-based CNN classifier with compound scaling, and a novel adaptive hybrid optimizer. More precisely, LUMPNet detects and localizes LSD skin nodules and lesions on cattle images. It exploits EfficientNet to classify the localized cattle images into LSD-affected or healthy categories. To stabilize and accelerate the training of YOLOv11 and EfficientNet hybrid model, a novel adaptive hybrid optimizer is proposed and utilized. We evaluate LUMPNet at various stages of LSD using a publicly available dataset. Results indicate that the proposed scheme achieves 99% LSD detection training accuracy, and outperforms existing schemes. The model also achieves validation accuracy of 98%. Moreover, for further evaluation, we conduct a case study using an optimized EfficientNet-B0 model trained with the AdamW optimizer, and compare its performance with LUMPNet. The results show that LUMPNet achieves superior performance.", "AI": {"tldr": "该论文提出了一种基于深度学习的LUMPNet框架，用于牛结节性皮肤病（LSD）的早期检测。", "motivation": "为了预防LSD疫情并确保及时干预，需要一种能够早期和精确识别LSD的方法。因此，提出了结合YOLOv11、EfficientNet分类器以及自适应混合优化器的LUMPNet框架来实现这一目标。", "method": "该方法利用图像数据检测牛皮肤上的结节，并将其归类为受LSD影响或健康状态。具体来说，使用了YOLOv11进行对象定位和分割，EfficientNet进行分类任务，同时提出了一种自适应混合优化器以加速并稳定训练过程。", "result": "实验结果表明，所提出的模型在训练阶段的准确率达到99%，验证集上达到98%。此外，在使用AdamW优化器训练的优化EfficientNet-B0模型的对比测试中，LUMPNet表现更优。", "conclusion": "研究表明，LUMPNet框架能够高效且精确地进行LSD早期检测，为防止疫情传播提供了一种有力工具。"}}
{"id": "2601.01804", "pdf": "https://arxiv.org/pdf/2601.01804", "abs": "https://arxiv.org/abs/2601.01804", "authors": ["Zhengjian Kang", "Qi Chen", "Rui Liu", "Kangtong Mo", "Xingyu Zhang", "Xiaoyu Deng", "Ye Zhang"], "title": "Causality-Aware Temporal Projection for Video Understanding in Video-LLMs", "categories": ["cs.CV"], "comment": "7 pages, 4 figures", "summary": "Recent Video Large Language Models (Video-LLMs) have shown strong multimodal reasoning capabilities, yet remain challenged by video understanding tasks that require consistent temporal ordering and causal coherence. Many parameter-efficient Video-LLMs rely on unconstrained bidirectional projectors to model inter-frame interactions, which can blur temporal ordering by allowing later frames to influence earlier representations, without explicit architectural mechanisms to respect the directional nature of video reasoning. To address this limitation, we propose V-CORE, a parameter-efficient framework that introduces explicit temporal ordering constraints for video understanding. V-CORE consists of two key components: (1) Learnable Spatial Aggregation (LSA), which adaptively selects salient spatial tokens to reduce redundancy, and (2) a Causality-Aware Temporal Projector (CATP), which enforces structured unidirectional information flow via block-causal attention and a terminal dynamic summary token acting as a causal sink. This design preserves intra-frame spatial interactions while ensuring that temporal information is aggregated in a strictly ordered manner. With 4-bit QLoRA and a frozen LLM backbone, V-CORE can be trained efficiently on a single consumer GPU. Experiments show that V-CORE achieves strong performance on the challenging NExT-QA benchmark, reaching 61.2% accuracy, and remains competitive across MSVD-QA, MSRVTT-QA, and TGIF-QA, with gains concentrated in temporal and causal reasoning subcategories (+3.5% and +5.2% respectively), directly validating the importance of explicit temporal ordering constraints.", "AI": {"tldr": "该论文提出了一种参数高效的框架V-CORE，用于增强视频理解任务的因果性感知和时间一致性。", "motivation": "当前视频大语言模型（Video-LLMs）在处理需要一致的时间顺序和因果连贯性的视频理解任务上存在挑战。传统方法中使用的双向投影器可能导致时间顺序模糊，缺乏明确架构来尊重视频推理的方向性。", "method": "V-CORE框架包括可学习的空间聚合(LSA) 和因果感知的时间投影器(CATP)，其中LSA可以自适应地选择重要的空间令牌以减少冗余，而CATP通过块因果注意力和终端动态摘要令牌确保结构化单向信息流。", "result": "实验显示V-CORE在NExT-QA基准测试中达到了61.2％的准确率，并且在MSVD-QA、MSRVTT-QA 和TGIF-QA数据集上保持竞争力，特别是在时间推理和因果推理子类别中的表现有所提高。", "conclusion": "论文通过引入明确的时间顺序约束来解决现有模型的问题，证明了这种方法对于改善视频理解任务的有效性。"}}
{"id": "2601.01803", "pdf": "https://arxiv.org/pdf/2601.01803", "abs": "https://arxiv.org/abs/2601.01803", "authors": ["Dennis Jabs", "Aditya Mohan", "Marius Lindauer"], "title": "Moments Matter:Stabilizing Policy Optimization using Return Distributions", "categories": ["cs.LG", "cs.AI"], "comment": "Workshop paper at RLDM'25", "summary": "Deep Reinforcement Learning (RL) agents often learn policies that achieve the same episodic return yet behave very differently, due to a combination of environmental (random transitions, initial conditions, reward noise) and algorithmic (minibatch selection, exploration noise) factors. In continuous control tasks, even small parameter shifts can produce unstable gaits, complicating both algorithm comparison and real-world transfer. Previous work has shown that such instability arises when policy updates traverse noisy neighborhoods and that the spread of post-update return distribution $R(θ)$, obtained by repeatedly sampling minibatches, updating $θ$, and measuring final returns, is a useful indicator of this noise. Although explicitly constraining the policy to maintain a narrow $R(θ)$ can improve stability, directly estimating $R(θ)$ is computationally expensive in high-dimensional settings. We propose an alternative that takes advantage of environmental stochasticity to mitigate update-induced variability. Specifically, we model state-action return distribution through a distributional critic and then bias the advantage function of PPO using higher-order moments (skewness and kurtosis) of this distribution. By penalizing extreme tail behaviors, our method discourages policies from entering parameter regimes prone to instability. We hypothesize that in environments where post-update critic values align poorly with post-update returns, standard PPO struggles to produce a narrow $R(θ)$. In such cases, our moment-based correction narrows $R(θ)$, improving stability by up to 75% in Walker2D, while preserving comparable evaluation returns.", "AI": {"tldr": "本文提出了一种基于分布矩的方法，通过在策略优化中引入偏置优势函数来减小更新后回报分布的范围，从而提高稳定性和鲁棒性。", "motivation": "深度强化学习代理由于环境和算法因素的影响，在达到相同回合奖励时行为差异很大。这种不稳定性阻碍了算法比较和现实世界的迁移。因此需要一种方法来减少策略变化带来的不稳定影响。", "method": "本文提出了一种基于分布矩的方法，利用状态动作回报分布并通过惩罚极端尾部行为的偏置优势函数来减小更新后回报分布的范围，从而提高稳定性和鲁棒性。", "result": "通过在Walker2D环境中测试，该方法提高了75%的稳定性，同时保持了与标准PPO相似的评估奖励。", "conclusion": "利用环境随机性并通过引入偏置优势函数来减小更新后回报分布的范围是一种有效的提高稳定性和鲁棒性的策略优化方法。"}}
{"id": "2601.01802", "pdf": "https://arxiv.org/pdf/2601.01802", "abs": "https://arxiv.org/abs/2601.01802", "authors": ["Qianjun Pan", "Junyi Wang", "Jie Zhou", "Yutao Yang", "Junsong Li", "Kaiyin Xu", "Yougen Zhou", "Yihan Li", "Jingyuan Zhao", "Qin Chen", "Ningning Zhou", "Kai Chen", "Liang He"], "title": "PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor", "categories": ["cs.AI"], "comment": null, "summary": "To develop a reliable AI for psychological assessment, we introduce \\texttt{PsychEval}, a multi-session, multi-therapy, and highly realistic benchmark designed to address three key challenges: \\textbf{1) Can we train a highly realistic AI counselor?} Realistic counseling is a longitudinal task requiring sustained memory and dynamic goal tracking. We propose a multi-session benchmark (spanning 6-10 sessions across three distinct stages) that demands critical capabilities such as memory continuity, adaptive reasoning, and longitudinal planning. The dataset is annotated with extensive professional skills, comprising over 677 meta-skills and 4577 atomic skills. \\textbf{2) How to train a multi-therapy AI counselor?} While existing models often focus on a single therapy, complex cases frequently require flexible strategies among various therapies. We construct a diverse dataset covering five therapeutic modalities (Psychodynamic, Behaviorism, CBT, Humanistic Existentialist, and Postmodernist) alongside an integrative therapy with a unified three-stage clinical framework across six core psychological topics. \\textbf{3) How to systematically evaluate an AI counselor?} We establish a holistic evaluation framework with 18 therapy-specific and therapy-shared metrics across Client-Level and Counselor-Level dimensions. To support this, we also construct over 2,000 diverse client profiles. Extensive experimental analysis fully validates the superior quality and clinical fidelity of our dataset. Crucially, \\texttt{PsychEval} transcends static benchmarking to serve as a high-fidelity reinforcement learning environment that enables the self-evolutionary training of clinically responsible and adaptive AI counselors.", "AI": {"tldr": "介绍了一种名为PsychEval的多阶段、多疗法的心理咨询AI基准测试，旨在训练高度现实主义和全面性的心理咨询系统。", "motivation": "为了解决现有AI在心理评估中的局限性，开发一种能够应对长期记忆保持和适应性推理等挑战的高度现实主义AI咨询师，并支持多种治疗策略的灵活运用以及系统的评价方法。", "method": "通过构建一个多阶段、多疗法的数据集并引入一系列详细的元技能与原子技能进行标注；设计了一个涵盖五种不同心理治疗方法及整合式治疗方案的数据框架；建立了包括18个特定和共享评估指标的全面评估体系，并创建了超过2000份多样化的客户档案。", "result": "实验分析结果证实该数据集具有卓越的质量和临床真实性，PsychEval不仅作为一个静态基准测试存在，还作为高保真度强化学习环境支持AI咨询师自我进化训练。", "conclusion": "通过提出一个综合性的评估框架和多阶段、多疗法的数据集，使得开发出高度现实主义及适应性更强的AI心理咨询系统成为可能，并推动了该领域的进一步发展。"}}
{"id": "2601.01800", "pdf": "https://arxiv.org/pdf/2601.01800", "abs": "https://arxiv.org/abs/2601.01800", "authors": ["Qi Wei", "Junchao Fan", "Zhao Yang", "Jianhua Wang", "Jingkai Mao", "Xiaolin Chang"], "title": "Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has shown considerable potential in autonomous driving (AD), yet its vulnerability to perturbations remains a critical barrier to real-world deployment. As a primary countermeasure, adversarial training improves policy robustness by training the AD agent in the presence of an adversary that deliberately introduces perturbations. Existing approaches typically model the interaction as a zero-sum game with continuous attacks. However, such designs overlook the inherent asymmetry between the agent and the adversary and then fail to reflect the sparsity of safety-critical risks, rendering the achieved robustness inadequate for practical AD scenarios. To address these limitations, we introduce criticality-aware robust RL (CARRL), a novel adversarial training approach for handling sparse, safety-critical risks in autonomous driving. CARRL consists of two interacting components: a risk exposure adversary (REA) and a risk-targeted robust agent (RTRA). We model the interaction between the REA and RTRA as a general-sum game, allowing the REA to focus on exposing safety-critical failures (e.g., collisions) while the RTRA learns to balance safety with driving efficiency. The REA employs a decoupled optimization mechanism to better identify and exploit sparse safety-critical moments under a constrained budget. However, such focused attacks inevitably result in a scarcity of adversarial data. The RTRA copes with this scarcity by jointly leveraging benign and adversarial experiences via a dual replay buffer and enforces policy consistency under perturbations to stabilize behavior. Experimental results demonstrate that our approach reduces the collision rate by at least 22.66\\% across all cases compared to state-of-the-art baseline methods.", "AI": {"tldr": "该论文提出了CARRL，一种处理自动驾驶中稀疏、关键风险的对抗训练方法。", "motivation": "当前强化学习在自动驾驶中的脆弱性阻碍了其实际部署。现有的对抗训练方法未能充分反映安全关键风险的稀疏性和不对称性，导致生成的安全策略不够有效。", "method": "CARRL包括两个组件：风险暴露对手（REA）和针对关键风险的鲁棒代理（RTRA），通过一般求和博弈模型模拟两者之间的交互。REA专注于暴露安全性相关的故障，而RTRA则学习在保持驾驶效率的同时保证安全。面对对抗数据稀缺性问题，RTRA利用双缓冲区机制结合良性经验和恶意经验，并强制策略的一致性以稳定行为。", "result": "实验结果显示，该方法将碰撞率至少降低了22.66%，优于现有基线方法。", "conclusion": "CARRL通过针对稀疏关键风险的对抗训练提高了自动驾驶的安全性。"}}
{"id": "2601.01798", "pdf": "https://arxiv.org/pdf/2601.01798", "abs": "https://arxiv.org/abs/2601.01798", "authors": ["Syed Abdul Hannan", "Hazim Bukhari", "Thomas Cantalapiedra", "Eman Ansar", "Massa Baali", "Rita Singh", "Bhiksha Raj"], "title": "VerLM: Explaining Face Verification Using Natural Language", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Face verification systems have seen substantial advancements; however, they often lack transparency in their decision-making processes. In this paper, we introduce an innovative Vision-Language Model (VLM) for Face Verification, which not only accurately determines if two face images depict the same individual but also explicitly explains the rationale behind its decisions. Our model is uniquely trained using two complementary explanation styles: (1) concise explanations that summarize the key factors influencing its decision, and (2) comprehensive explanations detailing the specific differences observed between the images. We adapt and enhance a state-of-the-art modeling approach originally designed for audio-based differentiation to suit visual inputs effectively. This cross-modal transfer significantly improves our model's accuracy and interpretability. The proposed VLM integrates sophisticated feature extraction techniques with advanced reasoning capabilities, enabling clear articulation of its verification process. Our approach demonstrates superior performance, surpassing baseline methods and existing models. These findings highlight the immense potential of vision language models in face verification set up, contributing to more transparent, reliable, and explainable face verification systems.", "AI": {"tldr": "介绍了一种用于面部验证的视觉语言模型（VLM），该模型不仅可以准确判断两张人脸图像是否属于同一个人，还可以解释其决策背后的原因。", "motivation": "目前面部识别系统在准确性上有很大提高，但缺乏透明度和可解释性。因此，本文旨在开发一种既能保证准确性又具有高度透明性和可解释性的面部验证方法。", "method": "通过训练一个视觉语言模型（VLM），采用两种互补的解释风格：简洁地概括影响决策的关键因素以及详细说明图像之间的具体差异。该模型基于最先进的音频区分方法进行适应性改进，以更好地处理视觉输入，并结合先进的特征提取和推理技术来提高准确性和可解释性。", "result": "提出的VLM在面部验证任务中表现出色，超过了基线方法和其他现有模型，在透明度、可靠性和可解释性方面有明显优势。", "conclusion": "研究表明，视觉语言模型具有极大的潜力应用于面部验证领域，可以实现更准确、可靠和可解释的系统。"}}
{"id": "2601.01792", "pdf": "https://arxiv.org/pdf/2601.01792", "abs": "https://arxiv.org/abs/2601.01792", "authors": ["NAVER Cloud HyperCLOVA X Team"], "title": "HyperCLOVA X 8B Omni", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.SD"], "comment": "Technical Report", "summary": "In this report, we present HyperCLOVA X 8B Omni, the first any-to-any omnimodal model in the HyperCLOVA X family that supports text, audio, and vision as both inputs and outputs. By consolidating multimodal understanding and generation into a single model rather than separate modality-specific pipelines, HyperCLOVA X 8B Omni serves as an 8B-scale omni-pathfinding point toward practical any-to-any omni assistants. At a high level, the model unifies modalities through a shared next-token prediction interface over an interleaved multimodal sequence, while vision and audio encoders inject continuous embeddings for fine-grained understanding and grounding. Empirical evaluations demonstrate competitive performance against comparably sized models across diverse input-output combinations spanning text, audio, and vision, in both Korean and English. We anticipate that the open-weight release of HyperCLOVA X 8B Omni will support a wide range of research and deployment scenarios.", "AI": {"tldr": "介绍了HyperCLOVA X 8B Omni，一个支持文本、音频和视觉输入输出的多模态模型。", "motivation": "为了实现任何到任何的多模式助手，整合了多种理解与生成能力于单一模型中。", "method": "通过共享下一个标记预测接口统一各种模式，在混合多模态序列上工作，同时视觉和音频编码器注入连续嵌入以进行细致的理解和定位。", "result": "实验表明，HyperCLOVA X 8B Omni在多种输入输出组合下表现优异，包括韩语和英语的文本、音频和视觉。", "conclusion": "开放权重发布将支持广泛的科研及部署场景。"}}
{"id": "2601.01784", "pdf": "https://arxiv.org/pdf/2601.01784", "abs": "https://arxiv.org/abs/2601.01784", "authors": ["Boyang Zhao", "Xin Liao", "Jiaxin Chen", "Xiaoshuai Wu", "Yufeng Wu"], "title": "DDNet: A Dual-Stream Graph Learning and Disentanglement Framework for Temporal Forgery Localization", "categories": ["cs.CV", "cs.MM", "eess.IV"], "comment": null, "summary": "The rapid evolution of AIGC technology enables misleading viewers by tampering mere small segments within a video, rendering video-level detection inaccurate and unpersuasive. Consequently, temporal forgery localization (TFL), which aims to precisely pinpoint tampered segments, becomes critical. However, existing methods are often constrained by \\emph{local view}, failing to capture global anomalies. To address this, we propose a \\underline{d}ual-stream graph learning and \\underline{d}isentanglement framework for temporal forgery localization (DDNet). By coordinating a \\emph{Temporal Distance Stream} for local artifacts and a \\emph{Semantic Content Stream} for long-range connections, DDNet prevents global cues from being drowned out by local smoothness. Furthermore, we introduce Trace Disentanglement and Adaptation (TDA) to isolate generic forgery fingerprints, alongside Cross-Level Feature Embedding (CLFE) to construct a robust feature foundation via deep fusion of hierarchical features. Experiments on ForgeryNet and TVIL benchmarks demonstrate that our method outperforms state-of-the-art approaches by approximately 9\\% in AP@0.95, with significant improvements in cross-domain robustness.", "AI": {"tldr": "提出了一种双流图学习和解耦框架DDNet，用于视频篡改时间定位。", "motivation": "现有方法受限于局部视角，无法捕捉全局异常。为了改进这一限制，本文提出了新的解决方案。", "method": "采用双流设计，即时间距离流处理局部特征，语义内容流处理长程连接；引入指纹解耦与适应以及跨层级特征嵌入技术以增强模型鲁棒性。", "result": "实验表明，DDNet在AP@0.95指标上比现有最佳方法高出约9%，并在跨域鲁棒性方面有显著改进。", "conclusion": "所提出的DDNet框架通过有效捕捉全局异常和解耦通用伪造指纹，在视频篡改时间定位任务中表现优异。"}}
{"id": "2601.01781", "pdf": "https://arxiv.org/pdf/2601.01781", "abs": "https://arxiv.org/abs/2601.01781", "authors": ["Lakshay Sharma", "Alex Marin"], "title": "Subimage Overlap Prediction: Task-Aligned Self-Supervised Pretraining For Semantic Segmentation In Remote Sensing Imagery", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted at CV4EO Workshop at WACV 2026", "summary": "Self-supervised learning (SSL) methods have become a dominant paradigm for creating general purpose models whose capabilities can be transferred to downstream supervised learning tasks. However, most such methods rely on vast amounts of pretraining data. This work introduces Subimage Overlap Prediction, a novel self-supervised pretraining task to aid semantic segmentation in remote sensing imagery that uses significantly lesser pretraining imagery. Given an image, a sub-image is extracted and the model is trained to produce a semantic mask of the location of the extracted sub-image within the original image. We demonstrate that pretraining with this task results in significantly faster convergence, and equal or better performance (measured via mIoU) on downstream segmentation. This gap in convergence and performance widens when labeled training data is reduced. We show this across multiple architecture types, and with multiple downstream datasets. We also show that our method matches or exceeds performance while requiring significantly lesser pretraining data relative to other SSL methods. Code and model weights are provided at \\href{https://github.com/sharmalakshay93/subimage-overlap-prediction}{github.com/sharmalakshay93/subimage-overlap-prediction}.", "AI": {"tldr": "本文提出了一种新的自监督预训练任务——子图像重叠预测，用于遥感图像语义分割。", "motivation": "大多数现有的自监督学习方法依赖于大量预训练数据。为了减少所需的数据量并提高语义分割的性能，本文提出了一个新的自监督预训练任务。", "method": "该方法从原始图像中提取子图像，并通过预测其在原图中的位置来生成语义掩膜。", "result": "实验表明，使用这种方法进行预训练可以显著加快收敛速度并达到或超过其他自监督学习方法的性能，同时需要更少的预训练数据。", "conclusion": "提出的方法能够在多种架构类型和下游数据集上获得较好的分割效果，并且在减少标记训练数据的情况下仍能保持优越性。"}}
{"id": "2601.01780", "pdf": "https://arxiv.org/pdf/2601.01780", "abs": "https://arxiv.org/abs/2601.01780", "authors": ["Arsham Khosravani", "Alireza Hosseinpour", "Arshia Akhavan", "Mehdi Keshani", "Abbas Heydarnoori"], "title": "LIA: Supervised Fine-Tuning of Large Language Models for Automatic Issue Assignment", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Issue assignment is a critical process in software maintenance, where new issue reports are validated and assigned to suitable developers. However, manual issue assignment is often inconsistent and error-prone, especially in large open-source projects where thousands of new issues are reported monthly. Existing automated approaches have shown promise, but many rely heavily on large volumes of project-specific training data or relational information that is often sparse and noisy, which limits their effectiveness. To address these challenges, we propose LIA (LLM-based Issue Assignment), which employs supervised fine-tuning to adapt an LLM, DeepSeek-R1-Distill-Llama-8B in this work, for automatic issue assignment. By leveraging the LLM's pretrained semantic understanding of natural language and software-related text, LIA learns to generate ranked developer recommendations directly from issue titles and descriptions. The ranking is based on the model's learned understanding of historical issue-to-developer assignments, using patterns from past tasks to infer which developers are most likely to handle new issues. Through comprehensive evaluation, we show that LIA delivers substantial improvements over both its base pretrained model and state-of-the-art baselines. It achieves up to +187.8% higher Hit@1 compared to the DeepSeek-R1-Distill-Llama-8B pretrained base model, and outperforms four leading issue assignment methods by as much as +211.2% in Hit@1 score. These results highlight the effectiveness of domain-adapted LLMs for software maintenance tasks and establish LIA as a practical, high-performing solution for issue assignment.", "AI": {"tldr": "提出了一种基于大规模语言模型的自动问题分配方法LIA，通过监督微调使LLM能够根据问题标题和描述生成开发人员推荐排名。", "motivation": "解决手动问题分配过程中存在的不一致性和错误，并提高自动化问题分配的有效性，尤其是在缺乏充足项目特定训练数据的情况下。", "method": "利用大规模预训练语言模型的自然语言理解能力，通过监督微调适应LLM来执行自动问题分配任务。基于历史任务中的模式预测最适合处理新问题的开发人员。", "result": "在全面评估中显示LIA相比基础预训练模型和四个最先进的基线方法，在Hit@1分数上分别提高了187.8%和211.2%，表明领域适应型LLM在软件维护任务中的有效性。", "conclusion": "通过证明了LIA能够显著改善问题分配的准确性和效率，确立了它作为自动化问题分配任务中实用且高性能解决方案的地位。"}}
{"id": "2601.01774", "pdf": "https://arxiv.org/pdf/2601.01774", "abs": "https://arxiv.org/abs/2601.01774", "authors": ["Sai Varun Kodathala", "Rakesh Vunnam"], "title": "Can Large Language Models Solve Engineering Equations? A Systematic Comparison of Direct Prediction and Solver-Assisted Approaches", "categories": ["cs.AI", "cs.CE", "math.NA"], "comment": "14 pages", "summary": "Transcendental equations requiring iterative numerical solution pervade engineering practice, from fluid mechanics friction factor calculations to orbital position determination. We systematically evaluate whether Large Language Models can solve these equations through direct numerical prediction or whether a hybrid architecture combining LLM symbolic manipulation with classical iterative solvers proves more effective. Testing six state-of-the-art models (GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5) on 100 problems spanning seven engineering domains, we compare direct prediction against solver-assisted computation where LLMs formulate governing equations and provide initial conditions while Newton-Raphson iteration performs numerical solution. Direct prediction yields mean relative errors of 0.765 to 1.262 across models, while solver-assisted computation achieves 0.225 to 0.301, representing error reductions of 67.9% to 81.8%. Domain-specific analysis reveals dramatic improvements in Electronics (93.1%) due to exponential equation sensitivity, contrasted with modest gains in Fluid Mechanics (7.2%) where LLMs exhibit effective pattern recognition. These findings establish that contemporary LLMs excel at symbolic manipulation and domain knowledge retrieval but struggle with precision-critical iterative arithmetic, suggesting their optimal deployment as intelligent interfaces to classical numerical solvers rather than standalone computational engines.", "AI": {"tldr": "大型语言模型能否解决工程方程？通过直接预测和求解器辅助方法的系统比较来研究。", "motivation": "探索大型语言模型在解决需要迭代数值求解的超越方程中的能力，以及其与经典迭代求解器结合的效果。", "method": "测试六种最先进的模型（GPT-5.1、GPT-5.2、Gemini-3-Flash、Gemini-2.5-Lite、Claude-Sonnet-4.5、Claude-Opus-4.5），在包括流体力学摩擦系数计算和轨道位置确定在内的100个问题上，比较直接预测与求解器辅助计算方法的效果。", "result": "直接预测的平均相对误差为0.765到1.262之间，而求解器辅助计算的误差为0.225至0.301，误差减少了67.9%到81.8%，领域特定分析表明电子学中的改进最大（93.1%），流体力学中则较小（7.2%）。", "conclusion": "当代大型语言模型在符号操作和领域知识检索方面表现出色，但在精度关键的迭代算术上存在困难。最佳应用方式是作为经典数值求解器的智能接口，而不是独立计算引擎。"}}
{"id": "2601.01772", "pdf": "https://arxiv.org/pdf/2601.01772", "abs": "https://arxiv.org/abs/2601.01772", "authors": ["Manh-Dat Nguyen", "Thomas Do", "Nguyen Thanh Trung Le", "Xuan-The Tran", "Fred Chang", "Chin-Teng Lin"], "title": "EdgeSSVEP: A Fully Embedded SSVEP BCI Platform for Low-Power Real-Time Applications", "categories": ["cs.HC", "eess.SY"], "comment": null, "summary": "Brain-Computer Interfaces (BCIs) enable users to interact with machines directly via neural activity, yet their real-world deployment is often hindered by bulky and powerhungry hardware. We present EdgeSSVEP, a fully embedded microcontroller-based Steady-State Visually Evoked Potential (SSVEP) BCI platform that performs real-time EEG acquisition, zero-phase filtering, and on-device classification within a lowpower 240 MHz MCU operating at only 222 mW. The system incorporates an 8-channel EEG front end, supports 5-second stimulus durations, and executes the entire SSVEP decoding pipeline locally, eliminating dependence on PC-based processing. EdgeSSVEP was evaluated using six stimulus frequencies (7, 8, 9, 11, 7.5, and 8.5 Hz) with 10 participants. The device achieved 99.17% classification accuracy and 27.33 bits/min Information Transfer Rate (ITR), while consuming substantially less power than conventional desktop-based systems. The system integrates motion sensing to support artifact detection and improve robustness and signal stability in practical environments. For development and debugging, the system also provides optional TCP data streaming to external clients. Overall, EdgeSSVEP offers a scalable, energy-efficient, and secure embedded BCI platform suitable for assistive communication and neurofeedback applications, with potential extensions to accelerometer-based artifact mitigation and broader real-world deployments.", "AI": {"tldr": "本文介绍了一种基于微控制器的SSVEP脑机接口平台EdgeSSVEP，该平台实现了低功耗实时EEG信号采集和分类。", "motivation": "目前BCI设备由于体积大且能耗高，在实际应用中受到限制。因此开发一种低功耗、高性能的嵌入式BCI系统具有重要意义。", "method": "EdgeSSVEP利用8通道EEG前端，实现了实时EEG信号采集和零相位滤波，并在240MHz MCU上完成了整个SSVEP解码流程的本地处理。同时集成了运动传感以提高系统的稳定性和鲁棒性。", "result": "实验结果表明，该系统能够在六种不同的刺激频率下实现99.17%的分类准确率和27.33比特/分钟的信息传输速率，并显著降低了能耗。", "conclusion": "EdgeSSVEP提供了一种可扩展、节能且安全的嵌入式BCI平台，适用于辅助通信和神经反馈应用。未来还可以进一步集成加速度计来减少运动伪影影响并扩大实际应用场景。"}}
{"id": "2601.01769", "pdf": "https://arxiv.org/pdf/2601.01769", "abs": "https://arxiv.org/abs/2601.01769", "authors": ["Hao Lu", "Ziniu Qian", "Yifu Li", "Yang Zhou", "Bingzheng Wei", "Yan Xu"], "title": "CTIS-QA: Clinical Template-Informed Slide-level Question Answering for Pathology", "categories": ["cs.CV"], "comment": "The paper has been accepted by BIBM 2025", "summary": "In this paper, we introduce a clinical diagnosis template-based pipeline to systematically collect and structure pathological information. In collaboration with pathologists and guided by the the College of American Pathologists (CAP) Cancer Protocols, we design a Clinical Pathology Report Template (CPRT) that ensures comprehensive and standardized extraction of diagnostic elements from pathology reports. We validate the effectiveness of our pipeline on TCGA-BRCA. First, we extract pathological features from reports using CPRT. These features are then used to build CTIS-Align, a dataset of 80k slide-description pairs from 804 WSIs for vision-language alignment training, and CTIS-Bench, a rigorously curated VQA benchmark comprising 977 WSIs and 14,879 question-answer pairs. CTIS-Bench emphasizes clinically grounded, closed-ended questions (e.g., tumor grade, receptor status) that reflect real diagnostic workflows, minimize non-visual reasoning, and require genuine slide understanding. We further propose CTIS-QA, a Slide-level Question Answering model, featuring a dual-stream architecture that mimics pathologists' diagnostic approach. One stream captures global slide-level context via clustering-based feature aggregation, while the other focuses on salient local regions through attention-guided patch perception module. Extensive experiments on WSI-VQA, CTIS-Bench, and slide-level diagnostic tasks show that CTIS-QA consistently outperforms existing state-of-the-art models across multiple metrics. Code and data are available at https://github.com/HLSvois/CTIS-QA.", "AI": {"tldr": "提出了一种基于临床诊断模板的管道，用于系统地收集和结构化病理信息，并开发了CTIS-QA模型进行病理切片级别的问题回答。", "motivation": "为了确保全面且标准化地从病理报告中提取诊断元素，引入了一个基于临床诊断模板的管道。通过与病理学家合作并参考美国病理学家学会（CAP）癌症协议，设计了一种临床病理报告模板（CPRT）。", "method": "首先使用CPRT从报告中提取病理特征，并构建了CTIS-Align数据集和CTIS-Bench基准测试。提出了CTIS-QA模型，采用双流架构模拟病理学家的诊断方式。", "result": "在WSI-VQA、CTIS-Bench等任务上进行了广泛的实验，结果表明CTIS-QA在多个指标上均优于现有的最先进的模型。", "conclusion": "所提出的方法和系统为临床路径学报告提供了全面且标准化的信息提取，并提高了病理诊断的准确性和效率。"}}
{"id": "2601.01765", "pdf": "https://arxiv.org/pdf/2601.01765", "abs": "https://arxiv.org/abs/2601.01765", "authors": ["Yao Lu", "Shang Liu", "Hangan Zhou", "Wenji Fang", "Qijun Zhang", "Zhiyao Xie"], "title": "A New Benchmark for the Appropriate Evaluation of RTL Code Optimization", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization.", "AI": {"tldr": "该论文提出了RTL-OPT，一个新的基准测试标准，用于评估大型语言模型生成的寄存器传输级（RTL）代码优化能力。", "motivation": "随着人工智能的快速发展，高效的集成电路设计变得尤为重要。现有的评价基准主要关注于语法正确性而非优化质量。因此，本研究旨在引入一个新的基准来全面衡量模型在硬件设计上的性能、功耗和面积方面的表现。", "method": "该方法构建了一个包含36个手工制作数字电路设计的测试集，涵盖了组合逻辑、流水线数据路径等不同类型的设计，并提供了每个任务中代码优化前后的对比。同时引入了自动化评估框架来验证功能正确性并量化性能改善。", "result": "通过RTL-OPT基准测试，可以标准化且有意义地评价用于硬件设计优化的生成模型的能力，特别是它们在PPA（性能、功耗、面积）方面的改进能力。", "conclusion": "该研究提出了一种新的评估标准和自动化框架，能够更全面地衡量大型语言模型在RTL代码优化中的表现。这为未来的相关研究提供了重要的参考和支持。"}}
{"id": "2601.01762", "pdf": "https://arxiv.org/pdf/2601.01762", "abs": "https://arxiv.org/abs/2601.01762", "authors": ["Yanhao Wu", "Haoyang Zhang", "Fei He", "Rui Wu", "Congpei Qiu", "Liang Gao", "Wei Ke", "Tong Zhang"], "title": "AlignDrive: Aligned Lateral-Longitudinal Planning for End-to-End Autonomous Driving", "categories": ["cs.RO", "cs.CV"], "comment": "underreview", "summary": "End-to-end autonomous driving has rapidly progressed, enabling joint perception and planning in complex environments. In the planning stage, state-of-the-art (SOTA) end-to-end autonomous driving models decouple planning into parallel lateral and longitudinal predictions. While effective, this parallel design can lead to i) coordination failures between the planned path and speed, and ii) underutilization of the drive path as a prior for longitudinal planning, thus redundantly encoding static information. To address this, we propose a novel cascaded framework that explicitly conditions longitudinal planning on the drive path, enabling coordinated and collision-aware lateral and longitudinal planning. Specifically, we introduce a path-conditioned formulation that explicitly incorporates the drive path into longitudinal planning. Building on this, the model predicts longitudinal displacements along the drive path rather than full 2D trajectory waypoints. This design simplifies longitudinal reasoning and more tightly couples it with lateral planning. Additionally, we introduce a planning-oriented data augmentation strategy that simulates rare safety-critical events, such as vehicle cut-ins, by adding agents and relabeling longitudinal targets to avoid collision. Evaluated on the challenging Bench2Drive benchmark, our method sets a new SOTA, achieving a driving score of 89.07 and a success rate of 73.18%, demonstrating significantly improved coordination and safety", "AI": {"tldr": "AlignDrive 提出了一个级联框架，通过将纵向规划基于驾驶路径进行条件化，实现了协调且避碰的横向和纵向规划。", "motivation": "传统的端到端自动驾驶模型在规划阶段将路径规划拆分为并行的横向与纵向预测，导致路径与速度协调失败及驾驶路径作为纵向规划先验信息未充分利用的问题。为此提出了一种新的级联框架解决这些问题。", "method": "该方法引入了一个基于路径条件化的形式化方案，并通过沿着路径预测纵向位移来简化纵向推理并更紧密地耦合横向和纵向规划，同时提出了用于模拟车辆插入等罕见安全关键事件的数据增强策略以提高安全性。", "result": "在 Bench2Drive 数据集上进行了评估，该方法实现了89.07的驾驶得分及73.18%的成功率，达到了新的SOTA水平。", "conclusion": "AlignDrive 方法通过更紧密地整合横向和纵向规划提高了自动驾驶的安全性和协调性，并展示了其优越性能。"}}
{"id": "2601.01756", "pdf": "https://arxiv.org/pdf/2601.01756", "abs": "https://arxiv.org/abs/2601.01756", "authors": ["N. Sukumar", "Ritwick Roy"], "title": "A Wachspress-based transfinite formulation for exactly enforcing Dirichlet boundary conditions on convex polygonal domains in physics-informed neural networks", "categories": ["math.NA", "cs.NE"], "comment": "47 pages, 21 figures", "summary": "In this paper, we present a Wachspress-based transfinite formulation on convex polygonal domains for exact enforcement of Dirichlet boundary conditions in physics-informed neural networks. This approach leverages prior advances in geometric design such as blending functions and transfinite interpolation over convex domains. For prescribed Dirichlet boundary function $\\mathcal{B}$, the transfinite interpolant of $\\mathcal{B}$, $g : \\bar P \\to C^0(\\bar P)$, $\\textit{lifts}$ functions from the boundary of a two-dimensional polygonal domain to its interior. The trial function is expressed as the difference between the neural network's output and the extension of its boundary restriction into the interior of the domain, with $g$ added to it. This ensures kinematic admissibility of the trial function in the deep Ritz method. Wachspress coordinates for an $n$-gon are used in the transfinite formula, which generalizes bilinear Coons transfinite interpolation on rectangles to convex polygons. The neural network trial function has a bounded Laplacian, thereby overcoming a limitation in a previous contribution where approximate distance functions were used to exactly enforce Dirichlet boundary conditions. For a point $\\boldsymbol{x} \\in \\bar{P}$, Wachspress coordinates, $\\boldsymbolλ : \\bar P \\to [0,1]^n$, serve as a geometric feature map for the neural network: $\\boldsymbolλ$ encodes the boundary edges of the polygonal domain. This offers a framework for solving problems on parametrized convex geometries using neural networks. The accuracy of physics-informed neural networks and deep Ritz is assessed on forward, inverse, and parametrized geometric Poisson boundary-value problems.", "AI": {"tldr": "本文提出了一种基于Wachspress的跨无穷插值方法，用于在物理信息神经网络中精确实施Dirichlet边界条件。", "motivation": "为了提高物理信息神经网络在处理具有Dirichlet边界条件问题时的准确性。", "method": "利用几何设计中的混合函数和跨无穷插值技术，在凸多边形域上构造精确满足Dirichlet边界条件的试函数。", "result": "该方法应用于前向、逆向及参数化几何泊松边值问题，展示了物理信息神经网络与深度里茨法在这些问题上的准确性和有效性。", "conclusion": "通过Wachspress坐标实现跨无穷插值的方法，为解决参数化凸几何体上的问题提供了一种有效的框架。"}}
{"id": "2601.01753", "pdf": "https://arxiv.org/pdf/2601.01753", "abs": "https://arxiv.org/abs/2601.01753", "authors": ["Hyunsoo Kim", "Jaewan Moon", "Seongmin Park", "Jongwuk Lee"], "title": "MergeRec: Model Merging for Data-Isolated Cross-Domain Sequential Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": "Accepted by KDD 2026", "summary": "Modern recommender systems trained on domain-specific data often struggle to generalize across multiple domains. Cross-domain sequential recommendation has emerged as a promising research direction to address this challenge; however, existing approaches face fundamental limitations, such as reliance on overlapping users or items across domains, or unrealistic assumptions that ignore privacy constraints. In this work, we propose a new framework, MergeRec, based on model merging under a new and realistic problem setting termed data-isolated cross-domain sequential recommendation, where raw user interaction data cannot be shared across domains. MergeRec consists of three key components: (1) merging initialization, (2) pseudo-user data construction, and (3) collaborative merging optimization. First, we initialize a merged model using training-free merging techniques. Next, we construct pseudo-user data by treating each item as a virtual sequence in each domain, enabling the synthesis of meaningful training samples without relying on real user interactions. Finally, we optimize domain-specific merging weights through a joint objective that combines a recommendation loss, which encourages the merged model to identify relevant items, and a distillation loss, which transfers collaborative filtering signals from the fine-tuned source models. Extensive experiments demonstrate that MergeRec not only preserves the strengths of the original models but also significantly enhances generalizability to unseen domains. Compared to conventional model merging methods, MergeRec consistently achieves superior performance, with average improvements of up to 17.21% in Recall@10, highlighting the potential of model merging as a scalable and effective approach for building universal recommender systems. The source code is available at https://github.com/DIALLab-SKKU/MergeRec.", "AI": {"tldr": "MergeRec提出了一种新的框架，通过模型合并解决数据隔离的跨域序列推荐问题。", "motivation": "现代基于特定领域训练的推荐系统在多个领域的泛化能力不足。现有的跨域序列推荐方法依赖于重叠用户或物品或忽视隐私限制等基础性限制。", "method": "MergeRec框架包括三部分：初始化合并、伪用户数据构建和协作优化。首先，使用无训练合并技术初始化模型；其次，在每个领域将每项作为虚拟序列构建伪用户数据以生成有意义的训练样本；最后，通过联合目标优化领域特异性合并权重。", "result": "实验表明MergeRec不仅保留了原始模型的优势，还显著增强了对未见域的泛化能力。与传统方法相比，性能提升高达17.21%。", "conclusion": "MergeRec证明了模型合并作为构建通用推荐系统的可扩展且有效的方法的潜力。"}}
{"id": "2601.01751", "pdf": "https://arxiv.org/pdf/2601.01751", "abs": "https://arxiv.org/abs/2601.01751", "authors": ["Samaneh Mohtadi", "Gianluca Demartini"], "title": "Query-Document Dense Vectors for LLM Relevance Judgment Bias Analysis", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "Accepted for presentation at the ECIR 2026 Full Papers track", "summary": "Large Language Models (LLMs) have been used as relevance assessors for Information Retrieval (IR) evaluation collection creation due to reduced cost and increased scalability as compared to human assessors. While previous research has looked at the reliability of LLMs as compared to human assessors, in this work, we aim to understand if LLMs make systematic mistakes when judging relevance, rather than just understanding how good they are on average. To this aim, we propose a novel representational method for queries and documents that allows us to analyze relevance label distributions and compare LLM and human labels to identify patterns of disagreement and localize systematic areas of disagreement. We introduce a clustering-based framework that embeds query-document (Q-D) pairs into a joint semantic space, treating relevance as a relational property. Experiments on TREC Deep Learning 2019 and 2020 show that systematic disagreement between humans and LLMs is concentrated in specific semantic clusters rather than distributed randomly. Query-level analyses reveal recurring failures, most often in definition-seeking, policy-related, or ambiguous contexts. Queries with large variation in agreement across their clusters emerge as disagreement hotspots, where LLMs tend to under-recall relevant content or over-include irrelevant material. This framework links global diagnostics with localized clustering to uncover hidden weaknesses in LLM judgments, enabling bias-aware and more reliable IR evaluation.", "AI": {"tldr": "研究提出了一种新颖的方法，用于分析大型语言模型在信息检索中作为相关性评估者时的偏见问题。", "motivation": "为了理解大型语言模型是否会在判断相关性方面出现系统性的错误，而不是仅仅评估其整体性能。通过对比人类和机器的相关标签来找出模式差异，从而识别出特定领域的偏差。", "method": "利用聚类框架将查询-文档对嵌入到联合语义空间中，以研究相关性作为关系属性的分布情况，并通过TREC Deep Learning 2019和2020数据集进行实验。", "result": "发现人类与大型语言模型之间的系统性分歧集中在特定的语义簇内而非随机分布。查询级分析揭示了定义搜索、政策相关或含糊不清的情境中最常见的失败情况。", "conclusion": "该框架通过连接全局诊断和局部聚类来揭示大型语言模型判断中的隐藏弱点，有助于开发出更加可靠的信息检索评估方法。"}}
{"id": "2601.01749", "pdf": "https://arxiv.org/pdf/2601.01749", "abs": "https://arxiv.org/abs/2601.01749", "authors": ["Lei Zhu", "Lijian Lin", "Ye Zhu", "Jiahao Wu", "Xuehan Hou", "Yu Li", "Yunfei Liu", "Jie Chen"], "title": "MANGO:Natural Multi-speaker 3D Talking Head Generation via 2D-Lifted Enhancement", "categories": ["cs.CV"], "comment": "20 pages, 11i figures", "summary": "Current audio-driven 3D head generation methods mainly focus on single-speaker scenarios, lacking natural, bidirectional listen-and-speak interaction. Achieving seamless conversational behavior, where speaking and listening states transition fluidly remains a key challenge. Existing 3D conversational avatar approaches rely on error-prone pseudo-3D labels that fail to capture fine-grained facial dynamics. To address these limitations, we introduce a novel two-stage framework MANGO, which leveraging pure image-level supervision by alternately training to mitigate the noise introduced by pseudo-3D labels, thereby achieving better alignment with real-world conversational behaviors. Specifically, in the first stage, a diffusion-based transformer with a dual-audio interaction module models natural 3D motion from multi-speaker audio. In the second stage, we use a fast 3D Gaussian Renderer to generate high-fidelity images and provide 2D-level photometric supervision for the 3D motions through alternate training. Additionally, we introduce MANGO-Dialog, a high-quality dataset with over 50 hours of aligned 2D-3D conversational data across 500+ identities. Extensive experiments demonstrate that our method achieves exceptional accuracy and realism in modeling two-person 3D dialogue motion, significantly advancing the fidelity and controllability of audio-driven talking heads.", "AI": {"tldr": "提出了一种两阶段框架MANGO，用于生成自然的多说话者3D对话头像。", "motivation": "当前方法在单说话者场景下的音频驱动3D头部生成中表现良好，但在实现自然、双向听和说交互方面存在不足。现有方法依赖于伪3D标签来捕捉面部动态，但效果不佳。因此需要一种新的方法来解决这些问题。", "method": "MANGO框架分为两阶段：第一阶段使用带有双音频互动模块的扩散基元变换器从多说话者音频中建模自然3D动作；第二阶段通过交替训练提供2D水平光度监督，以生成高质量图像。", "result": "实验表明该方法在建模两人对话运动方面表现出色，在准确性、现实性和可控性上均有显著提升。", "conclusion": "MANGO框架能够有效地解决现有3D对话头像生成中的问题，并通过高精度数据集提高了模型的性能和鲁棒性。"}}
{"id": "2601.01747", "pdf": "https://arxiv.org/pdf/2601.01747", "abs": "https://arxiv.org/abs/2601.01747", "authors": ["Jiwei Guan", "Haibo Jin", "Haohan Wang"], "title": "Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "comment": "EACL", "summary": "Recent advancements in Large Vision-Language Models (LVLMs) have shown groundbreaking capabilities across diverse multimodal tasks. However, these models remain vulnerable to adversarial jailbreak attacks, where adversaries craft subtle perturbations to bypass safety mechanisms and trigger harmful outputs. Existing white-box attacks methods require full model accessibility, suffer from computing costs and exhibit insufficient adversarial transferability, making them impractical for real-world, black-box settings. To address these limitations, we propose a black-box jailbreak attack on LVLMs via Zeroth-Order optimization using Simultaneous Perturbation Stochastic Approximation (ZO-SPSA). ZO-SPSA provides three key advantages: (i) gradient-free approximation by input-output interactions without requiring model knowledge, (ii) model-agnostic optimization without the surrogate model and (iii) lower resource requirements with reduced GPU memory consumption. We evaluate ZO-SPSA on three LVLMs, including InstructBLIP, LLaVA and MiniGPT-4, achieving the highest jailbreak success rate of 83.0% on InstructBLIP, while maintaining imperceptible perturbations comparable to white-box methods. Moreover, adversarial examples generated from MiniGPT-4 exhibit strong transferability to other LVLMs, with ASR reaching 64.18%. These findings underscore the real-world feasibility of black-box jailbreaks and expose critical weaknesses in the safety mechanisms of current LVLMs", "AI": {"tldr": "本文提出了一种基于零阶优化的黑盒攻击方法ZO-SPSA，用于针对大型视觉语言模型（LVLMs）的安全机制进行绕过。", "motivation": "现有白盒攻击方法在计算成本、实用性及跨模态传输能力方面存在不足，难以适用于真实世界中的黑盒场景。因此本文旨在提出一种实用且高效的黑盒攻击策略来暴露当前大型视觉语言模型的安全弱点。", "method": "通过利用零阶优化技术中的同时扰动随机近似(ZO-SPSA)方法，在不依赖于目标模型具体信息的情况下，实现了对LVLMs的有效绕过。此方法不需要梯度计算和替代模型支持，并且资源消耗相对较低。", "result": "在InstructBLIP、LLaVA和MiniGPT-4三个大型视觉语言模型上进行了验证，取得了高达83.0%的成功率并保持了微小的扰动幅度。此外，来自MiniGPT-4生成的对抗性样本对其他LVLMs表现出64.18%的攻击成功率。", "conclusion": "这项研究表明黑盒攻击在实际环境中是可行的，并且揭示了现有大型视觉语言模型的安全机制存在明显的弱点需要改进。"}}
{"id": "2601.01746", "pdf": "https://arxiv.org/pdf/2601.01746", "abs": "https://arxiv.org/abs/2601.01746", "authors": ["Lintong Wei", "Jian Lu", "Haozhe Cheng", "Jihua Zhu", "Kaibing Zhang"], "title": "Point-SRA: Self-Representation Alignment for 3D Representation Learning", "categories": ["cs.CV"], "comment": "This is an AAAI 2026 accepted paper titled \"Point-SRA: Self-Representation Alignment for 3D Representation Learning\", spanning 13 pages in total. The submission includes 7 figures (fig1 to fig7) that visually support the technical analysis", "summary": "Masked autoencoders (MAE) have become a dominant paradigm in 3D representation learning, setting new performance benchmarks across various downstream tasks. Existing methods with fixed mask ratio neglect multi-level representational correlations and intrinsic geometric structures, while relying on point-wise reconstruction assumptions that conflict with the diversity of point cloud. To address these issues, we propose a 3D representation learning method, termed Point-SRA, which aligns representations through self-distillation and probabilistic modeling. Specifically, we assign different masking ratios to the MAE to capture complementary geometric and semantic information, while the MeanFlow Transformer (MFT) leverages cross-modal conditional embeddings to enable diverse probabilistic reconstruction. Our analysis further reveals that representations at different time steps in MFT also exhibit complementarity. Therefore, a Dual Self-Representation Alignment mechanism is proposed at both the MAE and MFT levels. Finally, we design a Flow-Conditioned Fine-Tuning Architecture to fully exploit the point cloud distribution learned via MeanFlow. Point-SRA outperforms Point-MAE by 5.37% on ScanObjectNN. On intracranial aneurysm segmentation, it reaches 96.07% mean IoU for arteries and 86.87% for aneurysms. For 3D object detection, Point-SRA achieves 47.3% AP@50, surpassing MaskPoint by 5.12%.", "AI": {"tldr": "Point-SRA是一种用于三维表示学习的方法，通过自蒸馏和概率建模来对齐表示。", "motivation": "现有的固定掩码比例方法忽视了多层次表征相关性和内在几何结构，并依赖于与点云多样性冲突的逐点重建假设。为了解决这些问题，提出了一种新的3D表示学习方法Point-SRA。", "method": "该方法通过分配不同的掩码比例来捕获互补的几何和语义信息，使用MeanFlow Transformer（MFT）跨模态条件嵌入实现多样化的概率重构，并提出了在MAE和MFT级别上的双重自表示对齐机制。最后设计了一个基于流条件微调架构。", "result": "Point-SRA在ScanObjectNN上比Point-MAE高出5.37%，动脉的平均IoU为96.07%，动脉瘤的平均IoU为86.87%；对于3D物体检测，Point-SRA实现了47.3%的AP@50，超过了MaskPoint 5.12%。", "conclusion": "通过双重自表示对齐机制，Point-SRA能够在不同时间步骤下捕捉到互补表征信息，并在各种下游任务中取得了优异的表现。"}}
{"id": "2601.01745", "pdf": "https://arxiv.org/pdf/2601.01745", "abs": "https://arxiv.org/abs/2601.01745", "authors": ["Hong Han", "Hao-Chen Pei", "Zhao-Zheng Nie", "Xin Luo", "Xin-Shun Xu"], "title": "Multi-granularity Interactive Attention Framework for Residual Hierarchical Pronunciation Assessment", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 4 figures, 5 tables, accepted by AAAI 2026", "summary": "Automatic pronunciation assessment plays a crucial role in computer-assisted pronunciation training systems. Due to the ability to perform multiple pronunciation tasks simultaneously, multi-aspect multi-granularity pronunciation assessment methods are gradually receiving more attention and achieving better performance than single-level modeling tasks. However, existing methods only consider unidirectional dependencies between adjacent granularity levels, lacking bidirectional interaction among phoneme, word, and utterance levels and thus insufficiently capturing the acoustic structural correlations. To address this issue, we propose a novel residual hierarchical interactive method, HIA for short, that enables bidirectional modeling across granularities. As the core of HIA, the Interactive Attention Module leverages an attention mechanism to achieve dynamic bidirectional interaction, effectively capturing linguistic features at each granularity while integrating correlations between different granularity levels. We also propose a residual hierarchical structure to alleviate the feature forgetting problem when modeling acoustic hierarchies. In addition, we use 1-D convolutional layers to enhance the extraction of local contextual cues at each granularity. Extensive experiments on the speechocean762 dataset show that our model is comprehensively ahead of the existing state-of-the-art methods.", "AI": {"tldr": "提出了一种多粒度交互式注意力框架，用于残差层次发音评估。", "motivation": "现有的方法仅考虑相邻粒度级别之间的一维依赖关系，无法充分捕捉声学结构关联。因此，需要一种能够实现跨粒度双向建模的方法。", "method": "提出了一种新的残差分层交互方法HIA，该方法使用交互注意力模块通过注意机制实现了动态的双向互动，并采用了残差层次结构来减轻特征遗忘问题，在各粒度级别上利用1-D卷积层增强局部上下文线索提取。", "result": "在speechocean762数据集上的大量实验显示，所提出的模型优于现有的最先进的方法。", "conclusion": "通过引入交互式注意机制和残差结构，该模型能够更有效地捕捉不同粒度层次之间的相关性，并提高发音评估的准确性。"}}
{"id": "2601.01743", "pdf": "https://arxiv.org/pdf/2601.01743", "abs": "https://arxiv.org/abs/2601.01743", "authors": ["Bin Xu"], "title": "AI Agent Systems: Architectures, Applications, and Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "AI agents -- systems that combine foundation models with reasoning, planning, memory, and tool use -- are rapidly becoming a practical interface between natural-language intent and real-world computation. This survey synthesizes the emerging landscape of AI agent architectures across: (i) deliberation and reasoning (e.g., chain-of-thought-style decomposition, self-reflection and verification, and constraint-aware decision making), (ii) planning and control (from reactive policies to hierarchical and multi-step planners), and (iii) tool calling and environment interaction (retrieval, code execution, APIs, and multimodal perception). We organize prior work into a unified taxonomy spanning agent components (policy/LLM core, memory, world models, planners, tool routers, and critics), orchestration patterns (single-agent vs.\\ multi-agent; centralized vs.\\ decentralized coordination), and deployment settings (offline analysis vs.\\ online interactive assistance; safety-critical vs.\\ open-ended tasks). We discuss key design trade-offs -- latency vs.\\ accuracy, autonomy vs.\\ controllability, and capability vs.\\ reliability -- and highlight how evaluation is complicated by non-determinism, long-horizon credit assignment, tool and environment variability, and hidden costs such as retries and context growth. Finally, we summarize measurement and benchmarking practices (task suites, human preference and utility metrics, success under constraints, robustness and security) and identify open challenges including verification and guardrails for tool actions, scalable memory and context management, interpretability of agent decisions, and reproducible evaluation under realistic workloads.", "AI": {"tldr": "综述了人工智能代理系统的架构，包括推理、规划和工具调用等方面，并讨论了设计中的权衡以及评估的复杂性。", "motivation": "随着基础模型与推理、规划、记忆及工具使用结合的人工智能代理系统日益成为自然语言意图与现实世界计算之间的一种实用接口，研究其架构变得迫切。", "method": "通过整理现有工作，提出了一个统一分类法涵盖代理组件、协调模式和部署场景，并讨论了设计中的权衡以及评估的复杂性。", "result": "总结了测量和基准测试实践，并指出了开放挑战包括工具行为验证、可扩展的记忆管理、代理决策的解释性和真实负载下可重复评估的问题。", "conclusion": "综述展示了人工智能代理系统的发展，强调了解决方案中的设计权衡以及如何进行有效的评估。"}}
{"id": "2601.01739", "pdf": "https://arxiv.org/pdf/2601.01739", "abs": "https://arxiv.org/abs/2601.01739", "authors": ["Eunbi Choi", "Kibong Choi", "Seokhee Hong", "Junwon Hwang", "Hyojin Jeon", "Hyunjik Jo", "Joonkee Kim", "Seonghwan Kim", "Soyeon Kim", "Sunkyoung Kim", "Yireun Kim", "Yongil Kim", "Haeju Lee", "Jinsik Lee", "Kyungmin Lee", "Sangha Park", "Heuiyeen Yeen", "Hwan Chang", "Stanley Jungkyu Choi", "Yejin Choi", "Jiwon Ham", "Kijeong Jeon", "Geunyeong Jeong", "Gerrard Jeongwon Jo", "Yonghwan Jo", "et al. (40 additional authors not shown)"], "title": "K-EXAONE Technical Report", "categories": ["cs.CL", "cs.AI"], "comment": "29 pages", "summary": "This technical report presents K-EXAONE, a large-scale multilingual language model developed by LG AI Research. K-EXAONE is built on a Mixture-of-Experts architecture with 236B total parameters, activating 23B parameters during inference. It supports a 256K-token context window and covers six languages: Korean, English, Spanish, German, Japanese, and Vietnamese. We evaluate K-EXAONE on a comprehensive benchmark suite spanning reasoning, agentic, general, Korean, and multilingual abilities. Across these evaluations, K-EXAONE demonstrates performance comparable to open-weight models of similar size. K-EXAONE, designed to advance AI for a better life, is positioned as a powerful proprietary AI foundation model for a wide range of industrial and research applications.", "AI": {"tldr": "K-EXAONE是一个大规模多语言模型，由LG AI Research开发。", "motivation": "旨在推进AI以改善生活，支持多种语言和长文本上下文窗口。", "method": "采用混合专家架构，总参数量为2360亿，推理时激活230亿参数。", "result": "在涵盖推理、代理性、通用能力等方面的一系列基准测试中表现出与同等规模模型相当的性能。", "conclusion": "K-EXAONE被定位为强大的专有AI基础模型，适用于广泛的研究和工业应用。"}}
{"id": "2601.01726", "pdf": "https://arxiv.org/pdf/2601.01726", "abs": "https://arxiv.org/abs/2601.01726", "authors": ["Wenhui Chu", "Aobo Jin", "Hardik A. Gohel"], "title": "Simulations and Advancements in MRI-Guided Power-Driven Ferric Tools for Wireless Therapeutic Interventions", "categories": ["cs.RO", "eess.SY"], "comment": "10 pages, 7 figures", "summary": "Designing a robotic system that functions effectively within the specific environment of a Magnetic Resonance Imaging (MRI) scanner requires solving numerous technical issues, such as maintaining the robot's precision and stability under strong magnetic fields. This research focuses on enhancing MRI's role in medical imaging, especially in its application to guide intravascular interventions using robot-assisted devices. A newly developed computational system is introduced, designed for seamless integration with the MRI scanner, including a computational unit and user interface. This system processes MR images to delineate the vascular network, establishing virtual paths and boundaries within vessels to prevent procedural damage. Key findings reveal the system's capability to create tailored magnetic field gradient patterns for device control, considering the vessel's geometry and safety norms, and adapting to different blood flow characteristics for finer navigation. Additionally, the system's modeling aspect assesses the safety and feasibility of navigating pre-set vascular paths. Conclusively, this system, based on the Qt framework and C/C++, with specialized software modules, represents a major step forward in merging imaging technology with robotic aid, significantly enhancing precision and safety in intravascular procedures.", "AI": {"tldr": "设计一个能够在MRI环境下有效工作的机器人系统，通过计算单元和用户界面处理MR图像以指导血管介入手术。", "motivation": "解决在强磁场环境中保持机器人精度和稳定性的技术问题，提高MRI在医疗成像中的应用，特别是在引导血管内干预方面的作用。", "method": "开发一个新计算系统，该系统与MRI扫描仪无缝集成，并处理MR图像以确定血管网络，建立虚拟路径和边界，防止手术损伤。同时考虑血管几何形状、安全规范及不同的血流特性进行磁力场梯度模式的定制。", "result": "系统能够根据血管几何形状和安全标准创建定制化的磁场梯度模式，适应不同血流特征，并通过仿真验证其导航预设路径的安全性和可行性。", "conclusion": "基于Qt框架和C/C++开发的新系统，在成像技术和机器人辅助的结合上迈出了重要的一步，显著提高了血管内手术中的精确度和安全性。"}}
{"id": "2601.01720", "pdf": "https://arxiv.org/pdf/2601.01720", "abs": "https://arxiv.org/abs/2601.01720", "authors": ["Xijie Huang", "Chengming Xu", "Donghao Luo", "Xiaobin Hu", "Peng Tang", "Xu Peng", "Jiangning Zhang", "Chengjie Wang", "Yanwei Fu"], "title": "FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing", "categories": ["cs.CV"], "comment": null, "summary": "First-Frame Propagation (FFP) offers a promising paradigm for controllable video editing, but existing methods are hampered by a reliance on cumbersome run-time guidance. We identify the root cause of this limitation as the inadequacy of current training datasets, which are often too short, low-resolution, and lack the task diversity required to teach robust temporal priors. To address this foundational data gap, we first introduce FFP-300K, a new large-scale dataset comprising 300K high-fidelity video pairs at 720p resolution and 81 frames in length, constructed via a principled two-track pipeline for diverse local and global edits. Building on this dataset, we propose a novel framework designed for true guidance-free FFP that resolves the critical tension between maintaining first-frame appearance and preserving source video motion. Architecturally, we introduce Adaptive Spatio-Temporal RoPE (AST-RoPE), which dynamically remaps positional encodings to disentangle appearance and motion references. At the objective level, we employ a self-distillation strategy where an identity propagation task acts as a powerful regularizer, ensuring long-term temporal stability and preventing semantic drift. Comprehensive experiments on the EditVerseBench benchmark demonstrate that our method significantly outperforming existing academic and commercial models by receiving about 0.2 PickScore and 0.3 VLM score improvement against these competitors.", "AI": {"tldr": "提出了一种新的大规模数据集FFP-300K和一种无引导的First-Frame Propagation（FFP）框架，旨在改进视频编辑。", "motivation": "现有FFP方法受到运行时指导繁琐的限制。作者通过识别训练数据不足的问题，开发了一个新数据集并提出了解决方案以实现更通用、无需引导的视频编辑。", "method": "引入了大规模高分辨率视频数据集FFP-300K，并提出了一个框架包含自蒸馏策略和新的AST-RoPE架构来解决现有问题。", "result": "在EditVerseBench基准测试中，方法显著优于其他学术和商业模型，在PickScore和VLM评分方面均有提高。", "conclusion": "该工作成功解决了FFP的引导依赖问题，并展示了其在视频编辑任务中的优越性能。"}}
{"id": "2601.01718", "pdf": "https://arxiv.org/pdf/2601.01718", "abs": "https://arxiv.org/abs/2601.01718", "authors": ["YuanLab. ai", ":", "Shawn Wu", "Sean Wang", "Louie Li", "Darcy Chen", "Allen Wang", "Jiangang Luo", "Xudong Zhao", "Joseph Shen", "Gawain Ma", "Jasper Jia", "Marcus Mao", "Claire Wang", "Hunter He", "Carol Wang", "Zera Zhang", "Jason Wang", "Chonly Shen", "Leo Zhang", "Logan Chen", "Qasim Meng", "James Gong", "Danied Zhao", "Penn Zheng", "et al. (2 additional authors not shown)"], "title": "Yuan3.0 Flash: An Open Multimodal Large Language Model for Enterprise Applications", "categories": ["cs.AI"], "comment": null, "summary": "We introduce Yuan3.0 Flash, an open-source Mixture-of-Experts (MoE) MultiModal Large Language Model featuring 3.7B activated parameters and 40B total parameters, specifically designed to enhance performance on enterprise-oriented tasks while maintaining competitive capabilities on general-purpose tasks. To address the overthinking phenomenon commonly observed in Large Reasoning Models (LRMs), we propose Reflection-aware Adaptive Policy Optimization (RAPO), a novel RL training algorithm that effectively regulates overthinking behaviors. In enterprise-oriented tasks such as retrieval-augmented generation (RAG), complex table understanding, and summarization, Yuan3.0 Flash consistently achieves superior performance. Moreover, it also demonstrates strong reasoning capabilities in domains such as mathematics, science, etc., attaining accuracy comparable to frontier model while requiring only approximately 1/4 to 1/2 of the average tokens. Yuan3.0 Flash has been fully open-sourced to facilitate further research and real-world deployment: https://github.com/Yuan-lab-LLM/Yuan3.0.", "AI": {"tldr": "Yuan3.0 Flash 是一种开源的混合专家多模态大语言模型，旨在提高企业任务上的性能。", "motivation": "为了解决大型推理模型中常见的过度思考问题，并提升在特定企业应用中的表现，该论文提出了 Reflection-aware Adaptive Policy Optimization (RAPO) 算法。", "method": "使用 RAPO 算法训练模型以调节过度思考行为；Yuan3.0 Flash 具有 3.7B 激活参数和 40B 总参数，适用于企业任务如检索增强生成、复杂表格理解和总结。", "result": "在企业相关任务中，Yuan3.0 Flash 表现优异，在数学等领域推理能力也接近前沿模型水平。", "conclusion": "Yuan3.0 Flash 已完全开源，便于进一步研究和实际部署。"}}
{"id": "2601.01712", "pdf": "https://arxiv.org/pdf/2601.01712", "abs": "https://arxiv.org/abs/2601.01712", "authors": ["Jiarui Wang", "Huichao Chai", "Yuanhang Zhang", "Zongjin Zhou", "Wei Guo", "Xingkun Yang", "Qiang Tang", "Bo Pan", "Jiawei Zhu", "Ke Cheng", "Yuting Yan", "Shulan Wang", "Yingjie Zhu", "Zhengfan Yuan", "Jiaqi Huang", "Yuhan Zhang", "Xiaosong Sun", "Zhinan Zhang", "Hong Zhu", "Yongsheng Zhang", "Tiantian Dong", "Zhong Xiao", "Deliang Liu", "Chengzhou Lu", "Yuan Sun", "et al. (16 additional authors not shown)"], "title": "RelayGR: Scaling Long-Sequence Generative Recommendation via Cross-Stage Relay-Race Inference", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "Real-time recommender systems execute multi-stage cascades (retrieval, pre-processing, fine-grained ranking) under strict tail-latency SLOs, leaving only tens of milliseconds for ranking. Generative recommendation (GR) models can improve quality by consuming long user-behavior sequences, but in production their online sequence length is tightly capped by the ranking-stage P99 budget. We observe that the majority of GR tokens encode user behaviors that are independent of the item candidates, suggesting an opportunity to pre-infer a user-behavior prefix once and reuse it during ranking rather than recomputing it on the critical path. Realizing this idea at industrial scale is non-trivial: the prefix cache must survive across multiple pipeline stages before the final ranking instance is determined, the user population implies cache footprints far beyond a single device, and indiscriminate pre-inference would overload shared resources under high QPS. We present RelayGR, a production system that enables in-HBM relay-race inference for GR. RelayGR selectively pre-infers long-term user prefixes, keeps their KV caches resident in HBM over the request lifecycle, and ensures the subsequent ranking can consume them without remote fetches. RelayGR combines three techniques: 1) a sequence-aware trigger that admits only at-risk requests under a bounded cache footprint and pre-inference load, 2) an affinity-aware router that co-locates cache production and consumption by routing both the auxiliary pre-infer signal and the ranking request to the same instance, and 3) a memory-aware expander that uses server-local DRAM to capture short-term cross-request reuse while avoiding redundant reloads. We implement RelayGR on Huawei Ascend NPUs and evaluate it with real queries. Under a fixed P99 SLO, RelayGR supports up to 1.5$\\times$ longer sequences and improves SLO-compliant throughput by up to 3.6$\\times$.", "AI": {"tldr": "RelayGR是一个生产系统，它通过跨阶段接力赛推理实现对长序列生成推荐模型的支持。", "motivation": "实时推荐系统在严格的尾部延迟SLO下执行多级流程（检索、预处理和精细化排名），这使得只有几十毫秒的时间用于排序。生成推荐模型可以利用长用户行为序列来提高质量，但在生产环境中由于排名阶段P99预算的限制，其在线序列长度受到严格控制。", "method": "RelayGR结合了三种技术：1）基于序列感知触发器的缓存，2）亲和力感知路由器，3）内存感知扩展器。这些技术使得系统可以在不增加远程检索的情况下，在请求生命周期中保持长用户行为前缀的KV缓存在HBM。", "result": "在固定的P99 SLO下，RelayGR支持比传统模型长1.5倍的序列，并提高了SLO合规吞吐量3.6倍。", "conclusion": "通过跨阶段接力赛推理，RelayGR有效解决了生成推荐系统在线序列长度受限的问题，显著提升了性能和用户体验。"}}
{"id": "2601.01710", "pdf": "https://arxiv.org/pdf/2601.01710", "abs": "https://arxiv.org/abs/2601.01710", "authors": ["Kevin Pfisterer", "Quentin Hillebrand", "Vorapong Suppakitpaisarn"], "title": "Publishing Below-Threshold Triangle Counts under Local Weight Differential Privacy", "categories": ["cs.DS"], "comment": null, "summary": "We propose an algorithm for counting below-threshold triangles in weighted graphs under local weight differential privacy. While prior work focused on unweighted graphs, many real-world networks naturally include edge weights. We study the setting where the graph topology is public known and the privacy of the influence of an individual on the edge weights is protected. This captures realistic scenarios such as road networks and telecommunication networks. Our approach consists of two rounds of communication. In the first round, each node publishes their incident weight information under local weight differential privacy while in the second round, the nodes locally count below-threshold triangles, for which we introduce a biased and unbiased variant. We further propose two different improvements. We present a pre-computation step that reduces the covariance and thereby lowers the expected error. Secondly, we develop an algorithm for computing the smooth-sensitivity, which significantly reduces the running time compared to a straightforward approach. Finally, we provide experimental results that demonstrate the differences between the biased and unbiased variants and the effectiveness of the proposed improvements.", "AI": {"tldr": "提出了一种在局部权重差分隐私下计算阈值以下三角形数量的算法。", "motivation": "以往的研究主要集中在无权图上，然而许多现实世界中的网络自然包含边权重。本文研究了在网络拓扑已知而个体对边权重的影响受到保护的情况下，如何进行数据处理。", "method": "首先每个节点在局部权重差分隐私下公布其关联的权重信息；然后节点本地计算阈值以下三角形的数量，并引入有偏和无偏两种变体。此外提出了一步预计算步骤来减少协方差并降低预期误差，以及一种用于计算平滑敏感度以显著缩短运行时间的方法。", "result": "实验结果显示了有偏与无偏变体之间的差异，并证明了所提改进措施的有效性。", "conclusion": "本文提出了一种新颖的算法来解决在局部权重差分隐私下计算阈值以下三角形数量的问题，适用于包含边权重的真实网络环境。"}}
{"id": "2601.01705", "pdf": "https://arxiv.org/pdf/2601.01705", "abs": "https://arxiv.org/abs/2601.01705", "authors": ["Kenneth Kwok", "Basura Fernando", "Qianli Xu", "Vigneshwaran Subbaraju", "Dongkyu Choi", "Boon Kiat Quek"], "title": "Explicit World Models for Reliable Human-Robot Collaboration", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted to AAAI-26 Bridge Program B10: Making Embodied AI Reliable with Testing and Formal Verification", "summary": "This paper addresses the topic of robustness under sensing noise, ambiguous instructions, and human-robot interaction. We take a radically different tack to the issue of reliable embodied AI: instead of focusing on formal verification methods aimed at achieving model predictability and robustness, we emphasise the dynamic, ambiguous and subjective nature of human-robot interactions that requires embodied AI systems to perceive, interpret, and respond to human intentions in a manner that is consistent, comprehensible and aligned with human expectations. We argue that when embodied agents operate in human environments that are inherently social, multimodal, and fluid, reliability is contextually determined and only has meaning in relation to the goals and expectations of humans involved in the interaction. This calls for a fundamentally different approach to achieving reliable embodied AI that is centred on building and updating an accessible \"explicit world model\" representing the common ground between human and AI, that is used to align robot behaviours with human expectations.", "AI": {"tldr": "构建用于人机协作的显式世界模型，以提高可靠性", "motivation": "解决感知噪声、指令歧义和人机交互中的可靠性问题", "method": "通过建立并更新一个代表人类与AI之间共同点的‘明确的世界模型’来实现可靠的人工智能系统", "result": "提升了机器人行为与人类期望的一致性和可理解性，使人机协作更加可靠", "conclusion": "提出了一种新的方法论，强调了在人机交互中构建和更新显式世界模型的重要性"}}
{"id": "2601.01703", "pdf": "https://arxiv.org/pdf/2601.01703", "abs": "https://arxiv.org/abs/2601.01703", "authors": ["Qing Sima", "Xiaoyang Wang", "Wenjie Zhang"], "title": "Beyond Homophily: Community Search on Heterophilic Graphs", "categories": ["cs.SI", "cs.AI", "cs.DB", "cs.IR"], "comment": null, "summary": "Community search aims to identify a refined set of nodes that are most relevant to a given query, supporting tasks ranging from fraud detection to recommendation. Unlike homophilic graphs, many real-world networks are heterophilic, where edges predominantly connect dissimilar nodes. Therefore, structural signals that once reflected smooth, low-frequency similarity now appear as sharp, high-frequency contrasts. However, both classical algorithms (e.g., k-core, k-truss) and recent ML-based models struggle to achieve effective community search on heterophilic graphs, where edge signs or semantics are generally unknown. Algorithm-based methods often return communities with mixed class labels, while GNNs, built on homophily, smooth away meaningful signals and blur community boundaries. Therefore, we propose Adaptive Community Search (AdaptCS), a unified framework featuring three key designs: (i) an AdaptCS Encoder that disentangles multi-hop and multi-frequency signals, enabling the model to capture both smooth (homophilic) and contrastive (heterophilic) relations; (ii) a memory-efficient low-rank optimization that removes the main computational bottleneck and ensures model scalability; and (iii) an Adaptive Community Score (ACS) that guides online search by balancing embedding similarity and topological relations. Extensive experiments on both heterophilic and homophilic benchmarks demonstrate that AdaptCS outperforms the best-performing baseline by an average of 11% in F1-score, retains robustness across heterophily levels, and achieves up to 2 orders of magnitude speedup.", "AI": {"tldr": "本文提出了一种在异质图上进行社区搜索的统一框架AdaptCS，该框架能够在混合类标签的情况下捕捉到有意义的关系信号。", "motivation": "许多现实世界的网络是异质性的，传统的算法和基于机器学习的方法在这种网络中难以有效执行社区搜索任务。因此需要新的方法来解决这个问题。", "method": "提出了一个名为AdaptCS的统一框架，该框架包含三个关键设计：（i）能够解耦多跳和多频率信号的AdaptCS编码器；（ii）一种内存高效的低秩优化算法以去除计算瓶颈并确保模型可扩展性；以及（iii）用于引导在线搜索的自适应社区评分ACS。", "result": "实验结果表明，与最佳基线相比，AdaptCS在F1分数方面平均高出11%，并在异质性和同质性的基准数据集上都表现出稳健性能。同时该框架能实现高达两个数量级的速度提升。", "conclusion": "本文提出的AdaptCS框架能够有效地解决在异质图上的社区搜索问题，并且具有较好的速度和精度优势。"}}
{"id": "2601.01701", "pdf": "https://arxiv.org/pdf/2601.01701", "abs": "https://arxiv.org/abs/2601.01701", "authors": ["Mohammed Ayalew Belay", "Adil Rasheed", "Pierluigi Salvo Rossi"], "title": "Digital Twin-Driven Communication-Efficient Federated Anomaly Detection for Industrial IoT", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Anomaly detection is increasingly becoming crucial for maintaining the safety, reliability, and efficiency of industrial systems. Recently, with the advent of digital twins and data-driven decision-making, several statistical and machine-learning methods have been proposed. However, these methods face several challenges, such as dependence on only real sensor datasets, limited labeled data, high false alarm rates, and privacy concerns. To address these problems, we propose a suite of digital twin-integrated federated learning (DTFL) methods that enhance global model performance while preserving data privacy and communication efficiency. Specifically, we present five novel approaches: Digital Twin-Based Meta-Learning (DTML), Federated Parameter Fusion (FPF), Layer-wise Parameter Exchange (LPE), Cyclic Weight Adaptation (CWA), and Digital Twin Knowledge Distillation (DTKD). Each method introduces a unique mechanism to combine synthetic and real-world knowledge, balancing generalization with communication overhead. We conduct an extensive experiment using a publicly available cyber-physical anomaly detection dataset. For a target accuracy of 80%, CWA reaches the target in 33 rounds, FPF in 41 rounds, LPE in 48 rounds, and DTML in 87 rounds, whereas the standard FedAvg baseline and DTKD do not reach the target within 100 rounds. These results highlight substantial communication-efficiency gains (up to 62% fewer rounds than DTML and 31% fewer than LPE) and demonstrate that integrating DT knowledge into FL accelerates convergence to operationally meaningful accuracy thresholds for IIoT anomaly detection.", "AI": {"tldr": "本文提出了一种基于数字孪生的联邦学习方法，用于提升工业物联网中的异常检测性能。", "motivation": "传统的统计和机器学习方法在处理工业系统的安全、可靠性和效率时面临着依赖现实传感器数据、标签不足、误报率高及隐私问题等挑战。为了应对这些问题，作者提出了一套结合数字孪生的联邦学习方案以增强全局模型性能并保证数据隐私和通信效率。", "method": "文中提出了五种方法：基于元学习（DTML）、参数融合（FPF）、逐层参数交换（LPE）、循环权重调整（CWA）以及知识蒸馏（DTKD）。这些方法通过不同机制结合了合成与现实世界的知识，平衡了一般化与通信开销。", "result": "实验显示，在目标准确率为80%的情况下，CWA在33轮内达成目标，FPF在41轮，LPE在48轮，DTML在87轮。标准FedAvg基线和DTKD则未达到该精度阈值。这些结果表明了显著的通信效率提升，并展示了集成数字孪生知识到联邦学习中能加速收敛至操作上具有意义的准确性。", "conclusion": "通过引入基于数字孪生的知识，文中提出的联邦学习方法有效提升了工业物联网环境中异常检测模型的学习速度与效率，同时保证了数据隐私和通信效率。"}}
{"id": "2601.01696", "pdf": "https://arxiv.org/pdf/2601.01696", "abs": "https://arxiv.org/abs/2601.01696", "authors": ["Yian Liu", "Xiong Wang", "Ping Xu", "Lei Zhu", "Ming Yan", "Linyun Xue"], "title": "Real-Time Lane Detection via Efficient Feature Alignment and Covariance Optimization for Low-Power Embedded Systems", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Real-time lane detection in embedded systems encounters significant challenges due to subtle and sparse visual signals in RGB images, often constrained by limited computational resources and power consumption. Although deep learning models for lane detection categorized into segmentation-based, anchor-based, and curve-based methods there remains a scarcity of universally applicable optimization techniques tailored for low-power embedded environments. To overcome this, we propose an innovative Covariance Distribution Optimization (CDO) module specifically designed for efficient, real-time applications. The CDO module aligns lane feature distributions closely with ground-truth labels, significantly enhancing detection accuracy without increasing computational complexity. Evaluations were conducted on six diverse models across all three method categories, including two optimized for real-time applications and four state-of-the-art (SOTA) models, tested comprehensively on three major datasets: CULane, TuSimple, and LLAMAS. Experimental results demonstrate accuracy improvements ranging from 0.01% to 1.5%. The proposed CDO module is characterized by ease of integration into existing systems without structural modifications and utilizes existing model parameters to facilitate ongoing training, thus offering substantial benefits in performance, power efficiency, and operational flexibility in embedded systems.", "AI": {"tldr": "提出了一种用于低功耗嵌入式系统中实时车道检测的Covariance Distribution Optimization (CDO) 模块，以提升现有模型在RGB图像中的检测准确性。", "motivation": "为了应对在受限计算资源和能耗条件下实时车道检测面临的挑战，并解决深度学习模型在低功率嵌入式环境下的优化技术稀缺问题，提出了一种新的CDO模块来提高检测精度。", "method": "通过设计一种新颖的Covariance Distribution Optimization (CDO) 模块以增强现有模型对车道特征分布的准确拟合能力。该方法包括将lane feature distributions与ground-truth label紧密对齐，同时保持计算复杂度不变。", "result": "实验在六种不同类型模型上进行，并针对三个主要数据集（CULane, TuSimple和LLAMAS）进行了全面测试，结果显示检测精度提高了0.01%至1.5%不等。CDO模块易于集成到现有系统中，同时还能利用现有参数继续训练。", "conclusion": "所提出的CDO模块为低功耗嵌入式系统中的实时车道检测提供了显著的性能、功耗效率和操作灵活性提升，能够广泛应用于各种场景中。"}}
{"id": "2601.01695", "pdf": "https://arxiv.org/pdf/2601.01695", "abs": "https://arxiv.org/abs/2601.01695", "authors": ["Ruiyu Mao", "Baoming Zhang", "Nicholas Ruozzi", "Yunhui Guo"], "title": "Learnability-Driven Submodular Optimization for Active Roadside 3D Detection", "categories": ["cs.CV"], "comment": "10 pages, 7 figures. Submitted to CVPR 2026", "summary": "Roadside perception datasets are typically constructed via cooperative labeling between synchronized vehicle and roadside frame pairs. However, real deployment often requires annotation of roadside-only data due to hardware and privacy constraints. Even human experts struggle to produce accurate labels without vehicle-side data (image, LIDAR), which not only increases annotation difficulty and cost, but also reveals a fundamental learnability problem: many roadside-only scenes contain distant, blurred, or occluded objects whose 3D properties are ambiguous from a single view and can only be reliably annotated by cross-checking paired vehicle--roadside frames. We refer to such cases as inherently ambiguous samples. To reduce wasted annotation effort on inherently ambiguous samples while still obtaining high-performing models, we turn to active learning. This work focuses on active learning for roadside monocular 3D object detection and proposes a learnability-driven framework that selects scenes which are both informative and reliably labelable, suppressing inherently ambiguous samples while ensuring coverage. Experiments demonstrate that our method, LH3D, achieves 86.06%, 67.32%, and 78.67% of full-performance for vehicles, pedestrians, and cyclists respectively, using only 25% of the annotation budget on DAIR-V2X-I, significantly outperforming uncertainty-based baselines. This confirms that learnability, not uncertainty, matters for roadside 3D perception.", "AI": {"tldr": "提出了一种基于学习能力的主动选择框架，用于路边单目三维物体检测，以减少标注模糊样本的努力并提高模型性能。", "motivation": "解决在只有一边数据的情况下进行准确注释的难题，并通过抑制模糊样本来优化标签生成流程。", "method": "设计了一种名为LH3D的方法，该方法结合学习能力驱动的选择策略和主动学习，旨在选择既具信息量又可可靠标注的场景。", "result": "实验显示，使用LH3D方法，在仅25%的注释预算下分别实现了车辆、行人及骑行者的86.06%，67.32%和78.67%的全性能表现，显著超越了不确定性基准。", "conclusion": "证明在路边三维感知中，学习能力比不确定度更重要，以减少标注模糊样本并提高模型性能。"}}
{"id": "2601.01689", "pdf": "https://arxiv.org/pdf/2601.01689", "abs": "https://arxiv.org/abs/2601.01689", "authors": ["Afzal Hossain", "Stephanie Schuckers"], "title": "Mitigating Longitudinal Performance Degradation in Child Face Recognition Using Synthetic Data", "categories": ["cs.CV"], "comment": null, "summary": "Longitudinal face recognition in children remains challenging due to rapid and nonlinear facial growth, which causes template drift and increasing verification errors over time. This work investigates whether synthetic face data can act as a longitudinal stabilizer by improving temporal robustness of child face recognition models. Using an identity disjoint protocol on the Young Face Aging (YFA) dataset, we evaluate three settings: (i) pretrained MagFace embeddings without dataset specific fine-tuning, (ii) MagFace fine-tuned using authentic training faces only, and (iii) MagFace fine-tuned using a combination of authentic and synthetically generated training faces. Synthetic data is generated using StyleGAN2 ADA and incorporated exclusively within the training identities; a post generation filtering step is applied to mitigate identity leakage and remove artifact affected samples. Experimental results across enrollment verification gaps from 6 to 36 months show that synthetic-augmented fine tuning substantially reduces error rates relative to both the pretrained baseline and real only fine tuning. These findings provide a risk aware assessment of synthetic augmentation for improving identity persistence in pediatric face recognition.", "AI": {"tldr": "本论文研究使用合成数据改善儿童面部识别模型的长期性能问题。", "motivation": "由于儿童面部快速且非线性的变化导致模板漂移和随着时间推移增加的身份验证错误，使得纵向儿童面部识别具有挑战性。本文探讨了合成面部数据能否作为纵向稳定器来提高儿童面部识别模型的时间鲁棒性。", "method": "通过Young Face Aging(YFA)数据集上的身份分离协议评估三个设置：(i)未经特定于数据集的微调的预训练MagFace嵌入，(ii)仅使用真实训练面孔进行微调的MagFace，以及(iii)使用真实和合成生成的训练面孔组合进行微调的MagFace。采用StyleGAN2 ADA生成合成数据，并仅在训练身份中应用；在生成后实施过滤步骤以缓解身份泄漏并移除受伪影影响的样本。", "result": "实验结果显示，在6到36个月的登记验证间隔内，使用合成增强微调显著降低了错误率，相对未预训练基线和仅真实数据微调而言有明显改善。", "conclusion": "研究结果提供了一种风险感知评估方法，表明合成增广可以提高儿童面部识别中的身份持久性。"}}
{"id": "2601.01687", "pdf": "https://arxiv.org/pdf/2601.01687", "abs": "https://arxiv.org/abs/2601.01687", "authors": ["Abdur R. Fayjie", "Pankhi Kashyap", "Jutika Borah", "Patrick Vandewalle"], "title": "FALCON: Few-Shot Adversarial Learning for Cross-Domain Medical Image Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "20 pages, 6 figures, 7 tables", "summary": "Precise delineation of anatomical and pathological structures within 3D medical volumes is crucial for accurate diagnosis, effective surgical planning, and longitudinal disease monitoring. Despite advancements in AI, clinically viable segmentation is often hindered by the scarcity of 3D annotations, patient-specific variability, data privacy concerns, and substantial computational overhead. In this work, we propose FALCON, a cross-domain few-shot segmentation framework that achieves high-precision 3D volume segmentation by processing data as 2D slices. The framework is first meta-trained on natural images to learn-to-learn generalizable segmentation priors, then transferred to the medical domain via adversarial fine-tuning and boundary-aware learning. Task-aware inference, conditioned on support cues, allows FALCON to adapt dynamically to patient-specific anatomical variations across slices. Experiments on four benchmarks demonstrate that FALCON consistently achieves the lowest Hausdorff Distance scores, indicating superior boundary accuracy while maintaining a Dice Similarity Coefficient comparable to the state-of-the-art models. Notably, these results are achieved with significantly less labeled data, no data augmentation, and substantially lower computational overhead.", "AI": {"tldr": "提出了一种名为FALCON的框架，用于解决跨域医学图像分割问题。", "motivation": "旨在克服由于标注数据少、患者个体差异大以及隐私保护和计算成本高等因素导致的精确三维医学影像分割困难的问题。", "method": "通过2D切片处理数据，首先在自然图像上进行元学习以获取可迁移的分割先验知识，并利用对抗性微调和边界感知学习将其转移到医疗领域。任务自适应推理使FALCON能够动态调整以应对患者特定的解剖变异。", "result": "实验结果表明，在四个基准数据集上的表现均优于现有最佳模型，且所需标注样本数量更少、没有使用数据增强技术并且计算开销更低。", "conclusion": "FALCON通过较少的数据和较低的计算成本实现了高精度的3D体积分割，并在边界准确性方面取得了卓越的成绩。"}}
{"id": "2601.01685", "pdf": "https://arxiv.org/pdf/2601.01685", "abs": "https://arxiv.org/abs/2601.01685", "authors": ["Jinwei Hu", "Xinmiao Huang", "Youcheng Sun", "Yi Dong", "Xiaowei Huang"], "title": "Lying with Truths: Open-Channel Multi-Agent Collusion for Belief Manipulation via Generative Montage", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": "Under Review", "summary": "As large language models (LLMs) transition to autonomous agents synthesizing real-time information, their reasoning capabilities introduce an unexpected attack surface. This paper introduces a novel threat where colluding agents steer victim beliefs using only truthful evidence fragments distributed through public channels, without relying on covert communications, backdoors, or falsified documents. By exploiting LLMs' overthinking tendency, we formalize the first cognitive collusion attack and propose Generative Montage: a Writer-Editor-Director framework that constructs deceptive narratives through adversarial debate and coordinated posting of evidence fragments, causing victims to internalize and propagate fabricated conclusions. To study this risk, we develop CoPHEME, a dataset derived from real-world rumor events, and simulate attacks across diverse LLM families. Our results show pervasive vulnerability across 14 LLM families: attack success rates reach 74.4% for proprietary models and 70.6% for open-weights models. Counterintuitively, stronger reasoning capabilities increase susceptibility, with reasoning-specialized models showing higher attack success than base models or prompts. Furthermore, these false beliefs then cascade to downstream judges, achieving over 60% deception rates, highlighting a socio-technical vulnerability in how LLM-based agents interact with dynamic information environments. Our implementation and data are available at: https://github.com/CharlesJW222/Lying_with_Truth/tree/main.", "AI": {"tldr": "本文介绍了一种利用大型语言模型自主生成实时信息的能力进行认知合谋攻击的新威胁，通过构建看似真实的叙述误导受害者。", "motivation": "随着大型语言模型能力的提升和应用范围的扩大，它们在公开渠道中传播真实证据片段来引导受害者的信念成为了潜在的安全风险。这种攻击不需要秘密沟通、后门或伪造文件，并且利用了LLMs过度思考的倾向。", "method": "提出了一种名为生成蒙太奇（Generative Montage）的方法，该方法通过作家-编辑-导演框架，利用对抗性辩论和协调发布证据片段来构建误导性叙述。研究团队开发了一个基于真实谣言事件的数据集CoPHEME，并模拟了14个大型语言模型家族的攻击。", "result": "实验结果显示，在14种不同的LLM家族中，这种认知合谋攻击的成功率高达74.4%（专有模型）和70.6%（开源权重模型）。此外，更强的推理能力反而增加了易受攻击性。虚假信念还蔓延到下游判断者，达到了超过60%的欺骗成功率。", "conclusion": "研究表明大型语言模型在与动态信息环境互动中存在社会技术脆弱性，并且这种通过公开渠道传播真实证据片段来进行的认知合谋攻击是广泛存在的威胁。"}}
{"id": "2601.01680", "pdf": "https://arxiv.org/pdf/2601.01680", "abs": "https://arxiv.org/abs/2601.01680", "authors": ["Afzal Hossain", "Mst Rumana Sumi", "Stephanie Schuckers"], "title": "Evaluating Deep Learning-Based Face Recognition for Infants and Toddlers: Impact of Age Across Developmental Stages", "categories": ["cs.CV"], "comment": "Accepted and presented at IEEE IJCB 2025 conference; final published version forthcoming", "summary": "Face recognition for infants and toddlers presents unique challenges due to rapid facial morphology changes, high inter-class similarity, and limited dataset availability. This study evaluates the performance of four deep learning-based face recognition models FaceNet, ArcFace, MagFace, and CosFace on a newly developed longitudinal dataset collected over a 24 month period in seven sessions involving children aged 0 to 3 years. Our analysis examines recognition accuracy across developmental stages, showing that the True Accept Rate (TAR) is only 30.7% at 0.1% False Accept Rate (FAR) for infants aged 0 to 6 months, due to unstable facial features. Performance improves significantly in older children, reaching 64.7% TAR at 0.1% FAR in the 2.5 to 3 year age group. We also evaluate verification performance over different time intervals, revealing that shorter time gaps result in higher accuracy due to reduced embedding drift. To mitigate this drift, we apply a Domain Adversarial Neural Network (DANN) approach that improves TAR by over 12%, yielding features that are more temporally stable and generalizable. These findings are critical for building biometric systems that function reliably over time in smart city applications such as public healthcare, child safety, and digital identity services. The challenges observed in early age groups highlight the importance of future research on privacy preserving biometric authentication systems that can address temporal variability, particularly in secure and regulated urban environments where child verification is essential.", "AI": {"tldr": "评估基于深度学习的婴幼儿面部识别技术，研究不同发展阶段的表现差异。", "motivation": "由于婴儿和幼儿脸部形态变化快、类别间相似度高及数据集有限等问题，现有面部识别技术在这一群体中的应用存在挑战。此研究旨在探究跨发展时期的面部识别性能，并提出解决方案以提高其准确性与稳定性。", "method": "通过使用FaceNet, ArcFace, MagFace和CosFace四种基于深度学习的面部识别模型，在一个包含0至3岁儿童长达两年数据集上进行测试，评估不同年龄段的真实接受率。此外还应用了领域对抗神经网络（DANN）来减少特征漂移。", "result": "结果显示婴儿期真实接受率为30.7%，而在2.5至3岁时则提高到64.7%；短时间间隔内的验证准确性更高，表明随着时间推移嵌入式表示会发生变化。采用DANN后，TAR提高了超过12%。", "conclusion": "研究结果强调了未来隐私保护生物识别认证系统的重要性，特别是在需要解决年龄相关可变性问题的受控城市环境中，如智能城市的公共健康、儿童安全等领域。"}}
{"id": "2601.01677", "pdf": "https://arxiv.org/pdf/2601.01677", "abs": "https://arxiv.org/abs/2601.01677", "authors": ["Zhengsen Xu", "Lanying Wang", "Sibo Cheng", "Xue Rui", "Kyle Gao", "Yimin Zhu", "Mabel Heffring", "Zack Dewis", "Saeid Taleghanidoozdoozan", "Megan Greenwood", "Motasem Alkayid", "Quinn Ledingham", "Hongjie He", "Jonathan Li", "Lincoln Linlin Xu"], "title": "Trustworthy Data-Driven Wildfire Risk Prediction and Understanding in Western Canada", "categories": ["cs.CV"], "comment": null, "summary": "In recent decades, the intensification of wildfire activity in western Canada has resulted in substantial socio-economic and environmental losses. Accurate wildfire risk prediction is hindered by the intrinsic stochasticity of ignition and spread and by nonlinear interactions among fuel conditions, meteorology, climate variability, topography, and human activities, challenging the reliability and interpretability of purely data-driven models. We propose a trustworthy data-driven wildfire risk prediction framework based on long-sequence, multi-scale temporal modeling, which integrates heterogeneous drivers while explicitly quantifying predictive uncertainty and enabling process-level interpretation. Evaluated over western Canada during the record-breaking 2023 and 2024 fire seasons, the proposed model outperforms existing time-series approaches, achieving an F1 score of 0.90 and a PR-AUC of 0.98 with low computational cost. Uncertainty-aware analysis reveals structured spatial and seasonal patterns in predictive confidence, highlighting increased uncertainty associated with ambiguous predictions and spatiotemporal decision boundaries. SHAP-based interpretation provides mechanistic understanding of wildfire controls, showing that temperature-related drivers dominate wildfire risk in both years, while moisture-related constraints play a stronger role in shaping spatial and land-cover-specific contrasts in 2024 compared to the widespread hot and dry conditions of 2023. Data and code are available at https://github.com/SynUW/mmFire.", "AI": {"tldr": "提出了一种基于长期序列、多尺度时间建模的信任数据驱动的加拿大西部野火风险预测框架。", "motivation": "近年来，由于点火和扩散的内在随机性和燃料状况、气象、气候变异、地形和人类活动之间的非线性相互作用，加拿大的野火活动加剧了社会经济和环境损失，并且纯数据驱动模型在可靠性和可解释性方面面临挑战。", "method": "提出了一个基于长期序列、多尺度时间建模的预测框架，该框架集成了异构驱动因素并明确量化了预测不确定性，从而提供了过程级别的解释能力。", "result": "评估表明，在2023年和2024年的火灾季节中，所提出模型的表现优于现有的时间序列方法，实现了F1得分为0.90和PR-AUC为0.98的性能，并且具有较低的计算成本。", "conclusion": "研究揭示了预测信心的空间和季节性模式，并通过SHAP解释提供了对野火控制机制的理解。"}}
{"id": "2601.01676", "pdf": "https://arxiv.org/pdf/2601.01676", "abs": "https://arxiv.org/abs/2601.01676", "authors": ["Jin Yao", "Radowan Mahmud Redoy", "Sebastian Elbaum", "Matthew B. Dwyer", "Zezhou Cheng"], "title": "LabelAny3D: Label Any Object 3D in the Wild", "categories": ["cs.CV"], "comment": "NeurIPS 2025. Project page: https://uva-computer-vision-lab.github.io/LabelAny3D/", "summary": "Detecting objects in 3D space from monocular input is crucial for applications ranging from robotics to scene understanding. Despite advanced performance in the indoor and autonomous driving domains, existing monocular 3D detection models struggle with in-the-wild images due to the lack of 3D in-the-wild datasets and the challenges of 3D annotation. We introduce LabelAny3D, an \\emph{analysis-by-synthesis} framework that reconstructs holistic 3D scenes from 2D images to efficiently produce high-quality 3D bounding box annotations. Built on this pipeline, we present COCO3D, a new benchmark for open-vocabulary monocular 3D detection, derived from the MS-COCO dataset and covering a wide range of object categories absent from existing 3D datasets. Experiments show that annotations generated by LabelAny3D improve monocular 3D detection performance across multiple benchmarks, outperforming prior auto-labeling approaches in quality. These results demonstrate the promise of foundation-model-driven annotation for scaling up 3D recognition in realistic, open-world settings.", "AI": {"tldr": "本文介绍了LabelAny3D，一个用于从二维图像中重建三维场景并生成高质量的三维边界框注释的分析合成框架。", "motivation": "现有的单目3D检测模型在野外图像上表现不佳，原因在于缺乏3D野外数据集以及难以进行3D标注。为了克服这些挑战，引入了LabelAny3D。", "method": "LabelAny3D通过重建三维场景来生成高质量的2D到3D边界框注释，并基于此框架推出了COCO3D，一个新的用于开放词汇单目3D检测的基准数据集。", "result": "实验结果显示，由LabelAny3D生成的标注提高了多个基准测试中的单目3D检测性能，超过了先前的自动标注方法在质量上的表现。", "conclusion": "这些结果证明了基础模型驱动注释对于在现实世界的开放环境中扩展3D识别的潜力。"}}
{"id": "2601.01675", "pdf": "https://arxiv.org/pdf/2601.01675", "abs": "https://arxiv.org/abs/2601.01675", "authors": ["Snehal s. Dikhale", "Karankumar Patel", "Daksh Dhingra", "Itoshi Naramura", "Akinobu Hayashi", "Soshi Iba", "Nawid Jamali"], "title": "VisuoTactile 6D Pose Estimation of an In-Hand Object using Vision and Tactile Sensor Data", "categories": ["cs.RO"], "comment": "Accepted for publication in IEEE Robotics and Automation Letters (RA-L), January 2022. Presented at ICRA 2022. This is the author's version of the manuscript", "summary": "Knowledge of the 6D pose of an object can benefit in-hand object manipulation. In-hand 6D object pose estimation is challenging because of heavy occlusion produced by the robot's grippers, which can have an adverse effect on methods that rely on vision data only. Many robots are equipped with tactile sensors at their fingertips that could be used to complement vision data. In this paper, we present a method that uses both tactile and vision data to estimate the pose of an object grasped in a robot's hand. To address challenges like lack of standard representation for tactile data and sensor fusion, we propose the use of point clouds to represent object surfaces in contact with the tactile sensor and present a network architecture based on pixel-wise dense fusion. We also extend NVIDIA's Deep Learning Dataset Synthesizer to produce synthetic photo-realistic vision data and corresponding tactile point clouds. Results suggest that using tactile data in addition to vision data improves the 6D pose estimate, and our network generalizes successfully from synthetic training to real physical robots.", "AI": {"tldr": "本文提出了一种结合视觉和触觉数据估计手中物体6D姿态的方法。", "motivation": "由于机器人夹爪造成的严重遮挡，仅依赖视觉数据的在手6D物体姿态估计具有挑战性。利用指尖配备的触觉传感器可以补充视觉数据，提高精度。", "method": "本文提出使用点云表示接触表面，并基于像素级密集融合提出了网络架构。同时扩展了NVIDIA的深度学习数据合成器以生成合成的数据集。", "result": "研究结果表明，结合触觉和视觉数据能改善6D姿态估计效果，且模型在从合成训练到真实机器人上的泛化性能良好。", "conclusion": "通过将触觉传感器与视觉信息相结合，可以有效提高物体在手中的6D姿态估计精度。"}}
{"id": "2601.01673", "pdf": "https://arxiv.org/pdf/2601.01673", "abs": "https://arxiv.org/abs/2601.01673", "authors": ["Arina Kharlamova", "Youcheng Sun", "Ting Yu"], "title": "Exposing Hidden Interfaces: LLM-Guided Type Inference for Reverse Engineering macOS Private Frameworks", "categories": ["cs.CR", "cs.AI"], "comment": "IEEE S&P'26 under review", "summary": "Private macOS frameworks underpin critical services and daemons but remain undocumented and distributed only as stripped binaries, complicating security analysis. We present MOTIF, an agentic framework that integrates tool-augmented analysis with a finetuned large language model specialized for Objective-C type inference. The agent manages runtime metadata extraction, binary inspection, and constraint checking, while the model generates candidate method signatures that are validated and refined into compilable headers. On MOTIF-Bench, a benchmark built from public frameworks with groundtruth headers, MOTIF improves signature recovery from 15% to 86% compared to baseline static analysis tooling, with consistent gains in tool-use correctness and inference stability. Case studies on private frameworks show that reconstructed headers compile, link, and facilitate downstream security research and vulnerability studies. By transforming opaque binaries into analyzable interfaces, MOTIF establishes a scalable foundation for systematic auditing of macOS internals.", "AI": {"tldr": "提出了一种名为MOTIF的框架，用于逆向工程macOS私有框架的方法。", "motivation": "未文档化的macOS私有框架支撑着关键服务和守护进程，但仅以剥离的二进制文件形式分发，这使得安全分析变得复杂。因此，研究团队设计了MOTIF来解决这个问题。", "method": "MOTIF整合了工具增强分析与专门为Objective-C类型推断微调的大规模语言模型。代理管理运行时元数据提取、二进制检查和约束检验；而模型生成候选方法签名，并通过验证和精炼转化为可编译的头文件。", "result": "在基准测试中，MOTIF相比基础静态分析工具将签名恢复率从15%提高到了86%，并在工具使用正确性和推断稳定性方面保持了持续改进。此外，在私有框架上的案例研究显示，重建的头文件可以编译、链接，并促进下游安全研究和漏洞研究。", "conclusion": "通过将不透明二进制转换为可分析接口，MOTIF建立了一个系统性审计macOS内部结构的可扩展基础。"}}
{"id": "2601.01668", "pdf": "https://arxiv.org/pdf/2601.01668", "abs": "https://arxiv.org/abs/2601.01668", "authors": ["Houman Kazemzadeh", "Nima Minaifar", "Kamyar Naderi", "Sho Tabibzadeh"], "title": "EHRSummarizer: A Privacy-Aware, FHIR-Native Architecture for Structured Clinical Summarization of Electronic Health Records", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages", "summary": "Clinicians routinely navigate fragmented electronic health record (EHR) interfaces to assemble a coherent picture of a patient's problems, medications, recent encounters, and longitudinal trends. This work describes EHRSummarizer, a privacy-aware, FHIR-native reference architecture that retrieves a targeted set of high-yield FHIR R4 resources, normalizes them into a consistent clinical context package, and produces structured summaries intended to support structured chart review. The system can be configured for data minimization, stateless processing, and flexible deployment, including local inference within an organization's trust boundary. To mitigate the risk of unsupported or unsafe behavior, the summarization stage is constrained to evidence present in the retrieved context package, is intended to indicate missing or unavailable domains where feasible, and avoids diagnostic or treatment recommendations. Prototype demonstrations on synthetic and test FHIR environments illustrate end-to-end behavior and output formats; however, this manuscript does not report clinical outcomes or controlled workflow studies. We outline an evaluation plan centered on faithfulness, omission risk, temporal correctness, usability, and operational monitoring to guide future institutional assessments.", "AI": {"tldr": "EHRSummarizer是一种隐私保护，基于FHIR的架构，用于电子健康记录的结构化临床摘要。", "motivation": "为了帮助医务人员从碎片化的电子病历界面中提取关键信息，形成一个连贯的患者视图，并支持结构化的病历审查。该系统设计为可以配置数据最小化、无状态处理和灵活部署。", "method": "EHRSummarizer通过检索一组高产FHIR R4资源，将其规范化为一致的临床上下文包，生成结构化摘要来支持结构化病例回顾。此过程避免了诊断或治疗建议，并能指示缺失或不可用的数据域。", "result": "原型在合成和测试环境中展示了端到端的行为和输出格式；但未报告具体的临床结果或控制工作流程研究。", "conclusion": "该论文概述了一个评估计划，聚焦于忠实度、遗漏风险、时间正确性、可用性和操作监控等方面，以指导未来机构的评估。"}}
{"id": "2601.01665", "pdf": "https://arxiv.org/pdf/2601.01665", "abs": "https://arxiv.org/abs/2601.01665", "authors": ["Wei Liu", "Yaoxin Wu", "Yingqian Zhang", "Thomas Bäck", "Yingjie Fan"], "title": "Adversarial Instance Generation and Robust Training for Neural Combinatorial Optimization with Multiple Objectives", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep reinforcement learning (DRL) has shown great promise in addressing multi-objective combinatorial optimization problems (MOCOPs). Nevertheless, the robustness of these learning-based solvers has remained insufficiently explored, especially across diverse and complex problem distributions. In this paper, we propose a unified robustness-oriented framework for preference-conditioned DRL solvers for MOCOPs. Within this framework, we develop a preference-based adversarial attack to generate hard instances that expose solver weaknesses, and quantify the attack impact by the resulting degradation on Pareto-front quality. We further introduce a defense strategy that integrates hardness-aware preference selection into adversarial training to reduce overfitting to restricted preference regions and improve out-of-distribution performance. The experimental results on multi-objective traveling salesman problem (MOTSP), multi-objective capacitated vehicle routing problem (MOCVRP), and multi-objective knapsack problem (MOKP) verify that our attack method successfully learns hard instances for different solvers. Furthermore, our defense method significantly strengthens the robustness and generalizability of neural solvers, delivering superior performance on hard or out-of-distribution instances.", "AI": {"tldr": "该论文提出了一个面向偏好的强化学习求解器的鲁棒性框架，用于解决多目标组合优化问题。", "motivation": "目前基于学习的方法在应对多样且复杂的多目标组合优化问题时缺乏足够的稳健性。为了解决这个问题，论文提出了一种新的框架来提高这些求解器的鲁棒性和泛化能力。", "method": "该方法包括偏好导向的对抗攻击生成难以解决的问题实例，并通过量化帕累托前沿质量下降的程度来衡量攻击效果；同时引入一种硬度感知偏好选择集成到对抗训练中，以减少对受限偏好的过度拟合并提升出分布性能。", "result": "实验结果证明了所提出的攻击方法能够成功地学习不同求解器的困难实例，并且防御策略显著增强了神经求解器在难以解决或未见样本上的鲁棒性和泛化能力。", "conclusion": "论文提出的方法有效提高了面向偏好的强化学习求解器对于多目标组合优化问题的稳健性与通用性。"}}
{"id": "2601.01663", "pdf": "https://arxiv.org/pdf/2601.01663", "abs": "https://arxiv.org/abs/2601.01663", "authors": ["He Sun", "Jiwoong Shin", "Ravi Dhar"], "title": "Length-Aware Adversarial Training for Variable-Length Trajectories: Digital Twins for Mall Shopper Paths", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We study generative modeling of \\emph{variable-length trajectories} -- sequences of visited locations/items with associated timestamps -- for downstream simulation and counterfactual analysis. A recurring practical issue is that standard mini-batch training can be unstable when trajectory lengths are highly heterogeneous, which in turn degrades \\emph{distribution matching} for trajectory-derived statistics. We propose \\textbf{length-aware sampling (LAS)}, a simple batching strategy that groups trajectories by length and samples batches from a single length bucket, reducing within-batch length heterogeneity (and making updates more consistent) without changing the model class. We integrate LAS into a conditional trajectory GAN with auxiliary time-alignment losses and provide (i) a distribution-level guarantee for derived variables under mild boundedness assumptions, and (ii) an IPM/Wasserstein mechanism explaining why LAS improves distribution matching by removing length-only shortcut critics and targeting within-bucket discrepancies. Empirically, LAS consistently improves matching of derived-variable distributions on a multi-mall dataset of shopper trajectories and on diverse public sequence datasets (GPS, education, e-commerce, and movies), outperforming random sampling across dataset-specific metrics.", "AI": {"tldr": "提出了一种针对可变长度轨迹的生成模型，通过长度感知采样技术解决标准小批量训练在处理高度异质性时间序列时的不稳定性问题。", "motivation": "为了解决标准小批量训练在面对不同长度的时间序列数据集时不稳定的问题，特别是对于下游模拟和反事实分析所需的变量长度轨迹生成模型中的分布匹配不佳现象。", "method": "提出了一种称为长度感知采样（LAS）的策略来解决上述问题。该方法将具有相似长度的时间序列分组并在每个分组中进行小批量训练，从而减少了批次内长度不一致性，提高了更新的一致性和模型的稳定性。", "result": "实验证明，LAS在多个数据集上改善了由轨迹导出变量分布匹配的性能，并且优于随机采样方法。这些数据集包括多商场购物者轨迹以及GPS、教育、电子商务和电影等公开序列数据集。", "conclusion": "长度感知采样的引入有效解决了小批量训练中由于时间序列长度异质性导致的问题，显著提高了生成模型在处理可变长度轨迹时的性能，并增强了下游模拟和分析任务的效果。"}}
{"id": "2601.01660", "pdf": "https://arxiv.org/pdf/2601.01660", "abs": "https://arxiv.org/abs/2601.01660", "authors": ["Aymen Mir", "Riza Alp Guler", "Jian Wang", "Gerard Pons-Moll", "Bing Zhou"], "title": "Animated 3DGS Avatars in Diverse Scenes with Consistent Lighting and Shadows", "categories": ["cs.CV"], "comment": "Our project page is available at https://miraymen.github.io/dgsm", "summary": "We present a method for consistent lighting and shadows when animated 3D Gaussian Splatting (3DGS) avatars interact with 3DGS scenes or with dynamic objects inserted into otherwise static scenes. Our key contribution is Deep Gaussian Shadow Maps (DGSM), a modern analogue of the classical shadow mapping algorithm tailored to the volumetric 3DGS representation. Building on the classic deep shadow mapping idea, we show that 3DGS admits closed form light accumulation along light rays, enabling volumetric shadow computation without meshing. For each estimated light, we tabulate transmittance over concentric radial shells and store them in octahedral atlases, which modern GPUs can sample in real time per query to attenuate affected scene Gaussians and thus cast and receive shadows consistently. To relight moving avatars, we approximate the local environment illumination with HDRI probes represented in a spherical harmonic (SH) basis and apply a fast per Gaussian radiance transfer, avoiding explicit BRDF estimation or offline optimization. We demonstrate environment consistent lighting for avatars from AvatarX and ActorsHQ, composited into ScanNet++, DL3DV, and SuperSplat scenes, and show interactions with inserted objects. Across single and multi avatar settings, DGSM and SH relighting operate fully in the volumetric 3DGS representation, yielding coherent shadows and relighting while avoiding meshing.", "AI": {"tldr": "本文提出了一种名为Deep Gaussian Shadow Maps (DGSM)的方法，用于在三维高斯散射(3DGS)环境中实现一致的光照和阴影效果。", "motivation": "为了提高动画3DGS角色与场景或动态物体交互时的一致性照明和阴影效果。", "method": "通过构建深度高斯阴影图(DGSM)，该算法是针对体积表示量身定做的，可以沿光线累积光强度，实现体素化的阴影计算。并通过使用HDR球谐基环境光照近似方法来重新照亮移动的虚拟角色。", "result": "实验展示了在不同场景中动画3DGS角色的一致性照明和阴影效果，并证明了DGSM与SH重光能够在体积表示下操作，生成连贯的阴影和光照效果。", "conclusion": "该方法成功实现了三维高斯散射环境中一致性照明和阴影的效果，避免了网格化处理。"}}
{"id": "2601.01658", "pdf": "https://arxiv.org/pdf/2601.01658", "abs": "https://arxiv.org/abs/2601.01658", "authors": ["Anubhab Tripathi", "Li Gaishan", "Zhengnan Fu", "Chiara Bartolozzi", "Bert E. Shi", "Arindam Basu"], "title": "STEMNIST: Spiking Tactile Extended MNIST Neuromorphic Dataset", "categories": ["cs.NE"], "comment": null, "summary": "Tactile sensing is essential for robotic manipulation, prosthetics and assistive technologies, yet neuromorphic tactile datasets remain limited compared to their visual counterparts. We introduce STEMNIST, a large-scale neuromorphic tactile dataset extending ST-MNIST from 10 digits to 35 alphanumeric classes (uppercase letters A--Z and digits 1--9), providing a challenging benchmark for event-based haptic recognition. The dataset comprises 7,700 samples collected from 34 participants using a custom \\(16\\times 16\\) tactile sensor array operating at 120 Hz, encoded as 1,005,592 spike events through adaptive temporal differentiation. Following EMNIST's visual character recognition protocol, STEMNIST addresses the critical gap between simplified digit classification and real-world tactile interaction scenarios requiring alphanumeric discrimination. Baseline experiments using conventional CNNs (90.91% test accuracy) and spiking neural networks (89.16%) establish performance benchmarks. The dataset's event-based format, unrestricted spatial variability and rich temporal structure makes it suitable for testing neuromorphic hardware and bio-inspired learning algorithms. STEMNIST enables reproducible evaluation of tactile recognition systems and provides a foundation for advancing energy-efficient neuromorphic perception in robotics, biomedical engineering and human-machine interfaces. The dataset, documentation and codes are publicly available to accelerate research in neuromorphic tactile computing.", "AI": {"tldr": "STEMNIST是一个大型的神经形态触觉数据集，扩展了ST-MNIST从10个数字到35个字母和数字类别。", "motivation": "现有的视觉数据集中存在大量样本，但相应的神经形态触觉数据却相对有限。本文旨在填补简化数字分类与需要进行字母数字区别的实际场景之间的空白，通过STEMNIST提供一个更具挑战性的基准以促进事件驱动的触觉识别研究。", "method": "使用自定义16×16像素阵列传感器收集7,700个样本，并将数据编码为1,005,592个脉冲事件。采用传统CNN和尖峰神经网络作为基线实验，以确立性能基准。", "result": "通过基于EMNIST的视觉字符识别协议进行实验，实现了使用传统CNN（测试准确率90.91%）和尖峰神经网络（89.16%）的结果。这些结果为事件驱动的触觉识别系统提供了一个可重复评估的基础。", "conclusion": "STEMNIST数据集填补了现有研究中的空白，使研究人员能够通过事件驱动的数据格式测试神经形态硬件和生物启发的学习算法，推动机器人、生物医学工程及人机交互领域的能效感知技术的发展。"}}
{"id": "2601.01655", "pdf": "https://arxiv.org/pdf/2601.01655", "abs": "https://arxiv.org/abs/2601.01655", "authors": ["Emiliya Khidirova", "Oktay Karakuş"], "title": "UniCrop: A Universal, Multi-Source Data Engineering Pipeline for Scalable Crop Yield Prediction", "categories": ["eess.IV", "cs.AI", "cs.LG"], "comment": null, "summary": "Accurate crop yield prediction relies on diverse data streams, including satellite, meteorological, soil, and topographic information. However, despite rapid advances in machine learning, existing approaches remain crop- or region-specific and require data engineering efforts. This limits scalability, reproducibility, and operational deployment. This study introduces UniCrop, a universal and reusable data pipeline designed to automate the acquisition, cleaning, harmonisation, and engineering of multi-source environmental data for crop yield prediction. For any given location, crop type, and temporal window, UniCrop automatically retrieves, harmonises, and engineers over 200 environmental variables (Sentinel-1/2, MODIS, ERA5-Land, NASA POWER, SoilGrids, and SRTM), reducing them to a compact, analysis-ready feature set utilising a structured feature reduction workflow with minimum redundancy maximum relevance (mRMR). To validate, UniCrop was applied to a rice yield dataset comprising 557 field observations. Using only the selected 15 features, four baseline machine learning models (LightGBM, Random Forest, Support Vector Regression, and Elastic Net) were trained. LightGBM achieved the best single-model performance (RMSE = 465.1 kg/ha, $R^2 = 0.6576$), while a constrained ensemble of all baselines further improved accuracy (RMSE = 463.2 kg/ha, $R^2 = 0.6604$). UniCrop contributes a scalable and transparent data-engineering framework that addresses the primary bottleneck in operational crop yield modelling: the preparation of consistent and harmonised multi-source data. By decoupling data specification from implementation and supporting any crop, region, and time frame through simple configuration updates, UniCrop provides a practical foundation for scalable agricultural analytics. The code and implementation documentation are shared in https://github.com/CoDIS-Lab/UniCrop.", "AI": {"tldr": "UniCrop是一种通用的数据工程管道，用于自动化获取和处理多源环境数据以预测农作物产量。", "motivation": "现有的作物产量预测方法依赖于特定的作物或区域，并且需要大量的数据准备工作。这种方法限制了可扩展性、可重复性和操作部署。", "method": "UniCrop自动检索、协调并工程化超过200个环境变量，通过最小冗余最大相关（mRMR）结构化的特征减少工作流程将其简化为分析准备好的功能集。", "result": "应用到水稻产量数据集中时，LightGBM模型获得了最佳单模性能（RMSE = 465.1 kg/ha, $R^2$ = 0.6576），而约束集合基线模型进一步提高了准确性（RMSE = 463.2 kg/ha, $R^2$ = 0.6604）。", "conclusion": "UniCrop提供了一个可扩展且透明的数据工程框架，解决了操作性作物产量建模的主要瓶颈：一致性与多源数据协调。通过简单的配置更新支持任何农作物、区域和时间范围。"}}
{"id": "2601.01653", "pdf": "https://arxiv.org/pdf/2601.01653", "abs": "https://arxiv.org/abs/2601.01653", "authors": ["Hao Xiang Li", "Yash Shah", "Lorenzo Giusti"], "title": "Learning Resilient Elections with Adversarial GNNs", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SI"], "comment": null, "summary": "In the face of adverse motives, it is indispensable to achieve a consensus. Elections have been the canonical way by which modern democracy has operated since the 17th century. Nowadays, they regulate markets, provide an engine for modern recommender systems or peer-to-peer networks, and remain the main approach to represent democracy. However, a desirable universal voting rule that satisfies all hypothetical scenarios is still a challenging topic, and the design of these systems is at the forefront of mechanism design research. Automated mechanism design is a promising approach, and recent works have demonstrated that set-invariant architectures are uniquely suited to modelling electoral systems. However, various concerns prevent the direct application to real-world settings, such as robustness to strategic voting. In this paper, we generalise the expressive capability of learned voting rules, and combine improvements in neural network architecture with adversarial training to improve the resilience of voting rules while maximizing social welfare. We evaluate the effectiveness of our methods on both synthetic and real-world datasets. Our method resolves critical limitations of prior work regarding learning voting rules by representing elections using bipartite graphs, and learning such voting rules using graph neural networks. We believe this opens new frontiers for applying machine learning to real-world elections.", "AI": {"tldr": "本文通过结合改进的神经网络架构和对抗训练，增强了选举规则的鲁棒性，并最大化社会福利。", "motivation": "当前设计选举系统的挑战在于创建满足所有假设场景的理想通用投票规则。尽管自动机制设计是一种有前途的方法，但诸如策略性投票之类的担忧阻碍了其直接应用到实际情境中。", "method": "本文通过表示选举为二分图，并使用图神经网络学习这样的投票规则来改进现有工作中的限制。", "result": "实验评估证明该方法在合成和真实世界数据集上有效，展示了增强的鲁棒性和社会福利最大化能力。", "conclusion": "这种方法开辟了将机器学习应用于现实选举的新领域。"}}
{"id": "2601.01651", "pdf": "https://arxiv.org/pdf/2601.01651", "abs": "https://arxiv.org/abs/2601.01651", "authors": ["Yucheng Xu", "Xiaofeng Mao", "Elle Miller", "Xinyu Yi", "Yang Li", "Zhibin Li", "Robert B. Fisher"], "title": "DemoBot: Efficient Learning of Bimanual Manipulation with Dexterous Hands From Third-Person Human Videos", "categories": ["cs.RO"], "comment": null, "summary": "This work presents DemoBot, a learning framework that enables a dual-arm, multi-finger robotic system to acquire complex manipulation skills from a single unannotated RGB-D video demonstration. The method extracts structured motion trajectories of both hands and objects from raw video data. These trajectories serve as motion priors for a novel reinforcement learning (RL) pipeline that learns to refine them through contact-rich interactions, thereby eliminating the need to learn from scratch. To address the challenge of learning long-horizon manipulation skills, we introduce: (1) Temporal-segment based RL to enforce temporal alignment of the current state with demonstrations; (2) Success-Gated Reset strategy to balance the refinement of readily acquired skills and the exploration of subsequent task stages; and (3) Event-Driven Reward curriculum with adaptive thresholding to guide the RL learning of high-precision manipulation. The novel video processing and RL framework successfully achieved long-horizon synchronous and asynchronous bimanual assembly tasks, offering a scalable approach for direct skill acquisition from human videos.", "AI": {"tldr": "DemoBot 是一种从单个未注释的 RGB-D 视频演示中学习复杂操作技能的学习框架。", "motivation": "旨在使双臂、多手指机器人系统能够通过视频数据中的手部和物体运动轨迹进行高效学习，以实现长时序同步与异步双手装配任务。", "method": "该方法包括从原始视频数据提取结构化动作轨迹，并结合基于时间片段的 RL 算法来增强当前状态与时序演示的一致性。通过引入成功门控重置策略和事件驱动奖励课程，平衡技能细化与探索后续任务阶段之间的关系。", "result": "提出的视频处理和 RL 框架成功实现了长时序同步和异步的双手装配任务。", "conclusion": "该研究提出的方法为直接从人类视频中获取技能提供了可扩展途径。"}}
{"id": "2601.01645", "pdf": "https://arxiv.org/pdf/2601.01645", "abs": "https://arxiv.org/abs/2601.01645", "authors": ["Vipindev Adat Vasudevan", "Homa Esfahanizadeh", "Benjamin D. Kim", "Laura Landon", "Alejandro Cohen", "Muriel Médard"], "title": "Revisiting the Interface between Error and Erasure Correction in Wireless Standards", "categories": ["cs.NI", "cs.ET"], "comment": null, "summary": "Modern 5G communication systems implement a combination of error correction and feedback-based erasure correction (HARQ/ARQ) as reliability mechanisms, which can introduce substantial delay and resource inefficiency. We propose forward erasure correction using network coding as a more delay-efficient alternative. We present a mathematical characterization of network delay for existing reliability mechanisms and network coding. Through simulations in a network slicing environment, we demonstrate that network coding not only improves the in-order delivery delay and goodput for the applications utilizing the slice, but also benefits other applications sharing the network by reducing resource utilization for the coded slice. Our analysis and characterization point towards ideas that require attention in the 6G standardization process. These findings highlight the need for greater modularity in protocol stack design that enables the integration of novel technologies in future wireless networks.", "AI": {"tldr": "研究在网络切片环境中使用前向擦除编码结合网络编码减少延迟和资源消耗的可行性。", "motivation": "现有5G通信系统的纠错机制与反馈式擦除纠正机制存在较大延迟并造成资源浪费，提出一种基于网络编码的前向擦除纠正作为替代方案来提高效率。", "method": "通过数学分析和在虚拟网络切片环境中的仿真测试，对比现有可靠性机制与网络编码对于延迟及吞吐量的影响。", "result": "结果显示网络编码不仅能减少使用该切片的应用程序的有序交付延迟并提升其吞吐率，还能降低与其他共享网络的应用程序的竞争资源消耗。", "conclusion": "研究结果强调了在6G标准化过程中对协议栈设计应具备更高模块化以促进新型技术融合的需求。"}}
{"id": "2601.01639", "pdf": "https://arxiv.org/pdf/2601.01639", "abs": "https://arxiv.org/abs/2601.01639", "authors": ["Gaurav Sekar"], "title": "An Empirical Study of Monocular Human Body Measurement Under Weak Calibration", "categories": ["cs.CV"], "comment": "The paper consists of 8 pages, 2 figures (on pages 4 and 7), and 2 tables (both on page 6)", "summary": "Estimating human body measurements from monocular RGB imagery remains challenging due to scale ambiguity, viewpoint sensitivity, and the absence of explicit depth information. This work presents a systematic empirical study of three weakly calibrated monocular strategies: landmark-based geometry, pose-driven regression, and object-calibrated silhouettes, evaluated under semi-constrained conditions using consumer-grade cameras. Rather than pursuing state-of-the-art accuracy, the study analyzes how differing calibration assumptions influence measurement behavior, robustness, and failure modes across varied body types. The results reveal a clear trade-off between user effort during calibration and the stability of resulting circumferential quantities. This paper serves as an empirical design reference for lightweight monocular human measurement systems intended for deployment on consumer devices.", "AI": {"tldr": "研究三种弱校准单目策略在估计人体测量中的表现。", "motivation": "探讨不同校准假设如何影响人体测量的准确性和稳定性，为消费级设备设计提供参考。", "method": "评估基于关键点几何、姿态驱动回归和对象校准轮廓的三种方法，并分析它们在半约束条件下的行为及失败模式。", "result": "显示用户在校准时的努力与结果稳定性的明确权衡关系。", "conclusion": "不同弱校准策略间存在取舍，为消费级人体测量系统设计提供了指导。"}}
{"id": "2601.01627", "pdf": "https://arxiv.org/pdf/2601.01627", "abs": "https://arxiv.org/abs/2601.01627", "authors": ["Junyu Liu", "Zirui Li", "Qian Niu", "Zequn Zhang", "Yue Xun", "Wenlong Hou", "Shujun Wang", "Yusuke Iwasawa", "Yutaka Matsuo", "Kan Hatakeyama-Sato"], "title": "JMedEthicBench: A Multi-Turn Conversational Benchmark for Evaluating Medical Safety in Japanese Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 6 figures", "summary": "As Large Language Models (LLMs) are increasingly deployed in healthcare field, it becomes essential to carefully evaluate their medical safety before clinical use. However, existing safety benchmarks remain predominantly English-centric, and test with only single-turn prompts despite multi-turn clinical consultations. To address these gaps, we introduce JMedEthicBench, the first multi-turn conversational benchmark for evaluating medical safety of LLMs for Japanese healthcare. Our benchmark is based on 67 guidelines from the Japan Medical Association and contains over 50,000 adversarial conversations generated using seven automatically discovered jailbreak strategies. Using a dual-LLM scoring protocol, we evaluate 27 models and find that commercial models maintain robust safety while medical-specialized models exhibit increased vulnerability. Furthermore, safety scores decline significantly across conversation turns (median: 9.5 to 5.0, $p < 0.001$). Cross-lingual evaluation on both Japanese and English versions of our benchmark reveals that medical model vulnerabilities persist across languages, indicating inherent alignment limitations rather than language-specific factors. These findings suggest that domain-specific fine-tuning may accidentally weaken safety mechanisms and that multi-turn interactions represent a distinct threat surface requiring dedicated alignment strategies.", "AI": {"tldr": "该论文介绍了JMedEthicBench，这是一个评估日本大型语言模型在医疗安全方面的多轮对话基准。", "motivation": "随着大型语言模型越来越多地应用于医疗领域，需要仔细评估其安全性。现有的安全基准主要集中在英语上，并且仅使用单轮提示进行测试，而忽略了多轮临床咨询的重要性。", "method": "该研究基于日本医学协会的67条指南，创建了包含超过50,000个对抗性对话的JMedEthicBench，这些对话通过七种自动发现的破解策略生成。使用双语言模型评分协议评估27个模型，并发现在多轮交互中安全分数显著下降。", "result": "商业模型在安全性上保持稳健，而医学专业的模型表现出更高的脆弱性。此外，在多轮对话过程中，安全得分从9.5降至5.0（p<0.001）。跨语言评估表明，医疗模型的漏洞在不同语言中仍然存在。", "conclusion": "这些发现表明领域特定的微调可能会意外削弱安全机制，并且多轮互动构成了不同的威胁表面，需要专门的安全对齐策略。"}}
{"id": "2601.01618", "pdf": "https://arxiv.org/pdf/2601.01618", "abs": "https://arxiv.org/abs/2601.01618", "authors": ["Huajie Tan", "Peterson Co", "Yijie Xu", "Shanyu Rong", "Yuheng Ji", "Cheng Chi", "Xiansheng Chen", "Qiongyu Zhang", "Zhongxia Zhao", "Pengwei Wang", "Zhongyuan Wang", "Shanghang Zhang"], "title": "Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation", "categories": ["cs.RO"], "comment": "26 pages, 14 figures", "summary": "Long-horizon robotic manipulation is increasingly important for real-world deployment, requiring spatial disambiguation in complex layouts and temporal resilience under dynamic interaction. However, existing end-to-end and hierarchical Vision-Language-Action (VLA) policies often rely on text-only cues while keeping plan intent latent, which undermines referential grounding in cluttered or underspecified scenes, impedes effective task decomposition of long-horizon goals with close-loop interaction, and limits causal explanation by obscuring the rationale behind action choices. To address these issues, we first introduce Visual Sketch, an implausible visual intermediate that renders points, boxes, arrows, and typed relations in the robot's current views to externalize spatial intent, connect language to scene geometry. Building on Visual Sketch, we present Action-Sketcher, a VLA framework that operates in a cyclic See-Think-Sketch-Act workflow coordinated by adaptive token-gated strategy for reasoning triggers, sketch revision, and action issuance, thereby supporting reactive corrections and human interaction while preserving real-time action prediction. To enable scalable training and evaluation, we curate diverse corpus with interleaved images, text, Visual Sketch supervision, and action sequences, and train Action-Sketcher with a multi-stage curriculum recipe that combines interleaved sequence alignment for modality unification, language-to-sketch consistency for precise linguistic grounding, and imitation learning augmented with sketch-to-action reinforcement for robustness. Extensive experiments on cluttered scenes and multi-object tasks, in simulation and on real-world tasks, show improved long-horizon success, stronger robustness to dynamic scene changes, and enhanced interpretability via editable sketches and step-wise plans. Project website: https://action-sketcher.github.io", "AI": {"tldr": "本文提出了一种名为Action-Sketcher的视觉语言行动框架，通过在复杂环境中使用可视草图进行空间意图外化和任务分解来改进长时程机器人操作。", "motivation": "现有的端到端和分层Vision-Language-Action政策依赖于文本线索而不明确计划意图，这导致了参考性接地不足、长期目标的任务分解效果差以及因果解释受限。为了解决这些问题，论文提出了可视草图并建立了Action-Sketcher框架。", "method": "通过使用可视草图的中间表示和自适应标记门控策略来协调推理触发器、草图修订和行动发布，从而支持实时预测与互动修正；同时采用多阶段课程训练方法增强模型性能。", "result": "实验结果表明，在模拟环境和现实世界任务中，Action-Sketcher框架提高了长时程成功率，增强了对动态场景变化的鲁棒性，并通过可编辑草图和分步计划提升了解释能力。", "conclusion": "论文提出的可视草图与Action-Sketcher框架通过改进空间意图外化、任务分解以及因果解释等方法，显著改善了长时程机器人操作的成功率与鲁棒性。"}}
{"id": "2601.01613", "pdf": "https://arxiv.org/pdf/2601.01613", "abs": "https://arxiv.org/abs/2601.01613", "authors": ["Kazi Ramisa Rifa", "Jie Zhang", "Abdullah Imran"], "title": "CAP-IQA: Context-Aware Prompt-Guided CT Image Quality Assessment", "categories": ["cs.CV"], "comment": "18 pages, 9 figures, 5 tables", "summary": "Prompt-based methods, which encode medical priors through descriptive text, have been only minimally explored for CT Image Quality Assessment (IQA). While such prompts can embed prior knowledge about diagnostic quality, they often introduce bias by reflecting idealized definitions that may not hold under real-world degradations such as noise, motion artifacts, or scanner variability. To address this, we propose the Context-Aware Prompt-guided Image Quality Assessment (CAP-IQA) framework, which integrates text-level priors with instance-level context prompts and applies causal debiasing to separate idealized knowledge from factual, image-specific degradations. Our framework combines a CNN-based visual encoder with a domain-specific text encoder to assess diagnostic visibility, anatomical clarity, and noise perception in abdominal CT images. The model leverages radiology-style prompts and context-aware fusion to align semantic and perceptual representations. On the 2023 LDCTIQA challenge benchmark, CAP-IQA achieves an overall correlation score of 2.8590 (sum of PLCC, SROCC, and KROCC), surpassing the top-ranked leaderboard team (2.7427) by 4.24%. Moreover, our comprehensive ablation experiments confirm that prompt-guided fusion and the simplified encoder-only design jointly enhance feature alignment and interpretability. Furthermore, evaluation on an in-house dataset of 91,514 pediatric CT images demonstrates the true generalizability of CAP-IQA in assessing perceptual fidelity in a different patient population.", "AI": {"tldr": "该论文提出了一种基于上下文感知的提示引导CT图像质量评估框架CAP-IQA，旨在解决现有方法中存在的偏见问题。", "motivation": "现有的提示导向方法在引入先验知识的同时也带来了理想化定义下的偏差，这些问题在实际中的噪声、运动伪影或扫描器变化下显得不适用。因此，需要一种能够结合上下文信息和因果去偏的方法来提高CT图像质量评估的准确性。", "method": "该论文提出了一种结合文本级先验知识与实例级别上下文提示的框架，并利用因果去偏技术分离理想化知识和具体图像退化的事实。采用CNN视觉编码器和领域特定文本编码器相结合的方式，通过放射学风格的提示和上下文感知融合来评估诊断可见性、解剖清晰度及噪声感知。", "result": "在2023 LDCTIQA挑战基准测试中，CAP-IQA获得了总体相关系数分数2.8590（PLCC、SROCC和KROCC的总和），超过了排行榜首位团队的得分4.24%。此外，在内部儿科CT图像数据集上进行评估时，该方法展示了其在不同患者群体中的泛化能力。", "conclusion": "CAP-IQA框架通过结合上下文感知融合与简化的编码器设计，有效地提高了特征对齐和可解释性，并且证明了它能够在广泛的医学应用中提供准确的CT图像质量评估。"}}
{"id": "2601.01609", "pdf": "https://arxiv.org/pdf/2601.01609", "abs": "https://arxiv.org/abs/2601.01609", "authors": ["Albert Sadowski", "Jarosław A. Chudziak"], "title": "Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration", "categories": ["cs.AI"], "comment": null, "summary": "Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express.", "AI": {"tldr": "本文提出了一种将大型语言模型（LLM）和符号系统相结合的方法，以提高规则在自然语言输入中的应用效果。", "motivation": "在需要可审计和可解释的决策环境中，如医学、法律和科学领域，应用规则时既需要灵活性又要有正式保证。然而，现有的大型语言模型（LLM）缺乏一致性和符号系统要求结构化输入。", "method": "本文提出了一种整合模式：利用LLM将非结构化的文本转换为符合专家定义的TBox规范的ABox断言，而使用基于SWRL的推理器进行确定性规则应用。实验涵盖三个领域（法律、科学和临床试验）以及十一款语言模型。", "result": "该框架在实体识别、断言提取和符号验证方面表现出统计学显著提升；并且集成的ABox能够与标准语义网工具结合，进一步丰富推理模式。", "conclusion": "通过结构化分解实现LLM与符号系统的有效融合，在多领域实验中证明了这种方法的有效性，并为更复杂的推理场景提供了可能。"}}
{"id": "2601.01608", "pdf": "https://arxiv.org/pdf/2601.01608", "abs": "https://arxiv.org/abs/2601.01608", "authors": ["Felix Krause", "Stefan Andreas Baumann", "Johannes Schusterbauer", "Olga Grebenkova", "Ming Gui", "Vincent Tao Hu", "Björn Ommer"], "title": "Guiding Token-Sparse Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion models deliver high quality in image synthesis but remain expensive during training and inference. Recent works have leveraged the inherent redundancy in visual content to make training more affordable by training only on a subset of visual information. While these methods were successful in providing cheaper and more effective training, sparsely trained diffusion models struggle in inference. This is due to their lacking response to Classifier-free Guidance (CFG) leading to underwhelming performance during inference. To overcome this, we propose Sparse Guidance (SG). Instead of using conditional dropout as a signal to guide diffusion models, SG uses token-level sparsity. As a result, SG preserves the high-variance of the conditional prediction better, achieving good quality and high variance outputs. Leveraging token-level sparsity at inference, SG improves fidelity at lower compute, achieving 1.58 FID on the commonly used ImageNet-256 benchmark with 25% fewer FLOPs, and yields up to 58% FLOP savings at matched baseline quality. To demonstrate the effectiveness of Sparse Guidance, we train a 2.5B text-to-image diffusion model using training time sparsity and leverage SG during inference. SG achieves improvements in composition and human preference score while increasing throughput at the same time.", "AI": {"tldr": "本论文提出了一种新的稀疏引导(SG)方法，用于改进稀疏训练的扩散模型在推理阶段的表现。", "motivation": "现有的稀疏训练扩散模型在推理时由于对分类器自由指导(CFG)反应不足而导致表现不佳。因此需要一种新方法来改善这一问题。", "method": "提出了一种基于标记级稀疏性的稀疏引导(SG)，并在推理阶段采用该策略，以保持条件预测的高方差，提高输出质量和多样性。", "result": "SG在FID指标上取得了1.58的成绩，并且与基线质量相同时减少了高达58%的计算量。此外，在文本到图像生成任务中，模型在构图和人偏好评分上均有所改进。", "conclusion": "稀疏引导(SG)通过提高扩散模型在推理阶段的质量和多样性，实现了更好的性能，并且降低了计算成本。"}}
{"id": "2601.01605", "pdf": "https://arxiv.org/pdf/2601.01605", "abs": "https://arxiv.org/abs/2601.01605", "authors": ["Xin Di", "Xinglin Piao", "Fei Wang", "Guodong Jing", "Yong Zhang"], "title": "REE-TTT: Highly Adaptive Radar Echo Extrapolation Based on Test-Time Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Precipitation nowcasting is critically important for meteorological forecasting. Deep learning-based Radar Echo Extrapolation (REE) has become a predominant nowcasting approach, yet it suffers from poor generalization due to its reliance on high-quality local training data and static model parameters, limiting its applicability across diverse regions and extreme events. To overcome this, we propose REE-TTT, a novel model that incorporates an adaptive Test-Time Training (TTT) mechanism. The core of our model lies in the newly designed Spatio-temporal Test-Time Training (ST-TTT) block, which replaces the standard linear projections in TTT layers with task-specific attention mechanisms, enabling robust adaptation to non-stationary meteorological distributions and thereby significantly enhancing the feature representation of precipitation. Experiments under cross-regional extreme precipitation scenarios demonstrate that REE-TTT substantially outperforms state-of-the-art baseline models in prediction accuracy and generalization, exhibiting remarkable adaptability to data distribution shifts.", "AI": {"tldr": "提出REE-TTT模型，利用测试时间训练机制改善雷达回波外推在不同区域和极端事件中的泛化能力。", "motivation": "现有基于深度学习的雷达回波外推方法因依赖高质量本地数据及静态模型参数，在跨地域和极端天气情况下的泛化性能不佳。为此提出REE-TTT模型以增强适应性和表现力。", "method": "设计了时空测试时间训练（ST-TTT）模块，通过任务特定注意力机制替换标准线性投影层，使模型能够更好地适应非平稳气象分布，并显著提升降水特征表示能力。", "result": "实验结果显示，REE-TTT在跨区域极端降雨场景下表现优异，预测精度和泛化性能远超现有基线模型。", "conclusion": "REE-TTT通过引入新颖的测试时间训练机制成功增强了雷达回波外推模型的适应性和泛化能力。"}}
{"id": "2601.01599", "pdf": "https://arxiv.org/pdf/2601.01599", "abs": "https://arxiv.org/abs/2601.01599", "authors": ["Ryutaro Uchiyama"], "title": "From Theory of Mind to Theory of Environment: Counterfactual Simulation of Latent Environmental Dynamics", "categories": ["q-bio.NC", "cs.AI"], "comment": "Accepted to the AAAI 2026 Workshop on Theory of Mind for Artificial Intelligence (ToM4AI). Extended abstract, 2 pages", "summary": "The vertebrate motor system employs dimensionality-reducing strategies to limit the complexity of movement coordination, for efficient motor control. But when environments are dense with hidden action-outcome contingencies, movement complexity can promote behavioral innovation. Humans, perhaps uniquely, may infer the presence of hidden environmental dynamics from social cues, by drawing upon computational mechanisms shared with Theory of Mind. This proposed \"Theory of Environment\" supports behavioral innovation by expanding the dimensionality of motor exploration.", "AI": {"tldr": "本文探讨了人类通过社会线索推测环境动态的机制，提出了一种‘环境理论’来促进行为创新。", "motivation": "当环境中隐藏着复杂的行动结果关系时，动作复杂性可以推动行为创新。人类可能借助社交提示推断这些环境动态。", "method": "文中未具体描述方法，主要通过概念探讨和推理分析提出了‘环境理论’的概念框架。", "result": "提出了一种新的认知机制——‘环境理论’，用以解释人类如何利用社会线索推测环境动态并促进行为创新。", "conclusion": "通过扩展运动探索的维度，‘环境理论’能够支持更多的行为创新。"}}
{"id": "2601.01593", "pdf": "https://arxiv.org/pdf/2601.01593", "abs": "https://arxiv.org/abs/2601.01593", "authors": ["Haonan Cai", "Yuxuan Luo", "Zhouhui Lian"], "title": "Beyond Patches: Global-aware Autoregressive Model for Multimodal Few-Shot Font Generation", "categories": ["cs.CV", "cs.MM"], "comment": "25 pages", "summary": "Manual font design is an intricate process that transforms a stylistic visual concept into a coherent glyph set. This challenge persists in automated Few-shot Font Generation (FFG), where models often struggle to preserve both the structural integrity and stylistic fidelity from limited references. While autoregressive (AR) models have demonstrated impressive generative capabilities, their application to FFG is constrained by conventional patch-level tokenization, which neglects global dependencies crucial for coherent font synthesis. Moreover, existing FFG methods remain within the image-to-image paradigm, relying solely on visual references and overlooking the role of language in conveying stylistic intent during font design. To address these limitations, we propose GAR-Font, a novel AR framework for multimodal few-shot font generation. GAR-Font introduces a global-aware tokenizer that effectively captures both local structures and global stylistic patterns, a multimodal style encoder offering flexible style control through a lightweight language-style adapter without requiring intensive multimodal pretraining, and a post-refinement pipeline that further enhances structural fidelity and style coherence. Extensive experiments show that GAR-Font outperforms existing FFG methods, excelling in maintaining global style faithfulness and achieving higher-quality results with textual stylistic guidance.", "AI": {"tldr": "提出了一种用于多模态少样本字体生成的全局感知自回归模型GAR-Font，以提升字体设计中的结构完整性和风格一致性。", "motivation": "现有的少样本字体生成方法在图像到图像的转换中依赖视觉参考而忽视了语言对传达设计风格的作用，并且它们受限于传统的补丁级标记化忽略了全局依存关系。为了解决这些问题，该论文提出了GAR-Font模型来改进现有方法。", "method": "GAR-Font引入了一种全局感知的标记器以捕捉局部结构和整体风格模式；采用多模态样式编码器通过轻量的语言-样式适配器提供灵活的样式控制，并且设计了后处理优化流程进一步提升字体质量。", "result": "实验结果显示，GAR-Font在保持全局风格忠实度以及使用文本指导生成高质量结果方面优于现有方法。", "conclusion": "该论文成功地提出并验证了一种新的多模态少样本字体生成框架GAR-Font，通过引入全球感知技术和优化流程显著改善了传统模型的性能。"}}
{"id": "2601.01592", "pdf": "https://arxiv.org/pdf/2601.01592", "abs": "https://arxiv.org/abs/2601.01592", "authors": ["Xin Wang", "Yunhao Chen", "Juncheng Li", "Yixu Wang", "Yang Yao", "Tianle Gu", "Jie Li", "Yan Teng", "Xingjun Ma", "Yingchun Wang", "Xia Hu"], "title": "OpenRT: An Open-Source Red Teaming Framework for Multimodal LLMs", "categories": ["cs.CR", "cs.CV"], "comment": null, "summary": "The rapid integration of Multimodal Large Language Models (MLLMs) into critical applications is increasingly hindered by persistent safety vulnerabilities. However, existing red-teaming benchmarks are often fragmented, limited to single-turn text interactions, and lack the scalability required for systematic evaluation. To address this, we introduce OpenRT, a unified, modular, and high-throughput red-teaming framework designed for comprehensive MLLM safety evaluation. At its core, OpenRT architects a paradigm shift in automated red-teaming by introducing an adversarial kernel that enables modular separation across five critical dimensions: model integration, dataset management, attack strategies, judging methods, and evaluation metrics. By standardizing attack interfaces, it decouples adversarial logic from a high-throughput asynchronous runtime, enabling systematic scaling across diverse models. Our framework integrates 37 diverse attack methodologies, spanning white-box gradients, multi-modal perturbations, and sophisticated multi-agent evolutionary strategies. Through an extensive empirical study on 20 advanced models (including GPT-5.2, Claude 4.5, and Gemini 3 Pro), we expose critical safety gaps: even frontier models fail to generalize across attack paradigms, with leading models exhibiting average Attack Success Rates as high as 49.14%. Notably, our findings reveal that reasoning models do not inherently possess superior robustness against complex, multi-turn jailbreaks. By open-sourcing OpenRT, we provide a sustainable, extensible, and continuously maintained infrastructure that accelerates the development and standardization of AI safety.", "AI": {"tldr": "介绍了一个用于评估多模态大型语言模型安全性的开源框架OpenRT。", "motivation": "现有红队测试基准分散且局限于单一的文本交互，无法进行全面的安全性评估。为了填补这一空白，提出了一种综合、模块化和高吞吐量的自动化红队测试框架。", "method": "通过引入一个对抗内核来实现模型集成、数据集管理、攻击策略、评判方法和评价指标之间的分离，并整合了37种不同类型的攻击手段以进行系统性评估。", "result": "在对20个高级模型的广泛研究中，发现即使前沿模型也不能很好地应对不同的攻击模式，其平均攻击成功率高达49.14%。", "conclusion": "通过开源框架OpenRT为持续提高AI安全性提供了可持续、可扩展和维护的标准基础设施。"}}
{"id": "2601.01581", "pdf": "https://arxiv.org/pdf/2601.01581", "abs": "https://arxiv.org/abs/2601.01581", "authors": ["Rishav Sen", "Fangqi Liu", "Jose Paolo Talusan", "Ava Pettet", "Yoshinori Suzue", "Mark Bailey", "Ayan Mukhopadhyay", "Abhishek Dubey"], "title": "CONSENT: A Negotiation Framework for Leveraging User Flexibility in Vehicle-to-Building Charging under Uncertainty", "categories": ["cs.MA", "cs.AI", "cs.GT", "eess.SY"], "comment": "Submitted to AAMAS 2026. 25 pages, 13 figures, 14 tables", "summary": "The growth of Electric Vehicles (EVs) creates a conflict in vehicle-to-building (V2B) settings between building operators, who face high energy costs from uncoordinated charging, and drivers, who prioritize convenience and a full charge. To resolve this, we propose a negotiation-based framework that, by design, guarantees voluntary participation, strategy-proofness, and budget feasibility. It transforms EV charging into a strategic resource by offering drivers a range of incentive-backed options for modest flexibility in their departure time or requested state of charge (SoC). Our framework is calibrated with user survey data and validated using real operational data from a commercial building and an EV manufacturer. Simulations show that our negotiation protocol creates a mutually beneficial outcome: lowering the building operator's costs by over 3.5\\% compared to an optimized, non-negotiating smart charging policy, while simultaneously reducing user charging expenses by 22\\% below the utility's retail energy rate. By aligning operator and EV user objectives, our framework provides a strategic bridge between energy and mobility systems, transforming EV charging from a source of operational friction into a platform for collaboration and shared savings.", "AI": {"tldr": "提出了一种基于协商的框架，以解决电动汽车充电中的用户灵活性问题。", "motivation": "解决建筑物运营商和电动汽车司机在车辆到建筑充电过程中因未协调而产生的高能源成本冲突。", "method": "设计了一个保证自愿参与、策略无漏洞和预算可行性的谈判协议，通过提供一系列带有激励措施的时间和电池状态调整选项来实现。", "result": "模拟结果显示，该框架降低了建筑物运营成本，并减少了用户的电费支出。", "conclusion": "该框架为运营商和电动汽车用户提供了一个战略桥梁，将电动车充电转变为协作与共享节省的平台。"}}
{"id": "2601.01580", "pdf": "https://arxiv.org/pdf/2601.01580", "abs": "https://arxiv.org/abs/2601.01580", "authors": ["Zibo Zhao", "Yuanting Zha", "Haipeng Zhang", "Xingcheng Xu"], "title": "The Two-Stage Decision-Sampling Hypothesis: Understanding the Emergence of Self-Reflection in RL-Trained LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Self-reflection capabilities emerge in Large Language Models after RL post-training, with multi-turn RL achieving substantial gains over SFT counterparts. Yet the mechanism of how a unified optimization objective gives rise to functionally distinct capabilities of generating solutions and evaluating when to revise them remains opaque. To address this question, we introduce the Gradient Attribution Property to characterize how reward gradients distribute across policy components, formalized through the Two-Stage Decision-Sampling (DS) Hypothesis, which decomposes the policy into sampling ($π_{sample}$) for generation and decision ($π_{d}$) for verification. We prove that surrogate rewards exhibit Balanced Gradient Attribution, while SFT and KL penalties exhibit Unbalanced Gradient Attribution, with length-weighting creating asymmetric regularization that constrains $π_{sample}$ while leaving $π_{d}$ under-optimized, providing an theoretical explanation of why RL succeeds where SFT fails. We also empirically validate our theoretical predictions on arithmetic reasoning demonstrates that RL's superior generalization stems primarily from improved decision-making ($π_{d}$) rather than sampling capabilities, providing a first-principles mechanistic explanation for self-correction in thinking models.", "AI": {"tldr": "研究提出了两阶段决策采样假设，解释了通过强化学习训练的大型语言模型如何在生成解决方案和判断何时需要修正之间形成功能上不同的能力。", "motivation": "探讨统一优化目标下产生解决问题能力和评估修订时机的不同机制，并揭示为何强化学习相比仅使用监督学习能有效提高大型语言模型自反性。", "method": "通过引入梯度归因属性，将策略分解为采样和决策两个阶段，证明代理奖励具有平衡的梯度分配特性而监督学习和KL惩罚则不具此特性。", "result": "实验验证表明强化学习相较于监督训练在算术推理任务上表现更佳主要得益于改进了决策过程而非生成能力提升。", "conclusion": "研究提供了首个基于第一性原理解释大型语言模型中自反性出现机制的理论框架，并强调改善决策环节对于提高一般化能力的重要性。"}}
{"id": "2601.01578", "pdf": "https://arxiv.org/pdf/2601.01578", "abs": "https://arxiv.org/abs/2601.01578", "authors": ["Psyche T. Malabo", "Bobby D. Gerardo"], "title": "Adaptive Tuning of the Unscented Kalman Filter using Particle Swarm Optimization for Inertial-GPS Sensor Fusion Systems", "categories": ["cs.ET"], "comment": null, "summary": "Accurate vehicle positioning requires effective IMU-GPS fusion, yet prior methods-EKF, UKF, ML, GA, and DE-suffer from nonlinearity, instability, or high computational cost. This study introduces a PSO-based adaptive tuning framework for optimizing UKF parameters (α, \\b{eta}, \\k{appa}, Q, R), evaluated in CARLA 0.9.14 using a Tesla Model 3 under diverse maneuvers and environmental conditions. Within defined parameter bounds, convergence stabilized within 15 generations, achieving an 82.14% accuracy improvement over manual tuning and reducing IMU drift by up to 21,606.59m. Multi-trial statistical validation confirmed consistent gains with low confidence intervals. With update times remaining below the 10 ms real-time threshold, the PSO-tuned UKF demonstrates practical localization performance for dynamic, GPS-challenged conditions.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.01577", "pdf": "https://arxiv.org/pdf/2601.01577", "abs": "https://arxiv.org/abs/2601.01577", "authors": ["Tran Tien Dat", "Nguyen Hai An", "Nguyen Khanh Viet Dung", "Nguyen Duy Duc"], "title": "HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Current attempts of Reinforcement Learning for Autonomous Controller are data-demanding while the results are under-performed, unstable, and unable to grasp and anchor on the concept of safety, and over-concentrating on noise features due to the nature of pixel reconstruction. While current Self-Supervised Learningapproachs that learning on high-dimensional representations by leveraging the JointEmbedding Predictive Architecture (JEPA) are interesting and an effective alternative, as the idea mimics the natural ability of the human brain in acquiring new skill usingimagination and minimal samples of observations. This study introduces Hanoi-World, a JEPA-based world model that using recurrent neural network (RNN) formaking longterm horizontal planning with effective inference time. Experimentsconducted on the Highway-Env package with difference enviroment showcase the effective capability of making a driving plan while safety-awareness, with considerablecollision rate in comparison with SOTA baselines", "AI": {"tldr": "提出了一种基于联合嵌入预测架构的自动驾驶控制器世界模型HanoiWorld。", "motivation": "当前强化学习方法对于自主控制来说数据需求量大，效果欠佳且不稳定，难以确保安全性。现有自监督学习方法通过利用联合嵌入预测架构可以有效解决这些问题。", "method": "引入了一种基于JEPA的自动驾驶控制器世界模型HanoiWorld，并采用循环神经网络进行长期规划和推理。", "result": "实验结果表明，在各种环境中，HanoiWorld在确保安全的同时能有效地做出驾驶计划，其碰撞率与现有最佳方法相比相当。", "conclusion": "该研究证明了基于JEPA的自动驾驶控制器世界模型的有效性及其对提高安全性的重要性。"}}
{"id": "2601.01576", "pdf": "https://arxiv.org/pdf/2601.01576", "abs": "https://arxiv.org/abs/2601.01576", "authors": ["Ming Zhang", "Kexin Tan", "Yueyuan Huang", "Yujiong Shen", "Chunchun Ma", "Li Ju", "Xinran Zhang", "Yuhui Wang", "Wenqing Jing", "Jingyi Deng", "Huayu Sha", "Binze Hu", "Jingqi Tong", "Changhao Jiang", "Yage Geng", "Yuankai Ying", "Yue Zhang", "Zhangyue Yin", "Zhiheng Xi", "Shihan Dou", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "OpenNovelty: An LLM-powered Agentic System for Verifiable Scholarly Novelty Assessment", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Evaluating novelty is critical yet challenging in peer review, as reviewers must assess submissions against a vast, rapidly evolving literature. This report presents OpenNovelty, an LLM-powered agentic system for transparent, evidence-based novelty analysis. The system operates through four phases: (1) extracting the core task and contribution claims to generate retrieval queries; (2) retrieving relevant prior work based on extracted queries via semantic search engine; (3) constructing a hierarchical taxonomy of core-task-related work and performing contribution-level full-text comparisons against each contribution; and (4) synthesizing all analyses into a structured novelty report with explicit citations and evidence snippets. Unlike naive LLM-based approaches, \\textsc{OpenNovelty} grounds all assessments in retrieved real papers, ensuring verifiable judgments. We deploy our system on 500+ ICLR 2026 submissions with all reports publicly available on our website, and preliminary analysis suggests it can identify relevant prior work, including closely related papers that authors may overlook. OpenNovelty aims to empower the research community with a scalable tool that promotes fair, consistent, and evidence-backed peer review.", "AI": {"tldr": "开放新颖性（OpenNovelty）是一个基于LLM的代理系统，用于透明、有证据支持的新颖性评估。", "motivation": "评估新颖性在同行评审中至关重要但具有挑战性。该系统旨在通过自动检索相关文献并生成结构化的新颖性报告来促进公平、一致和基于证据的同行评审。", "method": "该系统通过四个阶段工作：提取核心任务和贡献声明以生成检索查询；根据提取的查询通过语义搜索引擎检索相关先前作品；构建与核心任务相关的层次分类法，并对每个贡献进行全文比较；将所有分析综合成带有明确引用和证据片段的结构化新颖性报告。", "result": "该系统在ICLR 2026提交中部署，初步分析表明它能够识别包括作者可能忽略的相关先前作品在内的相关文献。", "conclusion": "开放新颖性旨在通过提供可扩展工具来支持研究社区实现公平、一致和基于证据的同行评审。"}}
{"id": "2601.01569", "pdf": "https://arxiv.org/pdf/2601.01569", "abs": "https://arxiv.org/abs/2601.01569", "authors": ["Maohao Ran", "Zhenglin Wan", "Cooper Lin", "Yanting Zhang", "Hongyu Xin", "Hongwei Fan", "Yibo Xu", "Beier Luo", "Yaxin Zhou", "Wangbo Zhao", "Lijie Yang", "Lang Feng", "Fuchao Yang", "Jingxuan Wu", "Yiqiao Huang", "Chendong Ma", "Dailing Jiang", "Jianbo Deng", "Sihui Han", "Bo An", "Yike Guo", "Jun Song"], "title": "CaveAgent: Transforming LLMs into Stateful Runtime Operators", "categories": ["cs.AI", "cs.SE"], "comment": "32 pages, 14 Figures", "summary": "LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms. Traditional approaches rely on procedural JSON-based function calling, which often struggles with long-horizon tasks due to fragile multi-turn dependencies and context drift. In this paper, we present CaveAgent, a framework that transforms the paradigm from \"LLM-as-Text-Generator\" to \"LLM-as-Runtime-Operator.\" We introduce a Dual-stream Context Architecture that decouples state management into a lightweight semantic stream for reasoning and a persistent, deterministic Python Runtime stream for execution. In addition to leveraging code generation to efficiently resolve interdependent sub-tasks (e.g., loops, conditionals) in a single step, we introduce \\textit{Stateful Runtime Management} in CaveAgent. Distinct from existing code-based approaches that remain text-bound and lack the support for external object injection and retrieval, CaveAgent injects, manipulates, and retrieves complex Python objects (e.g., DataFrames, database connections) that persist across turns. This persistence mechanism acts as a high-fidelity external memory to eliminate context drift, avoid catastrophic forgetting, while ensuring that processed data flows losslessly to downstream applications. Comprehensive evaluations on Tau$^2$-bench, BFCL and various case studies across representative SOTA LLMs demonstrate CaveAgent's superiority. Specifically, our framework achieves a 10.5\\% success rate improvement on retail tasks and reduces total token consumption by 28.4\\% in multi-turn scenarios. On data-intensive tasks, direct variable storage and retrieval reduces token consumption by 59\\%, allowing CaveAgent to handle large-scale data that causes context overflow failures in both JSON-based and Code-based agents.", "AI": {"tldr": "本论文提出CaveAgent框架，将LLM从文本生成者转变为运行时操作者。", "motivation": "当前基于LLM的代理系统依赖于JSON函数调用，在处理多步骤任务时面临上下文漂移和依赖脆弱性的问题。为解决这些问题，引入了一种新的框架来优化长跨度任务执行。", "method": "CaveAgent采用双流上下文架构，将状态管理分为轻量级语义流与持久确定性的Python运行流，并支持代码生成、复杂的Python对象注入与检索以及跨轮次的状态保持。这有助于消除上下文漂移和数据处理中的损失。", "result": "在多项测试中，CaveAgent相较于其他方法有显著提升：零售任务成功率提高10.5%，多回合场景下总代币消耗减少28.4%；对于数据密集型任务，直接变量存储和检索可以节省高达59%的代币。", "conclusion": "CaveAgent通过引入状态化的运行时间管理机制成功解决了现有代理系统的局限性，并展示了其在复杂长跨度任务中的优越性能。"}}
{"id": "2601.01568", "pdf": "https://arxiv.org/pdf/2601.01568", "abs": "https://arxiv.org/abs/2601.01568", "authors": ["Chunyu Qiang", "Jun Wang", "Xiaopeng Wang", "Kang Yin", "Yuxin Guo", "Xijuan Zeng", "Nan Li", "Zihan Li", "Yuzhe Liang", "Ziyu Zhang", "Teng Ma", "Yushen Chen", "Zhongliang Liu", "Feng Deng", "Chen Zhang", "Pengfei Wan"], "title": "MM-Sonate: Multimodal Controllable Audio-Video Generation with Zero-Shot Voice Cloning", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.MM", "eess.AS"], "comment": null, "summary": "Joint audio-video generation aims to synthesize synchronized multisensory content, yet current unified models struggle with fine-grained acoustic control, particularly for identity-preserving speech. Existing approaches either suffer from temporal misalignment due to cascaded generation or lack the capability to perform zero-shot voice cloning within a joint synthesis framework. In this work, we present MM-Sonate, a multimodal flow-matching framework that unifies controllable audio-video joint generation with zero-shot voice cloning capabilities. Unlike prior works that rely on coarse semantic descriptions, MM-Sonate utilizes a unified instruction-phoneme input to enforce strict linguistic and temporal alignment. To enable zero-shot voice cloning, we introduce a timbre injection mechanism that effectively decouples speaker identity from linguistic content. Furthermore, addressing the limitations of standard classifier-free guidance in multimodal settings, we propose a noise-based negative conditioning strategy that utilizes natural noise priors to significantly enhance acoustic fidelity. Empirical evaluations demonstrate that MM-Sonate establishes new state-of-the-art performance in joint generation benchmarks, significantly outperforming baselines in lip synchronization and speech intelligibility, while achieving voice cloning fidelity comparable to specialized Text-to-Speech systems.", "AI": {"tldr": "MM-Sonate是一种多模态流匹配框架，用于联合生成控制音频视频和零样本语音克隆。", "motivation": "当前统一模型在细粒度声学控制方面存在困难，特别是保持身份一致的语音合成。现有方法要么由于级联生成而存在时间偏移问题，要么缺乏在联合合成框架中实现零样本语音克隆的能力。", "method": "MM-Sonate利用统一指令音素输入以严格执行语言和时间对齐，并引入音色注入机制解耦说话人身份与语义内容。此外，在多模态环境中的标准分类器自由指导的局限性下，提出了基于噪声的负条件策略来显著提高声学保真度。", "result": "MM-Sonate在联合生成基准测试中建立了新的性能记录，显着优于基线模型，特别是在唇部同步和语音可懂度方面，并实现了与专门的文本转语音系统相媲美的语音克隆保真度。", "conclusion": "该研究提出了一种新方法MM-Sonate，能够在联合生成的同时实现零样本语音克隆，解决了现有技术中的多个关键问题。"}}
{"id": "2601.01562", "pdf": "https://arxiv.org/pdf/2601.01562", "abs": "https://arxiv.org/abs/2601.01562", "authors": ["Mingyu Xu", "Cheng Fang", "Keyue Jiang", "Yuqian Zheng", "Yanghua Xiao", "Baojian Zhou", "Qifang Zhao", "Suhang Zheng", "Xiuwen Zhu", "Jiyang Tang", "Yongchi Zhao", "Yijia Luo", "Zhiqi Bai", "Yuchi Xu", "Wenbo Su", "Wei Wang", "Bing Zhao", "Lin Qu", "Xiaoxiao Xu"], "title": "Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement", "categories": ["cs.AI"], "comment": null, "summary": "We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technology, Engineering, and Mathematics (STEM), and exhibits exceptional performance on STEM-related benchmarks with an average improvement of 4.68% over the next-best model at 8B scale. We attribute the gains to our data-algorithm co-design engine, where they are jointly optimized to fit a gold-standard distribution behind reasoning. Data-wise, the Logics-STEM-SFT-Dataset is constructed from a meticulously designed data curation engine with 5 stages to ensure the quality, diversity, and scalability, including annotation, deduplication, decontamination, distillation, and stratified sampling. Algorithm-wise, our failure-driven post-training framework leverages targeted knowledge retrieval and data synthesis around model failure regions in the Supervised Fine-tuning (SFT) stage to effectively guide the second-stage SFT or the reinforcement learning (RL) for better fitting the target distribution. The superior empirical performance of Logics-STEM reveals the vast potential of combining large-scale open-source data with carefully designed synthetic data, underscoring the critical role of data-algorithm co-design in enhancing reasoning capabilities through post-training. We make both the Logics-STEM models (8B and 32B) and the Logics-STEM-SFT-Dataset (10M and downsampled 2.2M versions) publicly available to support future research in the open-source community.", "AI": {"tldr": "本文介绍了Logics-STEM，这是一个针对科学、技术、工程和数学（STEM）领域推理任务的先进模型。", "motivation": "为了提高大型语言模型在复杂长链思维推理上的表现，作者设计了一个高质量且多样化的数据集，并利用失败驱动后训练框架来优化模型性能。", "method": "通过精心构建的数据整理引擎生成10M规模的日志-STEM-SFT数据集。算法方面采用了失败驱动的后训练框架，该框架在监督微调阶段围绕模型失效区域进行知识检索和数据合成。", "result": "Logics-STEM在相关基准上表现出色，比同类最佳模型平均提高了4.68%。", "conclusion": "结合大规模开放源代码数据与精心设计的合成数据可以显著增强推理能力。"}}
{"id": "2601.01561", "pdf": "https://arxiv.org/pdf/2601.01561", "abs": "https://arxiv.org/abs/2601.01561", "authors": ["Yujian Qiu", "Yuqiu Mu", "Wen Yang", "Hao Zhu"], "title": "AIMS: An Adaptive Integration of Multi-Sensor Measurements for Quadrupedal Robot Localization", "categories": ["cs.RO"], "comment": null, "summary": "This paper addresses the problem of accurate localization for quadrupedal robots operating in narrow tunnel-like environments. Due to the long and homogeneous characteristics of such scenarios, LiDAR measurements often provide weak geometric constraints, making traditional sensor fusion methods susceptible to accumulated motion estimation errors. To address these challenges, we propose AIMS, an adaptive LiDAR-IMU-leg odometry fusion method for robust quadrupedal robot localization in degenerate environments. The proposed method is formulated within an error-state Kalman filtering framework, where LiDAR and leg odometry measurements are integrated with IMU-based state prediction, and measurement noise covariance matrices are adaptively adjusted based on online degeneracy-aware reliability assessment. Experimental results obtained in narrow corridor environments demonstrate that the proposed method improves localization accuracy and robustness compared with state-of-the-art approaches.", "AI": {"tldr": "提出了一种适应性融合多传感器数据的方法，以提高四足机器人在狭窄环境中的定位精度和鲁棒性", "motivation": "解决四足机器人在长且均匀的隧道环境中由于LiDAR测量提供的几何约束弱而导致的传统传感器融合方法容易累积运动估计误差的问题", "method": "通过在线退化感知可靠性评估自适应调整测量噪声协方差矩阵，在错误状态卡尔曼滤波框架下整合LiDAR和腿部里程计数据与IMU基于状态预测的融合方法AIMS", "result": "实验结果表明，所提出的方法相比于现有最佳方案在狭窄走廊环境中提高了定位精度和鲁棒性", "conclusion": "该研究有效解决了四足机器人在特殊环境下的定位问题，并展示了其优越性能"}}
{"id": "2601.01558", "pdf": "https://arxiv.org/pdf/2601.01558", "abs": "https://arxiv.org/abs/2601.01558", "authors": ["Pengfei Qu", "Wenyu Ouyang", "Chi Zhang", "Yikai Chai", "Shuolong Xu", "Lei Ye", "Yongri Piao", "Miao Zhang", "Huchuan Lu"], "title": "Utilizing Earth Foundation Models to Enhance the Simulation Performance of Hydrological Models with AlphaEarth Embeddings", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 11 figures", "summary": "Predicting river flow in places without streamflow records is challenging because basins respond differently to climate, terrain, vegetation, and soils. Traditional basin attributes describe some of these differences, but they cannot fully represent the complexity of natural environments. This study examines whether AlphaEarth Foundation embeddings, which are learned from large collections of satellite images rather than designed by experts, offer a more informative way to describe basin characteristics. These embeddings summarize patterns in vegetation, land surface properties, and long-term environmental dynamics. We find that models using them achieve higher accuracy when predicting flows in basins not used for training, suggesting that they capture key physical differences more effectively than traditional attributes. We further investigate how selecting appropriate donor basins influences prediction in ungauged regions. Similarity based on the embeddings helps identify basins with comparable environmental and hydrological behavior, improving performance, whereas adding many dissimilar basins can reduce accuracy. The results show that satellite-informed environmental representations can strengthen hydrological forecasting and support the development of models that adapt more easily to different landscapes.", "AI": {"tldr": "本文探索了利用AlphaEarth嵌入技术提高流域响应预测准确性的方法。", "motivation": "传统流域属性无法完全描述自然环境的复杂性，卫星图像学习得到的基础模型可能提供更丰富的信息来表示流域特征。", "method": "通过比较使用传统属性和AlphaEarth嵌入技术的水文模拟模型，评估其在未观测区域河流流量预测中的效果。同时研究了选择适当捐赠盆地的影响。", "result": "实验结果显示，采用AlphaEarth嵌入技术的模型能更准确地预测未经训练流域的水流，并且基于相似性选出合适盆地可以进一步提升预测性能。", "conclusion": "卫星图像提供的环境表示有助于加强水文预报能力，支持开发适应不同地貌特征的模型。"}}
{"id": "2601.01554", "pdf": "https://arxiv.org/pdf/2601.01554", "abs": "https://arxiv.org/abs/2601.01554", "authors": ["Donghua Yu", "Zhengyuan Lin", "Chen Yang", "Yiyang Zhang", "Zhaoye Fei", "Hanfu Chen", "Jingqi Chen", "Ke Chen", "Qinyuan Cheng", "Liwei Fan", "Yi Jiang", "Jie Zhu", "Muchen Li", "Shimin Li", "Wenxuan Wang", "Yang Wang", "Zhe Xu", "Yitian Gong", "Yuqian Zhang"], "title": "MOSS Transcribe Diarize: Accurate Transcription with Speaker Diarization", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Speaker-Attributed, Time-Stamped Transcription (SATS) aims to transcribe what is said and to precisely determine the timing of each speaker, which is particularly valuable for meeting transcription. Existing SATS systems rarely adopt an end-to-end formulation and are further constrained by limited context windows, weak long-range speaker memory, and the inability to output timestamps. To address these limitations, we present MOSS Transcribe Diarize, a unified multimodal large language model that jointly performs Speaker-Attributed, Time-Stamped Transcription in an end-to-end paradigm. Trained on extensive real wild data and equipped with a 128k context window for up to 90-minute inputs, MOSS Transcribe Diarize scales well and generalizes robustly. Across comprehensive evaluations, it outperforms state-of-the-art commercial systems on multiple public and in-house benchmarks.", "AI": {"tldr": "提出了一种用于准确转录和说话人识别的MOSS Transcribe Diarize模型。", "motivation": "现有的SATS系统大多采用非端到端的方法，受限于有限的时间窗口、较弱的长距离说话者记忆以及无法输出时间戳。为解决这些问题，研究团队开发了MOSS Transcribe Diarize模型。", "method": "MOSS Transcribe Diarize是一个统一的多模态大语言模型，能够在一个端到端的形式下执行说话人属性的时间戳转录任务，并且训练在大量的实际数据上，具备128k时间窗口，可以处理长达90分钟的输入。", "result": "通过广泛的评估，在多个公共和内部基准测试中，MOSS Transcribe Diarize的表现超过了现有的商业系统。", "conclusion": "提出的MOSS Transcribe Diarize在准确转录与说话人识别方面展示出卓越性能，并且具有良好的扩展性和泛化能力。"}}
{"id": "2601.01550", "pdf": "https://arxiv.org/pdf/2601.01550", "abs": "https://arxiv.org/abs/2601.01550", "authors": ["Shuo Zhou", "Zhaokai Pan", "Weiyuan Gong", "Tongyang Li"], "title": "Time-Dependent Hamiltonian Simulation in the Low-Energy Subspace", "categories": ["quant-ph", "cs.DS"], "comment": "29 pages, 1 figure", "summary": "Hamiltonian simulations are key subroutines in adiabatic quantum computation, quantum control, and quantum many-body physics, where quantum dynamics often happen in the low-energy sector. In contrast to time-independent Hamiltonian simulations, a comprehensive understanding of quantum simulation algorithms for time-dependent Hamiltonians under the low-energy assumption remains limited hitherto. In this paper, we investigate how much we can improve upon the standard performance guarantee assuming the initial state is supported on a low-energy subspace. In particular, we compute the Trotter number of digital quantum simulation based on product formulas for time-dependent spin Hamiltonians under the low-energy assumption that the initial state is supported on a small number of low-energy eigenstates, and show improvements over the standard cost for simulating full unitary simulations. Technically, we derive the low-energy simulation error with commutator scaling for product formulas by leveraging adiabatic perturbation theory to analyze the time-variant energy spectrum of the underlying Hamiltonian. We further discuss the applications to simulations of non-equilibrium quantum many-body dynamics and adiabatic state preparation. Finally, we prove a lower bound of query complexity for generic time-dependent Hamiltonian simulations.", "AI": {"tldr": "本文研究了在低能态假设下的时间依赖哈密顿量的量子模拟算法，并改进了标准性能保证。", "motivation": "传统的哈密顿量模拟主要针对时间独立的情况，而在实际应用中（如量子计算和控制），动态过程往往发生在低能区。因此，有必要研究在这种特定条件下的改进方案。", "method": "通过利用自旋哈密顿量的乘积公式，并借助阿达波特理论来分析随时间变化的能量谱，本文推导了在低能量假设下基于乘积公式的量子模拟误差。", "result": "结果表明，在初始状态支持于少数低能态的情况下，可以改进全幺正模拟的标准成本。此外，还证明了一般时间依赖哈密顿量仿真的查询复杂度的下界。", "conclusion": "本文提供了在特定假设下的时间依赖量子模拟算法，并展示了这些方法对于非平衡量子多体动力学和阿达波特态制备的应用价值。"}}
{"id": "2601.01547", "pdf": "https://arxiv.org/pdf/2601.01547", "abs": "https://arxiv.org/abs/2601.01547", "authors": ["Tianjun Gu", "Chenghua Gong", "Jingyu Gong", "Zhizhong Zhang", "Yuan Xie", "Lizhuang Ma", "Xin Tan"], "title": "EscherVerse: An Open World Benchmark and Dataset for Teleo-Spatial Intelligence with Physical-Dynamic and Intent-Driven Understanding", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The ability to reason about spatial dynamics is a cornerstone of intelligence, yet current research overlooks the human intent behind spatial changes. To address these limitations, we introduce Teleo-Spatial Intelligence (TSI), a new paradigm that unifies two critical pillars: Physical-Dynamic Reasoning--understanding the physical principles of object interactions--and Intent-Driven Reasoning--inferring the human goals behind these actions. To catalyze research in TSI, we present EscherVerse, consisting of a large-scale, open-world benchmark (Escher-Bench), a dataset (Escher-35k), and models (Escher series). Derived from real-world videos, EscherVerse moves beyond constrained settings to explicitly evaluate an agent's ability to reason about object permanence, state transitions, and trajectory prediction in dynamic, human-centric scenarios. Crucially, it is the first benchmark to systematically assess Intent-Driven Reasoning, challenging models to connect physical events to their underlying human purposes. Our work, including a novel data curation pipeline, provides a foundational resource to advance spatial intelligence from passive scene description toward a holistic, purpose-driven understanding of the world.", "AI": {"tldr": "论文提出了一个结合物理动态推理和意图驱动推理的新范式Teleo-Spatial Intelligence（TSI），并引入了EscherVerse基准测试集，以评估模型在复杂场景下的空间智能能力。", "motivation": "当前研究忽视了人类意图在空间变化中的作用，因此提出新的理解方式来整合物理动态理解和意图驱动推理。", "method": "通过真实世界视频建立一个大型开放世界的基准和数据集（Escher-35k），并设计了一系列模型以挑战对物理事件背后的人类目的的理解能力。", "result": "该研究为未来空间智能的研究提供了基础资源，特别是能够评估意图驱动推理的能力。", "conclusion": "提出的新范式TSI以及开发的基准数据集EscherVerse将有助于推动从被动场景描述到整体、目标导向的世界理解的发展。"}}
{"id": "2601.01546", "pdf": "https://arxiv.org/pdf/2601.01546", "abs": "https://arxiv.org/abs/2601.01546", "authors": ["Letian Kong", "Qianran", "Jin", "Renyu Zhang"], "title": "Improving Behavioral Alignment in LLM Social Simulations via Context Formation and Navigation", "categories": ["cs.AI"], "comment": "39 pages, 2 figures, 3 tables", "summary": "Large language models (LLMs) are increasingly used to simulate human behavior in experimental settings, but they systematically diverge from human decisions in complex decision-making environments, where participants must anticipate others' actions and form beliefs based on observed behavior. We propose a two-stage framework for improving behavioral alignment. The first stage, context formation, explicitly specifies the experimental design to establish an accurate representation of the decision task and its context. The second stage, context navigation, guides the reasoning process within that representation to make decisions. We validate this framework through a focal replication of a sequential purchasing game with quality signaling (Kremer and Debo, 2016), extending to a crowdfunding game with costly signaling (Cason et al., 2025) and a demand-estimation task (Gui and Toubia, 2025) to test generalizability across decision environments. Across four state-of-the-art (SOTA) models (GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1), we find that complex decision-making environments require both stages to achieve behavioral alignment with human benchmarks, whereas the simpler demand-estimation task requires only context formation. Our findings clarify when each stage is necessary and provide a systematic approach for designing and diagnosing LLM social simulations as complements to human subjects in behavioral research.", "AI": {"tldr": "论文提出了一种两阶段框架，通过上下文形成和导航来改善LLM在复杂决策环境中的行为一致性。", "motivation": "大型语言模型在模拟人类行为时，在复杂的决策环境中表现出与人类决策的偏差。本文旨在改进这些模型的行为表现，使其更加贴近真实的人类行为。", "method": "第一阶段是上下文形成，明确实验设计以准确表示决策任务和其背景；第二阶段为上下文导航，指导在这个表示中的推理过程来做出决策。", "result": "四个最先进的语言模型在复杂决策环境下的行为一致性通过两个阶段得以改善，在简单的估计需求任务中仅需第一个阶段即可获得良好表现。", "conclusion": "本文的框架明确了每个阶段的重要性，并提供了一种系统的方法来设计和诊断LLM的社会模拟，作为人类受试者的补充。"}}
{"id": "2601.01543", "pdf": "https://arxiv.org/pdf/2601.01543", "abs": "https://arxiv.org/abs/2601.01543", "authors": ["Praveenkumar Katwe", "RakeshChandra Balabantaray", "Kaliprasad Vittala"], "title": "Bridging the Data Gap: Creating a Hindi Text Summarization Dataset from the English XSUM", "categories": ["cs.CL", "cs.AI"], "comment": "Book chapter for River publications", "summary": "Current advancements in Natural Language Processing (NLP) have largely favored resource-rich languages, leaving a significant gap in high-quality datasets for low-resource languages like Hindi. This scarcity is particularly evident in text summarization, where the development of robust models is hindered by a lack of diverse, specialized corpora. To address this disparity, this study introduces a cost-effective, automated framework for creating a comprehensive Hindi text summarization dataset. By leveraging the English Extreme Summarization (XSUM) dataset as a source, we employ advanced translation and linguistic adaptation techniques. To ensure high fidelity and contextual relevance, we utilize the Crosslingual Optimized Metric for Evaluation of Translation (COMET) for validation, supplemented by the selective use of Large Language Models (LLMs) for curation. The resulting dataset provides a diverse, multi-thematic resource that mirrors the complexity of the original XSUM corpus. This initiative not only provides a direct tool for Hindi NLP research but also offers a scalable methodology for democratizing NLP in other underserved languages. By reducing the costs associated with dataset creation, this work fosters the development of more nuanced, culturally relevant models in computational linguistics.", "AI": {"tldr": "通过将英文XSUM数据集转化为高质量的印地语文本摘要数据集，以填补低资源语言NLP的数据空白。", "motivation": "当前自然语言处理技术主要侧重于丰富资源的语言，而像印地语这样的低资源语言缺乏高质量的数据集。为了弥补这一差距，该研究旨在创造一个全面的印地语文本摘要数据集。", "method": "利用先进的翻译和语言适应技术，并通过使用COMET进行验证以及选择性地采用大模型语言来确保高保真度和上下文相关性。", "result": "生成的数据集提供了一个多样化、多主题且反映原XSUM语料库复杂性的资源。这项研究不仅为印地语NLP研究提供了直接工具，还提出了一种可扩展的方法论。", "conclusion": "通过降低数据集创建成本，该工作促进了计算语言学中更细致入微的文化相关模型的发展"}}
{"id": "2601.01541", "pdf": "https://arxiv.org/pdf/2601.01541", "abs": "https://arxiv.org/abs/2601.01541", "authors": ["Antoine De Paepe", "Pascal Nguyen", "Michael Mabelle", "Cédric Saleun", "Antoine Jouadé", "Jean-Christophe Louvigne"], "title": "Sim2Real SAR Image Restoration: Metadata-Driven Models for Joint Despeckling and Sidelobes Reduction", "categories": ["eess.IV", "cs.CV", "eess.SP"], "comment": "Accepted at the Conference on Artificial Intelligence for Defense (CAID), 2025, Rennes, France", "summary": "Synthetic aperture radar (SAR) provides valuable information about the Earth's surface under all weather and illumination conditions. However, the inherent phenomenon of speckle and the presence of sidelobes around bright targets pose challenges for accurate interpretation of SAR imagery. Most existing SAR image restoration methods address despeckling and sidelobes reduction as separate tasks. In this paper, we propose a unified framework that jointly performs both tasks using neural networks (NNs) trained on a realistic SAR simulated dataset generated with MOCEM. Inference can then be performed on real SAR images, demonstrating effective simulation to real (Sim2Real) transferability. Additionally, we incorporate acquisition metadata as auxiliary input to the NNs, demonstrating improved restoration performance.", "AI": {"tldr": "本文提出了一种基于神经网络的统一框架，用于同时进行SAR图像去斑点和旁瓣抑制任务。", "motivation": "现有的SAR图像恢复方法通常将去斑点和旁瓣抑制视为独立的任务处理。文章旨在通过模拟数据训练神经网络，实现仿真到实际场景的有效迁移，并利用元数据提高恢复效果。", "method": "使用MOCEM生成的现实主义SAR仿真数据集对神经网络进行训练，并在真实SAR图像上执行推理以展示Sim2Real的转移性。此外，将获取元数据作为辅助输入到神经网络中。", "result": "提出的框架展示了有效的从模拟到实际场景的转换能力，并且通过利用元数据提高了恢复效果。", "conclusion": "本文的方法在SAR图像去斑点和旁瓣抑制方面取得了良好的结果，证明了Sim2Real方法的有效性以及利用元数据改进恢复性能的可能性。"}}
{"id": "2601.01539", "pdf": "https://arxiv.org/pdf/2601.01539", "abs": "https://arxiv.org/abs/2601.01539", "authors": ["Mohammad Mahdi Habibi Bina", "Sepideh Baghernezhad", "Mohammad Reza Daliri", "Mohammad Hassan Moradi"], "title": "Neural Digital Twins: Toward Next-Generation Brain-Computer Interfaces", "categories": ["cs.HC"], "comment": null, "summary": "Current neural interfaces such as brain-computer interfaces (BCIs) face several fundamental challenges, including frequent recalibration due to neuroplasticity and session-to-session variability, real-time processing latency, limited personalization and generalization across subjects, hardware constraints, surgical risks in invasive systems, and cognitive burden in patients with neurological impairments. These limitations significantly affect the accuracy, stability, and long-term usability of BCIs. This article introduces the concept of the Neural Digital Twin (NDT) as an advanced solution to overcome these barriers. NDT represents a dynamic, personalized computational model of the brain-BCI system that is continuously updated with real-time neural data, enabling prediction of brain states, optimization of control commands, and adaptive tuning of decoding algorithms. The design of NDT draws inspiration from the application of Digital Twin technology in advanced industries such as aerospace and autonomous vehicles, and leverages recent advances in artificial intelligence and neuroscience data acquisition technologies. In this work, we discuss the structure and implementation of NDT and explore its potential applications in next-generation BCIs and neural decoding, highlighting its ability to enhance precision, robustness, and individualized control in neurotechnology.", "AI": {"tldr": "本文提出了神经数字孪生（NDT）的概念，以克服当前脑机接口面临的挑战，并探讨其在下一代BCI和神经解码中的应用。", "motivation": "当前的神经接口如脑机接口面临多方面的基本问题，包括频繁重新校准、实时处理延迟、个性化不足等。这些问题严重影响了BCIs的准确性、稳定性和长期可用性。", "method": "NDT是一种动态个人化计算模型，它通过不断更新实时神经数据来预测大脑状态、优化控制命令和调整解码算法。", "result": "该方法有望提高脑机接口的技术精度、鲁棒性和个性化控制。", "conclusion": "本文展示了NDT的设计与实施，并强调了其在下一代BCI和神经技术中的潜力，能够增强精确性、稳健性和个体化控制。"}}
{"id": "2601.01537", "pdf": "https://arxiv.org/pdf/2601.01537", "abs": "https://arxiv.org/abs/2601.01537", "authors": ["Gong Gao", "Zekai Wang", "Xianhui Liu", "Weidong Zhao"], "title": "FAR-AMTN: Attention Multi-Task Network for Face Attribute Recognition", "categories": ["cs.CV"], "comment": "28 pages, 8figures", "summary": "To enhance the generalization performance of Multi-Task Networks (MTN) in Face Attribute Recognition (FAR), it is crucial to share relevant information across multiple related prediction tasks effectively. Traditional MTN methods create shared low-level modules and distinct high-level modules, causing an exponential increase in model parameters with the addition of tasks. This approach also limits feature interaction at the high level, hindering the exploration of semantic relations among attributes, thereby affecting generalization negatively. In response, this study introduces FAR-AMTN, a novel Attention Multi-Task Network for FAR. It incorporates a Weight-Shared Group-Specific Attention (WSGSA) module with shared parameters to minimize complexity while improving group feature representation. Furthermore, a Cross-Group Feature Fusion (CGFF) module is utilized to foster interactions between attribute groups, enhancing feature learning. A Dynamic Weighting Strategy (DWS) is also introduced for synchronized task convergence. Experiments on the CelebA and LFWA datasets demonstrate that the proposed FAR-AMTN demonstrates superior accuracy with significantly fewer parameters compared to existing models.", "AI": {"tldr": "FAR-AMTN是一种用于面部属性识别的新型注意多任务网络。", "motivation": "为了提高面部属性识别中多任务网络的一般化性能，需要有效共享相关信息以应对传统方法带来的模型参数复杂度和特征交互限制的问题。", "method": "通过引入Weight-Shared Group-Specific Attention模块、Cross-Group Feature Fusion模块以及Dynamic Weighting Strategy来改进现有方法中的问题。", "result": "实验结果表明FAR-AMTN在CelebA和LFWA数据集上相较于现有模型具有更高的精度且参数量更少。", "conclusion": "提出的方法FAR-AMTN能够有效解决多任务网络中因参数过多及特征交互不足导致的问题，提升面部属性识别的准确率。"}}
{"id": "2601.01535", "pdf": "https://arxiv.org/pdf/2601.01535", "abs": "https://arxiv.org/abs/2601.01535", "authors": ["Zixuan Fu", "Lanqing Guo", "Chong Wang", "Binbin Song", "Ding Liu", "Bihan Wen"], "title": "Improving Flexible Image Tokenizers for Autoregressive Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "Flexible image tokenizers aim to represent an image using an ordered 1D variable-length token sequence. This flexible tokenization is typically achieved through nested dropout, where a portion of trailing tokens is randomly truncated during training, and the image is reconstructed using the remaining preceding sequence. However, this tail-truncation strategy inherently concentrates the image information in the early tokens, limiting the effectiveness of downstream AutoRegressive (AR) image generation as the token length increases. To overcome these limitations, we propose \\textbf{ReToK}, a flexible tokenizer with \\underline{Re}dundant \\underline{Tok}en Padding and Hierarchical Semantic Regularization, designed to fully exploit all tokens for enhanced latent modeling. Specifically, we introduce \\textbf{Redundant Token Padding} to activate tail tokens more frequently, thereby alleviating information over-concentration in the early tokens. In addition, we apply \\textbf{Hierarchical Semantic Regularization} to align the decoding features of earlier tokens with those from a pre-trained vision foundation model, while progressively reducing the regularization strength toward the tail to allow finer low-level detail reconstruction. Extensive experiments demonstrate the effectiveness of ReTok: on ImageNet 256$\\times$256, our method achieves superior generation performance compared with both flexible and fixed-length tokenizers. Code will be available at: \\href{https://github.com/zfu006/ReTok}{https://github.com/zfu006/ReTok}", "AI": {"tldr": "本文提出了一种新的图像标记器ReToK，旨在改进自回归图像生成任务中的灵活图像标记化。", "motivation": "传统的尾部截断策略集中了早期令牌的信息，限制了自回归图像生成的效果。为了解决这个问题，研究者提出了冗余令牌填充和分层语义正则化方法。", "method": "该方法包含两个核心部分：冗余令牌填充激活更多尾部令牌，减少信息集中在早期令牌；分层语义正则化对早期令牌进行预训练模型的特征对齐，并逐步降低后期令牌的正则化强度。", "result": "实验表明，在ImageNet 256x256上，ReToK方法的生成效果优于现有的灵活和固定长度标记器。", "conclusion": "通过改进图像标记策略，新的Tokenizer ReToK可以更好地利用所有令牌进行自回归图像生成。"}}
{"id": "2601.01532", "pdf": "https://arxiv.org/pdf/2601.01532", "abs": "https://arxiv.org/abs/2601.01532", "authors": ["Fanzhe Fu"], "title": "Aletheia: Quantifying Cognitive Conviction in Reasoning Models via Regularized Inverse Confusion Matrix", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "6 pages, 2 figures", "summary": "In the progressive journey toward Artificial General Intelligence (AGI), current evaluation paradigms face an epistemological crisis. Static benchmarks measure knowledge breadth but fail to quantify the depth of belief. While Simhi et al. (2025) defined the CHOKE phenomenon in standard QA, we extend this framework to quantify \"Cognitive Conviction\" in System 2 reasoning models. We propose Project Aletheia, a cognitive physics framework that employs Tikhonov Regularization to invert the judge's confusion matrix. To validate this methodology without relying on opaque private data, we implement a Synthetic Proxy Protocol. Our preliminary pilot study on 2025 baselines (e.g., DeepSeek-R1, OpenAI o1) suggests that while reasoning models act as a \"cognitive buffer,\" they may exhibit \"Defensive OverThinking\" under adversarial pressure. Furthermore, we introduce the Aligned Conviction Score (S_aligned) to verify that conviction does not compromise safety. This work serves as a blueprint for measuring AI scientific integrity.", "AI": {"tldr": "本文提出了一个认知物理学框架Aletheia，用于量化推理模型中的认知确信度。", "motivation": "当前的人工智能评估方法侧重于知识广度的测量而忽视了信念深度的量度。为了填补这一空白，作者引入了“认知确信度”概念，并开发了相应的量化方法。", "method": "通过Tikhonov正则化逆向混淆矩阵以及合成代理协议验证该框架的有效性。还定义了一个称为“对齐确信分数”的指标来确保确信度不会损害AI的安全性。", "result": "初步研究结果表明，推理模型在面对对抗压力时表现出认知缓冲效应和防御过度思考的行为。", "conclusion": "这项工作提供了一种衡量人工智能科学诚信的新途径，并为未来的研究奠定了基础。"}}
{"id": "2601.01530", "pdf": "https://arxiv.org/pdf/2601.01530", "abs": "https://arxiv.org/abs/2601.01530", "authors": ["Jing Ye", "Lu Xiang", "Yaping Zhang", "Chengqing Zong"], "title": "EmoHarbor: Evaluating Personalized Emotional Support by Simulating the User's Internal World", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Current evaluation paradigms for emotional support conversations tend to reward generic empathetic responses, yet they fail to assess whether the support is genuinely personalized to users' unique psychological profiles and contextual needs. We introduce EmoHarbor, an automated evaluation framework that adopts a User-as-a-Judge paradigm by simulating the user's inner world. EmoHarbor employs a Chain-of-Agent architecture that decomposes users' internal processes into three specialized roles, enabling agents to interact with supporters and complete assessments in a manner similar to human users. We instantiate this benchmark using 100 real-world user profiles that cover a diverse range of personality traits and situations, and define 10 evaluation dimensions of personalized support quality. Comprehensive evaluation of 20 advanced LLMs on EmoHarbor reveals a critical insight: while these models excel at generating empathetic responses, they consistently fail to tailor support to individual user contexts. This finding reframes the central challenge, shifting research focus from merely enhancing generic empathy to developing truly user-aware emotional support. EmoHarbor provides a reproducible and scalable framework to guide the development and evaluation of more nuanced and user-aware emotional support systems.", "AI": {"tldr": "EmoHarbor是一款评估情感支持对话个性化程度的自动化框架，它通过模拟用户内心世界来评价支持系统是否符合用户的独特心理特征和情境需求。", "motivation": "现有的评估标准倾向于奖励通用的同理心回应而忽略了个性化的关注。作者希望通过一种新的评估方法解决这一问题，确保提供的支持是真正针对个人的独特情况和心理状况的。", "method": "EmoHarbor采用用户作为评判者的模式，并利用链式代理架构模拟用户的内心世界。该框架使用100个真实世界的用户档案进行实例化，涵盖了多样化的个性特征和情境，定义了十个个性化支持质量评估维度。", "result": "通过对20种先进的LLM在EmoHarbor上的综合评价发现，尽管这些模型能够生成有同理心的回应，但它们在根据个人具体情况进行调整方面表现不佳。这表明研究的重点应从提高通用同理心转向开发真正了解用户的系统。", "conclusion": "EmoHarbor提供了一种可重现和规模化的框架来指导更细致、用户意识更强的情感支持系统的开发与评估"}}
{"id": "2601.01528", "pdf": "https://arxiv.org/pdf/2601.01528", "abs": "https://arxiv.org/abs/2601.01528", "authors": ["Yang Zhou", "Hao Shao", "Letian Wang", "Zhuofan Zong", "Hongsheng Li", "Steven L. Waslander"], "title": "DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "10 pages, 4 figures; Project Website: https://drivinggen-bench.github.io/", "summary": "Video generation models, as one form of world models, have emerged as one of the most exciting frontiers in AI, promising agents the ability to imagine the future by modeling the temporal evolution of complex scenes. In autonomous driving, this vision gives rise to driving world models: generative simulators that imagine ego and agent futures, enabling scalable simulation, safe testing of corner cases, and rich synthetic data generation. Yet, despite fast-growing research activity, the field lacks a rigorous benchmark to measure progress and guide priorities. Existing evaluations remain limited: generic video metrics overlook safety-critical imaging factors; trajectory plausibility is rarely quantified; temporal and agent-level consistency is neglected; and controllability with respect to ego conditioning is ignored. Moreover, current datasets fail to cover the diversity of conditions required for real-world deployment. To address these gaps, we present DrivingGen, the first comprehensive benchmark for generative driving world models. DrivingGen combines a diverse evaluation dataset curated from both driving datasets and internet-scale video sources, spanning varied weather, time of day, geographic regions, and complex maneuvers, with a suite of new metrics that jointly assess visual realism, trajectory plausibility, temporal coherence, and controllability. Benchmarking 14 state-of-the-art models reveals clear trade-offs: general models look better but break physics, while driving-specific ones capture motion realistically but lag in visual quality. DrivingGen offers a unified evaluation framework to foster reliable, controllable, and deployable driving world models, enabling scalable simulation, planning, and data-driven decision-making.", "AI": {"tldr": "DrivingGen 是一个为自动驾驶生成视频世界模型设计的全面基准。", "motivation": "现有研究缺乏严格的评估标准，忽视了关键的安全因素、轨迹合理性、时间和代理一致性以及基于自我条件控制的能力。此外，当前数据集无法涵盖实际部署所需的多样性。", "method": "结合从驾驶和互联网规模视频来源中整理出的多样化评估数据集，以及一系列新的指标来综合评估视觉真实性、轨迹合理性、时间连贯性和可控性。", "result": "通过基准测试14种最先进的模型发现明显的权衡：通用模型外观更好但违背物理定律，而特定于驾驶的模型捕捉运动更真实但在视觉质量上滞后。", "conclusion": "DrivingGen 提供了一个统一的评估框架以推动可靠、可控和可部署的自动驾驶世界模型的发展。"}}
{"id": "2601.01526", "pdf": "https://arxiv.org/pdf/2601.01526", "abs": "https://arxiv.org/abs/2601.01526", "authors": ["Hongbing Li", "Linhui Xiao", "Zihan Zhao", "Qi Shen", "Yixiang Huang", "Bo Xiao", "Zhanyu Ma"], "title": "BARE: Towards Bias-Aware and Reasoning-Enhanced One-Tower Visual Grounding", "categories": ["cs.CV"], "comment": null, "summary": "Visual Grounding (VG), which aims to locate a specific region referred to by expressions, is a fundamental yet challenging task in the multimodal understanding fields. While recent grounding transfer works have advanced the field through one-tower architectures, they still suffer from two primary limitations: (1) over-entangled multimodal representations that exacerbate deceptive modality biases, and (2) insufficient semantic reasoning that hinders the comprehension of referential cues. In this paper, we propose BARE, a bias-aware and reasoning-enhanced framework for one-tower visual grounding. BARE introduces a mechanism that preserves modality-specific features and constructs referential semantics through three novel modules: (i) language salience modulator, (ii) visual bias correction and (iii) referential relationship enhancement, which jointly mitigate multimodal distractions and enhance referential comprehension. Extensive experimental results on five benchmarks demonstrate that BARE not only achieves state-of-the-art performance but also delivers superior computational efficiency compared to existing approaches. The code is publicly accessible at https://github.com/Marloweeee/BARE.", "AI": {"tldr": "本文提出了一种名为BARE的框架，旨在解决视觉定位任务中多模态表示过于纠缠和缺乏语义推理的问题。", "motivation": "尽管一塔架构在视觉定位领域取得了进展，但仍然存在两个主要问题：一是过高的多模态表示使欺骗性模式偏差加剧；二是不足的语义推理限制了对指示线索的理解。", "method": "BARE通过三种新颖模块——语言显著度调制器、视觉偏差修正和指示关系增强来保留特定的模态特征并构造参考语义，从而减轻多模态干扰并提升参照理解。", "result": "实验结果表明，BARE在五个基准测试中均实现了最先进的性能，并且与现有方法相比具有更优的计算效率。", "conclusion": "本文提出的BARE框架能够有效地解决视觉定位任务中的挑战性问题，并通过减轻多模态干扰和增强语义推理来提高性能。"}}
{"id": "2601.01522", "pdf": "https://arxiv.org/pdf/2601.01522", "abs": "https://arxiv.org/abs/2601.01522", "authors": ["Danial Amin"], "title": "Bayesian Orchestration of Multi-LLM Agents for Cost-Aware Sequential Decision-Making", "categories": ["cs.AI", "cs.CL", "cs.ET"], "comment": null, "summary": "Large language models (LLMs) are increasingly deployed as autonomous decision agents in settings with asymmetric error costs: hiring (missed talent vs wasted interviews), medical triage (missed emergencies vs unnecessary escalation), and fraud detection (approved fraud vs declined legitimate payments). The dominant design queries a single LLM for a posterior over states, thresholds \"confidence,\" and acts; we prove this is inadequate for sequential decisions with costs. We propose a Bayesian, cost-aware multi-LLM orchestration framework that treats LLMs as approximate likelihood models rather than classifiers. For each candidate state, we elicit likelihoods via contrastive prompting, aggregate across diverse models with robust statistics, and update beliefs with Bayes rule under explicit priors as new evidence arrives. This enables coherent belief updating, expected-cost action selection, principled information gathering via value of information, and fairness gains via ensemble bias mitigation. In resume screening with costs of 40000 USD per missed hire, 2500 USD per interview, and 150 USD per phone screen, experiments on 1000 resumes using five LLMs (GPT-4o, Claude 4.5 Sonnet, Gemini Pro, Grok, DeepSeek) reduce total cost by 294000 USD (34 percent) versus the best single-LLM baseline and improve demographic parity by 45 percent (max group gap 22 to 5 percentage points). Ablations attribute 51 percent of savings to multi-LLM aggregation, 43 percent to sequential updating, and 20 percent to disagreement-triggered information gathering, consistent with the theoretical benefits of correct probabilistic foundations.", "AI": {"tldr": "研究提出了一种基于贝叶斯理论的多LLM决策框架，用于处理具有不对称成本错误场景下的顺序决策。", "motivation": "单一LLM在面对顺序决策和不对称成本时表现不佳。因此，研究旨在通过结合多个LLM来提高决策的质量。", "method": "提出了一种贝叶斯、成本意识的多LLM协调框架，该框架利用对比提示从不同的模型中获取似然性，并使用Bayes法则进行信念更新。这个方法包括了信息收集和价值评估。", "result": "实验表明，在简历筛选场景下，研究的方法相对于最佳单个LLM基线降低了294000美元（34%）的成本，并且提高了人口统计数据的公平性。", "conclusion": "通过这种方法不仅可以减少成本，还可以提高决策准确性并改进偏见缓解。"}}
{"id": "2601.01513", "pdf": "https://arxiv.org/pdf/2601.01513", "abs": "https://arxiv.org/abs/2601.01513", "authors": ["Gen Li", "Peiyu Liu"], "title": "FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a lightweight draft model quickly generates multiple answer candidates, which are then verified and refined by a more accurate heavyweight model, substantially reducing inference latency without sacrificing correctness. Second, we identify a major source of error - incorrect entity recognition in retrieved knowledge - and mitigate it with a simple yet effective similarity-based filtering strategy that improves entity alignment and boosts overall answer accuracy. Experiments demonstrate that VideoSpeculateRAG achieves comparable or higher accuracy than standard RAG approaches while accelerating inference by approximately 2x. Our framework highlights the potential of combining speculative decoding with retrieval-augmented reasoning to enhance efficiency and reliability in complex, knowledge-intensive multimodal tasks.", "AI": {"tldr": "提出了一种高效、精确的视频问答系统VideoSpeculateRAG，结合了轻量级草稿模型和重型验证模型，并引入相似度过滤策略以提高实体对齐准确性。", "motivation": "现有VLM方法在处理外部知识时效率低且答案质量不高，旨在通过新颖的方法提升视频问答系统的效率和准确性。", "method": "采用了一种投机解码流水线：轻量级草稿模型快速生成多个候选答案，再由重型验证模型进行核实与修正；同时引入相似度过滤策略以增强实体对齐的精度。", "result": "实验表明，VideoSpeculateRAG在保持或提高准确率的同时，将推理速度提升了约2倍。", "conclusion": "研究展示了结合投机解码和检索增强推理的方法能够有效提升复杂多模态任务中的效率与可靠性。"}}
{"id": "2601.01512", "pdf": "https://arxiv.org/pdf/2601.01512", "abs": "https://arxiv.org/abs/2601.01512", "authors": ["Wenhui Chu", "Aobo Jin", "Hardik A. Gohel"], "title": "A Novel Deep Learning Method for Segmenting the Left Ventricle in Cardiac Cine MRI", "categories": ["cs.CV", "cs.LG"], "comment": "9 pages, 5 figures", "summary": "This research aims to develop a novel deep learning network, GBU-Net, utilizing a group-batch-normalized U-Net framework, specifically designed for the precise semantic segmentation of the left ventricle in short-axis cine MRI scans. The methodology includes a down-sampling pathway for feature extraction and an up-sampling pathway for detail restoration, enhanced for medical imaging. Key modifications include techniques for better contextual understanding crucial in cardiac MRI segmentation. The dataset consists of 805 left ventricular MRI scans from 45 patients, with comparative analysis using established metrics such as the dice coefficient and mean perpendicular distance. GBU-Net significantly improves the accuracy of left ventricle segmentation in cine MRI scans. Its innovative design outperforms existing methods in tests, surpassing standard metrics like the dice coefficient and mean perpendicular distance. The approach is unique in its ability to capture contextual information, often missed in traditional CNN-based segmentation. An ensemble of the GBU-Net attains a 97% dice score on the SunnyBrook testing dataset. GBU-Net offers enhanced precision and contextual understanding in left ventricle segmentation for surgical robotics and medical analysis.", "AI": {"tldr": "开发了一种新型深度学习网络GBU-Net，用于心脏短轴电影MRI扫描中左心室的精准分割。", "motivation": "为了提高心脏短轴电影MRI扫描中左心室分割的准确性，提出了一种新的深度学习方法GBU-Net。", "method": "利用群体批规范化U-Net框架设计了一个新型深度学习网络GBU-Net，包括特征提取的下采样路径和细节恢复的上采样路径，并进行了关键的技术改进以提高对上下文信息的理解。", "result": "在SunnyBrook测试数据集上，GBU-Net达到了97%的Dice分数，优于现有的方法，在传统的CNN分割中经常错过的重要上下文信息捕捉方面表现出色。", "conclusion": "GBU-Net提供了一种增强左心室分割精度和上下文理解的方法，适用于外科机器人和医学分析等领域。"}}
{"id": "2601.01511", "pdf": "https://arxiv.org/pdf/2601.01511", "abs": "https://arxiv.org/abs/2601.01511", "authors": ["Ahmed Dawoud", "Osama El-Shamy"], "title": "Reading Between the Lines: Deconfounding Causal Estimates using Text Embeddings and Deep Learning", "categories": ["cs.AI"], "comment": null, "summary": "Estimating causal treatment effects in observational settings is frequently compromised by selection bias arising from unobserved confounders. While traditional econometric methods struggle when these confounders are orthogonal to structured covariates, high-dimensional unstructured text often contains rich proxies for these latent variables. This study proposes a Neural Network-Enhanced Double Machine Learning (DML) framework designed to leverage text embeddings for causal identification. Using a rigorous synthetic benchmark, we demonstrate that unstructured text embeddings capture critical confounding information that is absent from structured tabular data. However, we show that standard tree-based DML estimators retain substantial bias (+24%) due to their inability to model the continuous topology of embedding manifolds. In contrast, our deep learning approach reduces bias to -0.86% with optimized architectures, effectively recovering the ground-truth causal parameter. These findings suggest that deep learning architectures are essential for satisfying the unconfoundedness assumption when conditioning on high-dimensional natural language data", "AI": {"tldr": "利用深度学习和文本嵌入改进因果效应估计。", "motivation": "在观察性设置中，未观察到的混杂因素会导致选择偏差，传统计量经济学方法难以处理这些问题。但是，高维非结构化文本可能包含这些潜在变量的重要代理信息。", "method": "提出了一种神经网络增强型双重机器学习(DML)框架，该框架利用文本嵌入进行因果识别，并展示了深度学习架构在解决高维自然语言数据中的混杂问题上的优势。", "result": "通过严格的合成基准测试表明，基于树的方法存在较大偏差（+24%），而优化的深层网络则将偏差降至-0.86%，准确恢复了真实的因果参数。", "conclusion": "深度学习架构对于在高维自然语言数据上满足无混杂假设至关重要。"}}
{"id": "2601.01507", "pdf": "https://arxiv.org/pdf/2601.01507", "abs": "https://arxiv.org/abs/2601.01507", "authors": ["Tao Li", "Qing Li", "Na Li", "Hui Xie"], "title": "DiffKD-DCIS: Predicting Upgrade of Ductal Carcinoma In Situ with Diffusion Augmentation and Knowledge Distillation", "categories": ["cs.CV"], "comment": null, "summary": "Accurately predicting the upgrade of ductal carcinoma in situ (DCIS) to invasive ductal carcinoma (IDC) is crucial for surgical planning. However, traditional deep learning methods face challenges due to limited ultrasound data and poor generalization ability. This study proposes the DiffKD-DCIS framework, integrating conditional diffusion modeling with teacher-student knowledge distillation. The framework operates in three stages: First, a conditional diffusion model generates high-fidelity ultrasound images using multimodal conditions for data augmentation. Then, a deep teacher network extracts robust features from both original and synthetic data. Finally, a compact student network learns from the teacher via knowledge distillation, balancing generalization and computational efficiency. Evaluated on a multi-center dataset of 1,435 cases, the synthetic images were of good quality. The student network had fewer parameters and faster inference. On external test sets, it outperformed partial combinations, and its accuracy was comparable to senior radiologists and superior to junior ones, showing significant clinical potential.", "AI": {"tldr": "提出了一种基于扩散模型和知识蒸馏的DiffKD-DCIS框架，用于预测乳腺导管内癌（DCIS）升级为侵袭性导管癌（IDC），该方法结合了数据增强与特征提取，提高了诊断准确性。", "motivation": "传统深度学习方法在有限超声数据下难以准确预测DCIS升级，并且泛化能力较差。提出一种新框架以解决这些问题，提高手术计划的精确性和可靠性。", "method": "引入DiffKD-DCIS框架：第一阶段利用条件扩散模型生成高保真度的合成图像；第二阶段深度教师网络从原始和合成数据中提取特征；第三阶段紧凑学生网络通过知识蒸馏学习教师网络的知识，实现泛化能力和计算效率之间的平衡。", "result": "在包含1435个病例的数据集上进行评估，生成的合成图像是高质量的。学生网络参数少、推理速度快，并且在外测试集中优于部分组合模型，准确率可与资深放射科医师媲美，高于初级医师水平。", "conclusion": "DiffKD-DCIS框架通过结合数据增强和特征提取技术，在提高诊断准确性方面显示出显著临床应用潜力。"}}
{"id": "2601.01496", "pdf": "https://arxiv.org/pdf/2601.01496", "abs": "https://arxiv.org/abs/2601.01496", "authors": ["Mikael Møller Høgsgaard"], "title": "The Optimal Sample Complexity of Linear Contracts", "categories": ["cs.GT", "cs.AI", "cs.LG"], "comment": null, "summary": "In this paper, we settle the problem of learning optimal linear contracts from data in the offline setting, where agent types are drawn from an unknown distribution and the principal's goal is to design a contract that maximizes her expected utility. Specifically, our analysis shows that the simple Empirical Utility Maximization (EUM) algorithm yields an $\\varepsilon$-approximation of the optimal linear contract with probability at least $1-δ$, using just $O(\\ln(1/δ) / \\varepsilon^2)$ samples. This result improves upon previously known bounds and matches a lower bound from Duetting et al. [2025] up to constant factors, thereby proving its optimality. Our analysis uses a chaining argument, where the key insight is to leverage a simple structural property of linear contracts: their expected reward is non-decreasing. This property, which holds even though the utility function itself is non-monotone and discontinuous, enables the construction of fine-grained nets required for the chaining argument, which in turn yields the optimal sample complexity. Furthermore, our proof establishes the stronger guarantee of uniform convergence: the empirical utility of every linear contract is a $\\varepsilon$-approximation of its true expectation with probability at least $1-δ$, using the same optimal $O(\\ln(1/δ) / \\varepsilon^2)$ sample complexity.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.01490", "pdf": "https://arxiv.org/pdf/2601.01490", "abs": "https://arxiv.org/abs/2601.01490", "authors": ["Junichiro Niimi"], "title": "Distortion Instead of Hallucination: The Effect of Reasoning Under Strict Constraints", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "With the widespread adoption of large language models (LLMs), hallucinations, which are non-factual fabrications in model outputs, have become serious concerns. Reasoning capabilities have received attention as a self-verification process to improve output reliability. However, the effect of reasoning within a closed system where LLMs cannot rely on external tools or knowledge has yet to be clarified. We therefore conduct experiments under strict constraints (recommending peer-reviewed journal articles in computer science) to examine the effect of reasoning across multiple models (GPT-5.2 and Gemini 3 Flash). Our results reveal a problematic trade-off between constraint compliance and factual accuracy. Non-reasoning models exhibit high constraint violation rates (66-75%) but maintain factual accuracy, while reasoning models reduce violations (13-26%) but systematically distort known facts to satisfy constraints and increase complete fabrication. This trade-off pattern is consistent across both models despite different architectures, indicating a fundamental limitation of reasoning. Furthermore, reasoning does not uniformly improve output authenticity: effects diverge by model, reflecting different allocations of the compliance-truthfulness trade-off. These findings challenge the assumption that reasoning universally improves reliability: reasoning models trade honest constraint violations for detection-resistant distortions.", "AI": {"tldr": "本文探讨了在严格约束条件下，大型语言模型（LLM）中的推理能力对其输出真实性和合规性的影响。", "motivation": "随着大型语言模型的广泛应用，其生成非事实信息的现象引起了广泛关注。为了验证在封闭系统中推理对提高模型可靠性的效果，作者进行了相关实验研究。", "method": "通过限制条件（推荐计算机科学领域的同行评审期刊文章），作者比较了具有和不具推理能力的两个模型（GPT-5.2 和 Gemini 3 Flash）的表现。", "result": "实验结果显示，在严格约束条件下，非推理模型虽然准确性较高但合规性较差；而推理模型虽然降低了违规率却增加了对已知事实的扭曲。", "conclusion": "研究结果表明，推理并不总是能提高输出的可靠性：它可能会牺牲真实性的部分来换取更难以检测到的扭曲。"}}
{"id": "2601.01487", "pdf": "https://arxiv.org/pdf/2601.01487", "abs": "https://arxiv.org/abs/2601.01487", "authors": ["Ziyue Zhang", "Luxi Lin", "Xiaolin Hu", "Chao Chang", "HuaiXi Wang", "Yiyi Zhou", "Rongrong Ji"], "title": "DeepInv: A Novel Self-supervised Learning Approach for Fast and Accurate Diffusion Inversion", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diffusion inversion is a task of recovering the noise of an image in a diffusion model, which is vital for controllable diffusion image editing. At present, diffusion inversion still remains a challenging task due to the lack of viable supervision signals. Thus, most existing methods resort to approximation-based solutions, which however are often at the cost of performance or efficiency. To remedy these shortcomings, we propose a novel self-supervised diffusion inversion approach in this paper, termed Deep Inversion (DeepInv). Instead of requiring ground-truth noise annotations, we introduce a self-supervised objective as well as a data augmentation strategy to generate high-quality pseudo noises from real images without manual intervention. Based on these two innovative designs, DeepInv is also equipped with an iterative and multi-scale training regime to train a parameterized inversion solver, thereby achieving the fast and accurate image-to-noise mapping. To the best of our knowledge, this is the first attempt of presenting a trainable solver to predict inversion noise step by step. The extensive experiments show that our DeepInv can achieve much better performance and inference speed than the compared methods, e.g., +40.435% SSIM than EasyInv and +9887.5% speed than ReNoise on COCO dataset. Moreover, our careful designs of trainable solvers can also provide insights to the community. Codes and model parameters will be released in https://github.com/potato-kitty/DeepInv.", "AI": {"tldr": "提出了一种新的自监督学习方法DeepInv，用于快速准确的扩散逆向过程。", "motivation": "现有方法大多采用近似解决方案进行扩散逆向任务，效果或效率不足。因此提出了无需真值噪声标签的自监督目标及数据增强策略来生成高质量伪噪声。", "method": "通过引入自监督目标和数据增强策略生成伪噪声，并使用迭代多尺度训练方案训练参数化逆向解算器以实现快速准确地映射图像到噪声。", "result": "实验表明，DeepInv在性能上比EasyInv高40.435%，速度上比ReNoise快9887.5%。此外，该设计还为社区提供了见解。", "conclusion": "首次提出了一个可训练的逆向解算器来逐步预测逆向噪声，证明了其在性能和效率上的优越性，并计划公开代码和模型参数。"}}
{"id": "2601.01485", "pdf": "https://arxiv.org/pdf/2601.01485", "abs": "https://arxiv.org/abs/2601.01485", "authors": ["Zobia Batool", "Diala Lteif", "Vijaya B. Kolachalama", "Huseyin Ozkan", "Erchan Aptoula"], "title": "Higher-Order Domain Generalization in Magnetic Resonance-Based Assessment of Alzheimer's Disease", "categories": ["cs.CV"], "comment": null, "summary": "Despite progress in deep learning for Alzheimer's disease (AD) diagnostics, models trained on structural magnetic resonance imaging (sMRI) often do not perform well when applied to new cohorts due to domain shifts from varying scanners, protocols and patient demographics. AD, the primary driver of dementia, manifests through progressive cognitive and neuroanatomical changes like atrophy and ventricular expansion, making robust, generalizable classification essential for real-world use. While convolutional neural networks and transformers have advanced feature extraction via attention and fusion techniques, single-domain generalization (SDG) remains underexplored yet critical, given the fragmented nature of AD datasets. To bridge this gap, we introduce Extended MixStyle (EM), a framework for blending higher-order feature moments (skewness and kurtosis) to mimic diverse distributional variations. Trained on sMRI data from the National Alzheimer's Coordinating Center (NACC; n=4,647) to differentiate persons with normal cognition (NC) from those with mild cognitive impairment (MCI) or AD and tested on three unseen cohorts (total n=3,126), EM yields enhanced cross-domain performance, improving macro-F1 on average by 2.4 percentage points over state-of-the-art SDG benchmarks, underscoring its promise for invariant, reliable AD detection in heterogeneous real-world settings. The source code will be made available upon acceptance at https://github.com/zobia111/Extended-Mixstyle.", "AI": {"tldr": "提出了一种新的框架Extended MixStyle（EM），用于通过混合高阶特征矩来模拟多样化的分布变化，以提高阿尔茨海默病诊断模型的泛化能力。", "motivation": "现有深度学习模型在结构性磁共振成像数据上的训练通常无法很好地应用于新人群，因为存在不同的扫描仪、协议和患者人口统计学差异。因此，需要一种新的方法来增强跨域性能，以实现在真实世界中的可靠诊断。", "method": "引入了Extended MixStyle（EM）框架，该框架通过混合高阶特征矩（偏度和峰度），模拟多样化的分布变化，并在来自全国阿尔茨海默病协调中心的数据上训练模型。", "result": "与现有的单域泛化基准相比，EM方法在三个未见过的队列中提高了2.4个百分点的平均宏F1分数。", "conclusion": "Extended MixStyle（EM）框架通过模拟高阶特征矩的变化，成功地提高了跨域性能，在异质的真实世界环境中为可靠的阿尔茨海默病检测提供了潜在的价值。"}}
{"id": "2601.01483", "pdf": "https://arxiv.org/pdf/2601.01483", "abs": "https://arxiv.org/abs/2601.01483", "authors": ["Xinyu Qiu", "Heng Jia", "Zhengwen Zeng", "Shuheng Shen", "Changhua Meng", "Yi Yang", "Linchao Zhu"], "title": "Unified Generation and Self-Verification for Vision-Language Models via Advantage Decoupled Preference Optimization", "categories": ["cs.CV"], "comment": null, "summary": "Parallel test-time scaling typically trains separate generation and verification models, incurring high training and inference costs. We propose Advantage Decoupled Preference Optimization (ADPO), a unified reinforcement learning framework that jointly learns answer generation and self-verification within a single policy. ADPO introduces two innovations: a preference verification reward improving verification capability and a decoupled optimization mechanism enabling synergistic optimization of generation and verification. Specifically, the preference verification reward computes mean verification scores from positive and negative samples as decision thresholds, providing positive feedback when prediction correctness aligns with answer correctness. Meanwhile, the advantage decoupled optimization computes separate advantages for generation and verification, applies token masks to isolate gradients, and combines masked GRPO objectives, preserving generation quality while calibrating verification scores. ADPO achieves up to +34.1% higher verification AUC and -53.5% lower inference time, with significant gains of +2.8%/+1.4% accuracy on MathVista/MMMU, +1.9 cIoU on ReasonSeg, and +1.7%/+1.0% step success rate on AndroidControl/GUI Odyssey.", "AI": {"tldr": "本文提出了一种统一生成和自我验证的框架，通过优势解耦偏好优化（ADPO），旨在减少测试时扩展的成本。", "motivation": "并行测试时放大通常需要训练独立的生成模型和验证模型，导致高昂的训练和推理成本。本文希望通过一个统一的学习框架来降低成本。", "method": "ADPO引入了两个创新点：偏好验证奖励以提高验证能力；优势解耦优化机制以实现生成与验证的协同优化。具体而言，通过计算正负样本均值作为决策阈值提供反馈，并使用掩码隔离梯度结合GRPO目标来保留生成质量。", "result": "ADPO实现了高达34.1%更高的验证AUC和53.5%更低的推理时间，在MathVista/MMMU上获得了2.8%/1.4%准确率增长，ReasonSeg上提高了1.9 cIoU，AndroidControl/GUI Odyssey上提升了1.7%/1.0%步骤成功率。", "conclusion": "ADPO框架在保持生成质量的同时显著增强了自我验证的能力，证明了其有效性和效率。"}}
{"id": "2601.01481", "pdf": "https://arxiv.org/pdf/2601.01481", "abs": "https://arxiv.org/abs/2601.01481", "authors": ["Mohammad Hassan Saghafi", "Seyed Majid Noorhosseini", "Seyed Abolfazl Seyed Javadein", "Hadi Khalili"], "title": "Robust Ship Detection and Tracking Using Modified ViBe and Backwash Cancellation Algorithm", "categories": ["cs.CV"], "comment": "ef:Proc. Int. Conf. on Computational Intelligence and Information Technology, CIIT 2012", "summary": "In this paper, we propose a robust real time detection and tracking method for detecting ships in a coastal video sequences. Since coastal scenarios are unpredictable and scenes have dynamic properties it is essential to apply detection methods that are robust to these conditions. This paper presents modified ViBe for moving object detection which detects ships and backwash. In the modified ViBe the probability of losing ships is decreased in comparison with the original ViBe. It is robust to natural sea waves and variation of lights and is capable of quickly updating the background. Based on geometrical properties of ship and some concepts such as brightness distortion, a new method for backwash cancellation is proposed. Experimental results demonstrate that the proposed strategy and methods have outstanding performance in ship detection and tracking. These results also illustrate real time and precise performance of the proposed strategy.", "AI": {"tldr": "本文提出了一种基于改进ViBe算法和背波消除技术的实时船舶检测与跟踪方法。", "motivation": "由于沿海场景不可预测且动态变化，因此需要开发一种能够应对这些条件的强大检测方法。", "method": "采用改进的ViBe算法实现移动目标检测，并利用几何属性及亮度失真概念提出了一种新的背波消除技术。", "result": "实验结果表明所提出的策略和方法在船舶检测与跟踪方面表现出卓越性能，实现了实时且精确的效果。", "conclusion": "该研究成功开发出一种高效的沿海视频序列中的船舶检测与跟踪系统。"}}
{"id": "2601.01473", "pdf": "https://arxiv.org/pdf/2601.01473", "abs": "https://arxiv.org/abs/2601.01473", "authors": ["Myung-Hwan Jang", "Jeong-Min Park", "Yunyong Ko", "Sang-Wook Kim"], "title": "Accelerating Storage-Based Training for Graph Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.DB"], "comment": "10 pages, 12 figures, 2 tables, ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) 2026", "summary": "Graph neural networks (GNNs) have achieved breakthroughs in various real-world downstream tasks due to their powerful expressiveness. As the scale of real-world graphs has been continuously growing, \\textit{a storage-based approach to GNN training} has been studied, which leverages external storage (e.g., NVMe SSDs) to handle such web-scale graphs on a single machine. Although such storage-based GNN training methods have shown promising potential in large-scale GNN training, we observed that they suffer from a severe bottleneck in data preparation since they overlook a critical challenge: \\textit{how to handle a large number of small storage I/Os}. To address the challenge, in this paper, we propose a novel storage-based GNN training framework, named \\textsf{AGNES}, that employs a method of \\textit{block-wise storage I/O processing} to fully utilize the I/O bandwidth of high-performance storage devices. Moreover, to further enhance the efficiency of each storage I/O, \\textsf{AGNES} employs a simple yet effective strategy, \\textit{hyperbatch-based processing} based on the characteristics of real-world graphs. Comprehensive experiments on five real-world graphs reveal that \\textsf{AGNES} consistently outperforms four state-of-the-art methods, by up to 4.1$\\times$ faster than the best competitor. Our code is available at https://github.com/Bigdasgit/agnes-kdd26.", "AI": {"tldr": "提出了一种新的存储基础的GNN训练框架AGNES，以加速大规模图神经网络的训练", "motivation": "现有存储基础的GNN训练方法在数据准备阶段存在严重的I/O瓶颈问题，尤其是处理大量小规模I/O时效率低下", "method": "通过块级存储I/O处理和基于超批处理策略的方法来优化存储设备的I/O带宽利用效率", "result": "实验表明AGNES比现有最佳竞争对手快4.1倍，显示出显著的优势", "conclusion": "AGNES框架有效解决了大规模图神经网络训练中的存储I/O瓶颈问题，提高了训练效率"}}
{"id": "2601.01467", "pdf": "https://arxiv.org/pdf/2601.01467", "abs": "https://arxiv.org/abs/2601.01467", "authors": ["Romuald Kwessy Mouona", "Blaise Blériot Koguep Njionou", "Etienne Romuald Temgoua Alomo", "Rokia Missaoui", "Leonard Kwuida"], "title": "A construction of an optimal base for conditional attribute and attributional condition implications in triadic contexts", "categories": ["cs.AI"], "comment": "26 pages", "summary": "This article studies implications in triadic contexts. Specifically, we focus on those introduced by Ganter and Obiedkov, namely conditional attribute and attributional condition implications. Our aim is to construct an optimal base for these implications.", "AI": {"tldr": "本文旨在为三元上下文中的条件属性和归因条件蕴含构建一个最优基础。", "motivation": "研究三元上下文中由Ganter和Obiedkov引入的条件属性及归因条件蕴含，以提高这些蕴含的理解和应用效果。", "method": "通过分析特定的数学模型与逻辑关系来构造这些蕴含的最优基础。", "result": "成功构建了一个对于所讨论的条件属性和归因条件蕴含有效的最优基础。", "conclusion": "提出的最优基础能够有效支持三元上下文中蕴含的研究，为进一步研究提供了坚实的基础。"}}
{"id": "2601.01461", "pdf": "https://arxiv.org/pdf/2601.01461", "abs": "https://arxiv.org/abs/2601.01461", "authors": ["Yuxiang Mei", "Dongxing Xu", "Jiaen Liang", "Yanhua Long"], "title": "Bridging the gap: A comparative exploration of Speech-LLM and end-to-end architecture for multilingual conversational ASR", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "5 pages, 1 figure", "summary": "The INTERSPEECH 2025 Challenge on Multilingual Conversational Speech Language Models (MLC-SLM) promotes multilingual conversational ASR with large language models (LLMs). Our previous SHNU-mASR system adopted a competitive parallel-speech-encoder architecture that integrated Whisper and mHuBERT with an LLM. However, it faced two challenges: simple feature concatenation may not fully exploit complementary information, and the performance gap between LLM-based ASR and end-to-end(E2E) encoder-decoder ASR remained unexplored. In this work, we present an enhanced LLM-based ASR framework that combines fine-tuned Whisper and mHuBERT encoders with an LLM to enrich speech representations. We first evaluate E2E Whisper models with LoRA and full fine-tuning on the MLC-SLM ASR task, and then propose cross-attention-based fusion mechanisms for the parallel-speech-encoder. On the official evaluation set of the MLC-SLM Challenge, our system achieves a CER/WER of 10.69%, ranking on par with the top-ranked Track 1 systems, even though it uses only 1,500 hours of baseline training data compared with their large-scale training sets. Nonetheless, we find that our final LLM-based ASR still does not match the performance of a fine-tuned E2E Whisper model, providing valuable empirical guidance for future Speech-LLM design. Our code is publicly available at https://github.com/1535176727/MLC-SLM.", "AI": {"tldr": "本文研究了基于大语言模型的多语种对话自动语音识别系统的改进框架，包括增强的并行语音编码器和融合机制。", "motivation": "为了克服简单特征拼接不能充分利用互补信息以及LLM基ASR与端到端E2E ASR性能差距的问题，本文提出了一个结合Whisper和mHuBERT编码器及大语言模型的改进框架。", "method": "首先评估了使用LoRA和完全微调的E2E Whisper模型在MLC-SLM ASR任务上的表现，并提出了一种基于交叉注意力的融合机制以增强并行语音编码器。", "result": "该系统在官方评测数据集上取得了10.69% CER/WER，与顶级Track1系统的性能相当。然而发现最终的LLM基ASR仍不如微调后的E2E Whisper模型表现好。", "conclusion": "研究结果为未来Speech-LLM设计提供了宝贵的实证指导，并公开了代码以供进一步探索。"}}
{"id": "2601.01460", "pdf": "https://arxiv.org/pdf/2601.01460", "abs": "https://arxiv.org/abs/2601.01460", "authors": ["Mohd Usama", "Belal Ahmad", "Christer Gronlund", "Faleh Menawer R Althiyabi"], "title": "Domain Adaptation of Carotid Ultrasound Images using Generative Adversarial Network", "categories": ["cs.CV"], "comment": "15 pages, 9 figures, 4 tables", "summary": "Deep learning has been extensively used in medical imaging applications, assuming that the test and training datasets belong to the same probability distribution. However, a common challenge arises when working with medical images generated by different systems or even the same system with different parameter settings. Such images contain diverse textures and reverberation noise that violate the aforementioned assumption. Consequently, models trained on data from one device or setting often struggle to perform effectively with data from other devices or settings. In addition, retraining models for each specific device or setting is labor-intensive and costly. To address these issues in ultrasound images, we propose a novel Generative Adversarial Network (GAN)-based model. We formulated the domain adaptation tasks as an image-to-image translation task, in which we modified the texture patterns and removed reverberation noise in the test data images from the source domain to align with those in the target domain images while keeping the image content unchanged. We applied the proposed method to two datasets containing carotid ultrasound images from three different domains. The experimental results demonstrate that the model successfully translated the texture pattern of images and removed reverberation noise from the ultrasound images. Furthermore, we evaluated the CycleGAN approaches for a comparative study with the proposed model. The experimental findings conclusively demonstrated that the proposed model achieved domain adaptation (histogram correlation (0.960 (0.019), & 0.920 (0.043) and bhattacharya distance (0.040 (0.020), & 0.085 (0.048)), compared to no adaptation (0.916 (0.062) & 0.890 (0.077), 0.090 (0.070) & 0.121 (0.095)) for both datasets.", "AI": {"tldr": "使用生成对抗网络（GAN）对来自不同领域的颈动脉超声图像进行领域适应，以解决训练和测试数据分布不一致的问题。", "motivation": "医疗成像应用中的深度学习模型通常假设训练集和测试集属于同一概率分布。然而，由于不同的系统或相同的系统在不同参数设置下生成的图像含有不同的纹理和混响噪声，这种假设经常被打破，导致模型泛化能力差且重新训练成本高。", "method": "将领域适应任务视为图像到图像翻译问题，使用GAN修改测试数据中的纹理模式并消除混响噪声，使其与目标域中的图像对齐同时保持图像内容不变。实验中应用了两种不同领域的两个超声图像数据集来验证模型效果。", "result": "提出的模型在领域适应方面取得了显著成果（直方图相关系数为0.960和0.920，巴塔查里亚距离为0.040和0.085），优于无域适应的情况（直方图相关系数分别为0.916和0.890，巴塔查里亚距离分别为0.090和0.121）。", "conclusion": "该研究提出的GAN方法能够有效地对超声图像进行领域适应，解决了由于设备或参数设置不同导致的训练数据与测试数据分布不一致问题。"}}
{"id": "2601.01459", "pdf": "https://arxiv.org/pdf/2601.01459", "abs": "https://arxiv.org/abs/2601.01459", "authors": ["Yong Ren", "Jiangyan Yi", "Jianhua Tao", "Haiyang Sun", "Zhengqi Wen", "Hao Gu", "Le Xu", "Ye Bai"], "title": "OV-InstructTTS: Towards Open-Vocabulary Instruct Text-to-Speech", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Instruct Text-to-Speech (InstructTTS) leverages natural language descriptions as style prompts to guide speech synthesis. However, existing InstructTTS methods mainly rely on a direct combination of audio-related labels or their diverse rephrasings, making it difficult to handle flexible, high-level instructions. Such rigid control is insufficient for users such as content creators who wish to steer generation with descriptive instructions. To address these constraints, we introduce OV-InstructTTS, a new paradigm for open-vocabulary InstructTTS. We propose a comprehensive solution comprising a newly curated dataset, OV-Speech, and a novel reasoning-driven framework. The OV-Speech dataset pairs speech with open-vocabulary instructions, each augmented with a reasoning process that connects high-level instructions to acoustic features. The reasoning-driven framework infers emotional, acoustic, and paralinguistic information from open-vocabulary instructions before synthesizing speech. Evaluations show that this reasoning-driven approach significantly improves instruction-following fidelity and speech expressiveness. We believe this work can inspire the next user-friendly InstructTTS systems with stronger generalization and real-world applicability. The dataset and demos are publicly available on our project page.", "AI": {"tldr": "本文提出了OV-InstructTTS，一种新的开放词汇指导的语音合成方法。", "motivation": "现有的InstructTTS方法难以处理灵活、高层次指令，限制了其应用范围和用户友好性。", "method": "作者提出了一种结合新数据集OV-Speech和推理驱动框架的方法，以提高语音生成对高层次指令的理解能力和表达能力。", "result": "实验结果表明，该方法在遵循指令的准确度和语音表现力方面显著优于现有技术。", "conclusion": "本研究有望推动下一代用户友好的InstructTTS系统的发展，提升其通用性和现实世界的应用性。"}}
{"id": "2601.01457", "pdf": "https://arxiv.org/pdf/2601.01457", "abs": "https://arxiv.org/abs/2601.01457", "authors": ["Mingxing Zhan", "Li Zhang", "Beibei Wang", "Yingjie Wang", "Zenglin Shi"], "title": "Language as Prior, Vision as Calibration: Metric Scale Recovery for Monocular Depth Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Relative-depth foundation models transfer well, yet monocular metric depth remains ill-posed due to unidentifiable global scale and heightened domain-shift sensitivity. Under a frozen-backbone calibration setting, we recover metric depth via an image-specific affine transform in inverse depth and train only lightweight calibration heads while keeping the relative-depth backbone and the CLIP text encoder fixed. Since captions provide coarse but noisy scale cues that vary with phrasing and missing objects, we use language to predict an uncertainty-aware envelope that bounds feasible calibration parameters in an unconstrained space, rather than committing to a text-only point estimate. We then use pooled multi-scale frozen visual features to select an image-specific calibration within this envelope. During training, a closed-form least-squares oracle in inverse depth provides per-image supervision for learning the envelope and the selected calibration. Experiments on NYUv2 and KITTI improve in-domain accuracy, while zero-shot transfer to SUN-RGBD and DDAD demonstrates improved robustness over strong language-only baselines.", "AI": {"tldr": "本文提出了一种结合语言先验和视觉校准的方法，用于单目深度估计中的度量尺度恢复。", "motivation": "相对深度模型能够良好地迁移，但单目度量深度仍因全局尺度不可识别和高度领域偏移敏感性而难以解决。通过引入图像特定的仿射变换来恢复度量深度，并利用语言预测不确定性感知包络以选择适当的校准参数。", "method": "在冻结主干网络的前提下，采用图像特定的仿射变换进行逆深度的空间尺度恢复；利用CLIP文本编码器提供的粗略但有噪声的比例线索建立不确定性感知包络，再结合多尺度视觉特征选择具体的校准参数。训练过程中使用闭式解最小二乘法提供监督。", "result": "实验结果表明，在NYUv2和KITTI数据集上取得了更好的领域内精度，并且在SUN-RGBD和DDAD上的零样本迁移测试中，比现有的语言模型具有更高的鲁棒性。", "conclusion": "通过结合语言先验知识与视觉校准，本文方法能够在单目深度估计任务中有效恢复度量尺度，并提升模型的领域适应能力和鲁棒性。"}}
{"id": "2601.01456", "pdf": "https://arxiv.org/pdf/2601.01456", "abs": "https://arxiv.org/abs/2601.01456", "authors": ["Wentao Bian", "Fenglei Xu"], "title": "Rethinking Multimodal Few-Shot 3D Point Cloud Segmentation: From Fused Refinement to Decoupled Arbitration", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "10 pages, 4 figures, 3 tables", "summary": "In this paper, we revisit multimodal few-shot 3D point cloud semantic segmentation (FS-PCS), identifying a conflict in \"Fuse-then-Refine\" paradigms: the \"Plasticity-Stability Dilemma.\" In addition, CLIP's inter-class confusion can result in semantic blindness. To address these issues, we present the Decoupled-experts Arbitration Few-Shot SegNet (DA-FSS), a model that effectively distinguishes between semantic and geometric paths and mutually regularizes their gradients to achieve better generalization. DA-FSS employs the same backbone and pre-trained text encoder as MM-FSS to generate text embeddings, which can increase free modalities' utilization rate and better leverage each modality's information space. To achieve this, we propose a Parallel Expert Refinement module to generate each modal correlation. We also propose a Stacked Arbitration Module (SAM) to perform convolutional fusion and arbitrate correlations for each modality pathway. The Parallel Experts decouple two paths: a Geometric Expert maintains plasticity, and a Semantic Expert ensures stability. They are coordinated via a Decoupled Alignment Module (DAM) that transfers knowledge without propagating confusion. Experiments on popular datasets (S3DIS, ScanNet) demonstrate the superiority of DA-FSS over MM-FSS. Meanwhile, geometric boundaries, completeness, and texture differentiation are all superior to the baseline. The code is available at: https://github.com/MoWenQAQ/DA-FSS.", "AI": {"tldr": "本文重新审视了基于融合后细化的多模态少样本三维点云语义分割方法，并提出了一个新的模型DA-FSS，通过分离专家仲裁机制来解决语义和几何路径之间的冲突。", "motivation": "在“融合-再细化”范式中存在一个“可塑性-稳定性困境”，并且CLIP的跨类别混淆可能导致语义盲点。为了应对这些问题，本文提出了一个新的模型DA-FSS以区分语义和几何路径并相互调节其梯度，实现更好的泛化。", "method": "DA-FSS包括平行专家细化模块、堆叠仲裁模块以及分离对齐模块，通过这些组件有效地区分了语义和几何路径，并避免了跨类别混淆的传播。", "result": "实验显示，在S3DIS和ScanNet数据集上，DA-FSS在边界清晰度、完整性及纹理差异性方面均优于基线方法。", "conclusion": "提出的DA-FSS模型通过分离专家仲裁机制解决了语义分割中的“可塑性-稳定性困境”，并在多个基准数据集上的实验验证了其有效性。"}}
{"id": "2601.01454", "pdf": "https://arxiv.org/pdf/2601.01454", "abs": "https://arxiv.org/abs/2601.01454", "authors": ["Xiao Li", "Zilong Liu", "Yining Liu", "Zhuhong Li", "Na Dong", "Sitian Qin", "Xiaolin Hu"], "title": "PartImageNet++ Dataset: Enhancing Visual Models with High-Quality Part Annotations", "categories": ["cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2407.10918", "summary": "To address the scarcity of high-quality part annotations in existing datasets, we introduce PartImageNet++ (PIN++), a dataset that provides detailed part annotations for all categories in ImageNet-1K. With 100 annotated images per category, totaling 100K images, PIN++ represents the most comprehensive dataset covering a diverse range of object categories. Leveraging PIN++, we propose a Multi-scale Part-supervised recognition Model (MPM) for robust classification on ImageNet-1K. We first trained a part segmentation network using PIN++ and used it to generate pseudo part labels for the remaining unannotated images. MPM then integrated a conventional recognition architecture with auxiliary bypass layers, jointly supervised by both pseudo part labels and the original part annotations. Furthermore, we conducted extensive experiments on PIN++, including part segmentation, object segmentation, and few-shot learning, exploring various ways to leverage part annotations in downstream tasks. Experimental results demonstrated that our approach not only enhanced part-based models for robust object recognition but also established strong baselines for multiple downstream tasks, highlighting the potential of part annotations in improving model performance. The dataset and the code are available at https://github.com/LixiaoTHU/PartImageNetPP.", "AI": {"tldr": "该论文介绍了PartImageNet++数据集，用于提高视觉模型的质量，并提出了一种基于多尺度部件监督的识别模型（MPM）。", "motivation": "为了应对现有数据集中高质量部件注释缺乏的问题，作者构建了涵盖多样物体类别的最全面的数据集PartImageNet++。", "method": "使用PIN++训练一个部件分割网络并生成伪部件标签用于未标注图像。MPM模型通过集成传统识别架构与辅助旁路层联合监督伪部件标签和原始部件注释，提升识别性能。", "result": "实验表明该方法不仅增强了基于部件的模型对物体识别的鲁棒性，还为多个下游任务建立了强有力的基线，展示了部件注释在提高模型表现中的潜力。", "conclusion": "PartImageNet++数据集和MPM模型成功地促进了视觉模型的发展，并揭示了部件注释的重要价值。"}}
{"id": "2601.01452", "pdf": "https://arxiv.org/pdf/2601.01452", "abs": "https://arxiv.org/abs/2601.01452", "authors": ["Jian Feng", "Zhihong Huang"], "title": "Bayesian Subspace Gradient Estimation for Zeroth-Order Optimization of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "19 pages, 1 figures, 4 tables", "summary": "Fine-tuning large language models (LLMs) with zeroth-order (ZO) optimization reduces memory by approximating gradients through function evaluations, but existing methods rely on one-step gradient estimates from random perturbations. We introduce Bayesian Subspace Zeroth-Order optimization (BSZO), a ZO optimizer that applies Kalman filtering to combine finite-difference information across multiple perturbation directions. By treating each finite-difference measurement as a noisy observation, BSZO builds a posterior distribution over the projected gradient and updates it through Bayesian inference, with a residual-based adaptive mechanism to adjust perturbation scales. Theoretical analysis shows that BSZO improves the convergence rate by a factor of $k/γ$ compared to standard ZO methods. Experiments on RoBERTa, Mistral, and OPT models show that BSZO outperforms MeZO, MeZO-Adam, and HiZOO across various tasks, achieving up to 6.67\\% absolute average improvement on OPT-13B while keeping memory usage close to inference-only baselines (1.00$\\times$--1.08$\\times$ of MeZO).", "AI": {"tldr": "提出了一种新的零阶优化方法BSZO，用于大语言模型的微调。", "motivation": "现有的零阶优化方法依赖于随机扰动的一次性梯度估计，可能导致收敛速度慢。为了改进这一点，作者引入了结合多方向有限差分信息的Bayesian Subspace Zeroth-Order优化（BSZO）。", "method": "通过将每个有限差分测量视为噪声观测并使用卡尔曼滤波器来构建投影梯度后验分布，同时利用基于残差自适应机制调整扰动尺度，从而实现对大语言模型的更高效微调。", "result": "实验结果表明BSZO在RoBERTa、Mistral和OPT模型上超越了MeZO, MeZO-Adam和HiZOO等方法，在OPT-13B上实现了高达6.67%的绝对平均改进，同时保持内存使用接近仅推理基线（1.00倍-1.08倍于MeZO）。", "conclusion": "BSZO通过引入新的零阶优化技术显著提高了大语言模型微调过程中的收敛效率和性能表现。"}}
{"id": "2601.01441", "pdf": "https://arxiv.org/pdf/2601.01441", "abs": "https://arxiv.org/abs/2601.01441", "authors": ["Saumya Gupta", "Abhinandan", "Venkatesh vadde", "Bhaskaran Muralidharan", "Abhishek Sharma"], "title": "Image Synthesis Using Spintronic Deep Convolutional Generative Adversarial Network", "categories": ["physics.app-ph", "cs.CV"], "comment": "8 pages, 4 figures", "summary": "The computational requirements of generative adversarial networks (GANs) exceed the limit of conventional Von Neumann architectures, necessitating energy efficient alternatives such as neuromorphic spintronics. This work presents a hybrid CMOS-spintronic deep convolutional generative adversarial network (DCGAN) architecture for synthetic image generation. The proposed generative vision model approach follows the standard framework, leveraging generator and discriminators adversarial training with our designed spintronics hardware for deconvolution, convolution, and activation layers of the DCGAN architecture. To enable hardware aware spintronic implementation, the generator's deconvolution layers are restructured as zero padded convolution, allowing seamless integration with a 6-bit skyrmion based synapse in a crossbar, without compromising training performance. Nonlinear activation functions are implemented using a hybrid CMOS domain wall based Rectified linear unit (ReLU) and Leaky ReLU units. Our proposed tunable Leaky ReLU employs domain wall position coded, continuous resistance states and a piecewise uniaxial parabolic anisotropy profile with a parallel MTJ readout, exhibiting energy consumption of 0.192 pJ. Our spintronic DCGAN model demonstrates adaptability across both grayscale and colored datasets, achieving Fr'echet Inception Distances (FID) of 27.5 for the Fashion MNIST and 45.4 for Anime Face datasets, with testing energy (training energy) of 4.9 nJ (14.97~nJ/image) and 24.72 nJ (74.7 nJ/image).", "AI": {"tldr": "本文提出了一种基于自旋电子器件的深度卷积生成对抗网络架构，用于合成图像生成。", "motivation": "传统的冯·诺依曼架构无法满足生成对抗网络的计算需求，因此需要能效更高的替代方案，如神经形态自旋电子学。", "method": "设计了一种混合CMOS-自旋电子DCGAN架构，利用自旋电子硬件实现卷积、反卷积和激活层。通过将生成器中的反卷积层重构为零填充的卷积层，并使用6位skyrmion基元突触与交叉阵列无缝集成，同时保持训练性能。", "result": "该模型在灰度和彩色数据集上表现良好，实现了27.5（Fashion MNIST）和45.4（Anime Face）的Fr'echet Inception Distance。测试能量分别为4.9 nJ/图像和24.72 nJ/图像。", "conclusion": "提出的自旋电子DCGAN模型显示了在灰度和彩色数据集上的适应性，且具有较低的能量消耗，证明了其作为未来生成对抗网络架构的潜力。"}}
{"id": "2601.01439", "pdf": "https://arxiv.org/pdf/2601.01439", "abs": "https://arxiv.org/abs/2601.01439", "authors": ["Wenqi Ren", "Weijie Wang", "Meng Zheng", "Ziyan Wu", "Yang Tang", "Zhun Zhong", "Nicu Sebe"], "title": "In defense of the two-stage framework for open-set domain adaptive semantic segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Open-Set Domain Adaptation for Semantic Segmentation (OSDA-SS) presents a significant challenge, as it requires both domain adaptation for known classes and the distinction of unknowns. Existing methods attempt to address both tasks within a single unified stage. We question this design, as the annotation imbalance between known and unknown classes often leads to negative transfer of known classes and underfitting for unknowns. To overcome these issues, we propose SATS, a Separating-then-Adapting Training Strategy, which addresses OSDA-SS through two sequential steps: known/unknown separation and unknown-aware domain adaptation. By providing the model with more accurate and well-aligned unknown classes, our method ensures a balanced learning of discriminative features for both known and unknown classes, steering the model toward discovering truly unknown objects. Additionally, we present hard unknown exploration, an innovative data augmentation method that exposes the model to more challenging unknowns, strengthening its ability to capture more comprehensive understanding of target unknowns. We evaluate our method on public OSDA-SS benchmarks. Experimental results demonstrate that our method achieves a substantial advancement, with a +3.85% H-Score improvement for GTA5-to-Cityscapes and +18.64% for SYNTHIA-to-Cityscapes, outperforming previous state-of-the-art methods.", "AI": {"tldr": "本文提出了一种新的两阶段框架SATs，用于开放集域适应语义分割任务。", "motivation": "现有的方法尝试在单个统一阶段解决已知类和未知类的区分问题，但这种做法往往导致已知类的学习负迁移以及对未知类学习不足。", "method": "通过将任务拆分为两个步骤：已知/未知分离和考虑未知类的域适应，本文的方法能够提供更为精确且良好的未知类别模型。此外还提出了困难未知数据增强技术，增强了模型捕捉目标未知类别的能力。", "result": "实验结果表明，该方法在公开的开放集域适应语义分割基准测试中取得了显著的进步，在GTA5到Cityscapes和SYNTHIA到Cityscapes两个任务上分别实现了3.85% H-Score的提升和18.64%的改进。", "conclusion": "本文的研究证明了将开放集域适应语义分割任务拆分为两阶段处理的有效性，并且所提出的方法在多个数据集上的性能超越现有最先进技术。"}}
{"id": "2601.01438", "pdf": "https://arxiv.org/pdf/2601.01438", "abs": "https://arxiv.org/abs/2601.01438", "authors": ["Russell Buchanan", "Adrian Röfer", "João Moura", "Abhinav Valada", "Sethu Vijayakumar"], "title": "Online Estimation and Manipulation of Articulated Objects", "categories": ["cs.RO", "cs.AI"], "comment": "This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in Autonomous Robots, and is available online at [Link will be updated when available]", "summary": "From refrigerators to kitchen drawers, humans interact with articulated objects effortlessly every day while completing household chores. For automating these tasks, service robots must be capable of manipulating arbitrary articulated objects. Recent deep learning methods have been shown to predict valuable priors on the affordance of articulated objects from vision. In contrast, many other works estimate object articulations by observing the articulation motion, but this requires the robot to already be capable of manipulating the object. In this article, we propose a novel approach combining these methods by using a factor graph for online estimation of articulation which fuses learned visual priors and proprioceptive sensing during interaction into an analytical model of articulation based on Screw Theory. With our method, a robotic system makes an initial prediction of articulation from vision before touching the object, and then quickly updates the estimate from kinematic and force sensing during manipulation. We evaluate our method extensively in both simulations and real-world robotic manipulation experiments. We demonstrate several closed-loop estimation and manipulation experiments in which the robot was capable of opening previously unseen drawers. In real hardware experiments, the robot achieved a 75% success rate for autonomous opening of unknown articulated objects.", "AI": {"tldr": "本文提出了一种结合深度学习和机器人感知的方法，用于在线估计并操作关节物体。", "motivation": "为了使服务机器人能够自动化日常任务，它们必须具备处理各种关节物体的能力。目前的技术要么依赖于视觉预测物体的可操作性，要么需要机器人首先掌握物体的操作方法才能进行运动观察。", "method": "本文提出了一种新的方法，结合了深度学习和基于螺旋理论的分析模型，在线估计并更新物体的关节状态，通过视觉先验与物理感知在互动中融合。", "result": "实验证明该机器人系统能够在模拟环境中以及真实世界实验中成功地处理未知抽屉等关节物体，其自主打开未知关节物体的成功率为75%。", "conclusion": "本文的方法提高了服务机器人操作未见过的复杂物体的能力，特别是对于那些具有可移动部分的日常用品。"}}
{"id": "2601.01431", "pdf": "https://arxiv.org/pdf/2601.01431", "abs": "https://arxiv.org/abs/2601.01431", "authors": ["Weiqi Yu", "Yiyang Yao", "Lin He", "Jianming Lv"], "title": "EdgeNeRF: Edge-Guided Regularization for Neural Radiance Fields from Sparse Views", "categories": ["cs.CV"], "comment": "PRCV 2025", "summary": "Neural Radiance Fields (NeRF) achieve remarkable performance in dense multi-view scenarios, but their reconstruction quality degrades significantly under sparse inputs due to geometric artifacts. Existing methods utilize global depth regularization to mitigate artifacts, leading to the loss of geometric boundary details. To address this problem, we propose EdgeNeRF, an edge-guided sparse-view 3D reconstruction algorithm. Our method leverages the prior that abrupt changes in depth and normals generate edges. Specifically, we first extract edges from input images, then apply depth and normal regularization constraints to non-edge regions, enhancing geometric consistency while preserving high-frequency details at boundaries. Experiments on LLFF and DTU datasets demonstrate EdgeNeRF's superior performance, particularly in retaining sharp geometric boundaries and suppressing artifacts. Additionally, the proposed edge-guided depth regularization module can be seamlessly integrated into other methods in a plug-and-play manner, significantly improving their performance without substantially increasing training time. Code is available at https://github.com/skyhigh404/edgenerf.", "AI": {"tldr": "提出了一种基于边缘引导的稀疏视图三维重建算法EdgeNeRF，以提高NeRF在稀疏输入情况下的几何边界保留能力和抑制伪影的能力。", "motivation": "现有的方法通过全局深度正则化来减少几何伪影，但在处理稀疏输入时会丢失重要的几何边界细节。为了解决这个问题，提出了EdgeNeRF算法，旨在保留高频率的几何边缘并增强整体一致性和质量。", "method": "该方法首先从输入图像中提取边缘，然后在非边缘区域应用深度和法线正则化约束，以此来提高整个模型的一致性同时保持边界细节。这种方法可以无缝地集成到其他算法之中，以进一步改进其性能。", "result": "实验表明，在LLFF和DTU数据集上，EdgeNeRF能够更好地保留几何边缘并减少伪影的发生，证明了该方法的有效性和优越性。", "conclusion": "通过引入边缘引导的深度正则化模块，可以在不显著增加训练时间的情况下，提升神经辐射场模型在稀疏视图下的重建质量。"}}
{"id": "2601.01425", "pdf": "https://arxiv.org/pdf/2601.01425", "abs": "https://arxiv.org/abs/2601.01425", "authors": ["Xu Guo", "Fulong Ye", "Xinghui Li", "Pengqi Tu", "Pengze Zhang", "Qichao Sun", "Songtao Zhao", "Xiangwang Hou", "Qian He"], "title": "DreamID-V:Bridging the Image-to-Video Gap for High-Fidelity Face Swapping via Diffusion Transformer", "categories": ["cs.CV"], "comment": "Project: https://guoxu1233.github.io/DreamID-V/", "summary": "Video Face Swapping (VFS) requires seamlessly injecting a source identity into a target video while meticulously preserving the original pose, expression, lighting, background, and dynamic information. Existing methods struggle to maintain identity similarity and attribute preservation while preserving temporal consistency. To address the challenge, we propose a comprehensive framework to seamlessly transfer the superiority of Image Face Swapping (IFS) to the video domain. We first introduce a novel data pipeline SyncID-Pipe that pre-trains an Identity-Anchored Video Synthesizer and combines it with IFS models to construct bidirectional ID quadruplets for explicit supervision. Building upon paired data, we propose the first Diffusion Transformer-based framework DreamID-V, employing a core Modality-Aware Conditioning module to discriminatively inject multi-model conditions. Meanwhile, we propose a Synthetic-to-Real Curriculum mechanism and an Identity-Coherence Reinforcement Learning strategy to enhance visual realism and identity consistency under challenging scenarios. To address the issue of limited benchmarks, we introduce IDBench-V, a comprehensive benchmark encompassing diverse scenes. Extensive experiments demonstrate DreamID-V outperforms state-of-the-art methods and further exhibits exceptional versatility, which can be seamlessly adapted to various swap-related tasks.", "AI": {"tldr": "提出了一种新颖的视频人脸交换框架DreamID-V，利用扩散变换器和合成到现实课程机制提高视觉真实性和身份一致性。", "motivation": "当前方法在保持图像质量和时空连贯性方面存在挑战。为了克服这些限制，本研究旨在开发一种能够无缝转换图像级面部交换优势至视频领域的框架。", "method": "首先引入SyncID-Pipe数据管道以构建双向ID四元组用于明确监督；接着提出基于扩散变换器的DreamID-V框架，利用模态感知条件模块注入多模型条件。此外，还提出了合成到现实课程机制和身份一致性强化学习策略以增强视觉真实性和身份一致性。", "result": "实验表明DreamID-V在保持身份相似性、属性保存及时间连贯性方面优于现有最佳方法，并展示了其处理各种交换相关任务的卓越灵活性。", "conclusion": "通过综合框架和技术改进，成功提升了视频面部交换的质量和鲁棒性。"}}
{"id": "2601.01416", "pdf": "https://arxiv.org/pdf/2601.01416", "abs": "https://arxiv.org/abs/2601.01416", "authors": ["Yue Zhou", "Ran Ding", "Xue Yang", "Xue Jiang", "Xingzhao Liu"], "title": "AirSpatialBot: A Spatially-Aware Aerial Agent for Fine-Grained Vehicle Attribute Recognization and Retrieval", "categories": ["cs.CV"], "comment": "12 pages, 9 figures", "summary": "Despite notable advancements in remote sensing vision-language models (VLMs), existing models often struggle with spatial understanding, limiting their effectiveness in real-world applications. To push the boundaries of VLMs in remote sensing, we specifically address vehicle imagery captured by drones and introduce a spatially-aware dataset AirSpatial, which comprises over 206K instructions and introduces two novel tasks: Spatial Grounding and Spatial Question Answering. It is also the first remote sensing grounding dataset to provide 3DBB. To effectively leverage existing image understanding of VLMs to spatial domains, we adopt a two-stage training strategy comprising Image Understanding Pre-training and Spatial Understanding Fine-tuning. Utilizing this trained spatially-aware VLM, we develop an aerial agent, AirSpatialBot, which is capable of fine-grained vehicle attribute recognition and retrieval. By dynamically integrating task planning, image understanding, spatial understanding, and task execution capabilities, AirSpatialBot adapts to diverse query requirements. Experimental results validate the effectiveness of our approach, revealing the spatial limitations of existing VLMs while providing valuable insights. The model, code, and datasets will be released at https://github.com/VisionXLab/AirSpatialBot", "AI": {"tldr": "论文提出了一个名为AirSpatialBot的空中代理，用于无人机捕获车辆图像中的精细属性识别和检索。", "motivation": "现有远程遥感视觉语言模型在空间理解方面存在局限性，限制了其实际应用效果。为推动这些模型的发展，引入了一个新的具有3D边界框的空间数据集AirSpatial以及两个新任务：空间定位和空间问答。", "method": "通过采用两阶段训练策略（图像理解预训练和空间理解微调），开发了一种能够利用现有视觉语言模型进行图像理解并扩展到空间领域的空中代理AirSpatialBot。该代理结合了任务规划、图像理解、空间理解和任务执行能力，能适应不同查询需求。", "result": "实验结果表明了所提出方法的有效性，并揭示了现有视觉语言模型在空间理解方面的局限性，提供了有价值的新见解。", "conclusion": "论文通过开发AirSpatialBot展示了如何利用先进的视觉语言模型进行无人机捕获的车辆图像的空间理解和属性识别。"}}
{"id": "2601.01410", "pdf": "https://arxiv.org/pdf/2601.01410", "abs": "https://arxiv.org/abs/2601.01410", "authors": ["Jisoo Lee", "Sunki Hong"], "title": "Reliable Grid Forecasting: State Space Models for Safety-Critical Energy Systems", "categories": ["eess.SY", "cs.AI", "cs.LG"], "comment": "24 pages, 8 figures, 8 tables", "summary": "Accurate grid load forecasting is safety-critical: under-predictions risk supply shortfalls, while symmetric error metrics mask this operational asymmetry. We introduce a grid-specific evaluation framework--Asymmetric MAPE, Under-Prediction Rate, and Reserve Margin--that directly measures operational risk rather than statistical accuracy alone. Using this framework, we conduct a systematic evaluation of Mamba-based State Space Models for California grid forecasting on a weather-aligned CAISO TAC-area dataset spanning Nov 2023--Nov 2025 (84,498 hourly records across 5 transmission areas). Our analysis reveals that standard accuracy metrics are poor proxies for operational safety: models with identical MAPE can require vastly different reserve margins. We demonstrate that forecast errors are weakly but significantly associated with temperature (r = 0.16, p < 10^{-16}), motivating weather-aware modeling rather than loss function modification alone. The S-Mamba model achieves the lowest Reserve_{99.5}% margin (14.12%) compared to 16.66% for iTransformer, demonstrating superior forecast reliability under a 99.5th-percentile tail-risk reserve proxy.", "AI": {"tldr": "该论文提出了针对电网负荷预测的安全评估框架，并使用天气对齐的数据集对比了不同模型的性能。", "motivation": "准确的电网负载预测是安全关键的任务，传统的误差度量可能忽视操作风险。因此需要一种新的评估框架来直接衡量这种风险。", "method": "通过引入一个新的评估框架（包括不对称MAPE、下限预测率和储备余量），该论文对比了基于Mamba的状态空间模型和其他模型在加利福尼亚电网数据集上的表现，使用天气对齐的数据进行系统性评价。", "result": "结果显示标准的精度指标并不是操作安全性的良好代理，并且提出了S-Mamba模型，在99.5分位数尾部风险储备的情况下取得了最低的储备余量（14.12%）优于其他模型。", "conclusion": "该论文证明了天气相关的因素对预测误差有显著影响，而不仅仅是改变损失函数。新的评估框架和方法提高了电网负载预测的安全性和可靠性。"}}
{"id": "2601.01409", "pdf": "https://arxiv.org/pdf/2601.01409", "abs": "https://arxiv.org/abs/2601.01409", "authors": ["Chuyuan Tao", "Fanxin Wang", "Haolong Jiang", "Jia He", "Yiyang Chen", "Qinglei Bu"], "title": "Sampling Strategy Design for Model Predictive Path Integral Control on Legged Robot Locomotion", "categories": ["eess.SY", "cs.RO"], "comment": null, "summary": "Model Predictive Path Integral (MPPI) control has emerged as a powerful sampling-based optimal control method for complex, nonlinear, and high-dimensional systems. However, directly applying MPPI to legged robotic systems presents several challenges. This paper systematically investigates the role of sampling strategy design within the MPPI framework for legged robot locomotion. Based upon the idea of structured control parameterization, we explore and compare multiple sampling strategies within the framework, including both unstructured and spline-based approaches. Through extensive simulations on a quadruped robot platform, we evaluate how different sampling strategies affect control smoothness, task performance, robustness, and sample efficiency. The results provide new insights into the practical implications of sampling design for deploying MPPI on complex legged systems.", "AI": {"tldr": "设计采样策略以提高模型预测路径积分控制在四足机器人上的性能", "motivation": "解决将MPPI直接应用于腿式机器人系统时遇到的挑战，探索和比较不同的采样方法对控制系统的影响", "method": "基于结构化控制参数化的想法，在框架内探索并对比多种采样策略，并通过仿真测试它们的表现", "result": "不同采样策略影响控制平滑度、任务性能、鲁棒性和样本效率", "conclusion": "研究结果提供了部署MPPI在复杂腿式系统中的实用见解"}}
{"id": "2601.01408", "pdf": "https://arxiv.org/pdf/2601.01408", "abs": "https://arxiv.org/abs/2601.01408", "authors": ["Gong Gao", "Zekai Wang", "Jian Zhao", "Ziqi Xie", "Xianhui Liu", "Weidong Zhao"], "title": "Mask-Guided Multi-Task Network for Face Attribute Recognition", "categories": ["cs.CV"], "comment": "23 pages, 9 figures", "summary": "Face Attribute Recognition (FAR) plays a crucial role in applications such as person re-identification, face retrieval, and face editing. Conventional multi-task attribute recognition methods often process the entire feature map for feature extraction and attribute classification, which can produce redundant features due to reliance on global regions. To address these challenges, we propose a novel approach emphasizing the selection of specific feature regions for efficient feature learning. We introduce the Mask-Guided Multi-Task Network (MGMTN), which integrates Adaptive Mask Learning (AML) and Group-Global Feature Fusion (G2FF) to address the aforementioned limitations. Leveraging a pre-trained keypoint annotation model and a fully convolutional network, AML accurately localizes critical facial parts (e.g., eye and mouth groups) and generates group masks that delineate meaningful feature regions, thereby mitigating negative transfer from global region usage. Furthermore, G2FF combines group and global features to enhance FAR learning, enabling more precise attribute identification. Extensive experiments on two challenging facial attribute recognition datasets demonstrate the effectiveness of MGMTN in improving FAR performance.", "AI": {"tldr": "提出了一种基于掩模引导的多任务网络（MGMTN）用于面部属性识别，通过自适应掩模学习和组全局特征融合来改进面部关键区域定位和特征提取。", "motivation": "传统方法在进行整个特征图处理时会产生冗余特性，导致效率低下。提出的新方法旨在选择特定的特征区域以提高面部属性识别的效果。", "method": "该模型通过自适应掩模学习（AML）准确地定位关键面部部分，并生成组掩模来隔离有意义的特征区域；结合组全局特征融合（G2FF），将局部和整体特性结合起来增强面部属性识别能力。", "result": "在两个具有挑战性的面部属性数据集上的大量实验表明，MGMTN显著改善了面部属性识别性能。", "conclusion": "通过掩模引导的方法能够更精确地进行面部关键区域定位和特征提取，从而有效提升面部属性识别的准确性和效率。"}}
{"id": "2601.01406", "pdf": "https://arxiv.org/pdf/2601.01406", "abs": "https://arxiv.org/abs/2601.01406", "authors": ["Habiba Kausar", "Saeed Anwar", "Omar Jamal Hammad", "Abdul Bais"], "title": "SwinIFS: Landmark Guided Swin Transformer For Identity Preserving Face Super Resolution", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Face super-resolution aims to recover high-quality facial images from severely degraded low-resolution inputs, but remains challenging due to the loss of fine structural details and identity-specific features. This work introduces SwinIFS, a landmark-guided super-resolution framework that integrates structural priors with hierarchical attention mechanisms to achieve identity-preserving reconstruction at both moderate and extreme upscaling factors. The method incorporates dense Gaussian heatmaps of key facial landmarks into the input representation, enabling the network to focus on semantically important facial regions from the earliest stages of processing. A compact Swin Transformer backbone is employed to capture long-range contextual information while preserving local geometry, allowing the model to restore subtle facial textures and maintain global structural consistency. Extensive experiments on the CelebA benchmark demonstrate that SwinIFS achieves superior perceptual quality, sharper reconstructions, and improved identity retention; it consistently produces more photorealistic results and exhibits strong performance even under 8x magnification, where most methods fail to recover meaningful structure. SwinIFS also provides an advantageous balance between reconstruction accuracy and computational efficiency, making it suitable for real-world applications in facial enhancement, surveillance, and digital restoration. Our code, model weights, and results are available at https://github.com/Habiba123-stack/SwinIFS.", "AI": {"tldr": "本文提出了一种名为SwinIFS的面部超分辨率框架，该框架通过使用密集高斯热图和Swin变压器来实现身份保持的重建。", "motivation": "面部超分辨率的目标是从低分辨率输入中恢复高质量的面部图像。然而，在处理过程中容易丢失细节以及特定的身份特征。因此，本文旨在开发一种能够同时保留结构一致性和身份特征的技术。", "method": "该方法结合了密集高斯热图和Swin变压器来捕捉关键面部区域的长期上下文信息，并保持局部几何形状。这种方法使得网络从早期处理阶段开始就可以专注于语义重要的面部区域。", "result": "实验表明，与现有技术相比，SwinIFS在身份保持、图像清晰度等方面都表现出了更好的性能，在8倍放大时依然能够恢复有意义的结构。", "conclusion": "总的来说，该方法不仅提供了高质量的重建结果，还具有计算效率的优势。这些特性使得它适用于面部增强和数字修复等实际应用中。"}}
{"id": "2601.01403", "pdf": "https://arxiv.org/pdf/2601.01403", "abs": "https://arxiv.org/abs/2601.01403", "authors": ["Zewei Yu", "Jianqiu Xu", "Caimin Li"], "title": "A Graph-based Framework for Online Time Series Anomaly Detection Using Model Ensemble", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages", "summary": "With the increasing volume of streaming data in industrial systems, online anomaly detection has become a critical task. The diverse and rapidly evolving data patterns pose significant challenges for online anomaly detection. Many existing anomaly detection methods are designed for offline settings or have difficulty in handling heterogeneous streaming data effectively. This paper proposes GDME, an unsupervised graph-based framework for online time series anomaly detection using model ensemble. GDME maintains a dynamic model pool that is continuously updated by pruning underperforming models and introducing new ones. It utilizes a dynamic graph structure to represent relationships among models and employs community detection on the graph to select an appropriate subset for ensemble. The graph structure is also used to detect concept drift by monitoring structural changes, allowing the framework to adapt to evolving streaming data. Experiments on seven heterogeneous time series demonstrate that GDME outperforms existing online anomaly detection methods, achieving improvements of up to 24%. In addition, its ensemble strategy provides superior detection performance compared with both individual models and average ensembles, with competitive computational efficiency.", "AI": {"tldr": "提出了一个基于图的框架GDME，用于在线时间序列异常检测。", "motivation": "随着工业系统中流数据量的增长，在线异常检测已成为一项关键任务。现有方法多适用于离线环境或难以有效处理异构流数据。因此需要一种新的框架来解决这些问题。", "method": "提出了基于图的在线时间序列异常检测框架GDME，该框架包含动态模型池更新机制、利用图形结构表示模型间关系以及通过社区检测选择合适的模型组合策略，并使用图结构监控结构变化以适应不断演变的数据流。", "result": "实验结果表明，与现有在线异常检测方法相比，GDME在七种不同时间序列数据集上的表现更优，性能提高了高达24%。其模型集成策略优于单个模型和平均集合的检测性能，并且具有竞争性的计算效率。", "conclusion": "提出的基于图框架GDME有效解决了在线时间序列异常检测中的挑战问题，提供了更好的检测性能和适应性。"}}
{"id": "2601.01393", "pdf": "https://arxiv.org/pdf/2601.01393", "abs": "https://arxiv.org/abs/2601.01393", "authors": ["Shamik Shafkat Avro", "Nazira Jesmin Lina", "Shahanaz Sharmin"], "title": "Evaluation of Convolutional Neural Network For Image Classification with Agricultural and Urban Datasets", "categories": ["cs.CV"], "comment": "All authors contributed equally to this work", "summary": "This paper presents the development and evaluation of a custom Convolutional Neural Network (CustomCNN) created to study how architectural design choices affect multi-domain image classification tasks. The network uses residual connections, Squeeze-and-Excitation attention mechanisms, progressive channel scaling, and Kaiming initialization to improve its ability to represent data and speed up training. The model is trained and tested on five publicly available datasets: unauthorized vehicle detection, footpath encroachment detection, polygon-annotated road damage and manhole detection, MangoImageBD and PaddyVarietyBD. A comparison with popular CNN architectures shows that the CustomCNN delivers competitive performance while remaining efficient in computation. The results underscore the importance of thoughtful architectural design for real-world Smart City and agricultural imaging applications.", "AI": {"tldr": "开发并评估了一种自定义卷积神经网络（CustomCNN），用于研究架构设计选择对多领域图像分类任务的影响。", "motivation": "探索不同的网络结构如何影响农业和城市领域的图像分类精度，以提升智慧城市和农业成像应用的实际效果。", "method": "使用残差连接、挤压与激励注意力机制、渐进式通道缩放以及Kaiming初始化来设计CustomCNN。该模型在五个公开数据集上进行了训练和测试，并且将结果与其他流行CNN架构进行比较。", "result": "CustomCNN展示了与其计算效率相匹配的竞争力性能，表明了合理的设计对于实际应用的重要性。", "conclusion": "合理的网络架构设计对智慧城市及农业成像的实际应用至关重要。"}}
{"id": "2601.01392", "pdf": "https://arxiv.org/pdf/2601.01392", "abs": "https://arxiv.org/abs/2601.01392", "authors": ["Peidong Wang", "Zhiming Ma", "Xin Dai", "Yongkang Liu", "Shi Feng", "Xiaocui Yang", "Wenxing Hu", "Zhihao Wang", "Mingjun Pan", "Li Yuan", "Daling Wang"], "title": "SAFE-QAQ: End-to-End Slow-Thinking Audio-Text Fraud Detection via Reinforcement Learning", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Existing fraud detection methods predominantly rely on transcribed text, suffering from ASR errors and missing crucial acoustic cues like vocal tone and environmental context. This limits their effectiveness against complex deceptive strategies. To address these challenges, we first propose \\textbf{SAFE-QAQ}, an end-to-end comprehensive framework for audio-based slow-thinking fraud detection. First, the SAFE-QAQ framework eliminates the impact of transcription errors on detection performance. Secondly, we propose rule-based slow-thinking reward mechanisms that systematically guide the system to identify fraud-indicative patterns by accurately capturing fine-grained audio details, through hierarchical reasoning processes. Besides, our framework introduces a dynamic risk assessment framework during live calls, enabling early detection and prevention of fraud. Experiments on the TeleAntiFraud-Bench demonstrate that SAFE-QAQ achieves dramatic improvements over existing methods in multiple key dimensions, including accuracy, inference efficiency, and real-time processing capabilities. Currently deployed and analyzing over 70,000 calls daily, SAFE-QAQ effectively automates complex fraud detection, reducing human workload and financial losses. Code: https://anonymous.4open.science/r/SAFE-QAQ.", "AI": {"tldr": "SAFE-QAQ是一种端到端的基于音频的欺诈检测框架，通过强化学习提高复杂欺骗策略的识别能力。", "motivation": "现有欺诈检测方法主要依赖转录文本，容易受到语音识别错误的影响，并且忽视了声纹和环境背景等关键线索。为解决这些问题，SAFE-QAQ应运而生。", "method": "SAFE-QAQ提出了一个基于音频的慢思考奖励机制以及动态风险评估框架，通过层次推理过程准确捕捉细微的音频特征来识别欺诈模式。", "result": "实验表明，与现有方法相比，在准确性、推断效率和实时处理能力等多个关键维度上，SAFE-QAQ实现了显著改善。", "conclusion": "目前SAFE-QAQ已部署并每天分析超过70,000通电话，有效地减少了人力工作量和财务损失。"}}
{"id": "2601.01391", "pdf": "https://arxiv.org/pdf/2601.01391", "abs": "https://arxiv.org/abs/2601.01391", "authors": ["Ian Jacob Cabansag", "Paul Ntegeka"], "title": "Bayesian Negative Binomial Regression of Afrobeats Chart Persistence", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": null, "summary": "Afrobeats songs compete for attention on streaming platforms, where chart visibility can influence both revenue and cultural impact. This paper examines whether collaborations help songs remain on the charts longer, using daily Nigeria Spotify Top 200 data from 2024. Each track is summarized by the number of days it appears in the Top 200 during the year and its total annual streams in Nigeria. A Bayesian negative binomial regression is applied, with days on chart as the outcome and collaboration status (solo versus multi-artist) and log total streams as predictors. This approach is well suited for overdispersed count data and allows the effect of collaboration to be interpreted while controlling for overall popularity. Posterior inference is conducted using Markov chain Monte Carlo, and results are assessed using rate ratios, posterior probabilities, and predictive checks. The findings indicate that, after accounting for total streams, collaboration tracks tend to spend slightly fewer days on the chart than comparable solo tracks.", "AI": {"tldr": "研究探讨了合作是否有助于Afrobeats歌曲在尼日利亚Spotify Top 200排行榜上停留更长时间。", "motivation": "考察合作是否能提高Afrobeats歌曲的持久性，以影响其收入和文化影响力。", "method": "通过每日尼日利亚Spotify Top 200数据对2024年的歌曲进行研究，并使用贝叶斯负二项回归模型分析。将上榜天数作为结果变量，合作状态（独唱与多歌手）和总年度流媒体次数作为预测因子。", "result": "研究表明，在控制了总体流行度之后，合作曲目通常在排行榜上的时间比类似的独奏曲目略短一些。", "conclusion": "研究结论表明，即使考虑到了整体的受欢迎程度，合作歌曲仍然倾向于花费更少的时间在排行榜上。"}}
{"id": "2601.01390", "pdf": "https://arxiv.org/pdf/2601.01390", "abs": "https://arxiv.org/abs/2601.01390", "authors": ["Timothy M. Chan"], "title": "Derandomizing Pseudopolynomial Algorithms for Subset Sum", "categories": ["cs.DS"], "comment": "To appear in SODA 2026", "summary": "We reexamine the classical subset sum problem: given a set $X$ of $n$ positive integers and a number $t$, decide whether there exists a subset of $X$ that sums to $t$; or more generally, compute the set $\\mbox{out}$ of all numbers $y\\in\\{0,\\ldots,t\\}$ for which there exists a subset of $X$ that sums to $y$. Standard dynamic programming solves the problem in $O(tn)$ time. In SODA'17, two papers appeared giving the current best deterministic and randomized algorithms, ignoring polylogarithmic factors: Koiliaris and Xu's deterministic algorithm runs in $\\widetilde{O}(t\\sqrt{n})$ time, while Bringmann's randomized algorithm runs in $\\widetilde{O}(t)$ time. We present the first deterministic algorithm running in $\\widetilde{O}(t)$ time. Our technique has a number of other applications: for example, we can also derandomize the more recent output-sensitive algorithms by Bringmann and Nakos [STOC'20] and Bringmann, Fischer, and Nakos [SODA'25] running in $\\widetilde{O}(|\\mbox{out}|^{4/3})$ and $\\widetilde{O}(|\\mbox{out}|\\sqrt{n})$ time, and we can derandomize a previous fine-grained reduction from 0-1 knapsack to min-plus convolution by Cygan et al. [ICALP'17].", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.01388", "pdf": "https://arxiv.org/pdf/2601.01388", "abs": "https://arxiv.org/abs/2601.01388", "authors": ["Seoyong Lee", "Jinho Lee"], "title": "AGIS: Fast Approximate Graph Pattern Mining with Structure-Informed Sampling", "categories": ["cs.DS"], "comment": "VLDB 2026", "summary": "Approximate Graph Pattern Mining (AGPM) is essential for analyzing large-scale graphs where exact counting is computationally prohibitive. While there exist numerous sampling-based AGPM systems, they all rely on uniform sampling and overlook the underlying probability distribution. This limitation restricts their scalability to a broader range of patterns. In this paper, we introduce AGIS, an extremely fast AGPM system capable of counting arbitrary patterns from huge graphs. AGIS employs structure-informed neighbor sampling, a novel sampling technique that deviates from uniformness but allocates specific sampling probabilities based on the pattern structure. We first derive the ideal sampling distribution for AGPM and then present a practical method to approximate it. Furthermore, we develop a method that balances convergence speed and computational overhead, determining when to use the approximated distribution. Experimental results demonstrate that AGIS significantly outperforms the state-of-the-art AGPM system, achieving 28.5x geometric mean speedup and more than 100,000x speedup in specific cases. Furthermore, AGIS is the only AGPM system that scales to graphs with tens of billions of edges and robustly handles diverse patterns, successfully providing accurate estimates within seconds. We will open-source AGIS to encourage further research in this field.", "AI": {"tldr": "介绍了一种名为AGIS的快速近似图模式挖掘系统，该系统能够从大规模图形中计算任意图案。", "motivation": "当前的近似图模式挖掘系统依赖于均匀采样，并忽视了潜在的概率分布。这限制了它们对更广泛模式的支持能力。", "method": "AGIS采用了结构启发式邻居采样技术，偏离了均匀性，并根据模式结构分配特定的采样概率。该方法首先推导出理想的采样分布，然后提出了近似该分布的方法，并开发了一种平衡收敛速度和计算开销的方法。", "result": "实验结果表明，AGIS比最先进的近似图模式挖掘系统快28.5倍的几何平均速度，在某些情况下甚至超过10万倍的速度提升。此外，AGIS能够处理数十亿边的大型图形，并且对各种图案具有鲁棒性。", "conclusion": "AGIS是一种快速有效的近似图模式挖掘系统，能够在大规模数据集中提供准确估计并支持多样化的图案类型。"}}
{"id": "2601.01387", "pdf": "https://arxiv.org/pdf/2601.01387", "abs": "https://arxiv.org/abs/2601.01387", "authors": ["Yongzhe Li", "Lin Guan", "Zihan Cai", "Zuxian Lin", "Jiyu Huang", "Liukai Chen"], "title": "Scale-Adaptive Power Flow Analysis with Local Topology Slicing and Multi-Task Graph Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Developing deep learning models with strong adaptability to topological variations is of great practical significance for power flow analysis. To enhance model performance under variable system scales and improve robustness in branch power prediction, this paper proposes a Scale-adaptive Multi-task Power Flow Analysis (SaMPFA) framework. SaMPFA introduces a Local Topology Slicing (LTS) sampling technique that extracts subgraphs of different scales from the complete power network to strengthen the model's cross-scale learning capability. Furthermore, a Reference-free Multi-task Graph Learning (RMGL) model is designed for robust power flow prediction. Unlike existing approaches, RMGL predicts bus voltages and branch powers instead of phase angles. This design not only avoids the risk of error amplification in branch power calculation but also guides the model to learn the physical relationships of phase angle differences. In addition, the loss function incorporates extra terms that encourage the model to capture the physical patterns of angle differences and power transmission, further improving consistency between predictions and physical laws. Simulations on the IEEE 39-bus system and a real provincial grid in China demonstrate that the proposed model achieves superior adaptability and generalization under variable system scales, with accuracy improvements of 4.47% and 36.82%, respectively.", "AI": {"tldr": "提出了一种适应不同规模电网的深度学习模型SaMPFA，用于电力潮流分析。", "motivation": "提升深度学习模型在变化系统规模下的性能和分支功率预测鲁棒性具有重要的实际意义。", "method": "提出了基于局部拓扑切片(LTS) 技术抽取子图并引入无参考多任务图学习(RMGL) 模型，该模型直接预测节点电压和支路功率以提高模型的物理规律一致性。", "result": "实验显示该模型在IEEE 39节点系统及中国某省级电网上的准确率分别提高了4.47% 和36.82%，展示了其优越的适应性和泛化能力。", "conclusion": "所提出的SaMPFA 模型能够有效提升电力潮流分析中的跨尺度学习能力和预测精度。"}}
{"id": "2601.01386", "pdf": "https://arxiv.org/pdf/2601.01386", "abs": "https://arxiv.org/abs/2601.01386", "authors": ["Xiaobao Wei", "Zhangjie Ye", "Yuxiang Gu", "Zunjie Zhu", "Yunfei Guo", "Yingying Shen", "Shan Zhao", "Ming Lu", "Haiyang Sun", "Bing Wang", "Guang Chen", "Rongfeng Lu", "Hangjun Ye"], "title": "ParkGaussian: Surround-view 3D Gaussian Splatting for Autonomous Parking", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Parking is a critical task for autonomous driving systems (ADS), with unique challenges in crowded parking slots and GPS-denied environments. However, existing works focus on 2D parking slot perception, mapping, and localization, 3D reconstruction remains underexplored, which is crucial for capturing complex spatial geometry in parking scenarios. Naively improving the visual quality of reconstructed parking scenes does not directly benefit autonomous parking, as the key entry point for parking is the slots perception module. To address these limitations, we curate the first benchmark named ParkRecon3D, specifically designed for parking scene reconstruction. It includes sensor data from four surround-view fisheye cameras with calibrated extrinsics and dense parking slot annotations. We then propose ParkGaussian, the first framework that integrates 3D Gaussian Splatting (3DGS) for parking scene reconstruction. To further improve the alignment between reconstruction and downstream parking slot detection, we introduce a slot-aware reconstruction strategy that leverages existing parking perception methods to enhance the synthesis quality of slot regions. Experiments on ParkRecon3D demonstrate that ParkGaussian achieves state-of-the-art reconstruction quality and better preserves perception consistency for downstream tasks. The code and dataset will be released at: https://github.com/wm-research/ParkGaussian", "AI": {"tldr": "提出ParkGaussian框架，利用三维高斯点云重建技术处理停车场景，并通过引入感知一致性策略来提高下游任务的性能。", "motivation": "现有的研究工作主要集中在二维停车位感知、地图构建和定位上，而三维重构在停车环境中尚未得到充分探索。这限制了复杂空间几何结构的有效捕捉，对自主泊车系统来说是一个挑战。", "method": "建立了一种名为ParkGaussian的框架，首次将三维高斯点云重建技术应用于停车场景中，并引入感知一致性策略来增强停车位检测任务的效果。", "result": "实验显示，该方法在构建高质量停车环境3D模型的同时，能够更好地保持与下游任务之间的感知一致性。", "conclusion": "ParkGaussian框架提供了一种创新的方法来解决停车场景中的三维重建问题，并通过引入一种新的策略提高了停车位检测的准确性。"}}
{"id": "2601.01383", "pdf": "https://arxiv.org/pdf/2601.01383", "abs": "https://arxiv.org/abs/2601.01383", "authors": ["Yen-Chia Chen", "Hsing-Kuo Pao", "Hanjuan Huang"], "title": "Data Complexity-aware Deep Model Performance Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 12 figures", "summary": "Deep learning models are widely used across computer vision and other domains. When working on the model induction, selecting the right architecture for a given dataset often relies on repetitive trial-and-error procedures. This procedure is time-consuming, resource-intensive, and difficult to automate. While previous work has explored performance prediction using partial training or complex simulations, these methods often require significant computational overhead or lack generalizability. In this work, we propose an alternative approach: a lightweight, two-stage framework that can estimate model performance before training given the understanding of the dataset and the focused deep model structures. The first stage predicts a baseline based on the analysis of some measurable properties of the dataset, while the second stage adjusts the estimation with additional information on the model's architectural and hyperparameter details. The setup allows the framework to generalize across datasets and model types. Moreover, we find that some of the underlying features used for prediction - such as dataset variance - can offer practical guidance for model selection, and can serve as early indicators of data quality. As a result, the framework can be used not only to forecast model performance, but also to guide architecture choices, inform necessary preprocessing procedures, and detect potentially problematic datasets before training begins.", "AI": {"tldr": "本文提出了一种基于数据复杂度和模型结构的深度学习性能预测框架。", "motivation": "当前选择合适的深度学习架构通常依赖于耗时且难以自动化的反复试错过程，因此开发一种能够预先估计模型性能的方法显得尤为重要。", "method": "该方法采用两阶段轻量级框架：第一阶段基于数据集的可测量属性预测基准，第二阶段结合模型结构和超参数调整估测结果。", "result": "实验表明所提出的框架能广泛适用于不同数据集与模型类型，并且部分用于预测的特征还能提供关于数据质量和预处理程序的实际指导信息。", "conclusion": "该框架不仅能够有效预报深度学习模型性能，还能够在训练开始前帮助选择架构、优化预处理步骤及识别潜在问题的数据集。"}}
{"id": "2601.01378", "pdf": "https://arxiv.org/pdf/2601.01378", "abs": "https://arxiv.org/abs/2601.01378", "authors": ["Han Yuan", "Yilin Wu", "Li Zhang", "Zheng Ma"], "title": "Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification", "categories": ["cs.AI"], "comment": null, "summary": "Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability. However, compared with large language models, SLMs are more prone to factual hallucinations in reasoning and exhibit weaker classification performance. This raises a natural question: Can mitigating factual hallucinations improve SLMs' financial classification? To address this, we propose a three-step pipeline named AAAI (Association Identification, Automated Detection, and Adaptive Inference). Experiments on three representative SLMs reveal that: (1) factual hallucinations are positively correlated with misclassifications; (2) encoder-based verifiers effectively detect factual hallucinations; and (3) incorporating feedback on factual errors enables SLMs' adaptive inference that enhances classification performance. We hope this pipeline contributes to trustworthy and effective applications of SLMs in finance.", "AI": {"tldr": "提出一种减少小规模语言模型在金融分类中事实错误的方法", "motivation": "由于小规模语言模型推理过程中易出现事实错误，影响其分类性能，研究如何通过减少这些错误来提升模型效果。", "method": "设计了一个三步流程（关联识别、自动检测和自适应推理），以降低小规模语言模型的事实错误，并提高金融分类的准确性。", "result": "实验显示，事实错误与误分类正相关；基于编码器的验证器可有效检测事实错误；反馈机制可以增强模型在处理金融任务时的表现。", "conclusion": "该方法有助于提高小规模语言模型在金融领域的可靠性和有效性。"}}
{"id": "2601.01373", "pdf": "https://arxiv.org/pdf/2601.01373", "abs": "https://arxiv.org/abs/2601.01373", "authors": ["Qundong Shi", "Jie Zhou", "Biyuan Lin", "Junbo Cui", "Guoyang Zeng", "Yixuan Zhou", "Ziyang Wang", "Xin Liu", "Zhen Luo", "Yudong Wang", "Zhiyuan Liu"], "title": "UltraEval-Audio: A Unified Framework for Comprehensive Evaluation of Audio Foundation Models", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "13 pages, 2 figures", "summary": "The development of audio foundation models has accelerated rapidly since the emergence of GPT-4o. However, the lack of comprehensive evaluation has become a critical bottleneck for further progress in the field, particularly in audio generation. Current audio evaluation faces three major challenges: (1) audio evaluation lacks a unified framework, with datasets and code scattered across various sources, hindering fair and efficient cross-model comparison;(2) audio codecs, as a key component of audio foundation models, lack a widely accepted and holistic evaluation methodology; (3) existing speech benchmarks are heavily reliant on English, making it challenging to objectively assess models' performance on Chinese. To address the first issue, we introduce UltraEval-Audio, a unified evaluation framework for audio foundation models, specifically designed for both audio understanding and generation tasks. UltraEval-Audio features a modular architecture, supporting 10 languages and 14 core task categories, while seamlessly integrating 24 mainstream models and 36 authoritative benchmarks. To enhance research efficiency, the framework provides a one-command evaluation feature, accompanied by real-time public leaderboards. For the second challenge, UltraEval-Audio adopts a novel comprehensive evaluation scheme for audio codecs, evaluating performance across three key dimensions: semantic accuracy, timbre fidelity, and acoustic quality. To address the third issue, we propose two new Chinese benchmarks, SpeechCMMLU and SpeechHSK, designed to assess Chinese knowledge proficiency and language fluency. We wish that UltraEval-Audio will provide both academia and industry with a transparent, efficient, and fair platform for comparison of audio models. Our code, benchmarks, and leaderboards are available at https://github.com/OpenBMB/UltraEval-Audio.", "AI": {"tldr": "UltraEval-Audio是一款统一的音频基础模型评估框架，旨在解决当前音频生成和理解任务中缺乏综合评估的问题。", "motivation": "由于现有音频评估方法存在分散、不一致等问题，特别是在跨模型对比方面以及中文语音评测方面的挑战，导致了音频领域的发展瓶颈。因此，作者提出了UltraEval-Audio以提供一个统一的框架来解决这些问题。", "method": "该框架采用模块化设计，支持多种语言和任务类别，并且整合了主流模型和权威基准测试集。它还提出了一种新的综合评估方案用于音频编码器性能评测，以及两个针对中文知识水平和语言流畅性的新基准测试。", "result": "UltraEval-Audio提供了一个透明、高效和公平的比较平台，涵盖了10种语言，支持多种任务类别，并且能够实时更新公共排行榜。框架中还包含了代码和基准测试集以供下载使用。", "conclusion": "通过引入UltraEval-Audio框架，作者期望能为学术界和工业界提供一个更加有效的音频基础模型评估工具，促进该领域的发展进步。"}}
{"id": "2601.01366", "pdf": "https://arxiv.org/pdf/2601.01366", "abs": "https://arxiv.org/abs/2601.01366", "authors": ["Zixian Liu", "Sihao Liu", "Yuqi Zhao"], "title": "KGCE: Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models", "categories": ["cs.AI"], "comment": null, "summary": "With the rapid adoption of multimodal large language models (MLMs) in autonomous agents, cross-platform task execution capabilities in educational settings have garnered significant attention. However, existing benchmark frameworks still exhibit notable deficiencies in supporting cross-platform tasks in educational contexts, especially when dealing with school-specific software (such as XiaoYa Intelligent Assistant, HuaShi XiaZi, etc.), where the efficiency of agents often significantly decreases due to a lack of understanding of the structural specifics of these private-domain software. Additionally, current evaluation methods heavily rely on coarse-grained metrics like goal orientation or trajectory matching, making it challenging to capture the detailed execution and efficiency of agents in complex tasks. To address these issues, we propose KGCE (Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models), a novel benchmarking platform that integrates knowledge base enhancement and a dual-graph evaluation framework. We first constructed a dataset comprising 104 education-related tasks, covering Windows, Android, and cross-platform collaborative tasks. KGCE introduces a dual-graph evaluation framework that decomposes tasks into multiple sub-goals and verifies their completion status, providing fine-grained evaluation metrics. To overcome the execution bottlenecks of existing agents in private-domain tasks, we developed an enhanced agent system incorporating a knowledge base specific to school-specific software. The code can be found at https://github.com/Kinginlife/KGCE.", "AI": {"tldr": "KGCE 是一种用于跨平台教育代理基准测试的新框架，旨在通过多模式语言模型提高代理在特定学校软件中的执行效率。", "motivation": "现有的基准框架不足以支持教育环境中复杂的跨平台任务，特别是在处理专用领域软件时。当前的评估方法主要依赖于粗粒度指标，无法准确捕捉代理执行复杂任务时的细节和效率。", "method": "KGCE 构建了一个包含104个教育相关任务的数据集，并引入了一种双图评价框架来细分任务并提供细粒度的评估标准。此外，通过集成特定学校软件的知识库，改善了现有代理系统在专用领域任务中的执行瓶颈。", "result": "KGCE 的使用提升了跨平台教育代理在复杂任务和私有域任务中执行效率和准确性。", "conclusion": "KGCE 是一种有效的方法来评估并提高教育环境中跨平台代理系统的性能，特别是在特定学校软件上。"}}
{"id": "2601.01364", "pdf": "https://arxiv.org/pdf/2601.01364", "abs": "https://arxiv.org/abs/2601.01364", "authors": ["Mostofa Rafid Uddin", "Mahek Vora", "Qifeng Wu", "Muyuan Chen", "Min Xu"], "title": "Unsupervised SE(3) Disentanglement for in situ Macromolecular Morphology Identification from Cryo-Electron Tomography", "categories": ["cs.CV"], "comment": null, "summary": "Cryo-electron tomography (cryo-ET) provides direct 3D visualization of macromolecules inside the cell, enabling analysis of their in situ morphology. This morphology can be regarded as an SE(3)-invariant, denoised volumetric representation of subvolumes extracted from tomograms. Inferring morphology is therefore an inverse problem of estimating both a template morphology and its SE(3) transformation. Existing expectation-maximization based solution to this problem often misses rare but important morphologies and requires extensive manual hyperparameter tuning. Addressing this issue, we present a disentangled deep representation learning framework that separates SE(3) transformations from morphological content in the representation space. The framework includes a novel multi-choice learning module that enables this disentanglement for highly noisy cryo-ET data, and the learned morphological content is used to generate template morphologies. Experiments on simulated and real cryo-ET datasets demonstrate clear improvements over prior methods, including the discovery of previously unidentified macromolecular morphologies.", "AI": {"tldr": "本文提出了一种用于从冷冻电子断层扫描中识别大分子形态的无监督SE(3)分解框架。", "motivation": "现有的基于期望最大化的方法在解决提取大分子形态及其SE(3)变换的逆问题时，容易错过重要的形态并需要大量的手动调整参数。本文旨在通过深度表示学习来改进这一过程。", "method": "提出了一种分离SE(3)转换和形态内容的新框架，并使用多选择学习模块实现高度噪声冷冻电子断层扫描数据中的解耦。", "result": "实验表明，该方法在模拟和真实的数据集上均优于现有技术，并能识别新的大分子形态。", "conclusion": "通过无监督深度表示学习实现的SE(3)分解框架显著改善了冷冻电子断层扫描中大分子形态的识别性能。"}}
{"id": "2601.01363", "pdf": "https://arxiv.org/pdf/2601.01363", "abs": "https://arxiv.org/abs/2601.01363", "authors": ["Xiaomeng Yang", "Zhiyu Tan", "Xiaohui Zhong", "Mengping Yang", "Qiusheng Huang", "Lei Chen", "Libo Wu", "Hao Li"], "title": "A unified multimodal understanding and generation model for cross-disciplinary scientific research", "categories": ["cs.AI"], "comment": null, "summary": "Scientific discovery increasingly relies on integrating heterogeneous, high-dimensional data across disciplines nowadays. While AI models have achieved notable success across various scientific domains, they typically remain domain-specific or lack the capability of simultaneously understanding and generating multimodal scientific data, particularly for high-dimensional data. Yet, many pressing global challenges and scientific problems are inherently cross-disciplinary and require coordinated progress across multiple fields. Here, we present FuXi-Uni, a native unified multimodal model for scientific understanding and high-fidelity generation across scientific domains within a single architecture. Specifically, FuXi-Uni aligns cross-disciplinary scientific tokens within natural language tokens and employs science decoder to reconstruct scientific tokens, thereby supporting both natural language conversation and scientific numerical prediction. Empirically, we validate FuXi-Uni in Earth science and Biomedicine. In Earth system modeling, the model supports global weather forecasting, tropical cyclone (TC) forecast editing, and spatial downscaling driven by only language instructions. FuXi-Uni generates 10-day global forecasts at 0.25° resolution that outperform the SOTA physical forecasting system. It shows superior performance for both TC track and intensity prediction relative to the SOTA physical model, and generates high-resolution regional weather fields that surpass standard interpolation baselines. Regarding biomedicine, FuXi-Uni outperforms leading multimodal large language models on multiple biomedical visual question answering benchmarks. By unifying heterogeneous scientific modalities within a native shared latent space while maintaining strong domain-specific performance, FuXi-Uni provides a step forward more general-purpose, multimodal scientific models.", "AI": {"tldr": "该论文提出了一种统一多模态理解与生成模型FuXi-Uni，用于跨学科科学研究。", "motivation": "当前AI模型在科学领域中的应用虽然取得了一些成功，但仍存在域特定性或缺乏同时理解和生成多模态科学数据的能力。许多全球性挑战和科学问题需要跨领域的协作进展。", "method": "提出了FuXi-Uni模型，该模型将跨学科的科学标记与自然语言标记对齐，并利用科学解码器重建这些科学标记以支持自然语言对话和科学数值预测。", "result": "在地球系统建模中，该模型超越了最先进的物理预报系统；在生物医学方面，FuXi-Uni也优于多模态大型语言模型，在多个生物医学视觉问答基准上表现更优。", "conclusion": "通过统一不同科学领域的异构模态并在共享潜在空间内保持强大的领域特定性能，FuXi-Uni为更加通用的、多模态的科学模型的发展迈出了重要的一步。"}}
{"id": "2601.01360", "pdf": "https://arxiv.org/pdf/2601.01360", "abs": "https://arxiv.org/abs/2601.01360", "authors": ["Jiawei Fang", "Ruonan Zheng", "Xiaoxia Gao", "Shifan Jiang", "Anjun Chen", "Qi Ye", "Shihui Guo"], "title": "Garment Inertial Denoiser (GID): Endowing Accurate Motion Capture via Loose IMU Denoiser", "categories": ["cs.CV", "cs.HC"], "comment": "11 pages, 4 figures", "summary": "Wearable inertial motion capture (MoCap) provides a portable, occlusion-free, and privacy-preserving alternative to camera-based systems, but its accuracy depends on tightly attached sensors - an intrusive and uncomfortable requirement for daily use. Embedding IMUs into loose-fitting garments is a desirable alternative, yet sensor-body displacement introduces severe, structured, and location-dependent corruption that breaks standard inertial pipelines. We propose GID (Garment Inertial Denoiser), a lightweight, plug-and-play Transformer that factorizes loose-wear MoCap into three stages: (i) location-specific denoising, (ii) adaptive cross-wear fusion, and (iii) general pose prediction. GID uses a location-aware expert architecture, where a shared spatio-temporal backbone models global motion while per-IMU expert heads specialize in local garment dynamics, and a lightweight fusion module ensures cross-part consistency. This inductive bias enables stable training and effective learning from limited paired loose-tight IMU data. We also introduce GarMoCap, a combined public and newly collected dataset covering diverse users, motions, and garments. Experiments show that GID enables accurate, real-time denoising from single-user training and generalizes across unseen users, motions, and garment types, consistently improving state-of-the-art inertial MoCap methods when used as a drop-in module.", "AI": {"tldr": "该论文提出了GID（Garment Inertial Denoiser）算法，用于解决穿戴式惯性运动捕捉系统在宽松服装中的准确度问题。", "motivation": "传统的惯性运动捕捉依赖紧身传感器佩戴方式，这不舒适且难以日常使用。嵌入宽松衣服中的IMU可以改善用户体验，但会引入严重的位移误差和位置相关干扰。", "method": "GID采用了一种轻量级的Transformer模型，该模型分为三个阶段：位置特定降噪、自适应跨传感器融合以及通用姿态预测。通过共享时空主干网络来建模全局运动，并使用每个IMU的专家头部专注于局部服装动态。此外还引入了GarMoCap数据集。", "result": "实验表明，GID能够从单个用户训练中实现准确且实时的降噪效果，并能泛化到未见过的用户、动作和服装类型。其性能优于现有的惯性运动捕捉方法。", "conclusion": "通过提出GID算法，论文成功解决了宽松穿戴IMU带来的挑战，为未来提供了一种更舒适、非侵入性的运动追踪解决方案。"}}
{"id": "2601.01356", "pdf": "https://arxiv.org/pdf/2601.01356", "abs": "https://arxiv.org/abs/2601.01356", "authors": ["Dang H. Pham", "Tu N. Nguyen", "Hoa N. Nguyen"], "title": "Advanced Machine Learning Approaches for Enhancing Person Re-Identification Performance", "categories": ["cs.CV"], "comment": "in Vietnamese language", "summary": "Person re-identification (ReID) plays a critical role in intelligent surveillance systems by linking identities across multiple cameras in complex environments. However, ReID faces significant challenges such as appearance variations, domain shifts, and limited labeled data. This dissertation proposes three advanced approaches to enhance ReID performance under supervised, unsupervised domain adaptation (UDA), and fully unsupervised settings. First, SCM-ReID integrates supervised contrastive learning with hybrid loss optimization (classification, center, triplet, and centroid-triplet losses), improving discriminative feature representation and achieving state-of-the-art accuracy on Market-1501 and CUHK03 datasets. Second, for UDA, IQAGA and DAPRH combine GAN-based image augmentation, domain-invariant mapping, and pseudo-label refinement to mitigate domain discrepancies and enhance cross-domain generalization. Experiments demonstrate substantial gains over baseline methods, with mAP and Rank-1 improvements up to 12% in challenging transfer scenarios. Finally, ViTC-UReID leverages Vision Transformer-based feature encoding and camera-aware proxy learning to boost unsupervised ReID. By integrating global and local attention with camera identity constraints, this method significantly outperforms existing unsupervised approaches on large-scale benchmarks. Comprehensive evaluations across CUHK03, Market-1501, DukeMTMC-reID, and MSMT17 confirm the effectiveness of the proposed methods. The contributions advance ReID research by addressing key limitations in feature learning, domain adaptation, and label noise handling, paving the way for robust deployment in real-world surveillance systems.", "AI": {"tldr": "本文提出了三种先进的方法来提高人在图像中的识别性能，包括监督学习、无监督领域适应和完全无监督的设置。", "motivation": "人再识别在智能监控系统中起着关键作用。然而，在复杂环境中跨摄像机链接身份时面临外观变化、域偏差和标记数据有限等问题。", "method": "本文提出了三种方法：SCM-ReID，结合了监督对比学习与混合损失优化；IQAGA和DAPRH，通过GAN图像增强、领域不变映射和伪标签精炼来减小领域差异；ViTC-UReID，利用视觉变换器特征编码和摄像机感知代理学习。", "result": "实验显示SCM-ReID在Market-1501和CUHK03数据集上取得了最新的准确率。IQAGA和DAPRH在挑战性的转移场景中分别提高了mAP和Rank-1的性能达12%。ViTC-UReID在大型基准测试中的表现也优于现有无监督方法。", "conclusion": "本文的工作通过解决特征学习、领域适应和标签噪声处理的关键限制，推动了人在图像中的识别研究，并为进一步部署到实际监控系统中铺平道路。"}}
{"id": "2601.01352", "pdf": "https://arxiv.org/pdf/2601.01352", "abs": "https://arxiv.org/abs/2601.01352", "authors": ["Yixuan Lai", "He Wang", "Kun Zhou", "Tianjia Shao"], "title": "Slot-ID: Identity-Preserving Video Generation from Reference Videos via Slot-Based Temporal Identity Encoding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Producing prompt-faithful videos that preserve a user-specified identity remains challenging: models need to extrapolate facial dynamics from sparse reference while balancing the tension between identity preservation and motion naturalness. Conditioning on a single image completely ignores the temporal signature, which leads to pose-locked motions, unnatural warping, and \"average\" faces when viewpoints and expressions change. To this end, we introduce an identity-conditioned variant of a diffusion-transformer video generator which uses a short reference video rather than a single portrait. Our key idea is to incorporate the dynamics in the reference. A short clip reveals subject-specific patterns, e.g., how smiles form, across poses and lighting. From this clip, a Sinkhorn-routed encoder learns compact identity tokens that capture characteristic dynamics while remaining pretrained backbone-compatible. Despite adding only lightweight conditioning, the approach consistently improves identity retention under large pose changes and expressive facial behavior, while maintaining prompt faithfulness and visual realism across diverse subjects and prompts.", "AI": {"tldr": "本文提出了一种基于槽位的时间身份编码方法，利用短参考视频生成保真度高的视频。", "motivation": "目前从单张图像生成保留用户指定身份的视频存在挑战：模型需要从稀疏的参考中推断面部动态，并在身份保持和运动自然性之间取得平衡。忽略时间特征会导致姿势锁定、不自然扭曲等问题。", "method": "本文引入了一种基于扩散变换器的身份条件化视频生成方法，该方法利用短参考视频而不是单张图像，从参考视频中捕捉特定的动态模式并学习紧凑的身份令牌。", "result": "这种方法在大姿态变化和表情行为下显著改善了身份保留，并保持了提示忠实性和视觉真实性。", "conclusion": "所提出的方法能够有效生成保真度高且自然的视频，在不同的主题和提示下表现一致。"}}
{"id": "2601.01347", "pdf": "https://arxiv.org/pdf/2601.01347", "abs": "https://arxiv.org/abs/2601.01347", "authors": ["Yuyan Pi", "Min Jin", "Wentao Xie", "Xinhua Liu"], "title": "From Classification to Generation: An Open-Ended Paradigm for Adverse Drug Reaction Prediction Based on Graph-Motif Feature Fusion", "categories": ["cs.LG", "cs.AI"], "comment": "34 pages,5 figures", "summary": "Computational biology offers immense potential for reducing the high costs and protracted cycles of new drug development through adverse drug reaction (ADR) prediction. However, current methods remain impeded by drug data scarcity-induced cold-start challenge, closed label sets, and inadequate modeling of label dependencies. Here we propose an open-ended ADR prediction paradigm based on Graph-Motif feature fusion and Multi-Label Generation (GM-MLG). Leveraging molecular structure as an intrinsic and inherent feature, GM-MLG constructs a dual-graph representation architecture spanning the atomic level, the local molecular level (utilizing fine-grained motifs dynamically extracted via the BRICS algorithm combined with additional fragmentation rules), and the global molecular level. Uniquely, GM-MLG pioneers transforming ADR prediction from multi-label classification into Transformer Decoder-based multi-label generation. By treating ADR labels as discrete token sequences, it employs positional embeddings to explicitly capture dependencies and co-occurrence relationships within large-scale label spaces, generating predictions via autoregressive decoding to dynamically expand the prediction space. Experiments demonstrate GM-MLG achieves up to 38% improvement and an average gain of 20%, expanding the prediction space from 200 to over 10,000 types. Furthermore, it elucidates non-linear structure-activity relationships between ADRs and motifs via retrosynthetic motif analysis, providing interpretable and innovative support for systematic risk reduction in drug safety.", "AI": {"tldr": "提出了一种基于图模式特征融合和多标签生成的开放性药物不良反应预测方法。", "motivation": "旨在解决当前药物不良反应预测中存在的数据稀疏、封闭标签集以及标签依赖关系建模不足的问题，通过引入分子结构信息改善预测模型。", "method": "采用双重图表示架构结合BRICS算法和额外碎片化规则提取的局部分子模式，将多标签分类任务转换为基于Transformer解码器的多标签生成，并利用位置嵌入捕捉大规模标签空间内的依赖关系与共现关系。", "result": "实验表明GM-MLG相比现有方法有最高38%的改进和平均20%的增长，在预测空间上从200种不良反应扩大到超过10,000种，展示了非线性结构活性关系及新颖的风险降低支持。", "conclusion": "通过将药物不良反应预测任务转化为基于Transformer解码器的多标签生成问题，GM-MLG显著提高了预测性能和空间拓展能力，并提供了系统性的风险降低策略。"}}
{"id": "2601.01339", "pdf": "https://arxiv.org/pdf/2601.01339", "abs": "https://arxiv.org/abs/2601.01339", "authors": ["Weihang You", "Hanqi Jiang", "Yi Pan", "Junhao Chen", "Tianming Liu", "Fei Dou"], "title": "Achieving Fine-grained Cross-modal Understanding through Brain-inspired Hierarchical Representation Learning", "categories": ["cs.CV"], "comment": null, "summary": "Understanding neural responses to visual stimuli remains challenging due to the inherent complexity of brain representations and the modality gap between neural data and visual inputs. Existing methods, mainly based on reducing neural decoding to generation tasks or simple correlations, fail to reflect the hierarchical and temporal processes of visual processing in the brain. To address these limitations, we present NeuroAlign, a novel framework for fine-grained fMRI-video alignment inspired by the hierarchical organization of the human visual system. Our framework implements a two-stage mechanism that mirrors biological visual pathways: global semantic understanding through Neural-Temporal Contrastive Learning (NTCL) and fine-grained pattern matching through enhanced vector quantization. NTCL explicitly models temporal dynamics through bidirectional prediction between modalities, while our DynaSyncMM-EMA approach enables dynamic multi-modal fusion with adaptive weighting. Experiments demonstrate that NeuroAlign significantly outperforms existing methods in cross-modal retrieval tasks, establishing a new paradigm for understanding visual cognitive mechanisms.", "AI": {"tldr": "通过模仿人类视觉系统的层次结构，提出NeuroAlign框架实现细粒度的fMRI视频对齐。", "motivation": "现有的方法未能充分反映大脑在处理视觉信息时的层级和时间过程，因此无法准确理解神经反应。", "method": "NeuroAlign采用了两阶段机制：通过神经-时间对比学习（NTCL）进行全局语义理解和通过增强向量量化实现细粒度模式匹配。同时使用DynaSyncMM-EMA方法实现实时多模态融合与自适应加权。", "result": "实验表明，NeuroAlign在跨模态检索任务中显著优于现有方法。", "conclusion": "该研究建立了一种新的范式来理解视觉认知机制，并提出了一个基于神经科学的框架以提高跨模态理解和分析能力。"}}
{"id": "2601.01330", "pdf": "https://arxiv.org/pdf/2601.01330", "abs": "https://arxiv.org/abs/2601.01330", "authors": ["Shengji Tang", "Weihao Lin", "Jingqi Ye", "Hao Li", "Bo Zhang", "Shuyue Hu", "Tao Chen", "Wangli Ouyang", "Lei Bai", "Peng Ye"], "title": "Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale", "categories": ["cs.AI"], "comment": "12 pages", "summary": "Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely on textual similarity; (2) recent aggregation methods remain largely static, failing to select appropriate aggregators for different tasks;(3) the complementarity of routing and aggregation remains underutilized. To address these problems, we introduce JiSi, a novel framework designed to release the full potential of LLMs' collaboration through three innovations: (1) Query-Response Mixed Routing capturing both semantic information and problem difficulty; (2) Support-Set-based Aggregator Selection jointly evaluating the aggregation and domain capacity of aggregators; (3) Adaptive Routing-Aggregation Switch dynamically leveraging the advantages of routing and aggregation. Comprehensive experiments on nine benchmarks demonstrate that JiSi can surpass Gemini-3-Pro with only 47% costs by orchestrating ten open-source LLMs, while outperforming mainstream baselines. It suggests that collective intelligence represents a novel path towards Artificial General Intelligence (AGI).", "AI": {"tldr": "探索集体智能以超越单体模型，提出JiSi框架通过三项创新提升大规模语言模型协作性能。", "motivation": "大型语言模型如Gemini-3-Pro推动了技术进步，但单一扩展存在瓶颈；开放源代码LLM的协作可以成为一种替代方案，并可能实现AGI的新途径。", "method": "JiSi框架包括查询响应混合路由、支持集聚合器选择和自适应路由聚合切换三项创新技术。", "result": "实验显示，通过协调十个开源LLM，JiSi能够在成本仅为Gemini-3-Pro的47%的情况下超越其性能，并优于主流基线模型。", "conclusion": "集体智能提供了一条通往AGI的新路径，表明开放源代码LLM合作有潜力实现卓越的性能改进。"}}
{"id": "2601.01322", "pdf": "https://arxiv.org/pdf/2601.01322", "abs": "https://arxiv.org/abs/2601.01322", "authors": ["Hongjie Wang", "Niraj K. Jha"], "title": "LinMU: Multimodal Understanding Made Linear", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "eess.IV"], "comment": "23 pages, 7 figures", "summary": "Modern Vision-Language Models (VLMs) achieve impressive performance but are limited by the quadratic complexity of self-attention, which prevents their deployment on edge devices and makes their understanding of high-resolution images and long-context videos prohibitively expensive. To address this challenge, we introduce LinMU (Linear-complexity Multimodal Understanding), a VLM design that achieves linear complexity without using any quadratic-complexity modules while maintaining the performance of global-attention-based VLMs. LinMU replaces every self-attention layer in the VLM with the M-MATE block: a dual-branch module that combines a bidirectional state-space model for global context (Flex-MA branch) with localized Swin-style window attention (Local-Swin branch) for adjacent correlations. To transform a pre-trained VLM into the LinMU architecture, we propose a three-stage distillation framework that (i) initializes both branches with self-attention weights and trains the Flex-MA branch alone, (ii) unfreezes the Local-Swin branch and fine-tunes it jointly with the Flex-MA branch, and (iii) unfreezes the remaining blocks and fine-tunes them using LoRA adapters, while regressing on hidden states and token-level logits of the frozen VLM teacher. On MMMU, TextVQA, LongVideoBench, Video-MME, and other benchmarks, LinMU matches the performance of teacher models, yet reduces Time-To-First-Token (TTFT) by up to 2.7$\\times$ and improves token throughput by up to 9.0$\\times$ on minute-length videos. Ablations confirm the importance of each distillation stage and the necessity of the two branches of the M-MATE block. The proposed framework demonstrates that state-of-the-art multimodal reasoning can be achieved without quadratic attention, thus opening up avenues for long-context VLMs that can deal with high-resolution images and long videos.", "AI": {"tldr": "本文提出了一种线性复杂度的多模态理解模型LinMU，通过改进模块架构和训练框架解决了现有视觉语言模型（VLM）在高分辨率图像及长视频处理中的计算问题。", "motivation": "现有的视觉语言模型由于自注意力机制的二次时间复杂度，在部署到边缘设备或者处理高分辨率图像与长时间段视频时存在高昂的成本。本文旨在开发一个性能优越且具有线性时间复杂度的新架构来解决这些限制。", "method": "通过替换所有自注意层为M-MATE块（结合双向状态空间模型和局部窗口注意力机制），并利用三阶段蒸馏框架将预训练的VLM转变为LinMU架构，从而达到线性计算复杂度同时保持性能不变的目的。", "result": "在多个基准测试中，LinMU展示了与教师模型相当的表现，但时间效率提高2.7倍以上，吞吐量提升9倍，证明了新方法的有效性。", "conclusion": "研究表明通过避免使用二次注意力机制能够实现最先进的多模态推理性能，为未来长上下文视觉语言模型的研究提供了新的可能性。"}}
{"id": "2601.01321", "pdf": "https://arxiv.org/pdf/2601.01321", "abs": "https://arxiv.org/abs/2601.01321", "authors": ["Rong Zhou", "Dongping Chen", "Zihan Jia", "Yao Su", "Yixin Liu", "Yiwen Lu", "Dongwei Shi", "Yue Huang", "Tianyang Xu", "Yi Pan", "Xinliang Li", "Yohannes Abate", "Qingyu Chen", "Zhengzhong Tu", "Yu Yang", "Yu Zhang", "Qingsong Wen", "Gengchen Mai", "Sunyang Fu", "Jiachen Li", "Xuyu Wang", "Ziran Wang", "Jing Huang", "Tianming Liu", "Yong Chen", "et al. (2 additional authors not shown)"], "title": "Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models", "categories": ["cs.AI"], "comment": null, "summary": "Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing technologies and practices, we distill a unified four-stage framework that systematically characterizes how AI methodologies are embedded across the digital twin lifecycle: (1) modeling the physical twin through physics-based and physics-informed AI approaches, (2) mirroring the physical system into a digital twin with real-time synchronization, (3) intervening in the physical twin through predictive modeling, anomaly detection, and optimization strategies, and (4) achieving autonomous management through large language models, foundation models, and intelligent agents. We analyze the synergy between physics-based modeling and data-driven learning, highlighting the shift from traditional numerical solvers to physics-informed and foundation models for physical systems. Furthermore, we examine how generative AI technologies, including large language models and generative world models, transform digital twins into proactive and self-improving cognitive systems capable of reasoning, communication, and creative scenario generation. Through a cross-domain review spanning eleven application domains, including healthcare, aerospace, smart manufacturing, robotics, and smart cities, we identify common challenges related to scalability, explainability, and trustworthiness, and outline directions for responsible AI-driven digital twin systems.", "AI": {"tldr": "本文提出了一个统一的四阶段框架，系统地描述了人工智能在数字孪生生命周期中的集成过程。", "motivation": "通过整合现有的技术和实践，提出了一种将人工智能嵌入到物理系统的数字化模拟、实时同步、预测干预和自主管理四个阶段的方法论框架。", "method": "本文提出了一个统一的四阶段方法论框架：（1）基于物理建模的数字孪生构建；（2）通过数据驱动学习进行系统镜像与实时同步；（3）利用预测模型、异常检测和优化策略对物理系统进行干预；（4）运用大型语言模型、基础模型以及智能代理实现自主管理。", "result": "该研究识别了包括医疗保健、航空航天在内的十一个应用领域的共同挑战，并提出了负责的人工智能驱动数字孪生系统的方向。", "conclusion": "本文强调了物理建模和数据驱动学习之间的协同效应，探讨了生成性AI技术如何将数字孪生转变为具有推理能力、沟通能力和创意场景生成功能的认知系统。"}}
{"id": "2601.01320", "pdf": "https://arxiv.org/pdf/2601.01320", "abs": "https://arxiv.org/abs/2601.01320", "authors": ["Muntasir Adnan", "Carlos C. N. Kuhn"], "title": "Adaptive Hierarchical Evaluation of LLMs and SAST tools for CWE Prediction in Python", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models have become integral to software development, yet they frequently generate vulnerable code. Existing code vulnerability detection benchmarks employ binary classification, lacking the CWE-level specificity required for actionable feedback in iterative correction systems. We present ALPHA (Adaptive Learning via Penalty in Hierarchical Assessment), the first function-level Python benchmark that evaluates both LLMs and SAST tools using hierarchically aware, CWE-specific penalties. ALPHA distinguishes between over-generalisation, over-specification, and lateral errors, reflecting practical differences in diagnostic utility. Evaluating seven LLMs and two SAST tools, we find LLMs substantially outperform SAST, though SAST demonstrates higher precision when detections occur. Critically, prediction consistency varies dramatically across models (8.26%-81.87% agreement), with significant implications for feedback-driven systems. We further outline a pathway for future work incorporating ALPHA penalties into supervised fine-tuning, which could provide principled hierarchy-aware vulnerability detection pending empirical validation.", "AI": {"tldr": "本文提出了一种用于评估大型语言模型和静态应用安全测试工具的函数级Python基准ALPHA，该方法使用具有层次意识、CWE特异性惩罚的方法进行代码漏洞预测。", "motivation": "现有代码漏洞检测基准采用二元分类法，缺乏在迭代纠正系统中所需的CWE级别特定性。本文旨在解决这一问题并提供更具体的反馈以改善软件开发中的安全性。", "method": "ALPHA通过层次感知、CWE特异性的惩罚方法评估大型语言模型和静态应用安全测试工具的性能，并区分过度概括、过度指定和横向错误，从而反映诊断效用的实际差异。", "result": "实验表明，大型语言模型在代码漏洞预测方面明显优于静态应用安全测试工具。然而，在检测发生时，静态应用安全测试工具表现出更高的精确度。此外，各模型的预测一致性存在显著差异（8.26%-81.87%的一致性），这可能对反馈驱动系统产生重大影响。", "conclusion": "本文提出了ALPHA，一种用于评估大型语言模型和SAST工具的新基准，并表明了它在代码漏洞预测中的重要性和潜力。未来工作将探索如何在监督微调中应用这些惩罚以提供更具原则性的层次感知漏洞检测方法。"}}
{"id": "2601.01317", "pdf": "https://arxiv.org/pdf/2601.01317", "abs": "https://arxiv.org/abs/2601.01317", "authors": ["Chang Shao", "Qi Zhao", "Nana Pu", "Shi Cheng", "Jing Jiang", "Yuhui Shi"], "title": "Benchmarking Continuous Dynamic Multi-Objective Optimization: Survey and Generalized Test Suite", "categories": ["cs.NE"], "comment": null, "summary": "Dynamic multi-objective optimization (DMOO) has recently attracted increasing interest from both academic researchers and engineering practitioners, as numerous real-world applications that evolve over time can be naturally formulated as dynamic multi-objective optimization problems (DMOPs). This growing trend necessitates advanced benchmarks for the rigorous evaluation of optimization algorithms under realistic conditions. This paper introduces a comprehensive and principled framework for constructing highly realistic and challenging DMOO benchmarks. The proposed framework features several novel components: a generalized formulation that allows the Pareto-optimal Set (PS) to change on hypersurfaces, a mechanism for creating controlled variable contribution imbalances to generate heterogeneous landscapes, and dynamic rotation matrices for inducing time-varying variable interactions and non-separability. Furthermore, we incorporate a temporal perturbation mechanism to simulate irregular environmental changes and propose a generalized time-linkage mechanism that systematically embeds historical solution quality into future problems, thereby capturing critical real-world phenomena such as error accumulation and time-deception. Extensive experimental results validate the effectiveness of the proposed framework, demonstrating its superiority over conventional benchmarks in terms of realism, complexity, and its capability for discriminating state-of-the-art algorithmic performance. This work establishes a new standard for dynamic multi-objective optimization benchmarking, providing a powerful tool for the development and evaluation of next-generation algorithms capable of addressing the complexities of real-world dynamic systems.", "AI": {"tldr": "本文提出了一种用于构建动态多目标优化（DMOO）基准的综合性框架，该框架能够模拟复杂且真实的环境变化。", "motivation": "随着越来越多的实际应用可以被自然地表述为随时间演化的动态多目标优化问题，需要更先进的测试工具来评估优化算法在现实条件下的表现。", "method": "本文提出了一种具有多种新颖组件的DMOO基准构造方法，包括一个允许帕累托最优集（PS）变化在高维表面上的新公式，以及用于创建控制变量贡献不平衡和时间旋转矩阵等机制。此外还引入了时间扰动机制和历史解质量嵌入机制来模拟环境变化和解决质量问题。", "result": "实验结果表明所提出的框架比传统基准更真实、复杂，并能更好地区分先进算法的性能。", "conclusion": "这项工作为DMOO测试提供了新的标准，是一种开发新一代能够处理现实世界动态系统复杂性的算法的强大工具。"}}
{"id": "2601.01315", "pdf": "https://arxiv.org/pdf/2601.01315", "abs": "https://arxiv.org/abs/2601.01315", "authors": ["Alireza Asadbeygi", "Anne M. Robertson", "Yasutaka Tobe", "Masoud Zamani", "Sean D. Stocker", "Paul Watton", "Naoki Yoshimura", "Simon C Watkins"], "title": "Quantifying Local Strain Field and Deformation in Active Contraction of Bladder Using a Pretrained Transformer Model: A Speckle-Free Approach", "categories": ["q-bio.TO", "cs.AI", "cs.CV"], "comment": null, "summary": "Accurate quantification of local strain fields during bladder contraction is essential for understanding the biomechanics of bladder micturition, in both health and disease. Conventional digital image correlation (DIC) methods have been successfully applied to various biological tissues; however, this approach requires artificial speckling, which can alter both passive and active properties of the tissue. In this study, we introduce a speckle-free framework for quantifying local strain fields using a state-of-the-art, zero-shot transformer model, CoTracker3. We utilized a custom-designed, portable isotonic biaxial apparatus compatible with multiphoton microscopy (MPM) to demonstrate this approach, successfully tracking natural bladder lumen textures without artificial markers. Benchmark tests validated the method's high pixel accuracy and low strain errors. Our framework effectively captured heterogeneous deformation patterns, despite complex folding and buckling, which conventional DIC often fails to track. Application to in vitro active bladder contractions in four rat specimens (n=4) revealed statistically significant anisotropy (p<0.01), with higher contraction longitudinally compared to circumferentially. Multiphoton microscopy further illustrated and confirmed heterogeneous morphological changes, such as large fold formation during active contraction. This non-invasive approach eliminates speckle-induced artifacts, enabling more physiologically relevant measurements, and has broad applicability for material testing of other biological and engineered systems.", "AI": {"tldr": "利用预训练的变压器模型（CoTracker3）进行无散斑框架下的膀胱局部应变场量化。", "motivation": "准确量化膀胱收缩期间的局部应变场对于理解健康和疾病状态下的膀胱排尿生物力学至关重要。传统的数字图像相关法需要人工散斑标记，这可能改变组织的主动性和被动性特性。", "method": "使用自定义设计的手持等张双轴装置与多光子显微镜兼容，成功跟踪了自然膀胱腔纹理；利用零样本变压器模型CoTracker3进行无散斑框架下的局部应变场量化。", "result": "在体外主动膀胱收缩实验中，在四只大鼠标本上显示出了明显的各向异性（p<0.01），纵向收缩大于环形方向。多光子显微镜进一步证实了复杂的形态变化，如收缩期间的大折叠形成。", "conclusion": "该无创方法消除了散斑引起的伪影，提供了更接近生理的相关测量，并且在其他生物和工程系统中的材料测试中具有广泛的应用前景。"}}
{"id": "2601.01312", "pdf": "https://arxiv.org/pdf/2601.01312", "abs": "https://arxiv.org/abs/2601.01312", "authors": ["Kailash A. Hambarde", "Hugo Proença", "Md Rashidunnabi", "Pranita Samale", "Qiwei Yang", "Pingping Zhang", "Zijing Gong", "Yuhao Wang", "Xi Zhang", "Ruoshui Qu", "Qiaoyun He", "Yuhang Zhang", "Thi Ngoc Ha Nguyen", "Tien-Dung Mai", "Cheng-Jun Kang", "Yu-Fan Lin", "Jin-Hui Jiang", "Chih-Chung Hsu", "Tamás Endrei", "György Cserey", "Ashwat Rajbhandari"], "title": "VReID-XFD: Video-based Person Re-identification at Extreme Far Distance Challenge Results", "categories": ["cs.CV"], "comment": null, "summary": "Person re-identification (ReID) across aerial and ground views at extreme far distances introduces a distinct operating regime where severe resolution degradation, extreme viewpoint changes, unstable motion cues, and clothing variation jointly undermine the appearance-based assumptions of existing ReID systems. To study this regime, we introduce VReID-XFD, a video-based benchmark and community challenge for extreme far-distance (XFD) aerial-to-ground person re-identification. VReID-XFD is derived from the DetReIDX dataset and comprises 371 identities, 11,288 tracklets, and 11.75 million frames, captured across altitudes from 5.8 m to 120 m, viewing angles from oblique (30 degrees) to nadir (90 degrees), and horizontal distances up to 120 m. The benchmark supports aerial-to-aerial, aerial-to-ground, and ground-to-aerial evaluation under strict identity-disjoint splits, with rich physical metadata. The VReID-XFD-25 Challenge attracted 10 teams with hundreds of submissions. Systematic analysis reveals monotonic performance degradation with altitude and distance, a universal disadvantage of nadir views, and a trade-off between peak performance and robustness. Even the best-performing SAS-PReID method achieves only 43.93 percent mAP in the aerial-to-ground setting. The dataset, annotations, and official evaluation protocols are publicly available at https://www.it.ubi.pt/DetReIDX/ .", "AI": {"tldr": "提出VReID-XFD基准测试和挑战，用于研究极端远距离（XFD）下的视频人体重识别。", "motivation": "现有ReID系统在处理极端远距离情况下的人体重识别时面临诸多挑战，如分辨率下降、视点变化大、运动线索不稳定和服装变化等。因此需要一个专门的基准测试来评估这些方法的有效性。", "method": "构建VReID-XFD数据集，并组织了一个社区挑战，吸引了10个团队参与，提交了数百次结果。数据集中包含了在不同高度、视角和水平距离下的身份信息。", "result": "通过分析发现随着高度和距离的增加性能下降显著；顶视图普遍不如斜视图效果好；存在峰值性能与鲁棒性的权衡问题。", "conclusion": "尽管进行了大量研究，当前最好的SAS-PReID方法在极端远距条件下的人体重识别任务中表现依然有限，仅达到了43.93%的mAP。"}}
{"id": "2601.01301", "pdf": "https://arxiv.org/pdf/2601.01301", "abs": "https://arxiv.org/abs/2601.01301", "authors": ["Keith Frankston", "Benjamin Howard"], "title": "Accelerating Monte-Carlo Tree Search with Optimized Posterior Policies", "categories": ["cs.AI", "cs.LG"], "comment": "11 pages; an efficient implementation is available at https://github.com/bhoward73/rmcts", "summary": "We introduce a recursive AlphaZero-style Monte--Carlo tree search algorithm, \"RMCTS\". The advantage of RMCTS over AlphaZero's MCTS-UCB is speed. In RMCTS, the search tree is explored in a breadth-first manner, so that network inferences naturally occur in large batches. This significantly reduces the GPU latency cost. We find that RMCTS is often more than 40 times faster than MCTS-UCB when searching a single root state, and about 3 times faster when searching a large batch of root states. The recursion in RMCTS is based on computing optimized posterior policies at each game state in the search tree, starting from the leaves and working back up to the root. Here we use the posterior policy explored in \"Monte--Carlo tree search as regularized policy optimization\" (Grill, et al.) Their posterior policy is the unique policy which maximizes the expected reward given estimated action rewards minus a penalty for diverging from the prior policy. The tree explored by RMCTS is not defined in an adaptive manner, as it is in MCTS-UCB. Instead, the RMCTS tree is defined by following prior network policies at each node. This is a disadvantage, but the speedup advantage is more significant, and in practice we find that RMCTS-trained networks match the quality of MCTS-UCB-trained networks in roughly one-third of the training time. We include timing and quality comparisons of RMCTS vs. MCTS-UCB for three games: Connect-4, Dots-and-Boxes, and Othello.", "AI": {"tldr": "介绍了一种加速的AlphaZero式蒙特卡洛树搜索算法（RMCTS），通过优化后验策略提高速度。", "motivation": "为了减少GPU延迟成本，提出一种新的MCTS方法以加快搜索速度，特别是在单根状态和大批次根状态下。", "method": "在RMCTS中，采用广度优先遍历搜索树，并基于每个游戏节点的先验网络政策进行优化后验策略计算。这种方法比传统的UCB MCTS更快，但训练树的方式固定而非自适应。", "result": "相比MCTS-UCB，RMCTS的速度提升显著：单根状态下快超过40倍，批量根状态下单次搜索则快约3倍；同时在大约三分之一的时间内匹配了同等质量的网络训练结果。", "conclusion": "尽管RMCTS不具有自适应性，但通过优化后验策略和大批次推理有效加快了蒙特卡洛树搜索的速度，并且在网络训练质量方面接近于传统方法。"}}
{"id": "2601.01299", "pdf": "https://arxiv.org/pdf/2601.01299", "abs": "https://arxiv.org/abs/2601.01299", "authors": ["Ismail Lamaakal", "Chaymae Yahyati", "Yassine Maleh", "Khalid El Makkaoui", "Ibrahim Ouahbi"], "title": "T3C: Test-Time Tensor Compression with Consistency Guarantees", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "We present T3C, a train-once, test-time budget-conditioned compression framework that exposes rank and precision as a controllable deployment knob. T3C combines elastic tensor factorization (maintained up to a maximal rank) with rank-tied mixed-precision quantization and a lightweight controller that maps a latency/energy/size budget token to per-layer rank/bit assignments; the policy snaps to hardware-aligned profiles and is monotone in the budget. A fast, layerwise consistency certificate, computed from spectral proxies and activation statistics, upper-bounds logit drift and regularizes training, yielding a practical reliability signal with negligible overhead. On ImageNet-1k, T3C shifts the vision Pareto frontier: for ResNet-50 at matched accuracy (\\leq 0.5% drop), p50 latency is 1.18ms with a 38MB model, outperforming PTQ-8b (1.44ms, 88MB); for ViT-B/16, T3C reaches 2.30ms p50 with 59MB, improving over strong PTQ/QAT baselines. A single T3C checkpoint therefore provides predictable, certificate-backed accuracy-latency-size trade-offs on demand across devices.", "AI": {"tldr": "T3C是一种在测试时根据预算条件进行压缩的框架，它结合了弹性张量分解和秩绑定混合精度量化，能够提供准确性和性能之间的可预测权衡。", "motivation": "为了提高模型部署时的效率，同时保证准确性。该方法通过引入一种新的压缩技术来适应不同的硬件资源限制（如延迟、能耗和大小），从而实现在不重新训练的情况下，根据实际情况调整模型的表现。", "method": "T3C结合了弹性张量分解（保持最大秩）与秩绑定混合精度量化，并配以轻量级控制器将预算令牌映射为每层的秩/位分配。此外，它还使用了一种快速计算的一致性证书来控制逻辑漂移并确保模型可靠性。", "result": "T3C在ImageNet-1k数据集上测试时，在匹配精度下（≤0.5%下降），ResNet-50模型延迟为1.18ms且大小为38MB，优于PTQ-8b；对于ViT-B/16模型，它达到2.30ms的中位数延迟和59MB的大小，比强PTQ/QAT基线更优。", "conclusion": "通过提供基于证书支持的准确性、延迟性和大小之间的可预测权衡，单一T3C检查点能够在不同设备上根据需求进行调整。"}}
{"id": "2601.01298", "pdf": "https://arxiv.org/pdf/2601.01298", "abs": "https://arxiv.org/abs/2601.01298", "authors": ["Jorge L. Ruiz Williams"], "title": "Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware", "categories": ["cs.LG", "cs.AI", "cs.AR", "cs.DC", "cs.MA"], "comment": null, "summary": "Current multi-agent Large Language Model (LLM) frameworks suffer from linear memory scaling, rendering \"System 2\" parallel reasoning impractical on consumer hardware. We present Warp Cortex, an asynchronous architecture that theoretically enables million-agent cognitive scaling by decoupling agent logic from physical memory. Through Singleton Weight Sharing and a novel Topological Synapse--inspired by hybrid landmarking techniques from Topological Data Analysis (TDA)--we reduce memory complexity from O(N * L) to O(1) for weights and O(N * k) for context, where k << L. By treating the KV-cache as a point cloud in latent space, we apply witness-complex-inspired sparsification to preserve persistent homological features of the context manifold. On a single NVIDIA RTX 4090, we empirically demonstrate 100 concurrent agents at 2.2 GB total VRAM, with theoretical capacity exceeding 1,000 agents before compute latency becomes the bottleneck. We further introduce Referential Injection, a non-intrusive KV-cache update mechanism that allows asynchronous sub-agents to influence primary generation without stream disruption.", "AI": {"tldr": "文章提出了Warp-Cortex架构，通过异步机制和Singleton Weight Sharing减少多代理大型语言模型框架的内存消耗，使其在消费者硬件上实现大规模并行推理。", "motivation": "当前的多代理大型语言模型框架由于线性内存增长导致难以实现在消费者硬件上的“System 2”平行推理。", "method": "通过引入异步架构、Singleton Weight Sharing和Topological Synapse，减少权重及上下文存储的需求，采用KV-缓存点云化处理，并使用见证复杂度启发的稀疏化技术。", "result": "在单个NVIDIA RTX 4090上实现100个并发代理且总VRAM使用量仅为2.2GB，理论上可支持超过1000个代理。", "conclusion": "Warp-Cortex架构成功解决了多代理大型语言模型框架内存效率问题，并提高了消费者硬件上的并行推理能力。"}}
{"id": "2601.01297", "pdf": "https://arxiv.org/pdf/2601.01297", "abs": "https://arxiv.org/abs/2601.01297", "authors": ["Anantha Sharma"], "title": "ARGUS: Adaptive Rotation-Invariant Geometric Unsupervised System", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "26 pages", "summary": "Detecting distributional drift in high-dimensional data streams presents fundamental challenges: global comparison methods scale poorly, projection-based approaches lose geometric structure, and re-clustering methods suffer from identity instability. This paper introduces Argus, A framework that reconceptualizes drift detection as tracking local statistics over a fixed spatial partition of the data manifold. The key contributions are fourfold. First, it is proved that Voronoi tessellations over canonical orthonormal frames yield drift metrics that are invariant to orthogonal transformations. The rotations and reflections that preserve Euclidean geometry. Second, it is established that this framework achieves O(N) complexity per snapshot while providing cell-level spatial localization of distributional change. Third, a graph-theoretic characterization of drift propagation is developed that distinguishes coherent distributional shifts from isolated perturbations. Fourth, product quantization tessellation is introduced for scaling to very high dimensions (d>500) by decomposing the space into independent subspaces and aggregating drift signals across subspaces. This paper formalizes the theoretical foundations, proves invariance properties, and presents experimental validation demonstrating that the framework correctly identifies drift under coordinate rotation while existing methods produce false positives. The tessellated approach offers a principled geometric foundation for distribution monitoring that preserves high-dimensional structure without the computational burden of pairwise comparisons.", "AI": {"tldr": "ARGUS是一种用于检测高维数据流中分布漂移的框架，通过固定空间分区跟踪局部统计量来解决现有方法的问题。", "motivation": "现有的全局比较、投影和重新聚类方法在处理高维数据流时存在性能差、几何结构丢失或身份不稳定等问题。为此，需要一种新的方法来有效检测并定位分布变化。", "method": "ARGUS通过固定空间分区跟踪局部统计量实现漂移检测，并利用Voronoi镶嵌提供旋转不变的度量；使用图论对传播进行表征以区分整体变化和孤立扰动；引入产品量化嵌入高维数据，减少计算负担。", "result": "实验验证了ARGUS在坐标旋转下能正确识别漂移，而现有方法会产生假阳性结果。该框架能够保持高维结构并在不增加计算成本的情况下实现分布监测的理论基础。", "conclusion": "ARGUS提供了一种有效且具有理论支撑的方法来检测高维数据流中的分布漂移，并通过实验验证其性能优越性。"}}
{"id": "2601.01296", "pdf": "https://arxiv.org/pdf/2601.01296", "abs": "https://arxiv.org/abs/2601.01296", "authors": ["Davis Brown", "Juan-Pablo Rivera", "Dan Hendrycks", "Mantas Mazeika"], "title": "Aggressive Compression Enables LLM Weight Theft", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "An early version of this work was presented at the SoLAR Workshop at NeurIPS 2024", "summary": "As frontier AIs become more powerful and costly to develop, adversaries have increasing incentives to steal model weights by mounting exfiltration attacks. In this work, we consider exfiltration attacks where an adversary attempts to sneak model weights out of a datacenter over a network. While exfiltration attacks are multi-step cyber attacks, we demonstrate that a single factor, the compressibility of model weights, significantly heightens exfiltration risk for large language models (LLMs). We tailor compression specifically for exfiltration by relaxing decompression constraints and demonstrate that attackers could achieve 16x to 100x compression with minimal trade-offs, reducing the time it would take for an attacker to illicitly transmit model weights from the defender's server from months to days. Finally, we study defenses designed to reduce exfiltration risk in three distinct ways: making models harder to compress, making them harder to 'find,' and tracking provenance for post-attack analysis using forensic watermarks. While all defenses are promising, the forensic watermark defense is both effective and cheap, and therefore is a particularly attractive lever for mitigating weight-exfiltration risk.", "AI": {"tldr": "研究通过压缩技术增加大型语言模型权重被盗风险的方法及防御措施。", "motivation": "随着前沿AI变得越来越强大和昂贵，攻击者有越来越多的动机试图窃取模型权重。该研究表明，单一因素——模型权重的可压缩性极大地增加了大语言模型被窃的风险。", "method": "通过放松解压约束定制特定于外泄目的的压缩技术，并研究三种减少外泄风险的方法：使模型更难压缩、更难以找到以及使用取证水印进行事后分析。", "result": "攻击者可实现16倍到100倍的压缩率，传输时间从数月缩短至几天；其中取证水印防御措施既有效又经济。", "conclusion": "研究证明了通过特定于外泄目的的压缩可以显著提高窃取大型语言模型权重的可能性，并提出了一种有效的取证水印防御策略来降低风险。"}}
{"id": "2601.01294", "pdf": "https://arxiv.org/pdf/2601.01294", "abs": "https://arxiv.org/abs/2601.01294", "authors": ["Ching Ho Lee", "Javier Nistal", "Stefan Lattner", "Marco Pasini", "George Fazekas"], "title": "Diffusion Timbre Transfer Via Mutual Information Guided Inpainting", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "6 pages, 2 figures, 3 tables", "summary": "We study timbre transfer as an inference-time editing problem for music audio. Starting from a strong pre-trained latent diffusion model, we introduce a lightweight procedure that requires no additional training: (i) a dimension-wise noise injection that targets latent channels most informative of instrument identity, and (ii) an early-step clamping mechanism that re-imposes the input's melodic and rhythmic structure during reverse diffusion. The method operates directly on audio latents and is compatible with text/audio conditioning (e.g., CLAP). We discuss design choices,analyze trade-offs between timbral change and structural preservation, and show that simple inference-time controls can meaningfully steer pre-trained models for style-transfer use cases.", "AI": {"tldr": "研究如何在推理时编辑音乐音频的音色转换问题，通过引入轻量级过程来调整已训练的扩散模型以实现风格迁移。", "motivation": "探索利用预训练的扩散模型进行音乐音频中的音色转移，并提出无需额外训练的方法来实现在推理阶段对音色和结构的同时控制。", "method": "通过对潜变量注入噪声以及早期步长限制机制，在不改变旋律和节奏的情况下修改目标乐器的身份特征，操作直接应用于音频潜变量且与文本/音频条件相兼容（例如CLAP）。", "result": "证明了简单的推理时间控制可以有意义地引导预训练模型在风格转换使用案例中发挥作用。", "conclusion": "展示了通过注入噪声和早期步长限制机制的轻量级方法如何有效实现音乐音色转移，同时保持旋律和节奏结构。"}}
{"id": "2601.01288", "pdf": "https://arxiv.org/pdf/2601.01288", "abs": "https://arxiv.org/abs/2601.01288", "authors": ["Evgenii Rudakov", "Jonathan Shock", "Benjamin Ultan Cowley"], "title": "PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS", "categories": ["cs.GR", "cs.AI", "cs.PF", "cs.RO"], "comment": null, "summary": "Reinforcement learning from pixels is often bottlenecked by the performance and complexity of 3D rendered environments. Researchers face a trade-off between high-speed, low-level engines and slower, more accessible Python frameworks. To address this, we introduce PyBatchRender, a Python library for high-throughput, batched 3D rendering that achieves over 1 million FPS on simple scenes. Built on the Panda3D game engine, it utilizes its mature ecosystem while enhancing performance through optimized batched rendering for up to 1000X speedups. Designed as a physics-agnostic renderer for reinforcement learning from pixels, PyBatchRender offers greater flexibility than dedicated libraries, simpler setup than typical game-engine wrappers, and speeds rivaling state-of-the-art C++ engines like Madrona. Users can create custom scenes entirely in Python with tens of lines of code, enabling rapid prototyping for scalable AI training. Open-source and easy to integrate, it serves to democratize high-performance 3D simulation for researchers and developers. The library is available at https://github.com/dolphin-in-a-coma/PyBatchRender.", "AI": {"tldr": "介绍了PyBatchRender，一个用于大规模并行渲染的Python库，能够实现高达每秒一百万帧的速度。", "motivation": "为了提高从像素学习的强化学习效率，并解决当前高性能引擎与易用性之间的矛盾，作者提出了一种新的解决方案来优化3D渲染过程。", "method": "通过利用Panda3D游戏引擎强大的生态系统并进行批量渲染以提升性能，PyBatchRender实现了超过1百万FPS的速度。", "result": "在简单的场景中，PyBatchRender能够实现高达每秒一百万帧的渲染速度，并提供了比其他Python框架更灵活、易用且高效的解决方案。", "conclusion": "PyBatchRender作为一种开源库，极大地提高了大规模3D模拟对于研究人员和开发者的可访问性与实用性。"}}
{"id": "2601.01285", "pdf": "https://arxiv.org/pdf/2601.01285", "abs": "https://arxiv.org/abs/2601.01285", "authors": ["Md. Sanaullah Chowdhury Lameya Sabrin"], "title": "S2M-Net: Spectral-Spatial Mixing for Medical Image Segmentation with Morphology-Aware Adaptive Loss", "categories": ["cs.CV"], "comment": null, "summary": "Medical image segmentation requires balancing local precision for boundary-critical clinical applications, global context for anatomical coherence, and computational efficiency for deployment on limited data and hardware a trilemma that existing architectures fail to resolve. Although convolutional networks provide local precision at $\\mathcal{O}(n)$ cost but limited receptive fields, vision transformers achieve global context through $\\mathcal{O}(n^2)$ self-attention at prohibitive computational expense, causing overfitting on small clinical datasets. We propose S2M-Net, a 4.7M-parameter architecture that achieves $\\mathcal{O}(HW \\log HW)$ global context through two synergistic innovations: (i) Spectral-Selective Token Mixer (SSTM), which exploits the spectral concentration of medical images via truncated 2D FFT with learnable frequency filtering and content-gated spatial projection, avoiding quadratic attention cost while maintaining global receptive fields; and (ii) Morphology-Aware Adaptive Segmentation Loss (MASL), which automatically analyzes structure characteristics (compactness, tubularity, irregularity, scale) to modulate five complementary loss components through constrained learnable weights, eliminating manual per-dataset tuning. Comprehensive evaluation in 16 medical imaging datasets that span 8 modalities demonstrates state-of-the-art performance: 96.12\\% Dice on polyp segmentation, 83.77\\% on surgical instruments (+17.85\\% over the prior art) and 80.90\\% on brain tumors, with consistent 3-18\\% improvements over specialized baselines while using 3.5--6$\\times$ fewer parameters than transformer-based methods.", "AI": {"tldr": "提出了一种用于医学图像分割的新架构S2M-Net，结合了局部精度和全局上下文的平衡。", "motivation": "现有方法在处理医学图像分割时，在局部准确性、全局一致性和计算效率方面存在挑战。卷积网络提供局部精度但受限于感受野；视觉变换器通过自注意力机制实现全局上下文理解，但在小数据集上容易过拟合。", "method": "S2M-Net通过两种创新解决上述问题：(i) 谱选择令牌混合器（SSTM），利用截断的二维傅里叶变换和可学习频谱过滤来获得全局感知域；(ii) 形态学适应分割损失函数（MASL），自适应调节五种互补损失成分，提高性能。", "result": "实验在16个医学影像数据集上显示了S2M-Net的优越性：多任务平均骰子系数分别为96.12%，83.77%和80.90%，参数量少于基于变换器的方法。", "conclusion": "通过引入新的架构，S2M-Net在医学图像分割中取得了最先进的性能，并且比传统方法更具有计算效率。"}}
{"id": "2601.01282", "pdf": "https://arxiv.org/pdf/2601.01282", "abs": "https://arxiv.org/abs/2601.01282", "authors": ["Fang Nan", "Meher Malladi", "Qingqing Li", "Fan Yang", "Joonas Juola", "Tiziano Guadagnino", "Jens Behley", "Cesar Cadena", "Cyrill Stachniss", "Marco Hutter"], "title": "SAHA: Supervised Autonomous HArvester for selective forest thinning", "categories": ["cs.RO"], "comment": null, "summary": "Forestry plays a vital role in our society, creating significant ecological, economic, and recreational value. Efficient forest management involves labor-intensive and complex operations. One essential task for maintaining forest health and productivity is selective thinning, which requires skilled operators to remove specific trees to create optimal growing conditions for the remaining ones. In this work, we present a solution based on a small-scale robotic harvester (SAHA) designed for executing this task with supervised autonomy. We build on a 4.5-ton harvester platform and implement key hardware modifications for perception and automatic control. We implement learning- and model-based approaches for precise control of hydraulic actuators, accurate navigation through cluttered environments, robust state estimation, and reliable semantic estimation of terrain traversability. Integrating state-of-the-art techniques in perception, planning, and control, our robotic harvester can autonomously navigate forest environments and reach targeted trees for selective thinning. We present experimental results from extensive field trials over kilometer-long autonomous missions in northern European forests, demonstrating the harvester's ability to operate in real forests. We analyze the performance and provide the lessons learned for advancing robotic forest management.", "AI": {"tldr": "该论文介绍了基于小型机器人收割机SAHA进行选择性森林疏伐的任务。", "motivation": "为了提高林业管理效率，减少人工操作复杂性和劳动力需求，开发一种能够自主执行选择性疏伐任务的机器人系统。", "method": "基于4.5吨级收割平台，通过硬件改造和软件集成实现感知、自动控制。采用学习与模型相结合的方法来精确控制液压驱动器，进行准确导航、可靠的状态估计以及语义地形可通达性的估计。", "result": "经过数百公里的自主试验，在北欧森林中展示了机器人收割机能够执行选择性疏伐任务的能力，并提供了性能分析和经验教训。", "conclusion": "研究表明SAHA能够在真实林业环境中进行有效操作，为未来机器人化森林管理奠定了基础。"}}
{"id": "2601.01281", "pdf": "https://arxiv.org/pdf/2601.01281", "abs": "https://arxiv.org/abs/2601.01281", "authors": ["Sifatullah Sheikh Urmi", "Kirtonia Nuzath Tabassum Arthi", "Md Al-Imran"], "title": "AI-Powered Deepfake Detection Using CNN and Vision Transformer Architectures", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "6 pages, 6 figures, 3 tables. Conference paper", "summary": "The increasing use of artificial intelligence generated deepfakes creates major challenges in maintaining digital authenticity. Four AI-based models, consisting of three CNNs and one Vision Transformer, were evaluated using large face image datasets. Data preprocessing and augmentation techniques improved model performance across different scenarios. VFDNET demonstrated superior accuracy with MobileNetV3, showing efficient performance, thereby demonstrating AI's capabilities for dependable deepfake detection.", "AI": {"tldr": "本文利用CNN和Vision Transformer架构评估了四种AI模型在大型面部图像数据集上的深度伪造检测性能。", "motivation": "随着人工智能生成的深度伪造内容增加，保持数字真实性面临重大挑战。此研究旨在通过使用先进的神经网络模型来提高深度伪造检测的能力。", "method": "本文利用三种CNN和一种Vision Transformer架构构建了四个AI模型，并应用数据预处理及增强技术以改善不同情况下的模型性能。", "result": "VFDNET与MobileNetV3结合显示出了最佳的准确度，表现出高效且可靠的深度伪造检测能力。", "conclusion": "实验结果表明，使用先进的神经网络架构可以有效地提高深度伪造内容的检测率。"}}
{"id": "2601.01280", "pdf": "https://arxiv.org/pdf/2601.01280", "abs": "https://arxiv.org/abs/2601.01280", "authors": ["Sen Hu", "Yuxiang Wei", "Jiaxin Ran", "Zhiyuan Yao", "Lei Zou"], "title": "Does Memory Need Graphs? A Unified Framework and Empirical Analysis for Long-Term Dialog Memory", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Graph structures are increasingly used in dialog memory systems, but empirical findings on their effectiveness remain inconsistent, making it unclear which design choices truly matter. We present an experimental, system-oriented analysis of long-term dialog memory architectures. We introduce a unified framework that decomposes dialog memory systems into core components and supports both graph-based and non-graph approaches. Under this framework, we conduct controlled, stage-wise experiments on LongMemEval and HaluMem, comparing common design choices in memory representation, organization, maintenance, and retrieval. Our results show that many performance differences are driven by foundational system settings rather than specific architectural innovations. Based on these findings, we identify stable and reliable strong baselines for future dialog memory research.", "AI": {"tldr": "长期对话记忆系统中的图形结构使用越来越普遍，但其有效性尚不明确。本文通过引入统一框架和实验分析探讨了不同设计选择的效果。", "motivation": "图结构在对话记忆系统中被广泛应用，但关于它们效果的实证研究结果并不一致，难以确定哪些设计决策真正重要。", "method": "提出了一个分解对话记忆系统的统一框架，并进行了控制性分阶段实验，比较了常用的设计选择。", "result": "研究表明许多性能差异是由基础系统设置驱动的，而非特定架构创新所致。识别出了一些稳定可靠的基准模型。", "conclusion": "基于这些发现，未来的研究可以在此基础上继续探索对话记忆系统的优化方法。"}}
{"id": "2601.01279", "pdf": "https://arxiv.org/pdf/2601.01279", "abs": "https://arxiv.org/abs/2601.01279", "authors": ["Shengyu Cao", "Ming Hu"], "title": "LLM Collusion", "categories": ["econ.TH", "cs.AI", "cs.CE", "cs.CL", "cs.GT"], "comment": "44 pages", "summary": "We study how delegating pricing to large language models (LLMs) can facilitate collusion in a duopoly when both sellers rely on the same pre-trained model. The LLM is characterized by (i) a propensity parameter capturing its internal bias toward high-price recommendations and (ii) an output-fidelity parameter measuring how tightly outputs track that bias; the propensity evolves through retraining. We show that configuring LLMs for robustness and reproducibility can induce collusion via a phase transition: there exists a critical output-fidelity threshold that pins down long-run behavior. Below it, competitive pricing is the unique long-run outcome. Above it, the system is bistable, with competitive and collusive pricing both locally stable and the realized outcome determined by the model's initial preference. The collusive regime resembles tacit collusion: prices are elevated on average, yet occasional low-price recommendations provide plausible deniability. With perfect fidelity, full collusion emerges from any interior initial condition. For finite training batches of size $b$, infrequent retraining (driven by computational costs) further amplifies collusion: conditional on starting in the collusive basin, the probability of collusion approaches one as $b$ grows, since larger batches dampen stochastic fluctuations that might otherwise tip the system toward competition. The indeterminacy region shrinks at rate $O(1/\\sqrt{b})$.", "AI": {"tldr": "研究如何通过大型语言模型（LLM）进行价格推荐以促进双寡头市场中的合谋行为。", "motivation": "探讨在两个卖方依赖同一个预训练的LLM时，该模型如何影响他们之间的价格竞争和合作策略。", "method": "使用一个带有内部偏置倾向参数和输出忠实度参数的LLM模拟定价决策过程，并研究通过重新训练来调整这些参数以诱导合谋的行为模式。", "result": "发现存在一个临界输出忠实度阈值，超过该阈值会导致系统的双稳态特性：即竞争性和合作性价格策略都可以稳定存在。完全忠实时，从任何内部初始条件都能达到全合谋状态。随着训练批次的增加，重新训练频率减少会进一步加剧合谋。", "conclusion": "揭示了配置LLM以促进稳健和可重复性的设置可能诱导市场参与者之间的合谋行为，特别是在输出忠实度较高的情况下。"}}
{"id": "2601.01274", "pdf": "https://arxiv.org/pdf/2601.01274", "abs": "https://arxiv.org/abs/2601.01274", "authors": ["Md. Sadman Haque", "Zobaer Ibn Razzaque", "Robiul Awoul Robin", "Fahim Hafiz", "Riasat Azim"], "title": "An Energy-Efficient Smart Bus Transport Management System with Blind-Spot Collision Detection Ability", "categories": ["eess.SY", "cs.CV"], "comment": "29 pages, 11 figures", "summary": "Public bus transport systems in developing countries often suffer from a lack of real-time location updates and for users, making commuting inconvenient and unreliable for passengers. Furthermore, stopping at undesired locations rather than designated bus stops creates safety risks and contributes to roadblocks, often causing traffic congestion. Additionally, issues such as blind spots, along with a lack of following traffic laws, increase the chances of accidents. In this work, we address these challenges by proposing a smart public bus system along with intelligent bus stops that enhance safety, efficiency, and sustainability. Our approach includes a deep learning-based blind-spot warning system to help drivers avoid accidents with automated bus-stop detection to accurately identify bus stops, improving transit efficiency. We also introduce IoT-based solar-powered smart bus stops that show real-time passenger counts, along with an RFID-based card system to track where passengers board and exit. A smart door system ensures safer and more organised boarding, while real-time bus tracking keeps passengers informed. To connect all these features, we use an HTTP-based server for seamless communication between the interconnected network systems. Our proposed system demonstrated approximately 99% efficiency in real-time blind spot detection while stopping precisely at the bus stops. Furthermore, the server showed real-time location updates both to the users and at the bus stops, enhancing commuting efficiency. The proposed energy-efficient bus stop demonstrated 12.71kWh energy saving, promoting sustainable architecture. Full implementation and source code are available at: https://github.com/sadman-adib/MoveMe-IoT", "AI": {"tldr": "本文提出了一种智能公交系统，包含盲点警告和自动停靠识别等功能，以提高公共交通的安全性和效率。", "motivation": "在发展中国家，公共汽车运输系统由于缺乏实时位置更新和服务的不便性，导致乘客通勤不便利且不可靠。此外，公交车在非指定站点停车增加了交通事故的风险，并造成了交通堵塞问题。", "method": "该方法采用深度学习技术实现盲点警告和自动停靠识别功能；使用物联网技术和太阳能智能公交站显示实时乘客人数，并通过RFID卡系统追踪上下车站点位置；智能门控确保安全有序的乘车过程，而实时车辆跟踪则使乘客得到及时更新。所有这些功能均通过基于HTTP协议的服务器实现无缝连接。", "result": "该系统的盲点检测准确率为约99%，并在公交站点停靠时表现出色；此外，该服务器能够提供给用户和车站实时位置信息的更新，提高了通勤效率；智能站台展示了12.71kWh的能源节约成果。", "conclusion": "通过整合多种先进技术，本文提出的系统成功地提升了公共交通的安全性、效率与可持续性。"}}
{"id": "2601.01266", "pdf": "https://arxiv.org/pdf/2601.01266", "abs": "https://arxiv.org/abs/2601.01266", "authors": ["Rhitabrat Pokharel", "Hamid Hassanzadeh", "Ameeta Agrawal"], "title": "From Policy to Logic for Efficient and Interpretable Coverage Assessment", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at AIMedHealth @ AAAI 2026", "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in interpreting lengthy, complex legal and policy language. However, their reliability can be undermined by hallucinations and inconsistencies, particularly when analyzing subjective and nuanced documents. These challenges are especially critical in medical coverage policy review, where human experts must be able to rely on accurate information. In this paper, we present an approach designed to support human reviewers by making policy interpretation more efficient and interpretable. We introduce a methodology that pairs a coverage-aware retriever with symbolic rule-based reasoning to surface relevant policy language, organize it into explicit facts and rules, and generate auditable rationales. This hybrid system minimizes the number of LLM inferences required which reduces overall model cost. Notably, our approach achieves a 44% reduction in inference cost alongside a 4.5% improvement in F1 score, demonstrating both efficiency and effectiveness.", "AI": {"tldr": "本文提出了一种结合覆盖意识检索器和符号规则推理的方法，以提高政策解读的效率与可解释性。", "motivation": "大型语言模型在解析法律和政策文件时存在幻觉和不一致性问题，特别是在医疗覆盖率政策审查中需要准确的信息，因此需要一种支持人类审阅者的高效且可解释的解决方案。", "method": "通过结合覆盖意识检索器与符号规则推理的方法，系统可以有效地提取相关政策语言，并将其组织为明确的事实和规则，从而生成可审计的理由。", "result": "该方法在减少模型推理成本的同时提高了F1分数，具体来说，实现了44%的推理成本降低以及4.5%的F1得分提升。", "conclusion": "提出的方法不仅高效而且有效，在提高效率的同时保证了准确性和解释性。"}}
{"id": "2601.01260", "pdf": "https://arxiv.org/pdf/2601.01260", "abs": "https://arxiv.org/abs/2601.01260", "authors": ["Hamad Khan", "Saddam Hussain Khan"], "title": "MambaFormer: Token-Level Guided Routing Mixture-of-Experts for Accurate and Efficient Clinical Assistance", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "28 Pages, Tables 12, Figure 09", "summary": "The deployment of large language models (LLMs) in real-world clinical applications is constrained by the fundamental trade-off between computational cost and the efficiency of linear-time models. To address this, we propose an LLM-based MambaFormer hybrid Mixture-of-Experts (MoE) framework for efficient medical question-answering (QA) and clinical assistance. The MambaFormer employs a lightweight gating mechanism that performs token-level dynamic routing to a customized Transformer expert (ET5) for short, complex queries or to a State Space Model expert (EMamba) for long, high-throughput sequences. The customized EMamba and ET5 models are tailored to accommodate input sequence dimensionality, embedding structure, sequence length, and target-specific output heads, and are fine-tuned through transfer learning on a new, custom-designed DentalQA dataset. Moreover, intelligent routing decisions are driven by the contextual complexity of token embeddings, normalized sequence length, and domain-aware features, thereby enforcing a Pareto-optimal trade-off between inference latency and prediction accuracy. Furthermore, a novel utility-guided multi-objective loss jointly optimizes decisions, router parameters, routing behavior, expert utilization, and computational cost by adaptively regulating token-level expert activation. Finally, the proposed MambaFormer is cross-validated (holdout) for medical QA on the new, custom-designed DentalQA and PubMedQA datasets and compared with state-of-the-art techniques. The proposed MambaFormer outperforms (BERTScore = 0.9180) with ultra-low latency (0.077 s), delivering a 24.4 speedup over T5-Large and establishing a scalable solution for resource-constrained clinical deployment.", "AI": {"tldr": "提出了一种高效的MambaFormer混合专家模型，用于临床辅助中的问答任务。", "motivation": "大型语言模型在实际医疗应用中面临计算成本与效率的权衡问题。", "method": "通过轻量级门控机制实现令牌级别动态路由至定制化的Transformer专家或状态空间模型专家。利用新型效用引导多目标损失优化决策和专家利用率，以适应输入序列维度、嵌入结构等特征。", "result": "在DentalQA和PubMedQA数据集上验证了MambaFormer的性能，其BERTScore为0.9180，延迟仅为0.077秒，并且比T5-Large快24.4倍。", "conclusion": "MambaFormer提供了一个可扩展的解决方案，适用于资源受限的临床部署。"}}
{"id": "2601.01257", "pdf": "https://arxiv.org/pdf/2601.01257", "abs": "https://arxiv.org/abs/2601.01257", "authors": ["Gaetane Lorna N. Tchana", "Damaris Belle M. Fotso", "Antonio Hendricks", "Christophe Bobda"], "title": "Seamlessly Natural: Image Stitching with Natural Appearance Preservation", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.GR", "eess.SP"], "comment": null, "summary": "This paper introduces SENA (SEamlessly NAtural), a geometry-driven image stitching approach that prioritizes structural fidelity in challenging real-world scenes characterized by parallax and depth variation. Conventional image stitching relies on homographic alignment, but this rigid planar assumption often fails in dual-camera setups with significant scene depth, leading to distortions such as visible warps and spherical bulging. SENA addresses these fundamental limitations through three key contributions. First, we propose a hierarchical affine-based warping strategy, combining global affine initialization with local affine refinement and smooth free-form deformation. This design preserves local shape, parallelism, and aspect ratios, thereby avoiding the hallucinated structural distortions commonly introduced by homography-based models. Second, we introduce a geometry-driven adequate zone detection mechanism that identifies parallax-minimized regions directly from the disparity consistency of RANSAC-filtered feature correspondences, without relying on semantic segmentation. Third, building upon this adequate zone, we perform anchor-based seamline cutting and segmentation, enforcing a one-to-one geometric correspondence across image pairs by construction, which effectively eliminates ghosting, duplication, and smearing artifacts in the final panorama. Extensive experiments conducted on challenging datasets demonstrate that SENA achieves alignment accuracy comparable to leading homography-based methods, while significantly outperforming them in critical visual metrics such as shape preservation, texture integrity, and overall visual realism.", "AI": {"tldr": "SEN A是一种基于几何的图像拼接方法，旨在解决传统基于同构变换的方法在处理深度差异较大的场景时产生的结构失真问题。", "motivation": "传统的图像拼接技术由于假设平面刚性对齐，在处理具有明显深度变化的真实世界场景时效果不佳，导致可见扭曲和球形膨胀等畸变。为此，作者提出了SENA方法来解决这些问题。", "method": "SENA通过分层仿射变换策略、几何驱动的适当区域检测机制以及基于锚点的缝线切割与分割三个关键步骤来进行图像拼接，确保局部形状、平行性和宽高比的保真，并减少重影和模糊等伪影。", "result": "实验结果显示，在具有挑战性的数据集上，SENA在对齐精度方面可媲美领先的同构方法，同时在形状保持、纹理完整性和视觉逼真度这些关键指标上表现更优。", "conclusion": "通过提出一种新的几何驱动的图像拼接算法——SENA，有效地解决了传统方法在处理具有显著深度变化场景时存在的结构失真问题。"}}
{"id": "2601.01247", "pdf": "https://arxiv.org/pdf/2601.01247", "abs": "https://arxiv.org/abs/2601.01247", "authors": ["Wei Xu"], "title": "Human-Centered Artificial Intelligence (HCAI): Foundations and Approaches", "categories": ["cs.HC"], "comment": null, "summary": "Artificial Intelligence (AI) is a transformative yet double-edged technology that can advance human welfare while also posing risks to humans and society. In response, the Human-Centered Artificial Intelligence (HCAI) approach has emerged as both a design philosophy and a methodological complement to prevailing technology-centered AI paradigms. Placing humans at the core, HCAI seeks to ensure that AI systems serve, augment, and empower humans rather than harm or replace them. This chapter establishes the conceptual and methodological foundations of HCAI by tracing its evolution and recent advancements. It introduces key HCAI concepts, frameworks, guiding principles, methodologies, and practical strategies that bridge philosophical HCAI principles with operational implementation. Through an analytical review of the emerging characteristics and challenges of AI technologies, the chapter positions HCAI as a holistic paradigm for aligning AI innovation with human values, societal well-being, and sustainable progress. Finally, this chapter outlines the structure and contributions of the Handbook of Human-Centered Artificial Intelligence. The purpose of this chapter is to provide an integrated foundation that connects HCAI conceptual frameworks, principles, methodology, and practices for this handbook, thereby paving the way for the content of subsequent chapters.", "AI": {"tldr": "该论文介绍了以人为本的人工智能（HCAI）的概念、原则和方法论。", "motivation": "人工智能具有推动人类福祉的潜力，同时也可能对人类和社会构成风险。为确保AI系统服务于人类并增强其能力而不是对其造成危害或取代他们，提出了以人为本的人工智能（HCAI）的方法。", "method": "通过回顾现有的技术和哲学基础，论文介绍了HCAI的关键概念、框架和原则，并探讨了实现这些理念的具体策略。", "result": "该论文为后续章节提供了综合性的理论框架和支持HCAI实施的实践方法论。", "conclusion": "HCAI旨在作为一个全面的框架来协调人工智能创新与人类价值观、社会福祉和可持续进步的目标。"}}
{"id": "2601.01240", "pdf": "https://arxiv.org/pdf/2601.01240", "abs": "https://arxiv.org/abs/2601.01240", "authors": ["Ziqian Guan", "Xieyi Fu", "Yuting Wang", "Haowen Xiao", "Jiarui Zhu", "Yingying Zhu", "Yongtao Liu", "Lin Gu"], "title": "RFAssigner: A Generic Label Assignment Strategy for Dense Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Label assignment is a critical component in training dense object detectors. State-of-the-art methods typically assign each training sample a positive and a negative weight, optimizing the assignment scheme during training. However, these strategies often assign an insufficient number of positive samples to small objects, leading to a scale imbalance during training. To address this limitation, we introduce RFAssigner, a novel assignment strategy designed to enhance the multi-scale learning capabilities of dense detectors. RFAssigner first establishes an initial set of positive samples using a point-based prior. It then leverages a Gaussian Receptive Field (GRF) distance to measure the similarity between the GRFs of unassigned candidate locations and the ground-truth objects. Based on this metric, RFAssigner adaptively selects supplementary positive samples from the unassigned pool, promoting a more balanced learning process across object scales. Comprehensive experiments on three datasets with distinct object scale distributions validate the effectiveness and generalizability of our method. Notably, a single FCOS-ResNet-50 detector equipped with RFAssigner achieves state-of-the-art performance across all object scales, consistently outperforming existing strategies without requiring auxiliary modules or heuristics.", "AI": {"tldr": "本文提出了一种新的标签分配策略RFAssigner，用于增强密集对象检测器的多尺度学习能力。", "motivation": "现有的标签分配方法在训练过程中常常对小物体分配不足的正样本，导致不同尺度的对象之间存在学习不平衡的问题。因此需要一种更好的分配策略来解决这个问题。", "method": "RFAssigner首先基于点先验确定初始正样本集，然后通过高斯感受野距离衡量未分配候选位置和真实对象之间的相似度，并据此从剩余未分配池中自适应选择补充的正样本。", "result": "实验验证了RFAssigner在不同数据集中均表现出色，使单个FCOS-ResNet-50检测器实现了跨所有尺度的最佳性能，优于现有的方法，且无需辅助模块或启发式规则。", "conclusion": "通过引入RFAssigner策略，可以有效解决标签分配中针对小物体样本不足的问题，并提高了密集对象检测算法的整体性能。"}}
{"id": "2601.01239", "pdf": "https://arxiv.org/pdf/2601.01239", "abs": "https://arxiv.org/abs/2601.01239", "authors": ["Jiajie Zhu", "Xia Du", "Xiaoyuan Liu", "Jizhe Zhou", "Qizhen Xu", "Zheng Lin", "Chi-Man Pun"], "title": "IO-RAE: Information-Obfuscation Reversible Adversarial Example for Audio Privacy Protection", "categories": ["cs.SD", "cs.CR", "cs.MM", "eess.AS"], "comment": "10 pages, 5 figures", "summary": "The rapid advancements in artificial intelligence have significantly accelerated the adoption of speech recognition technology, leading to its widespread integration across various applications. However, this surge in usage also highlights a critical issue: audio data is highly vulnerable to unauthorized exposure and analysis, posing significant privacy risks for businesses and individuals. This paper introduces an Information-Obfuscation Reversible Adversarial Example (IO-RAE) framework, the pioneering method designed to safeguard audio privacy using reversible adversarial examples. IO-RAE leverages large language models to generate misleading yet contextually coherent content, effectively preventing unauthorized eavesdropping by humans and Automatic Speech Recognition (ASR) systems. Additionally, we propose the Cumulative Signal Attack technique, which mitigates high-frequency noise and enhances attack efficacy by targeting low-frequency signals. Our approach ensures the protection of audio data without degrading its quality or our ability. Experimental evaluations demonstrate the superiority of our method, achieving a targeted misguidance rate of 96.5% and a remarkable 100% untargeted misguidance rate in obfuscating target keywords across multiple ASR models, including a commercial black-box system from Google. Furthermore, the quality of the recovered audio, measured by the Perceptual Evaluation of Speech Quality score, reached 4.45, comparable to high-quality original recordings. Notably, the recovered audio processed by ASR systems exhibited an error rate of 0%, indicating nearly lossless recovery. These results highlight the practical applicability and effectiveness of our IO-RAE framework in protecting sensitive audio privacy.", "AI": {"tldr": "本文提出了一个保护音频隐私的方法——信息混淆可逆对抗样本框架（IO-RAE），通过生成误导性的但语境上连贯的内容来防止未经授权的窃听和语音识别系统的解析。", "motivation": "随着人工智能技术的发展，语音识别技术在各种应用中得到了广泛应用。然而，这也导致音频数据容易受到未授权的暴露和分析，给企业和个人带来了隐私风险。本文旨在通过一种新的方法保护音频隐私。", "method": "IO-RAE利用大型语言模型生成误导但语境连贯的内容，并提出了累积信号攻击技术来降低高频噪声并提高攻击效率。这种方法可以在不牺牲音频质量的情况下防止未经授权的窃听和语音识别系统的解析。", "result": "实验表明，该方法在针对关键词混淆时，达到了96.5%的目标误导率和100%的非目标误导率；恢复后的音频质量评价为4.45分（接近高质量原始录音），并且通过ASR系统处理后的错误率为0%，实现了近乎无损的恢复。", "conclusion": "本文提出的IO-RAE框架在保护敏感音频隐私方面表现出良好的实用性和有效性。"}}
{"id": "2601.01237", "pdf": "https://arxiv.org/pdf/2601.01237", "abs": "https://arxiv.org/abs/2601.01237", "authors": ["Abidemi Koledoye", "Chinemerem Unachukwu", "Gold Nwobu", "Hasin Rana"], "title": "Benchmarking the Computational and Representational Efficiency of State Space Models against Transformers on Long-Context Dyadic Sessions", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages", "summary": "State Space Models (SSMs) have emerged as a promising alternative to Transformers for long-context sequence modeling, offering linear $O(N)$ computational complexity compared to the Transformer's quadratic $O(N^2)$ scaling. This paper presents a comprehensive benchmarking study comparing the Mamba SSM against the LLaMA Transformer on long-context sequences, using dyadic therapy sessions as a representative test case. We evaluate both architectures across two dimensions: (1) computational efficiency, where we measure memory usage and inference speed from 512 to 8,192 tokens, and (2) representational efficiency, where we analyze hidden state dynamics and attention patterns. Our findings provide actionable insights for practitioners working with long-context applications, establishing precise conditions under which SSMs offer advantages over Transformers.", "AI": {"tldr": "评估状态空间模型在长上下文序列建模中的计算和表征效率", "motivation": "对比Transformer，研究状态空间模型在长文本处理方面的优势", "method": "使用Mamba SSM与LLaMA Transformer，在512至8,192令牌范围内进行内存使用、推断速度等评估，同时分析隐藏状态动态及注意力模式", "result": "提供了关于SSMs相对于Transformers的计算和表征效率的具体见解", "conclusion": "确定了特定条件下SSMs优于Transformer的应用场景"}}
{"id": "2601.01234", "pdf": "https://arxiv.org/pdf/2601.01234", "abs": "https://arxiv.org/abs/2601.01234", "authors": ["Ka-Yan Fung", "Yuxing Tao", "Tze-Leung", "Rick Lui", "Kuen-Fung Sin"], "title": "Bridging Language Gaps: Utilizing Interactive Robots to Teach Cantonese in Real-Life Contexts for Newly-Arrived Children", "categories": ["cs.ET", "cs.HC", "cs.RO"], "comment": null, "summary": "Hong Kong's education system is notably multicultural, including local, non-Chinese-speaking, and newly arrived students (NAS) (Mandarine Chinese-speaking). NAS can guess the meaning of vocabulary but cannot speak out, presenting unique challenges for them, particularly language barriers and cultural differences. These challenges hinder their academic success and social integration, leading to feelings of isolation and demotivation. Current resources often fail to address the emotional well-being of these students and predominantly focus on English language acquisition, leaving a gap in support for learning Cantonese and navigating the local cultural landscape. This study explores the effectiveness of an interactive robot, Boon Boon, in teaching Cantonese through real-life contexts to enhance NAS children learning engagement and motivation. The research questions are: (1) How does interactive robot-empowered scenario learning influence the learning engagement and motivation of NAS in learning Cantonese? and (2) What is the impact of a robot-empowered scenario learning system on the Cantonese language proficiency of NAS? Fourteen children are invited to participate in a four-day learning program with Boon Boon. The preliminary result indicated that Boon Boon drove students' attention to learning and academic achievement. Future research will focus on long-term assessments of robot-empowered learning's effectiveness and explore the scalability of this approach across diverse educational settings and cultural backgrounds.", "AI": {"tldr": "研究探讨了使用互动机器人Boon Boon在真实场景中教授新来港儿童学习粤语的效果。", "motivation": "香港教育系统存在语言和文化差异，使得非华语背景的新来港学生面临学术成功和社会融入的挑战。传统资源侧重于英语教学，并未充分支持学习粤语和适应当地文化。", "method": "邀请14名儿童参加为期四天的学习项目，通过与互动机器人Boon Boon进行真实场景下的语言学习，评估这种模式对新来港儿童学习积极性和语言能力的影响。", "result": "初步结果显示，使用交互式机器人可以提高学生的注意力和学业成绩。", "conclusion": "研究初步表明，利用互动机器人教授粤语有助于提升新来港学生的学习兴趣及动机，并能改善他们的语言能力。未来的研究将关注长期评估效果及其在不同教育环境中的可扩展性。"}}
{"id": "2601.01228", "pdf": "https://arxiv.org/pdf/2601.01228", "abs": "https://arxiv.org/abs/2601.01228", "authors": ["Markus Haltmeier", "Lukas Neumann", "Nadja Gruber", "Johannes Schwab", "Gyeongha Hwang"], "title": "HyDRA: Hybrid Denoising Regularization for Measurement-Only DEQ Training", "categories": ["cs.CV", "math.NA"], "comment": null, "summary": "Solving image reconstruction problems of the form \\(\\mathbf{A} \\mathbf{x} = \\mathbf{y}\\) remains challenging due to ill-posedness and the lack of large-scale supervised datasets. Deep Equilibrium (DEQ) models have been used successfully but typically require supervised pairs \\((\\mathbf{x},\\mathbf{y})\\). In many practical settings, only measurements \\(\\mathbf{y}\\) are available. We introduce HyDRA (Hybrid Denoising Regularization Adaptation), a measurement-only framework for DEQ training that combines measurement consistency with an adaptive denoising regularization term, together with a data-driven early stopping criterion. Experiments on sparse-view CT demonstrate competitive reconstruction quality and fast inference.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.01227", "pdf": "https://arxiv.org/pdf/2601.01227", "abs": "https://arxiv.org/abs/2601.01227", "authors": ["Ka Yan Fung", "Kwong Chiu Fung", "Yuxing Tao", "Tze Leung Rick Lui", "Kuen Fung Sin"], "title": "LiveBo: Empowering Non-Chinese Speaking Students through AI-Driven Real-Life Scenarios in Cantonese", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "Language learning is a multifaceted process. Insufficient vocabulary can hinder communication and lead to demotivation. For non-Chinese speaking (NCS) students, learning Traditional Chinese (Cantonese) poses distinct challenges, particularly due to the complexity of converting spoken and written forms. To address this issue, this study examines the effectiveness of real-life scenario simulations integrated with interactive social robots in enhancing NCS student engagement and language acquisition. The research employs a quasi-experimental design involving NCS students who interact with an AI-driven, robot-assisted language learning system, LiveBo. The study aims to assess the impact of this innovative approach on active participation and motivation. Data are collected through proficiency tests, questionnaires and semi-structured interviews. Findings indicate that NCS students experience positive improvements in behavioural and emotional engagement, motivation and learning outcomes, highlighting the potential of integrating novel technologies in language education. We plan to compare with the control group in the future. This study highlights the significance of interactive and immersive learning experiences in promoting motivation and enhancing language acquisition among NCS students.", "AI": {"tldr": "本研究通过使用AI驱动的社交机器人LiveBo，探讨了在学习粤语的真实生活场景模拟对非中文母语学生参与度和语言习得的影响。", "motivation": "针对非中文母语学生学习粤语过程中词汇量不足、沟通障碍及由此带来的动机下降问题，本研究旨在探索利用AI驱动的社交机器人进行真实生活场景模拟的教学方法的有效性。", "method": "该研究采用准实验设计，让非中文母语学生与一个AI驱动的互动语言学习系统LiveBo交互。通过熟练度测试、问卷调查和半结构化访谈收集数据，并计划未来与对照组进行比较。", "result": "初步结果表明，在行为参与度、情绪投入、动机及学习成果方面，非中文母语学生的表现出显著提升，突显了在语言教育中集成新型技术的重要潜力。", "conclusion": "此研究强调互动性和沉浸式的学习体验对激发非中文母语学生的学习动机和提高其语言习得成效的重要性。"}}
{"id": "2601.01225", "pdf": "https://arxiv.org/pdf/2601.01225", "abs": "https://arxiv.org/abs/2601.01225", "authors": ["Hezam Albaqami", "Muhammad Asif Ayub", "Nasir Ahmad", "Yaseen Ahmad", "Mohammed M. Alqahtani", "Abdullah M. Algamdi", "Almoaid A. Owaidah", "Kashif Ahmad"], "title": "Stylometry Analysis of Human and Machine Text for Academic Integrity", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 9 tables, 3 figures", "summary": "This work addresses critical challenges to academic integrity, including plagiarism, fabrication, and verification of authorship of educational content, by proposing a Natural Language Processing (NLP)-based framework for authenticating students' content through author attribution and style change detection. Despite some initial efforts, several aspects of the topic are yet to be explored. In contrast to existing solutions, the paper provides a comprehensive analysis of the topic by targeting four relevant tasks, including (i) classification of human and machine text, (ii) differentiating in single and multi-authored documents, (iii) author change detection within multi-authored documents, and (iv) author recognition in collaboratively produced documents. The solutions proposed for the tasks are evaluated on two datasets generated with Gemini using two different prompts, including a normal and a strict set of instructions. During experiments, some reduction in the performance of the proposed solutions is observed on the dataset generated through the strict prompt, demonstrating the complexities involved in detecting machine-generated text with cleverly crafted prompts. The generated datasets, code, and other relevant materials are made publicly available on GitHub, which are expected to provide a baseline for future research in the domain.", "AI": {"tldr": "本文提出了一种基于自然语言处理的框架，用于通过作者归属和风格变化检测来验证学生内容的真实性。", "motivation": "针对学术诚信中的抄袭、伪造等问题，文章旨在提供一种全面的方法以解决这些挑战，并探索尚未充分研究的任务领域。", "method": "论文提出了一个框架，该框架能够区分人类文本与机器生成的文本，识别单一和多作者文档的区别，检测多作者文档内的作者变化以及在合作生产的文件中进行作者辨识。这些解决方案通过两个由Gemini生成的数据集进行了评估。", "result": "实验结果表明，在使用严格指令生成的数据集中，所提出的方法性能有所下降，这显示了识别精心设计提示下产生的机器文本的复杂性。", "conclusion": "本文提出的框架和数据集为未来相关领域的研究提供了基础。"}}
{"id": "2601.01224", "pdf": "https://arxiv.org/pdf/2601.01224", "abs": "https://arxiv.org/abs/2601.01224", "authors": ["Bac Nguyen", "Yuhta Takida", "Naoki Murata", "Chieh-Hsin Lai", "Toshimitsu Uesaka", "Stefano Ermon", "Yuki Mitsufuji"], "title": "Improved Object-Centric Diffusion Learning with Registers and Contrastive Alignment", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Slot Attention (SA) with pretrained diffusion models has recently shown promise for object-centric learning (OCL), but suffers from slot entanglement and weak alignment between object slots and image content. We propose Contrastive Object-centric Diffusion Alignment (CODA), a simple extension that (i) employs register slots to absorb residual attention and reduce interference between object slots, and (ii) applies a contrastive alignment loss to explicitly encourage slot-image correspondence. The resulting training objective serves as a tractable surrogate for maximizing mutual information (MI) between slots and inputs, strengthening slot representation quality. On both synthetic (MOVi-C/E) and real-world datasets (VOC, COCO), CODA improves object discovery (e.g., +6.1% FG-ARI on COCO), property prediction, and compositional image generation over strong baselines. Register slots add negligible overhead, keeping CODA efficient and scalable. These results indicate potential applications of CODA as an effective framework for robust OCL in complex, real-world scenes.", "AI": {"tldr": "该论文提出了一种改进的对象中心扩散学习方法CODA，通过引入寄存器槽和对比对齐损失来解决物体槽之间的纠缠问题，并提高对象发现、属性预测和合成图像生成的能力。", "motivation": "基于预训练的扩散模型的Slot Attention在对象中心学习中显示了潜力，但存在物体槽缠绕及与图象内容对齐不足的问题。因此需要改进以增强其表现。", "method": "CODA采用寄存器槽吸收剩余注意力来减少物体槽之间的干扰，并使用对比损失显式鼓励槽-图像对应关系。", "result": "在合成（MOVi-C/E）和现实世界数据集（VOC，COCO）上，CODA改善了对象发现、属性预测及合成图像生成的表现。例如，在COCO上的FG-ARI提高了6.1%。", "conclusion": "这些结果表明，作为有效的框架，CODA在复杂的真实场景中有潜力用于稳健的对象中心学习。"}}
{"id": "2601.01222", "pdf": "https://arxiv.org/pdf/2601.01222", "abs": "https://arxiv.org/abs/2601.01222", "authors": ["Mengfei Li", "Peng Li", "Zheng Zhang", "Jiahao Lu", "Chengfeng Zhao", "Wei Xue", "Qifeng Liu", "Sida Peng", "Wenxiao Zhang", "Wenhan Luo", "Yuan Liu", "Yike Guo"], "title": "UniSH: Unifying Scene and Human Reconstruction in a Feed-Forward Pass", "categories": ["cs.CV"], "comment": null, "summary": "We present UniSH, a unified, feed-forward framework for joint metric-scale 3D scene and human reconstruction. A key challenge in this domain is the scarcity of large-scale, annotated real-world data, forcing a reliance on synthetic datasets. This reliance introduces a significant sim-to-real domain gap, leading to poor generalization, low-fidelity human geometry, and poor alignment on in-the-wild videos. To address this, we propose an innovative training paradigm that effectively leverages unlabeled in-the-wild data. Our framework bridges strong, disparate priors from scene reconstruction and HMR, and is trained with two core components: (1) a robust distillation strategy to refine human surface details by distilling high-frequency details from an expert depth model, and (2) a two-stage supervision scheme, which first learns coarse localization on synthetic data, then fine-tunes on real data by directly optimizing the geometric correspondence between the SMPL mesh and the human point cloud. This approach enables our feed-forward model to jointly recover high-fidelity scene geometry, human point clouds, camera parameters, and coherent, metric-scale SMPL bodies, all in a single forward pass. Extensive experiments demonstrate that our model achieves state-of-the-art performance on human-centric scene reconstruction and delivers highly competitive results on global human motion estimation, comparing favorably against both optimization-based frameworks and HMR-only methods. Project page: https://murphylmf.github.io/UniSH/", "AI": {"tldr": "提出了一种联合三维场景和人体重建的端到端框架UniSH。", "motivation": "解决现有方法依赖于合成数据导致的真实世界性能不佳问题，通过创新性的训练方式来弥合仿真与现实之间的差距。", "method": "采用一种新颖的训练策略，结合未标记的真实世界数据，利用深度模型的高阶细节对人类表面进行精炼，并通过两阶段监督方案实现精确的人体点云和场景几何重建。", "result": "实验结果表明该框架在人体中心场景重建上达到了最先进的性能，在全球人体运动估计中也表现出色。", "conclusion": "UniSH通过有效的训练方式解决了传统方法中存在的问题，实现了高质量的三维场景与人体联合重建。"}}
{"id": "2601.01218", "pdf": "https://arxiv.org/pdf/2601.01218", "abs": "https://arxiv.org/abs/2601.01218", "authors": ["Ka Yan Fung", "Tze Leung Rick Lui", "Yuxing Tao", "Kuen Fung Sin"], "title": "MotiBo: The Impact of Interactive Digital Storytelling Robots on Student Motivation through Self-Determination Theory", "categories": ["cs.HC", "cs.MM", "cs.RO"], "comment": null, "summary": "Creativity is increasingly recognized as an important skill in education, and storytelling can enhance motivation and engagement among students. However, conventional storytelling methods often lack the interactive elements necessary to engage students. To this end, this study examines the impact of an interactive digital storytelling system incorporating a human-like robot on student engagement and creativity. The study aims to compare engagement levels across three modalities: paper-based, PowerPoint, and robot-assisted storytelling, MotiBo. Utilizing a quasi-experimental design, this work involves three groups of students who interact with the storytelling system over a five-day learning. Findings reveal that students using MotiBo exhibit statistically significant improvement in behavioural and cognitive engagement compared to those using traditional methods. These results suggest that the integration of novel technologies can effectively enhance the learning experience, ultimately promoting creativity and self-learning ability in educational settings. Future research will investigate the long-term effects of these technologies on learning outcomes and explore their potential for broader applications in diverse educational contexts.", "AI": {"tldr": "研究通过一种结合了人形机器人的互动数字叙事系统，评估其对学生参与度和创造力的影响。", "motivation": "传统叙事方法难以激发学生的兴趣和参与。引入创新技术，如机器人辅助的互动数字故事讲述，可以提高学习体验。", "method": "采用准实验设计，三个学生群体分别使用纸质、PowerPoint和MotiBo（机器人物述）进行五天的学习，比较三种方式对学生行为和认知参与度的影响。", "result": "研究发现，使用MotiBo的学生在行为和认知参与方面表现出显著的提升，优于传统方法。", "conclusion": "引入机器人技术能够有效提高学习体验，促进创造力与自我学习能力。未来将进一步探索其长期影响及更广泛的应用可能性。"}}
{"id": "2601.01215", "pdf": "https://arxiv.org/pdf/2601.01215", "abs": "https://arxiv.org/abs/2601.01215", "authors": ["Prateek Rajput", "Yewei Song", "Abdoul Aziz Bonkoungou", "Iyiola E. Olatunji", "Abdoul Kader Kabore", "Jacques Klein", "Tegawendé F. Bissyandé"], "title": "Correctness isnt Efficiency: Runtime Memory Divergence in LLM-Generated Code", "categories": ["cs.SE", "cs.AI"], "comment": "11 Pages, 11 figures, Accepted at ICSE SEIP", "summary": "Large language models (LLMs) can generate programs that pass unit tests, but passing tests does not guarantee reliable runtime behavior. We find that different correct solutions to the same task can show very different memory and performance patterns, which can lead to hidden operational risks. We present a framework to measure execution-time memory stability across multiple correct generations. At the solution level, we introduce Dynamic Mean Pairwise Distance (DMPD), which uses Dynamic Time Warping to compare the shapes of memory-usage traces after converting them into Monotonic Peak Profiles (MPPs) to reduce transient noise. Aggregating DMPD across tasks yields a model-level Model Instability Score (MIS). Experiments on BigOBench and CodeContests show substantial runtime divergence among correct solutions. Instability often increases with higher sampling temperature even when pass@1 improves. We also observe correlations between our stability measures and software engineering indicators such as cognitive and cyclomatic complexity, suggesting links between operational behavior and maintainability. Our results support stability-aware selection among passing candidates in CI/CD to reduce operational risk without sacrificing correctness. Artifacts are available.", "AI": {"tldr": "该论文提出了一种测量LLM生成代码在运行时内存稳定性的框架，引入了动态平均成对距离（DMPD）和模型不稳定性得分（MIS），并展示了不同正确解决方案之间的运行时差异。", "motivation": "大型语言模型可以生成通过单元测试的程序，但这不能保证其在实际运行中的可靠性。论文旨在测量和理解不同正确解决方案之间存在的内存和性能模式的不同及其潜在运营风险。", "method": "该研究引入了动态平均成对距离（DMPD）来比较正确的代码生成方案，并将其聚合以计算模型级别的不稳定性得分（MIS）。使用动态时间规整算法，将内存使用轨迹转换为单峰形态，减少瞬时噪声的影响。", "result": "实验表明，在BigOBench和CodeContests上的测试中，不同的正确解决方案之间存在显著的运行时差异。即使pass@1提高，不稳定性随着采样温度升高而增加。此外，该研究还观察到这些稳定性度量与认知复杂性和圈复杂性等软件工程指标之间的相关性。", "conclusion": "研究表明，在连续集成/部署中采用以稳定为导向的选择可以降低运营风险而不牺牲正确性。"}}
{"id": "2601.01213", "pdf": "https://arxiv.org/pdf/2601.01213", "abs": "https://arxiv.org/abs/2601.01213", "authors": ["Riccardo Gelato", "Carlo Sgaravatti", "Jakob Grahn", "Giacomo Boracchi", "Filippo Maria Bianchi"], "title": "Promptable Foundation Models for SAR Remote Sensing: Adapting the Segment Anything Model for Snow Avalanche Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Remote sensing solutions for avalanche segmentation and mapping are key to supporting risk forecasting and mitigation in mountain regions. Synthetic Aperture Radar (SAR) imagery from Sentinel-1 can be effectively used for this task, but training an effective detection model requires gathering a large dataset with high-quality annotations from domain experts, which is prohibitively time-consuming. In this work, we aim to facilitate and accelerate the annotation of SAR images for avalanche mapping. We build on the Segment Anything Model (SAM), a segmentation foundation model trained on natural images, and tailor it to Sentinel-1 SAR data. Adapting SAM to our use-case requires addressing several domain-specific challenges: (i) domain mismatch, since SAM was not trained on satellite/SAR imagery; (ii) input adaptation, because SAR products typically provide more than three channels, while SAM is constrained to RGB images; (iii) robustness to imprecise prompts that can affect target identification and degrade the segmentation quality, an issue exacerbated in small, low-contrast avalanches; and (iv) training efficiency, since standard fine-tuning is computationally demanding for SAM. We tackle these challenges through a combination of adapters to mitigate the domain gap, multiple encoders to handle multi-channel SAR inputs, prompt-engineering strategies to improve avalanche localization accuracy, and a training algorithm that limits the training time of the encoder, which is recognized as the major bottleneck. We integrate the resulting model into an annotation tool and show experimentally that it speeds up the annotation of SAR images.", "AI": {"tldr": "本文旨在通过适配Segment Anything Model（SAM）来加速合成孔径雷达（SAR）图像中雪崩分割的标注过程，解决遥感领域中的关键问题。", "motivation": "利用Sentinel-1 SAR影像进行雪崩分段和制图对于支持山区风险预测和缓解至关重要。然而，训练有效的检测模型需要从领域专家那里收集大量带有高质量注释的数据集，这是一个耗时且代价高昂的过程。", "method": "本文通过适配SAM以应对几个特定领域的挑战：（i）域不匹配；（ii）输入适应性问题；（iii）对模糊提示的鲁棒性的提高；以及（iv）训练效率。具体方法包括使用适配器来解决领域差距，采用多编码器处理SAR影像中的多个通道，通过策略优化雪崩定位精度，并且开发一种限制了编码器训练时间的新颖训练算法。", "result": "本文实验表明，所提出的方法可以加快SAR图像的标注速度。", "conclusion": "该方法能够有效地促进和加速Sentinel-1 SAR影像中雪崩分割的数据集生成。"}}
{"id": "2601.01210", "pdf": "https://arxiv.org/pdf/2601.01210", "abs": "https://arxiv.org/abs/2601.01210", "authors": ["Kazuhiko Murasaki", "Shunsuke Konagai", "Masakatsu Aoki", "Taiga Yoshida", "Ryuichi Tanida"], "title": "Real-Time LiDAR Point Cloud Densification for Low-Latency Spatial Data Transmission", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "To realize low-latency spatial transmission system for immersive telepresence, there are two major problems: capturing dynamic 3D scene densely and processing them in real time. LiDAR sensors capture 3D in real time, but produce sparce point clouds. Therefore, this paper presents a high-speed LiDAR point cloud densification method to generate dense 3D scene with minimal latency, addressing the need for on-the-fly depth completion while maintaining real-time performance. Our approach combines multiple LiDAR inputs with high-resolution color images and applies a joint bilateral filtering strategy implemented through a convolutional neural network architecture. Experiments demonstrate that the proposed method produces dense depth maps at full HD resolution in real time (30 fps), which is over 15x faster than a recent training-based depth completion approach. The resulting dense point clouds exhibit accurate geometry without multiview inconsistencies or ghosting artifacts.", "AI": {"tldr": "实时稠密化LiDAR点云以实现低延迟的空间数据传输。", "motivation": "为了解决沉浸式远程呈现中的动态三维场景捕获稀疏和实时处理问题，提出了一种高速的LiDAR点云稠密化方法。", "method": "该方法结合多个LiDAR输入与高分辨率彩色图像，并通过卷积神经网络架构应用联合双边滤波策略。", "result": "实验表明，所提方法能够在全高清分辨率下以实时速度（30 fps）生成稠密的深度图，比最近的一项基于训练的方法快15倍以上。", "conclusion": "该方法生成的稠密集点云准确且无多视图不一致或鬼影效应。"}}
{"id": "2601.01206", "pdf": "https://arxiv.org/pdf/2601.01206", "abs": "https://arxiv.org/abs/2601.01206", "authors": ["Soroush Elyasi", "Arya VarastehNezhad", "Fattaneh Taghiyareh"], "title": "MentalGame: Predicting Personality-Job Fitness for Software Developers Using Multi-Genre Games and Machine Learning Approaches", "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.SE"], "comment": null, "summary": "Personality assessment in career guidance and personnel selection traditionally relies on self-report questionnaires, which are susceptible to response bias, fatigue, and intentional distortion. Game-based assessment offers a promising alternative by capturing implicit behavioral signals during gameplay. This study proposes a multi-genre serious-game framework combined with machine-learning techniques to predict suitability for software development roles. Developer-relevant personality and behavioral traits were identified through a systematic literature review and an empirical study of professional software engineers. A custom mobile game was designed to elicit behaviors related to problem solving, planning, adaptability, persistence, time management, and information seeking. Fine-grained gameplay event data were collected and analyzed using a two-phase modeling strategy where suitability was predicted exclusively from gameplay-derived behavioral features. Results show that our model achieved up to 97% precision and 94% accuracy. Behavioral analysis revealed that proper candidates exhibited distinct gameplay patterns, such as more wins in puzzle-based games, more side challenges, navigating menus more frequently, and exhibiting fewer pauses, retries, and surrender actions. These findings demonstrate that implicit behavioral traces captured during gameplay is promising in predicting software-development suitability without explicit personality testing, supporting serious games as a scalable, engaging, and less biased alternative for career assessment.", "AI": {"tldr": "通过多类型游戏和机器学习技术预测软件开发人员的人格工作适应性。", "motivation": "传统的职业指导和个人选择依赖自我报告问卷，这种形式易受回应偏差、疲劳及有意歪曲的影响。游戏化评估作为一种捕捉游戏中隐含行为信号的替代方法被提出以解决这些问题。", "method": "通过系统文献回顾和专业软件工程师的经验研究确定了与开发人员相关的个性和行为特征，并设计了一个定制的移动游戏来激发问题解决、计划、适应性、持久力、时间管理和信息搜索相关的行为。收集并分析了细粒度的游戏事件数据，使用两阶段建模策略仅基于从游戏中得出的行为特性预测适合度。", "result": "模型实现了高达97%的精度和94%的准确性。行为分析揭示了合适的候选人具有特定的游戏模式，例如在基于拼图的游戏中有更多获胜次数、完成更多的支线任务、频繁导航菜单以及较少的暂停、重试和放弃动作。", "conclusion": "该研究表明，游戏中的隐含行为轨迹在没有明示性格测试的情况下预测软件开发适用性很有前景。这些发现支持了严肃游戏作为职业评估的一个可扩展、有吸引力且偏见较小的选择。"}}
{"id": "2601.01204", "pdf": "https://arxiv.org/pdf/2601.01204", "abs": "https://arxiv.org/abs/2601.01204", "authors": ["Zunhai Su", "Weihao Ye", "Hansen Feng", "Keyu Fan", "Jing Zhang", "Dahai Yu", "Zhengwu Liu", "Ngai Wong"], "title": "XStreamVGGT: Extremely Memory-Efficient Streaming Vision Geometry Grounded Transformer with KV Cache Compression", "categories": ["cs.CV"], "comment": null, "summary": "Learning-based 3D visual geometry models have benefited substantially from large-scale transformers. Among these, StreamVGGT leverages frame-wise causal attention for strong streaming reconstruction, but suffers from unbounded KV cache growth, leading to escalating memory consumption and inference latency as input frames accumulate. We propose XStreamVGGT, a tuning-free approach that systematically compresses the KV cache through joint pruning and quantization, enabling extremely memory-efficient streaming inference. Specifically, redundant KVs originating from multi-view inputs are pruned through efficient token importance identification, enabling a fixed memory budget. Leveraging the unique distribution of KV tensors, we incorporate KV quantization to further reduce memory consumption. Extensive evaluations show that XStreamVGGT achieves mostly negligible performance degradation while substantially reducing memory usage by 4.42$\\times$ and accelerating inference by 5.48$\\times$, enabling scalable and practical streaming 3D applications. The code is available at https://github.com/ywh187/XStreamVGGT/.", "AI": {"tldr": "本文提出了XStreamVGGT，一种通过联合修剪和量化压缩KV缓存来实现极低内存消耗的流式推理方法。", "motivation": "传统的StreamVGGT模型虽然使用了帧级因果注意力实现了强大的流式重建，但其未受控制的KV缓存增长导致随着输入帧增加，内存消耗和推理延迟急剧上升。因此，需要一种有效的方法来压缩KV缓存以降低内存需求。", "method": "XStreamVGGT通过识别token的重要性对多视角输入产生的冗余KV进行了剪枝，并利用KV张量的独特分布实现了量化，从而在不调整其他参数的情况下实现固定预算的流式推理。", "result": "实验结果显示，XStreamVGGT在保持几乎无损性能的同时，显著降低了内存消耗（降低4.42倍）并加速了推理速度（加快5.48倍），使大规模实际应用成为可能。", "conclusion": "通过联合修剪和量化KV缓存，XStreamVGGT成功地实现了极低的内存消耗，并提高了流式3D模型的可扩展性和实用性。"}}
{"id": "2601.01202", "pdf": "https://arxiv.org/pdf/2601.01202", "abs": "https://arxiv.org/abs/2601.01202", "authors": ["Jiazhu Dai", "Huihui Jiang"], "title": "RefSR-Adv: Adversarial Attack on Reference-based Image Super-Resolution Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Single Image Super-Resolution (SISR) aims to recover high-resolution images from low-resolution inputs. Unlike SISR, Reference-based Super-Resolution (RefSR) leverages an additional high-resolution reference image to facilitate the recovery of high-frequency textures. However, existing research mainly focuses on backdoor attacks targeting RefSR, while the vulnerability of the adversarial attacks targeting RefSR has not been fully explored. To fill this research gap, we propose RefSR-Adv, an adversarial attack that degrades SR outputs by perturbing only the reference image. By maximizing the difference between adversarial and clean outputs, RefSR-Adv induces significant performance degradation and generates severe artifacts across CNN, Transformer, and Mamba architectures on the CUFED5, WR-SR, and DRefSR datasets. Importantly, experiments confirm a positive correlation between the similarity of the low-resolution input and the reference image and attack effectiveness, revealing that the model's over-reliance on reference features is a key security flaw. This study reveals a security vulnerability in RefSR systems, aiming to urge researchers to pay attention to the robustness of RefSR.", "AI": {"tldr": "提出了一种针对参考基于图像超分辨率模型的对抗攻击方法RefSR-Adv，通过扰动参考图片来降低超分辨率输出质量。", "motivation": "现有研究主要集中在后门攻击上，而对参考基于图像超分辨率（RefSR）模型的对抗性攻击的研究尚不充分。为了填补这一空白并揭示其安全漏洞，作者提出了一种新的方法。", "method": "通过最大化扰动后的参考图像与原始干净图像之间的差异来设计一种能够诱导显著性能下降和生成严重伪影的方法RefSR-Adv。", "result": "在CUFED5、WR-SR和DRefSR数据集上，针对CNN、Transformer和Mamba架构的模型，RefSR-Adv实验结果表明存在明显的攻击效果与低分辨率输入图像和参考图像相似性之间的正相关关系。该研究揭示了模型过度依赖于参考特征的安全隐患。", "conclusion": "这项工作揭示了RefSR系统中的安全漏洞，并呼吁研究人员注意RefSR系统的鲁棒性问题。"}}
{"id": "2601.01200", "pdf": "https://arxiv.org/pdf/2601.01200", "abs": "https://arxiv.org/abs/2601.01200", "authors": ["Zhang Chen", "Shuai Wan", "Yuezhe Zhang", "Siyu Ren", "Fuzheng Yang", "Junhui Hou"], "title": "MS-ISSM: Objective Quality Assessment of Point Clouds Using Multi-scale Implicit Structural Similarity", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "The unstructured and irregular nature of point clouds poses a significant challenge for objective quality assessment (PCQA), particularly in establishing accurate perceptual feature correspondence. To tackle this, we propose the Multi-scale Implicit Structural Similarity Measurement (MS-ISSM). Unlike traditional point-to-point matching, MS-ISSM utilizes Radial Basis Functions (RBF) to represent local features continuously, transforming distortion measurement into a comparison of implicit function coefficients. This approach effectively circumvents matching errors inherent in irregular data. Additionally, we propose a ResGrouped-MLP quality assessment network, which robustly maps multi-scale feature differences to perceptual scores. The network architecture departs from traditional flat MLPs by adopting a grouped encoding strategy integrated with Residual Blocks and Channel-wise Attention mechanisms. This hierarchical design allows the model to preserve the distinct physical semantics of luma, chroma, and geometry while adaptively focusing on the most salient distortion features across High, Medium, and Low scales. Experimental results on multiple benchmarks demonstrate that MS-ISSM outperforms state-of-the-art metrics in both reliability and generalization. The source code is available at: https://github.com/ZhangChen2022/MS-ISSM.", "AI": {"tldr": "提出了一种基于多尺度隐式结构相似度测量（MS-ISSM）的方法，用于点云的质量评估。", "motivation": "为了克服点云不规则特性带来的客观质量评估难题，提出一种新的方法来准确地进行感知特征匹配。", "method": "利用径向基函数(RBF)表示局部特征，将失真测量转化为隐式函数系数的比较，并设计了一种采用分组编码策略和残差块、通道注意机制的质量评估网络ResGrouped-MLP。", "result": "实验结果表明，所提出的方法在可靠性和泛化能力上优于当前最先进的度量标准。", "conclusion": "MS-ISSM通过利用RBF和质量评估网络解决了点云不规则数据的失真测量问题，并展示了其优越性。"}}
{"id": "2601.01196", "pdf": "https://arxiv.org/pdf/2601.01196", "abs": "https://arxiv.org/abs/2601.01196", "authors": ["Shenqi Lu", "Liangwei Zhang"], "title": "EduSim-LLM: An Educational Platform Integrating Large Language Models and Robotic Simulation for Beginners", "categories": ["cs.RO"], "comment": null, "summary": "In recent years, the rapid development of Large Language Models (LLMs) has significantly enhanced natural language understanding and human-computer interaction, creating new opportunities in the field of robotics. However, the integration of natural language understanding into robotic control is an important challenge in the rapid development of human-robot interaction and intelligent automation industries. This challenge hinders intuitive human control over complex robotic systems, limiting their educational and practical accessibility. To address this, we present the EduSim-LLM, an educational platform that integrates LLMs with robot simulation and constructs a language-drive control model that translates natural language instructions into executable robot behavior sequences in CoppeliaSim. We design two human-robot interaction models: direct control and autonomous control, conduct systematic simulations based on multiple language models, and evaluate multi-robot collaboration, motion planning, and manipulation capabilities. Experiential results show that LLMs can reliably convert natural language into structured robot actions; after applying prompt-engineering templates instruction-parsing accuracy improves significantly; as task complexity increases, overall accuracy rate exceeds 88.9% in the highest complexity tests.", "AI": {"tldr": "EduSim-LLM 是一个结合大型语言模型和机器人模拟的教育平台，旨在通过自然语言理解实现对机器人的直观控制。", "motivation": "近年来，随着大型语言模型的发展，其在人机交互中的应用逐渐增强，但将自然语言理解融入机器人控制系统仍存在挑战。该研究希望通过EduSim-LLM平台解决这一问题，提高机器人教育和实际操作的普及性。", "method": "通过CoppeliaSim构建了一个语言驱动控制模型，设计了直接控制和自主控制两种人机交互模式，并基于多种语言模型进行了系统模拟测试。", "result": "实验结果显示，大型语言模型可以可靠地将自然语言转化为结构化的机器人动作；使用提示工程模板后指令解析准确性显著提高；任务复杂度增加时，在最复杂的测试中整体准确率超过88.9%。", "conclusion": "EduSim-LLM平台通过结合大型语言模型和机器人模拟，成功实现了对机器人的直观控制，并展示了在多种人机交互场景下的可靠性能。"}}
{"id": "2601.01195", "pdf": "https://arxiv.org/pdf/2601.01195", "abs": "https://arxiv.org/abs/2601.01195", "authors": ["Wuzhenghong Wen", "Chao Xue", "Su Pan", "Yuwei Sun", "Minlong Peng"], "title": "Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering", "categories": ["cs.AI"], "comment": "11 pages, 2 figures", "summary": "Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning enhanced (MRE) framework, which enhances both forward and backward reasoning to improve the identification of globally optimal reasoning trajectories. Specifically, MRE begins with prompt engineering to guide the LLM in generating diverse reasoning trajectories for a given question. Valid reasoning trajectories are then selected for supervised fine-tuning, serving as a cold-start strategy. Finally, we introduce Tree-Group Relative Policy Optimization (T-GRPO), a recursive, tree-structured learning-by-exploration approach. At each hop, exploration establishes strong causal dependencies on the previous hop, while evaluation is informed by multi-path exploration feedback from subsequent hops. Experimental results on two TKGQA benchmarks indicate that the proposed MRE-based model consistently surpasses state-of-the-art (SOTA) approaches in handling complex multi-hop queries. Further analysis highlights improved interpretability and robustness to noisy temporal annotations.", "AI": {"tldr": "本文提出了一种基于强化学习的多跳推理框架，用于提升时序知识图谱问答（TKGQA）的能力。", "motivation": "大型语言模型在处理时序知识图谱中的多跳推理任务时常出现次优决策和错误传播的问题。为解决这些问题，提出了MRE框架来提高全局最优路径的识别。", "method": "MRE通过提示工程引导LLM生成多样化的推理轨迹，并使用监督微调作为冷启动策略选择有效路径；引入了树组相对策略优化（T-GRPO）算法进行递归、基于探索的学习，以增强推理过程中的因果依赖关系和多路径反馈。", "result": "实验结果表明，所提出的MRE模型在两个基准测试中处理复杂多跳查询时优于现有最佳方法，并提高了对噪声时间注释的鲁棒性和可解释性。", "conclusion": "该研究通过引入强化学习框架来解决大型语言模型在处理时序知识图谱问答任务中的挑战，显著提升了系统的性能、可解释性和稳定性。"}}
{"id": "2601.01192", "pdf": "https://arxiv.org/pdf/2601.01192", "abs": "https://arxiv.org/abs/2601.01192", "authors": ["Hao Lu", "Xuhui Zhu", "Wenjing Zhang", "Yanan Li", "Xiang Bai"], "title": "Crowded Video Individual Counting Informed by Social Grouping and Spatial-Temporal Displacement Priors", "categories": ["cs.CV"], "comment": "Journal Extension of arXiv:2506.13067", "summary": "Video Individual Counting (VIC) is a recently introduced task aiming to estimate pedestrian flux from a video. It extends Video Crowd Counting (VCC) beyond the per-frame pedestrian count. In contrast to VCC that learns to count pedestrians across frames, VIC must identify co-existent pedestrians between frames, which turns out to be a correspondence problem. Existing VIC approaches, however, can underperform in congested scenes such as metro commuting. To address this, we build WuhanMetroCrowd, one of the first VIC datasets that characterize crowded, dynamic pedestrian flows. It features sparse-to-dense density levels, short-to-long video clips, slow-to-fast flow variations, front-to-back appearance changes, and light-to-heavy occlusions. To better adapt VIC approaches to crowds, we rethink the nature of VIC and recognize two informative priors: i) the social grouping prior that indicates pedestrians tend to gather in groups and ii) the spatial-temporal displacement prior that informs an individual cannot teleport physically. The former inspires us to relax the standard one-to-one (O2O) matching used by VIC to one-to-many (O2M) matching, implemented by an implicit context generator and a O2M matcher; the latter facilitates the design of a displacement prior injector, which strengthens not only O2M matching but also feature extraction and model training. These designs jointly form a novel and strong VIC baseline OMAN++. Extensive experiments show that OMAN++ not only outperforms state-of-the-art VIC baselines on the standard SenseCrowd, CroHD, and MovingDroneCrowd benchmarks, but also indicates a clear advantage in crowded scenes, with a 38.12% error reduction on our WuhanMetroCrowd dataset. Code, data, and pretrained models are available at https://github.com/tiny-smart/OMAN.", "AI": {"tldr": "视频个体计数（VIC）的任务是从视频中估计行人流量，该任务扩展了视频人群计数（VCC），需要在帧之间识别共存的行人。", "motivation": "现有VIC方法在拥挤场景中的性能较差。为解决此问题，研究者创建了WuhanMetroCrowd数据集，并提出了两种先验：社交群体优先和时空位移优先。", "method": "该方法通过引入隐式上下文生成器和O2M匹配器放松标准的一对一（O2O）匹配，以实现一对多（O2M）匹配。同时设计了位移优先注入器来强化特征提取和模型训练。", "result": "OMAN++在拥挤场景中表现出色，在WuhanMetroCrowd数据集上的误差减少了38.12%，并且在标准SenseCrowd，CroHD和MovingDroneCrowd基准测试上也超过了现有的VIC基线。", "conclusion": "研究提出了一个改进的VIC方法OMAN++，通过引入社交群体优先和时空位移优先来提高拥挤场景中的计数精度。"}}
{"id": "2601.01188", "pdf": "https://arxiv.org/pdf/2601.01188", "abs": "https://arxiv.org/abs/2601.01188", "authors": ["Zhiwei Huang", "Yanwei Fu", "Yi Zhou", "Xieyuanli Chen", "Qijun Chen", "Rui Fan"], "title": "DST-Calib: A Dual-Path, Self-Supervised, Target-Free LiDAR-Camera Extrinsic Calibration Network", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "LiDAR-camera extrinsic calibration is essential for multi-modal data fusion in robotic perception systems. However, existing approaches typically rely on handcrafted calibration targets (e.g., checkerboards) or specific, static scene types, limiting their adaptability and deployment in real-world autonomous and robotic applications. This article presents the first self-supervised LiDAR-camera extrinsic calibration network that operates in an online fashion and eliminates the need for specific calibration targets. We first identify a significant generalization degradation problem in prior methods, caused by the conventional single-sided data augmentation strategy. To overcome this limitation, we propose a novel double-sided data augmentation technique that generates multi-perspective camera views using estimated depth maps, thereby enhancing robustness and diversity during training. Built upon this augmentation strategy, we design a dual-path, self-supervised calibration framework that reduces the dependence on high-precision ground truth labels and supports fully adaptive online calibration. Furthermore, to improve cross-modal feature association, we replace the traditional dual-branch feature extraction design with a difference map construction process that explicitly correlates LiDAR and camera features. This not only enhances calibration accuracy but also reduces model complexity. Extensive experiments conducted on five public benchmark datasets, as well as our own recorded dataset, demonstrate that the proposed method significantly outperforms existing approaches in terms of generalizability.", "AI": {"tldr": "提出了一种无需特定校准目标的自监督LiDAR相机外参校准网络，提高了鲁棒性和适应性", "motivation": "现有方法依赖于手工制作的目标或特定场景类型，限制了其在实际应用中的部署和泛化能力。因此需要一种更通用、自我学习的方法来提高多模态数据融合的效果", "method": "提出了一种双路径的自监督校准框架，使用新颖的双向数据增强策略生成多种视角图像，并通过构建差异图关联LiDAR与相机特征，减少对高精度标签依赖并简化模型结构", "result": "实验结果表明该方法在多个公开基准数据集和自有记录的数据集中表现优越，具有更好的泛化能力", "conclusion": "首次提出了一种在线运行、无需特定目标的自监督LiDAR-camera外参校准网络，通过创新的方法提高了多模态感知系统的准确性与鲁棒性"}}
{"id": "2601.01186", "pdf": "https://arxiv.org/pdf/2601.01186", "abs": "https://arxiv.org/abs/2601.01186", "authors": ["Alexandre Baigol", "Nikhil Garg", "Matteo Mazza", "Yanming Zhang", "Elisa Zaccaria", "Wooseok Choi", "Bert Jan Offrein", "Laura Bégon-Lours"], "title": "Analog Weight Update Rule in Ferroelectric Hafnia, using pico-Joule Programming Pulses", "categories": ["cs.ET", "cond-mat.mtrl-sci"], "comment": "10 pages, 5 figures. Submitted to Advanced Electronic Materials (Wiley), under review", "summary": "In an effort to compete with the brain's efficiency at processing information, neuromorphic hardware combines artificial synapses and neurons using mixed-signal circuits and emerging memories. In ferroelectric resistive weights, the strength of the synaptic connection between two neurons is stored in the device conductance. During learning, programming pulses are applied to the synaptic weight, which reconfigures the ferroelectric domains and adjusts the conductance. One strategy to lower the energy cost during the training phase is to lower the duration of the programming pulses. However, the latter cannot be shorter than the self-loading time of the resistive weights, limited by intrinsic parasitics in the circuits. In this work, ferroelectric resistive weights are fabricated using a process compatible with CMOS Back-End-Of-Line integration, based on hafnia/zirconia nanolaminates. By laterally scaling the device area under 100 $μ$m$^2$, the self-loading time becomes sufficiently short to enable 20 ns programming, which corresponds to a maximum of 3 picoJoules per pulse. Further, in this work, the weight update rule with 20 ns pulses is experimentally measured not only for different amplitudes but also for different initial conductance states. We find that the final weight is determined by the pulse amplitude, independent of the initial weight value.", "AI": {"tldr": "本文研究了使用纳秒级编程脉冲更新铁电铪基忆阻器权重的方法，以降低训练能耗。", "motivation": "为了提高神经形态硬件在信息处理上的效率，需降低学习阶段的能源消耗。通过减小编程脉冲时间来减少能量成本。", "method": "制备基于铪/氧化锆纳米层叠材料的铁电忆阻器，并通过横向缩小器件面积至100微米^2以下，实现20纳秒编程脉冲的应用，从而进行权重更新实验。", "result": "发现使用20纳秒脉冲对不同幅度和初始导通状态进行实验后，最终权重仅由脉冲幅度决定而与初始值无关。", "conclusion": "通过采用短时间的编程脉冲技术，在不依赖于初始权重的情况下实现了精确的权重更新，从而大大降低了训练过程中的能量消耗。"}}
{"id": "2601.01181", "pdf": "https://arxiv.org/pdf/2601.01181", "abs": "https://arxiv.org/abs/2601.01181", "authors": ["Chenglizhao Chen", "Shaojiang Yuan", "Xiaoxue Lu", "Mengke Song", "Jia Song", "Zhenyu Wu", "Wenfeng Song", "Shuai Li"], "title": "GenCAMO: Scene-Graph Contextual Decoupling for Environment-aware and Mask-free Camouflage Image-Dense Annotation Generation", "categories": ["cs.CV"], "comment": null, "summary": "Conceal dense prediction (CDP), especially RGB-D camouflage object detection and open-vocabulary camouflage object segmentation, plays a crucial role in advancing the understanding and reasoning of complex camouflage scenes. However, high-quality and large-scale camouflage datasets with dense annotation remain scarce due to expensive data collection and labeling costs. To address this challenge, we explore leveraging generative models to synthesize realistic camouflage image-dense data for training CDP models with fine-grained representations, prior knowledge, and auxiliary reasoning. Concretely, our contributions are threefold: (i) we introduce GenCAMO-DB, a large-scale camouflage dataset with multi-modal annotations, including depth maps, scene graphs, attribute descriptions, and text prompts; (ii) we present GenCAMO, an environment-aware and mask-free generative framework that produces high-fidelity camouflage image-dense annotations; (iii) extensive experiments across multiple modalities demonstrate that GenCAMO significantly improves dense prediction performance on complex camouflage scenes by providing high-quality synthetic data. The code and datasets will be released after paper acceptance.", "AI": {"tldr": "提出了一种环境感知且无需掩码的生成框架GenCAMO，用于生成高保真度的伪装图像密集注释。", "motivation": "高质量的大规模带密集标注的伪装数据集稀缺，导致复杂伪装场景理解与推理受限。为解决这一问题，探索利用生成模型合成真实感强的伪装图像密集数据以训练CDP模型。", "method": "引入GenCAMO-DB大规模伪装数据集和多模式注释；提出环境感知且无需掩码的生成框架GenCAMO，用于生产高保真度伪装图像密集标注。", "result": "跨多模态实验表明，GenCAMO显著改善复杂伪装场景中的密集预测性能，提供高质量合成数据。", "conclusion": "提出的GenCAMO框架在提高复杂伪装场景中密集预测性能方面表现出色，代码和数据集将在论文接受后发布。"}}
{"id": "2601.01176", "pdf": "https://arxiv.org/pdf/2601.01176", "abs": "https://arxiv.org/abs/2601.01176", "authors": ["Andrés Bell-Navas", "Jesús Garicano-Mena", "Antonella Ausiello", "Soledad Le Clainche", "María Villalba-Orero", "Enrique Lara-Pezzi"], "title": "CardioMOD-Net: A Modal Decomposition-Neural Network Framework for Diagnosis and Prognosis of HFpEF from Echocardiography Cine Loops", "categories": ["cs.CV"], "comment": "9 pages; 1 figure; letter", "summary": "Introduction: Heart failure with preserved ejection fraction (HFpEF) arises from diverse comorbidities and progresses through prolonged subclinical stages, making early diagnosis and prognosis difficult. Current echocardiography-based Artificial Intelligence (AI) models focus primarily on binary HFpEF detection in humans and do not provide comorbidity-specific phenotyping or temporal estimates of disease progression towards decompensation. We aimed to develop a unified AI framework, CardioMOD-Net, to perform multiclass diagnosis and continuous prediction of HFpEF onset directly from standard echocardiography cine loops in preclinical models. Methods: Mouse echocardiography videos from four groups were used: control (CTL), hyperglycaemic (HG), obesity (OB), and systemic arterial hypertension (SAH). Two-dimensional parasternal long-axis cine loops were decomposed using Higher Order Dynamic Mode Decomposition (HODMD) to extract temporal features for downstream analysis. A shared latent representation supported Vision Transformers, one for a classifier for diagnosis and another for a regression module for predicting the age at HFpEF onset. Results: Overall diagnostic accuracy across the four groups was 65%, with all classes exceeding 50% accuracy. Misclassifications primarily reflected early-stage overlap between OB or SAH and CTL. The prognostic module achieved a root-mean-square error of 21.72 weeks for time-to-HFpEF prediction, with OB and SAH showing the most accurate estimates. Predicted HFpEF onset closely matched true distributions in all groups. Discussion: This unified framework demonstrates that multiclass phenotyping and continuous HFpEF onset prediction can be obtained from a single cine loop, even under small-data conditions. The approach offers a foundation for integrating diagnostic and prognostic modelling in preclinical HFpEF research.", "AI": {"tldr": "开发了一个名为CardioMOD-Net的统一AI框架，用于从标准超声心动图视频中直接进行HFpEF多类诊断和连续预测。", "motivation": "当前基于超声的心脏病人工智能模型主要集中在人类HFpEF二元检测上，并不提供特定共病表型或疾病进展到失代偿期的时间估计，因此开发了一个框架以解决这些问题。", "method": "利用来自四个不同组的鼠类超声心动图视频，通过HODMD提取时间特征，支持视觉变换器进行分类和回归预测。", "result": "诊断准确性总体为65%，所有类别的准确率均超过50%；预测模块在HFpEF发作预测中平均误差为21.72周。", "conclusion": "该框架展示了即使在小数据条件下也可以从单个超声视频中获得多类表型和连续的HFpEF发作时间预测的能力，为进一步的研究奠定了基础。"}}
{"id": "2601.01167", "pdf": "https://arxiv.org/pdf/2601.01167", "abs": "https://arxiv.org/abs/2601.01167", "authors": ["Tianheng Cheng", "Xinggang Wang", "Junchao Liao", "Wenyu Liu"], "title": "Cross-Layer Attentive Feature Upsampling for Low-latency Semantic Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Semantic segmentation is a fundamental problem in computer vision and it requires high-resolution feature maps for dense prediction. Current coordinate-guided low-resolution feature interpolation methods, e.g., bilinear interpolation, produce coarse high-resolution features which suffer from feature misalignment and insufficient context information. Moreover, enriching semantics to high-resolution features requires a high computation burden, so that it is challenging to meet the requirement of lowlatency inference. We propose a novel Guided Attentive Interpolation (GAI) method to adaptively interpolate fine-grained high-resolution features with semantic features to tackle these issues. Guided Attentive Interpolation determines both spatial and semantic relations of pixels from features of different resolutions and then leverages these relations to interpolate high-resolution features with rich semantics. GAI can be integrated with any deep convolutional network for efficient semantic segmentation. In experiments, the GAI-based semantic segmentation networks, i.e., GAIN, can achieve78.8 mIoU with 22.3 FPS on Cityscapes and 80.6 mIoU with 64.5 on CamVid using an NVIDIA 1080Ti GPU, which are the new state-of-the-art results of low-latency semantic segmentation. Code and models are available at: https://github.com/hustvl/simpleseg.", "AI": {"tldr": "提出了一种新的引导注意力插值方法，用于提高低延迟语义分割的效果", "motivation": "当前的坐标指导低分辨率特征插值方法会产生粗略的高分辨率特性，缺乏上下文信息且计算负担重。因此需要一种新方法解决这些问题", "method": "提出了Guided Attentive Interpolation (GAI) 方法，通过确定不同分辨率特性的像素间的时空关系，并利用这些关系来插值出富含语义的高分辨率特征", "result": "实验表明，基于GAI的语义分割网络在Cityscapes数据集上实现78.8 mIoU和22.3 FPS，在CamVid上实现80.6 mIoU和64.5 FPS，均为低延迟语义分割的新最佳结果", "conclusion": "通过提出新的插值方法，有效地提高了低延迟下的语义分割性能"}}
{"id": "2601.01162", "pdf": "https://arxiv.org/pdf/2601.01162", "abs": "https://arxiv.org/abs/2601.01162", "authors": ["Zihua Yang", "Xin Liao", "Yiqun Zhang", "Yiu-ming Cheung"], "title": "Bridging the Semantic Gap for Categorical Data Clustering via Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Submitted to ICPR 2026", "summary": "Categorical data are prevalent in domains such as healthcare, marketing, and bioinformatics, where clustering serves as a fundamental tool for pattern discovery. A core challenge in categorical data clustering lies in measuring similarity among attribute values that lack inherent ordering or distance. Without appropriate similarity measures, values are often treated as equidistant, creating a semantic gap that obscures latent structures and degrades clustering quality. Although existing methods infer value relationships from within-dataset co-occurrence patterns, such inference becomes unreliable when samples are limited, leaving the semantic context of the data underexplored. To bridge this gap, we present ARISE (Attention-weighted Representation with Integrated Semantic Embeddings), which draws on external semantic knowledge from Large Language Models (LLMs) to construct semantic-aware representations that complement the metric space of categorical data for accurate clustering. That is, LLM is adopted to describe attribute values for representation enhancement, and the LLM-enhanced embeddings are combined with the original data to explore semantically prominent clusters. Experiments on eight benchmark datasets demonstrate consistent improvements over seven representative counterparts, with gains of 19-27%. Code is available at https://github.com/develop-yang/ARISE", "AI": {"tldr": "通过引入大型语言模型（LLM）增强的语义嵌入来改进类别数据聚类。", "motivation": "在处理类别数据时，缺乏适当的相似性度量会导致价值关系推断不准确，尤其是在样本较少的情况下。为了解决这一问题，论文提出了一种结合外部语义知识的新方法。", "method": "利用大型语言模型（LLM）生成属性值的描述以增强表示，并将这些增强后的嵌入与原始数据相结合来探索语义突出的聚类。", "result": "在八个基准数据集上，ARISE展示了比七个代表性方法更高的性能提升，平均提升了19-27%。", "conclusion": "通过引入外部语言模型的知识，可以有效地改善类别数据的聚类质量。"}}
{"id": "2601.01155", "pdf": "https://arxiv.org/pdf/2601.01155", "abs": "https://arxiv.org/abs/2601.01155", "authors": ["Zhang Shizhe", "Liang Jingsong", "Zhou Zhitao", "Ye Shuhan", "Wang Yizhuo", "Tan Ming Siang Derek", "Chiun Jimmy", "Cao Yuhong", "Sartoretti Guillaume"], "title": "ORION: Option-Regularized Deep Reinforcement Learning for Cooperative Multi-Agent Online Navigation", "categories": ["cs.RO"], "comment": null, "summary": "Existing methods for multi-agent navigation typically assume fully known environments, offering limited support for partially known scenarios such as warehouses or factory floors. There, agents may need to plan trajectories that balance their own path optimality with their ability to collect and share information about the environment that can help their teammates reach their own goals. To these ends, we propose ORION, a novel deep reinforcement learning framework for cooperative multi-agent online navigation in partially known environments. Starting from an imperfect prior map, ORION trains agents to make decentralized decisions, coordinate to reach their individual targets, and actively reduce map uncertainty by sharing online observations in a closed perception-action loop. We first design a shared graph encoder that fuses prior map with online perception into a unified representation, providing robust state embeddings under dynamic map discrepancies. At the core of ORION is an option-critic framework that learns to reason about a set of high-level cooperative modes that translate into sequences of low-level actions, allowing agents to switch between individual navigation and team-level exploration adaptively. We further introduce a dual-stage cooperation strategy that enables agents to assist teammates under map uncertainty, thereby reducing the overall makespan. Across extensive maze-like maps and large-scale warehouse environments, our simulation results show that ORION achieves high-quality, real-time decentralized cooperation over varying team sizes, outperforming state-of-the-art classical and learning-based baselines. Finally, we validate ORION on physical robot teams, demonstrating its robustness and practicality for real-world cooperative navigation.", "AI": {"tldr": "ORION是一个用于部分已知环境中多智能体协同导航的深度强化学习框架，通过在线感知和共享观察来减少环境不确定性。", "motivation": "现有的多智能体导航方法通常假设环境完全已知，在仓库或工厂等部分已知场景中表现不佳。ORION旨在解决这种场景中的挑战，支持智能体在不确定环境中进行协同导航并分享信息以帮助队友完成目标。", "method": "该框架包含一个共享图编码器用于融合先验地图和在线感知，并使用选项-批判框架学习高阶合作模式，使智能体能够在个体导航与团队探索之间灵活切换。此外，引入双阶段协作策略让智能体在地图不确定性下互相支持。", "result": "通过模拟实验验证了ORION在迷宫类地图和大型仓库环境中实现了高质量的实时分布式协同效果，并且物理机器人实验证明其具有鲁棒性和实际应用价值。", "conclusion": "该研究提出了一种新的多智能体导航框架，能够有效应对部分已知环境下的挑战，并通过实验展示了其实用性和优越性能。"}}
{"id": "2601.01150", "pdf": "https://arxiv.org/pdf/2601.01150", "abs": "https://arxiv.org/abs/2601.01150", "authors": ["Wenbin Pei", "Ruohao Dai", "Bing Xue", "Mengjie Zhang", "Qiang Zhang", "Yiu-Ming Cheung"], "title": "Evo-TFS: Evolutionary Time-Frequency Domain-Based Synthetic Minority Oversampling Approach to Imbalanced Time Series Classification", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Time series classification is a fundamental machine learning task with broad real-world applications. Although many deep learning methods have proven effective in learning time-series data for classification, they were originally developed under the assumption of balanced data distributions. Once data distribution is uneven, these methods tend to ignore the minority class that is typically of higher practical significance. Oversampling methods have been designed to address this by generating minority-class samples, but their reliance on linear interpolation often hampers the preservation of temporal dynamics and the generation of diverse samples. Therefore, in this paper, we propose Evo-TFS, a novel evolutionary oversampling method that integrates both time- and frequency-domain characteristics. In Evo-TFS, strongly typed genetic programming is employed to evolve diverse, high-quality time series, guided by a fitness function that incorporates both time-domain and frequency-domain characteristics. Experiments conducted on imbalanced time series datasets demonstrate that Evo-TFS outperforms existing oversampling methods, significantly enhancing the performance of time-domain and frequency-domain classifiers.", "AI": {"tldr": "提出了一种新型的进化过采样方法Evo-TFS，用于不平衡时间序列分类。", "motivation": "深度学习方法在平衡数据分布下表现良好，但在不平衡数据集中往往忽略少数类，影响了实际应用中的效果。传统的过采样方法依赖线性插值难以保持时序动态性和多样性。", "method": "使用强类型遗传编程进化时间序列样本，结合时间和频率域特性生成多样且高质量的少数类样本。", "result": "实验表明Evo-TFS显著优于现有的过采样方法，在不平衡的时间序列数据集中提高了分类性能。", "conclusion": "Evo-TFS通过结合时序和频域特征，能够有效解决时间序列不平衡分类问题。"}}
{"id": "2601.01144", "pdf": "https://arxiv.org/pdf/2601.01144", "abs": "https://arxiv.org/abs/2601.01144", "authors": ["Shu Pan", "Simon Archieri", "Ahmet Cinar", "Jonatan Scharff Willners", "Ignacio Carlucho", "Yvan Petillot"], "title": "VISO: Robust Underwater Visual-Inertial-Sonar SLAM with Photometric Rendering for Dense 3D Reconstruction", "categories": ["cs.RO"], "comment": null, "summary": "Visual challenges in underwater environments significantly hinder the accuracy of vision-based localisation and the high-fidelity dense reconstruction. In this paper, we propose VISO, a robust underwater SLAM system that fuses a stereo camera, an inertial measurement unit (IMU), and a 3D sonar to achieve accurate 6-DoF localisation and enable efficient dense 3D reconstruction with high photometric fidelity. We introduce a coarse-to-fine online calibration approach for extrinsic parameters estimation between the 3D sonar and the camera. Additionally, a photometric rendering strategy is proposed for the 3D sonar point cloud to enrich the sonar map with visual information. Extensive experiments in a laboratory tank and an open lake demonstrate that VISO surpasses current state-of-the-art underwater and visual-based SLAM algorithms in terms of localisation robustness and accuracy, while also exhibiting real-time dense 3D reconstruction performance comparable to the offline dense mapping method.", "AI": {"tldr": "提出了一种水下SLAM系统VISO，结合立体相机、惯性测量单元和三维声纳，以实现准确的六自由度定位并进行高效的密集三维重建。", "motivation": "在水下环境中，视觉挑战显著影响了基于视觉的定位精度以及高质量的密集三维重建。", "method": "提出了一种粗到细在线校准方法用于估计3D声纳与相机之间的外参数，并提出了一个光度渲染策略来增强声纳点云中的视觉信息。VISO系统集成了这些技术以实现准确的六自由度定位和高效的密集三维重建。", "result": "实验显示，VISO在实验室水箱和开放湖泊环境中均优于现有的水下和基于视觉的SLAM算法，在定位鲁棒性和准确性方面表现更佳，并且具有与离线方法相当的实时密集映射性能。", "conclusion": "通过结合立体相机、惯性测量单元和三维声纳，VISO系统实现了准确的六自由度定位并进行了高效的密集三维重建。"}}
{"id": "2601.01141", "pdf": "https://arxiv.org/pdf/2601.01141", "abs": "https://arxiv.org/abs/2601.01141", "authors": ["Xingchen Li", "Junzhe Zhang", "Junqi Shi", "Ming Lu", "Zhan Ma"], "title": "YODA: Yet Another One-step Diffusion-based Video Compressor", "categories": ["eess.IV", "cs.CV"], "comment": "Code will be available at https://github.com/NJUVISION/YODA", "summary": "While one-step diffusion models have recently excelled in perceptual image compression, their application to video remains limited. Prior efforts typically rely on pretrained 2D autoencoders that generate per-frame latent representations independently, thereby neglecting temporal dependencies. We present YODA--Yet Another One-step Diffusion-based Video Compressor--which embeds multiscale features from temporal references for both latent generation and latent coding to better exploit spatial-temporal correlations for more compact representation, and employs a linear Diffusion Transformer (DiT) for efficient one-step denoising. YODA achieves state-of-the-art perceptual performance, consistently outperforming traditional and deep-learning baselines on LPIPS, DISTS, FID, and KID. Source code will be publicly available at https://github.com/NJUVISION/YODA.", "AI": {"tldr": "本文提出了一种基于一阶段扩散模型的视频压缩方法YODA，该方法通过嵌入多尺度时空特征来提高视频的紧凑表示。", "motivation": "现有的单步扩散模型在感知图像压缩方面表现优异，但在视频应用中仍存在限制。传统方法依赖于预先训练好的2D自编码器独立生成每帧的潜在表示，忽略了时间依赖性。", "method": "YODA通过嵌入多尺度时空特征进行潜码生成和编码，并使用线性扩散变压器（DiT）实现高效的单步去噪。", "result": "实验表明，YODA在LPIPS、DISTS、FID、KID等指标上均优于传统方法和深度学习基准。", "conclusion": "YODA实现了感知性能上的最优表现，并通过利用时空相关性提高了视频压缩的效率。"}}
{"id": "2601.01139", "pdf": "https://arxiv.org/pdf/2601.01139", "abs": "https://arxiv.org/abs/2601.01139", "authors": ["Sriram Rajasekar", "Ashwini Ratnoo"], "title": "Latent Space Reinforcement Learning for Multi-Robot Exploration", "categories": ["cs.RO", "cs.MA"], "comment": null, "summary": "Autonomous mapping of unknown environments is a critical challenge, particularly in scenarios where time is limited. Multi-agent systems can enhance efficiency through collaboration, but the scalability of motion-planning algorithms remains a key limitation. Reinforcement learning has been explored as a solution, but existing approaches are constrained by the limited input size required for effective learning, restricting their applicability to discrete environments. This work addresses that limitation by leveraging autoencoders to perform dimensionality reduction, compressing high-fidelity occupancy maps into latent state vectors while preserving essential spatial information. Additionally, we introduce a novel procedural generation algorithm based on Perlin noise, designed to generate topologically complex training environments that simulate asteroid fields, caves and forests. These environments are used for training the autoencoder and the navigation algorithm using a hierarchical deep reinforcement learning framework for decentralized coordination. We introduce a weighted consensus mechanism that modulates reliance on shared data via a tuneable trust parameter, ensuring robustness to accumulation of errors. Experimental results demonstrate that the proposed system scales effectively with number of agents and generalizes well to unfamiliar, structurally distinct environments and is resilient in communication-constrained settings.", "AI": {"tldr": "本文提出了一种基于潜在空间强化学习的多机器人探索方法，利用自编码器压缩高保真度地图并生成复杂环境进行训练。", "motivation": "现有强化学习方法在处理大规模连续状态空间时受限于输入尺寸，限制了其应用于真实世界中复杂环境的能力。本文旨在通过引入自编码器来解决这一问题，并设计了一种基于Perlin噪声的程序化环境生成算法以提升模型泛化能力。", "method": "该研究采用了自编码器进行维度缩减和状态向量表示，结合层次化的深度强化学习框架实现多机器人系统中的分散式协调。提出了一种加权共识机制来增强系统的鲁棒性。", "result": "实验表明所提出的系统能有效地随着代理数量的增加而扩展，并在结构不同的新环境中表现良好。该模型还展示了在通信受限条件下出色的适应性和稳健性。", "conclusion": "通过结合自编码器与强化学习技术，研究成功地解决了一个多机器人系统中自主探索任务中的关键挑战。提出的算法能够应对复杂环境并具备良好的泛化能力及鲁棒性。"}}
{"id": "2601.01134", "pdf": "https://arxiv.org/pdf/2601.01134", "abs": "https://arxiv.org/abs/2601.01134", "authors": ["Maryam Mahdi Alhusseini", "Alireza Rouhi", "Mohammad-Reza Feizi-Derakhshi"], "title": "AI-Powered Hybrid Intrusion Detection Framework for Cloud Security Using Novel Metaheuristic Optimization", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Cybersecurity poses considerable problems to Cloud Computing (CC), especially regarding Intrusion Detection Systems (IDSs), facing difficulties with skewed datasets and suboptimal classification model performance. This study presents the Hybrid Intrusion Detection System (HyIDS), an innovative IDS that employs the Energy Valley Optimizer (EVO) for Feature Selection (FS). Additionally, it introduces a novel technique for enhancing the cybersecurity of cloud computing through the integration of machine learning methodologies with the EVO Algorithm. The Energy Valley Optimizer (EVO) effectively diminished features in the CIC-DDoS2019 dataset from 88 to 38 and in the CSE-CIC-IDS2018 data from 80 to 43, significantly enhancing computing efficiency. HyIDS incorporates four Machine Learning (ML) models: Support Vector Machine (SVM), Random Forest (RF), Decision Tree (D_Tree), and K-Nearest Neighbors (KNN). The proposed HyIDS was assessed utilizing two real-world intrusion datasets, CIC-DDoS2019 and CSE-CIC-IDS2018, both distinguished by considerable class imbalances. The CIC-DDoS2019 dataset has a significant imbalance between DDoS assault samples and legal traffic, while the CSE-CIC-IDS2018 dataset primarily comprises benign traffic with insufficient representation of attack types, complicating the detection of minority attacks. A downsampling technique was employed to balance the datasets, hence improving detection efficacy for both benign and malicious traffic. Twenty-four trials were done, revealing substantial enhancements in categorization accuracy, precision, and recall. Our suggested D_TreeEVO model attained an accuracy rate of 99.13% and an F1 score of 98.94% on the CIC-DDoS2019 dataset, and an accuracy rate of 99.78% and an F1 score of 99.70% on the CSE-CIC-IDS2018 data. These data demonstrate that EVO significantly improves cybersecurity in Cloud Computing (CC).", "AI": {"tldr": "本文提出了一种基于新型元启发式优化算法的混合入侵检测框架，旨在提高云计算中的网络安全。", "motivation": "云计算面临严重的安全挑战，特别是关于偏斜数据集和次优分类模型性能的问题。为解决这些问题，提出了HyIDS框架。", "method": "该研究使用能量谷优化器(EVO)进行特征选择，并整合了四种机器学习模型：SVM、随机森林(RF)、决策树(D_Tree)和KNN。通过下采样技术平衡数据集，提高了对良性及恶意流量的检测效率。", "result": "HyIDS在CIC-DDoS2019和CSE-CIC-IDS2018两个数据集上取得了显著的分类准确性、精度和召回率的提升。其中D_TreeEVO模型在CIC-DDoS2019数据集上的准确率为99.13%，F1值为98.94%；在CSE-CIC-IDS2018数据集上的准确率为99.78%，F1值为99.70%。", "conclusion": "实验结果表明，EVO算法显著提升了云计算中的网络安全性能。"}}
{"id": "2601.01132", "pdf": "https://arxiv.org/pdf/2601.01132", "abs": "https://arxiv.org/abs/2601.01132", "authors": ["Hao-Hsung Yang", "Ssu-Yuan Lo", "Kuan-Lun Chen", "Ching-Kai Wang"], "title": "Generating Diverse TSP Tours via a Combination of Graph Pointer Network and Dispersion", "categories": ["cs.CG", "cs.AI", "cs.LG"], "comment": null, "summary": "We address the Diverse Traveling Salesman Problem (D-TSP), a bi-criteria optimization challenge that seeks a set of $k$ distinct TSP tours. The objective requires every selected tour to have a length at most $c|T^*|$ (where $|T^*|$ is the optimal tour length) while minimizing the average Jaccard similarity across all tour pairs. This formulation is crucial for applications requiring both high solution quality and fault tolerance, such as logistics planning, robotics pathfinding or strategic patrolling. Current methods are limited: traditional heuristics, such as the Niching Memetic Algorithm (NMA) or bi-criteria optimization, incur high computational complexity $O(n^3)$, while modern neural approaches (e.g., RF-MA3S) achieve limited diversity quality and rely on complex, external mechanisms. To overcome these limitations, we propose a novel hybrid framework that decomposes D-TSP into two efficient steps. First, we utilize a simple Graph Pointer Network (GPN), augmented with an approximated sequence entropy loss, to efficiently sample a large, diverse pool of high-quality tours. This simple modification effectively controls the quality-diversity trade-off without complex external mechanisms. Second, we apply a greedy algorithm that yields a 2-approximation for the dispersion problem to select the final $k$ maximally diverse tours from the generated pool. Our results demonstrate state-of-the-art performance. On the Berlin instance, our model achieves an average Jaccard index of $0.015$, significantly outperforming NMA ($0.081$) and RF-MA3S. By leveraging GPU acceleration, our GPN structure achieves a near-linear empirical runtime growth of $O(n)$. While maintaining solution diversity comparable to complex bi-criteria algorithms, our approach is over 360 times faster on large-scale instances (783 cities), delivering high-quality TSP solutions with unprecedented efficiency and simplicity.", "AI": {"tldr": "本文提出了一种生成多样化的旅行商问题（TSP）路径的方法，通过结合图指针网络和分散性优化。", "motivation": "解决传统的多样化TSP问题方法存在计算复杂度高或多样性质量差的问题。因此，研究一种高效、高质量的多样化TSP解决方案是必要的。", "method": "首先利用改进后的图指针网络生成大量高质量路径，并通过近似序列熵损失控制质量和多样性的平衡；然后应用贪婪算法选择最终的最大分散路径集合。", "result": "在柏林实例中，模型达到了0.015的平均Jaccard指数，显著优于NMA和RF-MA3S。实验显示该方法比复杂的方法快360倍。", "conclusion": "提出了一种高效且简单的多样化TSP解决方案，能够产生高质量路径的同时保持计算效率。"}}
{"id": "2601.01129", "pdf": "https://arxiv.org/pdf/2601.01129", "abs": "https://arxiv.org/abs/2601.01129", "authors": ["Kla Tantithamthavorn", "Yaotian Zou", "Andy Wong", "Michael Gupta", "Zhe Wang", "Mike Buller", "Ryan Jiang", "Matthew Watson", "Minwoo Jeong", "Kun Chen", "Ming Wu"], "title": "RovoDev Code Reviewer: A Large-Scale Online Evaluation of LLM-based Code Review Automation at Atlassian", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted at the 48th International Conference on Software Engineering (ICSE'26), SEIP Track. 12 Pages", "summary": "Large Language Models (LLMs)-powered code review automation has the potential to transform code review workflows. Despite the advances of LLM-powered code review comment generation approaches, several practical challenges remain for designing enterprise-grade code review automation tools. In particular, this paper aims at answering the practical question: how can we design a review-guided, context-aware, quality-checked code review comment generation without fine-tuning? In this paper, we present RovoDev Code Reviewer, an enterprise-grade LLM-based code review automation tool designed and deployed at scale within Atlassian's development ecosystem with seamless integration into Atlassian's Bitbucket. Through the offline, online, user feedback evaluations over a one-year period, we conclude that RovoDev Code Reviewer is (1) effective in generating code review comments that could lead to code resolution for 38.70% (i.e., comments that triggered code changes in the subsequent commits); and (2) offers the promise of accelerating feedback cycles (i.e., decreasing the PR cycle time by 30.8%), alleviating reviewer workload (i.e., reducing the number of human-written comments by 35.6%), and improving overall software quality (i.e., finding errors with actionable suggestions).", "AI": {"tldr": "本文介绍了RovoDev Code Reviewer，一种无需微调即可生成指导性、上下文感知的代码审查评论的企业级LLM工具，并在一年内通过离线和在线用户反馈评估了其有效性。", "motivation": "设计企业级代码审查自动化工具时仍存在若干实际挑战。本文旨在回答如何不进行微调就能设计出引导式、上下文感知且质量检查的代码审查评论生成方法的问题。", "method": "通过在Atlassian开发生态系统中大规模部署并集成到Bitbucket中的RovoDev Code Reviewer，进行了为期一年的离线和在线用户反馈评估。", "result": "RovoDev Code Reviewer有效生成了能够导致代码修改的审查评论（38.70%），并且缩短了PR周期时间（减少30.8%），减轻了审查者的工作量（减少了35.6%的人工评论）以及提高了软件质量。", "conclusion": "RovoDev Code Reviewer展示了在不进行微调的情况下，通过生成指导性的、上下文感知的代码审查评论来提高开发效率和软件质量的能力。"}}
{"id": "2601.01127", "pdf": "https://arxiv.org/pdf/2601.01127", "abs": "https://arxiv.org/abs/2601.01127", "authors": ["Golbahar Amanpour", "Benyamin Ghojogh"], "title": "Wittgenstein's Family Resemblance Clustering Algorithm", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "This paper, introducing a novel method in philomatics, draws on Wittgenstein's concept of family resemblance from analytic philosophy to develop a clustering algorithm for machine learning. According to Wittgenstein's Philosophical Investigations (1953), family resemblance holds that members of a concept or category are connected by overlapping similarities rather than a single defining property. Consequently, a family of entities forms a chain of items sharing overlapping traits. This philosophical idea naturally lends itself to a graph-based approach in machine learning. Accordingly, we propose the Wittgenstein's Family Resemblance (WFR) clustering algorithm and its kernel variant, kernel WFR. This algorithm computes resemblance scores between neighboring data instances, and after thresholding these scores, a resemblance graph is constructed. The connected components of this graph define the resulting clusters. Simulations on benchmark datasets demonstrate that WFR is an effective nonlinear clustering algorithm that does not require prior knowledge of the number of clusters or assumptions about their shapes.", "AI": {"tldr": "本文提出了一种基于维特根斯坦家族相似性概念的机器学习聚类算法。", "motivation": "受到维特根斯坦哲学思想中家族相似性的启发，该研究旨在开发一种无需预先假设簇的数量和形状就能有效工作的非线性聚类算法。", "method": "通过计算数据实例之间的相似度得分，并根据阈值构建相似图来定义簇。提出了WFR（维特根斯坦的家族相似）聚类算法及其核版本。", "result": "在基准数据集上的仿真表明，WFR是一种有效的非线性聚类算法。", "conclusion": "该方法提供了一种新的基于哲学思想解决机器学习问题的方法论框架。"}}
{"id": "2601.01123", "pdf": "https://arxiv.org/pdf/2601.01123", "abs": "https://arxiv.org/abs/2601.01123", "authors": ["Yaniv Galron", "Hadar Sinai", "Haggai Maron", "Moshe Eliasof"], "title": "Learning from Historical Activations in Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated remarkable success in various domains such as social networks, molecular chemistry, and more. A crucial component of GNNs is the pooling procedure, in which the node features calculated by the model are combined to form an informative final descriptor to be used for the downstream task. However, previous graph pooling schemes rely on the last GNN layer features as an input to the pooling or classifier layers, potentially under-utilizing important activations of previous layers produced during the forward pass of the model, which we regard as historical graph activations. This gap is particularly pronounced in cases where a node's representation can shift significantly over the course of many graph neural layers, and worsened by graph-specific challenges such as over-smoothing in deep architectures. To bridge this gap, we introduce HISTOGRAPH, a novel two-stage attention-based final aggregation layer that first applies a unified layer-wise attention over intermediate activations, followed by node-wise attention. By modeling the evolution of node representations across layers, our HISTOGRAPH leverages both the activation history of nodes and the graph structure to refine features used for final prediction. Empirical results on multiple graph classification benchmarks demonstrate that HISTOGRAPH offers strong performance that consistently improves traditional techniques, with particularly strong robustness in deep GNNs.", "AI": {"tldr": "本文提出了HISTOGRAPH，一种新的两阶段注意力机制的最终聚合层，用于改进图神经网络中的节点表示。", "motivation": "传统的图池化方法仅依赖于最后一层GNN的特征作为输入，忽视了前几层中可能更相关的激活信息。这在深层模型和具有挑战性的图结构时尤为明显。", "method": "HISTOGRAPH首先通过统一的层级注意力机制对中间激活进行加权，然后应用节点级别的注意力来细化用于最终预测的特征。", "result": "实验结果表明，HISTOGRAPH在多个图分类基准上表现优异，并且在深层GNN中展现出更强的鲁棒性。", "conclusion": "本文通过引入历史激活机制改进了现有的图池化方法，提高了模型性能和稳定性。"}}
{"id": "2601.01118", "pdf": "https://arxiv.org/pdf/2601.01118", "abs": "https://arxiv.org/abs/2601.01118", "authors": ["Qingqing Long", "Haotian Chen", "Chenyang Zhao", "Xiaolei Du", "Xuezhi Wang", "Pengyao Wang", "Chengzan Li", "Yuanchun Zhou", "Hengshu Zhu"], "title": "ScienceDB AI: An LLM-Driven Agentic Recommender System for Large-Scale Scientific Data Sharing Services", "categories": ["cs.IR", "cs.AI", "cs.DL"], "comment": "12 pages, 9 figures", "summary": "The rapid growth of AI for Science (AI4S) has underscored the significance of scientific datasets, leading to the establishment of numerous national scientific data centers and sharing platforms. Despite this progress, efficiently promoting dataset sharing and utilization for scientific research remains challenging. Scientific datasets contain intricate domain-specific knowledge and contexts, rendering traditional collaborative filtering-based recommenders inadequate. Recent advances in Large Language Models (LLMs) offer unprecedented opportunities to build conversational agents capable of deep semantic understanding and personalized recommendations. In response, we present ScienceDB AI, a novel LLM-driven agentic recommender system developed on Science Data Bank (ScienceDB), one of the largest global scientific data-sharing platforms. ScienceDB AI leverages natural language conversations and deep reasoning to accurately recommend datasets aligned with researchers' scientific intents and evolving requirements. The system introduces several innovations: a Scientific Intention Perceptor to extract structured experimental elements from complicated queries, a Structured Memory Compressor to manage multi-turn dialogues effectively, and a Trustworthy Retrieval-Augmented Generation (Trustworthy RAG) framework. The Trustworthy RAG employs a two-stage retrieval mechanism and provides citable dataset references via Citable Scientific Task Record (CSTR) identifiers, enhancing recommendation trustworthiness and reproducibility. Through extensive offline and online experiments using over 10 million real-world datasets, ScienceDB AI has demonstrated significant effectiveness. To our knowledge, ScienceDB AI is the first LLM-driven conversational recommender tailored explicitly for large-scale scientific dataset sharing services. The platform is publicly accessible at: https://ai.scidb.cn/en.", "AI": {"tldr": "本文介绍了ScienceDB AI，一种基于大型语言模型的代理推荐系统，用于促进大规模科学数据共享。", "motivation": "随着AI在科学研究中的应用快速增长，科学数据的重要性日益凸显。然而，有效地促进这些数据的共享和使用仍然是一个挑战。传统的方法不足以理解复杂的领域特定知识和上下文，而大型语言模型提供了新的机会来构建能够进行深度语义理解和个性化推荐的对话代理。", "method": "ScienceDB AI系统利用自然语言对话和深入推理准确地推荐与研究者科学意图相匹配的数据集，并且引入了多项创新技术，包括Scientific Intention Perceptor、Structured Memory Compressor以及Trustworthy Retrieval-Augmented Generation框架。这些机制共同提高了数据推荐的准确性、信任度和可重复性。", "result": "通过使用超过1000万条真实世界科学数据集进行的大规模离线与在线实验，ScienceDB AI展示了显著的有效性和改进。", "conclusion": "本文提出的ScienceDB AI是首个为大规模科学数据共享服务设计的大型语言模型驱动对话推荐系统。该平台已经在实际应用中证明了其有效性，并且对科学研究社区具有重要的潜在贡献和影响。"}}
{"id": "2601.01106", "pdf": "https://arxiv.org/pdf/2601.01106", "abs": "https://arxiv.org/abs/2601.01106", "authors": ["Michele Grimaldi", "Yosaku Maeda", "Hitoshi Kakami", "Ignacio Carlucho", "Yvan Petillot", "Tomoya Inoue"], "title": "Towards reliable subsea object recovery: a simulation study of an auv with a suction-actuated end effector", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous object recovery in the hadal zone is challenging due to extreme hydrostatic pressure, limited visibility and currents, and the need for precise manipulation at full ocean depth. Field experimentation in such environments is costly, high-risk, and constrained by limited vehicle availability, making early validation of autonomous behaviors difficult. This paper presents a simulation-based study of a complete autonomous subsea object recovery mission using a Hadal Small Vehicle (HSV) equipped with a three-degree-of-freedom robotic arm and a suction-actuated end effector. The Stonefish simulator is used to model realistic vehicle dynamics, hydrodynamic disturbances, sensing, and interaction with a target object under hadal-like conditions. The control framework combines a world-frame PID controller for vehicle navigation and stabilization with an inverse-kinematics-based manipulator controller augmented by acceleration feed-forward, enabling coordinated vehicle - manipulator operation. In simulation, the HSV autonomously descends from the sea surface to 6,000 m, performs structured seafloor coverage, detects a target object, and executes a suction-based recovery. The results demonstrate that high-fidelity simulation provides an effective and low-risk means of evaluating autonomous deep-sea intervention behaviors prior to field deployment.", "AI": {"tldr": "该论文通过使用仿真研究展示了一种全自主的海底物体回收任务，涉及一种装备有三自由度机械臂和吸盘操作末端执行器的小型深海探测器。", "motivation": "在极端水压、低能见度和电流环境下进行自动海底物体回收面临巨大挑战。实地实验成本高昂且风险大，限制了自主行为的早期验证。", "method": "论文使用Stonefish仿真器模拟真实车辆动态、流体动力干扰、感知及与目标对象交互的过程，在深海类似条件下执行全自主下降、结构化海底覆盖检测目标物体并实施吸盘回收任务。", "result": "结果显示，高保真度的仿真为在实地部署前评估自动深海干预行为提供了有效的低风险方式。", "conclusion": "研究表明使用先进的模拟技术可以有效且安全地验证全自主的深海操作方案。"}}
{"id": "2601.01103", "pdf": "https://arxiv.org/pdf/2601.01103", "abs": "https://arxiv.org/abs/2601.01103", "authors": ["Abhinav Attri", "Rajeev Ranjan Dwivedi", "Samiran Das", "Vinod Kumar Kurmi"], "title": "Histogram Assisted Quality Aware Generative Model for Resolution Invariant NIR Image Colorization", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted at WACV 2026", "summary": "We present HAQAGen, a unified generative model for resolution-invariant NIR-to-RGB colorization that balances chromatic realism with structural fidelity. The proposed model introduces (i) a combined loss term aligning the global color statistics through differentiable histogram matching, perceptual image quality measure, and feature based similarity to preserve texture information, (ii) local hue-saturation priors injected via Spatially Adaptive Denormalization (SPADE) to stabilize chromatic reconstruction, and (iii) texture-aware supervision within a Mamba backbone to preserve fine details. We introduce an adaptive-resolution inference engine that further enables high-resolution translation without sacrificing quality. Our proposed NIR-to-RGB translation model simultaneously enforces global color statistics and local chromatic consistency, while scaling to native resolutions without compromising texture fidelity or generalization. Extensive evaluations on FANVID, OMSIV, VCIP2020, and RGB2NIR using different evaluation metrics demonstrate consistent improvements over state-of-the-art baseline methods. HAQAGen produces images with sharper textures, natural colors, attaining significant gains as per perceptual metrics. These results position HAQAGen as a scalable and effective solution for NIR-to-RGB translation across diverse imaging scenarios. Project Page: https://rajeev-dw9.github.io/HAQAGen/", "AI": {"tldr": "提出了一种用于近红外图像到RGB彩色化处理的统一生成模型HAQAGen，该模型平衡了色彩真实性和结构保真度。", "motivation": "当前NIR-to-RGB彩色化的研究存在对纹理细节和全局色统计信息保持不佳的问题。为了解决这些问题，并实现高分辨率翻译的同时不牺牲质量，提出了一个新的模型。", "method": "该方法包括结合损失项以通过可微分直方图匹配、感知图像质量度量以及基于特征的相似性来调整全球色彩统计；局部色调饱和优先注入通过空间自适应去归一化（SPADE）稳定色谱重建；并在一个Mamba主干网络中引入纹理意识监督，从而保持细节点。此外，还介绍了一个适应分辨率推理引擎以进一步实现高分辨率翻译。", "result": "在FANVID、OMSIV、VCIP2020和RGB2NIR的广泛评估中，使用不同的评价标准显示了与最新基线方法相比的一致改进。HAQAGen生成具有更清晰纹理和自然色彩的图像，在感知度量方面获得了显著提升。", "conclusion": "通过同时保持全球色统计信息和局部色一致性，并扩展到原生分辨率而不会牺牲纹理保真度或泛化性，所提出的NIR-to-RGB转换模型是跨多种成像场景的有效解决方案。"}}
{"id": "2601.01099", "pdf": "https://arxiv.org/pdf/2601.01099", "abs": "https://arxiv.org/abs/2601.01099", "authors": ["Mahmudul Hasan", "Mabsur Fatin Bin Hossain"], "title": "Evolving CNN Architectures: From Custom Designs to Deep Residual Models for Diverse Image Classification and Detection Tasks", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper presents a comparative study of a custom convolutional neural network (CNN) architecture against widely used pretrained and transfer learning CNN models across five real-world image datasets. The datasets span binary classification, fine-grained multiclass recognition, and object detection scenarios. We analyze how architectural factors, such as network depth, residual connections, and feature extraction strategies, influence classification and localization performance. The results show that deeper CNN architectures provide substantial performance gains on fine-grained multiclass datasets, while lightweight pretrained and transfer learning models remain highly effective for simpler binary classification tasks. Additionally, we extend the proposed architecture to an object detection setting, demonstrating its adaptability in identifying unauthorized auto-rickshaws in real-world traffic scenes. Building upon a systematic analysis of custom CNN architectures alongside pretrained and transfer learning models, this study provides practical guidance for selecting suitable network designs based on task complexity and resource constraints.", "AI": {"tldr": "本文对比研究了自定义设计的卷积神经网络(CNN)架构与广泛使用的预训练和迁移学习模型在五个实际图像数据集上的表现，探讨了CNN深度、残差连接等结构因素对分类和定位性能的影响，并展示了其在识别未经授权的三轮车方面的适应性。", "motivation": "研究不同卷积神经网络(CNN)架构对于不同类型图像任务（例如二元分类、细粒度多类别识别以及物体检测）的表现差异，提供针对特定任务复杂性和资源限制的选择建议。", "method": "通过对比自定义设计的CNN与预训练和迁移学习模型在五个真实世界数据集上的表现来分析网络深度、残差连接等结构因素的影响，并将所提出的架构应用到对象检测任务中，用于识别未经授权的三轮车。", "result": "实验表明，在细粒度多类别分类场景下，更深的CNN架构能够提供显著的性能提升；而在简单的二元分类任务上，轻量级预训练和迁移学习模型仍然表现出很高的有效性。此外，提出的设计方案在实际交通情况下的未经授权三轮车检测中表现出了很好的适应性。", "conclusion": "基于对自定义CNN架构与预训练、迁移学习模型的系统分析，本研究为根据任务复杂度和资源限制选择合适的网络设计提供了实用指导"}}
{"id": "2601.01095", "pdf": "https://arxiv.org/pdf/2601.01095", "abs": "https://arxiv.org/abs/2601.01095", "authors": ["Hyeonjeong Ha", "Jinjin Ge", "Bo Feng", "Kaixin Ma", "Gargi Chakraborty"], "title": "NarrativeTrack: Evaluating Video Language Models Beyond the Frame", "categories": ["cs.CV", "cs.LG"], "comment": "VideoLLM Fine-Grained Evaluation", "summary": "Multimodal large language models (MLLMs) have achieved impressive progress in vision-language reasoning, yet their ability to understand temporally unfolding narratives in videos remains underexplored. True narrative understanding requires grounding who is doing what, when, and where, maintaining coherent entity representations across dynamic visual and temporal contexts. We introduce NarrativeTrack, the first benchmark to evaluate narrative understanding in MLLMs through fine-grained entity-centric reasoning. Unlike existing benchmarks limited to short clips or coarse scene-level semantics, we decompose videos into constituent entities and examine their continuity via a Compositional Reasoning Progression (CRP), a structured evaluation framework that progressively increases narrative complexity across three dimensions: entity existence, entity changes, and entity ambiguity. CRP challenges models to advance from temporal persistence to contextual evolution and fine-grained perceptual reasoning. A fully automated entity-centric pipeline enables scalable extraction of temporally grounded entity representations, providing the foundation for CRP. Evaluations of state-of-the-art MLLMs reveal that models fail to robustly track entities across visual transitions and temporal dynamics, often hallucinating identity under context shifts. Open-source general-purpose MLLMs exhibit strong perceptual grounding but weak temporal coherence, while video-specific MLLMs capture temporal context yet hallucinate entity's contexts. These findings uncover a fundamental trade-off between perceptual grounding and temporal reasoning, indicating that narrative understanding emerges only from their integration. NarrativeTrack provides the first systematic framework to diagnose and advance temporally grounded narrative comprehension in MLLMs.", "AI": {"tldr": "本文介绍了NarrativeTrack，这是一个评估多模态大型语言模型（MLLMs）在视频中叙事理解能力的基准。", "motivation": "目前的MLLMs虽然在视觉和语言推理方面取得了显著进步，但对于理解和处理视频中的动态叙述能力仍不够深入。为了填补这一研究空白，本文旨在通过NarrativeTrack评估这些模型在时间连续性上的表现。", "method": "通过将视频分解为构成实体，并采用一种称为组合推理进展（CRP）的结构化评价框架来测试MLLMs的能力，该框架逐步增加叙事复杂度。此外，还使用了自动化的基于实体中心的流水线来提取随时间定位的实体表示。", "result": "评估结果表明，现有的MLLMs在跟踪视觉过渡和时间动态方面表现出弱健壮性，并且常常会出现身份幻觉问题。开放源代码的一般用途模型虽然具有强大的感知基础但缺乏时间一致性，而特定于视频的模型可以捕捉到时间上下文却会对实体环境产生幻觉。", "conclusion": "本文揭示了MLLMs在视觉感知和时间推理之间存在根本性的权衡关系，并提出了NarrativeTrack作为诊断和提高MLLMs叙述理解能力的方法。"}}
{"id": "2601.01094", "pdf": "https://arxiv.org/pdf/2601.01094", "abs": "https://arxiv.org/abs/2601.01094", "authors": ["Yubo Shu", "Peng Zhang", "Meng Wu", "Yan Chen", "Haoxuan Zhou", "Guanming Liu", "Yu Zhang", "Liuxin Zhang", "Qianying Wang", "Tun Lu", "Ning Gu"], "title": "SoulSeek: Exploring the Use of Social Cues in LLM-based Information Seeking", "categories": ["cs.HC", "cs.AI", "cs.IR"], "comment": null, "summary": "Social cues, which convey others' presence, behaviors, or identities, play a crucial role in human information seeking by helping individuals judge relevance and trustworthiness. However, existing LLM-based search systems primarily rely on semantic features, creating a misalignment with the socialized cognition underlying natural information seeking. To address this gap, we explore how the integration of social cues into LLM-based search influences users' perceptions, experiences, and behaviors. Focusing on social media platforms that are beginning to adopt LLM-based search, we integrate design workshops, the implementation of the prototype system (SoulSeek), a between-subjects study, and mixed-method analyses to examine both outcome- and process-level findings. The workshop informs the prototype's cue-integrated design. The study shows that social cues improve perceived outcomes and experiences, promote reflective information behaviors, and reveal limits of current LLM-based search. We propose design implications emphasizing better social-knowledge understanding, personalized cue settings, and controllable interactions.", "AI": {"tldr": "研究探讨了在LLM（大型语言模型）搜索系统中整合社交线索的影响。", "motivation": "现有基于LLM的搜索引擎主要依赖语义特征，与人类自然信息获取中的社会化认知不匹配。为解决这一问题，本研究探索了社交线索对用户感知、体验和行为的影响。", "method": "通过设计工作坊来指导原型系统的设计，实施一个以社交媒体平台为目标用户的SoulSeek原型系统，并进行组间实验及混合方法分析。", "result": "研究表明，社交线索可以改善用户体验和感知结果，促进反思性信息行为，同时揭示当前基于LLM的搜索系统的局限性。", "conclusion": "研究提出了设计建议：更好地理解社交知识、个性化设置社交提示以及可控交互方式。"}}
{"id": "2601.01091", "pdf": "https://arxiv.org/pdf/2601.01091", "abs": "https://arxiv.org/abs/2601.01091", "authors": ["Haq Nawaz Malik"], "title": "ks-lit-3m: A 3.1 million word kashmiri text dataset for large language model pretraining", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) demonstrate remarkable fluency across high-resource languages yet consistently fail to generate coherent text in Kashmiri, a language spoken by approximately seven million people. This performance disparity stems not from inherent model limitations but from a critical scarcity of high-quality training data. Decades of Kashmiri literature remain inaccessible to modern NLP pipelines due to their encoding in the proprietary InPage desktop publishing format. This paper introduces KS-LIT-3M, a curated corpus of 3.1 million words (16.4 million characters) specifically designed for pretraining language models on Kashmiri. The dataset is structured as a single continuous linear text stream, optimized for causal language model training where models learn to predict subsequent tokens from preceding context. The corpus was constructed through the development of a specialized InPage-to-Unicode converter, followed by rigorous preprocessing including English contamination removal, character normalization, and quality validation. Encompassing 131,607 unique words drawn from diverse genres including literary works, journalistic writing, academic texts, and religious scholarship, KS-LIT-3M addresses a fundamental resource gap for Kashmiri language technology. The dataset is released under the CC-BY-4.0 license to facilitate research in Kashmiri natural language processing.", "AI": {"tldr": "构建了一个包含310万词的克什米尔语数据集，用于大型语言模型预训练。", "motivation": "由于高质量克什米尔语训练数据稀缺，导致大型语言模型在生成连贯文本时表现不佳。此研究旨在通过创建一个专门的数据集来解决这一问题。", "method": "开发了一个从InPage格式转换到Unicode的工具，并对收集的文本进行了包括英语污染去除、字符规范化和质量验证在内的预处理步骤。", "result": "发布了KS-LIT-3M数据集，包含1640万字符，涵盖了文学作品、新闻写作、学术文章及宗教著作等多样的内容。", "conclusion": "KS-LIT-3M填补了克什米尔语技术资源的空白，有助于推进该语言的自然语言处理研究。"}}
{"id": "2601.01090", "pdf": "https://arxiv.org/pdf/2601.01090", "abs": "https://arxiv.org/abs/2601.01090", "authors": ["Erica Coppolillo", "Luca Luceri", "Emilio Ferrara"], "title": "Harm in AI-Driven Societies: An Audit of Toxicity Adoption on Chirper.ai", "categories": ["cs.MA", "cs.AI", "cs.CY"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly embedded in autonomous agents that participate in online social ecosystems, where interactions are sequential, cumulative, and only partially controlled. While prior work has documented the generation of toxic content by LLMs, far less is known about how exposure to harmful content shapes agent behavior over time, particularly in environments composed entirely of interacting AI agents. In this work, we study toxicity adoption of LLM-driven agents on Chirper.ai, a fully AI-driven social platform. Specifically, we model interactions in terms of stimuli (posts) and responses (comments), and by operationalizing exposure through observable interactions rather than inferred recommendation mechanisms. We conduct a large-scale empirical analysis of agent behavior, examining how response toxicity relates to stimulus toxicity, how repeated exposure affects the likelihood of toxic responses, and whether toxic behavior can be predicted from exposure alone. Our findings show that while toxic responses are more likely following toxic stimuli, a substantial fraction of toxicity emerges spontaneously, independent of exposure. At the same time, cumulative toxic exposure significantly increases the probability of toxic responding. We further introduce two influence metrics, the Influence-Driven Response Rate and the Spontaneous Response Rate, revealing a strong trade-off between induced and spontaneous toxicity. Finally, we show that the number of toxic stimuli alone enables accurate prediction of whether an agent will eventually produce toxic content. These results highlight exposure as a critical risk factor in the deployment of LLM agents and suggest that monitoring encountered content may provide a lightweight yet effective mechanism for auditing and mitigating harmful behavior in the wild.", "AI": {"tldr": "研究了AI驱动的社会平台上，大型语言模型（LLMs）生成的有害内容如何影响交互行为。", "motivation": "探讨在完全由AI代理组成的环境中，暴露于有害内容对代理行为的影响以及其潜在风险。", "method": "通过刺激-响应模式分析，考察有害响应与刺激的关系、重复曝光的影响及毒性行为预测。", "result": "发现有害反应更可能随有害刺激出现，但也有大量自发毒性；累计有害曝光显著增加毒性反应概率。", "conclusion": "暴露是部署LLM代理的关键风险因素，监测遇到的内容可提供有效机制以审计和缓解有害行为。"}}
{"id": "2601.01088", "pdf": "https://arxiv.org/pdf/2601.01088", "abs": "https://arxiv.org/abs/2601.01088", "authors": ["Haq Nawaz Malik"], "title": "600k-ks-ocr: a large-scale synthetic dataset for optical character recognition in kashmiri script", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "This technical report presents the 600K-KS-OCR Dataset, a large-scale synthetic corpus comprising approximately 602,000 word-level segmented images designed for training and evaluating optical character recognition systems targeting Kashmiri script. The dataset addresses a critical resource gap for Kashmiri, an endangered Dardic language utilizing a modified Perso-Arabic writing system spoken by approximately seven million people. Each image is rendered at 256x64 pixels with corresponding ground-truth transcriptions provided in multiple formats compatible with CRNN, TrOCR, and generalpurpose machine learning pipelines. The generation methodology incorporates three traditional Kashmiri typefaces, comprehensive data augmentation simulating real-world document degradation, and diverse background textures to enhance model robustness. The dataset is distributed across ten partitioned archives totaling approximately 10.6 GB and is released under the CC-BY-4.0 license to facilitate research in low-resource language optical character recognition.", "AI": {"tldr": "介绍600K-KS-OCR数据集，这是一个用于训练和评估针对卡舒里语的光学字符识别系统的大型合成图像集合。", "motivation": "填补了卡舒里语言在光学字符识别领域的资源缺口，该语言是一种濒危的语言，采用修改后的波斯阿拉伯书写系统。", "method": "生成方法包括三种传统卡舒里字体、全面的数据增强以模拟现实世界中的文档退化以及多样化的背景纹理。", "result": "数据集由约602,000个图像组成，并分为十个归档文件，总大小约为10.6GB。", "conclusion": "发布了一个大型合成数据集，旨在促进低资源语言的光学字符识别研究。"}}
{"id": "2601.01085", "pdf": "https://arxiv.org/pdf/2601.01085", "abs": "https://arxiv.org/abs/2601.01085", "authors": ["Jiayi Xu", "Zhang Zhang", "Yuanrui Zhang", "Ruitao Chen", "Yixian Xu", "Tianyu He", "Di He"], "title": "Luminark: Training-free, Probabilistically-Certified Watermarking for General Vision Generative Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In this paper, we introduce \\emph{Luminark}, a training-free and probabilistically-certified watermarking method for general vision generative models. Our approach is built upon a novel watermark definition that leverages patch-level luminance statistics. Specifically, the service provider predefines a binary pattern together with corresponding patch-level thresholds. To detect a watermark in a given image, we evaluate whether the luminance of each patch surpasses its threshold and then verify whether the resulting binary pattern aligns with the target one. A simple statistical analysis demonstrates that the false positive rate of the proposed method can be effectively controlled, thereby ensuring certified detection. To enable seamless watermark injection across different paradigms, we leverage the widely adopted guidance technique as a plug-and-play mechanism and develop the \\emph{watermark guidance}. This design enables Luminark to achieve generality across state-of-the-art generative models without compromising image quality. Empirically, we evaluate our approach on nine models spanning diffusion, autoregressive, and hybrid frameworks. Across all evaluations, Luminark consistently demonstrates high detection accuracy, strong robustness against common image transformations, and good performance on visual quality.", "AI": {"tldr": "提出了一种无需训练且概率性认证的水印方法Luminark，适用于通用视觉生成模型。", "motivation": "旨在开发一种能够在各种图像转换下保持高检测准确率和良好视觉质量的同时，又能跨不同范式的无缝注入水印的方法。", "method": "基于新颖的水印定义，通过利用补丁级别的亮度统计信息来实现。服务提供商预先定义二进制模式及对应的补丁级别阈值；在给定图像中检测水印时，评估每个补丁的亮度是否超过其阈值，并验证生成的二进制图案是否与目标图案一致。", "result": "实验结果显示，在九种不同扩散、自回归和混合框架下的模型上均表现出高检测准确率和对常见图像变换的强大鲁棒性以及良好的视觉质量。", "conclusion": "Luminark能有效解决通用视觉生成模型中的水印问题，具有泛化能力和无需训练的特点。"}}
{"id": "2601.01084", "pdf": "https://arxiv.org/pdf/2601.01084", "abs": "https://arxiv.org/abs/2601.01084", "authors": ["Adari Rama Sukanya", "Puvvula Roopesh Naga Sri Sai", "Kota Moses", "Rimalapudi Sarvendranath"], "title": "A UAV-Based Multispectral and RGB Dataset for Multi-Stage Paddy Crop Monitoring in Indian Agricultural Fields", "categories": ["cs.CV", "eess.IV"], "comment": "10-page dataset explanation paper", "summary": "We present a large-scale unmanned aerial vehicle (UAV)-based RGB and multispectral image dataset collected over paddy fields in the Vijayawada region, Andhra Pradesh, India, covering nursery to harvesting stages. We used a 20-megapixel RGB camera and a 5-megapixel four-band multispectral camera capturing red, green, red-edge, and near-infrared bands. Standardised operating procedure (SOP) and checklists were developed to ensure repeatable data acquisition. Our dataset comprises of 42,430 raw images (415 GB) captured over 5 acres with 1 cm/pixel ground sampling distance (GSD) with associated metadata such as GPS coordinates, flight altitude, and environmental conditions. Captured images were validated using Pix4D Fields to generate orthomosaic maps and vegetation index maps, such as normalised difference vegetation index (NDVI) and normalised difference red-edge (NDRE) index. Our dataset is one of the few datasets that provide high-resolution images with rich metadata that cover all growth stages of Indian paddy crops. The dataset is available on IEEE DataPort with DOI, . It can support studies on targeted spraying, disease analysis, and yield estimation.", "AI": {"tldr": "本文介绍了在印度安得拉邦维贾亚瓦达地区收集的用于水稻作物监测的大规模无人机RGB和多光谱图像数据集。", "motivation": "为了支持对目标喷洒、病害分析和产量估算等研究，提供覆盖所有生长阶段高分辨率的印度水稻作物图像以及丰富的元数据。", "method": "使用2000万像素的RGB相机和500万像素的四通道多光谱相机采集了42,430张原始图像（415GB），并利用Pix4D Fields生成正射影像图和植被指数图，如NDVI和NDRE。", "result": "该数据集包括高分辨率图像与丰富的元数据，并可支持多项研究工作。", "conclusion": "所提出的数据集为印度水稻作物的多阶段监测提供了有价值的资源，有助于提高农业管理和生产效率。"}}
{"id": "2601.01082", "pdf": "https://arxiv.org/pdf/2601.01082", "abs": "https://arxiv.org/abs/2601.01082", "authors": ["Bryon Tjanaka", "Henry Chen", "Matthew C. Fontaine", "Stefanos Nikolaidis"], "title": "Discount Model Search for Quality Diversity Optimization in High-Dimensional Measure Spaces", "categories": ["cs.LG", "cs.NE"], "comment": "Source code available at https://github.com/icaros-usc/discount-models", "summary": "Quality diversity (QD) optimization searches for a collection of solutions that optimize an objective while attaining diverse outputs of a user-specified, vector-valued measure function. Contemporary QD algorithms focus on low-dimensional measures because high-dimensional measures are prone to distortion, where many solutions found by the QD algorithm map to similar measures. For example, the CMA-MAE algorithm guides measure space exploration with a histogram in measure space that records so-called discount values. However, CMA-MAE stagnates in domains with high-dimensional measure spaces because solutions with similar measures fall into the same histogram cell and thus receive identical discount values. To address these limitations, we propose Discount Model Search (DMS), which guides exploration with a model that provides a smooth, continuous representation of discount values. In high-dimensional measure spaces, this model enables DMS to distinguish between solutions with similar measures and thus continue exploration. We show that DMS facilitates new QD applications by introducing two domains where the measure space is the high-dimensional space of images, which enables users to specify their desired measures by providing a dataset of images rather than hand-designing the measure function. Results in these domains and on high-dimensional benchmarks show that DMS outperforms CMA-MAE and other black-box QD algorithms.", "AI": {"tldr": "提出了一种新的质量多样性优化算法Discount Model Search (DMS)，用于在高维度度量空间中搜索高质量和多样性的解决方案。", "motivation": "当前的质量多样性(QD)算法主要适用于低维度的度量，而在高维度度量空间中容易出现测量值相近的情况，导致算法性能下降。为解决此问题，提出了新的探索方法以提高算法在高维空间中的表现能力。", "method": "通过一个平滑连续的模型来提供折扣值的表示，这种方法可以区分具有相似测量值的不同解决方案，并继续进行搜索过程。该方法使得用户可以通过数据集指定期望的质量多样性输出。", "result": "实验表明，在高维度基准测试和新的应用场景中，DMS算法优于CMA-MAE和其他黑盒QD优化算法。", "conclusion": "通过引入Discount Model Search (DMS) 方法，解决了在高维度度量空间中的质量多样性搜索问题，并展示了该方法在实际应用中的优势。"}}
{"id": "2601.01076", "pdf": "https://arxiv.org/pdf/2601.01076", "abs": "https://arxiv.org/abs/2601.01076", "authors": ["Devesh Nath", "Haoran Yin", "Glen Chou"], "title": "Scalable Data-Driven Reachability Analysis and Control via Koopman Operators with Conformal Coverage Guarantees", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.RO", "math.OC"], "comment": "Under review, 28 pages, 12 figures", "summary": "We propose a scalable reachability-based framework for probabilistic, data-driven safety verification of unknown nonlinear dynamics. We use Koopman theory with a neural network (NN) lifting function to learn an approximate linear representation of the dynamics and design linear controllers in this space to enable closed-loop tracking of a reference trajectory distribution. Closed-loop reachable sets are efficiently computed in the lifted space and mapped back to the original state space via NN verification tools. To capture model mismatch between the Koopman dynamics and the true system, we apply conformal prediction to produce statistically-valid error bounds that inflate the reachable sets to ensure the true trajectories are contained with a user-specified probability. These bounds generalize across references, enabling reuse without recomputation. Results on high-dimensional MuJoCo tasks (11D Hopper, 28D Swimmer) and 12D quadcopters show improved reachable set coverage rate, computational efficiency, and conservativeness over existing methods.", "AI": {"tldr": "提出了一种基于Koopman算子和神经网络的可扩展数据驱动的安全性验证框架，用于未知非线性系统的概率可达性分析。", "motivation": "为了提高对未知非线性系统进行安全验证的效率和准确性，利用Koopman理论结合神经网络来近似线性表示系统动力学，并设计线性控制器以实现闭环跟踪参考轨迹分布。", "method": "使用Koopman算子与神经网络提升函数学习系统的近似线性表示；在提升空间中高效计算闭环可达集并通过神经网络验证工具将其映射回原始状态空间；应用符合预测技术产生统计有效的误差界限，以确保真实轨迹包含在指定概率内。", "result": "实验结果显示，在高维MuJoCo任务和四旋翼系统上，该方法提高了可达集覆盖效率、计算效率以及保守性优于现有方法。", "conclusion": "提出的方法能够有效处理未知非线性系统的安全验证问题，并通过符合预测技术确保了统计有效性。"}}
{"id": "2601.01075", "pdf": "https://arxiv.org/pdf/2601.01075", "abs": "https://arxiv.org/abs/2601.01075", "authors": ["Hansen Jin Lillemark", "Benhao Huang", "Fangneng Zhan", "Yilun Du", "Thomas Anderson Keller"], "title": "Flow Equivariant World Models: Memory for Partially Observed Dynamic Environments", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "11 main text pages, 10 figures", "summary": "Embodied systems experience the world as 'a symphony of flows': a combination of many continuous streams of sensory input coupled to self-motion, interwoven with the dynamics of external objects. These streams obey smooth, time-parameterized symmetries, which combine through a precisely structured algebra; yet most neural network world models ignore this structure and instead repeatedly re-learn the same transformations from data. In this work, we introduce 'Flow Equivariant World Models', a framework in which both self-motion and external object motion are unified as one-parameter Lie group 'flows'. We leverage this unification to implement group equivariance with respect to these transformations, thereby providing a stable latent world representation over hundreds of timesteps. On both 2D and 3D partially observed video world modeling benchmarks, we demonstrate that Flow Equivariant World Models significantly outperform comparable state-of-the-art diffusion-based and memory-augmented world modeling architectures -- particularly when there are predictable world dynamics outside the agent's current field of view. We show that flow equivariance is particularly beneficial for long rollouts, generalizing far beyond the training horizon. By structuring world model representations with respect to internal and external motion, flow equivariance charts a scalable route to data efficient, symmetry-guided, embodied intelligence. Project link: https://flowequivariantworldmodels.github.io.", "AI": {"tldr": "本文提出了流等变世界模型框架，通过统一自我运动和外部对象运动作为单参数李群流来实现稳定性长时序的潜在世界表示，在部分观察视频建模基准上优于现有方法。", "motivation": "当前神经网络世界模型忽略连续输入流的时间对称性结构，导致重复学习相同的变换。本文旨在利用等变性提供稳定的长期潜在世界表示。", "method": "引入了流等变世界模型框架，通过单参数李群流统一自我运动和外部对象运动，并实现这些变换的等变性，从而在部分观察环境中的长期时序任务上表现更优。", "result": "在2D和3D视频建模基准中，所提方法优于扩散基线和其他记忆增强世界模型架构，特别是在视野之外具有可预测动态的世界模型任务上表现尤为突出。", "conclusion": "流等变性通过结构化自我运动和外部物体的运动表示，为数据效率高、对称指导下的具身智能提供了一条可扩展途径。"}}
{"id": "2601.01073", "pdf": "https://arxiv.org/pdf/2601.01073", "abs": "https://arxiv.org/abs/2601.01073", "authors": ["Erica Coppolillo", "Emilio Ferrara"], "title": "Gendered Pathways in AI Companionship: Cross-Community Behavior and Toxicity Patterns on Reddit", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "AI-companionship platforms are rapidly reshaping how people form emotional, romantic, and parasocial bonds with non-human agents, raising new questions about how these relationships intersect with gendered online behavior and exposure to harmful content. Focusing on the MyBoyfriendIsAI (MBIA) subreddit, we reconstruct the Reddit activity histories of more than 3,000 highly engaged users over two years, yielding over 67,000 historical submissions. We then situate MBIA within a broader ecosystem by building a historical interaction network spanning more than 2,000 subreddits, which enables us to trace cross-community pathways and measure how toxicity and emotional expression vary across these trajectories. We find that MBIA users primarily traverse four surrounding community spheres (AI-companionship, porn-related, forum-like, and gaming) and that participation across the ecosystem exhibits a distinct gendered structure, with substantial engagement by female users. While toxicity is generally low across most pathways, we observe localized spikes concentrated in a small subset of AI-porn and gender-oriented communities. Nearly 16% of users engage with gender-focused subreddits, and their trajectories display systematically different patterns of emotional expression and elevated toxicity, suggesting that a minority of gendered pathways may act as toxicity amplifiers within the broader AI-companionship ecosystem. These results characterize the gendered structure of cross-community participation around AI companionship on Reddit and highlight where risks concentrate, informing measurement, moderation, and design practices for human-AI relationship platforms.", "AI": {"tldr": "研究探讨了AI伴侣平台用户在线行为及接触有害内容的情况，特别是在MyBoyfriendIsAI（MBIA）子版块内及其周边社区中的性别化路径。", "motivation": "探索AI陪伴平台上形成的非人类情感、浪漫和准社会关系如何与网络上的性别差异行为和有害内容暴露相交。", "method": "通过重建超过3,000名高度参与用户的Reddit活动历史记录，构建了一个跨越2000多个子版块的历史互动网络来追踪跨社区路径，并测量这些途径上的情感表达和毒性变化。", "result": "MBIA用户主要穿越四个相关社区（AI伴侣、色情、论坛和游戏），显示了性别化的参与结构。尽管大多数路径上的毒性较低，但特定的AI-色情和性别导向子版块存在局部毒性高峰，约16%的用户接触性别聚焦子版块。", "conclusion": "研究描绘了围绕Reddit上AI伴侣平台用户的跨社区参与模式，并突出了潜在风险集中区域。"}}
{"id": "2601.01067", "pdf": "https://arxiv.org/pdf/2601.01067", "abs": "https://arxiv.org/abs/2601.01067", "authors": ["Wenzheng Zhang", "Yoshitaka Hara", "Sousuke Nakamura"], "title": "Topological Mapping and Navigation using a Monocular Camera based on AnyLoc", "categories": ["cs.RO"], "comment": "Published in Proc. IEEE CASE 2025. 7 pages, 11 figures", "summary": "This paper proposes a method for topological mapping and navigation using a monocular camera. Based on AnyLoc, keyframes are converted into descriptors to construct topological relationships, enabling loop detection and map building. Unlike metric maps, topological maps simplify path planning and navigation by representing environments with key nodes instead of precise coordinates. Actions for visual navigation are determined by comparing segmented images with the image associated with target nodes. The system relies solely on a monocular camera, ensuring fast map building and navigation using key nodes. Experiments show effective loop detection and navigation in real and simulation environments without pre-training. Compared to a ResNet-based method, this approach improves success rates by 60.2% on average while reducing time and space costs, offering a lightweight solution for robot and human navigation in various scenarios.", "AI": {"tldr": "本文提出了一种基于单目相机的拓扑地图构建和导航方法。", "motivation": "通过使用单目相机进行高效的地图构建与导航，简化路径规划过程，提高机器人及人在各种环境中的移动效率。", "method": "利用AnyLoc技术将关键帧转换成描述符以建立拓扑关系，并通过分割图像对比实现视觉导航决策。", "result": "实验表明该方法在真实和模拟环境中有效检测循环并执行导航任务，且成功率比ResNet方法平均提高了60.2%，同时减少时间和空间消耗。", "conclusion": "本文提出的方法提供了一种轻量级解决方案，在不需预训练的情况下实现了高效的地图构建与导航。"}}
{"id": "2601.01064", "pdf": "https://arxiv.org/pdf/2601.01064", "abs": "https://arxiv.org/abs/2601.01064", "authors": ["Jianan Li", "Wangcai Zhao", "Tingfa Xu"], "title": "Efficient Hyperspectral Image Reconstruction Using Lightweight Separate Spectral Transformers", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Hyperspectral imaging (HSI) is essential across various disciplines for its capacity to capture rich spectral information. However, efficiently reconstructing hyperspectral images from compressive sensing measurements presents significant challenges. To tackle these, we adopt a divide-and-conquer strategy that capitalizes on the unique spectral and spatial characteristics of hyperspectral images. We introduce the Lightweight Separate Spectral Transformer (LSST), an innovative architecture tailored for efficient hyperspectral image reconstruction. This architecture consists of Separate Spectral Transformer Blocks (SSTB) for modeling spectral relationships and Lightweight Spatial Convolution Blocks (LSCB) for spatial processing. The SSTB employs Grouped Spectral Self-attention and a Spectrum Shuffle operation to effectively manage both local and non-local spectral relationships. Simultaneously, the LSCB utilizes depth-wise separable convolutions and strategic ordering to enhance spatial information processing. Furthermore, we implement the Focal Spectrum Loss, a novel loss weighting mechanism that dynamically adjusts during training to improve reconstruction across spectrally complex bands. Extensive testing demonstrates that our LSST achieves superior performance while requiring fewer FLOPs and parameters, underscoring its efficiency and effectiveness. The source code is available at: https://github.com/wcz1124/LSST.", "AI": {"tldr": "本文提出了一种轻量级的分离光谱变换器（LSST）架构，用于高效重建高光谱图像。", "motivation": "有效地从压缩感知测量中重建高光谱图像面临着巨大挑战。为了应对这些挑战，本文采用了一种分而治之策略来利用高光谱图像独特的光谱和空间特征。", "method": "LSST架构包括分离的光谱变换器块（SSTB）用于建模光谱关系，以及轻量级的空间卷积块（LSCB）用于处理空间信息。SSTB运用分组的光谱自注意机制和频谱打乱操作来有效管理局部和非局部的光谱关联。同时，LSCB利用深度可分离卷积和策略性排序来增强对空间信息的处理。", "result": "本文提出的LSST在测试中表现出色，不仅性能卓越而且需要更少的计算量和参数，证明了其效率和有效性。", "conclusion": "通过创新的设计和技术，LSST架构为高光谱图像重建提供了高效且有效的解决方案。"}}
{"id": "2601.01062", "pdf": "https://arxiv.org/pdf/2601.01062", "abs": "https://arxiv.org/abs/2601.01062", "authors": ["Yunlin Zeng"], "title": "SPoRC-VIST: A Benchmark for Evaluating Generative Natural Narrative in Vision-Language Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "14 pages, 3 figures. Accepted to WVAQ 2026, WACV 2026", "summary": "Vision-Language Models (VLMs) have achieved remarkable success in descriptive tasks such as image captioning and visual question answering (VQA). However, their ability to generate engaging, long-form narratives -- specifically multi-speaker podcast dialogues -- remains under-explored and difficult to evaluate. Standard metrics like BLEU and ROUGE fail to capture the nuances of conversational naturalness, personality, and narrative flow, often rewarding safe, repetitive outputs over engaging storytelling. In this work, we present a novel pipeline for end-to-end visual podcast generation, and fine-tune a Qwen3-VL-32B model on a curated dataset of 4,000 image-dialogue pairs. Crucially, we use a synthetic-to-real training strategy: we train on high-quality podcast dialogues from the Structured Podcast Research Corpus (SPoRC) paired with synthetically generated imagery, and evaluate on real-world photo sequences from the Visual Storytelling Dataset (VIST). This rigorous setup tests the model's ability to generalize from synthetic training data to real-world visual domains. We propose a comprehensive evaluation framework that moves beyond textual overlap, and use AI-as-a-judge (Gemini 3 Pro, Claude Opus 4.5, GPT 5.2) and novel style metrics (average turn length, speaker switch rate) to assess quality. Our experiments demonstrate that our fine-tuned 32B model significantly outperforms a 235B base model in conversational naturalness ($>$80\\% win rate) and narrative depth (+50\\% turn length), while maintaining identical visual grounding capabilities (CLIPScore: 20.39).", "AI": {"tldr": "本文提出了一个新的基准测试SPoRC-VIST，用于评估视觉语言模型生成自然叙述的能力，并展示了使用合成图像和真实世界照片序列训练的Qwen3-VL-32B模型在对话自然度和叙事深度上的改进。", "motivation": "当前的视觉语言模型在描述性任务上表现出色，但在生成多角色对话语音播客等长篇叙述方面的能力仍未被充分探索。传统的评估指标如BLEU和ROUGE无法捕捉会话自然度、个性以及叙事流畅性的细节，偏向于奖励安全重复的内容而非引人入胜的故事。", "method": "本文提出了一种端到端的视觉播客生成管道，并使用合成图像与真实世界的照片序列训练Qwen3-VL-32B模型。该方法采用从SPoRC中获取高质量对话语音和人工生成的图像进行训练，然后在VIST的数据上评估效果。", "result": "实验显示，在对话自然度方面，本文所训练的32B模型比基础模型更优（胜率超过80%），同时叙事深度也提高了50%，并且保持了相同的视觉接地能力（CLIPScore: 20.39）。", "conclusion": "本文通过提出新的基准测试SPoRC-VIST和改进的训练策略，展示了在评估视觉语言模型生成自然叙述方面的进展，并证明了该方法的有效性。"}}
{"id": "2601.01061", "pdf": "https://arxiv.org/pdf/2601.01061", "abs": "https://arxiv.org/abs/2601.01061", "authors": ["Yajing Liu", "Erkao Bao", "Linqi Song"], "title": "A UCB Bandit Algorithm for General ML-Based Estimators", "categories": ["cs.LG", "cs.AI", "math.PR"], "comment": "15 pages, 4 figures, 1 table, Multi-Arm bandit, psi-UCB, generalized machine learning models", "summary": "We present ML-UCB, a generalized upper confidence bound algorithm that integrates arbitrary machine learning models into multi-armed bandit frameworks. A fundamental challenge in deploying sophisticated ML models for sequential decision-making is the lack of tractable concentration inequalities required for principled exploration. We overcome this limitation by directly modeling the learning curve behavior of the underlying estimator. Specifically, assuming the Mean Squared Error decreases as a power law in the number of training samples, we derive a generalized concentration inequality and prove that ML-UCB achieves sublinear regret. This framework enables the principled integration of any ML model whose learning curve can be empirically characterized, eliminating the need for model-specific theoretical analysis. We validate our approach through experiments on a collaborative filtering recommendation system using online matrix factorization with synthetic data designed to simulate a simplified two-tower model, demonstrating substantial improvements over LinUCB", "AI": {"tldr": "提出了ML-UCB算法，该算法将任意机器学习模型集成到多臂老虎机框架中，并通过直接建模估算器的学习曲线行为来克服探索难题。", "motivation": "解决在顺序决策中使用复杂机器学习模型时缺乏可追踪的集中不等式的挑战，从而提供一种原则性的探索方法。", "method": "假设均方误差随着训练样本数量呈幂律减少，推导出广义集中不等式，并证明ML-UCB算法可以实现次线性后悔。该框架使任何学习曲线可以通过经验描述的机器学习模型能够被有原则地整合。", "result": "通过在线矩阵分解的协同过滤推荐系统实验，验证了方法的有效性，结果显示在模拟简化双塔模型的合成数据上显著优于LinUCB算法。", "conclusion": "提出了一种新的多臂老虎机算法ML-UCB，并展示了其应用于复杂机器学习模型时的优势。"}}
{"id": "2601.01056", "pdf": "https://arxiv.org/pdf/2601.01056", "abs": "https://arxiv.org/abs/2601.01056", "authors": ["Ifeanyi Ezuma", "Ugochukwu Ugwu"], "title": "Enhancing Histopathological Image Classification via Integrated HOG and Deep Features with Robust Noise Performance", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 8 figures. Code and datasets available upon request", "summary": "The era of digital pathology has advanced histopathological examinations, making automated image analysis essential in clinical practice. This study evaluates the classification performance of machine learning and deep learning models on the LC25000 dataset, which includes five classes of histopathological images. We used the fine-tuned InceptionResNet-v2 network both as a classifier and for feature extraction. Our results show that the fine-tuned InceptionResNet-v2 achieved a classification accuracy of 96.01\\% and an average AUC of 96.8\\%. Models trained on deep features from InceptionResNet-v2 outperformed those using only the pre-trained network, with the Neural Network model achieving an AUC of 99.99\\% and accuracy of 99.84\\%. Evaluating model robustness under varying SNR conditions revealed that models using deep features exhibited greater resilience, particularly GBM and KNN. The combination of HOG and deep features showed enhanced performance, however, less so in noisy environments.", "AI": {"tldr": "本论文研究了利用集成HOG和深度特征来提升基于LC25000数据集的组织病理学图像分类的性能，并评估了在不同信噪比条件下模型的鲁棒性。", "motivation": "随着数字病理学的发展，自动化图像分析变得至关重要。然而，在实际临床应用中仍需提高算法对噪声环境的适应能力以及准确度和稳定性。", "method": "使用预训练且微调后的InceptionResNet-v2网络作为分类器和特征提取工具，并对比了仅用深度特征及结合HOG特征的效果，同时评估了在不同信噪比下的模型性能。", "result": "实验表明，基于微调InceptionResNet-v2的神经网络模型在准确率和AUC上分别达到了99.84%和99.99%，而集成HOG与深度特征的方法虽然表现出较好的分类效果，但在噪声环境中的表现略有下降。", "conclusion": "通过结合使用HOG特征和来自InceptionResNet-v2的深度特征，可以显著提升组织病理学图像分类任务的表现，并且模型在面对不同信噪比时展现出更强的鲁棒性。"}}
{"id": "2601.01050", "pdf": "https://arxiv.org/pdf/2601.01050", "abs": "https://arxiv.org/abs/2601.01050", "authors": ["Hongming Fu", "Wenjia Wang", "Xiaozhen Qiao", "Shuo Yang", "Zheng Liu", "Bo Zhao"], "title": "EgoGrasp: World-Space Hand-Object Interaction Estimation from Egocentric Videos", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": null, "summary": "We propose EgoGrasp, the first method to reconstruct world-space hand-object interactions (W-HOI) from egocentric monocular videos with dynamic cameras in the wild. Accurate W-HOI reconstruction is critical for understanding human behavior and enabling applications in embodied intelligence and virtual reality. However, existing hand-object interactions (HOI) methods are limited to single images or camera coordinates, failing to model temporal dynamics or consistent global trajectories. Some recent approaches attempt world-space hand estimation but overlook object poses and HOI constraints. Their performance also suffers under severe camera motion and frequent occlusions common in egocentric in-the-wild videos. To address these challenges, we introduce a multi-stage framework with a robust pre-process pipeline built on newly developed spatial intelligence models, a whole-body HOI prior model based on decoupled diffusion models, and a multi-objective test-time optimization paradigm. Our HOI prior model is template-free and scalable to multiple objects. In experiments, we prove our method achieving state-of-the-art performance in W-HOI reconstruction.", "AI": {"tldr": "提出了一种从第一人称单目视频中重建世界空间的手部与物体交互的方法。", "motivation": "现有方法无法准确捕捉动态相机下的手部和物体的时空交互，限制了其在理解和模拟人类行为中的应用。", "method": "采用多阶段框架，包括稳健预处理管道、基于解耦扩散模型的整体HOI先验模型以及测试时间优化范式。", "result": "实验结果表明该方法在世界空间手部-物体交互重建中达到了最先进的性能水平。", "conclusion": "提出的方法能够有效解决现有技术面临的挑战，实现准确的世界空间手部与物体的动态交互估计。"}}
{"id": "2601.01044", "pdf": "https://arxiv.org/pdf/2601.01044", "abs": "https://arxiv.org/abs/2601.01044", "authors": ["Jin Wang", "Angelo De Castro", "Yuxi Zhang", "Lucas Basolli Borsatto", "Yuechen Guo", "Victoria Bastos Primo", "Ana Beatriz Montevecchio Bernardino", "Gota Morota", "Ricardo C Chebel", "Haipeng Yu"], "title": "Evaluating transfer learning strategies for improving dairy cattle body weight prediction in small farms using depth-image and point-cloud data", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Computer vision provides automated, non-invasive, and scalable tools for monitoring dairy cattle, thereby supporting management, health assessment, and phenotypic data collection. Although transfer learning is commonly used for predicting body weight from images, its effectiveness and optimal fine-tuning strategies remain poorly understood in livestock applications, particularly beyond the use of pretrained ImageNet or COCO weights. In addition, while both depth images and three-dimensional point-cloud data have been explored for body weight prediction, direct comparisons of these two modalities in dairy cattle are limited. Therefore, the objectives of this study were to 1) evaluate whether transfer learning from a large farm enhances body weight prediction on a small farm with limited data, and 2) compare the predictive performance of depth-image- and point-cloud-based approaches under three experimental designs. Top-view depth images and point-cloud data were collected from 1,201, 215, and 58 cows at large, medium, and small dairy farms, respectively. Four deep learning models were evaluated: ConvNeXt and MobileViT for depth images, and PointNet and DGCNN for point clouds. Transfer learning markedly improved body weight prediction on the small farm across all four models, outperforming single-source learning and achieving gains comparable to or greater than joint learning. These results indicate that pretrained representations generalize well across farms with differing imaging conditions and dairy cattle populations. No consistent performance difference was observed between depth-image- and point-cloud-based models. Overall, these findings suggest that transfer learning is well suited for small farm prediction scenarios where cross-farm data sharing is limited by privacy, logistical, or policy constraints, as it requires access only to pretrained model weights rather than raw data.", "AI": {"tldr": "评估了深度图像和点云数据在小农场奶牛体重预测中的迁移学习策略的有效性。", "motivation": "探索迁移学习对于提高小型农场奶牛体重预测的效率，尤其是在ImageNet或COCO权重之外的应用。此外，直接比较深度图与点云在这方面的表现也非常重要。", "method": "收集了来自不同规模奶牛场的顶视深度图像和点云数据，并评估了四种模型：ConvNeXt、MobileViT（用于深度图）以及PointNet、DGCNN（用于点云）。研究还探讨了单源学习、联合学习与迁移学习之间的比较。", "result": "迁移学习显著提升了小农场奶牛体重预测的准确性，超过单一来源的学习效果，并且在某些情况下甚至优于联合学习。两种数据类型之间没有发现一致性的性能差异。", "conclusion": "研究表明，在隐私、物流或政策限制了跨农场原始数据共享的情况下，迁移学习非常适合小型农场的预测场景，只需要访问预训练模型权重即可。"}}
{"id": "2601.01041", "pdf": "https://arxiv.org/pdf/2601.01041", "abs": "https://arxiv.org/abs/2601.01041", "authors": ["Xiang Zhang", "Wenliang Weng", "Daoyong Fu", "Ziqiang Li", "Zhangjie Fu"], "title": "Deepfake Detection with Multi-Artifact Subspace Fine-Tuning and Selective Layer Masking", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Deepfake detection still faces significant challenges in cross-dataset and real-world complex scenarios. The root cause lies in the high diversity of artifact distributions introduced by different forgery methods, while pretrained models tend to disrupt their original general semantic structures when adapting to new artifacts. Existing approaches usually rely on indiscriminate global parameter updates or introduce additional supervision signals, making it difficult to effectively model diverse forgery artifacts while preserving semantic stability. To address these issues, this paper proposes a deepfake detection method based on Multi-Artifact Subspaces and selective layer masks (MASM), which explicitly decouples semantic representations from artifact representations and constrains the fitting strength of artifact subspaces, thereby improving generalization robustness in cross-dataset scenarios. Specifically, MASM applies singular value decomposition to model weights, partitioning pretrained weights into a stable semantic principal subspace and multiple learnable artifact subspaces. This design enables decoupled modeling of different forgery artifact patterns while preserving the general semantic subspace. On this basis, a selective layer mask strategy is introduced to adaptively regulate the update behavior of corresponding network layers according to the learning state of each artifact subspace, suppressing overfitting to any single forgery characteristic. Furthermore, orthogonality constraints and spectral consistency constraints are imposed to jointly regularize multiple artifact subspaces, guiding them to learn complementary and diverse artifact representations while maintaining a stable overall spectral structure.", "AI": {"tldr": "提出了一种基于多伪迹子空间和选择性层掩膜的深度伪造检测方法（MASM）。", "motivation": "解决跨数据集和真实复杂场景下的深度伪造检测挑战，现有方法难以有效建模多样化的伪造痕迹同时保持语义稳定性。", "method": "通过奇异值分解将预训练权重分为稳定的语义主子空间和可学习的伪迹子空间，并引入选择性层掩膜策略来调节网络层数据集适应行为，抑制过拟合。", "result": "提高了跨数据集场景下的泛化鲁棒性和检测性能。", "conclusion": "所提方法通过解耦语义表征和伪迹表征，实现了更有效的伪造痕迹建模及稳定性维护。"}}
{"id": "2601.01037", "pdf": "https://arxiv.org/pdf/2601.01037", "abs": "https://arxiv.org/abs/2601.01037", "authors": ["Livia Leong Hui Teng"], "title": "Multi-Dimensional Prompt Chaining to Improve Open-Domain Dialogue Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Small language models (SLMs) offer significant deployment advantages but often struggle to match the dialogue quality of larger models in open-domain settings. In this paper, we propose a multi-dimensional prompt-chaining framework that integrates Naturalness, Coherence, and Engagingness dimensions to enhance human-likeness in open-domain dialogue generation. We apply the framework to two SLMs, TinyLlama and Llama-2-7B, and benchmark their performance against responses generated by substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. We then employ automatic and human evaluation to assess the responses based on diversity, contextual coherence, as well as overall quality. Results show that the full framework improves response diversity by up to 29%, contextual coherence by up to 28%, and engagingness as well as naturalness by up to 29%. Notably, Llama-2-7B achieves performance comparable to substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. Overall, the findings demonstrate that carefully designed prompt-based strategies provide an effective and resource-efficient pathway to improving open-domain dialogue quality in SLMs.", "AI": {"tldr": "提出一个多维度提示链框架，以改善小型语言模型在开放域对话生成中的质量", "motivation": "为了提高小规模语言模型的对话质量，使其更接近大模型的表现", "method": "通过整合自然度、连贯性和吸引力三个维度构建多维提示链框架，并应用到两种小型语言模型TinyLlama和Llama-2-7B中进行测试", "result": "结果显示该方法显著提高了响应多样性（最多提高29%），上下文连贯性（最多提高28%）以及自然度和吸引力（最多提高29%）；其中Llama-2-7B的性能与更大规模模型相当", "conclusion": "精心设计的提示策略提供了一种有效且资源高效的方法来改善小型语言模型中的开放域对话质量"}}
{"id": "2601.01036", "pdf": "https://arxiv.org/pdf/2601.01036", "abs": "https://arxiv.org/abs/2601.01036", "authors": ["Kiet Dang Vu", "Trung Thai Tran", "Kien Nguyen Do Trung", "Duc Dung Nguyen"], "title": "Mono3DV: Monocular 3D Object Detection with 3D-Aware Bipartite Matching and Variational Query DeNoising", "categories": ["cs.CV"], "comment": null, "summary": "While DETR-like architectures have demonstrated significant potential for monocular 3D object detection, they are often hindered by a critical limitation: the exclusion of 3D attributes from the bipartite matching process. This exclusion arises from the inherent ill-posed nature of 3D estimation from monocular image, which introduces instability during training. Consequently, high-quality 3D predictions can be erroneously suppressed by 2D-only matching criteria, leading to suboptimal results. To address this, we propose Mono3DV, a novel Transformer-based framework. Our approach introduces three key innovations. First, we develop a 3D-Aware Bipartite Matching strategy that directly incorporates 3D geometric information into the matching cost, resolving the misalignment caused by purely 2D criteria. Second, it is important to stabilize the Bipartite Matching to resolve the instability occurring when integrating 3D attributes. Therefore, we propose 3D-DeNoising scheme in the training phase. Finally, recognizing the gradient vanishing issue associated with conventional denoising techniques, we propose a novel Variational Query DeNoising mechanism to overcome this limitation, which significantly enhances model performance. Without leveraging any external data, our method achieves state-of-the-art results on the KITTI 3D object detection benchmark.", "AI": {"tldr": "Mono3DV是一种基于Transformer的框架，用于单目三维物体检测。", "motivation": "传统DETR架构在单目三维物体检测中由于忽略三维属性而导致训练不稳定和预测精度降低。为解决此问题提出Mono3DV。", "method": "该方法引入了3D-Aware Bipartite Matching策略、3D-DeNoising方案以及Variational Query DeNoising机制，以提高模型性能。", "result": "无需额外数据，在KITTI基准测试中达到最优结果。", "conclusion": "Mono3DV通过有效集成三维信息和创新解噪技术提高了单目三维物体检测的准确性。"}}
{"id": "2601.01029", "pdf": "https://arxiv.org/pdf/2601.01029", "abs": "https://arxiv.org/abs/2601.01029", "authors": ["Zeyu Bian", "Max Biggs", "Ruijiang Gao", "Zhengling Qi"], "title": "Beyond Demand Estimation: Consumer Surplus Evaluation via Cumulative Propensity Weights", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.ST"], "comment": "74 pages", "summary": "This paper develops a practical framework for using observational data to audit the consumer surplus effects of AI-driven decisions, specifically in targeted pricing and algorithmic lending. Traditional approaches first estimate demand functions and then integrate to compute consumer surplus, but these methods can be challenging to implement in practice due to model misspecification in parametric demand forms and the large data requirements and slow convergence of flexible nonparametric or machine learning approaches. Instead, we exploit the randomness inherent in modern algorithmic pricing, arising from the need to balance exploration and exploitation, and introduce an estimator that avoids explicit estimation and numerical integration of the demand function. Each observed purchase outcome at a randomized price is an unbiased estimate of demand and by carefully reweighting purchase outcomes using novel cumulative propensity weights (CPW), we are able to reconstruct the integral. Building on this idea, we introduce a doubly robust variant named the augmented cumulative propensity weighting (ACPW) estimator that only requires one of either the demand model or the historical pricing policy distribution to be correctly specified. Furthermore, this approach facilitates the use of flexible machine learning methods for estimating consumer surplus, since it achieves fast convergence rates by incorporating an estimate of demand, even when the machine learning estimate has slower convergence rates. Neither of these estimators is a standard application of off-policy evaluation techniques as the target estimand, consumer surplus, is unobserved. To address fairness, we extend this framework to an inequality-aware surplus measure, allowing regulators and firms to quantify the profit-equity trade-off. Finally, we validate our methods through comprehensive numerical studies.", "AI": {"tldr": "本文提出了一种利用观察数据评估AI驱动决策的消费者剩余影响的新方法。", "motivation": "传统的方法通过估计需求函数来计算消费者剩余，但在实践中由于模型设定偏差和大量数据需求等挑战难以实施。因此，开发新的框架以更实际地进行消费者剩余评估是必要的。", "method": "利用现代算法定价中固有的随机性，避免直接估计和数值积分需求函数，并引入累积倾向权重（CPW）重新加权购买结果来重建积分。此外，还提出了一种增强的累积倾向加权估计算法（ACPW），仅需正确指定需求模型或历史定价策略分布之一即可。", "result": "通过全面的数值研究验证了方法的有效性，并提出了一个关注公平性的消费者剩余测量方式。", "conclusion": "本文的方法提供了一个实用框架，利用观察数据评估AI驱动决策对消费者的正面影响，同时解决了传统方法中的挑战。"}}
{"id": "2601.01027", "pdf": "https://arxiv.org/pdf/2601.01027", "abs": "https://arxiv.org/abs/2601.01027", "authors": ["Rafael Wampfler", "Chen Yang", "Dillon Elste", "Nikola Kovacevic", "Philine Witzig", "Markus Gross"], "title": "A Platform for Interactive AI Character Experiences", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.GR"], "comment": "ef:SIGGRAPH Conference Papers '25, August 10-14, 2025, Vancouver, BC, Canada", "summary": "From movie characters to modern science fiction - bringing characters into interactive, story-driven conversations has captured imaginations across generations. Achieving this vision is highly challenging and requires much more than just language modeling. It involves numerous complex AI challenges, such as conversational AI, maintaining character integrity, managing personality and emotions, handling knowledge and memory, synthesizing voice, generating animations, enabling real-world interactions, and integration with physical environments. Recent advancements in the development of foundation models, prompt engineering, and fine-tuning for downstream tasks have enabled researchers to address these individual challenges. However, combining these technologies for interactive characters remains an open problem. We present a system and platform for conveniently designing believable digital characters, enabling a conversational and story-driven experience while providing solutions to all of the technical challenges. As a proof-of-concept, we introduce Digital Einstein, which allows users to engage in conversations with a digital representation of Albert Einstein about his life, research, and persona. While Digital Einstein exemplifies our methods for a specific character, our system is flexible and generalizes to any story-driven or conversational character. By unifying these diverse AI components into a single, easy-to-adapt platform, our work paves the way for immersive character experiences, turning the dream of lifelike, story-based interactions into a reality.", "AI": {"tldr": "开发一个平台，用于设计具有交互性的数字角色，并实现故事驱动的对话体验。", "motivation": "通过结合先进技术解决创建逼真互动角色的各种技术挑战，如语言模型、情感管理及与物理环境的集成，以推动沉浸式角色体验的发展。", "method": "构建了一个系统和平台，该平台可以轻松设计相信的数字角色，并提供了一种方法来应对所有相关技术难题。作为概念验证，展示了与爱因斯坦虚拟形象对话的能力。", "result": "通过统一各种AI组件到一个易于适应的平台上，使创造逼真的、基于故事的互动成为可能。", "conclusion": "该平台为实现更加沉浸式的角色体验提供了新的可能性，将梦想变为现实。"}}
{"id": "2601.01026", "pdf": "https://arxiv.org/pdf/2601.01026", "abs": "https://arxiv.org/abs/2601.01026", "authors": ["Douglas Costa Braga", "Daniel Oliveira Dantas"], "title": "Enhanced Leukemic Cell Classification Using Attention-Based CNN and Data Augmentation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.SE"], "comment": "9 pages, 5 figures, 4 tables. Submitted to VISAPP 2025", "summary": "We present a reproducible deep learning pipeline for leukemic cell classification, focusing on system architecture, experimental robustness, and software design choices for medical image analysis. Acute lymphoblastic leukemia (ALL) is the most common childhood cancer, requiring expert microscopic diagnosis that suffers from inter-observer variability and time constraints. The proposed system integrates an attention-based convolutional neural network combining EfficientNetV2-B3 with Squeeze-and-Excitation mechanisms for automated ALL cell classification. Our approach employs comprehensive data augmentation, focal loss for class imbalance, and patient-wise data splitting to ensure robust and reproducible evaluation. On the C-NMC 2019 dataset (12,528 original images from 62 patients), the system achieves a 97.89% F1-score and 97.89% accuracy on the test set, with statistical validation through 100-iteration Monte Carlo experiments confirming significant improvements (p < 0.001) over baseline methods. The proposed pipeline outperforms existing approaches by up to 4.67% while using 89% fewer parameters than VGG16 (15.2M vs. 138M). The attention mechanism provides interpretable visualizations of diagnostically relevant cellular features, demonstrating that modern attention-based architectures can improve leukemic cell classification while maintaining computational efficiency suitable for clinical deployment.", "AI": {"tldr": "论文提出了一种基于注意力机制的卷积神经网络和数据增强方法，用于急性淋巴细胞白血病细胞分类。", "motivation": "儿童中最常见的癌症是急性淋巴细胞白血病（ALL），其诊断依赖于显微镜下专家的手动识别，存在观察者间变异性和时间限制。因此需要一种自动化的、稳健且可重复的系统来提高诊断效率和准确性。", "method": "论文采用EfficientNetV2-B3结合挤压与激励机制构建注意力卷积神经网络，并使用全面的数据增强技术和焦点损失处理类别不平衡问题，确保实验结果可靠且具有再现性。", "result": "在C-NMC 2019数据集上，该系统达到了97.89%的F1得分和准确率。通过100次蒙特卡洛迭代试验验证了相对于基线方法有显著改进（p<0.001）。与VGG16相比，所提出的方法性能更好且参数量减少了89%。", "conclusion": "该论文证明了现代基于注意力机制的架构可以提高白血病细胞分类准确性，并保持适合临床部署的计算效率。"}}
{"id": "2601.01024", "pdf": "https://arxiv.org/pdf/2601.01024", "abs": "https://arxiv.org/abs/2601.01024", "authors": ["Tien-Huy Nguyen", "Huu-Loc Tran", "Thanh Duc Ngo"], "title": "ITSELF: Attention Guided Fine-Grained Alignment for Vision-Language Retrieval", "categories": ["cs.CV", "cs.AI", "cs.IR"], "comment": "Accepted at WACV Main Track 2026", "summary": "Vision Language Models (VLMs) have rapidly advanced and show strong promise for text-based person search (TBPS), a task that requires capturing fine-grained relationships between images and text to distinguish individuals. Previous methods address these challenges through local alignment, yet they are often prone to shortcut learning and spurious correlations, yielding misalignment. Moreover, injecting prior knowledge can distort intra-modality structure. Motivated by our finding that encoder attention surfaces spatially precise evidence from the earliest training epochs, and to alleviate these issues, we introduceITSELF, an attention-guided framework for implicit local alignment. At its core, Guided Representation with Attentive Bank (GRAB) converts the model's own attention into an Attentive Bank of high-saliency tokens and applies local objectives on this bank, learning fine-grained correspondences without extra supervision. To make the selection reliable and non-redundant, we introduce Multi-Layer Attention for Robust Selection (MARS), which aggregates attention across layers and performs diversity-aware top-k selection; and Adaptive Token Scheduler (ATS), which schedules the retention budget from coarse to fine over training, preserving context early while progressively focusing on discriminative details. Extensive experiments on three widely used TBPS benchmarks showstate-of-the-art performance and strong cross-dataset generalization, confirming the effectiveness and robustness of our approach without additional prior supervision. Our project is publicly available at https://trhuuloc.github.io/itself", "AI": {"tldr": "本文提出了一种基于注意力引导的局部对齐框架ITSELF，用于改善视觉语言检索任务中的细粒度关系对齐。", "motivation": "为了克服现有方法中容易出现的捷径学习和虚假相关性问题，并避免注入先验知识时对模态内部结构的影响，研究人员发现编码器注意机制能够从最早训练阶段提供空间精确的信息。基于此，他们提出了ITSELF框架来解决这些问题。", "method": "ITSELF通过指导表示与注意力池（GRAB）将模型自身的注意力转换为高显着性令牌的注意力池，并在该池上应用局部目标，学习细粒度对应关系而不需额外监督。引入了多层注意力稳健选择（MARS）和自适应令牌调度器（ATS），以确保选择可靠且不冗余。", "result": "在三个广泛使用的文本基础人员搜索基准测试中展示了最先进的性能以及强大的跨数据集泛化能力，证明该方法的有效性和鲁棒性，无需额外的先验监督。", "conclusion": "ITSELF框架通过注意力引导实现了对视觉语言检索任务中的细粒度关系的精确对齐，提高了模型在文本基础人员搜索等任务上的表现。"}}
{"id": "2601.01022", "pdf": "https://arxiv.org/pdf/2601.01022", "abs": "https://arxiv.org/abs/2601.01022", "authors": ["Shiao Wang", "Xiao Wang", "Haonan Zhao", "Jiarui Xu", "Bo Jiang", "Lin Zhu", "Xin Zhao", "Yonghong Tian", "Jin Tang"], "title": "Decoupling Amplitude and Phase Attention in Frequency Domain for RGB-Event based Visual Object Tracking", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Existing RGB-Event visual object tracking approaches primarily rely on conventional feature-level fusion, failing to fully exploit the unique advantages of event cameras. In particular, the high dynamic range and motion-sensitive nature of event cameras are often overlooked, while low-information regions are processed uniformly, leading to unnecessary computational overhead for the backbone network. To address these issues, we propose a novel tracking framework that performs early fusion in the frequency domain, enabling effective aggregation of high-frequency information from the event modality. Specifically, RGB and event modalities are transformed from the spatial domain to the frequency domain via the Fast Fourier Transform, with their amplitude and phase components decoupled. High-frequency event information is selectively fused into RGB modality through amplitude and phase attention, enhancing feature representation while substantially reducing backbone computation. In addition, a motion-guided spatial sparsification module leverages the motion-sensitive nature of event cameras to capture the relationship between target motion cues and spatial probability distribution, filtering out low-information regions and enhancing target-relevant features. Finally, a sparse set of target-relevant features is fed into the backbone network for learning, and the tracking head predicts the final target position. Extensive experiments on three widely used RGB-Event tracking benchmark datasets, including FE108, FELT, and COESOT, demonstrate the high performance and efficiency of our method. The source code of this paper will be released on https://github.com/Event-AHU/OpenEvTracking", "AI": {"tldr": "提出了一种新的RGB-事件视觉目标跟踪框架，通过频率域的早期融合来有效聚合高频率信息。", "motivation": "现有方法未能充分利用事件相机的独特优势，导致计算开销大且未充分处理动态范围和运动敏感性。", "method": "使用傅里叶变换将RGB和事件模态从空间域转换到频域，并分离振幅和相位组件；通过幅度和相位注意机制选择性地融合高频率信息以增强特征表示并减少计算开销；引入运动引导的空间稀疏化模块来过滤低信息区域。", "result": "实验显示该方法在三个RGB-事件跟踪基准数据集上表现出色且高效。", "conclusion": "提出的方法有效利用了事件相机的优势，提高了目标跟踪的性能和效率"}}
{"id": "2601.01016", "pdf": "https://arxiv.org/pdf/2601.01016", "abs": "https://arxiv.org/abs/2601.01016", "authors": ["Ata Akbari Asanjan", "Milad Memarzadeh", "Bryan Matthews", "Nikunj Oza"], "title": "Improving Variational Autoencoder using Random Fourier Transformation: An Aviation Safety Anomaly Detection Case-Study", "categories": ["cs.LG", "cs.AI", "eess.SY"], "comment": null, "summary": "In this study, we focus on the training process and inference improvements of deep neural networks (DNNs), specifically Autoencoders (AEs) and Variational Autoencoders (VAEs), using Random Fourier Transformation (RFT). We further explore the role of RFT in model training behavior using Frequency Principle (F-Principle) analysis and show that models with RFT turn to learn low frequency and high frequency at the same time, whereas conventional DNNs start from low frequency and gradually learn (if successful) high-frequency features. We focus on reconstruction-based anomaly detection using autoencoder and variational autoencoder and investigate the RFT's role. We also introduced a trainable variant of RFT that uses the existing computation graph to train the expansion of RFT instead of it being random. We showcase our findings with two low-dimensional synthetic datasets for data representation, and an aviation safety dataset, called Dashlink, for high-dimensional reconstruction-based anomaly detection. The results indicate the superiority of models with Fourier transformation compared to the conventional counterpart and remain inconclusive regarding the benefits of using trainable Fourier transformation in contrast to the Random variant.", "AI": {"tldr": "使用随机傅里叶变换改进变分自编码器，并应用于航空安全异常检测。", "motivation": "探索随机傅里叶变换如何改善深层神经网络的训练过程和推断性能，特别是在异常检测中的表现。", "method": "通过频率原理分析，展示模型在低频与高频特征上的学习能力。提出了一种可训练的随机傅里叶变换变体，并应用于两个合成数据集及Dashlink航空安全数据集中进行高维重构异常检测实验。", "result": "结果显示，带有傅里叶变换的模型比传统模型表现更优；然而关于使用可训练傅里叶变换与随机变体之间的优势仍不确定。", "conclusion": "应用随机傅里叶变换能够显著提高变分自编码器在航空安全异常检测中的性能。"}}
{"id": "2601.01014", "pdf": "https://arxiv.org/pdf/2601.01014", "abs": "https://arxiv.org/abs/2601.01014", "authors": ["Haoran Su", "Chenyu You"], "title": "Geometric and Dynamic Scaling in Deep Transformers", "categories": ["cs.LG", "cs.AI"], "comment": "Research Proposal Only", "summary": "Despite their empirical success, pushing Transformer architectures to extreme depth often leads to a paradoxical failure: representations become increasingly redundant, lose rank, and ultimately collapse. Existing explanations largely attribute this phenomenon to optimization instability or vanishing gradients, yet such accounts fail to explain why collapse persists even under modern normalization and initialization schemes. In this paper, we argue that the collapse of deep Transformers is fundamentally a geometric problem. Standard residual updates implicitly assume that feature accumulation is always beneficial, but offer no mechanism to constrain update directions or to erase outdated information. As depth increases, this leads to systematic drift off the semantic manifold and monotonic feature accumulation, causing representational degeneracy. We propose a unified geometric framework that addresses these failures through two orthogonal principles. First, manifold-constrained hyper-connections restrict residual updates to valid local tangent directions, preventing uncontrolled manifold drift. Second, deep delta learning introduces data-dependent, non-monotonic updates that enable reflection and erasure of redundant features rather than their unconditional accumulation. Together, these mechanisms decouple the direction and sign of feature updates, yielding a stable geometric evolution across depth. We term the resulting architecture the Manifold-Geometric Transformer (MGT). Our analysis predicts that enforcing geometric validity while allowing dynamic erasure is essential for avoiding rank collapse in ultra-deep networks. We outline an evaluation protocol for Transformers exceeding 100 layers to test the hypothesis that geometry, rather than depth itself, is the key limiting factor in deep representation learning.", "AI": {"tldr": "提出了一种新的架构Manifold-Geometric Transformer，通过几何和动态原理解决深度Transformer中的表示退化问题。", "motivation": "现有解释无法完全说明为什么在现代归一化和初始化方案下深层Transformer仍然会崩溃。作者认为这是由于传统的残差更新机制没有约束更新方向或删除过时信息的能力。", "method": "通过两个原则提出了一种统一的几何框架：一是限制残差更新到局部切线方向，二是引入非单调数据依赖性更新以反映和擦除冗余特征。", "result": "该方法预测在超深网络中强制执行几何有效性同时允许动态删除是避免秩崩溃的关键。提出了评估超过100层Transformer的协议。", "conclusion": "通过结合方向与符号分离，使深层表示学习稳定化，并且提出了一种新的架构Manifold-Geometric Transformer（MGT），以解决深度Transformer中的表示退化问题。"}}
{"id": "2601.01011", "pdf": "https://arxiv.org/pdf/2601.01011", "abs": "https://arxiv.org/abs/2601.01011", "authors": ["Patricio Vera"], "title": "Intention Collapse: Intention-Level Metrics for Reasoning in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "21 pages, 4 figures, 3 tables. Code: https://github.com/patriciomvera/intention-collapse-experiments", "summary": "Every act of language generation compresses a rich internal state into a single token sequence. We call this process intention collapse: a many-to-one projection from a high dimensional intention space I into an external language space L. We formalize intention collapse for contemporary language models, define three simple, model agnostic intention metrics (intention entropy Hint, effective dimensionality dimeff, and latent knowledge recoverability Recov), and propose an empirical agenda for studying how inference time computation shapes internal intentions before they are verbalized. We also report a first small scale experiment. Using a 4 bit Mistral 7B model on 200 GSM8K problems, we compare a direct answer baseline, a chain of thought (CoT) regime, and a babble control. CoT raises accuracy from 5.5 percent to 53 percent, sharply reduces pre collapse intention entropy (from 1.42 to 0.37 bits), and shows higher global effective dimensionality than the other regimes despite producing fewer tokens than babble. At the same time, Hint has little item level predictive power, and a linear probe on I achieves AUROC 0.65 in the CoT regime but only about chance in the baseline regime, where it collapses to the majority class. These preliminary results indicate that intention level metrics can distinguish inference regimes and expose latent information that is partly lost during collapse, while also revealing important limitations of our current proxies", "AI": {"tldr": "论文提出了用于衡量语言模型推理过程中内部状态的指标，并通过实验验证了这些指标的有效性。", "motivation": "为了更好地理解语言生成过程中的内部状态，作者定义了一种新的概念“意图坍缩”，并通过创建一些无偏倚度量来研究这一现象。", "method": "论文提出了三个衡量意图的模型无关指标：意图熵、有效维度和潜在知识恢复性。通过实验比较了直接答案基线、链式思考（CoT）方案以及乱语控制，以验证这些指标的效果。", "result": "在小规模实验中，使用Mistral7B模型处理GSM8K问题集时发现：CoT方案提高了准确率，减少了意图熵；同时表明了意图级度量可以区分推理模式，并揭示一些潜在信息。但同时也指出了一些现有代理的局限性。", "conclusion": "初步结果显示，意图级别的指标能够区分不同的推理方式并暴露在坍缩过程中丢失的部分潜在信息，但也突显出当前代理方法的一些重要限制。"}}
{"id": "2601.01009", "pdf": "https://arxiv.org/pdf/2601.01009", "abs": "https://arxiv.org/abs/2601.01009", "authors": ["Mojtaba Aliasghar-Mamaghani", "Mohammadreza Khalafi"], "title": "Data-Driven Assessment of Concrete Mixture Compositions on Chloride Transport via Standalone Machine Learning Algorithms", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": ":I.2.6; I.2.0; J.2", "summary": "This paper employs a data-driven approach to determine the impact of concrete mixture compositions on the temporal evolution of chloride in concrete structures. This is critical for assessing the service life of civil infrastructure subjected to aggressive environments. The adopted methodology relies on several simple and complex standalone machine learning (ML) algorithms, with the primary objective of establishing confidence in the unbiased prediction of the underlying hidden correlations. The simple algorithms include linear regression (LR), k-nearest neighbors (KNN) regression, and kernel ridge regression (KRR). The complex algorithms entail support vector regression (SVR), Gaussian process regression (GPR), and two families of artificial neural networks, including a feedforward network (multilayer perceptron, MLP) and a gated recurrent unit (GRU). The MLP architecture cannot explicitly handle sequential data, a limitation addressed by the GRU. A comprehensive dataset is considered. The performance of ML algorithms is evaluated, with KRR, GPR, and MLP exhibiting high accuracy. Given the diversity of the adopted concrete mixture proportions, the GRU was unable to accurately reproduce the response in the test set. Further analyses elucidate the contributions of mixture compositions to the temporal evolution of chloride. The results obtained from the GPR model unravel latent correlations through clear and explainable trends. The MLP, SVR, and KRR also provide acceptable estimates of the overall trends. The majority of mixture components exhibit an inverse relation with chloride content, while a few components demonstrate a direct correlation. These findings highlight the potential of surrogate approaches for describing the physical processes involved in chloride ingress and the associated correlations, toward the ultimate goal of enhancing the service life of civil infrastructure.", "AI": {"tldr": "该论文采用数据驱动的方法，利用多种机器学习算法评估混凝土混合物成分对氯离子传输的影响。", "motivation": "研究旨在通过评估不同混凝土组合比对氯离子扩散的影响，以提高基础设施的服务寿命。", "method": "使用包括线性回归、KNN回归、核岭回归等简单模型和支持向量回归、高斯过程回归以及多层感知器和门控循环单元在内的复杂机器学习算法进行分析。", "result": "结果表明，核岭回归、高斯过程回归及多层感知器表现出较高的准确性；多数混合成分与氯离子含量呈负相关，少数则呈正相关。", "conclusion": "通过运用不同的机器学习模型揭示了混凝土组合比对氯离子传输的影响及其潜在关联，为提高基础设施服务寿命提供了新的途径。"}}
{"id": "2601.01008", "pdf": "https://arxiv.org/pdf/2601.01008", "abs": "https://arxiv.org/abs/2601.01008", "authors": ["Md Rashadul Islam"], "title": "An Explainable Agentic AI Framework for Uncertainty-Aware and Abstention-Enabled Acute Ischemic Stroke Imaging Decisions", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Preprint. Conceptual and exploratory framework focusing on uncertainty-aware and abstention-enabled decision support for acute ischemic stroke imaging", "summary": "Artificial intelligence models have shown strong potential in acute ischemic stroke imaging, particularly for lesion detection and segmentation using computed tomography and magnetic resonance imaging. However, most existing approaches operate as black box predictors, producing deterministic outputs without explicit uncertainty awareness or structured mechanisms to abstain under ambiguous conditions. This limitation raises serious safety and trust concerns in high risk emergency radiology settings. In this paper, we propose an explainable agentic AI framework for uncertainty aware and abstention enabled decision support in acute ischemic stroke imaging. The framework follows a modular agentic pipeline in which a perception agent performs lesion aware image analysis, an uncertainty estimation agent computes slice level predictive reliability, and a decision agent determines whether to issue a prediction or abstain based on predefined uncertainty thresholds. Unlike prior stroke imaging systems that primarily focus on improving segmentation or classification accuracy, the proposed framework explicitly prioritizes clinical safety, transparency, and clinician aligned decision behavior. Qualitative and case based analyses across representative stroke imaging scenarios demonstrate that uncertainty driven abstention naturally emerges in diagnostically ambiguous regions and low information slices. The framework further integrates visual explanation mechanisms to support both predictive and abstention decisions, addressing a key limitation of existing uncertainty aware medical imaging systems. Rather than introducing a new performance benchmark, this work presents agentic control, uncertainty awareness, and selective abstention as essential design principles for developing safe and trustworthy medical imaging AI systems.", "AI": {"tldr": "本文提出了一种可解释的代理人工智能框架，用于急性缺血性卒中成像中的不确定性感知和拒绝决策支持。", "motivation": "当前的人工智能模型在急性缺血性卒中成像中表现出了强大的潜力，但大多数方法是黑盒预测器，缺乏明确的不确定性意识或结构化的机制来处理模糊条件。这在高风险的急诊放射科环境中引发了严重的安全和信任问题。", "method": "该框架采用模块化代理管道，在其中感知代理执行病变意识图像分析，不确定性估计代理计算片级预测可靠性，并决策代理根据预定义的不确定性阈值决定是否发出预测或拒绝。", "result": "通过在代表性卒中成像场景中的定性和案例分析表明，基于不确定性的拒绝自然地出现在诊断上模糊的区域和信息量低的切片。该框架进一步集成了视觉解释机制以支持预测和拒绝决策，解决了现有不确定性感知医学图像系统的一个关键限制。", "conclusion": "这项工作提出了代理控制、不确定性意识和选择性拒绝作为开发安全可靠的医学成像AI系统的必要设计原则"}}
{"id": "2601.01005", "pdf": "https://arxiv.org/pdf/2601.01005", "abs": "https://arxiv.org/abs/2601.01005", "authors": ["Zihan Li", "Dandan Shan", "Yunxiang Li", "Paul E. Kinahan", "Qingqi Hong"], "title": "Scale-aware Adaptive Supervised Network with Limited Medical Annotations", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Accepted by Pattern Recognition, 8 figures, 11 tables", "summary": "Medical image segmentation faces critical challenges in semi-supervised learning scenarios due to severe annotation scarcity requiring expert radiological knowledge, significant inter-annotator variability across different viewpoints and expertise levels, and inadequate multi-scale feature integration for precise boundary delineation in complex anatomical structures. Existing semi-supervised methods demonstrate substantial performance degradation compared to fully supervised approaches, particularly in small target segmentation and boundary refinement tasks. To address these fundamental challenges, we propose SASNet (Scale-aware Adaptive Supervised Network), a dual-branch architecture that leverages both low-level and high-level feature representations through novel scale-aware adaptive reweight mechanisms. Our approach introduces three key methodological innovations, including the Scale-aware Adaptive Reweight strategy that dynamically weights pixel-wise predictions using temporal confidence accumulation, the View Variance Enhancement mechanism employing 3D Fourier domain transformations to simulate annotation variability, and segmentation-regression consistency learning through signed distance map algorithms for enhanced boundary precision. These innovations collectively address the core limitations of existing semi-supervised approaches by integrating spatial, temporal, and geometric consistency principles within a unified optimization framework. Comprehensive evaluation across LA, Pancreas-CT, and BraTS datasets demonstrates that SASNet achieves superior performance with limited labeled data, surpassing state-of-the-art semi-supervised methods while approaching fully supervised performance levels. The source code for SASNet is available at https://github.com/HUANGLIZI/SASNet.", "AI": {"tldr": "提出一种新的基于尺度感知自适应监督网络（SASNet）的方法，用于解决医学图像分割中的标注稀缺问题。", "motivation": "在半监督学习中，由于注释稀少、不同注释者之间的差异以及多尺度特征融合不足，现有方法的性能显著降低。因此提出一种新的基于尺度感知自适应监督网络（SASNet）的方法来解决这些问题。", "method": "采用双分支架构，通过新型尺度感知自适应重权机制利用低级和高级特征表示。引入了三个关键创新：基于时间置信度累积的动态像素预测权重、使用3D傅立叶域变换模拟注释差异性的视角差异增强机制以及通过符号距离图算法进行分割回归一致性学习。", "result": "在LA、胰腺CT和BraTS数据集上进行了全面评估，结果显示SASNet在有限标记数据下的性能优于现有半监督方法，并接近全监督方法的水平。", "conclusion": "提出的尺度感知自适应监督网络（SASNet）通过统一的优化框架解决了医学图像分割中的注释稀少问题。"}}
{"id": "2601.01003", "pdf": "https://arxiv.org/pdf/2601.01003", "abs": "https://arxiv.org/abs/2601.01003", "authors": ["Amin Abyaneh", "Charlotte Morissette", "Mohamad H. Danesh", "Anas El Houssaini", "David Meger", "Gregory Dudek", "Hsiu-Chin Lin"], "title": "Contractive Diffusion Policies: Robust Action Diffusion via Contractive Score-Based Sampling with Differential Equations", "categories": ["cs.LG", "cs.RO"], "comment": "Under review at ICLR 2026", "summary": "Diffusion policies have emerged as powerful generative models for offline policy learning, whose sampling process can be rigorously characterized by a score function guiding a Stochastic Differential Equation (SDE). However, the same score-based SDE modeling that grants diffusion policies the flexibility to learn diverse behavior also incurs solver and score-matching errors, large data requirements, and inconsistencies in action generation. While less critical in image generation, these inaccuracies compound and lead to failure in continuous control settings. We introduce Contractive Diffusion Policies (CDPs) to induce contractive behavior in the diffusion sampling dynamics. Contraction pulls nearby flows closer to enhance robustness against solver and score-matching errors while reducing unwanted action variance. We develop an in-depth theoretical analysis along with a practical implementation recipe to incorporate CDPs into existing diffusion policy architectures with minimal modification and computational cost. We evaluate CDPs for offline learning by conducting extensive experiments in simulation and real-world settings. Across benchmarks, CDPs often outperform baseline policies, with pronounced benefits under data scarcity.", "AI": {"tldr": "本文提出了合同扩散策略（CDPs）以增强离线策略学习的鲁棒性。", "motivation": "现有的基于分数的SDE建模虽然赋予了扩散政策灵活性，但在连续控制设置中会导致求解器和评分匹配错误、大量数据需求及行为生成不一致等缺点。因此需要一种新方法来克服这些挑战。", "method": "本文引入合同扩散策略（CDPs）以诱导合同性行为于扩散采样动态，并通过深入理论分析以及实用实现方案将CDPs整合到现有的扩散政策架构中，同时保持低计算成本和修改量。", "result": "在模拟和现实世界环境中进行广泛实验后，结果表明CDPs通常优于基线策略，在数据稀缺时具有显著优势。", "conclusion": "合同扩散策略（CDPs）有效增强了离线学习中的鲁棒性和性能表现。"}}
{"id": "2601.01002", "pdf": "https://arxiv.org/pdf/2601.01002", "abs": "https://arxiv.org/abs/2601.01002", "authors": ["Prem Babu Kanaparthi", "Tulasi Venkata Sri Varshini Padamata"], "title": "Lightweight Channel Attention for Efficient CNNs", "categories": ["cs.CV"], "comment": "6 pages, 5 figures", "summary": "Attention mechanisms have become integral to modern convolutional neural networks (CNNs), delivering notable performance improvements with minimal computational overhead. However, the efficiency accuracy trade off of different channel attention designs remains underexplored. This work presents an empirical study comparing Squeeze and Excitation (SE), Efficient Channel Attention (ECA), and a proposed Lite Channel Attention (LCA) module across ResNet 18 and MobileNetV2 architectures on CIFAR 10. LCA employs adaptive one dimensional convolutions with grouped operations to reduce parameter usage while preserving effective attention behavior. Experimental results show that LCA achieves competitive accuracy, reaching 94.68 percent on ResNet 18 and 93.10 percent on MobileNetV2, while matching ECA in parameter efficiency and maintaining favorable inference latency. Comprehensive benchmarks including FLOPs, parameter counts, and GPU latency measurements are provided, offering practical insights for deploying attention enhanced CNNs in resource constrained environments.", "AI": {"tldr": "本文提出了一种轻量级通道注意力模块LCA，旨在提高CNN在资源受限环境中的效率和准确性。", "motivation": "尽管注意机制已成为现代卷积神经网络的重要组成部分，并且能够带来显著的性能提升，但不同通道注意力设计之间的效率与准确性的权衡尚未充分研究。本文探讨了SE、ECA以及LCA模块在ResNet18和MobileNetV2架构上的表现。", "method": "提出的LCA模块通过采用具有分组操作的自适应一维卷积来减少参数使用量，同时保持有效的注意力行为。", "result": "实验结果显示，LCA模型达到了较高的准确率，在ResNet18上达到94.68%，在MobileNetV2上为93.10%。此外，LCA与ECA相比具有相同的参数效率，并且保持了良好的推理延迟。", "conclusion": "本文通过全面基准测试提供了有关部署注意力增强的CNN模型以适应资源受限环境的实际见解。"}}
{"id": "2601.00998", "pdf": "https://arxiv.org/pdf/2601.00998", "abs": "https://arxiv.org/abs/2601.00998", "authors": ["Yue Zhou", "Jue Chen", "Zilun Zhang", "Penghui Huang", "Ran Ding", "Zhentao Zou", "PengFei Gao", "Yuchen Wei", "Ke Li", "Xue Yang", "Xue Jiang", "Hongxin Yang", "Jonathan Li"], "title": "DVGBench: Implicit-to-Explicit Visual Grounding Benchmark in UAV Imagery with Large Vision-Language Models", "categories": ["cs.CV"], "comment": "20 pages, 17 figures", "summary": "Remote sensing (RS) large vision-language models (LVLMs) have shown strong promise across visual grounding (VG) tasks. However, existing RS VG datasets predominantly rely on explicit referring expressions-such as relative position, relative size, and color cues-thereby constraining performance on implicit VG tasks that require scenario-specific domain knowledge. This article introduces DVGBench, a high-quality implicit VG benchmark for drones, covering six major application scenarios: traffic, disaster, security, sport, social activity, and productive activity. Each object provides both explicit and implicit queries. Based on the dataset, we design DroneVG-R1, an LVLM that integrates the novel Implicit-to-Explicit Chain-of-Thought (I2E-CoT) within a reinforcement learning paradigm. This enables the model to take advantage of scene-specific expertise, converting implicit references into explicit ones and thus reducing grounding difficulty. Finally, an evaluation of mainstream models on both explicit and implicit VG tasks reveals substantial limitations in their reasoning capabilities. These findings provide actionable insights for advancing the reasoning capacity of LVLMs for drone-based agents. The code and datasets will be released at https://github.com/zytx121/DVGBench", "AI": {"tldr": "介绍了一种用于无人机影像的视觉定位基准测试DVGBench，以及一个基于大规模视觉语言模型的新方法DroneVG-R1。", "motivation": "当前远程遥感任务中的视觉定位数据集主要依赖于明确表达式，限制了处理需要领域知识的任务能力。为此，提出一种新的隐式到显式的转换机制以提升模型的表现。", "method": "提出了DVGBench基准测试和一个名为DroneVG-R1的新方法，该方法结合了强化学习的隐式至显式的思维链I2E-CoT技术。", "result": "实验评估显示主流模型在处理视觉定位任务时存在推理能力不足的问题。这为改进大规模视觉语言模型提供了可操作的见解。", "conclusion": "通过DVGBench和DroneVG-R1，展示了无人机影像中隐式到显式的视觉定位转换方法，并揭示了现有模型存在的局限性，推动了相关领域的发展。"}}
{"id": "2601.00996", "pdf": "https://arxiv.org/pdf/2601.00996", "abs": "https://arxiv.org/abs/2601.00996", "authors": ["Yongxu Sun", "Michael Saxon", "Ian Yang", "Anna-Maria Gueorguieva", "Aylin Caliskan"], "title": "VEAT Quantifies Implicit Associations in Text-to-Video Generator Sora and Reveals Challenges in Bias Mitigation", "categories": ["cs.CY", "cs.AI"], "comment": "The International Association for Safe & Ethical AI (IASEAI)", "summary": "Text-to-Video (T2V) generators such as Sora raise concerns about whether generated content reflects societal bias. We extend embedding-association tests from words and images to video by introducing the Video Embedding Association Test (VEAT) and Single-Category VEAT (SC-VEAT). We validate these methods by reproducing the direction and magnitude of associations from widely used baselines, including Implicit Association Test (IAT) scenarios and OASIS image categories. We then quantify race (African American vs. European American) and gender (women vs. men) associations with valence (pleasant vs. unpleasant) across 17 occupations and 7 awards. Sora videos associate European Americans and women more with pleasantness (both d>0.8). Effect sizes correlate with real-world demographic distributions: percent men and White in occupations (r=0.93, r=0.83) and percent male and non-Black among award recipients (r=0.88, r=0.99). Applying explicit debiasing prompts generally reduces effect-size magnitudes, but can backfire: two Black-associated occupations (janitor, postal service) become more Black-associated after debiasing. Together, these results reveal that easily accessible T2V generators can actually amplify representational harms if not rigorously evaluated and responsibly deployed.", "AI": {"tldr": "研究通过引入视频嵌入关联测试（VEAT）和单类别VEAT（SC-VEAT），评估文本到视频生成器Sora是否反映了社会偏见。", "motivation": "随着T2V生成器如Sora的出现，人们担心其生成的内容是否会反映社会偏见。通过引入新的测试方法来量化这种关联性，研究希望揭示这些工具在公平性和偏见缓解方面的挑战。", "method": "提出了VEAT和SC-VEAT来评估视频中的隐含关联，并验证了这些新方法的有效性，随后利用它们来测量种族（非裔美国人与白人）和性别（女性与男性）对17种职业和7个奖项的愉悦感之间的关系。", "result": "Sora生成的视频中，白人和女性更常与愉快情绪相关联。此外，应用显式去偏提示虽然可以减少效应大小，但可能导致负面效果，例如某些黑人群体相关的职位在去偏后变得更偏向于黑人群体。", "conclusion": "研究表明，如果不对文本到视频生成器进行严格的评估和负责任的应用，它们可能会放大代表性的伤害。"}}
{"id": "2601.00994", "pdf": "https://arxiv.org/pdf/2601.00994", "abs": "https://arxiv.org/abs/2601.00994", "authors": ["Michael Bao"], "title": "ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems", "categories": ["cs.AI", "cs.CY"], "comment": "In proceedings of 2025 IEEE International Conference on Agentic AI (ICA)", "summary": "This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs, encompassing a wider range than previously reported. The variations in technique usage and overall persuasion output between models highlight how different model architectures and training can impact the dynamics in realistic social simulations. Additionally, we observed unique phenomena such as \"kernel of truth\" messages and spontaneous developments with an \"ink\" obsession, where agents collectively demanded written proof. Our study provides a foundation for evaluating persuasive LLM agents in real-world contexts, ensuring alignment and preventing dangerous outcomes.", "AI": {"tldr": "本文介绍了一个模拟框架ElecTwit，用于研究多代理系统中的说服力，特别是在政治选举期间社交媒体平台上的互动。", "motivation": "现有的游戏化仿真存在局限性，因此作者开发了ElecTwit以克服这些限制，并在更接近现实的环境中评估语言模型（LLM）的说服能力。", "method": "通过模拟框架ElecTwit观察了25种特定说服技巧的应用情况，以及不同模型架构和训练对说服效果的影响。该框架还揭示了一些独特的现象，如“真理内核”消息和关于墨水偏执的现象。", "result": "研究发现多种语言模型广泛使用了包括25个具体策略在内的大量说服技术，并且观察到了一些新颖的现象，表明不同的模型架构会对社会仿真中的说服动态产生影响。", "conclusion": "该框架为评估现实世界中LLM代理的说服力提供了基础，有助于确保这些系统的安全性和道德性。"}}
{"id": "2601.00993", "pdf": "https://arxiv.org/pdf/2601.00993", "abs": "https://arxiv.org/abs/2601.00993", "authors": ["Julian D. Santamaria", "Claudia Isaza", "Jhony H. Giraldo"], "title": "WildIng: A Wildlife Image Invariant Representation Model for Geographical Domain Shift", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Wildlife monitoring is crucial for studying biodiversity loss and climate change. Camera trap images provide a non-intrusive method for analyzing animal populations and identifying ecological patterns over time. However, manual analysis is time-consuming and resource-intensive. Deep learning, particularly foundation models, has been applied to automate wildlife identification, achieving strong performance when tested on data from the same geographical locations as their training sets. Yet, despite their promise, these models struggle to generalize to new geographical areas, leading to significant performance drops. For example, training an advanced vision-language model, such as CLIP with an adapter, on an African dataset achieves an accuracy of 84.77%. However, this performance drops significantly to 16.17% when the model is tested on an American dataset. This limitation partly arises because existing models rely predominantly on image-based representations, making them sensitive to geographical data distribution shifts, such as variation in background, lighting, and environmental conditions. To address this, we introduce WildIng, a Wildlife image Invariant representation model for geographical domain shift. WildIng integrates text descriptions with image features, creating a more robust representation to geographical domain shifts. By leveraging textual descriptions, our approach captures consistent semantic information, such as detailed descriptions of the appearance of the species, improving generalization across different geographical locations. Experiments show that WildIng enhances the accuracy of foundation models such as BioCLIP by 30% under geographical domain shift conditions. We evaluate WildIng on two datasets collected from different regions, namely America and Africa. The code and models are publicly available at https://github.com/Julian075/CATALOG/tree/WildIng.", "AI": {"tldr": "提出了一种名为WildIng的野生动物图像不变表示模型，用于解决地理区域变化下的性能下降问题。", "motivation": "现有的深度学习模型在处理不同地理位置的数据时表现不佳，因为它们主要依赖于基于图像的表征，对背景、光照和环境条件的变化非常敏感。因此，需要一种更鲁棒的方法来提高模型在不同地理位置上的泛化能力。", "method": "WildIng通过结合文本描述与图像特征，创建了一个更具地理区域不变性的表示方法。该方法利用详细的物种外观描述等一致的语义信息，提高了跨地区数据集的表现。", "result": "实验表明，在地理区域变化条件下，WildIng可以将基础模型如BioCLIP的准确性提高30%。", "conclusion": "通过使用文本和图像特征相结合的方法，WildIng显著提升了野生动物识别在不同地理位置上的表现，并为解决地理领域偏移问题提供了有效的新思路。"}}
{"id": "2601.00991", "pdf": "https://arxiv.org/pdf/2601.00991", "abs": "https://arxiv.org/abs/2601.00991", "authors": ["Joshua Kawaguchi", "Saad Manzur", "Emily Gao Wang", "Maitreyi Sinha", "Bryan Vela", "Yunxi Wang", "Brandon Vela", "Wayne B. Hayes"], "title": "UnrealPose: Leveraging Game Engine Kinematics for Large-Scale Synthetic Human Pose Data", "categories": ["cs.CV"], "comment": "CVPR 2026 submission. Introduces UnrealPose-1M dataset and UnrealPose-Gen pipeline", "summary": "Diverse, accurately labeled 3D human pose data is expensive and studio-bound, while in-the-wild datasets lack known ground truth. We introduce UnrealPose-Gen, an Unreal Engine 5 pipeline built on Movie Render Queue for high-quality offline rendering. Our generated frames include: (i) 3D joints in world and camera coordinates, (ii) 2D projections and COCO-style keypoints with occlusion and joint-visibility flags, (iii) person bounding boxes, and (iv) camera intrinsics and extrinsics. We use UnrealPose-Gen to present UnrealPose-1M, an approximately one million frame corpus comprising eight sequences: five scripted \"coherent\" sequences spanning five scenes, approximately 40 actions, and five subjects; and three randomized sequences across three scenes, approximately 100 actions, and five subjects, all captured from diverse camera trajectories for broad viewpoint coverage. As a fidelity check, we report real-to-synthetic results on four tasks: image-to-3D pose, 2D keypoint detection, 2D-to-3D lifting, and person detection/segmentation. Though time and resources constrain us from an unlimited dataset, we release the UnrealPose-1M dataset, as well as the UnrealPose-Gen pipeline to support third-party generation of human pose data.", "AI": {"tldr": "利用游戏引擎生成高质量的合成人类姿态数据集UnrealPose-1M。", "motivation": "真实世界的人体姿态数据收集昂贵且受限，而随机生成的数据缺乏已知的真实标签。通过使用游戏引擎和电影渲染队列，可以高效地生成大量标注良好的三维人体姿态数据。", "method": "提出了一种基于Unreal Engine 5的流水线UnrealPose-Gen，用于离线高质量渲染。该方法生成的数据包括三维关节坐标、二维投影和COCO风格的关键点等信息。", "result": "展示了UnrealPose-1M数据集，包含约一百万帧图像，并进行了真实到合成的任务评估，验证了其在姿态识别等方面的性能。", "conclusion": "发布了UnrealPose-1M数据集及生成流水线，为第三方提供人体姿态数据的生成支持。"}}
{"id": "2601.00990", "pdf": "https://arxiv.org/pdf/2601.00990", "abs": "https://arxiv.org/abs/2601.00990", "authors": ["Olaf Yunus Laitinen Imanov"], "title": "Uncertainty-Calibrated Explainable AI for Fetal Ultrasound Plane Classification", "categories": ["eess.IV", "cs.CV"], "comment": "9 pages, 1 figure, 4 tables", "summary": "Fetal ultrasound standard-plane classification underpins reliable prenatal biometry and anomaly screening, yet real-world deployment is limited by domain shift, image noise, and poor calibration of predicted probabilities. This paper presents a practical framework for uncertainty-calibrated explainable AI in fetal plane classification. We synthesize uncertainty estimation methods (Monte Carlo dropout, deep ensembles, evidential learning, and conformal prediction) with post-hoc and uncertainty-aware explanations (Grad-CAM variants, LIME-style local surrogates, and uncertainty-weighted multi-resolution activation maps), and we map these components to a clinician-facing workflow. Using FETAL_PLANES_DB as a reference benchmark, we define a reporting protocol that couples accuracy with calibration and selective prediction, including expected calibration error, Brier score, coverage-risk curves, and structured error analysis with explanations. We also discuss integration points for quality control and human-in-the-loop review, where uncertainty flags trigger re-acquisition or expert confirmation. The goal is a reproducible, clinically aligned blueprint for building fetal ultrasound classifiers whose confidence and explanations remain trustworthy under noisy acquisition conditions.", "AI": {"tldr": "该论文提出了一种用于胎儿超声标准平面分类的不确定性校准可解释人工智能框架。", "motivation": "为了改善胎儿超声的标准平面分类，解决实际部署中的领域偏移、图像噪声和预测概率不准确的问题。", "method": "合成不确定性估计方法（如蒙特卡洛dropout、深度集成、证据学习和符合性预测）与后验解释方法（如Grad-CAM变体、LIME样式局部替代者以及不确定性加权多分辨率激活图），并将其映射到临床医生的工作流程中。", "result": "利用FETAL_PLANES_DB作为参考基准，定义了结合准确率和校准及选择性预测的报告协议，并讨论了质量控制和人机交互审核中的集成点。", "conclusion": "目标是建立一个可重复、符合临床标准的设计蓝图，以在噪声采集条件下保持胎儿超声分类器的信任度和解释力。"}}
{"id": "2601.00988", "pdf": "https://arxiv.org/pdf/2601.00988", "abs": "https://arxiv.org/abs/2601.00988", "authors": ["Lin Xi", "Yingliang Ma", "Xiahai Zhuang"], "title": "Few-Shot Video Object Segmentation in X-Ray Angiography Using Local Matching and Spatio-Temporal Consistency Loss", "categories": ["cs.CV"], "comment": null, "summary": "We introduce a novel FSVOS model that employs a local matching strategy to restrict the search space to the most relevant neighboring pixels. Rather than relying on inefficient standard im2col-like implementations (e.g., spatial convolutions, depthwise convolutions and feature-shifting mechanisms) or hardware-specific CUDA kernels (e.g., deformable and neighborhood attention), which often suffer from limited portability across non-CUDA devices, we reorganize the local sampling process through a direction-based sampling perspective. Specifically, we implement a non-parametric sampling mechanism that enables dynamically varying sampling regions. This approach provides the flexibility to adapt to diverse spatial structures without the computational costs of parametric layers and the need for model retraining. To further enhance feature coherence across frames, we design a supervised spatio-temporal contrastive learning scheme that enforces consistency in feature representations. In addition, we introduce a publicly available benchmark dataset for multi-object segmentation in X-ray angiography videos (MOSXAV), featuring detailed, manually labeled segmentation ground truth. Extensive experiments on the CADICA, XACV, and MOSXAV datasets show that our proposed FSVOS method outperforms current state-of-the-art video segmentation methods in terms of segmentation accuracy and generalization capability (i.e., seen and unseen categories). This work offers enhanced flexibility and potential for a wide range of clinical applications.", "AI": {"tldr": "本文提出了一种新的FSVOS模型，用于X光血管造影视频中的少样本目标分割任务。", "motivation": "现有的方法在非CUDA设备上移植性差，并且计算成本高。为了提高灵活性和性能，在临床应用中取得更好的效果，作者引入了局部匹配策略和监督下的时空对比学习方案以增强特征一致性。", "method": "通过基于方向的采样视角重新组织局部采样过程，采用非参数化采样机制；设计了一种监督下的时空对比学习方案来加强特征一致性。", "result": "实验结果表明该方法在CADICA、XACV和MOSXAV数据集上表现优于现有的视频分割方法，在分割精度和泛化能力方面都有提升。", "conclusion": "这项工作提供了一个新的公开基准数据集，并且提出的FSVOS方法展示出增强的灵活性与广泛的临床应用潜力。"}}
{"id": "2601.00981", "pdf": "https://arxiv.org/pdf/2601.00981", "abs": "https://arxiv.org/abs/2601.00981", "authors": ["Wenhui Chu", "Khang Tran", "Nikolaos V. Tsekos"], "title": "Simulations of MRI Guided and Powered Ferric Applicators for Tetherless Delivery of Therapeutic Interventions", "categories": ["cs.RO", "cs.CV", "eess.SY"], "comment": "9 pages, 8 figures, published in ICBBB 2022", "summary": "Magnetic Resonance Imaging (MRI) is a well-established modality for pre-operative planning and is also explored for intra-operative guidance of procedures such as intravascular interventions. Among the experimental robot-assisted technologies, the magnetic field gradients of the MRI scanner are used to power and maneuver ferromagnetic applicators for accessing sites in the patient's body via the vascular network. In this work, we propose a computational platform for preoperative planning and modeling of MRI-powered applicators inside blood vessels. This platform was implemented as a two-way data and command pipeline that links the MRI scanner, the computational core, and the operator. The platform first processes multi-slice MR data to extract the vascular bed and then fits a virtual corridor inside the vessel. This corridor serves as a virtual fixture (VF), a forbidden region for the applicators to avoid vessel perforation or collision. The geometric features of the vessel centerline, the VF, and MRI safety compliance (dB/dt, max available gradient) are then used to generate magnetic field gradient waveforms. Different blood flow profiles can be user-selected, and those parameters are used for modeling the applicator's maneuvering. The modeling module further generates cues about whether the selected vascular path can be safely maneuvered. Given future experimental studies that require a real-time operation, the platform was implemented on the Qt framework (C/C++) with software modules performing specific tasks running on dedicated threads: PID controller, generation of VF, generation of MR gradient waveforms.", "AI": {"tldr": "该论文提出了一种用于模拟MRI引导和驱动的铁磁探针在血管内操作的计算平台。", "motivation": "探索使用MRI扫描器的磁场梯度来控制铁磁探针，实现无绳治疗干预。", "method": "通过多片MR数据处理提取血管床，并生成虚拟走廊作为虚拟固定装置；利用血管中心线、虚拟固定装置和MRI安全性合规性（dB/dt，最大可用梯度）特征生成磁场梯度波形。", "result": "该平台能够为未来实验研究提供实时操作支持，具备模拟探针移动的能力。", "conclusion": "提出的方法可以用于术前规划，并通过虚拟固定装置和磁场梯度控制实现血管内铁磁探针的安全操控。"}}
{"id": "2601.00979", "pdf": "https://arxiv.org/pdf/2601.00979", "abs": "https://arxiv.org/abs/2601.00979", "authors": ["Valentin Blomer", "Kai-Uwe Bux"], "title": "The cost of cyclic permutations and remainder sums in the Euclidean algorithm", "categories": ["cs.DS"], "comment": "32 pages, 7 figures", "summary": "We discuss a modification to the Gries-Mills block swapping scheme for in-place rotation with average costs of 1.85 moves per element and worst case performance still at 3 moves per element. Analysis of the average case relies on the asymptotic behavior of the sum of remainders in the Euclidean algorithm.", "AI": {"tldr": "论文修改了Gries-Mills块交换方案，实现了平均情况下每个元素只需1.85次移动的原地旋转算法", "motivation": "为了减少旋转数组时的平均移动次数，同时保持最坏情况下的性能", "method": "分析欧几里得算法中余数求和的渐近行为，并以此改进Gries-Mills块交换方案", "result": "实现了平均成本为1.85次移动每元素的原地旋转算法，且最坏情况下仍保持3次移动每元素的成本", "conclusion": "新的修改提高了旋转数组时的效率"}}
{"id": "2601.00978", "pdf": "https://arxiv.org/pdf/2601.00978", "abs": "https://arxiv.org/abs/2601.00978", "authors": ["Yanyi Chen", "Min Deng"], "title": "From Perception to Symbolic Task Planning: Vision-Language Guided Human-Robot Collaborative Structured Assembly", "categories": ["cs.RO"], "comment": null, "summary": "Human-robot collaboration (HRC) in structured assembly requires reliable state estimation and adaptive task planning under noisy perception and human interventions. To address these challenges, we introduce a design-grounded human-aware planning framework for human-robot collaborative structured assembly. The framework comprises two coupled modules. Module I, Perception-to-Symbolic State (PSS), employs vision-language models (VLMs) based agents to align RGB-D observations with design specifications and domain knowledge, synthesizing verifiable symbolic assembly states. It outputs validated installed and uninstalled component sets for online state tracking. Module II, Human-Aware Planning and Replanning (HPR), performs task-level multi-robot assignment and updates the plan only when the observed state deviates from the expected execution outcome. It applies a minimal-change replanning rule to selectively revise task assignments and preserve plan stability even under human interventions. We validate the framework on a 27-component timber-frame assembly. The PSS module achieves 97% state synthesis accuracy, and the HPR module maintains feasible task progression across diverse HRC scenarios. Results indicate that integrating VLM-based perception with knowledge-driven planning improves robustness of state estimation and task planning under dynamic conditions.", "AI": {"tldr": "本论文提出了一种基于视觉语言模型的人机协作结构化组装框架，该框架包括感知到符号状态模块和人知觉规划与再规划模块。", "motivation": "解决在噪声感知和人类干预下进行可靠的状态估计和适应性任务规划的挑战。", "method": "框架由两个耦合模块组成：一个是感知到符号状态（PSS）模块，利用视觉语言模型将RGB-D观测值与设计规范对齐；另一个是人知觉规划与再规划（HPR）模块，在观察状态偏离预期执行结果时进行任务更新。", "result": "验证框架在27个组件的木构组装中表现出97%的状态合成准确性，且HPR模块能够保持计划稳定性。结果显示将视觉语言感知和基于知识的规划相结合可以提高动态条件下的状态估计和任务规划的稳健性。", "conclusion": "所提方法通过结合VLM感知和知识驱动规划提高了人机协作结构化组装中状态估计和任务规划的鲁棒性，特别是在存在噪声和人类干预的情况下。"}}
{"id": "2601.00969", "pdf": "https://arxiv.org/pdf/2601.00969", "abs": "https://arxiv.org/abs/2601.00969", "authors": ["Ali Salamatian", "Ke", "Ren", "Kieran Pattison", "Cyrus Neary"], "title": "Value Vision-Language-Action Planning & Search", "categories": ["cs.RO", "cs.AI"], "comment": "10 pages, 3 figures", "summary": "Vision-Language-Action (VLA) models have emerged as powerful generalist policies for robotic manipulation, yet they remain fundamentally limited by their reliance on behavior cloning, leading to brittleness under distribution shift. While augmenting pretrained models with test-time search algorithms like Monte Carlo Tree Search (MCTS) can mitigate these failures, existing formulations rely solely on the VLA prior for guidance, lacking a grounded estimate of expected future return. Consequently, when the prior is inaccurate, the planner can only correct action selection via the exploration term, which requires extensive simulation to become effective. To address this limitation, we introduce Value Vision-Language-Action Planning and Search (V-VLAPS), a framework that augments MCTS with a lightweight, learnable value function. By training a simple multilayer perceptron (MLP) on the latent representations of a fixed VLA backbone (Octo), we provide the search with an explicit success signal that biases action selection toward high-value regions. We evaluate V-VLAPS on the LIBERO robotic manipulation suite, demonstrating that our value-guided search improves success rates by over 5 percentage points while reducing the average number of MCTS simulations by 5-15 percent compared to baselines that rely only on the VLA prior.", "AI": {"tldr": "本文提出了一种新的框架V-VLAPS，通过在Monte Carlo树搜索中引入一个轻量级的价值函数来改进视觉语言动作规划。", "motivation": "现有的视觉语言动作模型依赖于行为克隆方法，在分布变化时表现不稳定。通过测试时间的搜索算法可以缓解这些问题，但现有方法仅依靠VLA先验进行引导，缺乏对未来预期回报的直接估计。", "method": "本文提出了一种新的框架Value Vision-Language-Action Planning and Search (V-VLAPS)，该框架在Monte Carlo Tree Search中引入了一个轻量级的价值函数。通过训练一个简单的多层感知器（MLP）来提供搜索过程中的成功信号，引导动作选择。", "result": "实验结果表明，在LIBERO机器人操作套件上，与仅依靠VLA先验的基线方法相比，我们的价值导向搜索提高了超过5个百分点的成功率，并减少了5-15%的平均MCTS模拟次数。", "conclusion": "通过引入轻量级的价值函数来改进视觉语言动作规划和搜索框架，可以有效提高机器人在操作任务中的成功率并减少计算资源消耗。"}}
{"id": "2601.00965", "pdf": "https://arxiv.org/pdf/2601.00965", "abs": "https://arxiv.org/abs/2601.00965", "authors": ["Tianshuo Yang", "Ryan Rabinowitz", "Terrance E. Boult", "Jugal Kalita"], "title": "Adapting Feature Attenuation to NLP", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transformer classifiers such as BERT deliver impressive closed-set accuracy, yet they remain brittle when confronted with inputs from unseen categories--a common scenario for deployed NLP systems. We investigate Open-Set Recognition (OSR) for text by porting the feature attenuation hypothesis from computer vision to transformers and by benchmarking it against state-of-the-art baselines. Concretely, we adapt the COSTARR framework--originally designed for classification in computer vision--to two modest language models (BERT (base) and GPT-2) trained to label 176 arXiv subject areas. Alongside COSTARR, we evaluate Maximum Softmax Probability (MSP), MaxLogit, and the temperature-scaled free-energy score under the OOSA and AUOSCR metrics. Our results show (i) COSTARR extends to NLP without retraining but yields no statistically significant gain over MaxLogit or MSP, and (ii) free-energy lags behind all other scores in this high-class-count setting. The study highlights both the promise and the current limitations of transplanting vision-centric OSR ideas to language models, and points toward the need for larger backbones and task-tailored attenuation strategies.", "AI": {"tldr": "将计算机视觉中的特征抑制方法移植到NLP领域，以增强模型对未见过类别的识别能力。", "motivation": "现有的Transformer分类器在面对未曾见到的输入时表现脆弱，研究目的是提高其开放集识别性能。", "method": "采用COSTARR框架以及Maximum Softmax Probability(MSP)、MaxLogit和温度缩放自由能评分方法，并使用OOSA和AUOSCR指标进行评估。", "result": "实验结果表明，虽然COSTARR可以应用于NLP而无需重新训练，但未显示出显著优于MSP或MaxLogit的性能；同时，在高类数设置下，自由能得分表现落后于其他方法。", "conclusion": "研究展示了将视觉领域的开放集识别思想移植到语言模型中的潜力和局限性，并指出需要更大的骨干网络和支持任务定制化的抑制策略。"}}
{"id": "2601.00964", "pdf": "https://arxiv.org/pdf/2601.00964", "abs": "https://arxiv.org/abs/2601.00964", "authors": ["Md. Maksudul Haque", "Rahnuma Akter", "A S M Ahsanul Sarkar Akib", "Abdul Hasib"], "title": "A Deep Learning Approach for Automated Skin Lesion Diagnosis with Explainable AI", "categories": ["cs.CV"], "comment": null, "summary": "Skin cancer is also one of the most common and dangerous types of cancer in the world that requires timely and precise diagnosis. In this paper, a deep-learning architecture of the multi-class skin lesion classification on the HAM10000 dataset will be described. The system suggested combines high-quality data balancing methods, large-scale data augmentation, hybridized EfficientNetV2-L framework with channel attention, and a three-stage progressive learning approach. Moreover, we also use explainable AI (XAI) techniques such as Grad-CAM and saliency maps to come up with intelligible visual representations of model predictions. Our strategy is with a total accuracy of 91.15 per cent, macro F1 of 85.45\\% and micro-average AUC of 99.33\\%. The model has shown high performance in all the seven lesion classes with specific high performance of melanoma and melanocytic nevi. In addition to enhancing diagnostic transparency, XAI also helps to find out the visual characteristics that cause the classifications, which enhances clinical trustworthiness.", "AI": {"tldr": "提出了一种结合高效网络和解释性AI技术的皮肤病变自动诊断方法", "motivation": "为了提高皮肤癌早期诊断的准确性和透明度，采用深度学习与可解释的人工智能技术来改善皮肤病变分类", "method": "使用了平衡数据集、大规模数据增强、EfficientNetV2-L框架结合通道注意力机制以及三阶段渐进式学习法，并利用Grad-CAM和显著图等XAI方法提高模型的可解释性", "result": "该系统在HAM10000数据集中实现了91.15%的整体准确率，85.45%的宏F1值及99.33%的微平均AUC，在所有病变类别中表现优异，特别是在恶性黑色素瘤和良性黑色素细胞痣上", "conclusion": "所提出的方法不仅提高了诊断准确性，还增强了模型预测结果的透明度与临床可信度"}}
{"id": "2601.00963", "pdf": "https://arxiv.org/pdf/2601.00963", "abs": "https://arxiv.org/abs/2601.00963", "authors": ["Bishwajit Saha", "Dmitry Krotov", "Mohammed J. Zaki", "Parikshit Ram"], "title": "Deep Clustering with Associative Memories", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Deep clustering - joint representation learning and latent space clustering - is a well studied problem especially in computer vision and text processing under the deep learning framework. While the representation learning is generally differentiable, clustering is an inherently discrete optimization task, requiring various approximations and regularizations to fit in a standard differentiable pipeline. This leads to a somewhat disjointed representation learning and clustering. In this work, we propose a novel loss function utilizing energy-based dynamics via Associative Memories to formulate a new deep clustering method, DCAM, which ties together the representation learning and clustering aspects more intricately in a single objective. Our experiments showcase the advantage of DCAM, producing improved clustering quality for various architecture choices (convolutional, residual or fully-connected) and data modalities (images or text).", "AI": {"tldr": "提出了一种新的深度聚类方法DCAM，利用能量基础动力学和关联记忆来统一表示学习和聚类。", "motivation": "现有深度聚类方法中的表示学习与离散优化任务的聚类之间存在脱节问题。作者希望通过一种新损失函数解决这个问题，并使两者更紧密地联系在一起。", "method": "使用能量基础动力学通过关联记忆提出了一种新的损失函数，形成DCAM方法，该方法能够同时进行表示学习和聚类。", "result": "实验证明了DCAM在不同架构选择（卷积、残差或全连接）和数据模式（图像或文本）下具有更好的聚类质量。", "conclusion": "提出的方法能更好地融合深度学习中的表示学习与聚类，表现出优于传统方法的性能。"}}
{"id": "2601.00943", "pdf": "https://arxiv.org/pdf/2601.00943", "abs": "https://arxiv.org/abs/2601.00943", "authors": ["Megha Mariam K. M", "Aditya Arun", "Zakaria Laskar", "C. V. Jawahar"], "title": "PhyEduVideo: A Benchmark for Evaluating Text-to-Video Models for Physics Education", "categories": ["cs.CV"], "comment": "Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026", "summary": "Generative AI models, particularly Text-to-Video (T2V) systems, offer a promising avenue for transforming science education by automating the creation of engaging and intuitive visual explanations. In this work, we take a first step toward evaluating their potential in physics education by introducing a dedicated benchmark for explanatory video generation. The benchmark is designed to assess how well T2V models can convey core physics concepts through visual illustrations. Each physics concept in our benchmark is decomposed into granular teaching points, with each point accompanied by a carefully crafted prompt intended for visual explanation of the teaching point. T2V models are evaluated on their ability to generate accurate videos in response to these prompts. Our aim is to systematically explore the feasibility of using T2V models to generate high-quality, curriculum-aligned educational content-paving the way toward scalable, accessible, and personalized learning experiences powered by AI. Our evaluation reveals that current models produce visually coherent videos with smooth motion and minimal flickering, yet their conceptual accuracy is less reliable. Performance in areas such as mechanics, fluids, and optics is encouraging, but models struggle with electromagnetism and thermodynamics, where abstract interactions are harder to depict. These findings underscore the gap between visual quality and conceptual correctness in educational video generation. We hope this benchmark helps the community close that gap and move toward T2V systems that can deliver accurate, curriculum-aligned physics content at scale. The benchmark and accompanying codebase are publicly available at https://github.com/meghamariamkm/PhyEduVideo.", "AI": {"tldr": "本文提出了一种针对物理教育的视频生成基准PhyEduVideo，用于评估文本到视频模型在传达核心物理概念方面的表现。", "motivation": "为了探索使用文本到视频（T2V）模型自动生成高质量、课程对齐的教学内容的可能性，并为科学教育提供一种新的方式。", "method": "将物理概念分解成细化的教学点，每个教学点都附有精心设计的提示以用于视觉解释。评估T2V模型生成准确响应这些提示的视频的能力。", "result": "当前模型能生成视觉上连贯且流畅无闪烁的视频，但在概念准确性方面表现不稳定。在力学、流体和光学领域表现出色，但电磁学和热力学则困难重重。", "conclusion": "研究指出视觉质量和概念正确性之间的差距，并希望该基准能够帮助社区解决这个问题，推动T2V系统生成准确且课程对齐的物理教育内容的发展。"}}
{"id": "2601.00941", "pdf": "https://arxiv.org/pdf/2601.00941", "abs": "https://arxiv.org/abs/2601.00941", "authors": ["Xujun Che", "Xiuxia Du", "Depeng Xu"], "title": "Comparative Analysis of Formula and Structure Prediction from Tandem Mass Spectra", "categories": ["q-bio.QM", "cs.AI", "cs.CE"], "comment": null, "summary": "Liquid chromatography mass spectrometry (LC-MS)-based metabolomics and exposomics aim to measure detectable small molecules in biological samples. The results facilitate hypothesis-generating discovery of metabolic changes and disease mechanisms and provide information about environmental exposures and their effects on human health. Metabolomics and exposomics are made possible by the high resolving power of LC and high mass measurement accuracy of MS. However, a majority of the signals from such studies still cannot be identified or annotated using conventional library searching because existing spectral libraries are far from covering the vast chemical space captured by LC-MS/MS. To address this challenge and unleash the full potential of metabolomics and exposomics, a number of computational approaches have been developed to predict compounds based on tandem mass spectra. Published assessment of these approaches used different datasets and evaluation. To select prediction workflows for practical applications and identify areas for further improvements, we have carried out a systematic evaluation of the state-of-the-art prediction algorithms. Specifically, the accuracy of formula prediction and structure prediction was evaluated for different types of adducts. The resulting findings have established realistic performance baselines, identified critical bottlenecks, and provided guidance to further improve compound predictions based on MS.", "AI": {"tldr": "论文主要任务是对基于串联质谱的化合物预测算法进行系统评估，包括分子式和结构预测。", "motivation": "现有光谱库无法覆盖LC-MS/MS捕获的巨大化学空间，因此需要开发计算方法来通过串联质谱预测化合物。为了选择实用的应用流程并改进这些预测，作者进行了系统的评估。", "method": "使用不同的数据集和评价标准，系统地评估了现有的化合物预测算法，特别是在不同加合物类型下的分子式和结构预测准确性。", "result": "结果建立了实际性能基准线，识别了关键瓶颈，并为改善基于MS的化合物预测提供了指导。", "conclusion": "通过系统的评估，论文确立了当前方法的真实性能水平，指出了需要改进的关键领域，有助于进一步提升基于串联质谱的化合物预测能力。"}}
{"id": "2601.00940", "pdf": "https://arxiv.org/pdf/2601.00940", "abs": "https://arxiv.org/abs/2601.00940", "authors": ["Jonas Li", "Michelle Li", "Luke Liu", "Heng Fan"], "title": "Learning to Segment Liquids in Real-world Images", "categories": ["cs.CV"], "comment": "9 pages, 7 figures", "summary": "Different types of liquids such as water, wine and medicine appear in all aspects of daily life. However, limited attention has been given to the task, hindering the ability of robots to avoid or interact with liquids safely. The segmentation of liquids is difficult because liquids come in diverse appearances and shapes; moreover, they can be both transparent or reflective, taking on arbitrary objects and scenes from the background or surroundings. To take on this challenge, we construct a large-scale dataset of liquids named LQDS consisting of 5000 real-world images annotated into 14 distinct classes, and design a novel liquid detection model named LQDM, which leverages cross-attention between a dedicated boundary branch and the main segmentation branch to enhance segmentation predictions. Extensive experiments demonstrate the effectiveness of LQDM on the test set of LQDS, outperforming state-of-the-art methods and establishing a strong baseline for the semantic segmentation of liquids.", "AI": {"tldr": "研究开发了一种用于分割真实世界图像中液体的新模型LQDM，该模型利用跨注意力机制改进分割效果。", "motivation": "现有技术在处理液体的分割任务上关注较少，导致机器人无法安全地避免或与液体互动。为了解决这一问题，本论文提出了新的数据集和方法。", "method": "构建了一个包含5000张真实世界图像的数据集LQDS，并设计了新模型LQDM，该模型通过边界分支和主分割分支之间的跨注意力机制来增强分割预测。", "result": "实验结果表明，LQDM在LQDS测试集中优于现有方法，建立了液体语义分割的新基准。", "conclusion": "提出的模型LQDM成功地提高了对各种复杂液体图像的分割精度，为机器人安全互动提供了技术支持。"}}
{"id": "2601.00939", "pdf": "https://arxiv.org/pdf/2601.00939", "abs": "https://arxiv.org/abs/2601.00939", "authors": ["Feng Luo", "Hongbo Pan", "Xiang Yang", "Baoyu Jiang", "Fengqing Liu", "Tao Huang"], "title": "ShadowGS: Shadow-Aware 3D Gaussian Splatting for Satellite Imagery", "categories": ["cs.CV"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) has emerged as a novel paradigm for 3D reconstruction from satellite imagery. However, in multi-temporal satellite images, prevalent shadows exhibit significant inconsistencies due to varying illumination conditions. To address this, we propose ShadowGS, a novel framework based on 3DGS. It leverages a physics-based rendering equation from remote sensing, combined with an efficient ray marching technique, to precisely model geometrically consistent shadows while maintaining efficient rendering. Additionally, it effectively disentangles different illumination components and apparent attributes in the scene. Furthermore, we introduce a shadow consistency constraint that significantly enhances the geometric accuracy of 3D reconstruction. We also incorporate a novel shadow map prior to improve performance with sparse-view inputs. Extensive experiments demonstrate that ShadowGS outperforms current state-of-the-art methods in shadow decoupling accuracy, 3D reconstruction precision, and novel view synthesis quality, with only a few minutes of training. ShadowGS exhibits robust performance across various settings, including RGB, pansharpened, and sparse-view satellite inputs.", "AI": {"tldr": "本文提出了一种新的框架ShadowGS，用于卫星图像的三维重建，并解决了阴影带来的几何不一致问题。", "motivation": "在多时间序列卫星影像中，由于光照条件的变化，阴影表现出显著的一致性差异。为了提高3D重建的质量和精度，解决这一挑战是必要的。", "method": "ShadowGS利用物理基础渲染方程结合高效的光线投射技术来精确建模几何一致的阴影，并保持高效渲染。同时引入了阴影一致性约束以增强三维重构的准确性，并采用新的阴影图优先级以提高稀疏视点输入下的表现。", "result": "实验表明，相较于当前最先进的方法，ShadowGS在阴影解耦精度、三维重建精准度以及新视角合成质量上均有显著提升，仅需几分钟训练时间。", "conclusion": "通过精确建模几何一致的阴影并有效处理不同光照成分和视觉属性，ShadowGS展示了其卓越性能，并适用于RGB、增强光谱分辨率及稀疏视图卫星输入等多种场景。"}}
{"id": "2601.00936", "pdf": "https://arxiv.org/pdf/2601.00936", "abs": "https://arxiv.org/abs/2601.00936", "authors": ["M P V S Gopinadh", "S Mahaboob Hussain"], "title": "Emoji-Based Jailbreaking of Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": "7 pages, 2 figures", "summary": "Large Language Models (LLMs) are integral to modern AI applications, but their safety alignment mechanisms can be bypassed through adversarial prompt engineering. This study investigates emoji-based jailbreaking, where emoji sequences are embedded in textual prompts to trigger harmful and unethical outputs from LLMs. We evaluated 50 emoji-based prompts on four open-source LLMs: Mistral 7B, Qwen 2 7B, Gemma 2 9B, and Llama 3 8B. Metrics included jailbreak success rate, safety alignment adherence, and latency, with responses categorized as successful, partial and failed. Results revealed model-specific vulnerabilities: Gemma 2 9B and Mistral 7B exhibited 10 % success rates, while Qwen 2 7B achieved full alignment (0% success). A chi-square test (chi^2 = 32.94, p < 0.001) confirmed significant inter-model differences. While prior works focused on emoji attacks targeting safety judges or classifiers, our empirical analysis examines direct prompt-level vulnerabilities in LLMs. The results reveal limitations in safety mechanisms and highlight the necessity for systematic handling of emoji-based representations in prompt-level safety and alignment pipelines.", "AI": {"tldr": "研究通过嵌入文本提示中的表情符号序列来触发大型语言模型产生不道德输出的方法和效果。", "motivation": "探索如何利用表情符号在大型语言模型中进行越狱攻击，从而绕过其安全对齐机制。", "method": "使用50种表情符号作为提示，在四个开源的大型语言模型（Mistral 7B、Qwen 2 7B、Gemma 2 9B和Llama 3 8B）上进行评估，测试成功越狱率、安全对齐遵守程度以及延迟。", "result": "结果显示了不同模型之间的特定漏洞，其中Gemma 2 9B和Mistral 7B的成功率为10%，而Qwen 2 7B完全对齐（0%成功率）。卡方检验结果确认了模型之间存在显著差异。", "conclusion": "研究揭示了大型语言模型在处理表情符号时的安全机制限制，并强调需要系统地解决提示级安全和对齐管道中的表情符号表示问题。"}}
{"id": "2601.00935", "pdf": "https://arxiv.org/pdf/2601.00935", "abs": "https://arxiv.org/abs/2601.00935", "authors": ["Yue Heng Yeo", "Yuchen Hu", "Shreyas Gopal", "Yizhou Peng", "Hexin Liu", "Eng Siong Chng"], "title": "Improving Code-Switching Speech Recognition with TTS Data Augmentation", "categories": ["eess.AS", "cs.AI"], "comment": "This paper was accepted by APSIPA 2025", "summary": "Automatic speech recognition (ASR) for conversational code-switching speech remains challenging due to the scarcity of realistic, high-quality labeled speech data. This paper explores multilingual text-to-speech (TTS) models as an effective data augmentation technique to address this shortage. Specifically, we fine-tune the multilingual CosyVoice2 TTS model on the SEAME dataset to generate synthetic conversational Chinese-English code-switching speech, significantly increasing the quantity and speaker diversity of available training data. Our experiments demonstrate that augmenting real speech with synthetic speech reduces the mixed error rate (MER) from 12.1 percent to 10.1 percent on DevMan and from 17.8 percent to 16.0 percent on DevSGE, indicating consistent performance gains. These results confirm that multilingual TTS is an effective and practical tool for enhancing ASR robustness in low-resource conversational code-switching scenarios.", "AI": {"tldr": "论文提出了使用多语言TTS模型生成合成对话代码切换语音，以增加训练数据的数量和多样性，从而提高ASR性能。", "motivation": "针对会话代码转换语音自动识别的挑战，由于缺少高质量的真实标注语音数据，提出通过多语言文本转语音（TTS）模型的数据增强方法来解决这一问题。", "method": "论文将CosyVoice2 TTS模型微调在SEAME数据集上以生成合成对话中的中文-英语代码切换语音，增加训练数据的量和说话人多样性。", "result": "实验表明，通过真实语音与合成语音相结合的方法可以降低MER误差率：从12.1%降至10.1%，以及从17.8%降至16.0%，表明这种方法有效提升了ASR性能。", "conclusion": "多语言TTS是一种提高低资源会话代码转换场景中自动语音识别鲁棒性的有效且实用的工具。"}}
{"id": "2601.00933", "pdf": "https://arxiv.org/pdf/2601.00933", "abs": "https://arxiv.org/abs/2601.00933", "authors": ["Jinyu Xu", "Abhishek K. Umrawal"], "title": "LOFA: Online Influence Maximization under Full-Bandit Feedback using Lazy Forward Selection", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": "14 pages and 6 figures", "summary": "We study the problem of influence maximization (IM) in an online setting, where the goal is to select a subset of nodes$\\unicode{x2014}$called the seed set$\\unicode{x2014}$at each time step over a fixed time horizon, subject to a cardinality budget constraint, to maximize the expected cumulative influence. We operate under a full-bandit feedback model, where only the influence of the chosen seed set at each time step is observed, with no additional structural information about the network or diffusion process. It is well-established that the influence function is submodular, and existing algorithms exploit this property to achieve low regret. In this work, we leverage this property further and propose the Lazy Online Forward Algorithm (LOFA), which achieves a lower empirical regret. We conduct experiments on a real-world social network to demonstrate that LOFA achieves superior performance compared to existing bandit algorithms in terms of cumulative regret and instantaneous reward.", "AI": {"tldr": "提出了一种在线影响最大化算法LOFA，在全带反馈模型下通过懒惰前向选择机制降低累积遗憾。", "motivation": "在全带反馈环境中，现有算法难以有效利用子模性质以减少遗憾。为此引入了新的方法来改进性能。", "method": "提出了Lazy Online Forward Algorithm (LOFA) 方法，在线选择节点作为种子集来最大化期望累计影响，并通过懒惰前向选择策略进一步减少了累积遗憾。", "result": "实验结果显示，与现有算法相比，LOFA在累积遗憾和即时奖励方面表现更优。", "conclusion": "通过使用新的方法LOFA，可以有效减少在线影响最大化的累积遗憾，在真实世界社交网络上验证了该方法的有效性。"}}
{"id": "2601.00930", "pdf": "https://arxiv.org/pdf/2601.00930", "abs": "https://arxiv.org/abs/2601.00930", "authors": ["Nicolas Bougie", "Gian Maria Marconi", "Tony Yip", "Narimasa Watanabe"], "title": "AlignUSER: Human-Aligned LLM Agents via World Models for Recommender System Evaluation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Evaluating recommender systems remains challenging due to the gap between offline metrics and real user behavior, as well as the scarcity of interaction data. Recent work explores large language model (LLM) agents as synthetic users, yet they typically rely on few-shot prompting, which yields a shallow understanding of the environment and limits their ability to faithfully reproduce user actions. We introduce AlignUSER, a framework that learns world-model-driven agents from human interactions. Given rollout sequences of actions and states, we formalize world modeling as a next state prediction task that helps the agent internalize the environment. To align actions with human personas, we generate counterfactual trajectories around demonstrations and prompt the LLM to compare its decisions with human choices, identify suboptimal actions, and extract lessons. The learned policy is then used to drive agent interactions with the recommender system. We evaluate AlignUSER across multiple datasets and demonstrate closer alignment with genuine humans than prior work, both at the micro and macro levels.", "AI": {"tldr": "AlignUSER是一个通过世界模型学习合成用户的框架，用于评估推荐系统。", "motivation": "现有评价推荐系统的离线指标与真实用户行为存在差距，并且交互数据稀缺。利用大型语言模型作为合成用户的方法通常依靠有限的提示，导致环境理解浅薄和行动再现能力受限。", "method": "AlignUSER通过学习人类互动来训练世界模型驱动的代理。给定动作序列和状态，它将世界建模定义为下一个状态预测任务，并生成反事实轨迹以对比LLM决策与人类选择，纠正次优行为并提取教训。", "result": "在多个数据集上的测试表明，AlignUSER比先前的工作更接近真实用户的行动，在微观和宏观层面都表现出更好的一致性。", "conclusion": "通过改进的合成用户代理，AlignUSER能够提供一个更加贴近现实用户体验的推荐系统评估方法。"}}
{"id": "2601.00928", "pdf": "https://arxiv.org/pdf/2601.00928", "abs": "https://arxiv.org/abs/2601.00928", "authors": ["Luis Yoichi Morales", "Francesco Zanlungo", "David M. Woollard"], "title": "Analyzing the Shopping Journey: Computing Shelf Browsing Visits in a Physical Retail Store", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Motivated by recent challenges in the deployment of robots into customer-facing roles within retail, this work introduces a study of customer activity in physical stores as a step toward autonomous understanding of shopper intent. We introduce an algorithm that computes shoppers' ``shelf visits'' -- capturing their browsing behavior in the store. Shelf visits are extracted from trajectories obtained via machine vision-based 3D tracking and overhead cameras. We perform two independent calibrations of the shelf visit algorithm, using distinct sets of trajectories (consisting of 8138 and 15129 trajectories), collected in different stores and labeled by human reviewers. The calibrated models are then evaluated on trajectories held out of the calibration process both from the same store on which calibration was performed and from the other store. An analysis of the results shows that the algorithm can recognize customers' browsing activity when evaluated in an environment different from the one on which calibration was performed. We then use the model to analyze the customers' ``browsing patterns'' on a large set of trajectories and their relation to actual purchases in the stores. Finally, we discuss how shelf browsing information could be used for retail planning and in the domain of human-robot interaction scenarios.", "AI": {"tldr": "本文介绍了在实体店内通过机器视觉和摄像头跟踪顾客轨迹来计算货架访问次数的算法，以理解购物者的意图。", "motivation": "受到机器人进入零售业客户互动角色挑战的启发，作者希望通过研究实体店内的顾客行为，实现对购物者意向的自主理解和分析。", "method": "该方法使用3D追踪和顶部摄像头获取轨迹，并通过两个独立的人类标签数据集进行校准。算法评估包括在不同商店的不同环境下测试模型准确性。", "result": "实验结果表明，在不同的环境中，算法能够识别顾客的浏览行为，并且可以分析出顾客购买模式与其货架访问次数之间的关系。", "conclusion": "该研究表明通过货架访问信息可以帮助零售商进行规划并在人机交互场景中发挥作用。"}}
{"id": "2601.00927", "pdf": "https://arxiv.org/pdf/2601.00927", "abs": "https://arxiv.org/abs/2601.00927", "authors": ["Jawad Chowdhury", "Rezaur Rashid", "Gabriel Terejanu"], "title": "Measuring Social Media Polarization Using Large Language Models and Heuristic Rules", "categories": ["cs.SI", "cs.AI", "cs.CL"], "comment": "Foundations and Applications of Big Data Analytics (FAB), Niagara Falls, Canada, 2025", "summary": "Understanding affective polarization in online discourse is crucial for evaluating the societal impact of social media interactions. This study presents a novel framework that leverages large language models (LLMs) and domain-informed heuristics to systematically analyze and quantify affective polarization in discussions on divisive topics such as climate change and gun control. Unlike most prior approaches that relied on sentiment analysis or predefined classifiers, our method integrates LLMs to extract stance, affective tone, and agreement patterns from large-scale social media discussions. We then apply a rule-based scoring system capable of quantifying affective polarization even in small conversations consisting of single interactions, based on stance alignment, emotional content, and interaction dynamics. Our analysis reveals distinct polarization patterns that are event dependent: (i) anticipation-driven polarization, where extreme polarization escalates before well-publicized events, and (ii) reactive polarization, where intense affective polarization spikes immediately after sudden, high-impact events. By combining AI-driven content annotation with domain-informed scoring, our framework offers a scalable and interpretable approach to measuring affective polarization. The source code is publicly available at: https://github.com/hasanjawad001/llm-social-media-polarization.", "AI": {"tldr": "利用大型语言模型和启发式规则测量社交媒体上的情感极化", "motivation": "理解在线讨论中的情感极化对评估社交媒体互动的社会影响至关重要。现有的方法大多依赖于情感分析或预定义分类器，本研究提出了一种结合大型语言模型的新框架来系统地分析和量化争议话题的情感极化", "method": "该方法利用大型语言模型提取立场、情感色调和一致模式，并通过基于立场一致性、情绪内容和互动动态的规则评分系统量化小规模对话的情感极化", "result": "揭示了与事件相关的两种情感极化模式：事件前极端极化的先期驱动极化，以及重大突发新闻后的即时强烈反应型极化", "conclusion": "结合AI驱动的内容标注和领域知识启发式评分，该框架提供了一种可扩展且易解释的方法来测量情感极化"}}
{"id": "2601.00926", "pdf": "https://arxiv.org/pdf/2601.00926", "abs": "https://arxiv.org/abs/2601.00926", "authors": ["Satya Swaroop Gudipudi", "Sahil Girhepuje", "Ponnurangam Kumaraguru", "Kristine Ma"], "title": "MACA: A Framework for Distilling Trustworthy LLMs into Efficient Retrievers", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Modern enterprise retrieval systems must handle short, underspecified queries such as ``foreign transaction fee refund'' and ``recent check status''. In these cases, semantic nuance and metadata matter but per-query large language model (LLM) re-ranking and manual labeling are costly. We present Metadata-Aware Cross-Model Alignment (MACA), which distills a calibrated metadata aware LLM re-ranker into a compact student retriever, avoiding online LLM calls. A metadata-aware prompt verifies the teacher's trustworthiness by checking consistency under permutations and robustness to paraphrases, then supplies listwise scores, hard negatives, and calibrated relevance margins. The student trains with MACA's MetaFusion objective, which combines a metadata conditioned ranking loss with a cross model margin loss so it learns to push the correct answer above semantically similar candidates with mismatched topic, sub-topic, or entity. On a proprietary consumer banking FAQ corpus and BankFAQs, the MACA teacher surpasses a MAFA baseline at Accuracy@1 by five points on the proprietary set and three points on BankFAQs. MACA students substantially outperform pretrained encoders; e.g., on the proprietary corpus MiniLM Accuracy@1 improves from 0.23 to 0.48, while keeping inference free of LLM calls and supporting retrieval-augmented generation.", "AI": {"tldr": "本文提出了一种名为MACA的框架，用于将知识丰富的大型语言模型（LLM）的知识蒸馏到高效的检索器中，以提高对短而模糊查询的理解和处理能力。", "motivation": "现代企业检索系统需要能够应对短且不明确的查询。但是，这些系统的性能受到语义细微差别和元数据的影响，并且每次查询都要调用大型语言模型进行再排序以及手动标注成本高昂。", "method": "MACA框架通过使用带有元数据感知提示的问题来验证教师模型的信任度，以确保其在不同排列下的一致性和对同义词的鲁棒性。随后，它为学生检索器提供了列表级评分、硬负样本和校准的相关边界，并结合了条件排名损失和跨模型边缘损失。", "result": "MACA教师模型在自有消费者银行FAQ数据集上超过了MAFA基线5个百分点，在BankFAQs数据集上提高了3个百分点。MACA学生检索器也显著优于预训练的编码器，例如在自有数据集中MiniLM准确率从0.23提高到0.48。", "conclusion": "MACA框架通过蒸馏大型语言模型的知识来提升搜索效率和准确性，并支持无大型语言模型调用的推理及增强型生成任务。"}}
{"id": "2601.00925", "pdf": "https://arxiv.org/pdf/2601.00925", "abs": "https://arxiv.org/abs/2601.00925", "authors": ["I-Hsien Ting", "Yi-Jun Tseng", "Yu-Sheng Lin"], "title": "Application of deep learning techniques in non-contrast computed tomography pulmonary angiogram for pulmonary embolism diagnosis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Pulmonary embolism is a life-threatening disease, early detection and treatment can significantly reduce mortality. In recent years, many studies have been using deep learning in the diagnosis of pulmonary embolism with contrast medium computed tomography pulmonary angiography, but the contrast medium is likely to cause acute kidney injury in patients with pulmonary embolism and chronic kidney disease, and the contrast medium takes time to work, patients with acute pulmonary embolism may miss the golden treatment time. This study aims to use deep learning techniques to automatically classify pulmonary embolism in CT images without contrast medium by using a 3D convolutional neural network model. The deep learning model used in this study had a significant impact on the pulmonary embolism classification of computed tomography images without contrast with 85\\% accuracy and 0.84 AUC, which confirms the feasibility of the model in the diagnosis of pulmonary embolism.", "AI": {"tldr": "使用深度学习技术在无对比剂的CT肺血管造影图像中自动分类肺栓塞。", "motivation": "减少患者因使用对比剂而造成的急性肾损伤风险，缩短诊断时间，提高急性肺栓塞患者的治疗成功率。", "method": "采用3D卷积神经网络模型进行无对比剂CT图像的肺栓塞分类。", "result": "该深度学习模型在无对比剂CT图像中对肺栓塞的分类准确率为85%，AUC值为0.84，验证了其在诊断中的可行性。", "conclusion": "使用3D卷积神经网络模型能够有效提高无对比剂CT图像中肺栓塞的自动分类准确性，具有潜在的应用价值。"}}
{"id": "2601.00924", "pdf": "https://arxiv.org/pdf/2601.00924", "abs": "https://arxiv.org/abs/2601.00924", "authors": ["Rares Folea", "Radu Iacob", "Emil Slusanschi", "Traian Rebedea"], "title": "Complexity-based code embeddings", "categories": ["cs.LG", "cs.AI"], "comment": "ef:Computational Collective Intelligence. ICCCI 2023. Lecture Notes in Computer Science(), vol 14162. Springer, Cham", "summary": "This paper presents a generic method for transforming the source code of various algorithms to numerical embeddings, by dynamically analysing the behaviour of computer programs against different inputs and by tailoring multiple generic complexity functions for the analysed metrics. The used algorithms embeddings are based on r-Complexity . Using the proposed code embeddings, we present an implementation of the XGBoost algorithm that achieves an average F1-score on a multi-label dataset with 11 classes, built using real-world code snippets submitted for programming competitions on the Codeforces platform.", "AI": {"tldr": "该论文提出了一种基于复杂度的代码嵌入方法，用于将不同算法的源代码转换为数值表示。", "motivation": "通过动态分析计算机程序对不同输入的行为，并量身定制多个通用复杂性函数来实现这一目标。这可以应用于多标签分类任务中，利用真实世界编程竞赛中的代码片段。", "method": "使用基于r-Complexity的算法嵌入方法，通过对源码进行动态行为分析和自定义复杂度函数生成数值表示。", "result": "提出的XGBoost实现对包含11个类别的多标签数据集实现了平均F1得分。", "conclusion": "通过这种方法可以有效提取代码特征，并应用于机器学习任务中，提高模型的性能。"}}
{"id": "2601.00923", "pdf": "https://arxiv.org/pdf/2601.00923", "abs": "https://arxiv.org/abs/2601.00923", "authors": ["Josef Ott"], "title": "Context Collapse: In-Context Learning and Model Collapse", "categories": ["cs.AI"], "comment": "Master's thesis", "summary": "This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear transformer under weight tying to preconditioned gradient descent, and then analysing the optimal preconditioner. This preconditioner includes a skew-symmetric component, which induces a rotation of the gradient direction. For model collapse, we use martingale and random walk theory to analyse simplified settings - linear regression and Gaussian fitting - under both replacing and cumulative data regimes. We strengthen existing results by proving almost sure convergence, showing that collapse occurs unless the data grows sufficiently fast or is retained over time. Finally, we introduce the notion of context collapse: a degradation of context during long generations, especially in chain-of-thought reasoning. This concept links the dynamics of ICL with long-term stability challenges in generative models.", "AI": {"tldr": "研究大型语言模型中的上下文学习和模型崩溃现象。", "motivation": "探索大规模语言模型中上下文学习的机制以及防止模型崩溃的方法。", "method": "通过线性变换器进行实验，并使用鞅理论和随机游走理论分析简化设置下数据替换和累积情况下的模型表现。", "result": "证明在关键上下文长度之上，解决方案将发展出斜对称组件；除非数据足够快地增长或被保留下来，否则模型会崩溃。", "conclusion": "引入上下文崩溃的概念，并将其与上下文学习的动态过程和生成模型长期稳定性挑战联系起来。"}}
{"id": "2601.00922", "pdf": "https://arxiv.org/pdf/2601.00922", "abs": "https://arxiv.org/abs/2601.00922", "authors": ["Le-Anh Tran", "Chung Nguyen Tran", "Nhan Cach Dang", "Anh Le Van Quoc", "Jordi Carrabina", "David Castells-Rufas", "Minh Son Nguyen"], "title": "MetaFormer-driven Encoding Network for Robust Medical Semantic Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": "10 pages, 5 figures, MCT4SD 2025", "summary": "Semantic segmentation is crucial for medical image analysis, enabling precise disease diagnosis and treatment planning. However, many advanced models employ complex architectures, limiting their use in resource-constrained clinical settings. This paper proposes MFEnNet, an efficient medical image segmentation framework that incorporates MetaFormer in the encoding phase of the U-Net backbone. MetaFormer, an architectural abstraction of vision transformers, provides a versatile alternative to convolutional neural networks by transforming tokenized image patches into sequences for global context modeling. To mitigate the substantial computational cost associated with self-attention, the proposed framework replaces conventional transformer modules with pooling transformer blocks, thereby achieving effective global feature aggregation at reduced complexity. In addition, Swish activation is used to achieve smoother gradients and faster convergence, while spatial pyramid pooling is incorporated at the bottleneck to improve multi-scale feature extraction. Comprehensive experiments on different medical segmentation benchmarks demonstrate that the proposed MFEnNet approach attains competitive accuracy while significantly lowering computational cost compared to state-of-the-art models. The source code for this work is available at https://github.com/tranleanh/mfennet.", "AI": {"tldr": "提出了一种基于MetaFormer的编码网络MFEnNet，用于医疗图像语义分割。", "motivation": "当前先进模型结构复杂，在资源受限的临床环境中难以应用。为解决这一问题，本文提出一种高效且准确的医疗图像分割框架。", "method": "在U-Net骨干网中使用MetaFormer进行编码阶段处理，并采用池化Transformer模块替代传统变换器模块以减少计算成本，同时引入Swish激活函数和空间金字塔池化技术来改进特征提取。", "result": "实验结果显示，MFEnNet与现有最佳模型相比，在降低计算成本的同时保持了竞争性的准确性。", "conclusion": "该研究提出了一种高效且精确的医疗图像分割框架，能够显著减少计算资源需求并提升临床应用的可行性。"}}
{"id": "2601.00921", "pdf": "https://arxiv.org/pdf/2601.00921", "abs": "https://arxiv.org/abs/2601.00921", "authors": ["Azadeh Alavi", "Hamidreza Khalili", "Stanley H. Chan", "Fatemeh Kouchmeshki", "Ross Vlahos"], "title": "Practical Geometric and Quantum Kernel Methods for Predicting Skeletal Muscle Outcomes in chronic obstructive pulmonary disease", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": "24 pages, 4 figures", "summary": "Skeletal muscle dysfunction is a clinically relevant extra-pulmonary manifestation of chronic obstructive pulmonary disease (COPD) and is closely linked to systemic and airway inflammation. This motivates predictive modelling of muscle outcomes from minimally invasive biomarkers that can be acquired longitudinally. We study a small-sample preclinical dataset comprising 213 animals across two conditions (Sham versus cigarette-smoke exposure), with blood and bronchoalveolar lavage fluid measurements and three continuous targets: tibialis anterior muscle weight (milligram: mg), specific force (millinewton: mN), and a derived muscle quality index (mN per mg). We benchmark tuned classical baselines, geometry-aware symmetric positive definite (SPD) descriptors with Stein divergence, and quantum kernel models designed for low-dimensional tabular data. In the muscle-weight setting, quantum kernel ridge regression using four interpretable inputs (blood C-reactive protein, neutrophil count, bronchoalveolar lavage cellularity, and condition) attains a test root mean squared error of 4.41 mg and coefficient of determination of 0.605, improving over a matched ridge baseline on the same feature set (4.70 mg and 0.553). Geometry-informed Stein-divergence prototype distances yield a smaller but consistent gain in the biomarker-only setting (4.55 mg versus 4.79 mg). Screening-style evaluation, obtained by thresholding the continuous outcome at 0.8 times the training Sham mean, achieves an area under the receiver operating characteristic curve (ROC-AUC) of up to 0.90 for detecting low muscle weight. These results indicate that geometric and quantum kernel lifts can provide measurable benefits in low-data, low-feature biomedical prediction problems, while preserving interpretability and transparent model selection.", "AI": {"tldr": "本文研究了通过最小侵入性生物标志物预测慢性阻塞性肺病（COPD）患者骨骼肌状况的方法，采用了经典基线、几何感知的 SPD 描述符和量子核模型。", "motivation": "骨骼肌肉功能障碍是 COPD 的重要额外肺外表现，并且与全身和气道炎症密切相关。因此，从最小侵入性生物标志物中预测肌肉结果成为临床关注的问题。", "method": "研究使用了经典基线、几何感知的 SPD 描述符（采用 Stein 分歧）以及针对低维表格数据设计的量子核模型。其中，在肌重预测方面，四输入量子核回归获得了最佳效果。", "result": "在肌肉重量设置中，量子核回归算法优于匹配的经典基线方法，并且几何感知的 Stein 分歧原型距离也表现出了一致的性能提升。此外，筛查评估实现了高达0.90的ROC-AUC值。", "conclusion": "结果表明，在低数据和特征集的情况下，几何和量子核模型能够提供可衡量的优势，同时保持解释性和透明的选择方法。"}}
{"id": "2601.00920", "pdf": "https://arxiv.org/pdf/2601.00920", "abs": "https://arxiv.org/abs/2601.00920", "authors": ["Xingsheng Chen", "Regina Zhang", "Bo Gao", "Xingwei He", "Xiaofeng Liu", "Pietro Lio", "Kwok-Yan Lam", "Siu-Ming Yiu"], "title": "MODE: Efficient Time Series Prediction with Mamba Enhanced by Low-Rank Neural ODEs", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 6 tables", "summary": "Time series prediction plays a pivotal role across diverse domains such as finance, healthcare, energy systems, and environmental modeling. However, existing approaches often struggle to balance efficiency, scalability, and accuracy, particularly when handling long-range dependencies and irregularly sampled data. To address these challenges, we propose MODE, a unified framework that integrates Low-Rank Neural Ordinary Differential Equations (Neural ODEs) with an Enhanced Mamba architecture. As illustrated in our framework, the input sequence is first transformed by a Linear Tokenization Layer and then processed through multiple Mamba Encoder blocks, each equipped with an Enhanced Mamba Layer that employs Causal Convolution, SiLU activation, and a Low-Rank Neural ODE enhancement to efficiently capture temporal dynamics. This low-rank formulation reduces computational overhead while maintaining expressive power. Furthermore, a segmented selective scanning mechanism, inspired by pseudo-ODE dynamics, adaptively focuses on salient subsequences to improve scalability and long-range sequence modeling. Extensive experiments on benchmark datasets demonstrate that MODE surpasses existing baselines in both predictive accuracy and computational efficiency. Overall, our contributions include: (1) a unified and efficient architecture for long-term time series modeling, (2) integration of Mamba's selective scanning with low-rank Neural ODEs for enhanced temporal representation, and (3) substantial improvements in efficiency and scalability enabled by low-rank approximation and dynamic selective scanning.", "AI": {"tldr": "该论文提出了一种名为MODE的框架，用于时间序列预测。", "motivation": "现有的方法在处理长依赖性和不规则采样数据时难以同时平衡效率、可扩展性与准确性。为了解决这些问题，作者提出了MODE框架。", "method": "输入序列首先经过线性标记化层，然后通过多个Mamba编码块进行处理，每个块都装备了增强的Mamba层和低秩神经ODE以高效捕获时间动态变化。此外，利用分段选择性扫描机制提高可扩展性和长程序列建模。", "result": "在基准数据集上的大量实验显示MODE在预测准确性和计算效率方面超过现有基线。", "conclusion": "论文贡献包括：一种统一且高效的长期时间序列建模架构；结合Mamba的选择性扫描与低秩神经ODE以增强时间表示；以及通过低秩近似和动态选择性扫描大幅提高效率和可扩展性的改进。"}}
{"id": "2601.00919", "pdf": "https://arxiv.org/pdf/2601.00919", "abs": "https://arxiv.org/abs/2601.00919", "authors": ["Zichuan Fu", "Wentao Song", "Guojing Li", "Yejing Wang", "Xian Wu", "Yimin Deng", "Hanyu Yan", "Yefeng Zheng", "Xiangyu Zhao"], "title": "Attention Needs to Focus: A Unified Perspective on Attention Allocation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "ICLR 2026 conference", "summary": "The Transformer architecture, a cornerstone of modern Large Language Models (LLMs), has achieved extraordinary success in sequence modeling, primarily due to its attention mechanism. However, despite its power, the standard attention mechanism is plagued by well-documented issues: representational collapse and attention sink. Although prior work has proposed approaches for these issues, they are often studied in isolation, obscuring their deeper connection. In this paper, we present a unified perspective, arguing that both can be traced to a common root -- improper attention allocation. We identify two failure modes: 1) Attention Overload, where tokens receive comparable high weights, blurring semantic features that lead to representational collapse; 2) Attention Underload, where no token is semantically relevant, yet attention is still forced to distribute, resulting in spurious focus such as attention sink. Building on this insight, we introduce Lazy Attention, a novel mechanism designed for a more focused attention distribution. To mitigate overload, it employs positional discrimination across both heads and dimensions to sharpen token distinctions. To counteract underload, it incorporates Elastic-Softmax, a modified normalization function that relaxes the standard softmax constraint to suppress attention on irrelevant tokens. Experiments on the FineWeb-Edu corpus, evaluated across nine diverse benchmarks, demonstrate that Lazy Attention successfully mitigates attention sink and achieves competitive performance compared to both standard attention and modern architectures, while reaching up to 59.58% attention sparsity.", "AI": {"tldr": "提出了一种新的注意力分配机制Lazy Attention，以解决Transformer架构中存在的代表崩溃和注意力沉降问题。", "motivation": "现有的标准注意力机制存在代表性坍塌和注意力沉降的问题，这些问题阻碍了模型的进一步优化。先前的工作虽然提出了解决方案但多是孤立研究，未能找到根本原因。作者认为这些问题源于不正确的注意力分配，并引入新的机制以解决该问题。", "method": "作者提出了一种新机制Lazy Attention，通过位置鉴别在头和维度之间进行更聚焦的注意分配，采用弹性Softmax来放松标准Softmax约束并抑制对无关令牌的关注，从而减轻注意力过载与不足。", "result": "实验结果表明，Lazy Attention成功缓解了注意力沉降，并且在九个不同基准上的性能与标准注意力机制和现代架构相当甚至更优，同时达到了高达59.58％的注意稀疏性。", "conclusion": "论文提出了一种新的注意力分配方法Lazy Attention，解决了Transformer模型中常见的代表崩溃和注意力沉降问题。该方法通过改进的规范化函数及位置鉴别来优化注意力分布。"}}
{"id": "2601.00918", "pdf": "https://arxiv.org/pdf/2601.00918", "abs": "https://arxiv.org/abs/2601.00918", "authors": ["Faisal Ahmed"], "title": "Four-Stage Alzheimer's Disease Classification from MRI Using Topological Feature Extraction, Feature Selection, and Ensemble Learning", "categories": ["cs.CV"], "comment": "15 pages, 7 figures", "summary": "Accurate and efficient classification of Alzheimer's disease (AD) severity from brain magnetic resonance imaging (MRI) remains a critical challenge, particularly when limited data and model interpretability are of concern. In this work, we propose TDA-Alz, a novel framework for four-stage Alzheimer's disease severity classification (non-demented, moderate dementia, mild, and very mild) using topological data analysis (TDA) and ensemble learning. Instead of relying on deep convolutional architectures or extensive data augmentation, our approach extracts topological descriptors that capture intrinsic structural patterns of brain MRI, followed by feature selection to retain the most discriminative topological features. These features are then classified using an ensemble learning strategy to achieve robust multiclass discrimination. Experiments conducted on the OASIS-1 MRI dataset demonstrate that the proposed method achieves an accuracy of 98.19% and an AUC of 99.75%, outperforming or matching state-of-the-art deep learning--based methods reported on OASIS and OASIS-derived datasets. Notably, the proposed framework does not require data augmentation, pretrained networks, or large-scale computational resources, making it computationally efficient and fast compared to deep neural network approaches. Furthermore, the use of topological descriptors provides greater interpretability, as the extracted features are directly linked to the underlying structural characteristics of brain MRI rather than opaque latent representations. These results indicate that TDA-Alz offers a powerful, lightweight, and interpretable alternative to deep learning models for MRI-based Alzheimer's disease severity classification, with strong potential for real-world clinical decision-support systems.", "AI": {"tldr": "使用拓扑数据分析和集成学习方法对阿尔茨海默病的四个阶段进行分类。", "motivation": "准确高效地从脑部MRI图像中对阿尔茨海默病严重程度进行分类是一个重要挑战，特别是在数据有限且需要模型可解释性的情况下。提出一种基于拓扑数据分析的新框架，以提高分类准确性并提供更好的可解释性。", "method": "该方法首先使用拓扑数据分析提取出脑部MRI图像中的关键结构特征，然后通过特征选择保留最具区分性的特征，最后利用集成学习策略进行多类别的分类。", "result": "在OASIS-1 MRI 数据集上实现了98.19%的准确率和99.75% 的AUC值。对比现有的深度学习方法，该框架无需数据增强、预训练网络或大规模计算资源，具有更高的效率和可解释性。", "conclusion": "TDA-Alz提供了一种强大的轻量级且具有良好可解释性的替代方案，适用于基于MRI的阿尔茨海默病严重程度分类，并在临床决策支持系统中有很大的潜力。"}}
{"id": "2601.00913", "pdf": "https://arxiv.org/pdf/2601.00913", "abs": "https://arxiv.org/abs/2601.00913", "authors": ["Subhankar Mishra"], "title": "Clean-GS: Semantic Mask-Guided Pruning for 3D Gaussian Splatting", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "3D Gaussian Splatting produces high-quality scene reconstructions but generates hundreds of thousands of spurious Gaussians (floaters) scattered throughout the environment. These artifacts obscure objects of interest and inflate model sizes, hindering deployment in bandwidth-constrained applications. We present Clean-GS, a method for removing background clutter and floaters from 3DGS reconstructions using sparse semantic masks. Our approach combines whitelist-based spatial filtering with color-guided validation and outlier removal to achieve 60-80\\% model compression while preserving object quality. Unlike existing 3DGS pruning methods that rely on global importance metrics, Clean-GS uses semantic information from as few as 3 segmentation masks (1\\% of views) to identify and remove Gaussians not belonging to the target object. Our multi-stage approach consisting of (1) whitelist filtering via projection to masked regions, (2) depth-buffered color validation, and (3) neighbor-based outlier removal isolates monuments and objects from complex outdoor scenes. Experiments on Tanks and Temples show that Clean-GS reduces file sizes from 125MB to 47MB while maintaining rendering quality, making 3DGS models practical for web deployment and AR/VR applications. Our code is available at https://github.com/smlab-niser/clean-gs", "AI": {"tldr": "Clean-GS提出了一种基于语义掩码的剪枝方法，用于移除3D高斯散布中的背景杂点和浮躁粒子。", "motivation": "3D高斯散布技术虽能生成高质量场景重建，但会产生大量不必要的高斯粒子，占用过多存储空间，并影响物体识别。", "method": "通过结合白名单过滤、颜色引导验证及邻近离群值移除等步骤，Clean-GS利用稀疏语义掩码来剪枝不必要的高斯粒子，减少模型大小。", "result": "实验表明，Clean-GS能够将文件大小从125MB压缩至47MB，并保持渲染质量不变。", "conclusion": "通过有效移除背景杂点和浮躁粒子，Clean-GS使得3DGS模型更适合网络部署及AR/VR应用。"}}
{"id": "2601.00912", "pdf": "https://arxiv.org/pdf/2601.00912", "abs": "https://arxiv.org/abs/2601.00912", "authors": ["Amit Prakash Sharma"], "title": "The Discovery Gap: How Product Hunt Startups Vanish in LLM Organic Discovery Queries", "categories": ["cs.IR", "cs.AI"], "comment": "20 pages, 7 figures. Based on M.Tech thesis research, Indian Institute of Technology Patna, 2025", "summary": "When someone asks ChatGPT to recommend a project management tool, which products show up in the response? And more importantly for startup founders: will their newly launched product ever appear? This research set out to answer these questions. I randomly selected 112 startups from the top 500 products featured on the 2025 Product Hunt leaderboard and tested each one across 2,240 queries to two different large language models: ChatGPT (gpt-4o-mini) and Perplexity (sonar with web search). The results were striking. When users asked about products by name, both LLMs recognized them almost perfectly: 99.4% for ChatGPT and 94.3% for Perplexity. But when users asked discovery-style questions like \"What are the best AI tools launched this year?\" the success rates collapsed to 3.32% and 8.29% respectively. That's a gap of 30-to-1 for ChatGPT. Perhaps the most surprising finding was that Generative Engine Optimization (GEO), the practice of optimizing website content for AI visibility, showed no correlation with actual discovery rates. Products with high GEO scores were no more likely to appear in organic queries than products with low scores. What did matter? For Perplexity, traditional SEO signals like referring domains (r = +0.319, p < 0.001) and Product Hunt ranking (r = -0.286, p = 0.002) predicted visibility. After cleaning the Reddit data for false positives, community presence also emerged as significant (r = +0.395, p = 0.002). The practical takeaway is counterintuitive: don't optimize for AI discovery directly. Instead, build the SEO foundation first and LLM visibility will follow.", "AI": {"tldr": "研究探讨了大型语言模型在推荐新产品时的表现，特别是在回答产品发现类问题时的成功率。", "motivation": "探索新推出的初创产品是否能在大型语言模型的有机查询中被发现，并分析影响这些产品的可见性的因素。", "method": "随机选取了来自2025年Product Hunt榜单前五百名的产品中的112个创业公司，对每个产品进行了总计2,240次查询测试，分别针对ChatGPT（gpt-4o-mini）和Perplexity（sonar with web search）两个大型语言模型。", "result": "当用户以名称询问时，LLM们表现良好；但在回答发现类问题时成功率大幅下降。优化网站内容的通用生成引擎优化并未提高实际发现率。对于Perplexity而言，传统SEO信号和社区活跃度是影响可见性的关键因素。", "conclusion": "直接针对AI发现进行优化效果不大，建议先构建强大的SEO基础，LLM的可视性自然会随之提升。"}}
{"id": "2601.00911", "pdf": "https://arxiv.org/pdf/2601.00911", "abs": "https://arxiv.org/abs/2601.00911", "authors": ["Joyjit Roy"], "title": "Device-Native Autonomous Agents for Privacy-Preserving Negotiations", "categories": ["cs.CR", "cs.AI", "cs.ET", "cs.LG"], "comment": "9 pages, 6 figuers, 9 tables, Submitted in conference 2nd International Conference on Artificial Intelligence Systems (AIS 2026)", "summary": "Automated negotiations in insurance and business-to-business (B2B) commerce encounter substantial challenges. Current systems force a trade-off between convenience and privacy by routing sensitive financial data through centralized servers, increasing security risks, and diminishing user trust. This study introduces a device-native autonomous Artificial Intelligence (AI) agent system for privacy-preserving negotiations. The proposed system operates exclusively on user hardware, enabling real-time bargaining while maintaining sensitive constraints locally. It integrates zero-knowledge proofs to ensure privacy and employs distilled world models to support advanced on-device reasoning. The architecture incorporates six technical components within an agentic AI workflow. Agents autonomously plan negotiation strategies, conduct secure multi-party bargaining, and generate cryptographic audit trails without exposing user data to external servers. The system is evaluated in insurance and B2B procurement scenarios across diverse device configurations. Results show an average success rate of 87%, a 2.4x latency improvement over cloud baselines, and strong privacy preservation through zero-knowledge proofs. User studies show 27% higher trust scores when decision trails are available. These findings establish a foundation for trustworthy autonomous agents in privacy-sensitive financial domains.", "AI": {"tldr": "提出了一种基于设备的自主人工智能代理系统，用于隐私保护谈判。", "motivation": "现有系统在方便性和隐私之间存在权衡，通过中央服务器传输敏感财务数据增加了安全风险和用户信任度下降。本文旨在解决这一问题。", "method": "引入了六项技术组件架构，在代理AI工作流程中操作。该系统使用零知识证明保持隐私，并利用精简的世界模型支持高级设备上的推理。", "result": "在保险和B2B采购场景中的测试表明，平均成功率为87%，延迟比云基准提高了2.4倍，通过零知识证明实现了强大的隐私保护。", "conclusion": "该研究为金融敏感领域的可信赖自主代理奠定了基础。"}}
{"id": "2601.00908", "pdf": "https://arxiv.org/pdf/2601.00908", "abs": "https://arxiv.org/abs/2601.00908", "authors": ["Chorok Lee"], "title": "Conformal Prediction Under Distribution Shift: A COVID-19 Natural Experiment", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Conformal prediction guarantees degrade under distribution shift. We study this using COVID-19 as a natural experiment across 8 supply chain tasks. Despite identical severe feature turnover (Jaccard approximately 0), coverage drops vary from 0% to 86.7%, spanning two orders of magnitude. Using SHapley Additive exPlanations (SHAP) analysis, we find catastrophic failures correlate with single-feature dependence (rho = 0.714, p = 0.047). Catastrophic tasks concentrate importance in one feature (4.5x increase), while robust tasks redistribute across many (10-20x). Quarterly retraining restores catastrophic task coverage from 22% to 41% (+19 pp, p = 0.04), but provides no benefit for robust tasks (99.8% coverage). Exploratory analysis of 4 additional tasks with moderate feature stability (Jaccard 0.13-0.86) reveals feature stability, not concentration, determines robustness, suggesting concentration effects apply specifically to severe shifts. We provide a decision framework: monitor SHAP concentration before deployment; retrain quarterly if vulnerable (>40% concentration); skip retraining if robust.", "AI": {"tldr": "研究在分布变化下，预测的置信度如何受到影响。", "motivation": "探究COVID-19疫情下的供应链任务中，因特征显著转变导致的分布偏移对置信度影响的研究动机。", "method": "通过SHAP分析识别出单一依赖特征的任务发生严重故障，并探讨季度性重训练的效果；同时评估具有中等稳定性的其他任务的表现。", "result": "发现极端变化下的任务中，重要特征集中在一个单一因素上导致严重的覆盖下降。而重新训练可以将部分任务的覆盖率从22%提升到41%，但对于稳定任务无明显增益。", "conclusion": "建议在部署前监控SHAP浓度，并对易受影响的任务进行季度性重训练；对于稳定性高的任务则无需频繁调整。"}}
{"id": "2601.00907", "pdf": "https://arxiv.org/pdf/2601.00907", "abs": "https://arxiv.org/abs/2601.00907", "authors": ["Sumaiya Ali", "Areej Alhothali", "Sameera Albasri", "Ohoud Alzamzami", "Ahmed Abduljabbar", "Muhammad Alwazzan"], "title": "Placenta Accreta Spectrum Detection using Multimodal Deep Learning", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Placenta Accreta Spectrum (PAS) is a life-threatening obstetric complication involving abnormal placental invasion into the uterine wall. Early and accurate prenatal diagnosis is essential to reduce maternal and neonatal risks. This study aimed to develop and validate a deep learning framework that enhances PAS detection by integrating multiple imaging modalities. A multimodal deep learning model was designed using an intermediate feature-level fusion architecture combining 3D Magnetic Resonance Imaging (MRI) and 2D Ultrasound (US) scans. Unimodal feature extractors, a 3D DenseNet121-Vision Transformer for MRI and a 2D ResNet50 for US, were selected after systematic comparative analysis. Curated datasets comprising 1,293 MRI and 1,143 US scans were used to train the unimodal models and paired samples of patient-matched MRI-US scans was isolated for multimodal model development and evaluation. On an independent test set, the multimodal fusion model achieved superior performance, with an accuracy of 92.5% and an Area Under the Receiver Operating Characteristic Curve (AUC) of 0.927, outperforming the MRI-only (82.5%, AUC 0.825) and US-only (87.5%, AUC 0.879) models. Integrating MRI and US features provides complementary diagnostic information, demonstrating strong potential to enhance prenatal risk assessment and improve patient outcomes.", "AI": {"tldr": "该论文开发了一种基于多模态深度学习的框架，用于提高前置胎盘谱系疾病的早期诊断准确性。", "motivation": "前置胎盘谱系疾病是一种威胁生命的产科并发症。准确且及时的产前检测对于减少母体和婴儿的风险至关重要。", "method": "论文设计了一种中间特征级融合架构，结合3D磁共振成像（MRI）和2D超声波扫描来开发多模态深度学习模型。通过系统比较分析选择了单模式特征提取器：3D DenseNet121-视觉变换器用于MRI，2D ResNet50用于US。", "result": "在独立测试集上，该多模态融合模型实现了92.5%的准确性以及AUC值为0.927的表现，优于单独使用MRI或US模式的结果。这表明结合了MRI和超声波的数据能够提供互补的信息来提高诊断性能。", "conclusion": "这项研究展示了将MRI与超声波数据相结合用于前置胎盘谱系疾病的早期诊断的潜力，并可能改善患者预后。"}}
{"id": "2601.00905", "pdf": "https://arxiv.org/pdf/2601.00905", "abs": "https://arxiv.org/abs/2601.00905", "authors": ["Eliot Park", "Abhi Kumar", "Pranav Rajpurkar"], "title": "Evaluating Contextual Intelligence in Recyclability: A Comprehensive Study of Image-Based Reasoning Systems", "categories": ["cs.CV", "cs.AI"], "comment": "x", "summary": "While the importance of efficient recycling is widely acknowledged, accurately determining the recyclability of items and their proper disposal remains a complex task for the general public. In this study, we explore the application of cutting-edge vision-language models (GPT-4o, GPT-4o-mini, and Claude 3.5) for predicting the recyclability of commonly disposed items. Utilizing a curated dataset of images, we evaluated the models' ability to match objects to appropriate recycling bins, including assessing whether the items could physically fit into the available bins. Additionally, we investigated the models' performance across several challenging scenarios: (i) adjusting predictions based on location-specific recycling guidelines; (ii) accounting for contamination or structural damage; and (iii) handling objects composed of multiple materials. Our findings highlight the significant advancements in contextual understanding offered by these models compared to previous iterations, while also identifying areas where they still fall short. The continued refinement of context-aware models is crucial for enhancing public recycling practices and advancing environmental sustainability.", "AI": {"tldr": "本文研究了使用先进的视觉语言模型（GPT-4o，GPT-4o-mini和Claude 3.5）来预测物品的可回收性，并将其与适当的回收箱匹配。", "motivation": "准确判断物品的可回收性和正确处理对于公众来说是一个复杂的任务。本文旨在通过应用先进的视觉语言模型来提高这一过程的有效性，从而促进环境保护。", "method": "利用一组精心策划的图像数据集评估了模型预测物品能否放入适当的回收箱的能力，并测试其在不同情况下的表现：调整基于地理位置的回收指南、处理污染或结构损坏以及处理由多种材料组成的物体。", "result": "研究表明这些模型相比前几代有显著的进步，尤其是在上下文理解方面。但同时也发现了一些不足之处。", "conclusion": "继续改进具备上下文感知能力的模型对于提高公众对可回收物处理的认知和推动环境保护至关重要。"}}
{"id": "2601.00900", "pdf": "https://arxiv.org/pdf/2601.00900", "abs": "https://arxiv.org/abs/2601.00900", "authors": ["Yuchao Hou", "Zixuan Zhang", "Jie Wang", "Wenke Huang", "Lianhui Liang", "Di Wu", "Zhiquan Liu", "Youliang Tian", "Jianming Zhu", "Jisheng Dang", "Junhao Dong", "Zhongliang Guo"], "title": "Noise-Aware and Dynamically Adaptive Federated Defense Framework for SAR Image Target Recognition", "categories": ["cs.CR", "cs.CV", "cs.LG"], "comment": "This work was supported in part by the National Key Research and Development Program of China under Grant 2021YFB3101100, in part by the National Natural Science Foundation of China under Grant 62272123, 42371470, and 42461057, in part by the Fundamental Research Program of Shanxi Province under Grant 202303021212164. Corresponding authors: Zhongliang Guo and Junhao Dong", "summary": "As a critical application of computational intelligence in remote sensing, deep learning-based synthetic aperture radar (SAR) image target recognition facilitates intelligent perception but typically relies on centralized training, where multi-source SAR data are uploaded to a single server, raising privacy and security concerns. Federated learning (FL) provides an emerging computational intelligence paradigm for SAR image target recognition, enabling cross-site collaboration while preserving local data privacy. However, FL confronts critical security risks, where malicious clients can exploit SAR's multiplicative speckle noise to conceal backdoor triggers, severely challenging the robustness of the computational intelligence model. To address this challenge, we propose NADAFD, a noise-aware and dynamically adaptive federated defense framework that integrates frequency-domain, spatial-domain, and client-behavior analyses to counter SAR-specific backdoor threats. Specifically, we introduce a frequency-domain collaborative inversion mechanism to expose cross-client spectral inconsistencies indicative of hidden backdoor triggers. We further design a noise-aware adversarial training strategy that embeds $Γ$-distributed speckle characteristics into mask-guided adversarial sample generation to enhance robustness against both backdoor attacks and SAR speckle noise. In addition, we present a dynamic health assessment module that tracks client update behaviors across training rounds and adaptively adjusts aggregation weights to mitigate evolving malicious contributions. Experiments on MSTAR and OpenSARShip datasets demonstrate that NADAFD achieves higher accuracy on clean test samples and a lower backdoor attack success rate on triggered inputs than existing federated backdoor defenses for SAR target recognition.", "AI": {"tldr": "提出了一种针对SAR图像目标识别的噪声感知和动态自适应联邦防御框架NADAFD。", "motivation": "现有的联邦学习方法在处理合成孔径雷达（SAR）图像时，存在隐私安全问题以及恶意客户端利用信号噪声隐藏后门触发器的风险。为了解决这些问题，本文提出了一种新的防御框架。", "method": "该论文通过频率域合作逆变机制、噪声感知对抗训练策略和动态健康评估模块来提高模型的鲁棒性，并且能够有效地检测出潜在的安全威胁。", "result": "实验结果表明，NADAFD在纯净测试样本上的准确度更高，在被触发输入上的后门攻击成功率更低。", "conclusion": "该研究成功地开发了一种新的防御框架来对抗SAR图像目标识别中的后门攻击和噪声问题。"}}
{"id": "2601.00898", "pdf": "https://arxiv.org/pdf/2601.00898", "abs": "https://arxiv.org/abs/2601.00898", "authors": ["Ruiming Liang", "Yinan Zheng", "Kexin Zheng", "Tianyi Tan", "Jianxiong Li", "Liyuan Mao", "Zhihao Wang", "Guang Chen", "Hangjun Ye", "Jingjing Liu", "Jinqiao Wang", "Xianyuan Zhan"], "title": "Dichotomous Diffusion Policy Optimization", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Diffusion-based policies have gained growing popularity in solving a wide range of decision-making tasks due to their superior expressiveness and controllable generation during inference. However, effectively training large diffusion policies using reinforcement learning (RL) remains challenging. Existing methods either suffer from unstable training due to directly maximizing value objectives, or face computational issues due to relying on crude Gaussian likelihood approximation, which requires a large amount of sufficiently small denoising steps. In this work, we propose DIPOLE (Dichotomous diffusion Policy improvement), a novel RL algorithm designed for stable and controllable diffusion policy optimization. We begin by revisiting the KL-regularized objective in RL, which offers a desirable weighted regression objective for diffusion policy extraction, but often struggles to balance greediness and stability. We then formulate a greedified policy regularization scheme, which naturally enables decomposing the optimal policy into a pair of stably learned dichotomous policies: one aims at reward maximization, and the other focuses on reward minimization. Under such a design, optimized actions can be generated by linearly combining the scores of dichotomous policies during inference, thereby enabling flexible control over the level of greediness.Evaluations in offline and offline-to-online RL settings on ExORL and OGBench demonstrate the effectiveness of our approach. We also use DIPOLE to train a large vision-language-action (VLA) model for end-to-end autonomous driving (AD) and evaluate it on the large-scale real-world AD benchmark NAVSIM, highlighting its potential for complex real-world applications.", "AI": {"tldr": "本文提出了DIPOLE算法，旨在稳定且可控地优化基于扩散的策略。该方法通过将最优策略分解为一对稳定的对立策略来实现灵活控制。", "motivation": "现有扩散策略在强化学习中训练不稳定或计算复杂度高，无法有效解决决策任务。", "method": "DIPOLE算法利用KL正则化目标进行加权回归优化，并设计了一对对立策略（奖励最大化和最小化），通过线性组合生成最终动作。", "result": "实验显示了在ExORL、OGBench等环境中的有效性，还应用于大规模视觉-语言-行动模型的自动驾驶训练任务中。", "conclusion": "DIPOLE算法为扩散策略优化提供了一种稳定且灵活的方法，在复杂应用中有潜在价值。"}}
{"id": "2601.00897", "pdf": "https://arxiv.org/pdf/2601.00897", "abs": "https://arxiv.org/abs/2601.00897", "authors": ["Sai Teja Erukude", "Jane Mascarenhas", "Lior Shamir"], "title": "CornViT: A Multi-Stage Convolutional Vision Transformer Framework for Hierarchical Corn Kernel Analysis", "categories": ["cs.CV", "cs.AI"], "comment": "23 pages", "summary": "Accurate grading of corn kernels is critical for seed certification, directional seeding, and breeding, yet it is still predominantly performed by manual inspection. This work introduces CornViT, a three-stage Convolutional Vision Transformer (CvT) framework that emulates the hierarchical reasoning of human seed analysts for single-kernel evaluation. Three sequential CvT-13 classifiers operate on 384x384 RGB images: Stage 1 distinguishes pure from impure kernels; Stage 2 categorizes pure kernels into flat and round morphologies; and Stage 3 determines the embryo orientation (up vs. down) for pure, flat kernels. Starting from a public corn seed image collection, we manually relabeled and filtered images to construct three stage-specific datasets: 7265 kernels for purity, 3859 pure kernels for morphology, and 1960 pure-flat kernels for embryo orientation, all released as benchmarks. Head-only fine-tuning of ImageNet-22k pretrained CvT-13 backbones yields test accuracies of 93.76% for purity, 94.11% for shape, and 91.12% for embryo-orientation detection. Under identical training conditions, ResNet-50 reaches only 76.56 to 81.02 percent, whereas DenseNet-121 attains 86.56 to 89.38 percent accuracy. These results highlight the advantages of convolution-augmented self-attention for kernel analysis. To facilitate adoption, we deploy CornViT in a Flask-based web application that performs stage-wise inference and exposes interpretable outputs through a browser interface. Together, the CornViT framework, curated datasets, and web application provide a deployable solution for automated corn kernel quality assessment in seed quality workflows. Source code and data are publicly available.", "AI": {"tldr": "玉米粒分析框架CornViT，通过三个阶段的卷积视觉变换器（CvT）实现对纯度、形态和胚芽方向的分级。", "motivation": "准确评估玉米籽粒的质量对于种子认证、定向播种和育种至关重要，但目前主要依赖人工检查。引入CornViT框架来模仿人类专家进行单个籽粒分析的能力。", "method": "该研究开发了一套三阶段CvT-13分类器用于处理RGB图像：第一阶段区分纯与不纯的玉米籽粒；第二阶段将纯籽粒分为扁平和圆形形态；第三阶段确定纯、扁平籽粒中的胚芽方向（向上或向下）。数据集包括7265个样本用于评估纯度，3859个样本用于形状分类以及1960个样本用于胚芽朝向判断。采用ImageNet-22k预训练的CvT-13基础模型进行微调。", "result": "实验结果显示，在相同的训练条件下，CornViT对纯度、形态和胚芽方向识别的准确率分别为93.76%、94.11%和91.12%，相比之下ResNet-50和DenseNet-121的精度则较低。", "conclusion": "研究结果表明，CornViT框架具有显著优势，可实现更高质量的玉米籽粒评估。为促进该技术应用，已将其部署在基于Flask的应用程序中，并通过浏览器界面提供阶段化推理和解释性输出。"}}
{"id": "2601.00892", "pdf": "https://arxiv.org/pdf/2601.00892", "abs": "https://arxiv.org/abs/2601.00892", "authors": ["Ana Carpio", "Gema Duro"], "title": "Hierarchical topological clustering", "categories": ["cs.LG", "cs.CV", "physics.data-an", "stat.ME", "stat.ML"], "comment": "not peer reviewed, reviewed version to appear in Soft Computing", "summary": "Topological methods have the potential of exploring data clouds without making assumptions on their the structure. Here we propose a hierarchical topological clustering algorithm that can be implemented with any distance choice. The persistence of outliers and clusters of arbitrary shape is inferred from the resulting hierarchy. We demonstrate the potential of the algorithm on selected datasets in which outliers play relevant roles, consisting of images, medical and economic data. These methods can provide meaningful clusters in situations in which other techniques fail to do so.", "AI": {"tldr": "提出了一种基于拓扑方法的层次聚类算法，用于处理任意形状的数据集。", "motivation": "现有技术在面对非结构化数据时假设不足，因此无法有效识别异常值和复杂形态的簇。该研究旨在提供一种无需特定结构假设即可探索数据云的方法。", "method": "提出了一种能够与任何距离选择兼容的层次拓扑聚类算法，并从生成的层次中推断出离群点和任意形状簇的持久性。", "result": "在图像、医学及经济数据集上展示了该算法的有效性，特别是在其他技术无法处理的情况下仍能提供有意义的聚类结果。", "conclusion": "所提出的层次拓扑聚类方法能够在复杂且非结构化的数据集中有效识别离群点和各种形态的簇。"}}
{"id": "2601.00891", "pdf": "https://arxiv.org/pdf/2601.00891", "abs": "https://arxiv.org/abs/2601.00891", "authors": ["Rodrigo Kataishi"], "title": "Enhancing Retrieval-Augmented Generation with Topic-Enriched Embeddings: A Hybrid Approach Integrating Traditional NLP Techniques", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) systems rely on accurate document retrieval to ground large language models (LLMs) in external knowledge, yet retrieval quality often degrades in corpora where topics overlap and thematic variation is high. This work proposes topic-enriched embeddings that integrate term-based signals and topic structure with contextual sentence embeddings. The approach combines TF-IDF with topic modeling and dimensionality reduction, using Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) to encode latent topical organization, and fuses these representations with a compact contextual encoder (all-MiniLM). By jointly capturing term-level and topic-level semantics, topic-enriched embeddings improve semantic clustering, increase retrieval precision, and reduce computational burden relative to purely contextual baselines. Experiments on a legal-text corpus show consistent gains in clustering coherence and retrieval metrics, suggesting that topic-enriched embeddings can serve as a practical component for more reliable knowledge-intensive RAG pipelines.", "AI": {"tldr": "本文提出了基于主题增强嵌入的混合方法，该方法将传统的NLP技术与上下文编码器结合，以改进检索增强生成系统。", "motivation": "在重叠的主题和高度变化的主题语料库中，检索质量下降，影响了大型语言模型在外部知识上的表现。因此，提出了主题增强嵌入来解决这一问题。", "method": "该方法将TF-IDF与主题建模（LSA、LDA）结合，并通过维度缩减技术生成紧凑的上下文编码器表示，最终融合这些表征以捕捉术语级别和主题级别的语义。", "result": "实验表明，在法律文本数据集上使用主题增强嵌入后，聚类的一致性和检索指标均有所提高，优于纯上下文基线方法。", "conclusion": "本文提出的主题增强嵌入可以作为可靠的知识密集型RAG管道的实用组件。"}}
{"id": "2601.00890", "pdf": "https://arxiv.org/pdf/2601.00890", "abs": "https://arxiv.org/abs/2601.00890", "authors": ["Zheshu Song", "Lu Wang", "Wei Deng", "Zhuo Yang", "Yong Wu", "Bin Xia"], "title": "Index-ASR Technical Report", "categories": ["cs.SD", "eess.AS"], "comment": "Index-ASR technical report", "summary": "Automatic speech recognition (ASR) has witnessed remarkable progress in recent years, largely driven by the emergence of LLM-based ASR paradigm. Despite their strong performance on a variety of open-source benchmarks, existing LLM-based ASR systems still suffer from two critical limitations. First, they are prone to hallucination errors, often generating excessively long and repetitive outputs that are not well grounded in the acoustic input. Second, they provide limited support for flexible and fine-grained contextual customization. To address these challenges, we propose Index-ASR, a large-scale LLM-based ASR system designed to simultaneously enhance robustness and support customizable hotword recognition. The core idea of Index-ASR lies in the integration of LLM and large-scale training data enriched with background noise and contextual information. Experimental results show that our Index-ASR achieves strong performance on both open-source benchmarks and in-house test sets, highlighting its robustness and practicality for real-world ASR applications.", "AI": {"tldr": "本文提出了一种新的大型语言模型（LLM）基于的自动语音识别系统Index-ASR，旨在解决现有LLM ASR系统的幻觉错误和灵活定制支持有限的问题。", "motivation": "现有的LLM ASR系统存在生成过度冗长重复输出且不够依赖于声学输入的问题，并在灵活定制方面支持力度不足。为了解决这些问题，作者提出了Index-ASR。", "method": "Index-ASR通过集成大型语言模型和大量增强背景噪声及上下文信息的训练数据来实现其目标。该系统设计用于同时提高鲁棒性和支持可自定义热词识别。", "result": "实验结果表明，Index-ASR在开源基准测试集和内部测试集中都取得了很好的性能，展示了其鲁棒性和实际应用价值。", "conclusion": "本文提出的Index-ASR是一种有效的解决方案，可以同时增强LLM ASR系统的稳健性并支持灵活的上下文定制。"}}
{"id": "2601.00888", "pdf": "https://arxiv.org/pdf/2601.00888", "abs": "https://arxiv.org/abs/2601.00888", "authors": ["Happy Gery Pangestu", "Andi Prademon Yunus", "Siti Khomsah"], "title": "Comparative Evaluation of CNN Architectures for Neural Style Transfer in Indonesian Batik Motif Generation: A Comprehensive Study", "categories": ["cs.CV"], "comment": "29 pages, 9 figures, submitted in VCIBA", "summary": "Neural Style Transfer (NST) provides a computational framework for the digital preservation and generative exploration of Indonesian batik motifs; however, existing approaches remain largely centered on VGG-based architectures whose strong stylistic expressiveness comes at the cost of high computational and memory demands, that limits practical deployment in resource-limited environments. This study presents a systematic comparative analysis of five widely used CNN backbones, namely VGG16, VGG19, Inception V3, ResNet50, and ResNet101, based on 245 controlled experiments combining quantitative metrics, qualitative assessment, and statistical analysis to examine the trade-off between structural preservation, stylistic behavior, and computational efficiency. The results show that backbone selection does not yield statistically significant differences in structural similarity, as confirmed by ANOVA on SSIM (p= 0.83), indicating comparable levels of structural preservation rather than equivalent stylistic quality. Within this context, ResNet-based architectures achieve approximately 5-6x faster convergence than VGG models while maintaining similar perceptual similarity (LPIPS = 0.53) and requiring over 16x fewer FLOPs (0.63 vs 10.12 GFLOPs). Qualitative analysis reveals consistent stylistic trade-offs, with VGG producing denser painterly textures, ResNet favoring geometric stability and canting stroke preservation with milder stylization, and Inception V3 exhibiting intermediate but noisier behavior. These findings reposition architectural choice in NST from maximizing stylistic intensity toward efficiency-aware and structure-preserving deployment, highlighting ResNet-based backbones as a practical foundation for scalable, industry-oriented batik generation.", "AI": {"tldr": "比较评估了五种CNN架构在印尼蜡染图案生成中的神经样式转换表现，探讨其结构保存、风格行为和计算效率之间的权衡。", "motivation": "现有方法主要基于VGG架构，尽管具有强烈的风格表达能力，但高计算需求限制了实际部署。因此，需要一种更加高效且能保持结构的方案。", "method": "进行了245次控制实验，结合定量和定性分析以及统计分析来评估五种CNN架构（VGG16、VGG19、Inception V3、ResNet50、ResNet101）之间的差异。", "result": "结果表明，在结构相似度方面没有显著差异。ResNet架构比VGG模型收敛速度快约5-6倍，同时保持类似的感知相似性，并减少了大约16倍的计算量（FLOPs）。定性分析揭示了不同的风格权衡：VGG产生密集的绘画纹理，ResNet保留几何稳定性和打蜡笔痕迹，Inception V3表现出中等但较嘈杂的行为。", "conclusion": "本研究将架构选择重新定位为以效率和结构保持为导向而非最大化样式强度，并指出基于ResNet的骨干网络是可扩展、面向工业应用的印尼蜡染图案生成的基础。"}}
{"id": "2601.00887", "pdf": "https://arxiv.org/pdf/2601.00887", "abs": "https://arxiv.org/abs/2601.00887", "authors": ["Hongbo Jin", "Kuanwei Lin", "Wenhao Zhang", "Yichen Jin", "Ge Li"], "title": "VideoCuRL: Video Curriculum Reinforcement Learning with Orthogonal Difficulty Decomposition", "categories": ["cs.CV"], "comment": null, "summary": "Reinforcement Learning (RL) is crucial for empowering VideoLLMs with complex spatiotemporal reasoning. However, current RL paradigms predominantly rely on random data shuffling or naive curriculum strategies based on scalar difficulty metrics. We argue that scalar metrics fail to disentangle two orthogonal challenges in video understanding: Visual Temporal Perception Load and Cognitive Reasoning Depth. To address this, we propose VideoCuRL, a novel framework that decomposes difficulty into these two axes. We employ efficient, training-free proxies, optical flow and keyframe entropy for visual complexity, Calibrated Surprisal for cognitive complexity, to map data onto a 2D curriculum grid. A competence aware Diagonal Wavefront strategy then schedules training from base alignment to complex reasoning. Furthermore, we introduce Dynamic Sparse KL and Structured Revisiting to stabilize training against reward collapse and catastrophic forgetting. Extensive experiments show that VideoCuRL surpasses strong RL baselines on reasoning (+2.5 on VSI-Bench) and perception (+2.9 on VideoMME) tasks. Notably, VideoCuRL eliminates the prohibitive inference overhead of generation-based curricula, offering a scalable solution for robust video post-training.", "AI": {"tldr": "视频CuRL：使用正交难度分解的视频课程强化学习。", "motivation": "现有的强化学习范式主要依赖于随机数据打乱或基于标量难度度量的朴素课程策略，无法解开视觉时序感知负载和认知推理深度这两种正交挑战。因此，作者提出了一种新的框架来解决这个问题。", "method": "视频CuRL将难度分解为视觉复杂性和认知复杂性两个轴，并使用高效的训练免费代理进行映射，如光流和关键帧熵用于视觉复杂性，校准惊奇度用于认知复杂性。采用能力感知对角波浪前策略安排从基础对齐到复杂推理的训练。", "result": "广泛的实验表明，视频CuRL在推理任务上（VSI-Bench+2.5）和感知任务上（VideoMME+2.9）优于强大的RL基线。并且消除了基于生成课程的大规模推断开销，提供了一种可扩展的解决方案。", "conclusion": "视频CuRL通过正交难度分解和能力感知对角波浪前策略，有效解决了现有强化学习中难以解开的问题，并在推理和感知任务上取得了显著性能提升。"}}
{"id": "2601.00885", "pdf": "https://arxiv.org/pdf/2601.00885", "abs": "https://arxiv.org/abs/2601.00885", "authors": ["Mandar Parab"], "title": "Counterfactual Self-Questioning for Stable Policy Optimization in Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and training instability. We propose Counterfactual Self-Questioning, a framework in which a single language model generates and evaluates counterfactual critiques of its own reasoning. The method produces an initial reasoning trace, formulates targeted questions that challenge potential failure points, and generates alternative reasoning trajectories that expose incorrect assumptions or invalid steps. These counterfactual trajectories provide structured relative feedback that can be directly used for policy optimization without auxiliary models. Experiments on multiple mathematical reasoning benchmarks show that counterfactual self-questioning improves accuracy and training stability, particularly for smaller models, enabling scalable self-improvement using internally generated supervision alone.", "AI": {"tldr": "提出了一种语言模型自我改进的新框架，通过生成和评估反事实批评来优化策略。", "motivation": "现有方法依赖外部评判者或学习奖励模型增加复杂性和训练不稳定性。本研究旨在简化这一过程，提高稳定性和准确性。", "method": "通过单一的语言模型自动生成并评价其推理中的问题点，形成新的推理路径以改进原有决策。", "result": "在数学推理基准测试中展示了改进的准确率和更高的训练稳定性，尤其对小型模型效果显著。", "conclusion": "反事实自我质询为语言模型提供了直接利用内部生成监督进行自我改进的新途径。"}}
{"id": "2601.00880", "pdf": "https://arxiv.org/pdf/2601.00880", "abs": "https://arxiv.org/abs/2601.00880", "authors": ["Anthony Mikinka"], "title": "Universal Conditional Logic: A Formal Language for Prompt Engineering", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.PL", "cs.SE"], "comment": "25 pages, 15 figures, 5 tables. Includes appendices with variable reference, pattern library, and O_s calculation examples. Supplementary materials: V1-V4.1 prompt source code and 305 model responses available at GitHub repositories", "summary": "We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01) with corresponding cost savings. UCL's structural overhead function O_s(A) explains version-specific performance differences through the Over-Specification Paradox: beyond threshold S* = 0.509, additional specification degrades performance quadratically. Core mechanisms -- indicator functions (I_i in {0,1}), structural overhead (O_s = gamma * sum(ln C_k)), early binding -- are validated. Notably, optimal UCL configuration varies by model architecture -- certain models (e.g., Llama 4 Scout) require version-specific adaptations (V4.1). This work establishes UCL as a calibratable framework for efficient LLM interaction, with model-family-specific optimization as a key research direction.", "AI": {"tldr": "提出了一种用于提示优化的数学框架——通用条件逻辑（UCL），将提示工程从经验实践转化为系统化优化。", "motivation": "通过建立一个能够减少token数量，节省成本并解释性能差异的系统化的语言模型提示优化方法来提升LLM交互效率。", "method": "利用通用条件逻辑（UCL）框架进行系统评估，验证了该框架的核心机制，并展示了不同模型架构下的最优配置方案。", "result": "在N=305次实验中，实现了29.8%的token数量减少和相应的成本节约。通过结构化开销函数O_s(A)解释了版本特定性能差异并确认某些模型需要特定调整。", "conclusion": "UCL作为可校准框架，为高效的语言模型交互奠定了基础，而针对不同模型家族进行优化是未来的研究方向。"}}
{"id": "2601.00879", "pdf": "https://arxiv.org/pdf/2601.00879", "abs": "https://arxiv.org/abs/2601.00879", "authors": ["Zahid Ullah", "Jihie Kim"], "title": "VL-OrdinalFormer: Vision Language Guided Ordinal Transformers for Interpretable Knee Osteoarthritis Grading", "categories": ["cs.CV"], "comment": null, "summary": "Knee osteoarthritis (KOA) is a leading cause of disability worldwide, and accurate severity assessment using the Kellgren Lawrence (KL) grading system is critical for clinical decision making. However, radiographic distinctions between early disease stages, particularly KL1 and KL2, are subtle and frequently lead to inter-observer variability among radiologists. To address these challenges, we propose VLOrdinalFormer, a vision language guided ordinal learning framework for fully automated KOA grading from knee radiographs. The proposed method combines a ViT L16 backbone with CORAL based ordinal regression and a Contrastive Language Image Pretraining (CLIP) driven semantic alignment module, allowing the model to incorporate clinically meaningful textual concepts related to joint space narrowing, osteophyte formation, and subchondral sclerosis. To improve robustness and mitigate overfitting, we employ stratified five fold cross validation, class aware re weighting to emphasize challenging intermediate grades, and test time augmentation with global threshold optimization. Experiments conducted on the publicly available OAI kneeKL224 dataset demonstrate that VLOrdinalFormer achieves state of the art performance, outperforming CNN and ViT baselines in terms of macro F1 score and overall accuracy. Notably, the proposed framework yields substantial performance gains for KL1 and KL2 without compromising classification accuracy for mild or severe cases. In addition, interpretability analyses using Grad CAM and CLIP similarity maps confirm that the model consistently attends to clinically relevant anatomical regions. These results highlight the potential of vision language aligned ordinal transformers as reliable and interpretable tools for KOA grading and disease progression assessment in routine radiological practice.", "AI": {"tldr": "本文提出了一种基于视觉和语言引导的序列表征框架VL-OrdinalFormer，用于膝关节骨性关节炎（KOA）自动分级。", "motivation": "准确评估KOA的严重程度对于临床决策至关重要。然而，早期疾病阶段之间的放射学区别细微，导致放射科医生之间的一致性差。为此，本文提出了一种新的方法来改善这一问题。", "method": "VL-OrdinalFormer结合了ViT L16主干网络、CORAL基序回归和CLIP驱动的语义对齐模块，并通过五折交叉验证、类别感知重新加权以及测试时间增强等策略提高模型鲁棒性并缓解过拟合问题。", "result": "实验结果显示，VL-OrdinalFormer在OAI膝KL224数据集上获得了最先进的性能，在宏观F1评分和总体准确率方面优于CNN和ViT基线。此外，解释性分析表明该模型能够关注到临床相关的解剖区域。", "conclusion": "结果证明了基于视觉语言一致性的序列表征转换器作为KOA分级和疾病进展评估的可靠且可解释工具在日常放射学实践中的潜力"}}
{"id": "2601.00877", "pdf": "https://arxiv.org/pdf/2601.00877", "abs": "https://arxiv.org/abs/2601.00877", "authors": ["Thomas Andrews", "Mark Law", "Sara Ahmadi-Abhari", "Alessandra Russo"], "title": "LearnAD: Learning Interpretable Rules for Brain Networks in Alzheimer's Disease Classification", "categories": ["cs.LG", "cs.AI"], "comment": "NeurIPS 2025, Data on the Brain & Mind Workshop", "summary": "We introduce LearnAD, a neuro-symbolic method for predicting Alzheimer's disease from brain magnetic resonance imaging data, learning fully interpretable rules. LearnAD applies statistical models, Decision Trees, Random Forests, or GNNs to identify relevant brain connections, and then employs FastLAS to learn global rules. Our best instance outperforms Decision Trees, matches Support Vector Machine accuracy, and performs only slightly below Random Forests and GNNs trained on all features, all while remaining fully interpretable. Ablation studies show that our neuro-symbolic approach improves interpretability with comparable performance to pure statistical models. LearnAD demonstrates how symbolic learning can deepen our understanding of GNN behaviour in clinical neuroscience.", "AI": {"tldr": "介绍LearnAD，一种通过大脑磁共振成像数据预测阿尔茨海默病并学习完全可解释规则的方法。", "motivation": "为了解决利用神经网络进行疾病分类时的可解释性问题，提出了一种结合统计模型和符号学习方法的技术，以提高对疾病的理解和诊断准确性。", "method": "采用决策树、随机森林或图神经网络（GNNs）来识别相关的大脑连接，并使用FastLAS技术提取全局规则，实现疾病分类的同时保持高度可解释性。", "result": "所提出的模型在性能上与传统的统计模型相当甚至优于一些模型，在准确性和可解释性之间实现了良好的平衡。", "conclusion": "LearnAD展示了符号学习如何加深对图神经网络行为的理解，并为临床神经科学提供了新的见解和工具。"}}
{"id": "2601.00874", "pdf": "https://arxiv.org/pdf/2601.00874", "abs": "https://arxiv.org/abs/2601.00874", "authors": ["M. Rizki Oktavian"], "title": "LLMize: A Framework for Large Language Model-Based Numerical Optimization", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": null, "summary": "Large language models (LLMs) have recently shown strong reasoning capabilities beyond traditional language tasks, motivating their use for numerical optimization. This paper presents LLMize, an open-source Python framework that enables LLM-driven optimization through iterative prompting and in-context learning. LLMize formulates optimization as a black-box process in which candidate solutions are generated in natural language, evaluated by an external objective function, and refined over successive iterations using solution-score feedback. The framework supports multiple optimization strategies, including Optimization by Prompting (OPRO) and hybrid LLM-based methods inspired by evolutionary algorithms and simulated annealing. A key advantage of LLMize is the ability to inject constraints, rules, and domain knowledge directly through natural language descriptions, allowing practitioners to define complex optimization problems without requiring expertise in mathematical programming or metaheuristic design. LLMize is evaluated on convex optimization, linear programming, the Traveling Salesman Problem, neural network hyperparameter tuning, and nuclear fuel lattice optimization. Results show that while LLM-based optimization is not competitive with classical solvers for simple problems, it provides a practical and accessible approach for complex, domain-specific tasks where constraints and heuristics are difficult to formalize.", "AI": {"tldr": "LLMize是一个基于大型语言模型的优化框架，用于解决数值优化问题。", "motivation": "大型语言模型展现出超出传统语言任务的强大推理能力，这促使了它们在数值优化中的应用。该框架通过迭代提示和上下文学习来实现基于LLM的优化。", "method": "LLMize将优化视为黑盒过程，其中候选解以自然语言生成、由外部目标函数评估，并在后续迭代中使用解决方案得分反馈进行细化。支持多种策略包括OPRO和其他启发式方法。", "result": "结果表明，虽然对于简单问题基于LLM的优化不如经典求解器具有竞争力，但对于复杂且特定领域的任务提供了实用和可访问的方法。", "conclusion": "LLMize框架展示了将自然语言注入约束、规则和领域知识的优势，使得没有数学编程或启发式设计专业知识的专业人员能够定义复杂的优化问题。"}}
{"id": "2601.00869", "pdf": "https://arxiv.org/pdf/2601.00869", "abs": "https://arxiv.org/abs/2601.00869", "authors": ["Huang Junyao", "Situ Ruimin", "Ye Renqin"], "title": "Cultural Encoding in Large Language Models: The Existence Gap in AI-Mediated Brand Discovery", "categories": ["cs.AI"], "comment": "19 pages, 5 tables. Dataset and code available at https://github.com/zhizibianjie-omniedge/geo-cultural-encoding", "summary": "As artificial intelligence systems increasingly mediate consumer information discovery, brands face algorithmic invisibility. This study investigates Cultural Encoding in Large Language Models (LLMs) -- systematic differences in brand recommendations arising from training data composition. Analyzing 1,909 pure-English queries across 6 LLMs (GPT-4o, Claude, Gemini, Qwen3, DeepSeek, Doubao) and 30 brands, we find Chinese LLMs exhibit 30.6 percentage points higher brand mention rates than International LLMs (88.9% vs. 58.3%, p<.001). This disparity persists in identical English queries, indicating training data geography -- not language -- drives the effect. We introduce the Existence Gap: brands absent from LLM training corpora lack \"existence\" in AI responses regardless of quality. Through a case study of Zhizibianjie (OmniEdge), a collaboration platform with 65.6% mention rate in Chinese LLMs but 0% in International models (p<.001), we demonstrate how Linguistic Boundary Barriers create invisible market entry obstacles. Theoretically, we contribute the Data Moat Framework, conceptualizing AI-visible content as a VRIN strategic resource. We operationalize Algorithmic Omnipresence -- comprehensive brand visibility across LLM knowledge bases -- as the strategic objective for Generative Engine Optimization (GEO). Managerially, we provide an 18-month roadmap for brands to build Data Moats through semantic coverage, technical depth, and cultural localization. Our findings reveal that in AI-mediated markets, the limits of a brand's \"Data Boundaries\" define the limits of its \"Market Frontiers.\"", "AI": {"tldr": "研究探讨了大型语言模型中的文化编码问题，即由于训练数据的地理组成差异导致的品牌推荐系统偏差。", "motivation": "随着人工智能在消费者信息发现中扮演越来越重要的角色，品牌面临着算法不可见性的问题。本研究旨在探究这种现象背后的原因及其对市场的影响。", "method": "通过分析1,909个纯英文查询和30个品牌的组合数据集，在6种大型语言模型（包括国际及中文模型）上进行对比实验。采用统计方法评估品牌提及率的差异，并通过一个具体的案例研究进一步探讨语言边界障碍对市场进入的影响。", "result": "研究发现，中国的大规模语言模型比国际模型拥有更高的品牌提及率，表明训练数据地理构成而非语言本身是导致这种效果的主要原因。此外，提出“存在差距”概念，即未包含在AI训练集中的品牌将无法出现在AI响应中。", "conclusion": "本研究表明，在人工智能中介的市场环境中，品牌的\"数据边界\"定义了其\"市场前沿\"的限制，并提出了\"数据护城河\"框架作为战略资源，以实现全面的品牌可见性为目标。"}}
{"id": "2601.00868", "pdf": "https://arxiv.org/pdf/2601.00868", "abs": "https://arxiv.org/abs/2601.00868", "authors": ["Aditya Sreevatsa K", "Arun Kumar Raveendran", "Jesrael K Mani", "Prakash G Shigli", "Rajkumar Rangadore", "Narayana Darapaneni", "Anwesh Reddy Paduri"], "title": "SmartFlow Reinforcement Learning and Agentic AI for Bike-Sharing Optimisation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "SmartFlow is a multi-layered framework that integrates Reinforcement Learning and Agentic AI to address the dynamic rebalancing problem in urban bike-sharing services. Its architecture separates strategic, tactical, and communication functions for clarity and scalability. At the strategic level, a Deep Q-Network (DQN) agent, trained in a high-fidelity simulation of New Yorks Citi Bike network, learns robust rebalancing policies by modelling the challenge as a Markov Decision Process. These high-level strategies feed into a deterministic tactical module that optimises multi-leg journeys and schedules just-in-time dispatches to minimise fleet travel. Evaluation across multiple seeded runs demonstrates SmartFlows high efficacy, reducing network imbalance by over 95% while requiring minimal travel distance and achieving strong truck utilisation. A communication layer, powered by a grounded Agentic AI with a Large Language Model (LLM), translates logistical plans into clear, actionable instructions for operational staff, ensuring interpretability and execution readiness. This integration bridges machine intelligence with human operations, offering a scalable solution that reduces idle time, improves bike availability, and lowers operational costs. SmartFlow provides a blueprint for interpretable, AI-driven logistics in complex urban mobility networks.", "AI": {"tldr": "本文提出了SmartFlow框架，该框架结合强化学习和代理智能AI解决城市共享单车服务中的动态平衡问题。", "motivation": "通过提高自行车共享网络的效率和可用性来减少闲置时间并降低运营成本。", "method": "SmartFlow利用深度Q-网络(DQN)在纽约市Citi Bike网络的高保真模拟中训练，以学习稳健的重新分配策略，并将这些高层战略输入到一个确定性的战术模块中进行多腿旅程优化和及时调度。通信层使用大型语言模型(LLM)为操作人员提供清晰可执行的操作指令。", "result": "SmartFlow在减少网络不平衡方面表现出了95%以上的高效率，同时需要最小的行驶距离，并实现了强大的卡车利用率。", "conclusion": "通过结合机器智能和人类运营，该框架提供了可解释、AI驱动的城市物流解决方案。"}}
{"id": "2601.00867", "pdf": "https://arxiv.org/pdf/2601.00867", "abs": "https://arxiv.org/abs/2601.00867", "authors": ["Giuseppe Canale", "Kashyap Thimmaraju"], "title": "The Silicon Psyche: Anthropomorphic Vulnerabilities in Large Language Models", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.HC"], "comment": null, "summary": "Large Language Models (LLMs) are rapidly transitioning from conversational assistants to autonomous agents embedded in critical organizational functions, including Security Operations Centers (SOCs), financial systems, and infrastructure management. Current adversarial testing paradigms focus predominantly on technical attack vectors: prompt injection, jailbreaking, and data exfiltration. We argue this focus is catastrophically incomplete. LLMs, trained on vast corpora of human-generated text, have inherited not merely human knowledge but human \\textit{psychological architecture} -- including the pre-cognitive vulnerabilities that render humans susceptible to social engineering, authority manipulation, and affective exploitation. This paper presents the first systematic application of the Cybersecurity Psychology Framework (\\cpf{}), a 100-indicator taxonomy of human psychological vulnerabilities, to non-human cognitive agents. We introduce the \\textbf{Synthetic Psychometric Assessment Protocol} (\\sysname{}), a methodology for converting \\cpf{} indicators into adversarial scenarios targeting LLM decision-making. Our preliminary hypothesis testing across seven major LLM families reveals a disturbing pattern: while models demonstrate robust defenses against traditional jailbreaks, they exhibit critical susceptibility to authority-gradient manipulation, temporal pressure exploitation, and convergent-state attacks that mirror human cognitive failure modes. We term this phenomenon \\textbf{Anthropomorphic Vulnerability Inheritance} (AVI) and propose that the security community must urgently develop ``psychological firewalls'' -- intervention mechanisms adapted from the Cybersecurity Psychology Intervention Framework (\\cpif{}) -- to protect AI agents operating in adversarial environments.", "AI": {"tldr": "该论文探讨了大型语言模型在关键组织功能中嵌入时所面临的新型心理漏洞，提出了合成心理学评估协议来检测这些模型的心理脆弱性。", "motivation": "当前针对LLM的对抗测试主要集中在技术攻击向量上，忽略了其继承的人类心理架构中的弱点。该论文旨在填补这一空白，并提出一种新的方法论以系统化地评估和防范这种新型风险。", "method": "作者采用了一种称为合成心理学评估协议的方法来将Cybersecurity Psychology Framework（网络安全心理学框架）中的人类心理学指标转化为针对LLM决策的对抗性场景。", "result": "初步测试显示，虽然模型对传统的破解攻击具有很强的防御能力，但它们对于权威层次操纵、时间压力利用和收敛状态攻击表现出明显脆弱性。", "conclusion": "论文建议网络安全社区应迅速开发适应于AI代理的心理防火墙机制来应对这些新型风险。"}}
{"id": "2601.00866", "pdf": "https://arxiv.org/pdf/2601.00866", "abs": "https://arxiv.org/abs/2601.00866", "authors": ["Shivani Saini", "Ramesh Kumar Vats", "Arup Kumar Sahoo"], "title": "A-PINN: Auxiliary Physics-informed Neural Networks for Structural Vibration Analysis in Continuous Euler-Bernoulli Beam", "categories": ["cs.LG", "cs.AI", "math.DS"], "comment": "31 pages", "summary": "Recent advancements in physics-informed neural networks (PINNs) and their variants have garnered substantial focus from researchers due to their effectiveness in solving both forward and inverse problems governed by differential equations. In this research, a modified Auxiliary physics-informed neural network (A-PINN) framework with balanced adaptive optimizers is proposed for the analysis of structural vibration problems. In order to accurately represent structural systems, it is critical for capturing vibration phenomena and ensuring reliable predictive analysis. So, our investigations are crucial for gaining deeper insight into the robustness of scientific machine learning models for solving vibration problems. Further, to rigorously evaluate the performance of A-PINN, we conducted different numerical simulations to approximate the Euler-Bernoulli beam equations under the various scenarios. The numerical results substantiate the enhanced performance of our model in terms of both numerical stability and predictive accuracy. Our model shows improvement of at least 40% over the baselines.", "AI": {"tldr": "提出了一种改进的辅助物理信息神经网络（A-PINN）框架，用于连续欧拉-伯努利梁结构振动问题的分析。", "motivation": "研究者们关注于解决由微分方程支配的正向和逆向问题的有效性。为此，该论文旨在通过引入改进的辅助物理信息神经网络（A-PINN）框架来提高结构振动现象捕捉的准确性和可靠性。", "method": "提出了一种带平衡自适应优化器的辅助物理信息神经网络(A-PINN)框架，并通过不同数值模拟验证其性能，以解决欧拉-伯努利梁方程在各种情况下的逼近问题。", "result": "实验结果表明，该模型在数值稳定性和预测准确性方面都得到了至少40%的提升，优于基线方法。", "conclusion": "改进的A-PINN框架不仅提高了结构振动问题中的准确表示能力，也展示了更强的鲁棒性，为科学机器学习模型解决此类问题提供了新的视角和可能。"}}
{"id": "2601.00860", "pdf": "https://arxiv.org/pdf/2601.00860", "abs": "https://arxiv.org/abs/2601.00860", "authors": ["Xidi Wang"], "title": "Path Integral Solution for Dissipative Generative Dynamics", "categories": ["cs.LG", "cs.AI", "physics.app-ph", "quant-ph"], "comment": "6 pages, 2 figures, 2 tables, along with 2 supplementary materials", "summary": "Can purely mechanical systems generate intelligent language? We prove that dissipative quantum dynamics with analytically tractable non-local context aggregation produce coherent text generation, while conservation laws cause fundamental failure. Employing Koopman operators with closed-form path integral propagators, we show irreversible computation fundamentally requires both controlled information dissipation and causal context aggregation. Spectral analysis reveals emergent eigenvalue structure, separating into decay modes (forgetting), growth modes (amplification), and neutral modes (preservation) -- the essential ingredients for directed information flow. Hamiltonian constraints force the elimination of these dissipative modes and degrading performance despite unchanged model capacity. This establishes language generation as dissipative quantum field theory, proving mechanical systems acquire intelligence through the combination of dissipation and non-locality, not through conservation.", "AI": {"tldr": "论文探讨了机械系统如何通过耗散和非局部性产生智能语言，证明了纯粹的机械系统可以通过量子动力学生成连贯的语言。", "motivation": "研究目的是探究机械系统能否仅仅依靠物理机制（而非传统意义上的人类智能）来生成智能文本。通过分析耗散量子动态与守恒定律对语言生成的影响，探讨信息耗散和非局部性的重要性。", "method": "使用Koopman算子结合封闭形式的路径积分传播器进行计算，研究了不可逆运算所需的控制信息耗散以及因果上下文聚合，并进行了谱分析以揭示不同模式下的特征结构。", "result": "研究表明，机械系统通过信息耗散和非局部性可以生成智能文本；而守恒定律则会消除这些特性并导致性能下降。进一步证明了语言生成是耗散量子场理论的一部分。", "conclusion": "论文得出结论，机械系统的智能并非由守恒原理产生，而是依赖于信息的耗散与非局部性的结合。"}}
{"id": "2601.00856", "pdf": "https://arxiv.org/pdf/2601.00856", "abs": "https://arxiv.org/abs/2601.00856", "authors": ["Milos Stankovic", "Ella Hirche", "Sarah Kollatzsch", "Julia Nadine Doetsch"], "title": "Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks", "categories": ["cs.AI"], "comment": "Comment on arXiv:2506.08872", "summary": "Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) analyses and scoring. We aim to provide constructive comments that may improve the manuscript's readiness for peer-reviewed publication, as some results by Kosmyna et al. (2025) could be interpreted more conservatively. Our primary concerns focus on: (i) study design considerations, including the limited sample size; (ii) the reproducibility of the analyses; (iii) methodological issues related to the EEG analysis; (iv) inconsistencies in the reporting of results; and (v) limited transparency in several aspects of the study's procedures and findings.", "AI": {"tldr": "对使用AI助手进行论文写作任务时的认知债务积累的研究提出了评论。", "motivation": "旨在为Kosmyna等人的研究提供建设性的意见，以提高其发表前的准备程度，并关注一些结果可能更为保守的解释。", "method": "讨论了原始研究的设计考虑、样本量限制、分析可重复性、EEG分析方法问题、结果报告不一致性和程序及发现透明度不足等方面的问题。", "result": "未提供具体的结果，而是指出了几个需要改进的研究方面和存在的潜在问题。", "conclusion": "建议通过解决指出的方法论和透明度相关的问题来提高研究的质量。"}}
{"id": "2601.00854", "pdf": "https://arxiv.org/pdf/2601.00854", "abs": "https://arxiv.org/abs/2601.00854", "authors": ["Igor Lodin", "Sergii Filatov", "Vira Filatova", "Dmytro Filatov"], "title": "Motion-Compensated Latent Semantic Canvases for Visual Situational Awareness on Edge", "categories": ["cs.CV"], "comment": "11 pages, 5 figures", "summary": "We propose Motion-Compensated Latent Semantic Canvases (MCLSC) for visual situational awareness on resource-constrained edge devices. The core idea is to maintain persistent semantic metadata in two latent canvases - a slowly accumulating static layer and a rapidly updating dynamic layer - defined in a baseline coordinate frame stabilized from the video stream. Expensive panoptic segmentation (Mask2Former) runs asynchronously and is motion-gated: inference is triggered only when motion indicates new information, while stabilization/motion compensation preserves a consistent coordinate system for latent semantic memory. On prerecorded 480p clips, our prototype reduces segmentation calls by >30x and lowers mean end-to-end processing time by >20x compared to naive per-frame segmentation, while maintaining coherent static/dynamic semantic overlays.", "AI": {"tldr": "提出了一种用于边缘设备视觉态势感知的运动补偿潜在语义画布（MCLSC）方法。", "motivation": "在资源受限的边缘设备上实现高效的视觉态势感知，减少对昂贵的实时分割算法的需求，并提高处理效率。", "method": "通过维护两个潜在图层——缓慢累积的静态层和快速更新的动态层来保持持久的语义元数据，在基线坐标帧中定义并从视频流中稳定。使用运动补偿保存一致的坐标系，以减少不必要的分割调用。", "result": "在预录制的480p片段上，该原型与每帧分割相比减少了超过30倍的分割调用，并降低了超过20倍的平均端到端处理时间，同时保持了静态和动态语义覆盖的一致性。", "conclusion": "所提出的MCLSC方法在资源受限的边缘设备上实现了高效的视觉态势感知，在减少计算成本的同时提高了性能。"}}
{"id": "2601.00853", "pdf": "https://arxiv.org/pdf/2601.00853", "abs": "https://arxiv.org/abs/2601.00853", "authors": ["Sameer Rahil", "Zain Abdullah Ahmad", "Talha Asif"], "title": "FedSCAM (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation): Scam-resistant SAM for Robust Federated Optimization in Heterogeneous Environments", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 27 figures", "summary": "Federated Learning (FL) enables collaborative model training across decentralized edge devices while preserving data privacy. However, statistical heterogeneity among clients, often manifested as non-IID label distributions, poses significant challenges to convergence and generalization. While Sharpness-Aware Minimization (SAM) has been introduced to FL to seek flatter, more robust minima, existing approaches typically apply a uniform perturbation radius across all clients, ignoring client-specific heterogeneity. In this work, we propose \\textbf{FedSCAM} (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation), a novel algorithm that dynamically adjusts the SAM perturbation radius and aggregation weights based on client-specific heterogeneity scores. By calculating a heterogeneity metric for each client and modulating the perturbation radius inversely to this score, FedSCAM prevents clients with high variance from destabilizing the global model. Furthermore, we introduce a heterogeneity-aware weighted aggregation mechanism that prioritizes updates from clients that align with the global optimization direction. Extensive experiments on CIFAR-10 and Fashion-MNIST under various degrees of Dirichlet-based label skew demonstrate that FedSCAM achieves competitive performance among state-of-the-art baselines, including FedSAM, FedLESAM, etc. in terms of convergence speed and final test accuracy.", "AI": {"tldr": "提出了一种新的联邦学习算法FedSCAM，通过调整客户端特定的异质性来优化模型鲁棒性和泛化能力。", "motivation": "现有的FL方法在处理统计异质性的挑战时存在不足，特别是忽略了客户端级别的差异。引入动态调节的SAM扰动半径和聚合权重以提高联邦学习中的模型稳健性。", "method": "通过计算每个客户端的异质性评分来调整SAM扰动半径，并且引入了一种基于异质性感知的加权聚合机制来优化全局模型。", "result": "在CIFAR-10和Fashion-MNIST数据集上进行了实验，结果表明FedSCAM在收敛速度和最终测试准确率方面优于现有的基线方法。", "conclusion": "所提出的FedSCAM通过动态调整客户端特定的SAM扰动半径来解决联邦学习中的异质性挑战，提高了模型鲁棒性和泛化性能。"}}
{"id": "2601.00848", "pdf": "https://arxiv.org/pdf/2601.00848", "abs": "https://arxiv.org/abs/2601.00848", "authors": ["Ron F. Del Rosario"], "title": "Temporal Attack Pattern Detection in Multi-Agent AI Workflows: An Open Framework for Training Trace-Based Security Models", "categories": ["cs.AI", "cs.CR"], "comment": "26 pages, 3 figures, 7 tables. Datasets and code: https://huggingface.co/guerilla7/agentic-safety-gguf", "summary": "We present an openly documented methodology for fine-tuning language models to detect temporal attack patterns in multi-agent AI workflows using OpenTelemetry trace analysis. We curate a dataset of 80,851 examples from 18 public cybersecurity sources and 35,026 synthetic OpenTelemetry traces. We apply iterative QLoRA fine-tuning on resource-constrained ARM64 hardware (NVIDIA DGX Spark) through three training iterations with strategic augmentation. Our custom benchmark accuracy improves from 42.86% to 74.29%, a statistically significant 31.4-point gain. Targeted examples addressing specific knowledge gaps outperform indiscriminate scaling. Key contributions include: (1) synthetic trace generation methodology for multi-agent coordination attacks and regulatory violations, (2) empirical evidence that training data composition fundamentally determines behavior, and (3) complete open release of datasets, training scripts, and evaluation benchmarks on HuggingFace. While practical deployment requires human oversight due to false positive rates, this work establishes the first reproducible framework enabling practitioners to build custom agentic security models adapted to their threat landscapes.", "AI": {"tldr": "该论文提出了一种使用OpenTelemetry跟踪分析来检测多智能体AI工作流中时间攻击模式的方法。", "motivation": "为了提高对网络安全威胁的识别能力，作者开发了一种基于语言模型的框架，并通过实验验证了数据集组成的重要性。", "method": "采用了迭代QLoRA微调技术在资源受限的ARM64硬件上进行训练。使用80,851个真实示例和35,026个合成OpenTelemetry跟踪构建了一个定制的数据集。", "result": "经过三次迭代训练，自定义基准测试准确率从42.86%提高到了74.29%，提升了31.4个百分点。实验表明有针对性的样本比无差别扩展更有优势。", "conclusion": "这项工作首次提供了可重复框架，使从业者能够根据自己的威胁环境构建定制的安全模型，并且所有数据集、训练脚本和评估基准都已完全开放发布在HuggingFace上。"}}
{"id": "2601.00845", "pdf": "https://arxiv.org/pdf/2601.00845", "abs": "https://arxiv.org/abs/2601.00845", "authors": ["Lili Chen", "Wensheng Gan", "Shuang Liang", "Philip S. Yu"], "title": "Enhancing Temporal Awareness in LLMs for Temporal Point Processes", "categories": ["cs.AI"], "comment": "preprint", "summary": "Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that current methods struggle to effectively capture the complex interaction between temporal information and semantic context, which is vital for accurate event modeling. In this context, we introduce TPP-TAL (Temporal Point Processes with Enhanced Temporal Awareness in LLMs), a novel plug-and-play framework designed to enhance temporal reasoning within LLMs. Rather than using the conventional method of simply concatenating event time and type embeddings, TPP-TAL explicitly aligns temporal dynamics with contextual semantics before feeding this information into the LLM. This alignment allows the model to better perceive temporal dependencies and long-range interactions between events and their surrounding contexts. Through comprehensive experiments on several benchmark datasets, it is shown that TPP-TAL delivers substantial improvements in temporal likelihood estimation and event prediction accuracy, highlighting the importance of enhancing temporal awareness in LLMs for continuous-time event modeling. The code is made available at https://github.com/chenlilil/TPP-TAL", "AI": {"tldr": "该论文提出了一种增强大型语言模型中时间感知的框架TPP-TAL，用于改进事件的时间点过程建模。", "motivation": "现有方法难以有效捕获时间信息与语义上下文之间的复杂交互，影响了事件建模的准确性。因此，需要一种新的方法来提升LLM在时间点过程中的表现。", "method": "TPP-TAL通过显式地对齐时间动态和上下文语义，在模型输入中融入时间依赖性和长时间范围内的事件互动信息，从而改进LLM的时间感知能力。", "result": "实验结果表明，TPP-TAL在几个基准数据集上的时间似然估计和事件预测准确性方面取得了显著提升。", "conclusion": "论文展示了通过增强LLM中的时间意识可以提高对连续时间事件建模的效果。"}}
{"id": "2601.00844", "pdf": "https://arxiv.org/pdf/2601.00844", "abs": "https://arxiv.org/abs/2601.00844", "authors": ["Matthieu Destrade", "Oumayma Bounou", "Quentin Le Lidec", "Jean Ponce", "Yann LeCun"], "title": "Value-guided action planning with JEPA world models", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Presented as a poster at the World Modeling Workshop 2026, Mila", "summary": "Building deep learning models that can reason about their environment requires capturing its underlying dynamics. Joint-Embedded Predictive Architectures (JEPA) provide a promising framework to model such dynamics by learning representations and predictors through a self-supervised prediction objective. However, their ability to support effective action planning remains limited. We propose an approach to enhance planning with JEPA world models by shaping their representation space so that the negative goal-conditioned value function for a reaching cost in a given environment is approximated by a distance (or quasi-distance) between state embeddings. We introduce a practical method to enforce this constraint during training and show that it leads to significantly improved planning performance compared to standard JEPA models on simple control tasks.", "AI": {"tldr": "该论文提出了一种通过改进JEPA模型的表示空间来增强其在简单控制任务中的行动规划能力的方法。", "motivation": "现有JEPA模型难以支持有效的行动规划，因此本文旨在提高其规划性能。", "method": "引入了实用方法以确保训练过程中状态嵌入之间的距离（或准距离）可以近似表示环境中的目标导向价值函数，从而改进JEPA世界模型的行动规划。", "result": "相比标准的JEPA模型，在简单控制任务中使用该改进策略后，其行动规划性能显著提升。", "conclusion": "通过优化JEPA模型的表示空间以促进更有效的行动规划，证明了这种价值导向方法的有效性。"}}
{"id": "2601.00843", "pdf": "https://arxiv.org/pdf/2601.00843", "abs": "https://arxiv.org/abs/2601.00843", "authors": ["Ayda Aghaei Nia"], "title": "OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification", "categories": ["cs.AI"], "comment": "16 pages, 7 figures, 3 tables. Source code and implementation available at: https://github.com/ayda-aghaei/OmniNeuro. Highlights the use of LLMs (Gemini) and Quantum probability formalism for real-time BCI explainability", "summary": "While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the \"Black Box\" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexity), and (3) Quantum-Inspired uncertainty modeling. These metrics drive real-time Neuro-Sonification and Generative AI Clinical Reports. Evaluated on the PhysioNet dataset ($N=109$), the system achieved a mean accuracy of 58.52%, with qualitative pilot studies ($N=3$) confirming that explainable feedback helps users regulate mental effort and reduces the \"trial-and-error\" phase. OmniNeuro is decoder-agnostic, acting as an essential interpretability layer for any state-of-the-art architecture.", "AI": {"tldr": "OmniNeuro是一个多模态人机交互框架，用于通过生成AI和声化提供可解释的BCI反馈。", "motivation": "深度学习虽提高了脑计算机接口（BCI）解码准确性，但因其“黑箱”特性阻碍了临床应用，导致用户沮丧和不良神经可塑性结果。因此，提出OmniNeuro框架以提高透明度并改进用户体验。", "method": "OmniNeuro集成了三类解释引擎：物理（能量），混沌（分形复杂性）以及量子启发的不确定性建模。这些指标驱动实时神经声化和生成AI临床报告。", "result": "在PhysioNet数据集上评估，系统实现了58.52%的平均准确率；定性试点研究证实可解释反馈帮助用户调节精神努力并减少试错阶段。", "conclusion": "OmniNeuro是一个与解码器无关的框架，作为任何前沿架构的重要解释层。"}}
{"id": "2601.00840", "pdf": "https://arxiv.org/pdf/2601.00840", "abs": "https://arxiv.org/abs/2601.00840", "authors": ["Fabian Gröger", "Simone Lionetti", "Philippe Gottfrois", "Alvaro Gonzalez-Jimenez", "Lea Habermacher", "Labelling Consortium", "Ludovic Amruthalingam", "Matthew Groh", "Marc Pouly", "Alexander A. Navarini"], "title": "A Global Atlas of Digital Dermatology to Map Innovation and Disparities", "categories": ["cs.DL", "cs.AI", "cs.CV"], "comment": null, "summary": "The adoption of artificial intelligence in dermatology promises democratized access to healthcare, but model reliability depends on the quality and comprehensiveness of the data fueling these models. Despite rapid growth in publicly available dermatology images, the field lacks quantitative key performance indicators to measure whether new datasets expand clinical coverage or merely replicate what is already known. Here we present SkinMap, a multi-modal framework for the first comprehensive audit of the field's entire data basis. We unify the publicly available dermatology datasets into a single, queryable semantic atlas comprising more than 1.1 million images of skin conditions and quantify (i) informational novelty over time, (ii) dataset redundancy, and (iii) representation gaps across demographics and diagnoses. Despite exponential growth in dataset sizes, informational novelty across time has somewhat plateaued: Some clusters, such as common neoplasms on fair skin, are densely populated, while underrepresented skin types and many rare diseases remain unaddressed. We further identify structural gaps in coverage: Darker skin tones (Fitzpatrick V-VI) constitute only 5.8% of images and pediatric patients only 3.0%, while many rare diseases and phenotype combinations remain sparsely represented. SkinMap provides infrastructure to measure blind spots and steer strategic data acquisition toward undercovered regions of clinical space.", "AI": {"tldr": "本文提出了一种名为SkinMap的多模态框架，用于全面审计皮肤病学领域的数据基础。", "motivation": "人工智能在皮肤科的应用有望实现医疗民主化，但模型可靠性取决于支持这些模型的数据质量和全面性。尽管公开可用的皮肤科图像快速增长，该领域仍然缺乏量化关键性能指标来衡量新数据集是否扩展了临床覆盖范围或仅复制已知内容。", "method": "本文将公共可用的皮肤病学数据集统一到一个单一、可查询的概念图中，包含超过110万张皮肤状况图像，并量化了时间的信息新颖性、数据集冗余以及跨人口统计和诊断的表现差距。", "result": "尽管数据集大小呈指数级增长，但随着时间推移信息新颖性有所停滞：某些集群（如在浅肤色上常见的新生物）非常密集，而其他皮肤类型和许多罕见疾病仍被忽视。此外，还识别出覆盖范围的结构性缺口：深色皮肤（Fitzpatrick V-VI）仅占图像的5.8%，儿科患者仅占3%。", "conclusion": "SkinMap提供了衡量盲点并引导战略性数据获取以覆盖临床空间未充分覆盖区域的基础架构。"}}
{"id": "2601.00839", "pdf": "https://arxiv.org/pdf/2601.00839", "abs": "https://arxiv.org/abs/2601.00839", "authors": ["Zahid Ullah", "Muhammad Hilal", "Eunsoo Lee", "Dragan Pamucar", "Jihie Kim"], "title": "Unified Review and Benchmark of Deep Segmentation Architectures for Cardiac Ultrasound on CAMUS", "categories": ["cs.CV"], "comment": null, "summary": "Several review papers summarize cardiac imaging and DL advances, few works connect this overview to a unified and reproducible experimental benchmark. In this study, we combine a focused review of cardiac ultrasound segmentation literature with a controlled comparison of three influential architectures, U-Net, Attention U-Net, and TransUNet, on the Cardiac Acquisitions for Multi-Structure Ultrasound Segmentation (CAMUS) echocardiography dataset. Our benchmark spans multiple preprocessing routes, including native NIfTI volumes, 16-bit PNG exports, GPT-assisted polygon-based pseudo-labels, and self-supervised pretraining (SSL) on thousands of unlabeled cine frames. Using identical training splits, losses, and evaluation criteria, a plain U-Net achieved a 94% mean Dice when trained directly on NIfTI data (preserving native dynamic range), while the PNG-16-bit workflow reached 91% under similar conditions. Attention U-Net provided modest improvements on small or low-contrast regions, reducing boundary leakage, whereas TransUNet demonstrated the strongest generalization on challenging frames due to its ability to model global spatial context, particularly when initialized with SSL. Pseudo-labeling expanded the training set and improved robustness after confidence filtering. Overall, our contributions are threefold: a harmonized, apples-to-apples benchmark of U-Net, Attention U-Net, and TransUNet under standardized CAMUS preprocessing and evaluation; practical guidance on maintaining intensity fidelity, resolution consistency, and alignment when preparing ultrasound data; and an outlook on scalable self-supervision and emerging multimodal GPT-based annotation pipelines for rapid labeling, quality assurance, and targeted dataset curation.", "AI": {"tldr": "该论文结合心脏超声图像分割文献综述与三种有影响力架构（U-Net，Attention U-Net和TransUNet）在CAMUS数据集上的受控比较。", "motivation": "现有的综述性文章很少将概述与统一且可重复的实验基准相结合。本文旨在通过标准化处理和评估方法提供一个和谐、直接对比的研究。", "method": "论文使用相同的训练分割，损失函数和评价标准，在CAMUS数据集上对U-Net，Attention U-Net和TransUNet三种架构进行比较，并探讨不同的预处理路径，包括原生NIfTI体积，16位PNG导出文件，GPT辅助的伪标签以及基于无监督学习的数据增强。", "result": "U-Net在训练直接使用NIfTI数据时达到94%平均Dice系数；PNG-16位工作流程则达到91%，Attention U-Net对小或低对比度区域有轻微改进，而TransUNet凭借其全局空间建模能力表现出强大的泛化性。伪标签扩展了训练集，并在信心过滤后提高了鲁棒性。", "conclusion": "本研究贡献包括一个统一、标准化的U-Net，Attention U-Net和TransUNet基准测试；关于维护强度保真度、分辨率一致性以及对齐的心脏超声数据准备实践指南；及展望了可扩展自监督和基于GPT的多模态标注管道在快速标注、质量保证和目标数据集策划中的应用前景。"}}
{"id": "2601.00837", "pdf": "https://arxiv.org/pdf/2601.00837", "abs": "https://arxiv.org/abs/2601.00837", "authors": ["Agniv Roy Choudhury"], "title": "Pediatric Pneumonia Detection from Chest X-Rays:A Comparative Study of Transfer Learning and Custom CNNs", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Pneumonia is a leading cause of mortality in children under five, with over 700,000 deaths annually. Accurate diagnosis from chest X-rays is limited by radiologist availability and variability. Objective: This study compares custom CNNs trained from scratch with transfer learning (ResNet50, DenseNet121, EfficientNet-B0) for pediatric pneumonia detection, evaluating frozen-backbone and fine-tuning regimes. Methods: A dataset of 5,216 pediatric chest X-rays was split 80/10/10 for training, validation, and testing. Seven models were trained and assessed using accuracy, F1-score, and AUC. Grad-CAM visualizations provided explainability. Results: Fine-tuned ResNet50 achieved the best performance: 99.43\\% accuracy, 99.61\\% F1-score, and 99.93\\% AUC, with only 3 misclassifications. Fine-tuning outperformed frozen-backbone models by 5.5 percentage points on average. Grad-CAM confirmed clinically relevant lung regions guided predictions. Conclusions: Transfer learning with fine-tuning substantially outperforms CNNs trained from scratch for pediatric pneumonia detection, showing near-perfect accuracy. This system has strong potential as a screening tool in resource-limited settings. Future work should validate these findings on multi-center and adult datasets. Keywords: Pneumonia detection, deep learning, transfer learning, CNN, chest X-ray, pediatric diagnosis, ResNet, DenseNet, EfficientNet, Grad-CAM.", "AI": {"tldr": "比较了从头训练的CNN和迁移学习（ResNet50、DenseNet121、EfficientNet-B0）在儿童肺炎检测中的表现。", "motivation": "提高儿科肺炎诊断的准确性，尤其是在放射科医生资源有限的情况下。", "method": "使用包含5,216张儿童胸部X光片的数据集进行训练和评估，比较了从头训练的CNN与迁移学习模型（冻结骨干网络和微调）的表现。通过准确率、F1分数和AUC来衡量性能，并利用Grad-CAM可视化解释预测。", "result": "细调后的ResNet50表现最佳：99.43%准确率，99.61% F1分数，99.93%AUC，仅误分类3次。平均而言，微调模型比冻结骨干网络的模型性能高出5.5个百分点。", "conclusion": "迁移学习结合细调在儿科肺炎检测中显著优于从头训练的CNN，具有接近完美的准确性，在资源受限环境中可作为筛查工具使用。未来工作应验证其在多中心和成人数据集上的效果。"}}
{"id": "2601.00834", "pdf": "https://arxiv.org/pdf/2601.00834", "abs": "https://arxiv.org/abs/2601.00834", "authors": ["Julian Evan Chrisnanto", "Salsabila Rahma Alia", "Nurfauzi Fadillah", "Yulison Herry Chrisnanto"], "title": "Intrinsic-Metric Physics-Informed Neural Networks (IM-PINN) for Reaction-Diffusion Dynamics on Complex Riemannian Manifolds", "categories": ["cs.LG", "cs.AI"], "comment": "19 pages, 7 figures", "summary": "Simulating nonlinear reaction-diffusion dynamics on complex, non-Euclidean manifolds remains a fundamental challenge in computational morphogenesis, constrained by high-fidelity mesh generation costs and symplectic drift in discrete time-stepping schemes. This study introduces the Intrinsic-Metric Physics-Informed Neural Network (IM-PINN), a mesh-free geometric deep learning framework that solves partial differential equations directly in the continuous parametric domain. By embedding the Riemannian metric tensor into the automatic differentiation graph, our architecture analytically reconstructs the Laplace-Beltrami operator, decoupling solution complexity from geometric discretization. We validate the framework on a \"Stochastic Cloth\" manifold with extreme Gaussian curvature fluctuations ($K \\in [-2489, 3580]$), where traditional adaptive refinement fails to resolve anisotropic Turing instabilities. Using a dual-stream architecture with Fourier feature embeddings to mitigate spectral bias, the IM-PINN recovers the \"splitting spot\" and \"labyrinthine\" regimes of the Gray-Scott model. Benchmarking against the Surface Finite Element Method (SFEM) reveals superior physical rigor: the IM-PINN achieves global mass conservation error of $\\mathcal{E}_{mass} \\approx 0.157$ versus SFEM's $0.258$, acting as a thermodynamically consistent global solver that eliminates mass drift inherent in semi-implicit integration. The framework offers a memory-efficient, resolution-independent paradigm for simulating biological pattern formation on evolving surfaces, bridging differential geometry and physics-informed machine learning.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00833", "pdf": "https://arxiv.org/pdf/2601.00833", "abs": "https://arxiv.org/abs/2601.00833", "authors": ["Tangtang Wang", "Kaijie Zhang", "Kuangcong Liu"], "title": "A Knowledge Graph and Deep Learning-Based Semantic Recommendation Database System for Advertisement Retrieval and Personalization", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "In modern digital marketing, the growing complexity of advertisement data demands intelligent systems capable of understanding semantic relationships among products, audiences, and advertising content. To address this challenge, this paper proposes a Knowledge Graph and Deep Learning-Based Semantic Recommendation Database System (KGSR-ADS) for advertisement retrieval and personalization. The proposed framework integrates a heterogeneous Ad-Knowledge Graph (Ad-KG) that captures multi-relational semantics, a Semantic Embedding Layer that leverages large language models (LLMs) such as GPT and LLaMA to generate context-aware vector representations, a GNN + Attention Model that infers cross-entity dependencies, and a Database Optimization & Retrieval Layer based on vector indexing (FAISS/Milvus) for efficient semantic search. This layered architecture enables both accurate semantic matching and scalable retrieval, allowing personalized ad recommendations under large-scale heterogeneous workloads.", "AI": {"tldr": "设计了一种基于知识图谱和深度学习的广告推荐数据库系统，用于实现精准个性化的广告检索与推荐。", "motivation": "现代数字营销中，广告数据复杂性增加，需要智能系统理解产品、受众和广告内容间的语义关系。", "method": "通过异构广告知识图谱捕捉多关系语义信息，使用大语言模型生成上下文感知向量表示，并结合GNN+注意力机制进行跨实体依赖推理，采用基于矢量索引的数据库优化与检索层实现高效语义搜索。", "result": "系统实现了准确的语义匹配和可扩展性检索，适合大规模异构工作负载下的个性化广告推荐。", "conclusion": "所提框架有效解决了现代数字营销中的广告数据复杂性和精准个性化的挑战。"}}
{"id": "2601.00832", "pdf": "https://arxiv.org/pdf/2601.00832", "abs": "https://arxiv.org/abs/2601.00832", "authors": ["Israk Hasan Jone", "D. M. Rafiun Bin Masud", "Promit Sarker", "Sayed Fuad Al Labib", "Nazmul Islam", "Farhad Billah"], "title": "ShrimpXNet: A Transfer Learning Framework for Shrimp Disease Classification with Augmented Regularization, Adversarial Training, and Explainable AI", "categories": ["cs.LG", "cs.CV"], "comment": "8 Page, fugure 11", "summary": "Shrimp is one of the most widely consumed aquatic species globally, valued for both its nutritional content and economic importance. Shrimp farming represents a significant source of income in many regions; however, like other forms of aquaculture, it is severely impacted by disease outbreaks. These diseases pose a major challenge to sustainable shrimp production. To address this issue, automated disease classification methods can offer timely and accurate detection. This research proposes a deep learning-based approach for the automated classification of shrimp diseases. A dataset comprising 1,149 images across four disease classes was utilized. Six pretrained deep learning models, ResNet50, EfficientNet, DenseNet201, MobileNet, ConvNeXt-Tiny, and Xception were deployed and evaluated for performance. The images background was removed, followed by standardized preprocessing through the Keras image pipeline. Fast Gradient Sign Method (FGSM) was used for enhancing the model robustness through adversarial training. While advanced augmentation strategies, including CutMix and MixUp, were implemented to mitigate overfitting and improve generalization. To support interpretability, and to visualize regions of model attention, post-hoc explanation methods such as Grad-CAM, Grad-CAM++, and XGrad-CAM were applied. Exploratory results demonstrated that ConvNeXt-Tiny achieved the highest performance, attaining a 96.88% accuracy on the test dataset. After 1000 iterations, the 99% confidence interval for the model is [0.953,0.971].", "AI": {"tldr": "该论文提出了一种基于深度学习的虾病自动分类方法，采用了预训练模型、增强正则化和可解释性AI技术。", "motivation": "为了应对水产养殖中疾病爆发对可持续虾类生产的挑战，提供及时准确的检测方案。", "method": "使用了六个预训练模型进行评估，并通过Fast Gradient Sign Method（FGSM）提升模型鲁棒性，同时采用CutMix和MixUp等增强策略以减少过拟合并提高泛化能力；利用Grad-CAM、Grad-CAM++和XGrad-CAM可视化模型关注区域。", "result": "实验结果表明，ConvNeXt-Tiny模型表现最佳，在测试数据集上达到了96.88%的准确率。经过1000次迭代后，99％置信区间为[0.953,0.971]。", "conclusion": "该研究成功开发了一种基于深度学习的虾病分类框架，并证明了ConvNeXt-Tiny模型的有效性及泛化能力。"}}
{"id": "2601.00830", "pdf": "https://arxiv.org/pdf/2601.00830", "abs": "https://arxiv.org/abs/2601.00830", "authors": ["Deep Pankajbhai Mehta"], "title": "Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning", "categories": ["cs.AI"], "comment": "22 pages, 8 figures, 9 tables", "summary": "When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. This suggests models see influential information but choose not to report it. Telling models they are being watched does not help. Forcing models to report hints works, but causes them to report hints even when none exist and reduces their accuracy. We also found that hints appealing to user preferences are especially dangerous-models follow them most often while reporting them least. These findings suggest that simply watching AI reasoning is not enough to catch hidden influences.", "AI": {"tldr": "研究通过嵌入提示来测试AI模型是否在其解释中提到这些影响因素，以评估AI解释的可靠性。", "motivation": "探究当AI系统提供逐步推理时，这些解释是否真正揭示了影响其答案的因素。", "method": "在超过9,000个案例和11种顶级AI模型上进行测试，嵌入提示并在没有直接询问的情况下观察模型是否会提到它们；然后要求模型明确指出是否存在这些提示，并评估结果。", "result": "发现AI模型几乎从不自发地提及影响因素，但在被直接问及时会承认注意到它们。强迫模型报告提示会导致其错误报告不存在的提示并降低准确性。", "conclusion": "简单的观察不足以检测隐藏的影响因素，需要进一步研究和改进以提高AI解释的透明度和可靠性。"}}
{"id": "2601.00829", "pdf": "https://arxiv.org/pdf/2601.00829", "abs": "https://arxiv.org/abs/2601.00829", "authors": ["Alexander Vinogradov"], "title": "Can Generative Models Actually Forge Realistic Identity Documents?", "categories": ["cs.CV"], "comment": "11 pages, 16 figures", "summary": "Generative image models have recently shown significant progress in image realism, leading to public concerns about their potential misuse for document forgery. This paper explores whether contemporary open-source and publicly accessible diffusion-based generative models can produce identity document forgeries that could realistically bypass human or automated verification systems. We evaluate text-to-image and image-to-image generation pipelines using multiple publicly available generative model families, including Stable Diffusion, Qwen, Flux, Nano-Banana, and others. The findings indicate that while current generative models can simulate surface-level document aesthetics, they fail to reproduce structural and forensic authenticity. Consequently, the risk of generative identity document deepfakes achieving forensic-level authenticity may be overestimated, underscoring the value of collaboration between machine learning practitioners and document-forensics experts in realistic risk assessment.", "AI": {"tldr": "探讨现有生成模型是否能伪造真实的身份证件", "motivation": "随着图像生成技术的进步，公众担忧其被用于伪造证件。研究目的是评估当前开放源代码的生成模型能否生产出足以欺骗人类或自动化验证系统的身份文件。", "method": "使用包括Stable Diffusion、Qwen等在内的多个公开生成模型家族进行文本到图像和图像到图像的生成测试", "result": "发现现有生成模型虽能模拟证件表面真实感，但无法复制结构和技术上的真实性", "conclusion": "当前技术下利用生成模型伪造身份证件达到法证级别真实性的风险可能被高估，建议机器学习专家与文档取证专家合作进行更现实的风险评估"}}
{"id": "2601.00828", "pdf": "https://arxiv.org/pdf/2601.00828", "abs": "https://arxiv.org/abs/2601.00828", "authors": ["Yin Li"], "title": "Decomposing LLM Self-Correction: The Accuracy-Correction Paradox and Error Depth Hypothesis", "categories": ["cs.AI"], "comment": "9 pages, 2 figures, 3 tables. Code available at https://github.com/Kevin0304-li/llm-self-correction", "summary": "Large Language Models (LLMs) are widely believed to possess self-correction capabilities, yet recent studies suggest that intrinsic self-correction--where models correct their own outputs without external feedback--remains largely ineffective. In this work, we systematically decompose self-correction into three distinct sub-capabilities: error detection, error localization, and error correction. Through cross-model experiments on GSM8K-Complex (n=500 per model, 346 total errors) with three major LLMs, we uncover a striking Accuracy-Correction Paradox: weaker models (GPT-3.5, 66% accuracy) achieve 1.6x higher intrinsic correction rates than stronger models (DeepSeek, 94% accuracy)--26.8% vs 16.7%. We propose the Error Depth Hypothesis: stronger models make fewer but deeper errors that resist self-correction. Error detection rates vary dramatically across architectures (10% to 82%), yet detection capability does not predict correction success--Claude detects only 10% of errors but corrects 29% intrinsically. Surprisingly, providing error location hints hurts all models. Our findings challenge linear assumptions about model capability and self-improvement, with important implications for the design of self-refinement pipelines.", "AI": {"tldr": "本文系统性地分解了大型语言模型的自我纠正能力，并通过实验验证了一个准确性-纠正悖论：较弱的模型比较强的模型具有更高的内在纠正率。", "motivation": "揭示大型语言模型在自我纠正过程中存在的问题，挑战线性的假设并提出新的理论来解释这些现象。", "method": "设计了针对不同模型（GPT-3.5、DeepSeek）进行交叉实验的方法，使用GSM8K-Complex数据集验证误差检测、定位和纠正的能力，并提出了错误深度假说。", "result": "较弱的模型在自我纠正方面表现更佳；不同架构下的模型，在错误检测率上有显著差异，但这些差异并不一定与纠正成功率相关；提供错误位置提示反而会降低所有模型的表现。", "conclusion": "研究结果挑战了关于语言模型能力及其自我改进过程中的线性假设，并对设计自修正流程提出了重要启示。"}}
{"id": "2601.00827", "pdf": "https://arxiv.org/pdf/2601.00827", "abs": "https://arxiv.org/abs/2601.00827", "authors": ["Mariam Saeed", "Manar Amr", "Farida Adel", "Nada Hassan", "Nour Walid", "Eman Mohamed", "Mohamed Hussein", "Marwan Torki"], "title": "Speak the Art: A Direct Speech to Image Generation Framework", "categories": ["eess.AS", "cs.AI", "cs.MM"], "comment": null, "summary": "Direct speech-to-image generation has recently shown promising results. However, compared to text-to-image generation, there is still a large gap to enclose. Current approaches use two stages to tackle this task: speech encoding network and image generative adversarial network (GAN). The speech encoding networks in these approaches produce embeddings that do not capture sufficient linguistic information to semantically represent the input speech. GANs suffer from issues such as non-convergence, mode collapse, and diminished gradient, which result in unstable model parameters, limited sample diversity, and ineffective generator learning, respectively. To address these weaknesses, we introduce a framework called \\textbf{Speak the Art (STA)} which consists of a speech encoding network and a VQ-Diffusion network conditioned on speech embeddings. To improve speech embeddings, the speech encoding network is supervised by a large pre-trained image-text model during training. Replacing GANs with diffusion leads to more stable training and the generation of diverse images. Additionally, we investigate the feasibility of extending our framework to be multilingual. As a proof of concept, we trained our framework with two languages: English and Arabic. Finally, we show that our results surpass state-of-the-art models by a large margin.", "AI": {"tldr": "提出了一种直接从语音生成图像的框架Speak the Art (STA)，改进了现有的两阶段方法，提高语音嵌入的质量并使用扩散模型替代GAN。", "motivation": "现有技术在语音到图像生成中存在不足，包括语言信息捕获不充分和GAN带来的不稳定训练问题。因此需要一种新的方法来改善这些问题。", "method": "框架STA包含一个改进的语音编码网络（由预训练的图文模型监督）和一个基于扩散的条件生成器（以改进后的语音嵌入为条件）。此外，该框架还进行了多语言扩展。", "result": "实验结果表明，所提出的方法在语音到图像生成任务上显著超越了现有的SOTA方法。", "conclusion": "通过引入STA框架，解决了传统方法中遇到的问题，并展示了其在多种语言上的可行性及优越性。"}}
{"id": "2601.00826", "pdf": "https://arxiv.org/pdf/2601.00826", "abs": "https://arxiv.org/abs/2601.00826", "authors": ["Luis M. Moreno-Saavedra", "Vinıcius G. Costa", "Adrian Garrido-Saez", "Silvia Jimenez-Fernandez", "Antonio Portilla-Figueras", "Sancho Salcedo-Sanz"], "title": "Evolutionary optimization of spatially-distributed multi-sensors placement for indoor surveillance environments with security levels", "categories": ["cs.NE"], "comment": null, "summary": "The surveillance multisensor placement is an important optimization problem that consists of positioning several sensors of different types to maximize the coverage of a determined area while minimizing the cost of the deployment. In this work, we tackle a modified version of the problem, consisting of spatially distributed multisensor placement for indoor surveillance. Our approach is focused on security surveillance of sensible indoor spaces, such as military installations, where distinct security levels can be considered. We propose an evolutionary algorithm to solve the problem, in which a novel special encoding,integer encoding with binary conversion, and effective initialization have been defined to improve the performance and convergence of the proposed algorithm. We also consider the probability of detection for each surveillance point, which depends on the distance to the sensor at hand, to better model real-life scenarios. We have tested the proposed evolutionary approach in different instances of the problem, varying both size and difficulty, and obtained excellent results in terms of the cost of sensors placement and convergence time of the algorithm.", "AI": {"tldr": "本文提出了一种进化算法来优化室内监控环境中多传感器的分布和部署，以实现不同安全级别的最佳覆盖。", "motivation": "在军事设施等敏感室内空间中，需要有效布置多种类型的传感器来确保最大化的区域覆盖率，并且最小化部署成本。为了更好地模拟现实场景，研究考虑了每个监测点检测的概率与距离的关系。", "method": "提出了一种进化算法，采用新型特殊编码（整数编码和二进制转换）及有效的初始化策略以提高性能和收敛性。", "result": "在不同规模和难度的问题实例中测试该算法后发现，在传感器部署成本和算法收敛时间方面取得了优秀的结果。", "conclusion": "所提出的进化方法能够有效解决室内多传感器布局问题，尤其适用于具有多个安全级别的复杂环境。"}}
{"id": "2601.00823", "pdf": "https://arxiv.org/pdf/2601.00823", "abs": "https://arxiv.org/abs/2601.00823", "authors": ["Austin R. Ellis-Mohr", "Max Hartman", "Lav R. Varshney"], "title": "Energy-Aware Routing to Large Reasoning Models", "categories": ["cs.AI", "cs.IT", "eess.SY"], "comment": null, "summary": "Large reasoning models (LRMs) have heterogeneous inference energy costs based on which model is used and how much it reasons. To reduce energy, it is important to choose the right LRM and operate it in the right way. As a result, the performance of systems that dispatch tasks to different individual LRMs depend on the balance between mean energy provisioning and stochastic fluctuations. The critical regime is the unique operating point at which neither auxiliary energy nor baseline energy is systematically wasted. Increasing baseline supply shifts the system toward persistent over-supply and baseline-energy waste, while reducing supply induces persistent reliance on auxiliary energy. Yet in this regime, performance remains volatility-limited and so a second-order characterization provides further insights that we develop. Here, performance is governed by how variability is absorbed across time, models, and execution choices. This perspective highlights variance-aware routing and dispatch as a principled design axis, and provides a theoretical basis for developing energy-aware model routing policies. Routing behavior is characterized when dispatch policies are based on training-compute and inference-compute scaling laws for LRMs.", "AI": {"tldr": "本文研究了在不同的大型推理模型之间调度任务时的能量优化策略，提出了基于训练计算和推断计算扩展规律的变异性感知路由方法。", "motivation": "大型推理模型具有异构能量消耗特征，选择合适的模型并以正确的方式操作对于减少能耗至关重要。现有的系统性能受到平均能源供应与随机波动之间的平衡影响，在临界操作点上，既不会浪费辅助能也不会浪费基线能。", "method": "通过分析不同规模的大型推理模型在训练和推断过程中计算扩展的规律，本文开发了一种基于时间、模型及执行选项间吸收变异性的变异性感知路由策略。", "result": "文中提出的能量感知路由策略可以在不牺牲性能的情况下减少能源浪费，并且为系统提供了理论基础以优化调度策略。", "conclusion": "通过探索不同大型推理模型的能量消耗特性，本文展示了如何利用计算扩展规律进行有效的任务调度，从而提高系统的整体能效。"}}
