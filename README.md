# ğŸš€ arXiv-crawler-ai-enhanced

> [!CAUTION]
> è‹¥æ‚¨æ‰€åœ¨æ³•åŸŸå¯¹å­¦æœ¯æ•°æ®æœ‰å®¡æŸ¥è¦æ±‚ï¼Œè°¨æ…è¿è¡Œæœ¬ä»£ç ï¼›ä»»ä½•äºŒæ¬¡åˆ†å‘ç‰ˆæœ¬å¿…é¡»å±¥è¡Œåˆè§„å®¡æŸ¥ï¼ˆåŒ…æ‹¬ä½†ä¸é™äºåŸå§‹è®ºæ–‡åˆè§„æ€§ã€AIåˆè§„æ€§ï¼‰ä¹‰åŠ¡ï¼Œå¦åˆ™ä¸€åˆ‡æ³•å¾‹åæœç”±ä¸‹æ¸¸è‡ªè¡Œæ‰¿æ‹…ã€‚

> [!CAUTION]
> If your jurisdiction has censorship requirements for academic data, run this code with caution; any secondary distribution version must remove the entrance accessible to China and fulfill the content review obligations, otherwise all legal consequences will be borne by the downstream.

## ğŸ“ ä»“åº“è¯´æ˜

æœ¬ä»“åº“æ˜¯**daily-arXiv-ai-enhanced**å’Œ**arxiv_crawler**ä¸¤ä¸ªä»“åº“çš„èåˆç‰ˆæœ¬ï¼Œæ•´åˆäº†ä¸¤ä¸ªé¡¹ç›®çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œå®ç°äº†ä¸€ä¸ªå¼ºå¤§ã€çµæ´»çš„arxivè®ºæ–‡å¤„ç†ç³»ç»Ÿï¼š

- **daily-arXiv-ai-enhanced**ï¼šæä¾›äº†AIå¢å¼ºçš„arxivè®ºæ–‡é˜…è¯»ä½“éªŒï¼ŒåŒ…æ‹¬è‡ªåŠ¨åŒ–çˆ¬å–ã€AIæ‘˜è¦ç”Ÿæˆå’Œç¾è§‚çš„Webç•Œé¢
- **arxiv_crawler**ï¼šæä¾›äº†å¼ºå¤§çš„arxivè®ºæ–‡çˆ¬å–åŠŸèƒ½ï¼Œæ”¯æŒå¼‚æ­¥å¿«é€Ÿçˆ¬å–ï¼Œè‡ªå®šä¹‰åˆ†ç±»ã€å…³é”®è¯æœç´¢å’Œå¤šè¯­è¨€ç¿»è¯‘

é€šè¿‡èåˆè¿™ä¸¤ä¸ªä»“åº“ï¼Œæˆ‘ä»¬å®ç°äº†æ›´å¼ºå¤§ã€æ›´çµæ´»çš„arxivè®ºæ–‡å¤„ç†ç³»ç»Ÿï¼Œè®ºæ–‡æ•°æ®ä½¿ç”¨SQLiteæ•°æ®åº“ç®¡ç†ï¼ŒåŒæ—¶ä¿æŒäº†ä»£ç çš„å¯ç»´æŠ¤æ€§å’Œæ‰©å±•æ€§ã€‚

## âœ¨ æ ¸å¿ƒåŠŸèƒ½

ğŸ¯ **æ— éœ€åŸºç¡€è®¾æ–½**
- åˆ©ç”¨GitHub Actionså’ŒPages - æ— éœ€æœåŠ¡å™¨
- éƒ¨ç½²å’Œä½¿ç”¨å®Œå…¨å…è´¹
- é›¶è¿ç»´æˆæœ¬

ğŸ¤– **æ™ºèƒ½AIæ‘˜è¦**
- æ¯æ—¥è‡ªåŠ¨çˆ¬å–è®ºæ–‡ï¼Œä½¿ç”¨DeepSeekç”Ÿæˆç»“æ„åŒ–æ‘˜è¦
- æˆæœ¬æ•ˆç›Šé«˜ï¼šæ¯å¤©ä»…éœ€çº¦0.2å…ƒ
- æ”¯æŒå¯é…ç½®çš„å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ï¼Œæ€§èƒ½ä¼˜å¼‚
- ç»“æ„åŒ–è¾“å‡ºï¼šåŒ…æ‹¬tldrã€motivationã€methodã€resultã€conclusionç­‰

ğŸ’« **æ™ºèƒ½é˜…è¯»ä½“éªŒ**
- åŸºäºå…´è¶£çš„ä¸ªæ€§åŒ–è®ºæ–‡é«˜äº®
- è·¨è®¾å¤‡å…¼å®¹ï¼ˆæ¡Œé¢ç«¯å’Œç§»åŠ¨ç«¯ï¼‰
- æœ¬åœ°å­˜å‚¨åå¥½è®¾ç½®ï¼Œä¿æŠ¤éšç§
- çµæ´»çš„æ—¥æœŸèŒƒå›´ç­›é€‰
- æ”¯æŒå…³é”®è¯æœç´¢

ğŸ”§ **å¼ºå¤§çš„çˆ¬è™«æ”¯æŒ**
- é«˜çº§arxiv_crawleræ¨¡å—ï¼Œé…ç½®é€‰é¡¹ä¸°å¯Œ
- æ˜“ç”¨çš„run_crawler.pyè„šæœ¬
- æ”¯æŒç”ŸæˆJSONLæ–‡ä»¶å’ŒAIå¢å¼ºçš„JSONLæ–‡ä»¶
- é€šè¿‡ç¯å¢ƒå˜é‡é«˜åº¦å¯é…ç½®
- æ”¯æŒå…¨é‡æ›´æ–°å’Œå¢é‡æ›´æ–°ä¸¤ç§æ¨¡å¼

ğŸ“Š **æ•°æ®ç®¡ç†**
- ä½¿ç”¨SQLiteæ•°æ®åº“å­˜å‚¨è®ºæ–‡æ•°æ®
- æ”¯æŒæ•°æ®çš„å¢åˆ æ”¹æŸ¥
- é«˜æ•ˆçš„æ—¥æœŸç´¢å¼•
- æ”¯æŒæ•°æ®å¯¼å‡ºä¸ºå¤šç§æ ¼å¼

## ğŸ“¦ æœ¬åœ°éƒ¨ç½²

### å‰ç½®è¦æ±‚
- Python 3.8+ï¼ˆæ¨è3.10+ï¼‰
- Git
- å¯é€‰ï¼šNode.jsï¼ˆç”¨äºé«˜çº§HTTPæœåŠ¡å™¨ï¼‰

### å®‰è£…æ­¥éª¤

1. **å…‹éš†ä»“åº“**ï¼š
   ```bash
   git clone https://github.com/dw-dengwei/daily-arXiv-ai-enhanced.git
   cd daily-arXiv-ai-enhanced
   ```

2. **åˆ›å»ºå¹¶æ¿€æ´»condaç¯å¢ƒ**ï¼š
   ```bash
   # åˆ›å»ºcondaç¯å¢ƒ
   conda create -n arxiv-crawler python=3.10 -y
   
   # æ¿€æ´»ç¯å¢ƒï¼ˆWindows/Linux/Macé€šç”¨ï¼‰
   conda activate arxiv-crawler
   ```

3. **å®‰è£…ä¾èµ–**ï¼š
   ```bash
   pip install -r requirements.txt
   ```

4. **é…ç½®ç¯å¢ƒå˜é‡**ï¼š
   ```bash
   cp .env.example .env
   # ç¼–è¾‘.envæ–‡ä»¶ï¼Œé…ç½®APIå¯†é’¥å’Œå…¶ä»–å‚æ•°
   ```

### ç¯å¢ƒå˜é‡é…ç½®

æœ¬é¡¹ç›®é€šè¿‡ç¯å¢ƒå˜é‡è¿›è¡Œå…¨é¢é…ç½®ï¼Œæ‰€æœ‰å…³é”®å‚æ•°å‡å¯åœ¨`.env`æ–‡ä»¶ä¸­è®¾ç½®ï¼š

```env
# DeepSeek APIé…ç½®
OPENAI_API_KEY="your-api-key"          # DeepSeek APIå¯†é’¥
OPENAI_BASE_URL="https://api.deepseek.com"  # DeepSeek APIåŸºç¡€URL
MODEL_NAME="deepseek-chat"           # é»˜è®¤æ¨¡å‹åç§°
LANGUAGE="Chinese"                   # AIç”Ÿæˆå†…å®¹çš„è¯­è¨€

# çˆ¬è™«è¡Œä¸ºé…ç½®
MAX_WORKERS=4                        # AIå¢å¼ºçš„æœ€å¤§å¹¶è¡Œæ•°
CRAWL_ALL=false                      # çˆ¬å–æ¨¡å¼ï¼štrueè¡¨ç¤ºå…¨é‡æ›´æ–°ï¼Œfalseè¡¨ç¤ºå¢é‡æ›´æ–°
CRAWL_DATE=""                        # æŒ‡å®šçˆ¬å–æ—¥æœŸï¼Œæ ¼å¼ä¸ºYYYY-MM-DDï¼Œç•™ç©ºè¡¨ç¤ºä»Šå¤©

# è®ºæ–‡ç­›é€‰é…ç½®
CATEGORY_WHITELIST=cs.CV,cs.AI,cs.DS,cs.ET,cs.HC,cs.NE,cs.RO,cs.SD,eess.AS,eess.IV  # è®ºæ–‡åˆ†ç±»ç™½åå•
CATEGORY_BLACKLIST=                  # è®ºæ–‡åˆ†ç±»é»‘åå•ï¼Œä½¿ç”¨é€—å·åˆ†éš”
OPTIONAL_KEYWORDS=cs.CV,cs.AI,cs.DS,cs.ET,cs.HC,cs.NE,cs.RO,cs.SD,eess.AS,eess.IV  # å¯é€‰å…³é”®è¯

# ç¿»è¯‘é…ç½®
TRANS_TO=zh-CN                       # ç¿»è¯‘ç›®æ ‡è¯­è¨€ï¼Œç•™ç©ºè¡¨ç¤ºä¸ç¿»è¯‘
TRANSLATION_SEMAPHORE=80             # ç¿»è¯‘å¹¶å‘é™åˆ¶

# ç½‘ç»œé…ç½®
PROXY=                               # ä»£ç†è®¾ç½®ï¼Œæ ¼å¼ä¸ºhttp://127.0.0.1:7890ï¼Œç•™ç©ºè¡¨ç¤ºä¸ä½¿ç”¨ä»£ç†

# çˆ¬å–å‚æ•°é…ç½®
STEP=50                              # æ¯é¡µçˆ¬å–æ•°é‡

# éƒ¨ç½²ä¸å®‰å…¨é…ç½®
ACCESS_PASSWORD=                     # é¡µé¢è®¿é—®å¯†ç ï¼Œç•™ç©ºè¡¨ç¤ºä¸ä½¿ç”¨å¯†ç ä¿æŠ¤
EMAIL=your-email@example.com         # GitHubæäº¤é‚®ç®±ï¼Œç”¨äºGitHub Actionsè‡ªåŠ¨éƒ¨ç½²
NAME=your-github-username            # GitHubæäº¤ç”¨æˆ·åï¼Œç”¨äºGitHub Actionsè‡ªåŠ¨éƒ¨ç½²
```

## ğŸš€ è¿è¡Œçˆ¬è™«

### ä½¿ç”¨run_crawler.pyè„šæœ¬

```bash
# è¿è¡Œçˆ¬è™«ï¼Œä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
python run_crawler.py

# è¿è¡Œçˆ¬è™«ï¼ŒæŒ‡å®šæ—¥æœŸ
python run_crawler.py --date 2025-12-05

# è¿è¡Œçˆ¬è™«ï¼Œå…¨é‡æ›´æ–°(æ„å»ºä¸ªäººæœ¬åœ°æ•°æ®åº“ï¼Œé¦–æ¬¡è¿è¡Œå…ˆæ‰§è¡Œå…¨é‡æ›´æ–°)
python run_crawler.py --all

# ç»“åˆä½¿ç”¨ï¼šå…¨é‡æ›´æ–°+æŒ‡å®šæ—¥æœŸ
python run_crawler.py --all --date 2025-12-05
```

### å‚æ•°è¯´æ˜
- `--all`ï¼š**æ ‡å¿—å‚æ•°**ï¼Œä¸éœ€è¦è·Ÿå€¼ã€‚å½“å‡ºç°è¯¥å‚æ•°æ—¶ï¼Œè¡¨ç¤ºå…¨é‡æ›´æ–°å½“æœˆè®ºæ–‡ï¼›ä¸å‡ºç°æ—¶ï¼Œè¡¨ç¤ºå¢é‡æ›´æ–°å½“å¤©è®ºæ–‡
- `--date`ï¼šæŒ‡å®šè¦çˆ¬å–çš„æ—¥æœŸï¼Œæ ¼å¼ä¸ºYYYY-MM-DDï¼Œç•™ç©ºè¡¨ç¤ºä»Šå¤©
- ä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼

### è„šæœ¬è¾“å‡º

è¿è¡Œçˆ¬è™«åï¼Œä½ å°†çœ‹åˆ°ç±»ä¼¼ä»¥ä¸‹çš„è¾“å‡ºï¼š

```
--- ç¯å¢ƒå˜é‡é…ç½® ---
CRAWL_ALL: false
CRAWL_DATE:
MAX_WORKERS: 20
CATEGORY_BLACKLIST:
CATEGORY_WHITELIST: cs.CV,cs.AI,cs.DS,cs.ET,cs.HC,cs.NE,cs.RO,cs.SD,eess.AS,eess.IV
OPTIONAL_KEYWORDS: cs.CV,cs.AI,cs.DS,cs.ET,cs.HC,cs.NE,cs.RO,cs.SD,eess.AS,eess.IV
TRANS_TO: zh-CN
PROXY: http://127.0.0.1:10808
STEP: 50
------------------

å¼€å§‹çˆ¬å– 2025-12-05 çš„è®ºæ–‡æ•°æ®ï¼Œæ¨¡å¼ï¼šå¢é‡æ›´æ–°ï¼ŒAIå¹¶è¡Œæ•°ï¼š20
[22:49:40] last update: 2025-12-06 13:39:01, next arxiv update: 2025-12-08                        arxiv_crawler.py:225
           UTC now: 2025-12-06 14:49:39                                                           arxiv_crawler.py:228
           Your database is already up to date.                                                   arxiv_crawler.py:231
ç”Ÿæˆmarkdownæ–‡ä»¶...
[22:49:40] Output 2025-12-05.md completed. 196 papers chosen, 0 papers filtered                             paper.py:515
ç”Ÿæˆæ ‡å‡†JSONLæ–‡ä»¶...
           Output 2025-12-05.jsonl completed. 196 papers exported                                         paper.py:590
ç”ŸæˆAIå¢å¼ºçš„JSONLæ–‡ä»¶...
ç”ŸæˆAIå¢å¼ºçš„JSONLæ–‡ä»¶å¤±è´¥ï¼Œä½†å°†ç»§ç»­æ‰§è¡Œ: 'PaperExporter' object has no attribute 'to_ai_enhanced_jsonl'
æ›´æ–°assets/file-list.txt...
å·²æ›´æ–°file-list.txtï¼Œæ·»åŠ äº† 3 ä¸ªæ–°æ–‡ä»¶
çˆ¬å–å’Œç”Ÿæˆå®Œæˆï¼
```

## ğŸŒ æœ¬åœ°é¢„è§ˆ

### è¿è¡Œæœ¬åœ°HTTPæœåŠ¡

åœ¨æœ¬åœ°è¿è¡ŒHTTPæœåŠ¡ï¼Œæ–¹ä¾¿é¢„è§ˆç”Ÿæˆçš„è®ºæ–‡å†…å®¹ï¼š

#### æ–¹æ³•1ï¼šä½¿ç”¨Pythonå†…ç½®HTTPæœåŠ¡å™¨ï¼ˆæ¨èï¼Œæ— éœ€é¢å¤–ä¾èµ–ï¼‰
```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
python -m http.server 8000
```

ç„¶ååœ¨æµè§ˆå™¨ä¸­è®¿é—®ï¼š`http://localhost:8000`

#### æ–¹æ³•2ï¼šä½¿ç”¨http-serverï¼ˆæ”¯æŒè‡ªåŠ¨é‡è½½ï¼‰
```bash
# å…ˆå®‰è£…http-server
npm install -g http-server

# åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼Œå¯ç”¨è‡ªåŠ¨é‡è½½
http-server -p 8000 -o -c-1
```

ç„¶ååœ¨æµè§ˆå™¨ä¸­è®¿é—®ï¼š`http://localhost:8000`

#### æ–¹æ³•3ï¼šä½¿ç”¨live-serverï¼ˆæ”¯æŒå®æ—¶é¢„è§ˆï¼‰
```bash
# å…ˆå®‰è£…live-server
npm install -g live-server

# åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
live-server --port=8000
```

ç„¶ååœ¨æµè§ˆå™¨ä¸­è®¿é—®ï¼š`http://localhost:8000`

### è®¿é—®æœ¬åœ°æœåŠ¡

1. è¿è¡ŒHTTPæœåŠ¡åï¼Œåœ¨æµè§ˆå™¨ä¸­è¾“å…¥å¯¹åº”çš„URLï¼ˆå¦‚`http://localhost:8000`ï¼‰
2. é¡µé¢ä¼šæ˜¾ç¤ºè®ºæ–‡åˆ—è¡¨ï¼Œç‚¹å‡»ä»»æ„è®ºæ–‡å¯ä»¥æŸ¥çœ‹è¯¦ç»†å†…å®¹
3. ä½¿ç”¨é¡µé¢é¡¶éƒ¨çš„æœç´¢æ¡†å’Œç­›é€‰å™¨æŸ¥æ‰¾æ„Ÿå…´è¶£çš„è®ºæ–‡
4. æœ¬åœ°æœåŠ¡ä»…åœ¨æ‚¨çš„è®¡ç®—æœºä¸Šå¯ç”¨ï¼Œä¸ä¼šè¢«å¤–éƒ¨è®¿é—®

## ğŸ› ï¸ è°ƒè¯•ä¸æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

#### é—®é¢˜1ï¼šç”ŸæˆAIå¢å¼ºæ–‡ä»¶å¤±è´¥
**é”™è¯¯ä¿¡æ¯**ï¼š`'PaperExporter' object has no attribute 'to_ai_enhanced_jsonl'`

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥`paper.py`æ–‡ä»¶ä¸­æ˜¯å¦å­˜åœ¨`to_ai_enhanced_jsonl`æ–¹æ³•
2. ç¡®ä¿ä»£ç æ˜¯æœ€æ–°ç‰ˆæœ¬ï¼Œå°è¯•é‡æ–°å…‹éš†ä»“åº“
3. æ£€æŸ¥`arxiv_crawler.py`ä¸­æ˜¯å¦æ­£ç¡®è°ƒç”¨äº†è¯¥æ–¹æ³•

#### é—®é¢˜2ï¼šæ•æ„Ÿè¯æ£€æµ‹è¶…æ—¶
**é”™è¯¯ä¿¡æ¯**ï¼š`Sensitive check error: HTTPSConnectionPool(host='spam.dw-dengwei.workers.dev', port=443): Read timed out. (read timeout=5)`

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ç¼–è¾‘`ai/enhance.py`æ–‡ä»¶ï¼Œä¿®æ”¹æ•æ„Ÿè¯æ£€æµ‹çš„è¶…æ—¶æ—¶é—´
2. æˆ–è€…æš‚æ—¶ç¦ç”¨æ•æ„Ÿè¯æ£€æµ‹ï¼ˆæ³¨é‡Šç›¸å…³ä»£ç ï¼‰

#### é—®é¢˜3ï¼šæ•°æ®åº“è¿æ¥å¤±è´¥
**é”™è¯¯ä¿¡æ¯**ï¼š`sqlite3.OperationalError: unable to open database file`

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶çš„æƒé™
2. ç¡®ä¿å½“å‰ç”¨æˆ·æœ‰è¯»å†™æƒé™
3. å°è¯•é‡æ–°åˆ›å»ºæ•°æ®åº“

#### é—®é¢˜4ï¼šçˆ¬å–é€Ÿåº¦æ…¢
**è§£å†³æ–¹æ¡ˆ**ï¼š
1. è°ƒæ•´`STEP`å‚æ•°ï¼Œå¢åŠ æ¯é¡µçˆ¬å–æ•°é‡
2. è°ƒæ•´`MAX_WORKERS`å‚æ•°ï¼Œå¢åŠ å¹¶è¡Œæ•°
3. æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œä»£ç†è®¾ç½®

#### é—®é¢˜5ï¼šAIå¢å¼ºé€Ÿåº¦æ…¢
**è§£å†³æ–¹æ¡ˆ**ï¼š
1. è°ƒæ•´`MAX_WORKERS`å‚æ•°ï¼Œå¢åŠ AIç”Ÿæˆçš„å¹¶è¡Œæ•°
2. æ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œè¿æ¥
3. è€ƒè™‘ä½¿ç”¨æ€§èƒ½æ›´å¥½çš„AIæ¨¡å‹

### è°ƒè¯•å·¥å…·ä¸æŠ€å·§

1. **æŸ¥çœ‹æ—¥å¿—**ï¼šè¿è¡Œçˆ¬è™«æ—¶ï¼Œæ§åˆ¶å°ä¼šè¾“å‡ºè¯¦ç»†çš„æ—¥å¿—ä¿¡æ¯ï¼ŒåŒ…æ‹¬çˆ¬å–è¿›åº¦ã€é”™è¯¯ä¿¡æ¯ç­‰
2. **å¯ç”¨è°ƒè¯•æ¨¡å¼**ï¼šåœ¨`run_crawler.py`ä¸­æ·»åŠ `import logging; logging.basicConfig(level=logging.DEBUG)`
3. **ä½¿ç”¨æ•°æ®åº“æŸ¥çœ‹å·¥å…·**ï¼šå¦‚SQLiteBrowserï¼ŒæŸ¥çœ‹æ•°æ®åº“ä¸­çš„æ•°æ®
4. **æµ‹è¯•å•ä¸ªç»„ä»¶**ï¼šç¼–å†™ç®€å•çš„æµ‹è¯•è„šæœ¬ï¼Œæµ‹è¯•å•ä¸ªç»„ä»¶çš„åŠŸèƒ½
5. **æ£€æŸ¥APIå“åº”**ï¼šä½¿ç”¨Postmanæˆ–curlæµ‹è¯•APIå“åº”

## ğŸŒ GitHub Actions çº¿ä¸Šéƒ¨ç½²

### è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹

æœ¬é¡¹ç›®ä½¿ç”¨GitHub Actionså®ç°è‡ªåŠ¨åŒ–éƒ¨ç½²ï¼Œæ¯å¤©è‡ªåŠ¨çˆ¬å–arxivè®ºæ–‡å¹¶ç”ŸæˆAIå¢å¼ºå†…å®¹ï¼Œç„¶åéƒ¨ç½²åˆ°GitHub Pagesã€‚

### é…ç½®æ­¥éª¤

1. **Forkä»“åº“**ï¼šForkæœ¬ä»“åº“åˆ°æ‚¨è‡ªå·±çš„GitHubè´¦æˆ·ã€‚

2. **é…ç½®ç¯å¢ƒå˜é‡**ï¼š
   - ç›´æ¥ä¿®æ”¹ä»“åº“ä¸­çš„`.env`æ–‡ä»¶ï¼Œé…ç½®æ‰€æœ‰å¿…è¦å‚æ•°ï¼š
     - `OPENAI_API_KEY`ï¼šDeepSeek APIå¯†é’¥
     - `OPENAI_BASE_URL`ï¼šDeepSeek APIåŸºç¡€URL
     - `MODEL_NAME`ï¼šä½¿ç”¨çš„å¤§æ¨¡å‹åç§°ï¼ˆå¦‚"deepseek-chat"ï¼‰
     - `LANGUAGE`ï¼šç”Ÿæˆå†…å®¹çš„è¯­è¨€ï¼ˆå¦‚"Chinese"æˆ–"English"ï¼‰
     - `CATEGORY_WHITELIST`ï¼šè¦çˆ¬å–çš„arxivåˆ†ç±»ï¼Œä½¿ç”¨é€—å·åˆ†éš”ï¼ˆå¦‚"cs.CL, cs.CV"ï¼‰
     - å…¶ä»–å‚æ•°æ ¹æ®éœ€è¦è°ƒæ•´
   - æ‰€æœ‰å‚æ•°å‡å¯åœ¨`.env`æ–‡ä»¶ä¸­ç›´æ¥é…ç½®ï¼Œæ— éœ€åœ¨GitHubä»“åº“è®¾ç½®Secretså’ŒVariables

3. **å¯ç”¨GitHub Pages**ï¼š
   - è¿›å…¥æ‚¨çš„ä»“åº“ â†’ Settings â†’ Pages
   - åœ¨Build and deploymentéƒ¨åˆ†ï¼Œè®¾ç½®Sourceä¸º"Deploy from a branch"
   - è®¾ç½®Branchä¸º"main"ï¼Œç›®å½•ä¸º"/(root)"
   - ç‚¹å‡»Save

4. **è¿è¡ŒWorkflow**ï¼š
   - è¿›å…¥æ‚¨çš„ä»“åº“ â†’ Actions
   - é€‰æ‹©"arxiv-daily-ai-enhanced" workflow
   - ç‚¹å‡»"Run workflow"æŒ‰é’®ï¼Œæ‰‹åŠ¨è§¦å‘ç¬¬ä¸€æ¬¡è¿è¡Œ

### è‡ªå®šä¹‰éƒ¨ç½²

- **ä¿®æ”¹çˆ¬å–é¢‘ç‡**ï¼šç¼–è¾‘`.github/workflows/run.yml`æ–‡ä»¶ï¼Œä¿®æ”¹`schedule`éƒ¨åˆ†å¯ä»¥è°ƒæ•´çˆ¬å–é¢‘ç‡
- **ä¿®æ”¹çˆ¬å–åˆ†ç±»**ï¼šç›´æ¥ä¿®æ”¹`.env`æ–‡ä»¶ä¸­çš„`CATEGORY_WHITELIST`å˜é‡
- **ä¿®æ”¹AIæ¨¡å‹**ï¼šç›´æ¥ä¿®æ”¹`.env`æ–‡ä»¶ä¸­çš„`MODEL_NAME`å˜é‡
- **ä¿®æ”¹å…¶ä»–é…ç½®**ï¼šæ‰€æœ‰é…ç½®å‚æ•°å‡å¯åœ¨`.env`æ–‡ä»¶ä¸­ç›´æ¥ä¿®æ”¹

## ğŸ“ é¡¹ç›®ç»“æ„

```
daily-arXiv-ai-enhanced/
â”œâ”€â”€ .github/              # GitHub Actionsé…ç½®
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ run.yml        # è‡ªåŠ¨åŒ–éƒ¨ç½²é…ç½®
â”œâ”€â”€ ai/                   # AIå¢å¼ºæ¨¡å—
â”‚   â”œâ”€â”€ enhance.py        # AIå¢å¼ºæ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ structure.py      # AIè¾“å‡ºç»“æ„å®šä¹‰
â”‚   â”œâ”€â”€ system.txt        # ç³»ç»Ÿæç¤ºè¯
â”‚   â””â”€â”€ template.txt      # æç¤ºè¯æ¨¡æ¿
â”œâ”€â”€ arxiv_crawler/        # çˆ¬è™«æ¨¡å—
â”‚   â”œâ”€â”€ arxiv_crawler.py  # çˆ¬è™«æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ async_translator.py  # å¼‚æ­¥ç¿»è¯‘æ¨¡å—
â”‚   â”œâ”€â”€ categories.py     # åˆ†ç±»æ˜ å°„
â”‚   â””â”€â”€ paper.py          # è®ºæ–‡æ•°æ®ç»“æ„å’Œæ•°æ®åº“æ“ä½œ
â”œâ”€â”€ assets/               # é™æ€èµ„æº
â”‚   â””â”€â”€ file-list.txt     # ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨
â”œâ”€â”€ css/                  # CSSæ ·å¼æ–‡ä»¶
â”œâ”€â”€ data/                 # ç”Ÿæˆçš„æ•°æ®æ–‡ä»¶
â”‚   â”œâ”€â”€ YYYY-MM-DD.jsonl  # æ ‡å‡†è®ºæ–‡æ•°æ®
â”‚   â””â”€â”€ YYYY-MM-DD_AI_enhanced_*.jsonl  # AIå¢å¼ºçš„è®ºæ–‡æ•°æ®
â”œâ”€â”€ output_md/            # ç”Ÿæˆçš„Markdownæ–‡ä»¶
â”‚   â””â”€â”€ YYYY-MM-DD.md     # æ¯æ—¥è®ºæ–‡Markdownæ–‡ä»¶
â”œâ”€â”€ papers.db             # SQLiteæ•°æ®åº“æ–‡ä»¶
â”œâ”€â”€ .env                  # ç¯å¢ƒå˜é‡é…ç½®
â”œâ”€â”€ .env.example          # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â”œâ”€â”€ index.html            # Webç•Œé¢å…¥å£
â”œâ”€â”€ run_crawler.py        # çˆ¬è™«è¿è¡Œè„šæœ¬
â”œâ”€â”€ requirements.txt      # é¡¹ç›®ä¾èµ–
â””â”€â”€ README.md             # é¡¹ç›®è¯´æ˜æ–‡æ¡£
```

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½æ¨¡å—

### 1. çˆ¬è™«æ¨¡å—ï¼ˆarxiv_crawlerï¼‰

#### ä¸»è¦åŠŸèƒ½
- ä»arxiv.orgçˆ¬å–è®ºæ–‡æ•°æ®
- æ”¯æŒæŒ‰æ—¥æœŸèŒƒå›´ã€åˆ†ç±»ã€å…³é”®è¯ç­›é€‰
- æä¾›å¼‚æ­¥ç¿»è¯‘åŠŸèƒ½
- æ”¯æŒå…¨é‡æ›´æ–°å’Œå¢é‡æ›´æ–°ä¸¤ç§æ¨¡å¼
- ä½¿ç”¨å¼‚æ­¥HTTPè¯·æ±‚æé«˜çˆ¬å–æ•ˆç‡

#### æ ¸å¿ƒæ–‡ä»¶
- `arxiv_crawler.py`ï¼šçˆ¬è™«æ ¸å¿ƒä»£ç ï¼Œå¤„ç†HTTPè¯·æ±‚å’ŒHTMLè§£æ
- `async_translator.py`ï¼šå¼‚æ­¥ç¿»è¯‘æ¨¡å—ï¼Œä½¿ç”¨Google Translate API
- `categories.py`ï¼šåˆ†ç±»æ˜ å°„ï¼Œå¤„ç†arxivåˆ†ç±»å’Œä¸­æ–‡åç§°çš„æ˜ å°„
- `paper.py`ï¼šè®ºæ–‡æ•°æ®ç»“æ„å’Œæ•°æ®åº“æ“ä½œ

### 2. AIå¢å¼ºæ¨¡å—ï¼ˆaiï¼‰

#### ä¸»è¦åŠŸèƒ½
- ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆè®ºæ–‡æ‘˜è¦ã€åŠ¨æœºã€æ–¹æ³•ã€ç»“æœç­‰
- æ”¯æŒå¤šè¯­è¨€ç”Ÿæˆ
- æ”¯æŒå¹¶è¡Œå¤„ç†ï¼Œæé«˜æ•ˆç‡
- æä¾›ç»“æ„åŒ–è¾“å‡º
- åŒ…å«æ•æ„Ÿè¯æ£€æµ‹åŠŸèƒ½

#### æ ¸å¿ƒæ–‡ä»¶
- `enhance.py`ï¼šAIå¢å¼ºæ ¸å¿ƒä»£ç ï¼Œå¤„ç†AIç”Ÿæˆå’Œæ•æ„Ÿè¯æ£€æµ‹
- `structure.py`ï¼šAIè¾“å‡ºç»“æ„å®šä¹‰ï¼Œä½¿ç”¨Pydanticæ¨¡å‹
- `system.txt`ï¼šç³»ç»Ÿæç¤ºè¯ï¼ŒæŒ‡å¯¼AIç”Ÿæˆå†…å®¹
- `template.txt`ï¼šæç¤ºè¯æ¨¡æ¿ï¼ŒåŒ…å«ç”Ÿæˆå†…å®¹çš„æ ¼å¼å’Œè¦æ±‚

### 3. æ•°æ®ç®¡ç†æ¨¡å—

#### ä¸»è¦åŠŸèƒ½
- ä½¿ç”¨SQLiteæ•°æ®åº“å­˜å‚¨è®ºæ–‡æ•°æ®
- æ”¯æŒæ•°æ®çš„å¢åˆ æ”¹æŸ¥
- é«˜æ•ˆçš„æ—¥æœŸç´¢å¼•
- æ”¯æŒæ•°æ®å¯¼å‡ºä¸ºå¤šç§æ ¼å¼

#### æ ¸å¿ƒæ–‡ä»¶
- `paper.py`ï¼šåŒ…å«`PaperDatabase`ç±»ï¼Œå¤„ç†æ•°æ®åº“æ“ä½œ
- `papers.db`ï¼šSQLiteæ•°æ®åº“æ–‡ä»¶ï¼Œå­˜å‚¨æ‰€æœ‰è®ºæ–‡æ•°æ®

### 4. Webç•Œé¢æ¨¡å—

#### ä¸»è¦åŠŸèƒ½
- ç¾è§‚çš„è®ºæ–‡æµè§ˆç•Œé¢
- æ”¯æŒæŒ‰å…³é”®è¯æœç´¢
- æ”¯æŒæŒ‰æ—¥æœŸèŒƒå›´ç­›é€‰
- æ”¯æŒä¸ªæ€§åŒ–é«˜äº®
- æ”¯æŒè·¨è®¾å¤‡è®¿é—®

#### æ ¸å¿ƒæ–‡ä»¶
- `index.html`ï¼šWebç•Œé¢å…¥å£
- `css/`ï¼šCSSæ ·å¼æ–‡ä»¶
- `assets/file-list.txt`ï¼šç”Ÿæˆæ–‡ä»¶åˆ—è¡¨ï¼Œç”¨äºWebç•Œé¢åŠ è½½

## ğŸ“Š è¾“å‡ºæ–‡ä»¶æ ¼å¼

### JSONLæ–‡ä»¶

#### æ ‡å‡†JSONLæ–‡ä»¶ï¼ˆdata/YYYY-MM-DD.jsonlï¼‰
åŒ…å«è®ºæ–‡çš„åŸºç¡€ä¿¡æ¯ï¼š
```json
{
  "id": "2512.05117",
  "pdf": "https://arxiv.org/pdf/2512.05117",
  "abs": "https://arxiv.org/abs/2512.05117",
  "authors": ["Author1", "Author2"],
  "title": "The Universal Weight Subspace Hypothesis",
  "categories": ["cs.LG"],
  "comment": null,
  "summary": "We show that deep neural networks trained across diverse tasks exhibit remarkably similar low-dimensional parametric subspaces..."
}
```

#### AIå¢å¼ºJSONLæ–‡ä»¶ï¼ˆdata/YYYY-MM-DD_AI_enhanced_Chinese.jsonlï¼‰
åŒ…å«è®ºæ–‡çš„åŸºç¡€ä¿¡æ¯å’ŒAIç”Ÿæˆçš„ç»“æ„åŒ–æ‘˜è¦ï¼š
```json
{
  "id": "2512.05117",
  "pdf": "https://arxiv.org/pdf/2512.05117",
  "abs": "https://arxiv.org/abs/2512.05117",
  "authors": ["Author1", "Author2"],
  "title": "The Universal Weight Subspace Hypothesis",
  "categories": ["cs.LG"],
  "comment": null,
  "summary": "We show that deep neural networks trained across diverse tasks exhibit remarkably similar low-dimensional parametric subspaces...",
  "AI": {
    "tldr": "æœ¬æ–‡è¯æ˜äº†æ·±åº¦ç¥ç»ç½‘ç»œåœ¨ä¸åŒä»»åŠ¡ä¸Šè®­ç»ƒæ—¶ä¼šè¡¨ç°å‡ºç›¸ä¼¼çš„ä½ç»´å‚æ•°å­ç©ºé—´",
    "motivation": "ç†è§£æ·±åº¦ç¥ç»ç½‘ç»œçš„å­¦ä¹ æœºåˆ¶æ˜¯æ·±åº¦å­¦ä¹ é¢†åŸŸçš„é‡è¦é—®é¢˜",
    "method": "é€šè¿‡å¯¹1100å¤šä¸ªæ¨¡å‹è¿›è¡Œæ¨¡å¼è°±åˆ†æ",
    "result": "å‘ç°äº†æ•æ‰å¤§éƒ¨åˆ†æ–¹å·®çš„é€šç”¨å­ç©ºé—´",
    "conclusion": "è¿™ä¸€å‘ç°ä¸ºæ¨¡å‹é‡ç”¨å’Œå¤šä»»åŠ¡å­¦ä¹ æä¾›äº†æ–°çš„æ€è·¯"
  }
}
```

### Markdownæ–‡ä»¶

ç”Ÿæˆçš„Markdownæ–‡ä»¶ï¼ˆoutput_md/YYYY-MM-DD.mdï¼‰åŒ…å«å½“æ—¥æ‰€æœ‰è®ºæ–‡çš„è¯¦ç»†ä¿¡æ¯ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

```markdown
# è®ºæ–‡å…¨è§ˆï¼š2025-12-05

å…±æœ‰196ç¯‡ç›¸å…³é¢†åŸŸè®ºæ–‡, å¦æœ‰0ç¯‡å…¶ä»–

## è®¡ç®—æœºè§†è§‰(cs.CV:Computer Vision)

ã€2512.05117ã€‘The Universal Weight Subspace Hypothesis
- **æ ‡é¢˜**: é€šç”¨æƒé‡å­ç©ºé—´å‡è®¾
- **é“¾æ¥**: https://arxiv.org/abs/2512.05117
> **ä½œè€…**: Author1, Author2
> **æ‘˜è¦**: æˆ‘ä»¬è¯æ˜äº†æ·±åº¦ç¥ç»ç½‘ç»œåœ¨ä¸åŒä»»åŠ¡ä¸Šè®­ç»ƒæ—¶ä¼šè¡¨ç°å‡ºéå¸¸ç›¸ä¼¼çš„ä½ç»´å‚æ•°å­ç©ºé—´...
> **Abstract**: We show that deep neural networks trained across diverse tasks exhibit remarkably similar low-dimensional parametric subspaces...

...
```

## ğŸš€ ä½¿ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šæ¯æ—¥è‡ªåŠ¨æ›´æ–°

**ç›®æ ‡**ï¼šæ¯å¤©è‡ªåŠ¨çˆ¬å–æœ€æ–°è®ºæ–‡ï¼Œç”ŸæˆAIå¢å¼ºå†…å®¹ï¼Œå¹¶éƒ¨ç½²åˆ°GitHub Pages

**å®ç°æ­¥éª¤**ï¼š
1. Forkä»“åº“åˆ°è‡ªå·±çš„GitHubè´¦æˆ·
2. é…ç½®`.env`æ–‡ä»¶ï¼Œæ·»åŠ APIå¯†é’¥å’Œå…¶ä»–å‚æ•°
3. å¯ç”¨GitHub Pages
4. è¿è¡ŒGitHub Actions Workflow
5. è®¿é—®GitHub Pagesåœ°å€ï¼ŒæŸ¥çœ‹æ¯æ—¥æ›´æ–°

### æ¡ˆä¾‹2ï¼šæœ¬åœ°çˆ¬å–ç‰¹å®šåˆ†ç±»

**ç›®æ ‡**ï¼šåœ¨æœ¬åœ°çˆ¬å–ç‰¹å®šåˆ†ç±»çš„è®ºæ–‡ï¼Œç”ŸæˆAIå¢å¼ºå†…å®¹ï¼Œå¹¶ä½¿ç”¨Webç•Œé¢æµè§ˆ

**å®ç°æ­¥éª¤**ï¼š
1. å…‹éš†ä»“åº“åˆ°æœ¬åœ°
2. é…ç½®`.env`æ–‡ä»¶ï¼Œè®¾ç½®`CATEGORY_WHITELIST`ä¸ºæ„Ÿå…´è¶£çš„åˆ†ç±»
3. è¿è¡Œ`python run_crawler.py --all`ï¼Œå…¨é‡æ›´æ–°æ•°æ®
4. è¿è¡Œæœ¬åœ°HTTPæœåŠ¡å™¨
5. åœ¨æµè§ˆå™¨ä¸­è®¿é—®ï¼Œæµè§ˆå’Œæœç´¢è®ºæ–‡

### æ¡ˆä¾‹3ï¼šè‡ªå®šä¹‰AIå¢å¼º

**ç›®æ ‡**ï¼šä½¿ç”¨è‡ªå®šä¹‰çš„AIæ¨¡å‹å’Œæç¤ºè¯ï¼Œç”Ÿæˆä¸ªæ€§åŒ–çš„è®ºæ–‡æ‘˜è¦

**å®ç°æ­¥éª¤**ï¼š
1. å…‹éš†ä»“åº“åˆ°æœ¬åœ°
2. é…ç½®`.env`æ–‡ä»¶ï¼Œè®¾ç½®è‡ªå®šä¹‰çš„`MODEL_NAME`å’Œ`OPENAI_BASE_URL`
3. ä¿®æ”¹`ai/template.txt`å’Œ`ai/system.txt`ï¼Œè‡ªå®šä¹‰æç¤ºè¯
4. è¿è¡Œ`python run_crawler.py --date 2025-12-05`ï¼Œæµ‹è¯•ç‰¹å®šæ—¥æœŸçš„AIå¢å¼º
5. æŸ¥çœ‹ç”Ÿæˆçš„AIå¢å¼ºæ–‡ä»¶

### æ¡ˆä¾‹4ï¼šæ•°æ®å¯¼å‡ºä¸åˆ†æ

**ç›®æ ‡**ï¼šå°†çˆ¬å–çš„è®ºæ–‡æ•°æ®å¯¼å‡ºä¸ºCSVæ ¼å¼ï¼Œè¿›è¡Œæ•°æ®åˆ†æ

**å®ç°æ­¥éª¤**ï¼š
1. å…‹éš†ä»“åº“åˆ°æœ¬åœ°
2. è¿è¡Œ`python run_crawler.py --all`ï¼Œå…¨é‡æ›´æ–°æ•°æ®
3. ä½¿ç”¨SQLiteBrowseræ‰“å¼€`papers.db`æ–‡ä»¶
4. æ‰§è¡ŒSQLæŸ¥è¯¢ï¼Œå¯¼å‡ºæ•°æ®ä¸ºCSVæ ¼å¼
5. ä½¿ç”¨Excelæˆ–Pythonè¿›è¡Œæ•°æ®åˆ†æ


## ğŸ“ è®¸å¯è¯

MIT License - è¯¦è§[LICENSE](LICENSE)æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹é¡¹ç›®å’Œè´¡çŒ®è€…ï¼š

- **daily-arXiv-ai-enhanced**ï¼šæä¾›äº†AIå¢å¼ºå’ŒWebç•Œé¢åŠŸèƒ½
- **arxiv_crawler**ï¼šæä¾›äº†å¼ºå¤§çš„arxivçˆ¬å–åŠŸèƒ½
- æ‰€æœ‰ä¸ºæœ¬é¡¹ç›®è´¡çŒ®ä»£ç å’Œæå‡ºå»ºè®®çš„å¼€å‘è€…
- DeepSeek AIï¼šæä¾›äº†å¼ºå¤§çš„AIæ¨¡å‹æ”¯æŒ
- arXivï¼šæä¾›äº†ä¸°å¯Œçš„å­¦æœ¯è®ºæ–‡èµ„æº

## â­ Star History

[![Stargazers over time](https://starchart.cc/dw-dengwei/daily-arXiv-ai-enhanced.svg?variant=adaptive)](https://starchart.cc/dw-dengwei/daily-arXiv-ai-enhanced)

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»æˆ‘ä»¬ï¼š

- GitHub Issuesï¼šhttps://github.com/dw-dengwei/daily-arXiv-ai-enhanced/issues
- GitHub Discussionsï¼šhttps://github.com/dw-dengwei/daily-arXiv-ai-enhanced/discussions
- é‚®ç®±ï¼šyour-email@example.comï¼ˆæ›¿æ¢ä¸ºå®é™…é‚®ç®±ï¼‰

## ğŸ“š ç›¸å…³èµ„æº

- [arxiv.org](https://arxiv.org/)ï¼šåŸå§‹è®ºæ–‡èµ„æº
- [DeepSeek API](https://platform.deepseek.com/)ï¼šAIæ¨¡å‹API
- [GitHub Actions](https://docs.github.com/en/actions)ï¼šè‡ªåŠ¨åŒ–éƒ¨ç½²
- [GitHub Pages](https://pages.github.com/)ï¼šé™æ€ç½‘ç«™æ‰˜ç®¡
- [SQLite](https://www.sqlite.org/index.html)ï¼šè½»é‡çº§æ•°æ®åº“

## ğŸ“ˆ é¡¹ç›®ç»Ÿè®¡

- ä»£ç è¡Œæ•°ï¼šçº¦5000è¡Œ
- æ ¸å¿ƒåŠŸèƒ½æ¨¡å—ï¼š4ä¸ª
- æ”¯æŒçš„AIæ¨¡å‹ï¼šæ‰€æœ‰OpenAIå…¼å®¹æ¨¡å‹
- æ”¯æŒçš„è¯­è¨€ï¼šä¸­æ–‡ã€è‹±æ–‡ç­‰
- æ—¥å¤„ç†èƒ½åŠ›ï¼šçº¦1000ç¯‡è®ºæ–‡
- å¹³å‡AIå¢å¼ºæ—¶é—´ï¼šæ¯ç¯‡çº¦2ç§’

---

**arxiv-crawler-ai-enhanced** - è®©arxivè®ºæ–‡é˜…è¯»æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆï¼ ğŸš€